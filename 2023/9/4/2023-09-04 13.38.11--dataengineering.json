{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHello guys, i need you to score my side project (give a mark :p )... do you think it's worth mentioning in my cv.\n\n[https://github.com/kaoutaar/end-to-end-etl-pipeline-jcdecaux-API](https://github.com/kaoutaar/end-to-end-etl-pipeline-jcdecaux-API)\n\n ", "author_fullname": "t2_cvc17ynu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "checkout my first complete data-engineering project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1695hxl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693768424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, i need you to score my side project (give a mark :p )... do you think it&amp;#39;s worth mentioning in my cv.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/kaoutaar/end-to-end-etl-pipeline-jcdecaux-API\"&gt;https://github.com/kaoutaar/end-to-end-etl-pipeline-jcdecaux-API&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mwWsWb1Y6TsP2cZLY1rvgltSPAwS4sjgwMY6sWxETQ4.jpg?auto=webp&amp;s=76d7ece4bb96d36ad90390b5eb9ff4cd3f3905b6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/mwWsWb1Y6TsP2cZLY1rvgltSPAwS4sjgwMY6sWxETQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=74e75c5e080befb856e6bf80882a0a199e862b17", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/mwWsWb1Y6TsP2cZLY1rvgltSPAwS4sjgwMY6sWxETQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c0363163e4e34598fcf52c313def899f570e5c43", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/mwWsWb1Y6TsP2cZLY1rvgltSPAwS4sjgwMY6sWxETQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=30e52cc5b2bf17d317e132da8bd336c267a01f9f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/mwWsWb1Y6TsP2cZLY1rvgltSPAwS4sjgwMY6sWxETQ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d63fc45c7c1fd25c2fccf1f5b7a1e6bc1e4b47c2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/mwWsWb1Y6TsP2cZLY1rvgltSPAwS4sjgwMY6sWxETQ4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f57de4954d8de950d0dbcf794ff723dde1e3ba1", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/mwWsWb1Y6TsP2cZLY1rvgltSPAwS4sjgwMY6sWxETQ4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d5b6b2630111fa77dd4275295bd688798871390f", "width": 1080, "height": 540}], "variants": {}, "id": "iAITnwdVEVkFvtNuyK7kPfnh_DifbonJZ_Iisyn8JzY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1695hxl", "is_robot_indexable": true, "report_reasons": null, "author": "kaoutar-", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1695hxl/checkout_my_first_complete_dataengineering_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1695hxl/checkout_my_first_complete_dataengineering_project/", "subreddit_subscribers": 126749, "created_utc": 1693768424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please find a simple project I have done in the link below.\nhttps://github.com/JawaharRamis/reddit-streaming-kafka-spark-application\n\nI understand that this is not the best use-case scenario for utilizing kafka but the personal goal of this project was for me to familiarize with the kafka and spark integration. Kindly give me your feedback where and what I can do better. This subreddit has been really helpful during my learning journey and I hope it continues.", "author_fullname": "t2_67og6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First project, Kindly give your feedback and criticisms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169l3p1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693811667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please find a simple project I have done in the link below.\n&lt;a href=\"https://github.com/JawaharRamis/reddit-streaming-kafka-spark-application\"&gt;https://github.com/JawaharRamis/reddit-streaming-kafka-spark-application&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I understand that this is not the best use-case scenario for utilizing kafka but the personal goal of this project was for me to familiarize with the kafka and spark integration. Kindly give me your feedback where and what I can do better. This subreddit has been really helpful during my learning journey and I hope it continues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?auto=webp&amp;s=b5c797a7cbc89d32410d737e255be4271a9d94a6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6d0f5fe2724b02f6b9354f75611f3028e786b76", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=46b9d2e701d1395e1fb3edc77053ad7329266255", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b54599afae812ed83772cd2a9d0908e0cdb0141f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c9e6c1e6ed0ce3ac92deb24e2bb082fbc0791711", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae25156fdfae4669eb338e5e08d1fe323844d13d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6c0f830c434676df456cae9ba8ddadad9b82fc7f", "width": 1080, "height": 540}], "variants": {}, "id": "DaeCVLuQ0lefRgXksGWUNqrs-_dik3hYF9PGv6cMtPo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "169l3p1", "is_robot_indexable": true, "report_reasons": null, "author": "jawz96", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169l3p1/first_project_kindly_give_your_feedback_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169l3p1/first_project_kindly_give_your_feedback_and/", "subreddit_subscribers": 126749, "created_utc": 1693811667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a background in both data engineering (4 y) and software engineering (8 y). So I am not a complete noob. I've worked with various data processing tools like Spark, Beam, and BigQuery. However, my experience with BigQuery has mostly been for analytics purposes. In my current role, one of my primary tasks is to refactor our ETL processes in BigQuery into a more conventional programming setup. I am thinking of Scala+Spark or PySpark. The main reason - we want normal programming language. With tests, functions, etc.\n\nCost issue never was my responsibility, but now it is.\n\nTo assess the potential performance and cost implications of this transition, I decided to run some benchmarks based on our data and transformations patterns. Surprisingly, BigQuery turned out to be extremely efficient! I couldn't achieve anywhere near the same level of performance with Spark \u2013 the difference was substantial, with BigQuery taking about 50 seconds to Spark's 8 minutes. Additionally, in terms of cost, BigQuery came out significantly cheaper. BigQuery charges only for the scanned data bytes, so no matter how complex the computation, it doesn't impact the final cost much. In my benchmark, I observed something like $0.2 in BigQuery compared to $0.9 in Spark.\n\n&amp;#x200B;\n\nAnother thing that impressed me during my analysis is that the shuffle size in BigQuery can be up to 5 or even 10 times larger than the scanned bytes, but it's not charged. Moreover, the performance impact doesn't seem to be as significant as I initially thought. \n\n&amp;#x200B;\n\nWhat's baffling to me is how they achieved such remarkable performance and usability in BigQuery. Now, I'm facing a dilemma. For those of you who've been in a similar situation, have you ever opted for Spark over BigQuery in terms of performance and cost? Or did you choose Spark only because it offered something that BigQuery didn't, like avoiding vendor lock-in, greater extensibility, or other specific features?\n\n&amp;#x200B;\n\nShould I simply accept that running Spark on BigQuery (or possibly Dataproc, as we're still deciding) might be more expensive and slower for our specific use case?\n\n&amp;#x200B;\n\nI'm aware that BigQuery charges not just for computation but also for storage, but for this discussion, I'm mainly focusing on computation to keep the scope manageable.", "author_fullname": "t2_561hhyzn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark vs BigQuery cost and performance benchmarks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1697bu8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693772803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a background in both data engineering (4 y) and software engineering (8 y). So I am not a complete noob. I&amp;#39;ve worked with various data processing tools like Spark, Beam, and BigQuery. However, my experience with BigQuery has mostly been for analytics purposes. In my current role, one of my primary tasks is to refactor our ETL processes in BigQuery into a more conventional programming setup. I am thinking of Scala+Spark or PySpark. The main reason - we want normal programming language. With tests, functions, etc.&lt;/p&gt;\n\n&lt;p&gt;Cost issue never was my responsibility, but now it is.&lt;/p&gt;\n\n&lt;p&gt;To assess the potential performance and cost implications of this transition, I decided to run some benchmarks based on our data and transformations patterns. Surprisingly, BigQuery turned out to be extremely efficient! I couldn&amp;#39;t achieve anywhere near the same level of performance with Spark \u2013 the difference was substantial, with BigQuery taking about 50 seconds to Spark&amp;#39;s 8 minutes. Additionally, in terms of cost, BigQuery came out significantly cheaper. BigQuery charges only for the scanned data bytes, so no matter how complex the computation, it doesn&amp;#39;t impact the final cost much. In my benchmark, I observed something like $0.2 in BigQuery compared to $0.9 in Spark.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Another thing that impressed me during my analysis is that the shuffle size in BigQuery can be up to 5 or even 10 times larger than the scanned bytes, but it&amp;#39;s not charged. Moreover, the performance impact doesn&amp;#39;t seem to be as significant as I initially thought. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s baffling to me is how they achieved such remarkable performance and usability in BigQuery. Now, I&amp;#39;m facing a dilemma. For those of you who&amp;#39;ve been in a similar situation, have you ever opted for Spark over BigQuery in terms of performance and cost? Or did you choose Spark only because it offered something that BigQuery didn&amp;#39;t, like avoiding vendor lock-in, greater extensibility, or other specific features?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Should I simply accept that running Spark on BigQuery (or possibly Dataproc, as we&amp;#39;re still deciding) might be more expensive and slower for our specific use case?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that BigQuery charges not just for computation but also for storage, but for this discussion, I&amp;#39;m mainly focusing on computation to keep the scope manageable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1697bu8", "is_robot_indexable": true, "report_reasons": null, "author": "myhl_I", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1697bu8/spark_vs_bigquery_cost_and_performance_benchmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1697bu8/spark_vs_bigquery_cost_and_performance_benchmarks/", "subreddit_subscribers": 126749, "created_utc": 1693772803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked in data since 2019. Got my to Senior level last year and being paid in the mid \u00a350K zone. Some of the practices in my current workplace I'm not happy about but I've been able to secure a small pay rise as well as a chance to start a Level 7 AI Apprenticeship coming up in October.\n\nI pushed for it as it was something that: \n\n1. I'm interested in and want to eventually open my own business doing something within AI. \n2. I'd be able to own/create a new MLOps department which will most likely stretch into developing AI solutions.\n\nHowever, for the 3rd time in the past 6 months I've been offered Senior titles with wages in the \u00a380K zone and at first i thought it was just recruiters being recruiters but this one I went through the motions and have been offered \u00a390K which is more than I asked for. This has only happened for me twice and it was in my role before my current role and now. \n\nI got myself where I am today, by sheer force and learning power. No academic background... Hell, I don't even hold a Maths GCSE. So I'm struggling to pick between the money and a masters degree equivalent in a field I'm highly interested in.\n\nMy partner says do what makes you happy, my parents say take the money, my friends have actually stopped talking to me since they revealed they earn under the \u00a330K mark and now seem to just ghost me all the time... but that's for another thread I guess. \n\nSo, i thought reaching out to people in my role and see what you would all do in this situation?", "author_fullname": "t2_al2yxww8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Been working at a business for just over a year as a Senior Data Engineer. I've been offered to take a LVL 7 AI Apprenticeship but I've been headhunted for another role closer to home for a lot more money. Struggling with which choice will be the right one so looking for some advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169mqdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693817335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked in data since 2019. Got my to Senior level last year and being paid in the mid \u00a350K zone. Some of the practices in my current workplace I&amp;#39;m not happy about but I&amp;#39;ve been able to secure a small pay rise as well as a chance to start a Level 7 AI Apprenticeship coming up in October.&lt;/p&gt;\n\n&lt;p&gt;I pushed for it as it was something that: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I&amp;#39;m interested in and want to eventually open my own business doing something within AI. &lt;/li&gt;\n&lt;li&gt;I&amp;#39;d be able to own/create a new MLOps department which will most likely stretch into developing AI solutions.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;However, for the 3rd time in the past 6 months I&amp;#39;ve been offered Senior titles with wages in the \u00a380K zone and at first i thought it was just recruiters being recruiters but this one I went through the motions and have been offered \u00a390K which is more than I asked for. This has only happened for me twice and it was in my role before my current role and now. &lt;/p&gt;\n\n&lt;p&gt;I got myself where I am today, by sheer force and learning power. No academic background... Hell, I don&amp;#39;t even hold a Maths GCSE. So I&amp;#39;m struggling to pick between the money and a masters degree equivalent in a field I&amp;#39;m highly interested in.&lt;/p&gt;\n\n&lt;p&gt;My partner says do what makes you happy, my parents say take the money, my friends have actually stopped talking to me since they revealed they earn under the \u00a330K mark and now seem to just ghost me all the time... but that&amp;#39;s for another thread I guess. &lt;/p&gt;\n\n&lt;p&gt;So, i thought reaching out to people in my role and see what you would all do in this situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169mqdp", "is_robot_indexable": true, "report_reasons": null, "author": "The-Engineer-93", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169mqdp/been_working_at_a_business_for_just_over_a_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169mqdp/been_working_at_a_business_for_just_over_a_year/", "subreddit_subscribers": 126749, "created_utc": 1693817335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.dremio.com/pricing/](https://www.dremio.com/pricing/)  \n\n\nWhat is the business idea behind it? Also, I've see another provider (some new company), I don't remember the name, offering the same forever free, infinite scale. Why?  \n\n\nI do understand two facts:  \n\n\n1. In the end of the day, compute and storage resources run on the underlying cloud provider, for example, AWS.   \n\n2. The enterprise plan will allways propose features we need to fully run, mostly security features.\n\n&amp;#x200B;\n\nBut, everyone understands it. So what is the point in having something that seems like free forever, but we all know it's not useful for real data platforms?   \n\n\nHope to honestly understand it. :)   \n\n\n&amp;#x200B;", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where is the catch with Dremio's forever free plan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168z4sy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693753066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.dremio.com/pricing/\"&gt;https://www.dremio.com/pricing/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;What is the business idea behind it? Also, I&amp;#39;ve see another provider (some new company), I don&amp;#39;t remember the name, offering the same forever free, infinite scale. Why?  &lt;/p&gt;\n\n&lt;p&gt;I do understand two facts:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;In the end of the day, compute and storage resources run on the underlying cloud provider, for example, AWS.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The enterprise plan will allways propose features we need to fully run, mostly security features.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But, everyone understands it. So what is the point in having something that seems like free forever, but we all know it&amp;#39;s not useful for real data platforms?   &lt;/p&gt;\n\n&lt;p&gt;Hope to honestly understand it. :)   &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eGBPrHRptGctgpZu5KfLoQsrw71H8kwDpdhQcxFHyx4.jpg?auto=webp&amp;s=98daffe98c29cff42b94e180c9bbfd45d9b2bed9", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/eGBPrHRptGctgpZu5KfLoQsrw71H8kwDpdhQcxFHyx4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=980e2d8920e2721ac7f36d478b50ed39dc31bbdf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/eGBPrHRptGctgpZu5KfLoQsrw71H8kwDpdhQcxFHyx4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb0507399da410c42749d974532918fca7e86bef", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/eGBPrHRptGctgpZu5KfLoQsrw71H8kwDpdhQcxFHyx4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf51a382af9a14570a603386d1b6b52c88200e76", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/eGBPrHRptGctgpZu5KfLoQsrw71H8kwDpdhQcxFHyx4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=084c18286444d29b3eefd7ccd7be3d4871eeb78c", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/eGBPrHRptGctgpZu5KfLoQsrw71H8kwDpdhQcxFHyx4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a605f4f51e1ff40edfd3163edc803f3355286842", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/eGBPrHRptGctgpZu5KfLoQsrw71H8kwDpdhQcxFHyx4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69de0ad76242e5f72eb1ac9b2809aa4147fd192b", "width": 1080, "height": 565}], "variants": {}, "id": "k2T-wtT1nA9No3UeiA9JrBspx4x-R3VGx1GRjqXPHdQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "168z4sy", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/168z4sy/where_is_the_catch_with_dremios_forever_free_plan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/168z4sy/where_is_the_catch_with_dremios_forever_free_plan/", "subreddit_subscribers": 126749, "created_utc": 1693753066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to connect specially marketing related APIs such as Google Ads, GA4, Instagram Insights, Instagram Ads, Meta Ads, TikTok Ads, Youtube API, Pinterest Ads, etc and ideally push a copy of the data into a PostgreSQL hosted on AWS, GCP or worst case Azure.\n\nThe ultimate idea is that I want to pull the data from these marketing APIs and have near real time dashboards created with Superset (I already have my Superset instance set up and working).\n\nHowever, my mains skills are related to data analytics and some cloud infrastructure, not data engineering per se, therefore I can't write ad hoc code to connect to each API by myself.\n\nSo far I've researched about [nocodeapi.com](https://nocodeapi.com), Airbyte Open Source, [Singer.io](https://Singer.io) and [integrate](https://integrate.io).io, which I'll be testing during the week and sharing my findings.", "author_fullname": "t2_yikhi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you recommend an open source (or low cost software) that enables connecting to APIs without code or low code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169eq5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693791963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to connect specially marketing related APIs such as Google Ads, GA4, Instagram Insights, Instagram Ads, Meta Ads, TikTok Ads, Youtube API, Pinterest Ads, etc and ideally push a copy of the data into a PostgreSQL hosted on AWS, GCP or worst case Azure.&lt;/p&gt;\n\n&lt;p&gt;The ultimate idea is that I want to pull the data from these marketing APIs and have near real time dashboards created with Superset (I already have my Superset instance set up and working).&lt;/p&gt;\n\n&lt;p&gt;However, my mains skills are related to data analytics and some cloud infrastructure, not data engineering per se, therefore I can&amp;#39;t write ad hoc code to connect to each API by myself.&lt;/p&gt;\n\n&lt;p&gt;So far I&amp;#39;ve researched about &lt;a href=\"https://nocodeapi.com\"&gt;nocodeapi.com&lt;/a&gt;, Airbyte Open Source, &lt;a href=\"https://Singer.io\"&gt;Singer.io&lt;/a&gt; and &lt;a href=\"https://integrate.io\"&gt;integrate&lt;/a&gt;.io, which I&amp;#39;ll be testing during the week and sharing my findings.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169eq5i", "is_robot_indexable": true, "report_reasons": null, "author": "gglavida", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169eq5i/can_you_recommend_an_open_source_or_low_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169eq5i/can_you_recommend_an_open_source_or_low_cost/", "subreddit_subscribers": 126749, "created_utc": 1693791963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is another one of the noob career advice posts, I hope more experienced people in this subreddit are not inundated by them. I am sorry if this one will be a bit long.\n\nA bit of background first (feel free to skip if this is too long):\n\nI have an economics degree, and all of my programming knowledge is self-taught as needed.\n\nI started my career as DA in a very antiquated consulting firm which did everything in Excel manually, with a bit of SAS (which I did not write). I did some automation of very repetitive tasks there (first in VBA then in Python), and I liked doing it a lot, but ultimately management told me \"You are not a software engineer so don't try to build your own tools, work with the tools you are given and focus on the business.\" I did not like the client-facing side (I had to make and deliver power-point presentations to people with scary big titles), so I left. That was a about a year ago.\n\nMy second and current employer is a mid-sized product company. I also joined as DA, in an \"analytics\" team which primarily is focused on automated regular reports. We do work in Python, but it was quite \"low-tech\" - our orchestration tool is cron, most people have never written code outside of Jupyter notebook, until a few months ago all our Git repos had only 1 branch called master. My managers heard that I liked the \"technical\" side so I was primarily given such tasks - scripts, managing the internal team server, moving stuff from crontab to Airflow, refactoring old scripts, writing a \"git guide\" for people on the team, etc. I actually do not think I am the most qualified person with this, even on the team, but I seem to be the only one who wants this work as other people want to go more into ML or into business/leadership track.\n\nNow the actual situation:\n\nRecently some high-level people joined to build the \"Data organization\" across the company, started talking about reorganizing and they had the perspective of \"data analysts create requirements, data engineers create and ship solutions\". They hired a team of data engineers in one of our Asia offices - these guys are quite closed and I cannot switch there. I saw the danger and asked my managers to make me an Analytics Engineer to make sure I don't get stuck in the business-facing role again. Surprisingly, they told me \"we don't expect Analytics Engineers in the org, but we will make you a Data Engineer\", and so it was done.\n\nRight now I have a title, but I do not know how to live up to it. I look at code that other people who are Data Engineers put out, and it is clear I am not on that level. I have never built a Python package into a wheel, I understand what Docker does but have never used it, and when I open a module that has a lot of custom classes, decorators and extensions in it - I panic. I do know some PySpark as we have a Spark cluster, but I do not know enough about the insides of Spark to optimize it well. I recently started reading Kleppmann but the idea that at some point I will have to actually use that knowledge about what database replicates using a master or using a quorum, and that production will depend on it, scares me.\n\nWhat maybe scares me even more is that because of the \"analysts are not engineers\" perspective the team does not have a tech lead. I tried to introduce code reviews as a practice in the team, but people on my team can review the business logic of what I write, but not the codestyle or abstraction choices I make. When I have technical questions (\"what tool do we need here?\"), I have to pester other teams with questions, and some of them (like the DE team in Asia) clearly do not like it as it is not their job to support me.\n\nIn such conditions, what can I focus on and do to actually grow into my Data Engineer position and make sure I can stay in this career field? I like the work, and I do not want to go back to \"business side\", but I feel like I am going toward a dead end.\n\nAnd thank you if you read through all that.\n\n&amp;#x200B;", "author_fullname": "t2_iz8jz8e2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DA, ended up with a DE title, I want to live up to it - how?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169e9tj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693792399.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693790628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is another one of the noob career advice posts, I hope more experienced people in this subreddit are not inundated by them. I am sorry if this one will be a bit long.&lt;/p&gt;\n\n&lt;p&gt;A bit of background first (feel free to skip if this is too long):&lt;/p&gt;\n\n&lt;p&gt;I have an economics degree, and all of my programming knowledge is self-taught as needed.&lt;/p&gt;\n\n&lt;p&gt;I started my career as DA in a very antiquated consulting firm which did everything in Excel manually, with a bit of SAS (which I did not write). I did some automation of very repetitive tasks there (first in VBA then in Python), and I liked doing it a lot, but ultimately management told me &amp;quot;You are not a software engineer so don&amp;#39;t try to build your own tools, work with the tools you are given and focus on the business.&amp;quot; I did not like the client-facing side (I had to make and deliver power-point presentations to people with scary big titles), so I left. That was a about a year ago.&lt;/p&gt;\n\n&lt;p&gt;My second and current employer is a mid-sized product company. I also joined as DA, in an &amp;quot;analytics&amp;quot; team which primarily is focused on automated regular reports. We do work in Python, but it was quite &amp;quot;low-tech&amp;quot; - our orchestration tool is cron, most people have never written code outside of Jupyter notebook, until a few months ago all our Git repos had only 1 branch called master. My managers heard that I liked the &amp;quot;technical&amp;quot; side so I was primarily given such tasks - scripts, managing the internal team server, moving stuff from crontab to Airflow, refactoring old scripts, writing a &amp;quot;git guide&amp;quot; for people on the team, etc. I actually do not think I am the most qualified person with this, even on the team, but I seem to be the only one who wants this work as other people want to go more into ML or into business/leadership track.&lt;/p&gt;\n\n&lt;p&gt;Now the actual situation:&lt;/p&gt;\n\n&lt;p&gt;Recently some high-level people joined to build the &amp;quot;Data organization&amp;quot; across the company, started talking about reorganizing and they had the perspective of &amp;quot;data analysts create requirements, data engineers create and ship solutions&amp;quot;. They hired a team of data engineers in one of our Asia offices - these guys are quite closed and I cannot switch there. I saw the danger and asked my managers to make me an Analytics Engineer to make sure I don&amp;#39;t get stuck in the business-facing role again. Surprisingly, they told me &amp;quot;we don&amp;#39;t expect Analytics Engineers in the org, but we will make you a Data Engineer&amp;quot;, and so it was done.&lt;/p&gt;\n\n&lt;p&gt;Right now I have a title, but I do not know how to live up to it. I look at code that other people who are Data Engineers put out, and it is clear I am not on that level. I have never built a Python package into a wheel, I understand what Docker does but have never used it, and when I open a module that has a lot of custom classes, decorators and extensions in it - I panic. I do know some PySpark as we have a Spark cluster, but I do not know enough about the insides of Spark to optimize it well. I recently started reading Kleppmann but the idea that at some point I will have to actually use that knowledge about what database replicates using a master or using a quorum, and that production will depend on it, scares me.&lt;/p&gt;\n\n&lt;p&gt;What maybe scares me even more is that because of the &amp;quot;analysts are not engineers&amp;quot; perspective the team does not have a tech lead. I tried to introduce code reviews as a practice in the team, but people on my team can review the business logic of what I write, but not the codestyle or abstraction choices I make. When I have technical questions (&amp;quot;what tool do we need here?&amp;quot;), I have to pester other teams with questions, and some of them (like the DE team in Asia) clearly do not like it as it is not their job to support me.&lt;/p&gt;\n\n&lt;p&gt;In such conditions, what can I focus on and do to actually grow into my Data Engineer position and make sure I can stay in this career field? I like the work, and I do not want to go back to &amp;quot;business side&amp;quot;, but I feel like I am going toward a dead end.&lt;/p&gt;\n\n&lt;p&gt;And thank you if you read through all that.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "169e9tj", "is_robot_indexable": true, "report_reasons": null, "author": "yetanotherfakede", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169e9tj/da_ended_up_with_a_de_title_i_want_to_live_up_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169e9tj/da_ended_up_with_a_de_title_i_want_to_live_up_to/", "subreddit_subscribers": 126749, "created_utc": 1693790628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Year 1\n\n* **Communication for the IT Professional**\n* **Internetworking**\n* **Virtualisation**\n* **Professional Issues in IT**\n* **Introduction to Programming**\n* **Internetworking 1**\n* **Introduction to Cyber Security**\n* **Introduction to Databases**\n\nYear 2\n\n* **Advanced data analysis**\n* **Introduction to data analysis**\n* **Network Security**\n* **Critical Thinking for the IT Professional**\n* **Project Management**\n* **Data infrastructure engineering**\n* **Machine learning**\n\nYear 3\n\n* **Data and network security**\n* **Data mining and visualisation**\n* **Emerging trends in data technology**\n* **Major Group Project**\n* **Major Individual Project**\n* **Mobile Computing and Security**\n\nElectives:\n\n* **National Data Infrastructure Security**\n* **Software defined and programmable networks**\n* **Secure Programming**\n* **Cloud Computing**\n* **Distributed computing**\n* **Computer and Network Forensics**\n* **Enterprise Security**\n* **Introduction to Cryptography**\n* **Fundamentals of computer science**\n* **Knowledge Management**\n* **Wireless Networks**\n\nAdditionally, which electives would you recommend me taking?", "author_fullname": "t2_5pilhaal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these good courses for a Bachelor of IT (Data Engineering) degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169oy1d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693824981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Year 1&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Communication for the IT Professional&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Internetworking&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Virtualisation&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Professional Issues in IT&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to Programming&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Internetworking 1&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to Cyber Security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to Databases&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Year 2&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Advanced data analysis&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to data analysis&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Network Security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Critical Thinking for the IT Professional&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Project Management&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data infrastructure engineering&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Machine learning&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Year 3&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data and network security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data mining and visualisation&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Emerging trends in data technology&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Major Group Project&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Major Individual Project&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Mobile Computing and Security&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Electives:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;National Data Infrastructure Security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Software defined and programmable networks&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Secure Programming&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Cloud Computing&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Distributed computing&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Computer and Network Forensics&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enterprise Security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to Cryptography&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fundamentals of computer science&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Knowledge Management&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Wireless Networks&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Additionally, which electives would you recommend me taking?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169oy1d", "is_robot_indexable": true, "report_reasons": null, "author": "groovyeverywhere", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169oy1d/are_these_good_courses_for_a_bachelor_of_it_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169oy1d/are_these_good_courses_for_a_bachelor_of_it_data/", "subreddit_subscribers": 126749, "created_utc": 1693824981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would love to hear how you build data sharing api's and what tools you use?\n\nour data is of course across many tables. we need to join it and create metrics to share out. Would like to know how everyone approaches this", "author_fullname": "t2_8ijlx2ot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you build data sharing apis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169o1uv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693821956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would love to hear how you build data sharing api&amp;#39;s and what tools you use?&lt;/p&gt;\n\n&lt;p&gt;our data is of course across many tables. we need to join it and create metrics to share out. Would like to know how everyone approaches this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169o1uv", "is_robot_indexable": true, "report_reasons": null, "author": "Itchy-Side4624", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169o1uv/how_do_you_build_data_sharing_apis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169o1uv/how_do_you_build_data_sharing_apis/", "subreddit_subscribers": 126749, "created_utc": 1693821956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ken jee is Data scientist. He has been doing data work from 7 years. In my opinion he is good at explaining how the data industry works and seems legitimate.\n\nAlthough I have a question to ask, Is this true the supply is very less in data engineer roles? I even heard from Mike west (who is data engineer, and working for several years with big companies, also creator), that data engineer is probably the most sexiest job than data scientist or any other tech jobs.\n\nI just want to start a discussion here regarding this. The reason is that many people complain a lot that the job market is dry and there aren't many jobs available. I genuinely believe it's because of their competence as data engineers.\n\nSource: https://youtube.com/shorts/L6lXKdP4Qbg?si=fjUKofmNk7DE75yf", "author_fullname": "t2_8i81bbqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are the supply &amp; demand of data roles is imbalanced??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_169r2hc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693831567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ken jee is Data scientist. He has been doing data work from 7 years. In my opinion he is good at explaining how the data industry works and seems legitimate.&lt;/p&gt;\n\n&lt;p&gt;Although I have a question to ask, Is this true the supply is very less in data engineer roles? I even heard from Mike west (who is data engineer, and working for several years with big companies, also creator), that data engineer is probably the most sexiest job than data scientist or any other tech jobs.&lt;/p&gt;\n\n&lt;p&gt;I just want to start a discussion here regarding this. The reason is that many people complain a lot that the job market is dry and there aren&amp;#39;t many jobs available. I genuinely believe it&amp;#39;s because of their competence as data engineers.&lt;/p&gt;\n\n&lt;p&gt;Source: &lt;a href=\"https://youtube.com/shorts/L6lXKdP4Qbg?si=fjUKofmNk7DE75yf\"&gt;https://youtube.com/shorts/L6lXKdP4Qbg?si=fjUKofmNk7DE75yf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4JBLh-yGMSKGFsBNT97ayxOu5hNuh6GfyMyCdMznDu8.jpg?auto=webp&amp;s=284c4eaad296ca46a881d8e20ae5195d46c4f76c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/4JBLh-yGMSKGFsBNT97ayxOu5hNuh6GfyMyCdMznDu8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=193cdd2d67b1693b4e5262105f518928bfccaba3", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/4JBLh-yGMSKGFsBNT97ayxOu5hNuh6GfyMyCdMznDu8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7709b97108eda8e31a2d90a9177f7cd5eca62fa1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/4JBLh-yGMSKGFsBNT97ayxOu5hNuh6GfyMyCdMznDu8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=210abbe77d05f697efcf3c28a02951ec73b4a9e3", "width": 320, "height": 240}], "variants": {}, "id": "qMhhR0bFWhCJIv4Go9Ra8jRditTLzZ8IORfOcVIAcvM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169r2hc", "is_robot_indexable": true, "report_reasons": null, "author": "trafalgar28", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169r2hc/are_the_supply_demand_of_data_roles_is_imbalanced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169r2hc/are_the_supply_demand_of_data_roles_is_imbalanced/", "subreddit_subscribers": 126749, "created_utc": 1693831567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, Reddit community!\n\nI'm interested in obtaining the Google Cloud Platform (GCP) Professional Data Engineer Certification, and I'd like to know what the best up-to-date course is in 2023 to prepare effectively. I understand that technologies and best practices can change over time, so I'm looking for the latest recommendations.\n\nIf you've recently earned this certification or if you're aware of the most current courses, I would greatly appreciate your advice and suggestions. I'm seeking high-quality resources that cover all aspects of the exam and provide a solid understanding of the skills required to succeed in the field of cloud data engineering.\n\nAdditionally, if you have any personal experiences you'd like to share regarding exam preparation or any other helpful tips, please do so! I'm confident that other community members will also benefit from your insights.", "author_fullname": "t2_14y86z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the Best Up-to-Date Course for Preparing for the GCP Professional Data Engineer Certification in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169jlvc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693806830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, Reddit community!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in obtaining the Google Cloud Platform (GCP) Professional Data Engineer Certification, and I&amp;#39;d like to know what the best up-to-date course is in 2023 to prepare effectively. I understand that technologies and best practices can change over time, so I&amp;#39;m looking for the latest recommendations.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve recently earned this certification or if you&amp;#39;re aware of the most current courses, I would greatly appreciate your advice and suggestions. I&amp;#39;m seeking high-quality resources that cover all aspects of the exam and provide a solid understanding of the skills required to succeed in the field of cloud data engineering.&lt;/p&gt;\n\n&lt;p&gt;Additionally, if you have any personal experiences you&amp;#39;d like to share regarding exam preparation or any other helpful tips, please do so! I&amp;#39;m confident that other community members will also benefit from your insights.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169jlvc", "is_robot_indexable": true, "report_reasons": null, "author": "whitekuriboh", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/169jlvc/whats_the_best_uptodate_course_for_preparing_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169jlvc/whats_the_best_uptodate_course_for_preparing_for/", "subreddit_subscribers": 126749, "created_utc": 1693806830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you move semistructured data such as JSON CSV from an external data source to an internal data warehouse? Curious about how different companies handle this process. Do you have specific tools or customized automation processes for these types of data?", "author_fullname": "t2_3prcs1n2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data pipeline question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169doaa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693788909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you move semistructured data such as JSON CSV from an external data source to an internal data warehouse? Curious about how different companies handle this process. Do you have specific tools or customized automation processes for these types of data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169doaa", "is_robot_indexable": true, "report_reasons": null, "author": "Mastermind6688", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169doaa/data_pipeline_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169doaa/data_pipeline_question/", "subreddit_subscribers": 126749, "created_utc": 1693788909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear all, \nI am trying to implement an interface between an ERP system and a MES system. \nProduction orders (po) shall be transferred when released in the erp system. Communication is done via REST.\n\nI am not sure which architektur to pick.\nOn the one hand, I could implement a trigger in the ERP system via programming that when a po is released necessary data will be transferred. On the other hand, I could implement CDC (log based change data capture) on sql server side. \n\nMy toughts: Since you can manipulate the status of an PO at many different places in the system I will need a lot of coding. I would rather try to avoid this. With the sql Solution, I would watch only one table for changes. \n\nAppreciate your thoughts!", "author_fullname": "t2_rvcqr61d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MES - ERP Interface", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_169qt5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693830798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all, \nI am trying to implement an interface between an ERP system and a MES system. \nProduction orders (po) shall be transferred when released in the erp system. Communication is done via REST.&lt;/p&gt;\n\n&lt;p&gt;I am not sure which architektur to pick.\nOn the one hand, I could implement a trigger in the ERP system via programming that when a po is released necessary data will be transferred. On the other hand, I could implement CDC (log based change data capture) on sql server side. &lt;/p&gt;\n\n&lt;p&gt;My toughts: Since you can manipulate the status of an PO at many different places in the system I will need a lot of coding. I would rather try to avoid this. With the sql Solution, I would watch only one table for changes. &lt;/p&gt;\n\n&lt;p&gt;Appreciate your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169qt5h", "is_robot_indexable": true, "report_reasons": null, "author": "Limp_Recording3399", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169qt5h/mes_erp_interface/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169qt5h/mes_erp_interface/", "subreddit_subscribers": 126749, "created_utc": 1693830798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Why Data Craves Product Managers Beyond Doubt\": The Data Product Manager, Product Strategies, and the Pointless War on Definitions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_169pysz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CyJSDqToa-p8X411gFwiksqFpoijnF4iWhMAXF8Mn0M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693828303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/unveiling-a-necessity-why-data-craves", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?auto=webp&amp;s=bc3e828bb0254b9dddcb46350602ea32b1ce35ec", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=91222858a7a91f974fa1ed8f5041c3059afa21a3", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1d03e9048f845f06239a80a12e2bbea5e1bdc81d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=10dd292a124cfa0530368c0804eaa7407bfe42a0", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b8406e434fd7593c3f9d58bf2493eba70e8a2a4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=94a8623dd89033cd0a0a39c0cec1316ea6e5a770", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b8df557ea182c92f684b3f21d04a7b3b12ad8576", "width": 1080, "height": 540}], "variants": {}, "id": "nuFhIdW5-Vx-iWhaSXDeNr7dLeCdylJgzLdJOMDHyTM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "169pysz", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169pysz/why_data_craves_product_managers_beyond_doubt_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/unveiling-a-necessity-why-data-craves", "subreddit_subscribers": 126749, "created_utc": 1693828303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nChecking in to see if any of you would share some input regarding the following problem I'm currently looking into. \n\nUse case: \n\nMy departement have manually been maintaining around 100-150 SQL tables by writing insert queries to update or modify the data. The data is typically \"business knowledge\", which is not available through any of our other systems. We're now moving out of our onprem platform, and thus - need to migrate these tables as well. I'm currently looking into tooling's which can simplify this experience, but I'm struggling to find a solid candidate.\n\n&amp;#x200B;\n\nI want something that is easy to use for the business, so we can transfer the ownership back to them and not have to maintain this on our own, but rather just read the data on a need to basis. preferably I'd like to connect directly to an Azure SQL server if possible. Also, additional things like data quality rules, access management, etc. are nice to haves. \n\n&amp;#x200B;\n\nDoes anyone have any suggestions or experience to add here? The more seasoned guys are talking about MDS and Microsoft Access as potential products but have little to no experience regarding any of them.  Any input weel be much appreciated \n\n&amp;#x200B;\n\nAdditional Info:\n\n* Primarily azure stack \n* Can create some low-code/no-code solutions using PowerApps ", "author_fullname": "t2_4dzyhxpi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience regarding tooling for manual data entry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_169puga", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693827931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;Checking in to see if any of you would share some input regarding the following problem I&amp;#39;m currently looking into. &lt;/p&gt;\n\n&lt;p&gt;Use case: &lt;/p&gt;\n\n&lt;p&gt;My departement have manually been maintaining around 100-150 SQL tables by writing insert queries to update or modify the data. The data is typically &amp;quot;business knowledge&amp;quot;, which is not available through any of our other systems. We&amp;#39;re now moving out of our onprem platform, and thus - need to migrate these tables as well. I&amp;#39;m currently looking into tooling&amp;#39;s which can simplify this experience, but I&amp;#39;m struggling to find a solid candidate.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want something that is easy to use for the business, so we can transfer the ownership back to them and not have to maintain this on our own, but rather just read the data on a need to basis. preferably I&amp;#39;d like to connect directly to an Azure SQL server if possible. Also, additional things like data quality rules, access management, etc. are nice to haves. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any suggestions or experience to add here? The more seasoned guys are talking about MDS and Microsoft Access as potential products but have little to no experience regarding any of them.  Any input weel be much appreciated &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Additional Info:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Primarily azure stack &lt;/li&gt;\n&lt;li&gt;Can create some low-code/no-code solutions using PowerApps &lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169puga", "is_robot_indexable": true, "report_reasons": null, "author": "ejn999", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169puga/experience_regarding_tooling_for_manual_data_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169puga/experience_regarding_tooling_for_manual_data_entry/", "subreddit_subscribers": 126749, "created_utc": 1693827931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a background for this, in my current workplace we don't necessarily have a huge volume of data but the variance is high. We have a graph data model so each row of data from our customers might end up being split into 25 different nodes (or objects, it\nif you like). We have been heavily relying on Pydantic for this, in conjunction with some asyncio coding, but it's still just a simple iteration going on. We plan to do this through Redpanda or RabbitMQ down the line, for now it's just fine. Essentially this is our E and T stage in ETL.\n\nI am curious to know how others have been using schema validator like Pydantic in other usecases as well!", "author_fullname": "t2_12lkky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you using Pydantic for data projects? (and other similar schema libraries)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169ooln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693824102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a background for this, in my current workplace we don&amp;#39;t necessarily have a huge volume of data but the variance is high. We have a graph data model so each row of data from our customers might end up being split into 25 different nodes (or objects, it\nif you like). We have been heavily relying on Pydantic for this, in conjunction with some asyncio coding, but it&amp;#39;s still just a simple iteration going on. We plan to do this through Redpanda or RabbitMQ down the line, for now it&amp;#39;s just fine. Essentially this is our E and T stage in ETL.&lt;/p&gt;\n\n&lt;p&gt;I am curious to know how others have been using schema validator like Pydantic in other usecases as well!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Plumber", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169ooln", "is_robot_indexable": true, "report_reasons": null, "author": "ratulotron", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/169ooln/how_are_you_using_pydantic_for_data_projects_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169ooln/how_are_you_using_pydantic_for_data_projects_and/", "subreddit_subscribers": 126749, "created_utc": 1693824102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, we currently download geographical data from various APIs and save this data in an Azure Datalake. Then, we transform this data and store it back in the Datalake. We use these transformed data as input for a forecasting algorithm, and subsequently save this forecast back into the Datalake. Lastly, we utilize these data to integrate into our portal. At present, we manually create a data warehouse using Python and PostgreSQL, attempting to log every operation conducted in our Datalake along with its metadata. This is to avoid making many API calls to the Datalake listing all the files, as our forecasting algorithms require accessing multiple data from previous days. The problem is, it feels like we're trying to reinvent the wheel and the system became complex during development. Is there an existing solution to help us with this use case of automatically cataloging our data in a Datalake? It could be a Python library or a tool that we can host on an Azure machine. I am new to this area, so I would like suggestions.", "author_fullname": "t2_9ca451os", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for data warehouse tools for my use case", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169o71m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693822448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, we currently download geographical data from various APIs and save this data in an Azure Datalake. Then, we transform this data and store it back in the Datalake. We use these transformed data as input for a forecasting algorithm, and subsequently save this forecast back into the Datalake. Lastly, we utilize these data to integrate into our portal. At present, we manually create a data warehouse using Python and PostgreSQL, attempting to log every operation conducted in our Datalake along with its metadata. This is to avoid making many API calls to the Datalake listing all the files, as our forecasting algorithms require accessing multiple data from previous days. The problem is, it feels like we&amp;#39;re trying to reinvent the wheel and the system became complex during development. Is there an existing solution to help us with this use case of automatically cataloging our data in a Datalake? It could be a Python library or a tool that we can host on an Azure machine. I am new to this area, so I would like suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169o71m", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableAstronaut77", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169o71m/looking_for_data_warehouse_tools_for_my_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169o71m/looking_for_data_warehouse_tools_for_my_use_case/", "subreddit_subscribers": 126749, "created_utc": 1693822448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I believe this to still be in the data engineering realm but I\u2019m talking about the best ways to keep up with trends and vendors in the API landscape such as Mulesoft, Boomi, Apigee, SnapLogic, Azure AIS, etc\u2026\n\nMy role requires me to dabble in that space a bit and I\u2019d like to learn more and find ways to keep up with trends.\n\nI know this sub tends to focus more on the data pipeline space and not necessarily the integration space but figured there would be some overlap.", "author_fullname": "t2_lsj9hxhk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good ways to keep up with the API management landscape?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169bq4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693783497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I believe this to still be in the data engineering realm but I\u2019m talking about the best ways to keep up with trends and vendors in the API landscape such as Mulesoft, Boomi, Apigee, SnapLogic, Azure AIS, etc\u2026&lt;/p&gt;\n\n&lt;p&gt;My role requires me to dabble in that space a bit and I\u2019d like to learn more and find ways to keep up with trends.&lt;/p&gt;\n\n&lt;p&gt;I know this sub tends to focus more on the data pipeline space and not necessarily the integration space but figured there would be some overlap.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169bq4n", "is_robot_indexable": true, "report_reasons": null, "author": "CorgiSideEye", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169bq4n/what_are_some_good_ways_to_keep_up_with_the_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169bq4n/what_are_some_good_ways_to_keep_up_with_the_api/", "subreddit_subscribers": 126749, "created_utc": 1693783497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We used to insert data into the database using asyncpg/psycopg by passing insert query with parameters being the values to insert. I consider this not very safe and pretty loose as if the schema changes it will break the inserts. \n\nWhat is your approach for inserting data? I thought of something maybe like SQLAlchemy? Or validating each record using pydantic?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Safe inserts using python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169162b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693758116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We used to insert data into the database using asyncpg/psycopg by passing insert query with parameters being the values to insert. I consider this not very safe and pretty loose as if the schema changes it will break the inserts. &lt;/p&gt;\n\n&lt;p&gt;What is your approach for inserting data? I thought of something maybe like SQLAlchemy? Or validating each record using pydantic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169162b", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169162b/safe_inserts_using_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169162b/safe_inserts_using_python/", "subreddit_subscribers": 126749, "created_utc": 1693758116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I've just started to learn Spark, it's said that Spark has advantage over Hadoop to process data on RAM level across multiple nodes.\n\nNow I'm practicing to use PySpark to work with dataframes, and looking at some documents and tutorials online I can see the following step I could do is get hands on data processing and machine learning modeling via PySpark framework.\n\nBut I can't see the strengths of Spark so far, from what I see I can do all these works without Spark.\n\nI can do data manipulation with Pandas, can train machine learning model with scikit-learn...all of these 'guides', 'sharing', 'tutorial' I found introducing Spark seems to use it as another normal python library.\n\nI haven't see any posts or sharings to utilize Spark to display the strength of it's parallel processing ability, speed up the processing time for large scale data and so on.\n\n&amp;#x200B;\n\nI'm confusing what I can do with Spark right now, is there any sharings or resources that have guide about how to make the most of Spark? \n\nThanks a lot for any advice!", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any tutorial/sharing/projects/demonstration about using Spark to create effective data pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168wq12", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693746832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I&amp;#39;ve just started to learn Spark, it&amp;#39;s said that Spark has advantage over Hadoop to process data on RAM level across multiple nodes.&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m practicing to use PySpark to work with dataframes, and looking at some documents and tutorials online I can see the following step I could do is get hands on data processing and machine learning modeling via PySpark framework.&lt;/p&gt;\n\n&lt;p&gt;But I can&amp;#39;t see the strengths of Spark so far, from what I see I can do all these works without Spark.&lt;/p&gt;\n\n&lt;p&gt;I can do data manipulation with Pandas, can train machine learning model with scikit-learn...all of these &amp;#39;guides&amp;#39;, &amp;#39;sharing&amp;#39;, &amp;#39;tutorial&amp;#39; I found introducing Spark seems to use it as another normal python library.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t see any posts or sharings to utilize Spark to display the strength of it&amp;#39;s parallel processing ability, speed up the processing time for large scale data and so on.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m confusing what I can do with Spark right now, is there any sharings or resources that have guide about how to make the most of Spark? &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for any advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "168wq12", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/168wq12/is_there_any_tutorialsharingprojectsdemonstration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/168wq12/is_there_any_tutorialsharingprojectsdemonstration/", "subreddit_subscribers": 126749, "created_utc": 1693746832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nAs part of a study into the use of integration solutions, I've noticed that some users seem to be combining different tools, in particular Qlik Replicate + Qlik compose + Informatica (powercenter/ICS) or even Qlik Replicate + Qlik compose + IBM DataStage. \n\nIs this the case for you or have you already seen this type of usage? If so, what does it involve?\n\nThanks for your help!\n\nWinterCod!\n\n&amp;#x200B;", "author_fullname": "t2_iy585b7ld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Qlik Replicate + Informatica // Qlik Replicate + IBM Datastage: What is it used for?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168xzmf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693750122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;As part of a study into the use of integration solutions, I&amp;#39;ve noticed that some users seem to be combining different tools, in particular Qlik Replicate + Qlik compose + Informatica (powercenter/ICS) or even Qlik Replicate + Qlik compose + IBM DataStage. &lt;/p&gt;\n\n&lt;p&gt;Is this the case for you or have you already seen this type of usage? If so, what does it involve?&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help!&lt;/p&gt;\n\n&lt;p&gt;WinterCod!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "168xzmf", "is_robot_indexable": true, "report_reasons": null, "author": "Winter_Cod_6272", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/168xzmf/qlik_replicate_informatica_qlik_replicate_ibm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/168xzmf/qlik_replicate_informatica_qlik_replicate_ibm/", "subreddit_subscribers": 126749, "created_utc": 1693750122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cb5j4xjcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Semi-structured data modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_169o3x4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3ZtDB20cZT6A3LX8fKQ-2X61VSMuNIvCuNPAt5K40ls.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693822145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/r/SQL/comments/169o1ts/semistructured_data_modeling_firebolt/?utm_source=share&amp;utm_medium=web2x&amp;context=3", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?auto=webp&amp;s=833f6ef5a8f5faa26b3e83468504526cd82f1695", "width": 1200, "height": 1317}, "resolutions": [{"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67b10932c6d3d18f91c769e7cafdaf5d1cc455ff", "width": 108, "height": 118}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c80b3e39c2cdd1ded87008dca3e70151be3a6176", "width": 216, "height": 237}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f95c25186230bc3ccf34656e0b4e794400cad1a", "width": 320, "height": 351}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=39b57294e1d4fae5824e7540d7cdc71a13147b4e", "width": 640, "height": 702}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bd6836cf9ca5e5afef430ec98b4745948ec26f02", "width": 960, "height": 1053}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=621012b93de740a58720a943ad89cb444adc3e66", "width": 1080, "height": 1185}], "variants": {}, "id": "jfZxUG5Arretfp5CC6Dl5Pxy_2XTUY2Fs_Jv4_um2tQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "169o3x4", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous-Surround882", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169o3x4/semistructured_data_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/SQL/comments/169o1ts/semistructured_data_modeling_firebolt/?utm_source=share&amp;utm_medium=web2x&amp;context=3", "subreddit_subscribers": 126749, "created_utc": 1693822145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why does the below Athena code filter out rows with null values in field1?\n\nwhere field1 not in (\u2018x\u2019, \u2018y\u2019)", "author_fullname": "t2_fwqwbjia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Athena Where Not In", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1698m0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693776334.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693775814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why does the below Athena code filter out rows with null values in field1?&lt;/p&gt;\n\n&lt;p&gt;where field1 not in (\u2018x\u2019, \u2018y\u2019)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1698m0z", "is_robot_indexable": true, "report_reasons": null, "author": "space-trader-92", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1698m0z/athena_where_not_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1698m0z/athena_where_not_in/", "subreddit_subscribers": 126749, "created_utc": 1693775814.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}