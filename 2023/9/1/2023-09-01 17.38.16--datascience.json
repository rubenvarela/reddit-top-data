{"kind": "Listing", "data": {"after": "t3_1677ezd", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jkyey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what do you expect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1676ej3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 314, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 314, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vUsKocueWbXxyiZJaEPLm8lBpJmIBKgBQdvb2nhq_BA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693572988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/u831r97x5nlb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/u831r97x5nlb1.jpg?auto=webp&amp;s=f1cf9b979208f34fc58fb413cf37e0bc18749c9f", "width": 680, "height": 900}, "resolutions": [{"url": "https://preview.redd.it/u831r97x5nlb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da01c68f38b34336d891f56c501d082334395440", "width": 108, "height": 142}, {"url": "https://preview.redd.it/u831r97x5nlb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c12c52afeadc5f50fab5da533d515ee8fc7a64d6", "width": 216, "height": 285}, {"url": "https://preview.redd.it/u831r97x5nlb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c501737b7054b3a3306be758e75d2f3de2941d6d", "width": 320, "height": 423}, {"url": "https://preview.redd.it/u831r97x5nlb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d97546fbd896a7ff8e7a7d09e045e9768ffd9970", "width": 640, "height": 847}], "variants": {}, "id": "CG_ndoKmXiJz5rZY-Vk_W37z_9S9SZmleSQECL2l8K0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1676ej3", "is_robot_indexable": true, "report_reasons": null, "author": "Greenland_", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1676ej3/what_do_you_expect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/u831r97x5nlb1.jpg", "subreddit_subscribers": 1025434, "created_utc": 1693572988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've started a new job in a industry company. \n\nBasically, my department does market analysis. They've been doing it for years and everything is a big Excel file. Everything is excel and kind of a mess. For more info about the context, here the [episode 1](https://old.reddit.com/r/dataengineering/comments/1271cb2/new_job_as_a_data_manager_the_data_is_a_bunch_of/) of my adventures.\n\nSo, I've had to build from scratch some kind of data *stack*. Currently it is :\n\n* A postgresql database\n* Jupyter environment\n\nTo be honest, I was skeptical about Jupyter because it shouldn't be a production jack-of-all-trades-data-tools. But so far so good.\n\nI'm fairly experienced in SQL, Python (for data analysis: pandas, numpy). \n\nHere is my question. A huge part of the job is producing charts and graphs and so on. **The most typical case is producing one chart and doing 10 variations of it**. Basically for each business line. So, it's just a matter a filtering there and there and that's it. \n\nBefore, everything was done in Excel. And kind of a pain, because you had a bunch of sheets and pivot tables and then the charts. You clicked update and everything went to shit because Excel freaks out if the context moves a tiny bit, etc. It was almost impossible to maintain consistency with colors, etc. So... not ideal. And on top of that, people had to draw by hand square and things on top of the charts because there are no ways to do it in Excel.\n\nMy solution for that is... Doing it in Python... And I don't know if it's a good idea. I'm self taught and has no idea if there are more proper way to produce charts for print/presentations. Main motivation was: \"I can get Python working fast, I really want to practice it more\"\n\nMy approach is:\n\n- If I have to produce a report, that is like 30 charts and they all have 5 variations. I build a notebook for this purpose. \n- In the notebook I try to make everything nice and tidy by using parameters and functions a lot (and comments, and text blocks with explanations for future-me). I try to pull data once (SQL) and keep it as a dataframe, manipulate it with Pandas and do the chart with Matplotlib. Each chart is a function and variations are handled by passing a parameters. And styling, etc. Is done by calling a module I've made.\n\nFor example, I want to produce the the bar chart `P3G2_B1`. It's the Graph #2 on page #3 for Business line #1. \n\nI call the function `P3G2()` with B1 as parameters and it produces the desired chart. With proper styling (Title, proper stylesheet, and a footer mentioning the chart id and the date). It's saved as a SVG (P3G2_B1.svg) and later converted to .EMF (because my company uses an old version of PPT that doesn't support SVG.\n\nSo far, what is good about this approach :\n\n- The charts look nice and are very visually consistent. Matplotlib allows me to specify a lot of things so there are few surprises.\n- It's fast enough. Doing an update and outputing 50 charts is a matter of minutes.\n\nWhat I'm not too happy about :\n\n- Matplotlib makes me miserable. I'm still learning Python and everything is painful. I find matplotlib confusing as hell. There are multiples and wildly different ways to do anything. Half of my days are just googling \"How to so &lt;insert weird request&gt; in matplotlib\". I've tried seaborn, plain pandas, and so on that are supposed to be *easier* than pure matplotlib. Well, I end up having to do something weird and having to sprinkle it with plain old matplotlib regardless. So I've decided to just go with it.\n- Matplotlib to do print is quite awful. My powerpoint slides have a grid, and let's say I want to create a bar chart that is 8 by 6 on this grid. So I expect a 800x600 pixels image. Not. so. easy. (especially since I need space for title and footer around the chart). What you see and not always what you get (through savefig, as an image file). My module handles that mostly OK but it's very hacky and still a mess. And also, the .svg to .emf conversion is another layer of pain. Some graphical things don't convert well (hatches for example).\n- Some charts functions are more than 100 hundreds lines of code. It scares me a bit. I have a hard time convincing people that it is better than Excel. They just see a house of cards waiting to fall.\n\nSo. Given the assignment, am I crazy to go with Python notebooks?\nDo you have suggestions to make my life easier producing nice, print quality charts to insert in Powerpoint?", "author_fullname": "t2_cr1c7y8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My job is producing loads of charts for Powerpoint...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166p30n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693520635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve started a new job in a industry company. &lt;/p&gt;\n\n&lt;p&gt;Basically, my department does market analysis. They&amp;#39;ve been doing it for years and everything is a big Excel file. Everything is excel and kind of a mess. For more info about the context, here the &lt;a href=\"https://old.reddit.com/r/dataengineering/comments/1271cb2/new_job_as_a_data_manager_the_data_is_a_bunch_of/\"&gt;episode 1&lt;/a&gt; of my adventures.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;ve had to build from scratch some kind of data &lt;em&gt;stack&lt;/em&gt;. Currently it is :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A postgresql database&lt;/li&gt;\n&lt;li&gt;Jupyter environment&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To be honest, I was skeptical about Jupyter because it shouldn&amp;#39;t be a production jack-of-all-trades-data-tools. But so far so good.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fairly experienced in SQL, Python (for data analysis: pandas, numpy). &lt;/p&gt;\n\n&lt;p&gt;Here is my question. A huge part of the job is producing charts and graphs and so on. &lt;strong&gt;The most typical case is producing one chart and doing 10 variations of it&lt;/strong&gt;. Basically for each business line. So, it&amp;#39;s just a matter a filtering there and there and that&amp;#39;s it. &lt;/p&gt;\n\n&lt;p&gt;Before, everything was done in Excel. And kind of a pain, because you had a bunch of sheets and pivot tables and then the charts. You clicked update and everything went to shit because Excel freaks out if the context moves a tiny bit, etc. It was almost impossible to maintain consistency with colors, etc. So... not ideal. And on top of that, people had to draw by hand square and things on top of the charts because there are no ways to do it in Excel.&lt;/p&gt;\n\n&lt;p&gt;My solution for that is... Doing it in Python... And I don&amp;#39;t know if it&amp;#39;s a good idea. I&amp;#39;m self taught and has no idea if there are more proper way to produce charts for print/presentations. Main motivation was: &amp;quot;I can get Python working fast, I really want to practice it more&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;My approach is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;If I have to produce a report, that is like 30 charts and they all have 5 variations. I build a notebook for this purpose. &lt;/li&gt;\n&lt;li&gt;In the notebook I try to make everything nice and tidy by using parameters and functions a lot (and comments, and text blocks with explanations for future-me). I try to pull data once (SQL) and keep it as a dataframe, manipulate it with Pandas and do the chart with Matplotlib. Each chart is a function and variations are handled by passing a parameters. And styling, etc. Is done by calling a module I&amp;#39;ve made.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For example, I want to produce the the bar chart &lt;code&gt;P3G2_B1&lt;/code&gt;. It&amp;#39;s the Graph #2 on page #3 for Business line #1. &lt;/p&gt;\n\n&lt;p&gt;I call the function &lt;code&gt;P3G2()&lt;/code&gt; with B1 as parameters and it produces the desired chart. With proper styling (Title, proper stylesheet, and a footer mentioning the chart id and the date). It&amp;#39;s saved as a SVG (P3G2_B1.svg) and later converted to .EMF (because my company uses an old version of PPT that doesn&amp;#39;t support SVG.&lt;/p&gt;\n\n&lt;p&gt;So far, what is good about this approach :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The charts look nice and are very visually consistent. Matplotlib allows me to specify a lot of things so there are few surprises.&lt;/li&gt;\n&lt;li&gt;It&amp;#39;s fast enough. Doing an update and outputing 50 charts is a matter of minutes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What I&amp;#39;m not too happy about :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Matplotlib makes me miserable. I&amp;#39;m still learning Python and everything is painful. I find matplotlib confusing as hell. There are multiples and wildly different ways to do anything. Half of my days are just googling &amp;quot;How to so &amp;lt;insert weird request&amp;gt; in matplotlib&amp;quot;. I&amp;#39;ve tried seaborn, plain pandas, and so on that are supposed to be &lt;em&gt;easier&lt;/em&gt; than pure matplotlib. Well, I end up having to do something weird and having to sprinkle it with plain old matplotlib regardless. So I&amp;#39;ve decided to just go with it.&lt;/li&gt;\n&lt;li&gt;Matplotlib to do print is quite awful. My powerpoint slides have a grid, and let&amp;#39;s say I want to create a bar chart that is 8 by 6 on this grid. So I expect a 800x600 pixels image. Not. so. easy. (especially since I need space for title and footer around the chart). What you see and not always what you get (through savefig, as an image file). My module handles that mostly OK but it&amp;#39;s very hacky and still a mess. And also, the .svg to .emf conversion is another layer of pain. Some graphical things don&amp;#39;t convert well (hatches for example).&lt;/li&gt;\n&lt;li&gt;Some charts functions are more than 100 hundreds lines of code. It scares me a bit. I have a hard time convincing people that it is better than Excel. They just see a house of cards waiting to fall.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So. Given the assignment, am I crazy to go with Python notebooks?\nDo you have suggestions to make my life easier producing nice, print quality charts to insert in Powerpoint?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166p30n", "is_robot_indexable": true, "report_reasons": null, "author": "raymondstanz", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166p30n/my_job_is_producing_loads_of_charts_for_powerpoint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166p30n/my_job_is_producing_loads_of_charts_for_powerpoint/", "subreddit_subscribers": 1025434, "created_utc": 1693520635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently a lead/senior data analyst with 8 years experience and I'm thinking about getting into data science. My education is in business. TC is 150k + in mid size metro.\n\nRather than becoming a fully fledged data scientist, my goal is to become more of a \"super duper data analyst\" or an analytics manager with data science knowledge to increase my comp.\n\nSkills:\n\nTechnical (almost all self taught).\n\n* Expert Data Visualization (Looker/Power BI, Excel)\n* Expert SQL and complex data wrangling/data modeling\n* Intermediate python/pandas\n* Recently brushed up on Basic Stats (Regression, standard deviations, p-values, etc) with a stats class.\n\nSoft:\n\n* Presenting insights to stakeholders\n* Leading data analytics/engineering projects with other data folks\n* Working with upper management\n\n&amp;#x200B;\n\nIs this \"path\" of learning data science worthwhile/valuable for someone like me?\n\nCurrent data science plan\n\n* Read [Data Science for Business](https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/B08VL5K5ZX/ref=sr_1_1?crid=3TU7LKIX9YREK&amp;keywords=data+science+for+business&amp;qid=1693530503&amp;sprefix=data+science+for+business%2Caps%2C101&amp;sr=8-1)\n* Read [Intro to Stat Learning](https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/3031387465/ref=sr_1_2?crid=WCKIHHMTEUO5&amp;keywords=introduction+to+statistical&amp;qid=1693530539&amp;s=audible&amp;sprefix=introduction+to+statistional+%2Caudible%2C86&amp;sr=1-2-catcorr&amp;ufe=app_do%3Aamzn1.fos.18ed3cb5-28d5-4975-8bc7-93deae8f9840)\n* Finish DataCamp Data Science Course\n* Practice a lot of kaggle data science exercises?\n\n&amp;#x200B;", "author_fullname": "t2_bmmlgaw4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Realistic Expectations DA --&gt; DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166t4lc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693530673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a lead/senior data analyst with 8 years experience and I&amp;#39;m thinking about getting into data science. My education is in business. TC is 150k + in mid size metro.&lt;/p&gt;\n\n&lt;p&gt;Rather than becoming a fully fledged data scientist, my goal is to become more of a &amp;quot;super duper data analyst&amp;quot; or an analytics manager with data science knowledge to increase my comp.&lt;/p&gt;\n\n&lt;p&gt;Skills:&lt;/p&gt;\n\n&lt;p&gt;Technical (almost all self taught).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Expert Data Visualization (Looker/Power BI, Excel)&lt;/li&gt;\n&lt;li&gt;Expert SQL and complex data wrangling/data modeling&lt;/li&gt;\n&lt;li&gt;Intermediate python/pandas&lt;/li&gt;\n&lt;li&gt;Recently brushed up on Basic Stats (Regression, standard deviations, p-values, etc) with a stats class.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Soft:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Presenting insights to stakeholders&lt;/li&gt;\n&lt;li&gt;Leading data analytics/engineering projects with other data folks&lt;/li&gt;\n&lt;li&gt;Working with upper management&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this &amp;quot;path&amp;quot; of learning data science worthwhile/valuable for someone like me?&lt;/p&gt;\n\n&lt;p&gt;Current data science plan&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Read &lt;a href=\"https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/B08VL5K5ZX/ref=sr_1_1?crid=3TU7LKIX9YREK&amp;amp;keywords=data+science+for+business&amp;amp;qid=1693530503&amp;amp;sprefix=data+science+for+business%2Caps%2C101&amp;amp;sr=8-1\"&gt;Data Science for Business&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Read &lt;a href=\"https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/3031387465/ref=sr_1_2?crid=WCKIHHMTEUO5&amp;amp;keywords=introduction+to+statistical&amp;amp;qid=1693530539&amp;amp;s=audible&amp;amp;sprefix=introduction+to+statistional+%2Caudible%2C86&amp;amp;sr=1-2-catcorr&amp;amp;ufe=app_do%3Aamzn1.fos.18ed3cb5-28d5-4975-8bc7-93deae8f9840\"&gt;Intro to Stat Learning&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Finish DataCamp Data Science Course&lt;/li&gt;\n&lt;li&gt;Practice a lot of kaggle data science exercises?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166t4lc", "is_robot_indexable": true, "report_reasons": null, "author": "Miserable_Lion_6896", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166t4lc/realistic_expectations_da_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166t4lc/realistic_expectations_da_ds/", "subreddit_subscribers": 1025434, "created_utc": 1693530673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I want to buy a laptop for ml,web development and data science for college. Should I go for xiomi notebook pro i5 11300h 16 gb ram, acer aspire 3 i5 1235u, msi modern 14 c11m, msi modern 14 c12m 16gb, asus 16x, asus vivobook 15 i3 1220p, 1215u , asus vivobook 15 i5 11th gen? As most of them are around 46k-50k, I'm very confused, like down 4 years I can't use any of these laptop for professional use as they might not be enough. So should I go for any laptop under 40k rupees with ryzen 5 5500u, i3 12th gen so that I may be able to just survive college and then buy laptop after 4 years? Also, I had a doubt if i3 12th gen processor or i3 13th gen processor like i3 1315u would be better than i5 11 th gen ones, as acer laptop with i3 1315u is available under 40k? ", "author_fullname": "t2_5atabn136", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Doubt regarding laptop requirements for data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16713vl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693556027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to buy a laptop for ml,web development and data science for college. Should I go for xiomi notebook pro i5 11300h 16 gb ram, acer aspire 3 i5 1235u, msi modern 14 c11m, msi modern 14 c12m 16gb, asus 16x, asus vivobook 15 i3 1220p, 1215u , asus vivobook 15 i5 11th gen? As most of them are around 46k-50k, I&amp;#39;m very confused, like down 4 years I can&amp;#39;t use any of these laptop for professional use as they might not be enough. So should I go for any laptop under 40k rupees with ryzen 5 5500u, i3 12th gen so that I may be able to just survive college and then buy laptop after 4 years? Also, I had a doubt if i3 12th gen processor or i3 13th gen processor like i3 1315u would be better than i5 11 th gen ones, as acer laptop with i3 1315u is available under 40k? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16713vl", "is_robot_indexable": true, "report_reasons": null, "author": "OpenCombination714", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16713vl/doubt_regarding_laptop_requirements_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16713vl/doubt_regarding_laptop_requirements_for_data/", "subreddit_subscribers": 1025434, "created_utc": 1693556027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently doing my master thesis on a topic regarding interpret ability of data science models and their applications. Interpretability currently holds no strict definition in the field (Doshi &amp; Kim, 2017) and it may be synonymous with explainability (to a human/end-user).\n\n I am curious as to how would you guys define or how do you think of interpretability as. Is there a way you use to measure it ? \n\nPersonally I really like the parallel used by Efron, where it can be thought of as a communication; an exchange of information that depends on the parties involved. For example a doctor may find the name of a predicted disease by a model a sufficient amount of information, but a patient may require a lengthier explanation. \n\nThank you !", "author_fullname": "t2_21mlx7b9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you define interpretability of a model ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166gubu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693501776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently doing my master thesis on a topic regarding interpret ability of data science models and their applications. Interpretability currently holds no strict definition in the field (Doshi &amp;amp; Kim, 2017) and it may be synonymous with explainability (to a human/end-user).&lt;/p&gt;\n\n&lt;p&gt;I am curious as to how would you guys define or how do you think of interpretability as. Is there a way you use to measure it ? &lt;/p&gt;\n\n&lt;p&gt;Personally I really like the parallel used by Efron, where it can be thought of as a communication; an exchange of information that depends on the parties involved. For example a doctor may find the name of a predicted disease by a model a sufficient amount of information, but a patient may require a lengthier explanation. &lt;/p&gt;\n\n&lt;p&gt;Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166gubu", "is_robot_indexable": true, "report_reasons": null, "author": "johntsaou", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166gubu/how_would_you_define_interpretability_of_a_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166gubu/how_would_you_define_interpretability_of_a_model/", "subreddit_subscribers": 1025434, "created_utc": 1693501776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Title says it.\n\nTo add some background. I've decided that after some time in academia that I want to earn real money (and have less awful work hours). Most aligned with my interests (and abilities) is data science.\n\nOr so I've thought. But reading around (like e.g. here) I think may have a very wrong idea of what makes a data scientist a data scientist.\n\nI am very aware that nobody in the real world really *needs* to understand why you need lebesgue integrals in statistics to do some exploratory data analysis.\n\nBut with so much here I don't get it at all *or* don't get the connection to data science. I mean surely I've read somewhere something about kubernetes but a) I've never used it and b) I don't see how that is not just normal programmer stuff.  \nSame with using pandas, python, R, tensorflow etc.  \nI would expect from any halfway decent programmer to be able to use all of this. But what (in my mind) differentiates the data scientist is what happens behind the scenes and therefore the ability to properly judge it.   \n\n\nTo give an example. I've had a lengthy discussion with a colleague about the applicability of his model. He gave me a score of 9X.XX% accuracy for his model. And I just did not see why I would even remotely care about this number (overstated).\n\nMy specific application required (in my mind) a statistical meaningful number on each prediction. And (that may be due to my background in physics) was less than convinced by those magical numbers the neurons put out. I guess it's a nice indicator and helps searching for optimization potential but thats it (there are research papers that back that up).  \nSo I've requested a confidence interval or at least something similar. I did not get that and ended up implementing that with bootstrapping on my own.   \nThe gist of it was that this really highlighted for me the difference between a programmer and a data scientist (he was an electrical engineer so that mostly fits).\n\nHe can do a lot of good stuff with pytorch, pandas etc. and that has a lot of merit. But he missed the background in statistics to explain to me convincingly (to put it a bit meanly) that he did not just doodle around but that his model actually had some connection to the underlying causalities in the dataset.\n\nBut reading descriptions around here, job offerings etc. his skillset seems to fit a lot better than mine. I can do python and c++ very well. Outside of that, there are few languages where I would say confidently I can do a lot more than implementing a perceptron.\n\nI've never used VMs in a serious manner either. I just build stuff on my own. That way I directly have the source code to look up stuff. But this really doesn't seem how one works in the field.\n\nSo to exaggerate wildly. I am afraid to land in a team where tech buzzword bingo and endless meetings dominate the day, new software is tried out biweekly and if I mention that NNs are not only overkill but worse for this scenario I get looked at weirdly.\n\nAgain I know exaggeration. But I did read a post here about a doctorate fellow that seemed to antagonize quite a bit with his comments and I would prefer not to be that fellow.\n\nTL;DR\n\nWhat makes a data scientist for you?  \nWhat is it like in your team?  \nHow much do you deal with actual statistics in your day-to-day work?  \nCan you really do all this stuff properly that is listed on LinkedIn? And if yes, does it help?  \nHow much do you do \"on your own\" i.e. not just using some numpy or pandas methods but implementing something problem specific?  \n", "author_fullname": "t2_hsfjblk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What distinguishes data scientist from a programmer, computer scientist...?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167a2u9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693581708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title says it.&lt;/p&gt;\n\n&lt;p&gt;To add some background. I&amp;#39;ve decided that after some time in academia that I want to earn real money (and have less awful work hours). Most aligned with my interests (and abilities) is data science.&lt;/p&gt;\n\n&lt;p&gt;Or so I&amp;#39;ve thought. But reading around (like e.g. here) I think may have a very wrong idea of what makes a data scientist a data scientist.&lt;/p&gt;\n\n&lt;p&gt;I am very aware that nobody in the real world really &lt;em&gt;needs&lt;/em&gt; to understand why you need lebesgue integrals in statistics to do some exploratory data analysis.&lt;/p&gt;\n\n&lt;p&gt;But with so much here I don&amp;#39;t get it at all &lt;em&gt;or&lt;/em&gt; don&amp;#39;t get the connection to data science. I mean surely I&amp;#39;ve read somewhere something about kubernetes but a) I&amp;#39;ve never used it and b) I don&amp;#39;t see how that is not just normal programmer stuff.&lt;br/&gt;\nSame with using pandas, python, R, tensorflow etc.&lt;br/&gt;\nI would expect from any halfway decent programmer to be able to use all of this. But what (in my mind) differentiates the data scientist is what happens behind the scenes and therefore the ability to properly judge it.   &lt;/p&gt;\n\n&lt;p&gt;To give an example. I&amp;#39;ve had a lengthy discussion with a colleague about the applicability of his model. He gave me a score of 9X.XX% accuracy for his model. And I just did not see why I would even remotely care about this number (overstated).&lt;/p&gt;\n\n&lt;p&gt;My specific application required (in my mind) a statistical meaningful number on each prediction. And (that may be due to my background in physics) was less than convinced by those magical numbers the neurons put out. I guess it&amp;#39;s a nice indicator and helps searching for optimization potential but thats it (there are research papers that back that up).&lt;br/&gt;\nSo I&amp;#39;ve requested a confidence interval or at least something similar. I did not get that and ended up implementing that with bootstrapping on my own.&lt;br/&gt;\nThe gist of it was that this really highlighted for me the difference between a programmer and a data scientist (he was an electrical engineer so that mostly fits).&lt;/p&gt;\n\n&lt;p&gt;He can do a lot of good stuff with pytorch, pandas etc. and that has a lot of merit. But he missed the background in statistics to explain to me convincingly (to put it a bit meanly) that he did not just doodle around but that his model actually had some connection to the underlying causalities in the dataset.&lt;/p&gt;\n\n&lt;p&gt;But reading descriptions around here, job offerings etc. his skillset seems to fit a lot better than mine. I can do python and c++ very well. Outside of that, there are few languages where I would say confidently I can do a lot more than implementing a perceptron.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve never used VMs in a serious manner either. I just build stuff on my own. That way I directly have the source code to look up stuff. But this really doesn&amp;#39;t seem how one works in the field.&lt;/p&gt;\n\n&lt;p&gt;So to exaggerate wildly. I am afraid to land in a team where tech buzzword bingo and endless meetings dominate the day, new software is tried out biweekly and if I mention that NNs are not only overkill but worse for this scenario I get looked at weirdly.&lt;/p&gt;\n\n&lt;p&gt;Again I know exaggeration. But I did read a post here about a doctorate fellow that seemed to antagonize quite a bit with his comments and I would prefer not to be that fellow.&lt;/p&gt;\n\n&lt;p&gt;TL;DR&lt;/p&gt;\n\n&lt;p&gt;What makes a data scientist for you?&lt;br/&gt;\nWhat is it like in your team?&lt;br/&gt;\nHow much do you deal with actual statistics in your day-to-day work?&lt;br/&gt;\nCan you really do all this stuff properly that is listed on LinkedIn? And if yes, does it help?&lt;br/&gt;\nHow much do you do &amp;quot;on your own&amp;quot; i.e. not just using some numpy or pandas methods but implementing something problem specific?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "167a2u9", "is_robot_indexable": true, "report_reasons": null, "author": "randrayner", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/167a2u9/what_distinguishes_data_scientist_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/167a2u9/what_distinguishes_data_scientist_from_a/", "subreddit_subscribers": 1025434, "created_utc": 1693581708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone! I recently started looking for a new job. I applied to several companies and was scheduled for interviews at Google and Nvidia. A senior at Nvidia and something unclear at Google, kind of like a mid-level+/senior. I'm currently working as an ML tech lead at large company (90kk+ MAU), have ~7y experience, have very relevant experience for both positions, speak at conferences, write scientific articles, and have good hard skills. I write a lot of code at work and do many reviews.\n\nAt Google, I had 3 technical interviews, and at Nvidia, I had 3 technical interviews plus a test assignment. After each round, I sat down and rechecked my answers. Everything was always correct, both regarding algorithm tasks and technical questions. The only flaws were very minor, mistakenly using += instead of =, writing !(cond) instead of cond, but I corrected myself or with minimal prompting.\n\nI got rejected from Google with the feedback \"bad understanding of algorithms and data structures, also not clear way of solving\", and from Nvidia simply \"decided not to move forward\". This sounds absurd to me since such minor mistakes, which I corrected myself, cannot be such a strong rejection reason. I'm starting to feel paranoid, thinking that the reason for the rejections is that I am in Russia and its hard to relocate for me. These thoughts aren't unfounded because one of the rounds  was canceled and HR literally wrote \"ow, just found you're a Russian, lets cancel the section\". Some companies from Japan directly told me that the refusal was due to being \"Russian\". But I feel like I might be looking for false reasons. I'm bewildered and confused. What can you advise or where I made a mistakes and didnt realise it? How to successfully pass these sections?", "author_fullname": "t2_8fm3pxva", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rejected after techical sections", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1672xkd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693562561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I recently started looking for a new job. I applied to several companies and was scheduled for interviews at Google and Nvidia. A senior at Nvidia and something unclear at Google, kind of like a mid-level+/senior. I&amp;#39;m currently working as an ML tech lead at large company (90kk+ MAU), have ~7y experience, have very relevant experience for both positions, speak at conferences, write scientific articles, and have good hard skills. I write a lot of code at work and do many reviews.&lt;/p&gt;\n\n&lt;p&gt;At Google, I had 3 technical interviews, and at Nvidia, I had 3 technical interviews plus a test assignment. After each round, I sat down and rechecked my answers. Everything was always correct, both regarding algorithm tasks and technical questions. The only flaws were very minor, mistakenly using += instead of =, writing !(cond) instead of cond, but I corrected myself or with minimal prompting.&lt;/p&gt;\n\n&lt;p&gt;I got rejected from Google with the feedback &amp;quot;bad understanding of algorithms and data structures, also not clear way of solving&amp;quot;, and from Nvidia simply &amp;quot;decided not to move forward&amp;quot;. This sounds absurd to me since such minor mistakes, which I corrected myself, cannot be such a strong rejection reason. I&amp;#39;m starting to feel paranoid, thinking that the reason for the rejections is that I am in Russia and its hard to relocate for me. These thoughts aren&amp;#39;t unfounded because one of the rounds  was canceled and HR literally wrote &amp;quot;ow, just found you&amp;#39;re a Russian, lets cancel the section&amp;quot;. Some companies from Japan directly told me that the refusal was due to being &amp;quot;Russian&amp;quot;. But I feel like I might be looking for false reasons. I&amp;#39;m bewildered and confused. What can you advise or where I made a mistakes and didnt realise it? How to successfully pass these sections?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1672xkd", "is_robot_indexable": true, "report_reasons": null, "author": "ShabelonMagician", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1672xkd/rejected_after_techical_sections/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1672xkd/rejected_after_techical_sections/", "subreddit_subscribers": 1025434, "created_utc": 1693562561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking to change jobs, working on my resume. Everyone says quantify your accomplishments but how do you quantify research work? The goal of research is to understand the underlying relationship, look for associations, etc., but companies are looking for how much money did you earn/save, how many people you managed, etc. I have one model that I can quantify but everything else not so much. Are there any data scientists that have had this same or similar problem?", "author_fullname": "t2_6jhdopac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do you quantify research work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166z240", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693548685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to change jobs, working on my resume. Everyone says quantify your accomplishments but how do you quantify research work? The goal of research is to understand the underlying relationship, look for associations, etc., but companies are looking for how much money did you earn/save, how many people you managed, etc. I have one model that I can quantify but everything else not so much. Are there any data scientists that have had this same or similar problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166z240", "is_robot_indexable": true, "report_reasons": null, "author": "axescot", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166z240/how_do_you_quantify_research_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166z240/how_do_you_quantify_research_work/", "subreddit_subscribers": 1025434, "created_utc": 1693548685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The NYU Tandon School of Engineering's researchers have developed a technique that alters apparent age in images\u2014all the while preserving the subject's unique identity as shared in [the paper](https://arxiv.org/abs/2307.08585).\n\nIf you want to stay on top of the latest trends and insights in AI and tech, [look here first.](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=nyu-research&amp;utm_campaign=campaign)\n\n**Why this counts:**\n\n* **Issues with current models are being countered:** Existing AI models grapple with changing age attributes without tarnishing the individual's identity. The robust model developed by NYU researchers confronts this problem head-on.\n* **Harnessing the power of small data sets:** Unlike alternative models that need extensive amounts of pictures over many years, the NYU team harnessed a small set of captioned images and individual images to train the model.\n* **Multifaceted applications:** The new AI technique may be employed for \"aging\" or \"de-aging\" scenarios by merely designating a target age through a text prompt.\n\nHere are some important details\\*\\*:\\*\\*\n\n* **DreamBooth technique shines:** Using a composite of neural network components, researchers manipulated facial images within this fusion referred to as a DreamBooth technique.\n* **Superior performance compared to alternative methods:** When set against other age-modification techniques, this AI model outdid others, reducing incorrect rejections by up to 44%.\n* **Excellent representation across age groups:** The model demonstrates a greater capability to generate images across diverse age groups, more notably in transforming images into older age groups.\n\n**P.S. If you like this kind of analysis,**\u00a0I write\u00a0[a free newsletter](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=nyu-research&amp;utm_campaign=campaign)\u00a0that tracks the most relevant news and research in AI and tech\u2014stay updated in under 2 mins/day.\n\n[(arXiv)](https://arxiv.org/abs/2307.08585)", "author_fullname": "t2_h4jb4maul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New AI Technique by NYU Researchers Modifies Age in Images while Retaining Identity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166wpyf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693541057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The NYU Tandon School of Engineering&amp;#39;s researchers have developed a technique that alters apparent age in images\u2014all the while preserving the subject&amp;#39;s unique identity as shared in &lt;a href=\"https://arxiv.org/abs/2307.08585\"&gt;the paper&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;If you want to stay on top of the latest trends and insights in AI and tech, &lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=nyu-research&amp;amp;utm_campaign=campaign\"&gt;look here first.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why this counts:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Issues with current models are being countered:&lt;/strong&gt; Existing AI models grapple with changing age attributes without tarnishing the individual&amp;#39;s identity. The robust model developed by NYU researchers confronts this problem head-on.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Harnessing the power of small data sets:&lt;/strong&gt; Unlike alternative models that need extensive amounts of pictures over many years, the NYU team harnessed a small set of captioned images and individual images to train the model.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Multifaceted applications:&lt;/strong&gt; The new AI technique may be employed for &amp;quot;aging&amp;quot; or &amp;quot;de-aging&amp;quot; scenarios by merely designating a target age through a text prompt.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here are some important details**:**&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;DreamBooth technique shines:&lt;/strong&gt; Using a composite of neural network components, researchers manipulated facial images within this fusion referred to as a DreamBooth technique.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Superior performance compared to alternative methods:&lt;/strong&gt; When set against other age-modification techniques, this AI model outdid others, reducing incorrect rejections by up to 44%.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Excellent representation across age groups:&lt;/strong&gt; The model demonstrates a greater capability to generate images across diverse age groups, more notably in transforming images into older age groups.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;P.S. If you like this kind of analysis,&lt;/strong&gt;\u00a0I write\u00a0&lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=nyu-research&amp;amp;utm_campaign=campaign\"&gt;a free newsletter&lt;/a&gt;\u00a0that tracks the most relevant news and research in AI and tech\u2014stay updated in under 2 mins/day.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2307.08585\"&gt;(arXiv)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?auto=webp&amp;s=f1cd025aeb52ffa82fc9e5a4a2f157da0d919147", "width": 1200, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2711d572cfc6c713893cf24e8c4a7344d5ad8a4c", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6624f0c1eedc14997e7f1780efbe6e5cb50c1e2", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9db38144ef3065833b9ba158c764f7be47de3016", "width": 320, "height": 186}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075", "width": 640, "height": 373}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2637f961ee21190172b9ca6c8adf3ac9612db083", "width": 960, "height": 560}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=782eead871df2939a587ee3beae442cc59282f64", "width": 1080, "height": 630}], "variants": {}, "id": "q3evP6JeDpAC2MdSQHWYxnCYTqbJkElIQsLFqVSdkss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166wpyf", "is_robot_indexable": true, "report_reasons": null, "author": "AIsupercharged", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166wpyf/new_ai_technique_by_nyu_researchers_modifies_age/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166wpyf/new_ai_technique_by_nyu_researchers_modifies_age/", "subreddit_subscribers": 1025434, "created_utc": 1693541057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_14izoucv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever deployed LLama on AWS Kubernetes? I'm stuck and getting many errors such as \"waiting for Auto Scaling Group\" anyone solved it before?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 21, "top_awarded_type": null, "hide_score": false, "name": "t3_166i0q0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/E0bOwqgp4ZqLwGCDW7yT7sZ1patojOxqY0lE1_9u6m4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693504526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/i1db7089ihlb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?auto=webp&amp;s=06859b5e9cc0d76ebdcd7c577e307f4b3e7160a1", "width": 1600, "height": 242}, "resolutions": [{"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=35f58a41721ace877fdd90c91dd23120125e8729", "width": 108, "height": 16}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2418dfc949e94a52a33fae911463365396c7a234", "width": 216, "height": 32}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4007ad0c712d5643c886ae7871338a2b536d0b8c", "width": 320, "height": 48}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff16e8eb8a8d281d35d26740e4e0a654b2021d0b", "width": 640, "height": 96}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aec65af0973b5f3f14bd9bf3d74c138e25a475bc", "width": 960, "height": 145}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7c72478925a6d0745b66cf5c936c4c73ebd67ea5", "width": 1080, "height": 163}], "variants": {}, "id": "pIR74sF8xKS0ayVDm8otnRW2VYpeQto8G2JnwyIk_jM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "166i0q0", "is_robot_indexable": true, "report_reasons": null, "author": "AILaunchpad", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166i0q0/have_you_ever_deployed_llama_on_aws_kubernetes_im/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/i1db7089ihlb1.jpg", "subreddit_subscribers": 1025434, "created_utc": 1693504526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to train a model to predict flavour pairings.  \nI have a dataset of recipes including lists of ingredients.  \nEach ingredient has a 100 dimension vector that represents it's flavour. For instance, position 0 is degree of fructose flavour, etc...  \nMost ingredient flavour vectors are valued at around 0 - 0.2 for most flavour dimensions with a few flavours that reach around 5.0 - 6.0.  \nI've created training data by pairing ingredients that appear together. So I have a many to many mapping between ingredient pairs.  \nI've tried to train a simple feedforward neural network to map input vectors but the outputs always come out as general averages with no real peaks across flavour dimensions. So they don't really look representative of any real life ingredient.  \nDoes anyone have any advice on which models might be appropriate to use here or any advice about data processing or custom loss functions that might help.  \nThanks", "author_fullname": "t2_dcu0a8ch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help training a flavour pairing model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_167brkd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693585540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to train a model to predict flavour pairings.&lt;br/&gt;\nI have a dataset of recipes including lists of ingredients.&lt;br/&gt;\nEach ingredient has a 100 dimension vector that represents it&amp;#39;s flavour. For instance, position 0 is degree of fructose flavour, etc...&lt;br/&gt;\nMost ingredient flavour vectors are valued at around 0 - 0.2 for most flavour dimensions with a few flavours that reach around 5.0 - 6.0.&lt;br/&gt;\nI&amp;#39;ve created training data by pairing ingredients that appear together. So I have a many to many mapping between ingredient pairs.&lt;br/&gt;\nI&amp;#39;ve tried to train a simple feedforward neural network to map input vectors but the outputs always come out as general averages with no real peaks across flavour dimensions. So they don&amp;#39;t really look representative of any real life ingredient.&lt;br/&gt;\nDoes anyone have any advice on which models might be appropriate to use here or any advice about data processing or custom loss functions that might help.&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "167brkd", "is_robot_indexable": true, "report_reasons": null, "author": "bigslimjim91", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/167brkd/help_training_a_flavour_pairing_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/167brkd/help_training_a_flavour_pairing_model/", "subreddit_subscribers": 1025434, "created_utc": 1693585540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a BA in English, but currently work in beverage sales as a rep. I deal a lot with our sales reporting software and my plan is to learn some more about data analytics and start to apply it at my current position before trying to find a bonafide data analyst job. Having a humanities background, my skills are shit and I honestly am not even well versed in Excel, but I\u2019m very confident I can learn. It just wasn\u2019t part of my degree. Because I know so little, I thought it\u2019d be worth to pay for a certification from an actual university. I\u2019m looking at one that\u2019s $2k for a 10 week course. I know there are free resources, but being that I\u2019m starting from almost scratch I worry about my ability to navigate all the info I need to take in. Is it a complete ripoff or is there some value in the structure of a university program?", "author_fullname": "t2_g6l86nhd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth it to pay for a certification from a university?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167a13v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693581600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a BA in English, but currently work in beverage sales as a rep. I deal a lot with our sales reporting software and my plan is to learn some more about data analytics and start to apply it at my current position before trying to find a bonafide data analyst job. Having a humanities background, my skills are shit and I honestly am not even well versed in Excel, but I\u2019m very confident I can learn. It just wasn\u2019t part of my degree. Because I know so little, I thought it\u2019d be worth to pay for a certification from an actual university. I\u2019m looking at one that\u2019s $2k for a 10 week course. I know there are free resources, but being that I\u2019m starting from almost scratch I worry about my ability to navigate all the info I need to take in. Is it a complete ripoff or is there some value in the structure of a university program?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "167a13v", "is_robot_indexable": true, "report_reasons": null, "author": "Aggravating_Okra_191", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/167a13v/is_it_worth_it_to_pay_for_a_certification_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/167a13v/is_it_worth_it_to_pay_for_a_certification_from_a/", "subreddit_subscribers": 1025434, "created_utc": 1693581600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, so I am a little confused on how many target variable classes does the BERT and RoBERTa models have?\n\nSo I understand these 2 models are pre-trained models, which means the number of target variable classes are fixed (if I am not wrong!). For example, the link below for the RoBERTa model in Hugging Face has fixed 3 target variable classes (Negative, Neutral and Positive):\n\n[https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)\n\nBut when I googled around and also asked ChatGPT and Bard, they tell me these models can have as many target variable classes as the user wants (or rather this depends on how many target variable classes there are in the training dataset).\n\nIf these are pre-trained models already (which already have the number of target variable classes pre-determined in the model already), then how come some of the google sites and ChatGPT and Bard is telling me the user can choose however many target variable classes that they want?", "author_fullname": "t2_hjlrj5fp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many target variable classes does sentiment analysis models BERT and RoBERTa have?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1673f7o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693564239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, so I am a little confused on how many target variable classes does the BERT and RoBERTa models have?&lt;/p&gt;\n\n&lt;p&gt;So I understand these 2 models are pre-trained models, which means the number of target variable classes are fixed (if I am not wrong!). For example, the link below for the RoBERTa model in Hugging Face has fixed 3 target variable classes (Negative, Neutral and Positive):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\"&gt;https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But when I googled around and also asked ChatGPT and Bard, they tell me these models can have as many target variable classes as the user wants (or rather this depends on how many target variable classes there are in the training dataset).&lt;/p&gt;\n\n&lt;p&gt;If these are pre-trained models already (which already have the number of target variable classes pre-determined in the model already), then how come some of the google sites and ChatGPT and Bard is telling me the user can choose however many target variable classes that they want?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aVr2n5Vz_oeegUudYOQoQJ__IPqUNhLQsbMzAiZJIus.jpg?auto=webp&amp;s=770b36fdee75fd572c594241b472c67716dbd083", "width": 1200, "height": 648}, "resolutions": [{"url": "https://external-preview.redd.it/aVr2n5Vz_oeegUudYOQoQJ__IPqUNhLQsbMzAiZJIus.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=913ee6909b6c5750b64757ac4b9d51adbcea96f0", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/aVr2n5Vz_oeegUudYOQoQJ__IPqUNhLQsbMzAiZJIus.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a24502becd896111f3fe287073103acdfe84d8da", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/aVr2n5Vz_oeegUudYOQoQJ__IPqUNhLQsbMzAiZJIus.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=41a8379872293f94568a03fa08ae1d881e23cbff", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/aVr2n5Vz_oeegUudYOQoQJ__IPqUNhLQsbMzAiZJIus.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=31296fe78ebf3510708d8cd976be2cdb43a8b77b", "width": 640, "height": 345}, {"url": "https://external-preview.redd.it/aVr2n5Vz_oeegUudYOQoQJ__IPqUNhLQsbMzAiZJIus.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c4a4a571b6f3b76eb4e0cfab17331304e24338e", "width": 960, "height": 518}, {"url": "https://external-preview.redd.it/aVr2n5Vz_oeegUudYOQoQJ__IPqUNhLQsbMzAiZJIus.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=112297d55d87b0e99a410ef513a129693fc62f85", "width": 1080, "height": 583}], "variants": {}, "id": "bAlj_Smn_EwJ0fGKOy91cejbrQ9TMF5zcvTlNP9ErH0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1673f7o", "is_robot_indexable": true, "report_reasons": null, "author": "--leockl--", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1673f7o/how_many_target_variable_classes_does_sentiment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1673f7o/how_many_target_variable_classes_does_sentiment/", "subreddit_subscribers": 1025434, "created_utc": 1693564239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i was exploring jobs on linkedin i noticed there are more applicants for data science jobs than web related like backend full stack doest that mean data science is saturated in real life we hear reverse of it so why is this ?", "author_fullname": "t2_l4783ng3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "more applicants for data science jobs than full stack or backend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1670zdb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693555573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i was exploring jobs on linkedin i noticed there are more applicants for data science jobs than web related like backend full stack doest that mean data science is saturated in real life we hear reverse of it so why is this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1670zdb", "is_robot_indexable": true, "report_reasons": null, "author": "Parking-Sun-8979", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1670zdb/more_applicants_for_data_science_jobs_than_full/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1670zdb/more_applicants_for_data_science_jobs_than_full/", "subreddit_subscribers": 1025434, "created_utc": 1693555573.0, "num_crossposts": 3, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nA little background about myself - I have completed my Bachelor's in Engineering in Information Technology and have fairly good programming skills. I have also completed some courses in Machine Learning and am currently doing a Data Science one.\n\nI want to enroll for my Masters in Data Science (probably in a University in the US) since I am enjoying the course and I know the career has broad prospects in the future. However, what I am finding challenging and is making me a little nervous is the kind of subjects that I'll have to study. While I consider myself to be fairly good at Math and Analysis, I am unsure about what to expect from the Masters course.\n\nAny help/suggestions or simply your experience in those regards would be highly beneficial.\n\nThanks in advance :)", "author_fullname": "t2_vlptpp2l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to expect in a Data science masters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166z4y2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693548977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A little background about myself - I have completed my Bachelor&amp;#39;s in Engineering in Information Technology and have fairly good programming skills. I have also completed some courses in Machine Learning and am currently doing a Data Science one.&lt;/p&gt;\n\n&lt;p&gt;I want to enroll for my Masters in Data Science (probably in a University in the US) since I am enjoying the course and I know the career has broad prospects in the future. However, what I am finding challenging and is making me a little nervous is the kind of subjects that I&amp;#39;ll have to study. While I consider myself to be fairly good at Math and Analysis, I am unsure about what to expect from the Masters course.&lt;/p&gt;\n\n&lt;p&gt;Any help/suggestions or simply your experience in those regards would be highly beneficial.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166z4y2", "is_robot_indexable": true, "report_reasons": null, "author": "improversationalist", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166z4y2/what_to_expect_in_a_data_science_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166z4y2/what_to_expect_in_a_data_science_masters/", "subreddit_subscribers": 1025434, "created_utc": 1693548977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to identify the minimum set of behaviors (features) that can help distinguish different types of data scientists in a mutually exclusive way (this is an intellectual exercise, not an actual model). \nHere\u2019s my proposal of the minimum list of questions necessary to do this:\n\n1. Do you build models or analyses to help people make decisions or to help systems make decisions? (Neither, People, Systems, Both)\n2. Do you work with experiments, A/B tests or RCTs? (No, Yes - Analyze, Yes - Design and analyze, Yes - Design, Analyse and decide)\n3. When you create a process to transform data, is it one time or is it a scalable process that will run daily? (Only one time, mostly one time, evenly split, mostly scalable)\n4. How important is the efficiency of your data processing for your role? (As long as it runs I\u2019m good, I need efficiency because I need things fast, Efficiency is essential as I\u2019m part of a cost center).\n\nWhat am I missing?", "author_fullname": "t2_18sinzf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would a decision tree to classify data scientists look like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166y57s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693545555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to identify the minimum set of behaviors (features) that can help distinguish different types of data scientists in a mutually exclusive way (this is an intellectual exercise, not an actual model). \nHere\u2019s my proposal of the minimum list of questions necessary to do this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do you build models or analyses to help people make decisions or to help systems make decisions? (Neither, People, Systems, Both)&lt;/li&gt;\n&lt;li&gt;Do you work with experiments, A/B tests or RCTs? (No, Yes - Analyze, Yes - Design and analyze, Yes - Design, Analyse and decide)&lt;/li&gt;\n&lt;li&gt;When you create a process to transform data, is it one time or is it a scalable process that will run daily? (Only one time, mostly one time, evenly split, mostly scalable)&lt;/li&gt;\n&lt;li&gt;How important is the efficiency of your data processing for your role? (As long as it runs I\u2019m good, I need efficiency because I need things fast, Efficiency is essential as I\u2019m part of a cost center).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166y57s", "is_robot_indexable": true, "report_reasons": null, "author": "poitrenaud", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166y57s/how_would_a_decision_tree_to_classify_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166y57s/how_would_a_decision_tree_to_classify_data/", "subreddit_subscribers": 1025434, "created_utc": 1693545555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In a bid to rival the United States\u2019 stronghold in the AI industry, Chinese search engine and AI firm Baidu, has made its ChatGPT-equivalent language model, Ernie Bot, fully available to the public. This marks a significant move on the AI chessboard.\n\nIf you want to stay on top of everything AI,\u00a0[look here first.](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=baidu-ai&amp;utm_campaign=campaign)\n\nhttps://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=e7779eea500a502465bef116fa53a2bbc23c4019\n\n**Why does this matter?**\n\n* **Baidu's public release of Ernie Bot signals the company's aggressive push in the generative AI market.** By opening up its model to the public, Baidu can leverage expansive real-world human feedback to improve Ernie Bot.\n* **China's determination to lead the AI industry is unabated,** with many tech firms launching their own generative models in response to OpenAI's popular ChatGPT. Baidu's move further fuels this rivalry.\n* **Regulation in China seems to support such AI advancements.** CEO Robin Li voiced his optimism about the AI regulations\u2014calling them \"more pro-innovation than regulation\".\n\n**What's the broader response?**\n\n* **Baidu's latest stride has boosted its stock price by over 3%,** underlining the market's high anticipation of Baidu's AI efforts.\n* **Ernie Bot has rocketed to the top of Apple's iOS free app chart in China.** This demonstrates a positive initial response from the public.\n\n**Regulation is key in China's AI game:**\n\n* **China has stringent regulations for the generative AI industry,** requiring a security review and government approvals before any product launch. Moreover, companies need to comply with governmental tech and data requests.\n* **The US, on the other hand, doesn't currently have such regulations in place.** A markedly different approach that could significantly influence the development and application of AI technologies.\n\nIf you like this kind of analysis,\u00a0you might want to [check this out](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=baidu-ai&amp;utm_campaign=campaign).\n\n[(source)](https://apnews.com/article/baidu-ai-chatbot-ernie-chatgpt-627bd09608816847907d41f44da235d9)", "author_fullname": "t2_h4jb4maul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Baidu publicly releases their AI chatbot Ernie Bot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3e08q8utihlb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d1b1b1f72729af1e0be763a013d42e2c15fa9ef2"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f75f9ef2b22fd8d70dd3387ad581296f74a20d76"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd723570150ec115c9a63c2ccf5956e32c1ebef0"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4da750348d5b7963360368f537ce39b7e8bf135"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=358d17d55d50b4d79881057e6867a96eec11bf4f"}], "s": {"y": 682, "x": 1024, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=e7779eea500a502465bef116fa53a2bbc23c4019"}, "id": "3e08q8utihlb1"}}, "name": "t3_166i2tp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/rPQz06Dwfph2KnPWxOJOGKgRmPdZbNB9p1w88oxG6fA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693504666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In a bid to rival the United States\u2019 stronghold in the AI industry, Chinese search engine and AI firm Baidu, has made its ChatGPT-equivalent language model, Ernie Bot, fully available to the public. This marks a significant move on the AI chessboard.&lt;/p&gt;\n\n&lt;p&gt;If you want to stay on top of everything AI,\u00a0&lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=baidu-ai&amp;amp;utm_campaign=campaign\"&gt;look here first.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e7779eea500a502465bef116fa53a2bbc23c4019\"&gt;https://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e7779eea500a502465bef116fa53a2bbc23c4019&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why does this matter?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Baidu&amp;#39;s public release of Ernie Bot signals the company&amp;#39;s aggressive push in the generative AI market.&lt;/strong&gt; By opening up its model to the public, Baidu can leverage expansive real-world human feedback to improve Ernie Bot.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;China&amp;#39;s determination to lead the AI industry is unabated,&lt;/strong&gt; with many tech firms launching their own generative models in response to OpenAI&amp;#39;s popular ChatGPT. Baidu&amp;#39;s move further fuels this rivalry.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Regulation in China seems to support such AI advancements.&lt;/strong&gt; CEO Robin Li voiced his optimism about the AI regulations\u2014calling them &amp;quot;more pro-innovation than regulation&amp;quot;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What&amp;#39;s the broader response?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Baidu&amp;#39;s latest stride has boosted its stock price by over 3%,&lt;/strong&gt; underlining the market&amp;#39;s high anticipation of Baidu&amp;#39;s AI efforts.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Ernie Bot has rocketed to the top of Apple&amp;#39;s iOS free app chart in China.&lt;/strong&gt; This demonstrates a positive initial response from the public.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Regulation is key in China&amp;#39;s AI game:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;China has stringent regulations for the generative AI industry,&lt;/strong&gt; requiring a security review and government approvals before any product launch. Moreover, companies need to comply with governmental tech and data requests.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;The US, on the other hand, doesn&amp;#39;t currently have such regulations in place.&lt;/strong&gt; A markedly different approach that could significantly influence the development and application of AI technologies.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you like this kind of analysis,\u00a0you might want to &lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=baidu-ai&amp;amp;utm_campaign=campaign\"&gt;check this out&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://apnews.com/article/baidu-ai-chatbot-ernie-chatgpt-627bd09608816847907d41f44da235d9\"&gt;(source)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?auto=webp&amp;s=8972442682f23755fe3d4d7aea312e1cff5c8512", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce15b9c726f05a168b1db503df7ab26f60f62501", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=177bdfd4af3db3eb7dfe0b92698bbd1d97974ee8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3630ec555e6a1910b62043cf2097eb88a6f14ef5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=312e7a99fa2a2080e445758016e4648398339990", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87aa77b180bceb48e3af8ae0450b505860d95694", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=78860fb6488536b343b979bab9c14c0815d49eb5", "width": 1080, "height": 567}], "variants": {}, "id": "NPZM0p8FtC5HwSLNn0lZ-Kh6AiQlvJ78GtZ_8REUGxc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "166i2tp", "is_robot_indexable": true, "report_reasons": null, "author": "AIsupercharged", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166i2tp/baidu_publicly_releases_their_ai_chatbot_ernie_bot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166i2tp/baidu_publicly_releases_their_ai_chatbot_ernie_bot/", "subreddit_subscribers": 1025434, "created_utc": 1693504666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone! \nI'm working on a sales data analysis project and hitting a bit of a snag, especially when it comes to customer segmentation using RFM analysis. I've got some data and goals, but I'm not quite sure how to make it all come together. If anyone's got experience or is looking to expand their portfolio, your help would be a game-changer.\n\nI have 30K rows data, here's the kind of data I'm working with:\n- Salesperson names\n- Customer names\n- Invoice dates\n- Invoice numbers\n- Products sold\n- Quantity\n- Total amount\n\nAnd what I want to get my head around:\n- Sales team KPIs like per-person sales, conversion rates, and targets\n\n- Customer insights like who's spending the most and how often\n\n- Product metrics like what's selling and what's not\n\n- Time-based trends, financials, and geographic performance\n\n- And specifically, I'm stuck on RFM segmentation for customers. Like, how do I categorize them based on their recent purchases, how often they buy, and how much they're spending?\n\nIf anyone's got the know-how, especially with RFM segmentation, or is just up for lending a hand, that'd be awesome. I'm down for using Google Sheets or Excel.\n\nHuge thanks for taking the time to read this. Can't wait to hear from you", "author_fullname": "t2_k0r0127f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stuck on Sales Data &amp; RFM Stuff, Anyone Up for Helping me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_167cqxj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693587797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! \nI&amp;#39;m working on a sales data analysis project and hitting a bit of a snag, especially when it comes to customer segmentation using RFM analysis. I&amp;#39;ve got some data and goals, but I&amp;#39;m not quite sure how to make it all come together. If anyone&amp;#39;s got experience or is looking to expand their portfolio, your help would be a game-changer.&lt;/p&gt;\n\n&lt;p&gt;I have 30K rows data, here&amp;#39;s the kind of data I&amp;#39;m working with:\n- Salesperson names\n- Customer names\n- Invoice dates\n- Invoice numbers\n- Products sold\n- Quantity\n- Total amount&lt;/p&gt;\n\n&lt;p&gt;And what I want to get my head around:\n- Sales team KPIs like per-person sales, conversion rates, and targets&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Customer insights like who&amp;#39;s spending the most and how often&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Product metrics like what&amp;#39;s selling and what&amp;#39;s not&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Time-based trends, financials, and geographic performance&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;And specifically, I&amp;#39;m stuck on RFM segmentation for customers. Like, how do I categorize them based on their recent purchases, how often they buy, and how much they&amp;#39;re spending?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If anyone&amp;#39;s got the know-how, especially with RFM segmentation, or is just up for lending a hand, that&amp;#39;d be awesome. I&amp;#39;m down for using Google Sheets or Excel.&lt;/p&gt;\n\n&lt;p&gt;Huge thanks for taking the time to read this. Can&amp;#39;t wait to hear from you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "167cqxj", "is_robot_indexable": true, "report_reasons": null, "author": "bertcapus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/167cqxj/stuck_on_sales_data_rfm_stuff_anyone_up_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/167cqxj/stuck_on_sales_data_rfm_stuff_anyone_up_for/", "subreddit_subscribers": 1025434, "created_utc": 1693587797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time analytics with stream processing and OLAP | Cloud Native Computing Foundation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_167cag0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BL9kn680EulfLI3hHrqcAdXHkFMMFzaXi7iWk9jr6Kc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693586753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cncf.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.cncf.io/blog/2023/08/08/real-time-analytics-with-stream-processing-and-olap/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wb8V32HSWiGuzLWeXHOo_jUVV4rbypXOGW054mrEeMw.jpg?auto=webp&amp;s=aa9c97b89a689c02153495e71ae322e889ed2a79", "width": 1800, "height": 945}, "resolutions": [{"url": "https://external-preview.redd.it/wb8V32HSWiGuzLWeXHOo_jUVV4rbypXOGW054mrEeMw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=36492cce1a5aefd781178516173ce930344a8804", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/wb8V32HSWiGuzLWeXHOo_jUVV4rbypXOGW054mrEeMw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4c8e9748ac1ae16dc6ff8fe6647452d3e589e655", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/wb8V32HSWiGuzLWeXHOo_jUVV4rbypXOGW054mrEeMw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f441731ee0e03af104d62223bfb9172cee18412c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/wb8V32HSWiGuzLWeXHOo_jUVV4rbypXOGW054mrEeMw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=35702090a162c7675aa7b1fa81806bc8c5903f9a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/wb8V32HSWiGuzLWeXHOo_jUVV4rbypXOGW054mrEeMw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=986e5eaa2b94709ada0073190e6b3824c382e3d4", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/wb8V32HSWiGuzLWeXHOo_jUVV4rbypXOGW054mrEeMw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=da3c7c626025598cc75822c7b7012ca26e337b25", "width": 1080, "height": 567}], "variants": {}, "id": "ijWR1Swl--0rICxKThDapxecUio0Z7lHASQK8kpLP60"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "167cag0", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/167cag0/realtime_analytics_with_stream_processing_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cncf.io/blog/2023/08/08/real-time-analytics-with-stream-processing-and-olap/", "subreddit_subscribers": 1025434, "created_utc": 1693586753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi I was going through the basics of Neural  Networks going through the code, I was not able to understand in the hidden layer how we select a number of neurons.\n\ncode:\n\n \n\nmodel = tf.keras.Sequential(\\[  \ntf.keras.layers.Flatten(input\\_shape=(28, 28, 1)),  \ntf.keras.layers.Dense(128, activation=tf.nn.relu),  \ntf.keras.layers.Dense(10, activation=tf.nn.softmax)  \n\\])\n\n&amp;#x200B;\n\nthe data was  Fashion MNIST.", "author_fullname": "t2_5e2w4e58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Neural Network | Hidden Layer | neurons", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_167bstu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693585619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I was going through the basics of Neural  Networks going through the code, I was not able to understand in the hidden layer how we select a number of neurons.&lt;/p&gt;\n\n&lt;p&gt;code:&lt;/p&gt;\n\n&lt;p&gt;model = tf.keras.Sequential([&lt;br/&gt;\ntf.keras.layers.Flatten(input_shape=(28, 28, 1)),&lt;br/&gt;\ntf.keras.layers.Dense(128, activation=tf.nn.relu),&lt;br/&gt;\ntf.keras.layers.Dense(10, activation=tf.nn.softmax)&lt;br/&gt;\n])&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;the data was  Fashion MNIST.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "167bstu", "is_robot_indexable": true, "report_reasons": null, "author": "mr_anonymous_26", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/167bstu/neural_network_hidden_layer_neurons/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/167bstu/neural_network_hidden_layer_neurons/", "subreddit_subscribers": 1025434, "created_utc": 1693585619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data Scientist from analytical background but my current organization's approach to Data Science is highly software development oriented one as most of the data scientists in our team are from Software engineering background. How can I learn software engineering concepts? What would be the best approach? Any online courses I can refer to?", "author_fullname": "t2_s4zjmwwz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best approach for a data scientist to acquire Software Engineering skills?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_167bgh2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693584849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Scientist from analytical background but my current organization&amp;#39;s approach to Data Science is highly software development oriented one as most of the data scientists in our team are from Software engineering background. How can I learn software engineering concepts? What would be the best approach? Any online courses I can refer to?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "167bgh2", "is_robot_indexable": true, "report_reasons": null, "author": "Winter_Salt1084", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/167bgh2/best_approach_for_a_data_scientist_to_acquire/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/167bgh2/best_approach_for_a_data_scientist_to_acquire/", "subreddit_subscribers": 1025434, "created_utc": 1693584849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My previous experience in risk analysis was mentally exhausting, prompting my interest in exploring different areas of data analysis, such as marketing and AB testing. \n\nI am curious to know what types of personal projects can facilitate a transition into the business domain, considering the limited availability of public data.", "author_fullname": "t2_elfp5eeg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning into a Different Domain with Personal Projects: Is It Possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167adco", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693582386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My previous experience in risk analysis was mentally exhausting, prompting my interest in exploring different areas of data analysis, such as marketing and AB testing. &lt;/p&gt;\n\n&lt;p&gt;I am curious to know what types of personal projects can facilitate a transition into the business domain, considering the limited availability of public data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "167adco", "is_robot_indexable": true, "report_reasons": null, "author": "ok_effect_6502", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/167adco/transitioning_into_a_different_domain_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/167adco/transitioning_into_a_different_domain_with/", "subreddit_subscribers": 1025434, "created_utc": 1693582386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello - forgive me as I'm not a data scientist or analyst or even remotely technical and do not come from this background.  I have started a job where I'll be working with a lot of data but not a lot of technical people.\n\nWe work with a lot of a) clients who have large data sets with millions of rows - in snowflake, in SAP, in salesforce, etc and b) vendors who we need to ingest specific columns of our clients data sets in a secure way.\n\nI am struggling to wrap my head around how these giant data sets get moved around or pushed over to other places.  I don't get Google Cloud or AWS or S3 or \"buckets\" or even what an SFTP is.    Obviously you can not just export a CSV file with 10 million rows and just upload it to a tech vendors platform.  A bunch of \"pipelines\" need to be \"set up\".  All of it feels so incredibly abstract to me - is there any very basic 101 educational resources or online classes that help me understand this?\n\nApologies for the 101 question.", "author_fullname": "t2_1o3tbnvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Layperson Question: How do giant datasets (millions of rows) get moved from *here* to *there*? What are educational resources that can help me understand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1679z4v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693581469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello - forgive me as I&amp;#39;m not a data scientist or analyst or even remotely technical and do not come from this background.  I have started a job where I&amp;#39;ll be working with a lot of data but not a lot of technical people.&lt;/p&gt;\n\n&lt;p&gt;We work with a lot of a) clients who have large data sets with millions of rows - in snowflake, in SAP, in salesforce, etc and b) vendors who we need to ingest specific columns of our clients data sets in a secure way.&lt;/p&gt;\n\n&lt;p&gt;I am struggling to wrap my head around how these giant data sets get moved around or pushed over to other places.  I don&amp;#39;t get Google Cloud or AWS or S3 or &amp;quot;buckets&amp;quot; or even what an SFTP is.    Obviously you can not just export a CSV file with 10 million rows and just upload it to a tech vendors platform.  A bunch of &amp;quot;pipelines&amp;quot; need to be &amp;quot;set up&amp;quot;.  All of it feels so incredibly abstract to me - is there any very basic 101 educational resources or online classes that help me understand this?&lt;/p&gt;\n\n&lt;p&gt;Apologies for the 101 question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1679z4v", "is_robot_indexable": true, "report_reasons": null, "author": "milkshakedog111", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1679z4v/layperson_question_how_do_giant_datasets_millions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1679z4v/layperson_question_how_do_giant_datasets_millions/", "subreddit_subscribers": 1025434, "created_utc": 1693581469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nFor example I have  salary , partner salary and total salary \nFew of partner salary is missing. \nHow to replace them with total - salary?", "author_fullname": "t2_752hstavi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to replace missing values with difference of corresponding columns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1679ja7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693580477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example I have  salary , partner salary and total salary \nFew of partner salary is missing. \nHow to replace them with total - salary?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1679ja7", "is_robot_indexable": true, "report_reasons": null, "author": "baelorthebest", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1679ja7/how_to_replace_missing_values_with_difference_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1679ja7/how_to_replace_missing_values_with_difference_of/", "subreddit_subscribers": 1025434, "created_utc": 1693580477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am in the process of developing an XGBoost model for the task of multivariate regression. Specifically, I am focused on predicting values for the most recent 30 data points in my time series. Intriguingly, when I employ the entire dataset for model training, it yields suboptimal performance, whereas training the model on a carefully selected subset of the training data results in a substantial improvement in performance.\n\nMy objective is to adopt a statistical approach for the purpose of systematically identifying the optimal subset of the dataset for training, with the ultimate goal of enhancing the model's performance on the test data. For performance evaluation, I employ two distinct metrics: the Mean Absolute Error (MAE) calculated for the initial 15 days of test data and the MAE computed for the entire month of test data. My aim is to achieve optimal values for both metrics.\n\nWhat statistical methodology or techniques should I employ to effectively and rigorously determine the most suitable subset of data for model training?", "author_fullname": "t2_ffdv5pbv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Statistically choose subset of data for model training", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1677ezd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693575529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in the process of developing an XGBoost model for the task of multivariate regression. Specifically, I am focused on predicting values for the most recent 30 data points in my time series. Intriguingly, when I employ the entire dataset for model training, it yields suboptimal performance, whereas training the model on a carefully selected subset of the training data results in a substantial improvement in performance.&lt;/p&gt;\n\n&lt;p&gt;My objective is to adopt a statistical approach for the purpose of systematically identifying the optimal subset of the dataset for training, with the ultimate goal of enhancing the model&amp;#39;s performance on the test data. For performance evaluation, I employ two distinct metrics: the Mean Absolute Error (MAE) calculated for the initial 15 days of test data and the MAE computed for the entire month of test data. My aim is to achieve optimal values for both metrics.&lt;/p&gt;\n\n&lt;p&gt;What statistical methodology or techniques should I employ to effectively and rigorously determine the most suitable subset of data for model training?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1677ezd", "is_robot_indexable": true, "report_reasons": null, "author": "Several-Donut4969", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1677ezd/statistically_choose_subset_of_data_for_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1677ezd/statistically_choose_subset_of_data_for_model/", "subreddit_subscribers": 1025434, "created_utc": 1693575529.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}