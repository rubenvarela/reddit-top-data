{"kind": "Listing", "data": {"after": "t3_166nteq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When will the industry realise if they make a large budget for juniors in just 3 years it will be trivial to find seniors", "author_fullname": "t2_b9zxq8w1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Over 2 million and not a single junior position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_166fyd5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 338, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 338, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pLwg1vRXb9fYAjtqes68LpkYbzEX3mKQN62GgtM74So.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693499671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When will the industry realise if they make a large budget for juniors in just 3 years it will be trivial to find seniors&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q5cizucz3hlb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?auto=webp&amp;s=70ee458daff6a7eba8f1b45b025dbe22759b9db9", "width": 828, "height": 1008}, "resolutions": [{"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=540e0b20513e438dc34debd43e42046226ed2927", "width": 108, "height": 131}, {"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5f345782d28ae27473cfb823702872a42a6eeb93", "width": 216, "height": 262}, {"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e9d34a32b8c6c431b3fa2b45e556e5b4aaa8d17", "width": 320, "height": 389}, {"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc0d8937b20517b17d0308eae90b27edd4e48faf", "width": 640, "height": 779}], "variants": {}, "id": "PCYRgPjep3dXh5zr873WHR6FDNMkaZxlgXhFA7m33qs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "166fyd5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Reality2341", "discussion_type": null, "num_comments": 118, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166fyd5/over_2_million_and_not_a_single_junior_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q5cizucz3hlb1.jpg", "subreddit_subscribers": 1024631, "created_utc": 1693499671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It is easy to be swayed by the llm-gen-ai hype, while analyst jobs actually constitute the majority of the job market.\n\nThese are new job openings that my bots at [jobs-in-data.com](https://jobs-in-data.com) indexed in August:\n\nTotal Jobs: 75,947\n\n**Split by Position:**\n\n* Analyst: 52,738 jobs (69.44%)\n* Other: 6,933 jobs (9.13%)\n* Other Engineers: 4,639 jobs (6.11%)\n* Data Engineer: 4,575 jobs (6.02%)\n* Data Scientist: 3,419 jobs (4.50%)\n* Data Manager: 1,473 jobs (1.94%)\n* Machine Learning Engineer: 951 jobs (1.25%)\n* Data Entry Clerk: 627 jobs (0.83%)\n* Actuary: 592 jobs (0.78%)\n\nI am also adding the most sought-after platform-related skills (right - MS Excel is not a platform - but is put there just for comparison).\n\n**Split by Platform:**\n\n* MS Excel: 38,408 jobs (50.57%)\n* Tableau: 6,452 jobs (8.50%)\n* Power BI: 6,187 jobs (8.15%)\n* SalesForce: 2,537 jobs (3.34%)\n* Apache Hadoop: 2,256 jobs (2.97%)\n* Snowflake: 2,043 jobs (2.69%)\n* Apache Kafka: 1,787 jobs (2.35%)\n* Databricks: 1,510 jobs (1.99%)\n* Amazon Redshift: 1,013 jobs (1.33%)\n* Google BigQuery: 840 jobs (1.11%)\n* Alteryx: 712 jobs (0.94%)\n* Teradata: 516 jobs (0.68%)\n* Cloudera: 215 jobs (0.28%)\n* Microsoft Azure Synapse Analytics: 203 jobs (0.27%)\n* Hortonworks: 102 jobs (0.13%)\n* Delta Lake: 100 jobs (0.13%)\n* Qubole: 3 jobs (0.00%)\n\n&amp;#x200B;\n\n\\[EDIT\\]:\n\nAlso, as per requests below, I show required programming languages\n\n&amp;#x200B;\n\nhttps://preview.redd.it/vy652vwk3hlb1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=103722ce813491cb1bca64fd1f33c0e88b7cd2cc", "author_fullname": "t2_h7ibth00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analysts &gt; others (in terms of open job positions)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vy652vwk3hlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=062de38e097bb7a13ca3640500387786197c5714"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=951e9dd75586bbc29d914dbc2e3ed8cef9560f85"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e45ce2cf98b32e9674bf8413b6add686b2ad5366"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6a925ae463fc6a0a7dfe2c717d30f14b06b5c036"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f27cbb13dfc5e12b0052a18265681de0843502d4"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa6a9666d6b5bd7a028acdc3413601b0787df141"}], "s": {"y": 1440, "x": 2560, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=103722ce813491cb1bca64fd1f33c0e88b7cd2cc"}, "id": "vy652vwk3hlb1"}}, "name": "t3_166bj2q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 124, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 124, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qLtqezLdWFqW3ZQ7eLTybyYOHNW9bqWbEcrmbcn3e7U.jpg", "edited": 1693499535.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693489327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is easy to be swayed by the llm-gen-ai hype, while analyst jobs actually constitute the majority of the job market.&lt;/p&gt;\n\n&lt;p&gt;These are new job openings that my bots at &lt;a href=\"https://jobs-in-data.com\"&gt;jobs-in-data.com&lt;/a&gt; indexed in August:&lt;/p&gt;\n\n&lt;p&gt;Total Jobs: 75,947&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Split by Position:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Analyst: 52,738 jobs (69.44%)&lt;/li&gt;\n&lt;li&gt;Other: 6,933 jobs (9.13%)&lt;/li&gt;\n&lt;li&gt;Other Engineers: 4,639 jobs (6.11%)&lt;/li&gt;\n&lt;li&gt;Data Engineer: 4,575 jobs (6.02%)&lt;/li&gt;\n&lt;li&gt;Data Scientist: 3,419 jobs (4.50%)&lt;/li&gt;\n&lt;li&gt;Data Manager: 1,473 jobs (1.94%)&lt;/li&gt;\n&lt;li&gt;Machine Learning Engineer: 951 jobs (1.25%)&lt;/li&gt;\n&lt;li&gt;Data Entry Clerk: 627 jobs (0.83%)&lt;/li&gt;\n&lt;li&gt;Actuary: 592 jobs (0.78%)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am also adding the most sought-after platform-related skills (right - MS Excel is not a platform - but is put there just for comparison).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Split by Platform:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;MS Excel: 38,408 jobs (50.57%)&lt;/li&gt;\n&lt;li&gt;Tableau: 6,452 jobs (8.50%)&lt;/li&gt;\n&lt;li&gt;Power BI: 6,187 jobs (8.15%)&lt;/li&gt;\n&lt;li&gt;SalesForce: 2,537 jobs (3.34%)&lt;/li&gt;\n&lt;li&gt;Apache Hadoop: 2,256 jobs (2.97%)&lt;/li&gt;\n&lt;li&gt;Snowflake: 2,043 jobs (2.69%)&lt;/li&gt;\n&lt;li&gt;Apache Kafka: 1,787 jobs (2.35%)&lt;/li&gt;\n&lt;li&gt;Databricks: 1,510 jobs (1.99%)&lt;/li&gt;\n&lt;li&gt;Amazon Redshift: 1,013 jobs (1.33%)&lt;/li&gt;\n&lt;li&gt;Google BigQuery: 840 jobs (1.11%)&lt;/li&gt;\n&lt;li&gt;Alteryx: 712 jobs (0.94%)&lt;/li&gt;\n&lt;li&gt;Teradata: 516 jobs (0.68%)&lt;/li&gt;\n&lt;li&gt;Cloudera: 215 jobs (0.28%)&lt;/li&gt;\n&lt;li&gt;Microsoft Azure Synapse Analytics: 203 jobs (0.27%)&lt;/li&gt;\n&lt;li&gt;Hortonworks: 102 jobs (0.13%)&lt;/li&gt;\n&lt;li&gt;Delta Lake: 100 jobs (0.13%)&lt;/li&gt;\n&lt;li&gt;Qubole: 3 jobs (0.00%)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;[EDIT]:&lt;/p&gt;\n\n&lt;p&gt;Also, as per requests below, I show required programming languages&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vy652vwk3hlb1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=103722ce813491cb1bca64fd1f33c0e88b7cd2cc\"&gt;https://preview.redd.it/vy652vwk3hlb1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=103722ce813491cb1bca64fd1f33c0e88b7cd2cc&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166bj2q", "is_robot_indexable": true, "report_reasons": null, "author": "pg860", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166bj2q/analysts_others_in_terms_of_open_job_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166bj2q/analysts_others_in_terms_of_open_job_positions/", "subreddit_subscribers": 1024631, "created_utc": 1693489327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've started a new job in a industry company. \n\nBasically, my department does market analysis. They've been doing it for years and everything is a big Excel file. Everything is excel and kind of a mess. For more info about the context, here the [episode 1](https://old.reddit.com/r/dataengineering/comments/1271cb2/new_job_as_a_data_manager_the_data_is_a_bunch_of/) of my adventures.\n\nSo, I've had to build from scratch some kind of data *stack*. Currently it is :\n\n* A postgresql database\n* Jupyter environment\n\nTo be honest, I was skeptical about Jupyter because it shouldn't be a production jack-of-all-trades-data-tools. But so far so good.\n\nI'm fairly experienced in SQL, Python (for data analysis: pandas, numpy). \n\nHere is my question. A huge part of the job is producing charts and graphs and so on. **The most typical case is producing one chart and doing 10 variations of it**. Basically for each business line. So, it's just a matter a filtering there and there and that's it. \n\nBefore, everything was done in Excel. And kind of a pain, because you had a bunch of sheets and pivot tables and then the charts. You clicked update and everything went to shit because Excel freaks out if the context moves a tiny bit, etc. It was almost impossible to maintain consistency with colors, etc. So... not ideal. And on top of that, people had to draw by hand square and things on top of the charts because there are no ways to do it in Excel.\n\nMy solution for that is... Doing it in Python... And I don't know if it's a good idea. I'm self taught and has no idea if there are more proper way to produce charts for print/presentations. Main motivation was: \"I can get Python working fast, I really want to practice it more\"\n\nMy approach is:\n\n- If I have to produce a report, that is like 30 charts and they all have 5 variations. I build a notebook for this purpose. \n- In the notebook I try to make everything nice and tidy by using parameters and functions a lot (and comments, and text blocks with explanations for future-me). I try to pull data once (SQL) and keep it as a dataframe, manipulate it with Pandas and do the chart with Matplotlib. Each chart is a function and variations are handled by passing a parameters. And styling, etc. Is done by calling a module I've made.\n\nFor example, I want to produce the the bar chart `P3G2_B1`. It's the Graph #2 on page #3 for Business line #1. \n\nI call the function `P3G2()` with B1 as parameters and it produces the desired chart. With proper styling (Title, proper stylesheet, and a footer mentioning the chart id and the date). It's saved as a SVG (P3G2_B1.svg) and later converted to .EMF (because my company uses an old version of PPT that doesn't support SVG.\n\nSo far, what is good about this approach :\n\n- The charts look nice and are very visually consistent. Matplotlib allows me to specify a lot of things so there are few surprises.\n- It's fast enough. Doing an update and outputing 50 charts is a matter of minutes.\n\nWhat I'm not too happy about :\n\n- Matplotlib makes me miserable. I'm still learning Python and everything is painful. I find matplotlib confusing as hell. There are multiples and wildly different ways to do anything. Half of my days are just googling \"How to so &lt;insert weird request&gt; in matplotlib\". I've tried seaborn, plain pandas, and so on that are supposed to be *easier* than pure matplotlib. Well, I end up having to do something weird and having to sprinkle it with plain old matplotlib regardless. So I've decided to just go with it.\n- Matplotlib to do print is quite awful. My powerpoint slides have a grid, and let's say I want to create a bar chart that is 8 by 6 on this grid. So I expect a 800x600 pixels image. Not. so. easy. (especially since I need space for title and footer around the chart). What you see and not always what you get (through savefig, as an image file). My module handles that mostly OK but it's very hacky and still a mess. And also, the .svg to .emf conversion is another layer of pain. Some graphical things don't convert well (hatches for example).\n- Some charts functions are more than 100 hundreds lines of code. It scares me a bit. I have a hard time convincing people that it is better than Excel. They just see a house of cards waiting to fall.\n\nSo. Given the assignment, am I crazy to go with Python notebooks?\nDo you have suggestions to make my life easier producing nice, print quality charts to insert in Powerpoint?", "author_fullname": "t2_cr1c7y8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My job is producing loads of charts for Powerpoint...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166p30n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693520635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve started a new job in a industry company. &lt;/p&gt;\n\n&lt;p&gt;Basically, my department does market analysis. They&amp;#39;ve been doing it for years and everything is a big Excel file. Everything is excel and kind of a mess. For more info about the context, here the &lt;a href=\"https://old.reddit.com/r/dataengineering/comments/1271cb2/new_job_as_a_data_manager_the_data_is_a_bunch_of/\"&gt;episode 1&lt;/a&gt; of my adventures.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;ve had to build from scratch some kind of data &lt;em&gt;stack&lt;/em&gt;. Currently it is :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A postgresql database&lt;/li&gt;\n&lt;li&gt;Jupyter environment&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To be honest, I was skeptical about Jupyter because it shouldn&amp;#39;t be a production jack-of-all-trades-data-tools. But so far so good.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fairly experienced in SQL, Python (for data analysis: pandas, numpy). &lt;/p&gt;\n\n&lt;p&gt;Here is my question. A huge part of the job is producing charts and graphs and so on. &lt;strong&gt;The most typical case is producing one chart and doing 10 variations of it&lt;/strong&gt;. Basically for each business line. So, it&amp;#39;s just a matter a filtering there and there and that&amp;#39;s it. &lt;/p&gt;\n\n&lt;p&gt;Before, everything was done in Excel. And kind of a pain, because you had a bunch of sheets and pivot tables and then the charts. You clicked update and everything went to shit because Excel freaks out if the context moves a tiny bit, etc. It was almost impossible to maintain consistency with colors, etc. So... not ideal. And on top of that, people had to draw by hand square and things on top of the charts because there are no ways to do it in Excel.&lt;/p&gt;\n\n&lt;p&gt;My solution for that is... Doing it in Python... And I don&amp;#39;t know if it&amp;#39;s a good idea. I&amp;#39;m self taught and has no idea if there are more proper way to produce charts for print/presentations. Main motivation was: &amp;quot;I can get Python working fast, I really want to practice it more&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;My approach is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;If I have to produce a report, that is like 30 charts and they all have 5 variations. I build a notebook for this purpose. &lt;/li&gt;\n&lt;li&gt;In the notebook I try to make everything nice and tidy by using parameters and functions a lot (and comments, and text blocks with explanations for future-me). I try to pull data once (SQL) and keep it as a dataframe, manipulate it with Pandas and do the chart with Matplotlib. Each chart is a function and variations are handled by passing a parameters. And styling, etc. Is done by calling a module I&amp;#39;ve made.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For example, I want to produce the the bar chart &lt;code&gt;P3G2_B1&lt;/code&gt;. It&amp;#39;s the Graph #2 on page #3 for Business line #1. &lt;/p&gt;\n\n&lt;p&gt;I call the function &lt;code&gt;P3G2()&lt;/code&gt; with B1 as parameters and it produces the desired chart. With proper styling (Title, proper stylesheet, and a footer mentioning the chart id and the date). It&amp;#39;s saved as a SVG (P3G2_B1.svg) and later converted to .EMF (because my company uses an old version of PPT that doesn&amp;#39;t support SVG.&lt;/p&gt;\n\n&lt;p&gt;So far, what is good about this approach :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The charts look nice and are very visually consistent. Matplotlib allows me to specify a lot of things so there are few surprises.&lt;/li&gt;\n&lt;li&gt;It&amp;#39;s fast enough. Doing an update and outputing 50 charts is a matter of minutes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What I&amp;#39;m not too happy about :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Matplotlib makes me miserable. I&amp;#39;m still learning Python and everything is painful. I find matplotlib confusing as hell. There are multiples and wildly different ways to do anything. Half of my days are just googling &amp;quot;How to so &amp;lt;insert weird request&amp;gt; in matplotlib&amp;quot;. I&amp;#39;ve tried seaborn, plain pandas, and so on that are supposed to be &lt;em&gt;easier&lt;/em&gt; than pure matplotlib. Well, I end up having to do something weird and having to sprinkle it with plain old matplotlib regardless. So I&amp;#39;ve decided to just go with it.&lt;/li&gt;\n&lt;li&gt;Matplotlib to do print is quite awful. My powerpoint slides have a grid, and let&amp;#39;s say I want to create a bar chart that is 8 by 6 on this grid. So I expect a 800x600 pixels image. Not. so. easy. (especially since I need space for title and footer around the chart). What you see and not always what you get (through savefig, as an image file). My module handles that mostly OK but it&amp;#39;s very hacky and still a mess. And also, the .svg to .emf conversion is another layer of pain. Some graphical things don&amp;#39;t convert well (hatches for example).&lt;/li&gt;\n&lt;li&gt;Some charts functions are more than 100 hundreds lines of code. It scares me a bit. I have a hard time convincing people that it is better than Excel. They just see a house of cards waiting to fall.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So. Given the assignment, am I crazy to go with Python notebooks?\nDo you have suggestions to make my life easier producing nice, print quality charts to insert in Powerpoint?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166p30n", "is_robot_indexable": true, "report_reasons": null, "author": "raymondstanz", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166p30n/my_job_is_producing_loads_of_charts_for_powerpoint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166p30n/my_job_is_producing_loads_of_charts_for_powerpoint/", "subreddit_subscribers": 1024631, "created_utc": 1693520635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been giving interviews every now and then but with little success.\n\nOne question is \"why looking for new job?\"\n\nto which I state \"looking to explore a new domain\".\n\nI'm currently in banking domain and truly want to switch.\n\nI'm applying for Sr. Analyst roles, not anything managerial or SME level.", "author_fullname": "t2_736ioria", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is \"change of domain\" not a good reason for job switch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1662ppu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693461813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been giving interviews every now and then but with little success.&lt;/p&gt;\n\n&lt;p&gt;One question is &amp;quot;why looking for new job?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;to which I state &amp;quot;looking to explore a new domain&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently in banking domain and truly want to switch.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m applying for Sr. Analyst roles, not anything managerial or SME level.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1662ppu", "is_robot_indexable": true, "report_reasons": null, "author": "jaegarbong", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1662ppu/is_change_of_domain_not_a_good_reason_for_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1662ppu/is_change_of_domain_not_a_good_reason_for_job/", "subreddit_subscribers": 1024631, "created_utc": 1693461813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_icnu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New data strategy: German government recognises untapped data potential", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1667qft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ikIKDm-eh5IkmjhYrx8r7pqyFFwO5Xu-LKrDuYJy9hk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693478875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "euractiv.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.euractiv.com/section/data-privacy/news/new-data-strategy-german-government-recognises-untapped-data-potential/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?auto=webp&amp;s=50a41b77a34e1ac2bf48ffdc9d71a1941db6df80", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7cd046fb739bf05f183a890cd0999d352942f40d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e0f5fdeaa2d8e3d0245dcc8183f085e0c2db6b5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=27688813a47c18fdedc11c7bf0b99d76ab3c5c76", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b46f95afb4ef0daf64ee0d58711530a1e805b9f7", "width": 640, "height": 360}], "variants": {}, "id": "_FUrr4nkJJyC_TtHBSCwmBdqbKnATVApPRqYKZ1Dquc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1667qft", "is_robot_indexable": true, "report_reasons": null, "author": "allants2", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1667qft/new_data_strategy_german_government_recognises/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.euractiv.com/section/data-privacy/news/new-data-strategy-german-government-recognises-untapped-data-potential/", "subreddit_subscribers": 1024631, "created_utc": 1693478875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'd like to get into the data science industry after spending 8 years in the academia side of data science. I can confidently say that I have a solid foundation on the theoretical side of data science and I have done some computer programming for my thesis and other projects, but I fear that I lack the industry-grade experience to pursue a career in the corporate world.\n\nIn our country, you have to experience other roles first before officially becoming a data scientist. Most people with science degrees that are not heavy on math start as data analysts. IT/CS/Stat/Math graduates usually start as data engineers.\n\nThe problem with my background is that I find the job requirements for data engineering **extremely intimidating**. I only know Python, R, SQL, MATLAB, and C, but somehow the job apparently requires me to also know Java, C# (.NET), Perl, Groovy, and JavaScript. On top of that, this is apparently an entry-level position. \n\nI feel like the only way for me to apply what I studied in school is to become a data engineer first. Unfortunately for me, the multitude of programming languages and the data engineering pipeline intimidates me.\n\nDoes anyone here have any stories to share about shifting from academia (heavy on theory, so-so applications) to the industry? Did any of you also find the IT-heavy background intimidating? I am eager to learn these languages and tech, but I also don't want to overwhelm myself and pretend as if I am fit for data engineering.", "author_fullname": "t2_bmbqthh3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For math/stat majors, do you think data engineering is intimidating?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1664dnx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693467484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to get into the data science industry after spending 8 years in the academia side of data science. I can confidently say that I have a solid foundation on the theoretical side of data science and I have done some computer programming for my thesis and other projects, but I fear that I lack the industry-grade experience to pursue a career in the corporate world.&lt;/p&gt;\n\n&lt;p&gt;In our country, you have to experience other roles first before officially becoming a data scientist. Most people with science degrees that are not heavy on math start as data analysts. IT/CS/Stat/Math graduates usually start as data engineers.&lt;/p&gt;\n\n&lt;p&gt;The problem with my background is that I find the job requirements for data engineering &lt;strong&gt;extremely intimidating&lt;/strong&gt;. I only know Python, R, SQL, MATLAB, and C, but somehow the job apparently requires me to also know Java, C# (.NET), Perl, Groovy, and JavaScript. On top of that, this is apparently an entry-level position. &lt;/p&gt;\n\n&lt;p&gt;I feel like the only way for me to apply what I studied in school is to become a data engineer first. Unfortunately for me, the multitude of programming languages and the data engineering pipeline intimidates me.&lt;/p&gt;\n\n&lt;p&gt;Does anyone here have any stories to share about shifting from academia (heavy on theory, so-so applications) to the industry? Did any of you also find the IT-heavy background intimidating? I am eager to learn these languages and tech, but I also don&amp;#39;t want to overwhelm myself and pretend as if I am fit for data engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1664dnx", "is_robot_indexable": true, "report_reasons": null, "author": "krabbypatty-o-fish", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1664dnx/for_mathstat_majors_do_you_think_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1664dnx/for_mathstat_majors_do_you_think_data_engineering/", "subreddit_subscribers": 1024631, "created_utc": 1693467484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently a lead/senior data analyst with 8 years experience and I'm thinking about getting into data science. My education is in business. TC is 150k + in mid size metro.\n\nRather than becoming a fully fledged data scientist, my goal is to become more of a \"super duper data analyst\" or an analytics manager with data science knowledge to increase my comp.\n\nSkills:\n\nTechnical (almost all self taught).\n\n* Expert Data Visualization (Looker/Power BI, Excel)\n* Expert SQL and complex data wrangling/data modeling\n* Intermediate python/pandas\n* Recently brushed up on Basic Stats (Regression, standard deviations, p-values, etc) with a stats class.\n\nSoft:\n\n* Presenting insights to stakeholders\n* Leading data analytics/engineering projects with other data folks\n* Working with upper management\n\n&amp;#x200B;\n\nIs this \"path\" of learning data science worthwhile/valuable for someone like me?\n\nCurrent data science plan\n\n* Read [Data Science for Business](https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/B08VL5K5ZX/ref=sr_1_1?crid=3TU7LKIX9YREK&amp;keywords=data+science+for+business&amp;qid=1693530503&amp;sprefix=data+science+for+business%2Caps%2C101&amp;sr=8-1)\n* Read [Intro to Stat Learning](https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/3031387465/ref=sr_1_2?crid=WCKIHHMTEUO5&amp;keywords=introduction+to+statistical&amp;qid=1693530539&amp;s=audible&amp;sprefix=introduction+to+statistional+%2Caudible%2C86&amp;sr=1-2-catcorr&amp;ufe=app_do%3Aamzn1.fos.18ed3cb5-28d5-4975-8bc7-93deae8f9840)\n* Finish DataCamp Data Science Course\n* Practice a lot of kaggle data science exercises?\n\n&amp;#x200B;", "author_fullname": "t2_bmmlgaw4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Realistic Expectations DA --&gt; DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166t4lc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693530673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a lead/senior data analyst with 8 years experience and I&amp;#39;m thinking about getting into data science. My education is in business. TC is 150k + in mid size metro.&lt;/p&gt;\n\n&lt;p&gt;Rather than becoming a fully fledged data scientist, my goal is to become more of a &amp;quot;super duper data analyst&amp;quot; or an analytics manager with data science knowledge to increase my comp.&lt;/p&gt;\n\n&lt;p&gt;Skills:&lt;/p&gt;\n\n&lt;p&gt;Technical (almost all self taught).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Expert Data Visualization (Looker/Power BI, Excel)&lt;/li&gt;\n&lt;li&gt;Expert SQL and complex data wrangling/data modeling&lt;/li&gt;\n&lt;li&gt;Intermediate python/pandas&lt;/li&gt;\n&lt;li&gt;Recently brushed up on Basic Stats (Regression, standard deviations, p-values, etc) with a stats class.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Soft:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Presenting insights to stakeholders&lt;/li&gt;\n&lt;li&gt;Leading data analytics/engineering projects with other data folks&lt;/li&gt;\n&lt;li&gt;Working with upper management&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this &amp;quot;path&amp;quot; of learning data science worthwhile/valuable for someone like me?&lt;/p&gt;\n\n&lt;p&gt;Current data science plan&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Read &lt;a href=\"https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/B08VL5K5ZX/ref=sr_1_1?crid=3TU7LKIX9YREK&amp;amp;keywords=data+science+for+business&amp;amp;qid=1693530503&amp;amp;sprefix=data+science+for+business%2Caps%2C101&amp;amp;sr=8-1\"&gt;Data Science for Business&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Read &lt;a href=\"https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/3031387465/ref=sr_1_2?crid=WCKIHHMTEUO5&amp;amp;keywords=introduction+to+statistical&amp;amp;qid=1693530539&amp;amp;s=audible&amp;amp;sprefix=introduction+to+statistional+%2Caudible%2C86&amp;amp;sr=1-2-catcorr&amp;amp;ufe=app_do%3Aamzn1.fos.18ed3cb5-28d5-4975-8bc7-93deae8f9840\"&gt;Intro to Stat Learning&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Finish DataCamp Data Science Course&lt;/li&gt;\n&lt;li&gt;Practice a lot of kaggle data science exercises?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166t4lc", "is_robot_indexable": true, "report_reasons": null, "author": "Miserable_Lion_6896", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166t4lc/realistic_expectations_da_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166t4lc/realistic_expectations_da_ds/", "subreddit_subscribers": 1024631, "created_utc": 1693530673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am not talking about trying it out hoping to boost the performance. I'm asking what situations make you think that stacking would be the best approach here?\n\nI know it works because different models works best with certain type of problems and stacking helps you to combine such particular strengths of multiple models.\n\nBut I'm asking for an example that you encountered that would demonstrate this idea where the data told you to use stacking.", "author_fullname": "t2_4s456zpp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "People who are experienced with stacking ensembling, when do you use it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16673tm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693476839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not talking about trying it out hoping to boost the performance. I&amp;#39;m asking what situations make you think that stacking would be the best approach here?&lt;/p&gt;\n\n&lt;p&gt;I know it works because different models works best with certain type of problems and stacking helps you to combine such particular strengths of multiple models.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m asking for an example that you encountered that would demonstrate this idea where the data told you to use stacking.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16673tm", "is_robot_indexable": true, "report_reasons": null, "author": "dopplegangery", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16673tm/people_who_are_experienced_with_stacking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16673tm/people_who_are_experienced_with_stacking/", "subreddit_subscribers": 1024631, "created_utc": 1693476839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The NYU Tandon School of Engineering's researchers have developed a technique that alters apparent age in images\u2014all the while preserving the subject's unique identity as shared in [the paper](https://arxiv.org/abs/2307.08585).\n\nIf you want to stay on top of the latest trends and insights in AI and tech, [look here first.](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=nyu-research&amp;utm_campaign=campaign)\n\n**Why this counts:**\n\n* **Issues with current models are being countered:** Existing AI models grapple with changing age attributes without tarnishing the individual's identity. The robust model developed by NYU researchers confronts this problem head-on.\n* **Harnessing the power of small data sets:** Unlike alternative models that need extensive amounts of pictures over many years, the NYU team harnessed a small set of captioned images and individual images to train the model.\n* **Multifaceted applications:** The new AI technique may be employed for \"aging\" or \"de-aging\" scenarios by merely designating a target age through a text prompt.\n\nHere are some important details\\*\\*:\\*\\*\n\n* **DreamBooth technique shines:** Using a composite of neural network components, researchers manipulated facial images within this fusion referred to as a DreamBooth technique.\n* **Superior performance compared to alternative methods:** When set against other age-modification techniques, this AI model outdid others, reducing incorrect rejections by up to 44%.\n* **Excellent representation across age groups:** The model demonstrates a greater capability to generate images across diverse age groups, more notably in transforming images into older age groups.\n\n**P.S. If you like this kind of analysis,**\u00a0I write\u00a0[a free newsletter](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=nyu-research&amp;utm_campaign=campaign)\u00a0that tracks the most relevant news and research in AI and tech\u2014stay updated in under 2 mins/day.\n\n[(arXiv)](https://arxiv.org/abs/2307.08585)", "author_fullname": "t2_h4jb4maul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New AI Technique by NYU Researchers Modifies Age in Images while Retaining Identity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166wpyf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693541057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The NYU Tandon School of Engineering&amp;#39;s researchers have developed a technique that alters apparent age in images\u2014all the while preserving the subject&amp;#39;s unique identity as shared in &lt;a href=\"https://arxiv.org/abs/2307.08585\"&gt;the paper&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;If you want to stay on top of the latest trends and insights in AI and tech, &lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=nyu-research&amp;amp;utm_campaign=campaign\"&gt;look here first.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why this counts:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Issues with current models are being countered:&lt;/strong&gt; Existing AI models grapple with changing age attributes without tarnishing the individual&amp;#39;s identity. The robust model developed by NYU researchers confronts this problem head-on.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Harnessing the power of small data sets:&lt;/strong&gt; Unlike alternative models that need extensive amounts of pictures over many years, the NYU team harnessed a small set of captioned images and individual images to train the model.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Multifaceted applications:&lt;/strong&gt; The new AI technique may be employed for &amp;quot;aging&amp;quot; or &amp;quot;de-aging&amp;quot; scenarios by merely designating a target age through a text prompt.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here are some important details**:**&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;DreamBooth technique shines:&lt;/strong&gt; Using a composite of neural network components, researchers manipulated facial images within this fusion referred to as a DreamBooth technique.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Superior performance compared to alternative methods:&lt;/strong&gt; When set against other age-modification techniques, this AI model outdid others, reducing incorrect rejections by up to 44%.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Excellent representation across age groups:&lt;/strong&gt; The model demonstrates a greater capability to generate images across diverse age groups, more notably in transforming images into older age groups.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;P.S. If you like this kind of analysis,&lt;/strong&gt;\u00a0I write\u00a0&lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=nyu-research&amp;amp;utm_campaign=campaign\"&gt;a free newsletter&lt;/a&gt;\u00a0that tracks the most relevant news and research in AI and tech\u2014stay updated in under 2 mins/day.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2307.08585\"&gt;(arXiv)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?auto=webp&amp;s=f1cd025aeb52ffa82fc9e5a4a2f157da0d919147", "width": 1200, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2711d572cfc6c713893cf24e8c4a7344d5ad8a4c", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6624f0c1eedc14997e7f1780efbe6e5cb50c1e2", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9db38144ef3065833b9ba158c764f7be47de3016", "width": 320, "height": 186}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075", "width": 640, "height": 373}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2637f961ee21190172b9ca6c8adf3ac9612db083", "width": 960, "height": 560}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=782eead871df2939a587ee3beae442cc59282f64", "width": 1080, "height": 630}], "variants": {}, "id": "q3evP6JeDpAC2MdSQHWYxnCYTqbJkElIQsLFqVSdkss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166wpyf", "is_robot_indexable": true, "report_reasons": null, "author": "AIsupercharged", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166wpyf/new_ai_technique_by_nyu_researchers_modifies_age/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166wpyf/new_ai_technique_by_nyu_researchers_modifies_age/", "subreddit_subscribers": 1024631, "created_utc": 1693541057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In a bid to rival the United States\u2019 stronghold in the AI industry, Chinese search engine and AI firm Baidu, has made its ChatGPT-equivalent language model, Ernie Bot, fully available to the public. This marks a significant move on the AI chessboard.\n\nIf you want to stay on top of everything AI,\u00a0[look here first.](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=baidu-ai&amp;utm_campaign=campaign)\n\nhttps://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=e7779eea500a502465bef116fa53a2bbc23c4019\n\n**Why does this matter?**\n\n* **Baidu's public release of Ernie Bot signals the company's aggressive push in the generative AI market.** By opening up its model to the public, Baidu can leverage expansive real-world human feedback to improve Ernie Bot.\n* **China's determination to lead the AI industry is unabated,** with many tech firms launching their own generative models in response to OpenAI's popular ChatGPT. Baidu's move further fuels this rivalry.\n* **Regulation in China seems to support such AI advancements.** CEO Robin Li voiced his optimism about the AI regulations\u2014calling them \"more pro-innovation than regulation\".\n\n**What's the broader response?**\n\n* **Baidu's latest stride has boosted its stock price by over 3%,** underlining the market's high anticipation of Baidu's AI efforts.\n* **Ernie Bot has rocketed to the top of Apple's iOS free app chart in China.** This demonstrates a positive initial response from the public.\n\n**Regulation is key in China's AI game:**\n\n* **China has stringent regulations for the generative AI industry,** requiring a security review and government approvals before any product launch. Moreover, companies need to comply with governmental tech and data requests.\n* **The US, on the other hand, doesn't currently have such regulations in place.** A markedly different approach that could significantly influence the development and application of AI technologies.\n\nIf you like this kind of analysis,\u00a0you might want to [check this out](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=baidu-ai&amp;utm_campaign=campaign).\n\n[(source)](https://apnews.com/article/baidu-ai-chatbot-ernie-chatgpt-627bd09608816847907d41f44da235d9)", "author_fullname": "t2_h4jb4maul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Baidu publicly releases their AI chatbot Ernie Bot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3e08q8utihlb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d1b1b1f72729af1e0be763a013d42e2c15fa9ef2"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f75f9ef2b22fd8d70dd3387ad581296f74a20d76"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd723570150ec115c9a63c2ccf5956e32c1ebef0"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4da750348d5b7963360368f537ce39b7e8bf135"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=358d17d55d50b4d79881057e6867a96eec11bf4f"}], "s": {"y": 682, "x": 1024, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=e7779eea500a502465bef116fa53a2bbc23c4019"}, "id": "3e08q8utihlb1"}}, "name": "t3_166i2tp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/rPQz06Dwfph2KnPWxOJOGKgRmPdZbNB9p1w88oxG6fA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693504666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In a bid to rival the United States\u2019 stronghold in the AI industry, Chinese search engine and AI firm Baidu, has made its ChatGPT-equivalent language model, Ernie Bot, fully available to the public. This marks a significant move on the AI chessboard.&lt;/p&gt;\n\n&lt;p&gt;If you want to stay on top of everything AI,\u00a0&lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=baidu-ai&amp;amp;utm_campaign=campaign\"&gt;look here first.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e7779eea500a502465bef116fa53a2bbc23c4019\"&gt;https://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e7779eea500a502465bef116fa53a2bbc23c4019&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why does this matter?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Baidu&amp;#39;s public release of Ernie Bot signals the company&amp;#39;s aggressive push in the generative AI market.&lt;/strong&gt; By opening up its model to the public, Baidu can leverage expansive real-world human feedback to improve Ernie Bot.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;China&amp;#39;s determination to lead the AI industry is unabated,&lt;/strong&gt; with many tech firms launching their own generative models in response to OpenAI&amp;#39;s popular ChatGPT. Baidu&amp;#39;s move further fuels this rivalry.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Regulation in China seems to support such AI advancements.&lt;/strong&gt; CEO Robin Li voiced his optimism about the AI regulations\u2014calling them &amp;quot;more pro-innovation than regulation&amp;quot;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What&amp;#39;s the broader response?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Baidu&amp;#39;s latest stride has boosted its stock price by over 3%,&lt;/strong&gt; underlining the market&amp;#39;s high anticipation of Baidu&amp;#39;s AI efforts.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Ernie Bot has rocketed to the top of Apple&amp;#39;s iOS free app chart in China.&lt;/strong&gt; This demonstrates a positive initial response from the public.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Regulation is key in China&amp;#39;s AI game:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;China has stringent regulations for the generative AI industry,&lt;/strong&gt; requiring a security review and government approvals before any product launch. Moreover, companies need to comply with governmental tech and data requests.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;The US, on the other hand, doesn&amp;#39;t currently have such regulations in place.&lt;/strong&gt; A markedly different approach that could significantly influence the development and application of AI technologies.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you like this kind of analysis,\u00a0you might want to &lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=baidu-ai&amp;amp;utm_campaign=campaign\"&gt;check this out&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://apnews.com/article/baidu-ai-chatbot-ernie-chatgpt-627bd09608816847907d41f44da235d9\"&gt;(source)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?auto=webp&amp;s=8972442682f23755fe3d4d7aea312e1cff5c8512", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce15b9c726f05a168b1db503df7ab26f60f62501", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=177bdfd4af3db3eb7dfe0b92698bbd1d97974ee8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3630ec555e6a1910b62043cf2097eb88a6f14ef5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=312e7a99fa2a2080e445758016e4648398339990", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87aa77b180bceb48e3af8ae0450b505860d95694", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=78860fb6488536b343b979bab9c14c0815d49eb5", "width": 1080, "height": 567}], "variants": {}, "id": "NPZM0p8FtC5HwSLNn0lZ-Kh6AiQlvJ78GtZ_8REUGxc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "166i2tp", "is_robot_indexable": true, "report_reasons": null, "author": "AIsupercharged", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166i2tp/baidu_publicly_releases_their_ai_chatbot_ernie_bot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166i2tp/baidu_publicly_releases_their_ai_chatbot_ernie_bot/", "subreddit_subscribers": 1024631, "created_utc": 1693504666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_14izoucv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever deployed LLama on AWS Kubernetes? I'm stuck and getting many errors such as \"waiting for Auto Scaling Group\" anyone solved it before?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 21, "top_awarded_type": null, "hide_score": false, "name": "t3_166i0q0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/E0bOwqgp4ZqLwGCDW7yT7sZ1patojOxqY0lE1_9u6m4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693504526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/i1db7089ihlb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?auto=webp&amp;s=06859b5e9cc0d76ebdcd7c577e307f4b3e7160a1", "width": 1600, "height": 242}, "resolutions": [{"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=35f58a41721ace877fdd90c91dd23120125e8729", "width": 108, "height": 16}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2418dfc949e94a52a33fae911463365396c7a234", "width": 216, "height": 32}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4007ad0c712d5643c886ae7871338a2b536d0b8c", "width": 320, "height": 48}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff16e8eb8a8d281d35d26740e4e0a654b2021d0b", "width": 640, "height": 96}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aec65af0973b5f3f14bd9bf3d74c138e25a475bc", "width": 960, "height": 145}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7c72478925a6d0745b66cf5c936c4c73ebd67ea5", "width": 1080, "height": 163}], "variants": {}, "id": "pIR74sF8xKS0ayVDm8otnRW2VYpeQto8G2JnwyIk_jM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "166i0q0", "is_robot_indexable": true, "report_reasons": null, "author": "AILaunchpad", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166i0q0/have_you_ever_deployed_llama_on_aws_kubernetes_im/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/i1db7089ihlb1.jpg", "subreddit_subscribers": 1024631, "created_utc": 1693504526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys,\n\nI've been working in the CV domain in the past 2 years and noticed that some peers, which are way more experienced than me (7+ yoe), will implement thier own versions of tools for commonly used tasks. Such examples include annotation tools or data pipelines that a pytorch dataloader is very much suited to perform (load files, split to sets, transform, argument. The basics really..)\n\nPersonally, I'm a lazy fak, so whenever I can I'll prefer an open source, widely used solution for such things. I get that sometimes building your own is a better option like when you have a special use case or want to optimize an important part, but for those type of common tasks I don't see the point.\n\nI consider my colleagues to be good at what they do, but couldn't get a real answer so I'm asking here, hoping for the more experienced of us to share their views.\n\nWhat are your thoughts on this? Where do you draw the line?", "author_fullname": "t2_18148gk5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When should I implement vs of the shelf open source?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16698zq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693483341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working in the CV domain in the past 2 years and noticed that some peers, which are way more experienced than me (7+ yoe), will implement thier own versions of tools for commonly used tasks. Such examples include annotation tools or data pipelines that a pytorch dataloader is very much suited to perform (load files, split to sets, transform, argument. The basics really..)&lt;/p&gt;\n\n&lt;p&gt;Personally, I&amp;#39;m a lazy fak, so whenever I can I&amp;#39;ll prefer an open source, widely used solution for such things. I get that sometimes building your own is a better option like when you have a special use case or want to optimize an important part, but for those type of common tasks I don&amp;#39;t see the point.&lt;/p&gt;\n\n&lt;p&gt;I consider my colleagues to be good at what they do, but couldn&amp;#39;t get a real answer so I&amp;#39;m asking here, hoping for the more experienced of us to share their views.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this? Where do you draw the line?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16698zq", "is_robot_indexable": true, "report_reasons": null, "author": "Darmerr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16698zq/when_should_i_implement_vs_of_the_shelf_open/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16698zq/when_should_i_implement_vs_of_the_shelf_open/", "subreddit_subscribers": 1024631, "created_utc": 1693483341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently doing my master thesis on a topic regarding interpret ability of data science models and their applications. Interpretability currently holds no strict definition in the field (Doshi &amp; Kim, 2017) and it may be synonymous with explainability (to a human/end-user).\n\n I am curious as to how would you guys define or how do you think of interpretability as. Is there a way you use to measure it ? \n\nPersonally I really like the parallel used by Efron, where it can be thought of as a communication; an exchange of information that depends on the parties involved. For example a doctor may find the name of a predicted disease by a model a sufficient amount of information, but a patient may require a lengthier explanation. \n\nThank you !", "author_fullname": "t2_21mlx7b9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you define interpretability of a model ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166gubu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693501776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently doing my master thesis on a topic regarding interpret ability of data science models and their applications. Interpretability currently holds no strict definition in the field (Doshi &amp;amp; Kim, 2017) and it may be synonymous with explainability (to a human/end-user).&lt;/p&gt;\n\n&lt;p&gt;I am curious as to how would you guys define or how do you think of interpretability as. Is there a way you use to measure it ? &lt;/p&gt;\n\n&lt;p&gt;Personally I really like the parallel used by Efron, where it can be thought of as a communication; an exchange of information that depends on the parties involved. For example a doctor may find the name of a predicted disease by a model a sufficient amount of information, but a patient may require a lengthier explanation. &lt;/p&gt;\n\n&lt;p&gt;Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166gubu", "is_robot_indexable": true, "report_reasons": null, "author": "johntsaou", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166gubu/how_would_you_define_interpretability_of_a_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166gubu/how_would_you_define_interpretability_of_a_model/", "subreddit_subscribers": 1024631, "created_utc": 1693501776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!\n\nI am a recent graduate with a master's degree in biomedical engineer with a few university subjects related to AI, databases and a master's thesis related to data science.\n\n\nI want to find a junior data scientist position and I have recently done some interviews. I feel I fail in these interviews not because of the data science techniques but because of questions related to programming and my knowledge of some tools. For example 1) what is the difference between a Jupyter notebook and a Python script, 2) what do you do to optimise your code, and 3) do you know what Docker is?\n\u00a0\n\nThis is probably trivial for a lot of you, but from my past experiences (internships, university subjects), I've never needed to think about these questions.\n\u00a0\n\nSo, I wanted to know, for someone without a background in CS, how can I learn about these things more related to programming besides applying libraries and exploring data? And what do you think I should learn to fill this gap?\n\u00a0\n\nThank you all!", "author_fullname": "t2_jsgqs13t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Advice) Data Science Interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1666n3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693475346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I am a recent graduate with a master&amp;#39;s degree in biomedical engineer with a few university subjects related to AI, databases and a master&amp;#39;s thesis related to data science.&lt;/p&gt;\n\n&lt;p&gt;I want to find a junior data scientist position and I have recently done some interviews. I feel I fail in these interviews not because of the data science techniques but because of questions related to programming and my knowledge of some tools. For example 1) what is the difference between a Jupyter notebook and a Python script, 2) what do you do to optimise your code, and 3) do you know what Docker is?\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;This is probably trivial for a lot of you, but from my past experiences (internships, university subjects), I&amp;#39;ve never needed to think about these questions.\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;So, I wanted to know, for someone without a background in CS, how can I learn about these things more related to programming besides applying libraries and exploring data? And what do you think I should learn to fill this gap?\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;Thank you all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1666n3b", "is_robot_indexable": true, "report_reasons": null, "author": "Throwawaylafora", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1666n3b/advice_data_science_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1666n3b/advice_data_science_interviews/", "subreddit_subscribers": 1024631, "created_utc": 1693475346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Want to learn how to create a React Native to take images and read the text from them using OCR? Check out [this article on using OCR with React Native and Flask](https://medium.com/python-in-plain-english/how-to-use-innovative-ocr-to-effortlessly-empower-your-react-native-app-ea3364ae9ab5). \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_9ssuhjvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn how to integrate OCR into your React Native app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1665kom", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693471623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to learn how to create a React Native to take images and read the text from them using OCR? Check out &lt;a href=\"https://medium.com/python-in-plain-english/how-to-use-innovative-ocr-to-effortlessly-empower-your-react-native-app-ea3364ae9ab5\"&gt;this article on using OCR with React Native and Flask&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?auto=webp&amp;s=5cf1e85f007076324f13a1a290f71a97ada23e5c", "width": 1022, "height": 794}, "resolutions": [{"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1844e5b8d665444e1b159144853a04bf26adb823", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9936e3049cb6b33a5f570c463755b8e64b4a5298", "width": 216, "height": 167}, {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e98e21dff282fe3e9244a66a6de13457df60095e", "width": 320, "height": 248}, {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=46dc1c05a100b2108367758b1cdfb3c017afb9cd", "width": 640, "height": 497}, {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=10a09d082e9e3ad284b7cc929a51de6472ed9cb8", "width": 960, "height": 745}], "variants": {}, "id": "N6pjWI3s3BucVc77NoV7vxeumKJowbwGj2OIlZ76USc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1665kom", "is_robot_indexable": true, "report_reasons": null, "author": "Artistic_Highlight_1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1665kom/learn_how_to_integrate_ocr_into_your_react_native/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1665kom/learn_how_to_integrate_ocr_into_your_react_native/", "subreddit_subscribers": 1024631, "created_utc": 1693471623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to identify the minimum set of behaviors (features) that can help distinguish different types of data scientists in a mutually exclusive way (this is an intellectual exercise, not an actual model). \nHere\u2019s my proposal of the minimum list of questions necessary to do this:\n\n1. Do you build models or analyses to help people make decisions or to help systems make decisions? (Neither, People, Systems, Both)\n2. Do you work with experiments, A/B tests or RCTs? (No, Yes - Analyze, Yes - Design and analyze, Yes - Design, Analyse and decide)\n3. When you create a process to transform data, is it one time or is it a scalable process that will run daily? (Only one time, mostly one time, evenly split, mostly scalable)\n4. How important is the efficiency of your data processing for your role? (As long as it runs I\u2019m good, I need efficiency because I need things fast, Efficiency is essential as I\u2019m part of a cost center).\n\nWhat am I missing?", "author_fullname": "t2_18sinzf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would a decision tree to classify data scientists look like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_166y57s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693545555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to identify the minimum set of behaviors (features) that can help distinguish different types of data scientists in a mutually exclusive way (this is an intellectual exercise, not an actual model). \nHere\u2019s my proposal of the minimum list of questions necessary to do this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do you build models or analyses to help people make decisions or to help systems make decisions? (Neither, People, Systems, Both)&lt;/li&gt;\n&lt;li&gt;Do you work with experiments, A/B tests or RCTs? (No, Yes - Analyze, Yes - Design and analyze, Yes - Design, Analyse and decide)&lt;/li&gt;\n&lt;li&gt;When you create a process to transform data, is it one time or is it a scalable process that will run daily? (Only one time, mostly one time, evenly split, mostly scalable)&lt;/li&gt;\n&lt;li&gt;How important is the efficiency of your data processing for your role? (As long as it runs I\u2019m good, I need efficiency because I need things fast, Efficiency is essential as I\u2019m part of a cost center).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166y57s", "is_robot_indexable": true, "report_reasons": null, "author": "poitrenaud", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166y57s/how_would_a_decision_tree_to_classify_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166y57s/how_would_a_decision_tree_to_classify_data/", "subreddit_subscribers": 1024631, "created_utc": 1693545555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone!   \nI am searching for some exciting football-related project ideas to practice my data skills. I'm open to any suggestions - whether it's data sources, intriguing questions to answer, or example projects. \n\nI have strong knowledge of the tools and concepts involved/ used in the data science workflow, except predictive analytics( DL in particular). Any ideas you have would be greatly appreciated.", "author_fullname": "t2_eo907yrs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cool football/soccer analytics project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166nikx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693516968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;br/&gt;\nI am searching for some exciting football-related project ideas to practice my data skills. I&amp;#39;m open to any suggestions - whether it&amp;#39;s data sources, intriguing questions to answer, or example projects. &lt;/p&gt;\n\n&lt;p&gt;I have strong knowledge of the tools and concepts involved/ used in the data science workflow, except predictive analytics( DL in particular). Any ideas you have would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166nikx", "is_robot_indexable": true, "report_reasons": null, "author": "avg_ali", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166nikx/cool_footballsoccer_analytics_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166nikx/cool_footballsoccer_analytics_project/", "subreddit_subscribers": 1024631, "created_utc": 1693516968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello fellows  \nI have a seemingly simple issue but I was wanted to consult with you on how you would solve that.\n\nI have an incremental learning model that I try to predict user actions with. Lets say I have 5 possible actions encoded from 0 to 4 as classes. The model is in batches of 5, meaning I get a batch of 5 records each time. \n\nThe first batch I get has unique classes of 0,1,2 - but since it is the first batch I have nothing to predict so it is moved to train data immediately. The 2nd batch I have is of classes 0,1,3 , I try to predict it with the trained data (the batch from before). My problem is while hyperparameters tuning I use ROC AUC (decision by my coworker) which causes me issues as the labels are not in order (2 is missing in my example)\n\n( [https://stackoverflow.com/questions/63140095/roc-auc-score-mismatch-between-y-test-and-y-score](https://stackoverflow.com/questions/63140095/roc-auc-score-mismatch-between-y-test-and-y-score) )  \n\n\nNow in real life I obviously can't guarentee that I will get batches of records with actions that match the classes order. I can't balance the classes since I have no place to sample the new daAnd I can't change encodings to match the new order since it can cause data leakage (and in general a wrong practice). The only solution I came up with is to replace ROC AUC with a different metric (Balanced Accuracy - since my data is unbalanced) but my coworker does not want to change the metric to a threshold dependent metric.\n\nMy question is both specific and general - how do you handle errors and issues caused by misrepresentation of classes in train/test data? Assuming you are not batch training and/or can not manipulate the train and test data to prevent it?\n\nHighly appreciate your help\n\n \n\n&amp;#x200B;", "author_fullname": "t2_3hqmko1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle issues caused by missing classes representation in dataset when running a model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166e7kl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693495632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellows&lt;br/&gt;\nI have a seemingly simple issue but I was wanted to consult with you on how you would solve that.&lt;/p&gt;\n\n&lt;p&gt;I have an incremental learning model that I try to predict user actions with. Lets say I have 5 possible actions encoded from 0 to 4 as classes. The model is in batches of 5, meaning I get a batch of 5 records each time. &lt;/p&gt;\n\n&lt;p&gt;The first batch I get has unique classes of 0,1,2 - but since it is the first batch I have nothing to predict so it is moved to train data immediately. The 2nd batch I have is of classes 0,1,3 , I try to predict it with the trained data (the batch from before). My problem is while hyperparameters tuning I use ROC AUC (decision by my coworker) which causes me issues as the labels are not in order (2 is missing in my example)&lt;/p&gt;\n\n&lt;p&gt;( &lt;a href=\"https://stackoverflow.com/questions/63140095/roc-auc-score-mismatch-between-y-test-and-y-score\"&gt;https://stackoverflow.com/questions/63140095/roc-auc-score-mismatch-between-y-test-and-y-score&lt;/a&gt; )  &lt;/p&gt;\n\n&lt;p&gt;Now in real life I obviously can&amp;#39;t guarentee that I will get batches of records with actions that match the classes order. I can&amp;#39;t balance the classes since I have no place to sample the new daAnd I can&amp;#39;t change encodings to match the new order since it can cause data leakage (and in general a wrong practice). The only solution I came up with is to replace ROC AUC with a different metric (Balanced Accuracy - since my data is unbalanced) but my coworker does not want to change the metric to a threshold dependent metric.&lt;/p&gt;\n\n&lt;p&gt;My question is both specific and general - how do you handle errors and issues caused by misrepresentation of classes in train/test data? Assuming you are not batch training and/or can not manipulate the train and test data to prevent it?&lt;/p&gt;\n\n&lt;p&gt;Highly appreciate your help&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166e7kl", "is_robot_indexable": true, "report_reasons": null, "author": "nuriel8833", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166e7kl/how_to_handle_issues_caused_by_missing_classes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166e7kl/how_to_handle_issues_caused_by_missing_classes/", "subreddit_subscribers": 1024631, "created_utc": 1693495632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Thinking through a simple A/B test with 2 variants:\n\n* Control\n   * Step 1 -&gt; Step 2 -&gt; Step 3 -&gt; Conversion\n* Test\n   * Step 1 -&gt; Step 2 -&gt; Step 3 -&gt; Step 4 -&gt; Conversion\n\nAssume users are randomly assigned at Step 3 with a coin flip and 50/50 split.\n\nAlso assume that conversion can happen at any time and that, while users can continue browsing through N additional steps, only Step 1-3 are mandatory.\n\nMy hypothesis is that adding Step 4 will reduce conversions. \n\nWhat would be the right metric to measure here? I would say it should be % converting from Step 3, but wondering if I should also consider % converting from Step 4, since those users would be the ones actually impacted by the change.", "author_fullname": "t2_7zmoi25a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Picking the right metric for an A/B test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166dkkf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693494154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thinking through a simple A/B test with 2 variants:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Control\n\n&lt;ul&gt;\n&lt;li&gt;Step 1 -&amp;gt; Step 2 -&amp;gt; Step 3 -&amp;gt; Conversion&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Test\n\n&lt;ul&gt;\n&lt;li&gt;Step 1 -&amp;gt; Step 2 -&amp;gt; Step 3 -&amp;gt; Step 4 -&amp;gt; Conversion&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Assume users are randomly assigned at Step 3 with a coin flip and 50/50 split.&lt;/p&gt;\n\n&lt;p&gt;Also assume that conversion can happen at any time and that, while users can continue browsing through N additional steps, only Step 1-3 are mandatory.&lt;/p&gt;\n\n&lt;p&gt;My hypothesis is that adding Step 4 will reduce conversions. &lt;/p&gt;\n\n&lt;p&gt;What would be the right metric to measure here? I would say it should be % converting from Step 3, but wondering if I should also consider % converting from Step 4, since those users would be the ones actually impacted by the change.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166dkkf", "is_robot_indexable": true, "report_reasons": null, "author": "ergodym", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166dkkf/picking_the_right_metric_for_an_ab_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166dkkf/picking_the_right_metric_for_an_ab_test/", "subreddit_subscribers": 1024631, "created_utc": 1693494154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI have the opportunity to take one of [these](https://ivmf.syracuse.edu/programs/career-training/learning-pathways/) industry-recognized certification exams for free, along with the course that goes with it. I know certifications don't mean much but figured it's free learning and that never hurts. Which would you choose? I'm torn between..\n\n\\- CompTIA A+\n\n\\- CompTIA Security+\n\n\\- PCAP: Programming Essentials in Python\n\nI'm leaning more towards the PCAP, since Python is used in this field and I only really have experience with R. Cyber security interests me but I feel the Python one would be more valuable in this field. What do you all think? Has anyone taken any of these? Thanks!", "author_fullname": "t2_2r732rgx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have the opportunity to take one of these certification exams for free. Which would you choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166c2e1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693490651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have the opportunity to take one of &lt;a href=\"https://ivmf.syracuse.edu/programs/career-training/learning-pathways/\"&gt;these&lt;/a&gt; industry-recognized certification exams for free, along with the course that goes with it. I know certifications don&amp;#39;t mean much but figured it&amp;#39;s free learning and that never hurts. Which would you choose? I&amp;#39;m torn between..&lt;/p&gt;\n\n&lt;p&gt;- CompTIA A+&lt;/p&gt;\n\n&lt;p&gt;- CompTIA Security+&lt;/p&gt;\n\n&lt;p&gt;- PCAP: Programming Essentials in Python&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m leaning more towards the PCAP, since Python is used in this field and I only really have experience with R. Cyber security interests me but I feel the Python one would be more valuable in this field. What do you all think? Has anyone taken any of these? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?auto=webp&amp;s=065b5f1a21125c981c4752d4730ce2c5f994c5d9", "width": 1000, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7edd285dd2e253638ea7ee89b82e4e7bb8ba4951", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69e396c3ddf0c29ae788ed905ea046c5b2324b0b", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb587ae6e45adb10f2266fc495d2a2d2fb6fa093", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd0859be93b8e47e2bab6793d04f11a2dcd7a07a", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=582531477503ebe06deb1768fd9d5fbb12e4da30", "width": 960, "height": 960}], "variants": {}, "id": "jm5fJs9Ll5rM5S1CS8qzs0tySn6P7yhaVWuQFkRoZ9Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166c2e1", "is_robot_indexable": true, "report_reasons": null, "author": "4077hawkeye-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166c2e1/i_have_the_opportunity_to_take_one_of_these/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166c2e1/i_have_the_opportunity_to_take_one_of_these/", "subreddit_subscribers": 1024631, "created_utc": 1693490651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I need to make a tree-graph. The distance between 2 nodes should be proportional to the weight of their adjacent edge. \n\nThe library should display certain information on hover and do something on click too. \n\nPlease help.", "author_fullname": "t2_9peiwedk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advanced graph visualization libraries in python that are supported by streamlit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166as6f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693487468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to make a tree-graph. The distance between 2 nodes should be proportional to the weight of their adjacent edge. &lt;/p&gt;\n\n&lt;p&gt;The library should display certain information on hover and do something on click too. &lt;/p&gt;\n\n&lt;p&gt;Please help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166as6f", "is_robot_indexable": true, "report_reasons": null, "author": "LucaMarko", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166as6f/advanced_graph_visualization_libraries_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166as6f/advanced_graph_visualization_libraries_in_python/", "subreddit_subscribers": 1024631, "created_utc": 1693487468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Time series sales forecasting.\n\nI have this dataset from 2015 to 2019 with rows of around 10k.\n\nMy goal is to predict sales for the future period. \n\n\nMy question is do I need to group the data by date(a single date has many rows) \n\nOr do I need to run the machine learning models as a regression?\n\n\n\nAlso, the r2 values are too low and what can be done to improve this?(i have extracted variables like years, day, week, and lagged variables too)", "author_fullname": "t2_iqg2cfga3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series sales forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16688n0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693480385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Time series sales forecasting.&lt;/p&gt;\n\n&lt;p&gt;I have this dataset from 2015 to 2019 with rows of around 10k.&lt;/p&gt;\n\n&lt;p&gt;My goal is to predict sales for the future period. &lt;/p&gt;\n\n&lt;p&gt;My question is do I need to group the data by date(a single date has many rows) &lt;/p&gt;\n\n&lt;p&gt;Or do I need to run the machine learning models as a regression?&lt;/p&gt;\n\n&lt;p&gt;Also, the r2 values are too low and what can be done to improve this?(i have extracted variables like years, day, week, and lagged variables too)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16688n0", "is_robot_indexable": true, "report_reasons": null, "author": "Superb-Ad9832", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16688n0/time_series_sales_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16688n0/time_series_sales_forecasting/", "subreddit_subscribers": 1024631, "created_utc": 1693480385.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in the commodities sector as a data scientist and since one year ago we have a algo trader we are using in one of the markets we are trading in. Now we are looking into feeding this algo trader with better predictions to increase profitability. Since the beginning of this year the company hired 3 data engineers to build an Azure data lake, mainly for enabling the rest of the company to increase the internal use of Power BI. But they have also been tasked to fetch high resolution data to the lake for us since our current on-preem database can't handle that type of data. Using this data will absolutely increase profitability so it definitely valid to get access to it.\n\n&amp;#x200B;\n\nSince they started working on this they have imported some relevant data for the data science team to the Azure Data Lake. At first we looked into running and training models in the cloud but it was deemed to expensive since we have to have a 100% up time of the spark cluster if we want the prediction to be calculated precisely when we want it to be calculated. So this led us to our current trouble, fetching data from Azure data lake to on-preem. Running the prediction models on-preem is no problem, because we already do that but fetching data from Azure data lake to on-preem is such a headache! Anybody got some tips and tricks on how to do this best practise? Especially if we can skip to rely on some external tool like excel (proposed by one of the DA) because we want the prediction models to be their own applications.\n\n&amp;#x200B;\n\nI realise this might be more of a data engineering question but nevertheless... ", "author_fullname": "t2_iq9gwn38g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solutions for fetching data from cloud to on-preem in Azure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166657o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693473649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in the commodities sector as a data scientist and since one year ago we have a algo trader we are using in one of the markets we are trading in. Now we are looking into feeding this algo trader with better predictions to increase profitability. Since the beginning of this year the company hired 3 data engineers to build an Azure data lake, mainly for enabling the rest of the company to increase the internal use of Power BI. But they have also been tasked to fetch high resolution data to the lake for us since our current on-preem database can&amp;#39;t handle that type of data. Using this data will absolutely increase profitability so it definitely valid to get access to it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Since they started working on this they have imported some relevant data for the data science team to the Azure Data Lake. At first we looked into running and training models in the cloud but it was deemed to expensive since we have to have a 100% up time of the spark cluster if we want the prediction to be calculated precisely when we want it to be calculated. So this led us to our current trouble, fetching data from Azure data lake to on-preem. Running the prediction models on-preem is no problem, because we already do that but fetching data from Azure data lake to on-preem is such a headache! Anybody got some tips and tricks on how to do this best practise? Especially if we can skip to rely on some external tool like excel (proposed by one of the DA) because we want the prediction models to be their own applications.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I realise this might be more of a data engineering question but nevertheless... &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166657o", "is_robot_indexable": true, "report_reasons": null, "author": "commodity_ds", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166657o/solutions_for_fetching_data_from_cloud_to_onpreem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166657o/solutions_for_fetching_data_from_cloud_to_onpreem/", "subreddit_subscribers": 1024631, "created_utc": 1693473649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Question:**  \nIs there a method to gauge the forecastability of an e-commerce demand dataset? As I invest more time in refining the forecast, I notice diminishing returns. I'd like to determine the potential maximum accuracy I can achieve to decide when it's best to stop.\n\n**Background:**  \nI'm working on a research paper where I apply various novel ML models to warehouse operations in e-commerce. The primary aim is to enhance demand forecasts, which in turn aids in optimizing weekly workforce planning.\n\n**Challenge:**  \nMy research partner and I grapple with the age-old Return On Investment question: Is it justifiable to allocate one or two data scientists to further refine the demand forecast? This would potentially involve altering workflows, ensuring models remain current, and so on, all for a marginal improvement in forecast accuracy. I've used a stochastic multi-stage program to gauge the savings from a refined forecast. It would be immensely beneficial to have a method to estimate the maximum possible improvement, allowing for a more informed evaluation of the project upfront.\n\nAny insights, opinions, or resources would be greatly appreciated. If there are ambiguities, please don't hesitate to ask for clarifications. Thank you!", "author_fullname": "t2_mjxj3wws", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Estimating the Forecastability of an E-commerce Demand Dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1664vq0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693469192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;br/&gt;\nIs there a method to gauge the forecastability of an e-commerce demand dataset? As I invest more time in refining the forecast, I notice diminishing returns. I&amp;#39;d like to determine the potential maximum accuracy I can achieve to decide when it&amp;#39;s best to stop.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;br/&gt;\nI&amp;#39;m working on a research paper where I apply various novel ML models to warehouse operations in e-commerce. The primary aim is to enhance demand forecasts, which in turn aids in optimizing weekly workforce planning.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Challenge:&lt;/strong&gt;&lt;br/&gt;\nMy research partner and I grapple with the age-old Return On Investment question: Is it justifiable to allocate one or two data scientists to further refine the demand forecast? This would potentially involve altering workflows, ensuring models remain current, and so on, all for a marginal improvement in forecast accuracy. I&amp;#39;ve used a stochastic multi-stage program to gauge the savings from a refined forecast. It would be immensely beneficial to have a method to estimate the maximum possible improvement, allowing for a more informed evaluation of the project upfront.&lt;/p&gt;\n\n&lt;p&gt;Any insights, opinions, or resources would be greatly appreciated. If there are ambiguities, please don&amp;#39;t hesitate to ask for clarifications. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1664vq0", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Law-2556", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1664vq0/estimating_the_forecastability_of_an_ecommerce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1664vq0/estimating_the_forecastability_of_an_ecommerce/", "subreddit_subscribers": 1024631, "created_utc": 1693469192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Since around a month I am trying to find an internship somewhere around broad spectrum of Data Science. I have been applying to all kind of types of internships, although I have never even got a single interview. I have bachelors in Business Administration and currently doing Masters in Data Science in Pace University in nyc (i am 23 on f1 visa) My focus was around banking/financial institutions but also I was looking at some other positions in different industries. I would really appreciate any help or guidance. Main two projects on my resume is an windows desktop app to analyze your own portfolio with live data, live notifications about price changes if chosen stocks and AI chatbot that allows your to control, check and alter your portfolio as well as gives \u201ctips\u201d based on some basic analysis and machine learning algorithms. 2nd project is a DCF valuation model in Python. Also I don\u2019t really have any prior experience. Would appreciate any tips or maybe it\u2019s too late for me ?", "author_fullname": "t2_6kow62ly", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Internships", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166nteq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693517667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since around a month I am trying to find an internship somewhere around broad spectrum of Data Science. I have been applying to all kind of types of internships, although I have never even got a single interview. I have bachelors in Business Administration and currently doing Masters in Data Science in Pace University in nyc (i am 23 on f1 visa) My focus was around banking/financial institutions but also I was looking at some other positions in different industries. I would really appreciate any help or guidance. Main two projects on my resume is an windows desktop app to analyze your own portfolio with live data, live notifications about price changes if chosen stocks and AI chatbot that allows your to control, check and alter your portfolio as well as gives \u201ctips\u201d based on some basic analysis and machine learning algorithms. 2nd project is a DCF valuation model in Python. Also I don\u2019t really have any prior experience. Would appreciate any tips or maybe it\u2019s too late for me ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166nteq", "is_robot_indexable": true, "report_reasons": null, "author": "Serdyna13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166nteq/data_science_internships/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166nteq/data_science_internships/", "subreddit_subscribers": 1024631, "created_utc": 1693517667.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}