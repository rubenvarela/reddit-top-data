{"kind": "Listing", "data": {"after": "t3_16v2eaf", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've grown to hate Alteryx.  It might be fine as a self service / desktop tool but anything enterprise/at scale is a nightmare.  It is a pain to deploy.  It is a pain to orchestrate.  The macro system is a nightmare to use.  Most of the time it is slow as well.  Plus it is extremely expensive to top it all off.", "author_fullname": "t2_9jd4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools that seemed cool at first but you've grown to loathe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16uu03a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 161, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 161, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695940468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve grown to hate Alteryx.  It might be fine as a self service / desktop tool but anything enterprise/at scale is a nightmare.  It is a pain to deploy.  It is a pain to orchestrate.  The macro system is a nightmare to use.  Most of the time it is slow as well.  Plus it is extremely expensive to top it all off.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16uu03a", "is_robot_indexable": true, "report_reasons": null, "author": "endless_sea_of_stars", "discussion_type": null, "num_comments": 197, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16uu03a/tools_that_seemed_cool_at_first_but_youve_grown/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16uu03a/tools_that_seemed_cool_at_first_but_youve_grown/", "subreddit_subscribers": 131086, "created_utc": 1695940468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started work at a company that just got databricks and did not understand how it worked.\n\nSo, they set everything to run on their private clusters with all purpose compute(3x's the price) with auto terminate turned off because they were ok with things running over the weekend.  Finance made them stop using databricks after two months lol.\n\nIm sure people have fucked up worse.  What is the worst youve experienced?", "author_fullname": "t2_vnvmwnbl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worst Data Engineering Mistake youve seen?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vhp70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696008387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started work at a company that just got databricks and did not understand how it worked.&lt;/p&gt;\n\n&lt;p&gt;So, they set everything to run on their private clusters with all purpose compute(3x&amp;#39;s the price) with auto terminate turned off because they were ok with things running over the weekend.  Finance made them stop using databricks after two months lol.&lt;/p&gt;\n\n&lt;p&gt;Im sure people have fucked up worse.  What is the worst youve experienced?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16vhp70", "is_robot_indexable": true, "report_reasons": null, "author": "Inevitable-Quality15", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vhp70/worst_data_engineering_mistake_youve_seen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16vhp70/worst_data_engineering_mistake_youve_seen/", "subreddit_subscribers": 131086, "created_utc": 1696008387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Data Engineering Community!\n\nI'm a junior project manager part of a team that operates a data engineering pipeline on AWS, leveraging services like Lambda, S3, Step Functions, and Glue. We serve as an analytical platform for our organization and have a reasonably optimized flow. We are a small, american based company and so our every cent is examined. \n\nRecently, Databricks has piqued our interest, and we are considering running a \"Proof-of-Value\" (PoV) experiment to evaluate the feasibility and benefits of a potential migration. I\u2019m reaching out to gather insights and learn from those who have walked this path before.\n\n#### What I'm Looking For:\n\n1. **Reasons for the Switch**: Why did you or would you consider transitioning from AWS services to Databricks? Is it for performance gains, ease of use, feature set, or something else?\n2. **Key Metrics for PoV**: What key metrics did you monitor before and after the PoV to evaluate the success or failure of the transition? How did you quantify value?\n3. **Challenges Faced**: What obstacles did you encounter during the transition, particularly during the PoV phase? How did you overcome them?\n4. **Cost Considerations**: Was the transition cost-effective based on your PoV experiment? Are there any hidden costs or pricing traps we should be aware of?\n5. **Integration Points**: How easily or challengingly did Databricks integrate with your existing systems? Our data sources currently include SAP, SAP BW, and Salesforce.\n6. **Metrics for Success Post-Switch**: Aside from the PoV metrics, are there long-term KPIs you have used to measure the ongoing success or shortcomings of the transition?\n7. **Any Regrets?**: Post-transition, are there any features or capabilities from the AWS stack that you find missing or less effective in Databricks?\n8. **Advice for the PoV**: Any tips or recommendations specifically for conducting a successful PoV? Things to look out for or best practices to follow?", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving from a reasonably optimised AWS flow to databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vbs8s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695994364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Data Engineering Community!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a junior project manager part of a team that operates a data engineering pipeline on AWS, leveraging services like Lambda, S3, Step Functions, and Glue. We serve as an analytical platform for our organization and have a reasonably optimized flow. We are a small, american based company and so our every cent is examined. &lt;/p&gt;\n\n&lt;p&gt;Recently, Databricks has piqued our interest, and we are considering running a &amp;quot;Proof-of-Value&amp;quot; (PoV) experiment to evaluate the feasibility and benefits of a potential migration. I\u2019m reaching out to gather insights and learn from those who have walked this path before.&lt;/p&gt;\n\n&lt;h4&gt;What I&amp;#39;m Looking For:&lt;/h4&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Reasons for the Switch&lt;/strong&gt;: Why did you or would you consider transitioning from AWS services to Databricks? Is it for performance gains, ease of use, feature set, or something else?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Key Metrics for PoV&lt;/strong&gt;: What key metrics did you monitor before and after the PoV to evaluate the success or failure of the transition? How did you quantify value?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Challenges Faced&lt;/strong&gt;: What obstacles did you encounter during the transition, particularly during the PoV phase? How did you overcome them?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Cost Considerations&lt;/strong&gt;: Was the transition cost-effective based on your PoV experiment? Are there any hidden costs or pricing traps we should be aware of?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Integration Points&lt;/strong&gt;: How easily or challengingly did Databricks integrate with your existing systems? Our data sources currently include SAP, SAP BW, and Salesforce.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Metrics for Success Post-Switch&lt;/strong&gt;: Aside from the PoV metrics, are there long-term KPIs you have used to measure the ongoing success or shortcomings of the transition?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Any Regrets?&lt;/strong&gt;: Post-transition, are there any features or capabilities from the AWS stack that you find missing or less effective in Databricks?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Advice for the PoV&lt;/strong&gt;: Any tips or recommendations specifically for conducting a successful PoV? Things to look out for or best practices to follow?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16vbs8s", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vbs8s/moving_from_a_reasonably_optimised_aws_flow_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16vbs8s/moving_from_a_reasonably_optimised_aws_flow_to/", "subreddit_subscribers": 131086, "created_utc": 1695994364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a team of 12 analysts and DEs and we keep our documentation within the team and share bits to other colleagues only as required, usually by email. \n\nI\u2019m trying to think of any negatives of making our knowledge base available to the whole organisation (local government) but other than the obvious like ensuring credentials are not stored, it seems like a good idea. As a government there\u2019s even an argument to making it publicly accessible. \n\nHow well locked down are your docs and have you had any negative experiences if it\u2019s widely available? Any stupid requests etc?", "author_fullname": "t2_2vncts9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How open is your documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16v71cq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695980163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a team of 12 analysts and DEs and we keep our documentation within the team and share bits to other colleagues only as required, usually by email. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to think of any negatives of making our knowledge base available to the whole organisation (local government) but other than the obvious like ensuring credentials are not stored, it seems like a good idea. As a government there\u2019s even an argument to making it publicly accessible. &lt;/p&gt;\n\n&lt;p&gt;How well locked down are your docs and have you had any negative experiences if it\u2019s widely available? Any stupid requests etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16v71cq", "is_robot_indexable": true, "report_reasons": null, "author": "nbjersey", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16v71cq/how_open_is_your_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16v71cq/how_open_is_your_documentation/", "subreddit_subscribers": 131086, "created_utc": 1695980163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi r/dataengineering, just wanted to share these resources with y'all.\n\n* updated wiki: [https://www.reddit.com/r/EngineeringResumes/comments/m2cc65/new\\_and\\_improved\\_wiki/](https://www.reddit.com/r/EngineeringResumes/comments/m2cc65/new_and_improved_wiki/)\n* resume templates: [https://www.reddit.com/r/EngineeringResumes/comments/169ddk8/rengineeringresumes\\_resume\\_templates](https://www.reddit.com/r/EngineeringResumes/comments/169ddk8/rengineeringresumes_resume_templates)", "author_fullname": "t2_1ftztr81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "r/EngineeringResumes Updated Wiki + Resume Templates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16uzvhy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695955551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;, just wanted to share these resources with y&amp;#39;all.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;updated wiki: &lt;a href=\"https://www.reddit.com/r/EngineeringResumes/comments/m2cc65/new_and_improved_wiki/\"&gt;https://www.reddit.com/r/EngineeringResumes/comments/m2cc65/new_and_improved_wiki/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;resume templates: &lt;a href=\"https://www.reddit.com/r/EngineeringResumes/comments/169ddk8/rengineeringresumes_resume_templates\"&gt;https://www.reddit.com/r/EngineeringResumes/comments/169ddk8/rengineeringresumes_resume_templates&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16uzvhy", "is_robot_indexable": true, "report_reasons": null, "author": "rapsforlife647", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16uzvhy/rengineeringresumes_updated_wiki_resume_templates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16uzvhy/rengineeringresumes_updated_wiki_resume_templates/", "subreddit_subscribers": 131086, "created_utc": 1695955551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am interviewing for data engineering roles and recently, at Nvidia interview, a system design question was asked as such - how would you design data pipeline for a charbot app? \n\n\nI wonder if there are any courses/books/blogs/videos or other such resources which can help witj such data engineering related system design questions.\n\nPlease share any if you have in mind. Thanks in advance and good luck if you're in the market for job", "author_fullname": "t2_7xefhox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "System Design Resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16v2f9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695963365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interviewing for data engineering roles and recently, at Nvidia interview, a system design question was asked as such - how would you design data pipeline for a charbot app? &lt;/p&gt;\n\n&lt;p&gt;I wonder if there are any courses/books/blogs/videos or other such resources which can help witj such data engineering related system design questions.&lt;/p&gt;\n\n&lt;p&gt;Please share any if you have in mind. Thanks in advance and good luck if you&amp;#39;re in the market for job&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16v2f9f", "is_robot_indexable": true, "report_reasons": null, "author": "warrior008", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16v2f9f/system_design_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16v2f9f/system_design_resources/", "subreddit_subscribers": 131086, "created_utc": 1695963365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a49okn69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Look what you made me do...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16vetkl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.59, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hLtrhSY5LNjecJODvYVzALpwTRIPz2sRJywNnSKEvGY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696001615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/eu46lm68r7rb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/eu46lm68r7rb1.jpg?auto=webp&amp;s=1f2837a88f2c7b0973c40f15d6abeeaba9d0fbc7", "width": 666, "height": 500}, "resolutions": [{"url": "https://preview.redd.it/eu46lm68r7rb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=172d2b9f0e16570e8d02dda54e542fac6fa6d22b", "width": 108, "height": 81}, {"url": "https://preview.redd.it/eu46lm68r7rb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1bc8b2ba3076e34c11050424f60342d27b356ad1", "width": 216, "height": 162}, {"url": "https://preview.redd.it/eu46lm68r7rb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9afe95db9627d38225c706f61adc2ed8f91c1c0f", "width": 320, "height": 240}, {"url": "https://preview.redd.it/eu46lm68r7rb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb555d8f61c7bba100c5239cc3ea7bdda1bee1be", "width": 640, "height": 480}], "variants": {}, "id": "GCkNz3Fb9q595iL_2xY86B_415fZmFORI9SfE2fUYyU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "16vetkl", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Substance2185", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vetkl/look_what_you_made_me_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/eu46lm68r7rb1.jpg", "subreddit_subscribers": 131086, "created_utc": 1696001615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nThis is my 1st post so I apologize for my grammer, inexperience and just general ignorance.\n\nI'm currently a data engineer consultant building a datalake from scratch on AWS for a client and looking for any guidence/advice from the skillfull/knowledge people in this sub.\n\nBasically the client wants a low cost datalake solution with low maintenance for daily feeds and a streaming feed. Apache superset will connect to the datalake and display a dashboard on their website application.\n\nThings to keep in mind:\n- Low cost\n- Low Maintenance\n- Low Volume of data\n- +- Daily feeds\n- A few Streaming feeds\n- data is in CSV/json\n\nWhat I built:\nAWS Step functions - Orchestration\nAWS Event Bridge - Scheduling\nAWS Lambda - fetch data from sources via rest API into S3 Landing bucket and another for moving files to different bucket for transforms and cleaning\nAWS S3 storage - 4 buckets (landing ,raw,processed, scripts)\nAWS Glue - Pyspark for transformations and cleaning ( built library for easy script writing for when adding new data/sources) data is compressed in gzip and parquet format\nAWS Glue Spark Streaming job to run 24/7 for the data consumed from Kafka\nAWS Lake formation - Security/ Governance\nApache Iceberg - Table format(with parquet) with glue catalog and Athena as the query engine for processed data and config tables to keep track of pipelines, data is partitioned by week.\n\nThings I need guidance with:\n- I'm not sure entirely about the maintenance that needs to be done with iceberg\n- Don't know much about the glue spark streaming job,maybe need a different ETL tool? Like Nifi?\n- Is my solution correct for this case,maybe different tech/tools?\n- Maybe need a DQ tool?\n- I need a way to handle updates made on the the front-end that uodates the data in the datalake and Apache superset dashboard on the front-end is updated accordingly \n- Am I missing anything? Especially things with best practice and standards.\n\nThis is just high level and I apologize if I'm not giving enough info. Please ask and I'll try to clarify.\n\nThanks in advance, I would appreciate any advice that can be given", "author_fullname": "t2_a6nvs4dv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for building datalake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16v9iwi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695988340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;This is my 1st post so I apologize for my grammer, inexperience and just general ignorance.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a data engineer consultant building a datalake from scratch on AWS for a client and looking for any guidence/advice from the skillfull/knowledge people in this sub.&lt;/p&gt;\n\n&lt;p&gt;Basically the client wants a low cost datalake solution with low maintenance for daily feeds and a streaming feed. Apache superset will connect to the datalake and display a dashboard on their website application.&lt;/p&gt;\n\n&lt;p&gt;Things to keep in mind:\n- Low cost\n- Low Maintenance\n- Low Volume of data\n- +- Daily feeds\n- A few Streaming feeds\n- data is in CSV/json&lt;/p&gt;\n\n&lt;p&gt;What I built:\nAWS Step functions - Orchestration\nAWS Event Bridge - Scheduling\nAWS Lambda - fetch data from sources via rest API into S3 Landing bucket and another for moving files to different bucket for transforms and cleaning\nAWS S3 storage - 4 buckets (landing ,raw,processed, scripts)\nAWS Glue - Pyspark for transformations and cleaning ( built library for easy script writing for when adding new data/sources) data is compressed in gzip and parquet format\nAWS Glue Spark Streaming job to run 24/7 for the data consumed from Kafka\nAWS Lake formation - Security/ Governance\nApache Iceberg - Table format(with parquet) with glue catalog and Athena as the query engine for processed data and config tables to keep track of pipelines, data is partitioned by week.&lt;/p&gt;\n\n&lt;p&gt;Things I need guidance with:\n- I&amp;#39;m not sure entirely about the maintenance that needs to be done with iceberg\n- Don&amp;#39;t know much about the glue spark streaming job,maybe need a different ETL tool? Like Nifi?\n- Is my solution correct for this case,maybe different tech/tools?\n- Maybe need a DQ tool?\n- I need a way to handle updates made on the the front-end that uodates the data in the datalake and Apache superset dashboard on the front-end is updated accordingly \n- Am I missing anything? Especially things with best practice and standards.&lt;/p&gt;\n\n&lt;p&gt;This is just high level and I apologize if I&amp;#39;m not giving enough info. Please ask and I&amp;#39;ll try to clarify.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance, I would appreciate any advice that can be given&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16v9iwi", "is_robot_indexable": true, "report_reasons": null, "author": "Expensive-Lab-497", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16v9iwi/advice_for_building_datalake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16v9iwi/advice_for_building_datalake/", "subreddit_subscribers": 131086, "created_utc": 1695988340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a little stumped by this \u201cnontechnical users\u201d part of the requirement.\n\nI\u2019ll be hosting a mini Postgres database on AWS, and users will need only to append new records. I can handle any cleaning, validation, etc.\n\nShould I create a lambda function that can validate and process a JSON payload into the database \u2014 and create the nontechnical user some kind of webapp that can submit these payloads to lambda?\n\n What do you guys usually do in these cases?\n\nEdit: should I just give them an AWS account and tell them to drop CSVs in an S3 bucket manually?", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good data integration plans that require a database to be updated by nontechnical users?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16veyny", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696002917.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696001955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a little stumped by this \u201cnontechnical users\u201d part of the requirement.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll be hosting a mini Postgres database on AWS, and users will need only to append new records. I can handle any cleaning, validation, etc.&lt;/p&gt;\n\n&lt;p&gt;Should I create a lambda function that can validate and process a JSON payload into the database \u2014 and create the nontechnical user some kind of webapp that can submit these payloads to lambda?&lt;/p&gt;\n\n&lt;p&gt;What do you guys usually do in these cases?&lt;/p&gt;\n\n&lt;p&gt;Edit: should I just give them an AWS account and tell them to drop CSVs in an S3 bucket manually?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16veyny", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16veyny/what_are_some_good_data_integration_plans_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16veyny/what_are_some_good_data_integration_plans_that/", "subreddit_subscribers": 131086, "created_utc": 1696001955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a pipeline that takes millions of IDs and then requests additional info for each ID from a 3rd party API. The support for this API isn't great. \n\nGetting through all API calls requires days. If we need to refetch, days again. \n\nI haven't dug into the profiling to see where it's most slow, but there isn't much to the code anyway. Iterate through batches of IDs, make an API call for each ID in the batch, load blobs into the DB, continue with the next batch. \nBecause it's a GET/id call there is no pagination so I'm thinking concurrent calls for multiple IDs might be the way to go. \n\nProbably need to dig into profiling the code to get better insight into the bottlenecks. But figured I'd ask in case I'm missing something obvious that I should check out. \n\nThanks for any thoughts.", "author_fullname": "t2_gua18k7sg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone deal with 3rd party API data pulls that take a long time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ussho", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695937729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a pipeline that takes millions of IDs and then requests additional info for each ID from a 3rd party API. The support for this API isn&amp;#39;t great. &lt;/p&gt;\n\n&lt;p&gt;Getting through all API calls requires days. If we need to refetch, days again. &lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t dug into the profiling to see where it&amp;#39;s most slow, but there isn&amp;#39;t much to the code anyway. Iterate through batches of IDs, make an API call for each ID in the batch, load blobs into the DB, continue with the next batch. \nBecause it&amp;#39;s a GET/id call there is no pagination so I&amp;#39;m thinking concurrent calls for multiple IDs might be the way to go. &lt;/p&gt;\n\n&lt;p&gt;Probably need to dig into profiling the code to get better insight into the bottlenecks. But figured I&amp;#39;d ask in case I&amp;#39;m missing something obvious that I should check out. &lt;/p&gt;\n\n&lt;p&gt;Thanks for any thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ussho", "is_robot_indexable": true, "report_reasons": null, "author": "alexcontrerasdppl", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ussho/anyone_deal_with_3rd_party_api_data_pulls_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ussho/anyone_deal_with_3rd_party_api_data_pulls_that/", "subreddit_subscribers": 131086, "created_utc": 1695937729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working at a sports organization that is developing a data infrastructure from basically ground zero. For the moment we are working on data for the sports department, and we will likely first move into media, ticketing, finance etc. in a couple of years.\n\nAt the moment we have a central IO package for database operations, a repository for quality checks ([soda](https://docs.soda.io/)) and a Github repo for each data source API wrapper and ETL/ELT pipeline.\nThe repos could look like `central-db-io`, `data-quality`, `data-source-1-api`, `data-source-1-db-io`, `data-source-2-api`, `data-source-2-db-io`...\nThis means that `data-source-1-db-io` uses functions from the `central-db-io` and `data-source-1-api`.\n\nHow do you / would you organize your codebase for an organization with multiple data sources?\nWhat are your experiences with monorepo and multi-repo approach?\nWhat are the main drawbacks and benefits of these approaches?\nAn example codebase structure would be highly appreciated!", "author_fullname": "t2_226yoed5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you organize your codebase?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vipp8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696010726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working at a sports organization that is developing a data infrastructure from basically ground zero. For the moment we are working on data for the sports department, and we will likely first move into media, ticketing, finance etc. in a couple of years.&lt;/p&gt;\n\n&lt;p&gt;At the moment we have a central IO package for database operations, a repository for quality checks (&lt;a href=\"https://docs.soda.io/\"&gt;soda&lt;/a&gt;) and a Github repo for each data source API wrapper and ETL/ELT pipeline.\nThe repos could look like &lt;code&gt;central-db-io&lt;/code&gt;, &lt;code&gt;data-quality&lt;/code&gt;, &lt;code&gt;data-source-1-api&lt;/code&gt;, &lt;code&gt;data-source-1-db-io&lt;/code&gt;, &lt;code&gt;data-source-2-api&lt;/code&gt;, &lt;code&gt;data-source-2-db-io&lt;/code&gt;...\nThis means that &lt;code&gt;data-source-1-db-io&lt;/code&gt; uses functions from the &lt;code&gt;central-db-io&lt;/code&gt; and &lt;code&gt;data-source-1-api&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;How do you / would you organize your codebase for an organization with multiple data sources?\nWhat are your experiences with monorepo and multi-repo approach?\nWhat are the main drawbacks and benefits of these approaches?\nAn example codebase structure would be highly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jAWcsU-gRo_AbpFZ1-iJw0BoGi3ArN2W8uH5_6o8vk4.jpg?auto=webp&amp;s=794864da9e2043083ad5f5b3b0a6f285c4a05f00", "width": 1910, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/jAWcsU-gRo_AbpFZ1-iJw0BoGi3ArN2W8uH5_6o8vk4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f0f71854822e9fc39559983e189041d97e33a14b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/jAWcsU-gRo_AbpFZ1-iJw0BoGi3ArN2W8uH5_6o8vk4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1d4a1bbc46a0fdbb5259355890c5943fb9ca5610", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/jAWcsU-gRo_AbpFZ1-iJw0BoGi3ArN2W8uH5_6o8vk4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9fd273f180a6682f48b158a5a057ce8196bd06d3", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/jAWcsU-gRo_AbpFZ1-iJw0BoGi3ArN2W8uH5_6o8vk4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=27660a750ae413f3abe463c61b6083da0f541090", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/jAWcsU-gRo_AbpFZ1-iJw0BoGi3ArN2W8uH5_6o8vk4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6bafe163a7948308017b11bc656c9f57328fe0a", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/jAWcsU-gRo_AbpFZ1-iJw0BoGi3ArN2W8uH5_6o8vk4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4700ec9114920043d9f69c366a7391b589ff30e6", "width": 1080, "height": 565}], "variants": {}, "id": "a4KfaJ4Tgr2cU4tdciUl9Jd10jdseU7uCcfMRiN0m7Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16vipp8", "is_robot_indexable": true, "report_reasons": null, "author": "C_Ronsholt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vipp8/how_do_you_organize_your_codebase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16vipp8/how_do_you_organize_your_codebase/", "subreddit_subscribers": 131086, "created_utc": 1696010726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is your work as a data engineer always directly geared towards analytics, data science, and increasing profits? Or do you ever work more with business processes and workflow? Im attracted to data engineering because I like databases and making life easier for people, but I\u2019m worried that I\u2019ll lose motivation if all my focus and effort just goes towards optimizing profits instead of real change, even if that\u2019s just within the company like helping it run better or more efficiently. Have any of you felt this in your careers?\n\nEdit: This is definitely more of a concern as a data scientist/analyst, but still I've heard that some data engineers have lots of meetings and are very involved in deciding how data is used and what to focus on, while I just wanna do my thing and do it well if that makes sense. I get every job in a business really has the same end goal, but if I'm removed from that side of things, I'm happier.", "author_fullname": "t2_70jftqmq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Driving profits or enabling businesses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16v3xw4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695976546.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695968552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is your work as a data engineer always directly geared towards analytics, data science, and increasing profits? Or do you ever work more with business processes and workflow? Im attracted to data engineering because I like databases and making life easier for people, but I\u2019m worried that I\u2019ll lose motivation if all my focus and effort just goes towards optimizing profits instead of real change, even if that\u2019s just within the company like helping it run better or more efficiently. Have any of you felt this in your careers?&lt;/p&gt;\n\n&lt;p&gt;Edit: This is definitely more of a concern as a data scientist/analyst, but still I&amp;#39;ve heard that some data engineers have lots of meetings and are very involved in deciding how data is used and what to focus on, while I just wanna do my thing and do it well if that makes sense. I get every job in a business really has the same end goal, but if I&amp;#39;m removed from that side of things, I&amp;#39;m happier.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16v3xw4", "is_robot_indexable": true, "report_reasons": null, "author": "cadet1249", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16v3xw4/driving_profits_or_enabling_businesses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16v3xw4/driving_profits_or_enabling_businesses/", "subreddit_subscribers": 131086, "created_utc": 1695968552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team is experiencing performance issues with our jobs that use DBT and I've seen a couple of examples online about potential performance issues with DBT + Redshift but they seem to be from a couple of years ago (e.g. [https://github.com/dbt-labs/dbt-core/issues/3112](https://github.com/dbt-labs/dbt-core/issues/3112))\n\nAre there any current known performance issues with DBT + Redshift? Is DBT able to take advantage of Redshift query optimization like a stored procedure can?", "author_fullname": "t2_jx5l6r0ay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any known performance issues with using DBT with Redshift rather than just using Stored Procedures?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16urrko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695935440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team is experiencing performance issues with our jobs that use DBT and I&amp;#39;ve seen a couple of examples online about potential performance issues with DBT + Redshift but they seem to be from a couple of years ago (e.g. &lt;a href=\"https://github.com/dbt-labs/dbt-core/issues/3112\"&gt;https://github.com/dbt-labs/dbt-core/issues/3112&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Are there any current known performance issues with DBT + Redshift? Is DBT able to take advantage of Redshift query optimization like a stored procedure can?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3MFqS5n6orSjDgRwoZ3ZmnIT7-kzsEkg-jBbMBfIoDQ.jpg?auto=webp&amp;s=c27f5c512e0937f3fb31df45b56f4defffee8c74", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/3MFqS5n6orSjDgRwoZ3ZmnIT7-kzsEkg-jBbMBfIoDQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=053ee38f041387ff6894839a8a11641f465717b0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/3MFqS5n6orSjDgRwoZ3ZmnIT7-kzsEkg-jBbMBfIoDQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=268a38656d9cd7b96e9d1f2a129adf687cc6a71e", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/3MFqS5n6orSjDgRwoZ3ZmnIT7-kzsEkg-jBbMBfIoDQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0c492ab706d28d2efa6ac6062da93d41e07ffd3", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/3MFqS5n6orSjDgRwoZ3ZmnIT7-kzsEkg-jBbMBfIoDQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=607ee10126c693e9cf5f52bba95a8743ba730cb0", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/3MFqS5n6orSjDgRwoZ3ZmnIT7-kzsEkg-jBbMBfIoDQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0b22be1253f4365f9dc8997ffd87b6319a2b70c0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/3MFqS5n6orSjDgRwoZ3ZmnIT7-kzsEkg-jBbMBfIoDQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bb95747192e882a118075e9bb1e7c34d7dda4de0", "width": 1080, "height": 540}], "variants": {}, "id": "JkJo2ZeV8-7dP2qc7pdNuHWB-Q0SZGdChzLzldo7rNM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16urrko", "is_robot_indexable": true, "report_reasons": null, "author": "IllRepresentative858", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16urrko/are_there_any_known_performance_issues_with_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16urrko/are_there_any_known_performance_issues_with_using/", "subreddit_subscribers": 131086, "created_utc": 1695935440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB + Delta Lake (the new lake house?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "name": "t3_16vjab1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MRNnT9VG5l0M7jeRhdjTX_ezrHlHJbwbBVG60cywCrI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696012024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confessionsofadataguy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confessionsofadataguy.com/duckdb-delta-lake-the-new-lake-house/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-GTdV0M2QQefE9FJcVVUmgiephIA0UDMSN_KxsTlkEw.jpg?auto=webp&amp;s=270d832b3ce61c334db744b2e7a0282e972d26de", "width": 1030, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/-GTdV0M2QQefE9FJcVVUmgiephIA0UDMSN_KxsTlkEw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae8561dda5783ef4f34260d337bae886f73c2000", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/-GTdV0M2QQefE9FJcVVUmgiephIA0UDMSN_KxsTlkEw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=87ee2f3bd1ab47de61cc2f8aed7c6fbb711f9e0d", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/-GTdV0M2QQefE9FJcVVUmgiephIA0UDMSN_KxsTlkEw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=029ff2d63dc00598e00c1c3766df2705b16cad07", "width": 320, "height": 238}, {"url": "https://external-preview.redd.it/-GTdV0M2QQefE9FJcVVUmgiephIA0UDMSN_KxsTlkEw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=625fe3927e8c9faba38377f09a84fb53b6292b7b", "width": 640, "height": 477}, {"url": "https://external-preview.redd.it/-GTdV0M2QQefE9FJcVVUmgiephIA0UDMSN_KxsTlkEw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bbf7d5e65f6ff3ee037daee664aa6cc5347ff1f3", "width": 960, "height": 715}], "variants": {}, "id": "EOmtoeLkevfWCLc_W7oSaTnUgH8Ecg3zviFr2dSBs1A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16vjab1", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vjab1/duckdb_delta_lake_the_new_lake_house/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confessionsofadataguy.com/duckdb-delta-lake-the-new-lake-house/", "subreddit_subscribers": 131086, "created_utc": 1696012024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, \n\nLet's say that you have a team of 4 software engineers at your disposal (Java with Spring, Nodejs, sql, different nosql databases, messaging systems knowledge). \n\nThe requirements to design would be a data hub that aggregates information from different sources that are the authoring applications.  \n\nThe authoring applications can not be trusted fully, meaning that when data gets added it can be inconsistent with data from other authoring systems (let's say system A says that there's a blue ice cream, system B says the yellow ice cream costs \u20ac4 but there is no yellow ice cream in the system) and you also want to have a four eyes principle to validate changes in the data before the new version is available for consumers.  \n\nThe complete data schema is quite extensive, and a large amount (hundreds) of different kinds of systems need to be able to consume from the system. Not a lot of data changes during the day, but a lot of data is being read by the different consuming systems.  \n\nIs there some kind of industry standard architecture available for this kind of data hub? Or a framework or tool that would be even better than only custom application development?   \n\nThanks!", "author_fullname": "t2_8n7hm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you architect a data hub with four eyes validation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16vk4bt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696013975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say that you have a team of 4 software engineers at your disposal (Java with Spring, Nodejs, sql, different nosql databases, messaging systems knowledge). &lt;/p&gt;\n\n&lt;p&gt;The requirements to design would be a data hub that aggregates information from different sources that are the authoring applications.  &lt;/p&gt;\n\n&lt;p&gt;The authoring applications can not be trusted fully, meaning that when data gets added it can be inconsistent with data from other authoring systems (let&amp;#39;s say system A says that there&amp;#39;s a blue ice cream, system B says the yellow ice cream costs \u20ac4 but there is no yellow ice cream in the system) and you also want to have a four eyes principle to validate changes in the data before the new version is available for consumers.  &lt;/p&gt;\n\n&lt;p&gt;The complete data schema is quite extensive, and a large amount (hundreds) of different kinds of systems need to be able to consume from the system. Not a lot of data changes during the day, but a lot of data is being read by the different consuming systems.  &lt;/p&gt;\n\n&lt;p&gt;Is there some kind of industry standard architecture available for this kind of data hub? Or a framework or tool that would be even better than only custom application development?   &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16vk4bt", "is_robot_indexable": true, "report_reasons": null, "author": "steampunkdev", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vk4bt/how_would_you_architect_a_data_hub_with_four_eyes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16vk4bt/how_would_you_architect_a_data_hub_with_four_eyes/", "subreddit_subscribers": 131086, "created_utc": 1696013975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have two usecases in pyspark that would be suitable for concurrency\n\n1. Read tables from source, do SCD and ingest in destination table (totally 5-6 tables)\n2. Extract data from a nested JSON, where  50K JSON rows is exploded into a table of 1.5M records\n\nI know the spark architecture does parallel processing on it's own. I am not able to figure out why we need to set up a concurrency function even then. Using threadpools, i am able to reduce the runtime of my SCD ingestion jobs. Is this the best approach to implement concurrency in spark? and would this work for my 2nd usecase as well?", "author_fullname": "t2_xap78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Concurrency in pyspark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vismd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696010915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two usecases in pyspark that would be suitable for concurrency&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Read tables from source, do SCD and ingest in destination table (totally 5-6 tables)&lt;/li&gt;\n&lt;li&gt;Extract data from a nested JSON, where  50K JSON rows is exploded into a table of 1.5M records&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I know the spark architecture does parallel processing on it&amp;#39;s own. I am not able to figure out why we need to set up a concurrency function even then. Using threadpools, i am able to reduce the runtime of my SCD ingestion jobs. Is this the best approach to implement concurrency in spark? and would this work for my 2nd usecase as well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16vismd", "is_robot_indexable": true, "report_reasons": null, "author": "totalsports1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16vismd/concurrency_in_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16vismd/concurrency_in_pyspark/", "subreddit_subscribers": 131086, "created_utc": 1696010915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What impact does having a postgrad in Computer science have on one's data engineering career going forward?", "author_fullname": "t2_hq9ww050", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impact of postgraduate degree", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vfwpz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696004145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What impact does having a postgrad in Computer science have on one&amp;#39;s data engineering career going forward?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16vfwpz", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Note-457", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vfwpz/impact_of_postgraduate_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16vfwpz/impact_of_postgraduate_degree/", "subreddit_subscribers": 131086, "created_utc": 1696004145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jyrtun40", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overloaded Spark cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_16vbobm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vWgxyFuPgoeiBaENagOqAtXB8Fw3-7yOhHuE-7pvEcI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695994081.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/rv2tt5l557rb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/rv2tt5l557rb1.jpg?auto=webp&amp;s=86643d5c5be145b57823078be2829042aab4d9b2", "width": 1200, "height": 568}, "resolutions": [{"url": "https://preview.redd.it/rv2tt5l557rb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dba7374c41d6e398756eee0d46840ee41fac4638", "width": 108, "height": 51}, {"url": "https://preview.redd.it/rv2tt5l557rb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bbfc3db8e25ed48b0557298c24c29ac2b63488f7", "width": 216, "height": 102}, {"url": "https://preview.redd.it/rv2tt5l557rb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc2a21d9895f34b6454291d6baff43235b6d64dc", "width": 320, "height": 151}, {"url": "https://preview.redd.it/rv2tt5l557rb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7f5d572859cb457f953b03e07ebaa42dda2e9460", "width": 640, "height": 302}, {"url": "https://preview.redd.it/rv2tt5l557rb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5db2a296dd1230bbc0085356ae262136913b81aa", "width": 960, "height": 454}, {"url": "https://preview.redd.it/rv2tt5l557rb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=91ac80dbfea717b7ff0038ae3155fb45fb93a916", "width": 1080, "height": 511}], "variants": {}, "id": "4IEpTY4FtE4I39b4YQFMNtfrS373BXXYwOyIP_Ml7BQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "16vbobm", "is_robot_indexable": true, "report_reasons": null, "author": "CarelessPassage8579", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vbobm/overloaded_spark_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/rv2tt5l557rb1.jpg", "subreddit_subscribers": 131086, "created_utc": 1695994081.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here is our blog post - please check it out: [https://forums.autodesk.com/t5/engineering-hub-blog/autodesk-and-outerbounds-partner-to-open-source-ray-and-hpc/ba-p/12254816](https://forums.autodesk.com/t5/engineering-hub-blog/autodesk-and-outerbounds-partner-to-open-source-ray-and-hpc/ba-p/12254816)\n\nAnd try out the `metaflow-ray` extension here: [https://github.com/outerbounds/metaflow-ray](https://github.com/outerbounds/metaflow-ray)", "author_fullname": "t2_53pxmg7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We Collaborated With Outerbounds to Open Source Ray and HPC Integrations in Metaflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16uw2yg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695945493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here is our blog post - please check it out: &lt;a href=\"https://forums.autodesk.com/t5/engineering-hub-blog/autodesk-and-outerbounds-partner-to-open-source-ray-and-hpc/ba-p/12254816\"&gt;https://forums.autodesk.com/t5/engineering-hub-blog/autodesk-and-outerbounds-partner-to-open-source-ray-and-hpc/ba-p/12254816&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And try out the &lt;code&gt;metaflow-ray&lt;/code&gt; extension here: &lt;a href=\"https://github.com/outerbounds/metaflow-ray\"&gt;https://github.com/outerbounds/metaflow-ray&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/INWOhLc_U-g9YvDfrtMj0qLezg7gKLoaDG7u6H2UHvY.jpg?auto=webp&amp;s=7f9412f04c8503a5605729861d936daea0487f3e", "width": 1400, "height": 788}, "resolutions": [{"url": "https://external-preview.redd.it/INWOhLc_U-g9YvDfrtMj0qLezg7gKLoaDG7u6H2UHvY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e5b75bcec5f3d0a6d9492cebf4f76d5095dbe5e4", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/INWOhLc_U-g9YvDfrtMj0qLezg7gKLoaDG7u6H2UHvY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=985f2eaa70f73484a273b1d6ddf43ea143b0a14d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/INWOhLc_U-g9YvDfrtMj0qLezg7gKLoaDG7u6H2UHvY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c6a3d232a80c140950b4c584515d9d32577d917e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/INWOhLc_U-g9YvDfrtMj0qLezg7gKLoaDG7u6H2UHvY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=64aaf7d2605ff791e366cebb38bf83e8ff072b01", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/INWOhLc_U-g9YvDfrtMj0qLezg7gKLoaDG7u6H2UHvY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2b5f305abfd51932703edd8888d1b4b2c9b3c578", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/INWOhLc_U-g9YvDfrtMj0qLezg7gKLoaDG7u6H2UHvY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=41466a8b17537bdf3456671d82987b99eabab693", "width": 1080, "height": 607}], "variants": {}, "id": "3JKcdMim8UZuRHMw4mORV_syX6rRw5TGS1hHCVRO5sg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16uw2yg", "is_robot_indexable": true, "report_reasons": null, "author": "rirhun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16uw2yg/we_collaborated_with_outerbounds_to_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16uw2yg/we_collaborated_with_outerbounds_to_open_source/", "subreddit_subscribers": 131086, "created_utc": 1695945493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to create an ingestion endpoint for analytics events that takes in events, processes them and writes them into a PostgreSQL database, kinda like Amplitude's/Posthog's/ HTTP API endpoint. The backend is in Django.  \nI'm trying to understand how to engineer the endpoint correctly so that it can sustain peak loads. I read all the recent discussions on Reddit and Eran Stiller's excellent [two-part post](https://eranstiller.com/rabbitmq-vs-kafka-an-architects-dilemma-part-1), and I'm still not sure what's right. Should I use Kafka, or is Celery (w/RabbitMQ) enough for the first few years? I know that Posthog [use Kafka](https://posthog.com/handbook/engineering/databases/event-ingestion) for their ingestion, but they use Clickhouse where writes are more complex and our product won't be near their scale for a long time (Just developing the MVP at the moment.) ", "author_fullname": "t2_8zqsmsyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka vs Celery+RabbitMQ for a Django event ingestion API endpoint", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16usf4g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695936891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to create an ingestion endpoint for analytics events that takes in events, processes them and writes them into a PostgreSQL database, kinda like Amplitude&amp;#39;s/Posthog&amp;#39;s/ HTTP API endpoint. The backend is in Django.&lt;br/&gt;\nI&amp;#39;m trying to understand how to engineer the endpoint correctly so that it can sustain peak loads. I read all the recent discussions on Reddit and Eran Stiller&amp;#39;s excellent &lt;a href=\"https://eranstiller.com/rabbitmq-vs-kafka-an-architects-dilemma-part-1\"&gt;two-part post&lt;/a&gt;, and I&amp;#39;m still not sure what&amp;#39;s right. Should I use Kafka, or is Celery (w/RabbitMQ) enough for the first few years? I know that Posthog &lt;a href=\"https://posthog.com/handbook/engineering/databases/event-ingestion\"&gt;use Kafka&lt;/a&gt; for their ingestion, but they use Clickhouse where writes are more complex and our product won&amp;#39;t be near their scale for a long time (Just developing the MVP at the moment.) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZU5JO68WUcN5xXwpiJ9dPiW6aoKhN-ElLO9uvi9CVk8.jpg?auto=webp&amp;s=8b36fe5a3c3f47a3fb5ac0815750dcb8cac9fd03", "width": 1024, "height": 682}, "resolutions": [{"url": "https://external-preview.redd.it/ZU5JO68WUcN5xXwpiJ9dPiW6aoKhN-ElLO9uvi9CVk8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec716f07f66faa5d41e873f0e68c9b7a455a8128", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/ZU5JO68WUcN5xXwpiJ9dPiW6aoKhN-ElLO9uvi9CVk8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e4ed62cfdf754cc4a4d900870a1cf55dd5167db", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/ZU5JO68WUcN5xXwpiJ9dPiW6aoKhN-ElLO9uvi9CVk8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=883a5b5cbccbcd670155443c50a06ef9979e422e", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/ZU5JO68WUcN5xXwpiJ9dPiW6aoKhN-ElLO9uvi9CVk8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1a91ddc617eb2ad930e3b41e4b57311acf5f9664", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/ZU5JO68WUcN5xXwpiJ9dPiW6aoKhN-ElLO9uvi9CVk8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f427a89f867a41a07ee9c5a82ba05f99a85d381", "width": 960, "height": 639}], "variants": {}, "id": "8llVTlqXNoUfmExXO6h_JOmt2RyQv9_znqqUK8hONow"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16usf4g", "is_robot_indexable": true, "report_reasons": null, "author": "Low_Adhesiveness_130", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16usf4g/kafka_vs_celeryrabbitmq_for_a_django_event/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16usf4g/kafka_vs_celeryrabbitmq_for_a_django_event/", "subreddit_subscribers": 131086, "created_utc": 1695936891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I  want to test some tools that can find secrets in unstructured data, and I was curious if anyone can point me towards a database of data that I can download and insert into my crawler to test some code at finding sensitive pii and other data.  Anyone know a list or  a dump of a lot of sensitive PDF files.   Also is there another reddit group that might know? like  security groups?  which one?", "author_fullname": "t2_12uxau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "trying locate unstructured test data with known secrets, know a resource where I can download and test my software for finding secrets like pii and gdpr", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16us3nl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695936170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I  want to test some tools that can find secrets in unstructured data, and I was curious if anyone can point me towards a database of data that I can download and insert into my crawler to test some code at finding sensitive pii and other data.  Anyone know a list or  a dump of a lot of sensitive PDF files.   Also is there another reddit group that might know? like  security groups?  which one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16us3nl", "is_robot_indexable": true, "report_reasons": null, "author": "chris415", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16us3nl/trying_locate_unstructured_test_data_with_known/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16us3nl/trying_locate_unstructured_test_data_with_known/", "subreddit_subscribers": 131086, "created_utc": 1695936170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am giving an interview this weekend and just wanted to know about the different ways you use Azure in your businesses! I'm transitioning from support to DE and so have no experience with DE as of now. But I have studied it personally. I'm planning to say that I have worked on DE in my current job. Could you guys help me out with your use cases so I can build up something believable to tell!?", "author_fullname": "t2_dblnp6f9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE in Business", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16vlpzs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696017671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am giving an interview this weekend and just wanted to know about the different ways you use Azure in your businesses! I&amp;#39;m transitioning from support to DE and so have no experience with DE as of now. But I have studied it personally. I&amp;#39;m planning to say that I have worked on DE in my current job. Could you guys help me out with your use cases so I can build up something believable to tell!?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16vlpzs", "is_robot_indexable": true, "report_reasons": null, "author": "yeetdiver", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vlpzs/de_in_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16vlpzs/de_in_business/", "subreddit_subscribers": 131086, "created_utc": 1696017671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone use DuckDB in production for their data engineering work? Or is planning on using it/building POCs?   \n\n\nI  really love DuckDB, I think it's a fantastic tool. But I'm finding it hard to justify using it in production, especially in an enterprise setting when you already have so many options like DataBricks, Snowflake, BigQuery + GCP ecosystem, etc.  \n\n\nThat being said, I showcased it to our data analysts &amp; data scientists a few months back, and they absolutely love it. I'm seeing a lot more DuckDB and a lot less panda in the code they push to our GitHub. That's been really cool to see! ", "author_fullname": "t2_6l1e382d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB in production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16vjld3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696012739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone use DuckDB in production for their data engineering work? Or is planning on using it/building POCs?   &lt;/p&gt;\n\n&lt;p&gt;I  really love DuckDB, I think it&amp;#39;s a fantastic tool. But I&amp;#39;m finding it hard to justify using it in production, especially in an enterprise setting when you already have so many options like DataBricks, Snowflake, BigQuery + GCP ecosystem, etc.  &lt;/p&gt;\n\n&lt;p&gt;That being said, I showcased it to our data analysts &amp;amp; data scientists a few months back, and they absolutely love it. I&amp;#39;m seeing a lot more DuckDB and a lot less panda in the code they push to our GitHub. That&amp;#39;s been really cool to see! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16vjld3", "is_robot_indexable": true, "report_reasons": null, "author": "unfair_pandah", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16vjld3/duckdb_in_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16vjld3/duckdb_in_production/", "subreddit_subscribers": 131086, "created_utc": 1696012739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know these are not mutually exclusive, but I'm just curious how you balance new project ideas with improving existing processes in your current/past organizations.\n\n* Are you just resolving tickets handed to you by a manager? \n* Are you trying to solve more general business problems handed over to you and designing the solutions from ground up?\n* Are you trying to identify the problems yourself and putting forward project proposals that might bring value to the business? \n* Or are you just making sure your data platform is as reliable as possible - and mostly fighting the business on chasing new projects?\n\n&amp;#x200B;", "author_fullname": "t2_286kcv5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Chasing new projects VS improving existing processes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16v9a29", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695987628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know these are not mutually exclusive, but I&amp;#39;m just curious how you balance new project ideas with improving existing processes in your current/past organizations.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are you just resolving tickets handed to you by a manager? &lt;/li&gt;\n&lt;li&gt;Are you trying to solve more general business problems handed over to you and designing the solutions from ground up?&lt;/li&gt;\n&lt;li&gt;Are you trying to identify the problems yourself and putting forward project proposals that might bring value to the business? &lt;/li&gt;\n&lt;li&gt;Or are you just making sure your data platform is as reliable as possible - and mostly fighting the business on chasing new projects?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16v9a29", "is_robot_indexable": true, "report_reasons": null, "author": "thecrixus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16v9a29/chasing_new_projects_vs_improving_existing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16v9a29/chasing_new_projects_vs_improving_existing/", "subreddit_subscribers": 131086, "created_utc": 1695987628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For example, if it's being run with the BashOperator. Is it resource-intensive? Trying to figure out if a DBT deployment on Airflow is expected to be resource intensive and will require scaling of Airflow infrastructure even though there aren't that many DAGS, or if there is something unusual going wrong that needs to be investigated.", "author_fullname": "t2_jx5l6r0ay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does using DBT Core on Airflow cause performance issues?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16v2eaf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695963278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, if it&amp;#39;s being run with the BashOperator. Is it resource-intensive? Trying to figure out if a DBT deployment on Airflow is expected to be resource intensive and will require scaling of Airflow infrastructure even though there aren&amp;#39;t that many DAGS, or if there is something unusual going wrong that needs to be investigated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16v2eaf", "is_robot_indexable": true, "report_reasons": null, "author": "IllRepresentative858", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16v2eaf/does_using_dbt_core_on_airflow_cause_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16v2eaf/does_using_dbt_core_on_airflow_cause_performance/", "subreddit_subscribers": 131086, "created_utc": 1695963278.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}