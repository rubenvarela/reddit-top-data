{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious. I was thinking about the DBT packages I couldn't live without and Elementary is the the one. It gives you stored metadata about your models, runs, tests and test results. Slack notification on test failures. Various custom tests. A test dashboard.  I could live without dbt_utils, but not Elementary. Just a ton of useful stuff we'd have to create on our own.", "author_fullname": "t2_8ov8i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Users - What Single Package Could You Not Live Without?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k8qaw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694874034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious. I was thinking about the DBT packages I couldn&amp;#39;t live without and Elementary is the the one. It gives you stored metadata about your models, runs, tests and test results. Slack notification on test failures. Various custom tests. A test dashboard.  I could live without dbt_utils, but not Elementary. Just a ton of useful stuff we&amp;#39;d have to create on our own.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16k8qaw", "is_robot_indexable": true, "report_reasons": null, "author": "leogodin217", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16k8qaw/dbt_users_what_single_package_could_you_not_live/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16k8qaw/dbt_users_what_single_package_could_you_not_live/", "subreddit_subscribers": 128818, "created_utc": 1694874034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been in this game for 10 or so years, and I must say I feel guilty about using chatGPT and the like!\n\nI use it mostly for that first entry point to working thought data ideas, issues with pipelines, or even to get an overview of that new piece of open source software everyone in my circle is raving about. It\u2019s useful but only to a point.\n\nThe crux of my question, what do you use it for and do you even use it\u2026boils down to this\u2026i feel guilty! I\u2019m from a time when you literally had to grapple with some code for a good while. You couldn\u2019t just plug in a question and more or less get the answer (the internet is good but with chatGPT it\u2019s pretty much all there for the taking with one question, no research needed) - it\u2019s a great time saver to get to that point of \u2018now i understand and I\u2019m away writing some code\u2019 or refocusing on what the solution is. But I feel guilty. I have A LOT more time to ponder and get through the day to day work pretty quickly. Does that make anyone else feel kind of guilty or is this a late mid-life existential crisis! \n\nFriends\u2026your opinions\u2026and be kind, this could be burnout or the sudden realisation that maybe after years of being a one man band of all things data I may actually have some free time on my hands\u2026what to do with it without feeling guilty!", "author_fullname": "t2_hg12i599c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ChatGPT - do you use it? And what do you use it for? Feelings of guilt!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kl69k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694906110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in this game for 10 or so years, and I must say I feel guilty about using chatGPT and the like!&lt;/p&gt;\n\n&lt;p&gt;I use it mostly for that first entry point to working thought data ideas, issues with pipelines, or even to get an overview of that new piece of open source software everyone in my circle is raving about. It\u2019s useful but only to a point.&lt;/p&gt;\n\n&lt;p&gt;The crux of my question, what do you use it for and do you even use it\u2026boils down to this\u2026i feel guilty! I\u2019m from a time when you literally had to grapple with some code for a good while. You couldn\u2019t just plug in a question and more or less get the answer (the internet is good but with chatGPT it\u2019s pretty much all there for the taking with one question, no research needed) - it\u2019s a great time saver to get to that point of \u2018now i understand and I\u2019m away writing some code\u2019 or refocusing on what the solution is. But I feel guilty. I have A LOT more time to ponder and get through the day to day work pretty quickly. Does that make anyone else feel kind of guilty or is this a late mid-life existential crisis! &lt;/p&gt;\n\n&lt;p&gt;Friends\u2026your opinions\u2026and be kind, this could be burnout or the sudden realisation that maybe after years of being a one man band of all things data I may actually have some free time on my hands\u2026what to do with it without feeling guilty!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kl69k", "is_robot_indexable": true, "report_reasons": null, "author": "BumblyWurzle", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kl69k/chatgpt_do_you_use_it_and_what_do_you_use_it_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kl69k/chatgpt_do_you_use_it_and_what_do_you_use_it_for/", "subreddit_subscribers": 128818, "created_utc": 1694906110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a data engineer, I like to spend my free time building data pipelines. This is a data pipeline I built using streaming databases and Formula 1 data because I find it very interesting. What do you think about it, any input is highly appreciated.\n\n[https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave](https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave)", "author_fullname": "t2_nvvyzf8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Formula 1 streaming pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kcti2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694884654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data engineer, I like to spend my free time building data pipelines. This is a data pipeline I built using streaming databases and Formula 1 data because I find it very interesting. What do you think about it, any input is highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave\"&gt;https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?auto=webp&amp;s=c75a4459630fbf2ba807d871253197c73fee84b3", "width": 1640, "height": 924}, "resolutions": [{"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78c5e8ca5e715c2b45977bc797a53958df5e5350", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f65b3fc49964ecea50d1415b3f430435adf1e443", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e670fb69551dd0234d86517fc6806afd11c931fd", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b92f03ec856f8721ee28ab2329bf6d974ecd2861", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93b4bebf3215729b045c167284a40639a5933735", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=493c7ec70ca522c3536bc6164c8d5e6ca3602be1", "width": 1080, "height": 608}], "variants": {}, "id": "4o0Esqv7Gv1mS0Up9bOubHnnI0tJen4dv1w3Mvm0BfE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16kcti2", "is_robot_indexable": true, "report_reasons": null, "author": "WhiteLionGr", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kcti2/formula_1_streaming_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kcti2/formula_1_streaming_pipeline/", "subreddit_subscribers": 128818, "created_utc": 1694884654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last week, I got laid off because my employer decided to lay off approx 7% of the workforce which amounts to more than 1000 employees in the US. \n\nNonetheless, I have my first technical round for the Sr. Data Engineer interview with Amazon Pharmacy next week. I would be glad and grateful if people out here could help me in preparing for that. The first round is the live coding round (80% data structure and algorithms, 20 % SQL). Due to layoffs, I am feeling underconfident but this is probably my best chance to bounce back.  \n\n\nThank you in advance!", "author_fullname": "t2_c2efbhzn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in preparing for Sr. Data Engineer at Amazon Pharmacy || Impacted by recent layoff last week.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k9n58", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694876419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week, I got laid off because my employer decided to lay off approx 7% of the workforce which amounts to more than 1000 employees in the US. &lt;/p&gt;\n\n&lt;p&gt;Nonetheless, I have my first technical round for the Sr. Data Engineer interview with Amazon Pharmacy next week. I would be glad and grateful if people out here could help me in preparing for that. The first round is the live coding round (80% data structure and algorithms, 20 % SQL). Due to layoffs, I am feeling underconfident but this is probably my best chance to bounce back.  &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16k9n58", "is_robot_indexable": true, "report_reasons": null, "author": "Professional_Bug_729", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16k9n58/need_help_in_preparing_for_sr_data_engineer_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16k9n58/need_help_in_preparing_for_sr_data_engineer_at/", "subreddit_subscribers": 128818, "created_utc": 1694876419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wasn't sure how to best word the title here, and most probably worded things wrong...\n\nBut to exemplify my question, say I'm a data engineer working with an analyst, getting them access to some CDC data. Their requirement is that they want to be able to query the dataset on day 1 and get some result A. days later, after multiple updates to the table, they want to be able to query the dataset again and get result B (the new up-to-date data); however, they also want to be able to run a separate query on the same dataset and get result A (the original result) using some timestamp.\n\nI think that the only way to accomplish this is to have the CDC change operation and timestamp in the dataset itself. And when running any query you would need to:\n\n1. select records where timestamps are less than some input timestamp\n2. group by some primary key\n3. select records with max timestamp of each group\n4. select records where operation is insert or update (i.e. drop deletes)\n\nAm I thinking about this the correct way? It seems like the logic is getting a bit complicated here for something that might be rather common, so I wasn't sure if I was going in the wrong direction. Any help is appreciated!", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to query point-in-time state when working with transformed CDC data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kmaas", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694909108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wasn&amp;#39;t sure how to best word the title here, and most probably worded things wrong...&lt;/p&gt;\n\n&lt;p&gt;But to exemplify my question, say I&amp;#39;m a data engineer working with an analyst, getting them access to some CDC data. Their requirement is that they want to be able to query the dataset on day 1 and get some result A. days later, after multiple updates to the table, they want to be able to query the dataset again and get result B (the new up-to-date data); however, they also want to be able to run a separate query on the same dataset and get result A (the original result) using some timestamp.&lt;/p&gt;\n\n&lt;p&gt;I think that the only way to accomplish this is to have the CDC change operation and timestamp in the dataset itself. And when running any query you would need to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;select records where timestamps are less than some input timestamp&lt;/li&gt;\n&lt;li&gt;group by some primary key&lt;/li&gt;\n&lt;li&gt;select records with max timestamp of each group&lt;/li&gt;\n&lt;li&gt;select records where operation is insert or update (i.e. drop deletes)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I thinking about this the correct way? It seems like the logic is getting a bit complicated here for something that might be rather common, so I wasn&amp;#39;t sure if I was going in the wrong direction. Any help is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16kmaas", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kmaas/how_to_query_pointintime_state_when_working_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kmaas/how_to_query_pointintime_state_when_working_with/", "subreddit_subscribers": 128818, "created_utc": 1694909108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  \nI'm learning Airflow and have some simple tasks running.  I am having a very serious problem with the  update task running successfully, but, no changes in the database.    \n\n\nThis is all just running on my laptop, so, there aren't networking complications.  It's just a way to get my feet wet with airflow.  \n\n\nThis task finds files in the pickup directory.  The file has a query in it.  like so:  \n*UPDATE public.public\\_statistics set date\\_exported = CURRENT\\_TIMESTAMP where county\\_fips in (31109); COMMIT;*\n\nRunning the query in psql and the update occurs.  So, there's no syntax issues.  Also, it appears that the PostgresOperator and PostgresHandler are being deprecated in favor of SQLExecuteQueryOperator??  Not sure if that has anything to do with my issue.  \n\n\nPretty sure I am missing something small.  Any advice is welcome.\n\n    import json\n    import sys\n    import os\n    from airflow.models import Variable\n    from airflow.models.xcom import XCom\n    #from airflow.operators.postgres_operator import PostgresOperator\n    from airflow import AirflowException\n    from airflow.exceptions import AirflowProviderDeprecationWarning\n    from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator\n    \n    def update_pg_row():\n    \n     os.chdir('/home/sandbox/airflow/dags/datasets/pickup')\n     process_file_list = list()\n    \n     all_files_list = os.listdir(\"./\")\n     #KISS any file here has not been imported to snowflake\n    \n     for i in all_files_list:\n      if i.startswith('update_row_'):\n        process_file_list.append(i)\n    \n    \n     if len(process_file_list) == 0:\n       print(\"no fips update files to process\")\n       return()\n    \n     print(process_file_list)\n     print(\"length of file_list {}\".format(len(process_file_list)))\n     for f in process_file_list:\n      file_stats = os.stat(f)\n      print(\"processing {}\".format(f))\n      if file_stats.st_size &gt; 10:\n       fh = open(f, \"r+\")\n       qry = fh.read()\n       print(\"!!!!!!!!!!!! DEBUG !!!!!!!!!!!!!!!\")\n       print(qry)\n       try:\n        conn_op = SQLExecuteQueryOperator(\n         conn_id='pg_for_me',\n         task_id='update-pg-row-as-synced',\n         autocommit=True,\n         sql=f\n         )\n       except Exception as e:\n        print('cannot get queryoperator')\n        raise AirflowException(e)\n      else:\n       #should never be here.\n       print(\"{} is too small??  {}\".format(f,file_stats.st_size))\n    \n\n&amp;#x200B;", "author_fullname": "t2_km4f2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Airflow PostgreSQL not Committing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kev5p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694890026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;br/&gt;\nI&amp;#39;m learning Airflow and have some simple tasks running.  I am having a very serious problem with the  update task running successfully, but, no changes in the database.    &lt;/p&gt;\n\n&lt;p&gt;This is all just running on my laptop, so, there aren&amp;#39;t networking complications.  It&amp;#39;s just a way to get my feet wet with airflow.  &lt;/p&gt;\n\n&lt;p&gt;This task finds files in the pickup directory.  The file has a query in it.  like so:&lt;br/&gt;\n&lt;em&gt;UPDATE public.public_statistics set date_exported = CURRENT_TIMESTAMP where county_fips in (31109); COMMIT;&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Running the query in psql and the update occurs.  So, there&amp;#39;s no syntax issues.  Also, it appears that the PostgresOperator and PostgresHandler are being deprecated in favor of SQLExecuteQueryOperator??  Not sure if that has anything to do with my issue.  &lt;/p&gt;\n\n&lt;p&gt;Pretty sure I am missing something small.  Any advice is welcome.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import json\nimport sys\nimport os\nfrom airflow.models import Variable\nfrom airflow.models.xcom import XCom\n#from airflow.operators.postgres_operator import PostgresOperator\nfrom airflow import AirflowException\nfrom airflow.exceptions import AirflowProviderDeprecationWarning\nfrom airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator\n\ndef update_pg_row():\n\n os.chdir(&amp;#39;/home/sandbox/airflow/dags/datasets/pickup&amp;#39;)\n process_file_list = list()\n\n all_files_list = os.listdir(&amp;quot;./&amp;quot;)\n #KISS any file here has not been imported to snowflake\n\n for i in all_files_list:\n  if i.startswith(&amp;#39;update_row_&amp;#39;):\n    process_file_list.append(i)\n\n\n if len(process_file_list) == 0:\n   print(&amp;quot;no fips update files to process&amp;quot;)\n   return()\n\n print(process_file_list)\n print(&amp;quot;length of file_list {}&amp;quot;.format(len(process_file_list)))\n for f in process_file_list:\n  file_stats = os.stat(f)\n  print(&amp;quot;processing {}&amp;quot;.format(f))\n  if file_stats.st_size &amp;gt; 10:\n   fh = open(f, &amp;quot;r+&amp;quot;)\n   qry = fh.read()\n   print(&amp;quot;!!!!!!!!!!!! DEBUG !!!!!!!!!!!!!!!&amp;quot;)\n   print(qry)\n   try:\n    conn_op = SQLExecuteQueryOperator(\n     conn_id=&amp;#39;pg_for_me&amp;#39;,\n     task_id=&amp;#39;update-pg-row-as-synced&amp;#39;,\n     autocommit=True,\n     sql=f\n     )\n   except Exception as e:\n    print(&amp;#39;cannot get queryoperator&amp;#39;)\n    raise AirflowException(e)\n  else:\n   #should never be here.\n   print(&amp;quot;{} is too small??  {}&amp;quot;.format(f,file_stats.st_size))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16kev5p", "is_robot_indexable": true, "report_reasons": null, "author": "chock-a-block", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kev5p/apache_airflow_postgresql_not_committing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kev5p/apache_airflow_postgresql_not_committing/", "subreddit_subscribers": 128818, "created_utc": 1694890026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are in need for an analytics system that ingests customer json data every hour into a relational form for querying. We will be receiving the complete data for each customer as a giant json blob. And because we are getting it every hour, most of the data should already be in the system with only some attributes added/updated (unless its a new customer). There is some time-series data in it as well. The system should be able to handle this.\n\nWe need to run some specific queries for a customer dashboard. They need to be near realtime and will be run often. We also want the flexibility to run other queries (in SQL) for ad-hoc BI stuff and/or add it to the customer dashboard. Going forward, analytics is going to be a core offering and competitive advantage.\n\nWe are an AWS shop and not opposed to paying so long as the pricing is reasonable. For context, I'm a backend engineer that's only dabbled with DE here and there. A friend recommended Snowflake but I'm not sure how to calculate pricing. The SQL queries will involve a lot of joins.\n\nThoughts/Advice? Thanks.", "author_fullname": "t2_rz22aza", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be a good analytics setup for this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kh0p9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694895675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are in need for an analytics system that ingests customer json data every hour into a relational form for querying. We will be receiving the complete data for each customer as a giant json blob. And because we are getting it every hour, most of the data should already be in the system with only some attributes added/updated (unless its a new customer). There is some time-series data in it as well. The system should be able to handle this.&lt;/p&gt;\n\n&lt;p&gt;We need to run some specific queries for a customer dashboard. They need to be near realtime and will be run often. We also want the flexibility to run other queries (in SQL) for ad-hoc BI stuff and/or add it to the customer dashboard. Going forward, analytics is going to be a core offering and competitive advantage.&lt;/p&gt;\n\n&lt;p&gt;We are an AWS shop and not opposed to paying so long as the pricing is reasonable. For context, I&amp;#39;m a backend engineer that&amp;#39;s only dabbled with DE here and there. A friend recommended Snowflake but I&amp;#39;m not sure how to calculate pricing. The SQL queries will involve a lot of joins.&lt;/p&gt;\n\n&lt;p&gt;Thoughts/Advice? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kh0p9", "is_robot_indexable": true, "report_reasons": null, "author": "grchelp2018", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kh0p9/what_would_be_a_good_analytics_setup_for_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kh0p9/what_would_be_a_good_analytics_setup_for_this/", "subreddit_subscribers": 128818, "created_utc": 1694895675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI have been working a lot with Azure technology and I made Databricks the primary tool for my organization. I noticed that Azure Synapse has Data Studio which provides a free, lightweight, cross-platform data management and development tool that supports a wide range of database platforms.  \n\n\nI would love to know if Databricks offers a similar feature/product.  \n\n\nThanks.", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Databricks Similar to Synapse Azure Data Studio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kfrbq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694892385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been working a lot with Azure technology and I made Databricks the primary tool for my organization. I noticed that Azure Synapse has Data Studio which provides a free, lightweight, cross-platform data management and development tool that supports a wide range of database platforms.  &lt;/p&gt;\n\n&lt;p&gt;I would love to know if Databricks offers a similar feature/product.  &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kfrbq", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kfrbq/azure_databricks_similar_to_synapse_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kfrbq/azure_databricks_similar_to_synapse_azure_data/", "subreddit_subscribers": 128818, "created_utc": 1694892385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I'm planning to build a new microservice where I'm going to execute an athena query and send the query results as response after doing some transformations through pandas.\n\nAnd I'm having limitations with Athena since max results I can get from athena is 1000 and I need to implement pagination. And most of the queries going to be have more than 150k results.. so paginations gonna take alot time and I feels like its a hectic process as well.\n\nIs there any other way we can do it much simpler ? Where I get complete query result in one go ?", "author_fullname": "t2_5s0b87mm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complete Athena Query results", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kec3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694888634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I&amp;#39;m planning to build a new microservice where I&amp;#39;m going to execute an athena query and send the query results as response after doing some transformations through pandas.&lt;/p&gt;\n\n&lt;p&gt;And I&amp;#39;m having limitations with Athena since max results I can get from athena is 1000 and I need to implement pagination. And most of the queries going to be have more than 150k results.. so paginations gonna take alot time and I feels like its a hectic process as well.&lt;/p&gt;\n\n&lt;p&gt;Is there any other way we can do it much simpler ? Where I get complete query result in one go ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16kec3d", "is_robot_indexable": true, "report_reasons": null, "author": "imameeer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kec3d/complete_athena_query_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kec3d/complete_athena_query_results/", "subreddit_subscribers": 128818, "created_utc": 1694888634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u9bnox3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone looking to learn Azure Data Factory? Here is my introduction video to Azure Data Factory.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16ka9bx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xBJbvTAi5lY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Azure Data Factory | Introduction\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Azure Data Factory | Introduction", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xBJbvTAi5lY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Azure Data Factory | Introduction\"&gt;&lt;/iframe&gt;", "author_name": "Aleksi Partanen Tech", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xBJbvTAi5lY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@AleksiPartanenTech"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xBJbvTAi5lY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Azure Data Factory | Introduction\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16ka9bx", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FKeEuNNSruSnCC6To09w28ojpVFNxdjGdbteplEfVNE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694878002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xBJbvTAi5lY", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3036-VBJK6hj5tduHFLBI40yzkmgpPWrD08pljZYDK0.jpg?auto=webp&amp;s=34679e520bdd4300038a8b6504f24639b57abac3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/3036-VBJK6hj5tduHFLBI40yzkmgpPWrD08pljZYDK0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da229ee7498fd3071489e3e26efa528437a95553", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/3036-VBJK6hj5tduHFLBI40yzkmgpPWrD08pljZYDK0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=735f4314e784b4c2a708f3dc60d81387160fb9ae", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/3036-VBJK6hj5tduHFLBI40yzkmgpPWrD08pljZYDK0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2b29fbf1c5701423ac04992f94e087aa5c820a8", "width": 320, "height": 240}], "variants": {}, "id": "RqHZKoU-tPSLU13wCGokSe0IKcQImAAcwtz5ECvsrSE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16ka9bx", "is_robot_indexable": true, "report_reasons": null, "author": "aleks1ck", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ka9bx/anyone_looking_to_learn_azure_data_factory_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xBJbvTAi5lY", "subreddit_subscribers": 128818, "created_utc": 1694878002.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Azure Data Factory | Introduction", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xBJbvTAi5lY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Azure Data Factory | Introduction\"&gt;&lt;/iframe&gt;", "author_name": "Aleksi Partanen Tech", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xBJbvTAi5lY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@AleksiPartanenTech"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It has become mandatory to get cert\u00edfication in AZ 104 to stay in my current project and my manager is asking me to clear AZ 400 certification as early as possible. So please suggest any course or any website or any Youtube channel or any platform to gain the required knowledge to clear this AZ 104 certification as early as possible.\n\nThose who cleared this AZ 104 certification or those who have knowledge in this, Please guide me where and how to learn and clear the certification as early as possible.", "author_fullname": "t2_ljqmevrg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to clear AZ 104 certification as early as poss\u00edble ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k97q1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694875315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It has become mandatory to get cert\u00edfication in AZ 104 to stay in my current project and my manager is asking me to clear AZ 400 certification as early as possible. So please suggest any course or any website or any Youtube channel or any platform to gain the required knowledge to clear this AZ 104 certification as early as possible.&lt;/p&gt;\n\n&lt;p&gt;Those who cleared this AZ 104 certification or those who have knowledge in this, Please guide me where and how to learn and clear the certification as early as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16k97q1", "is_robot_indexable": true, "report_reasons": null, "author": "viking_spartan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16k97q1/how_to_clear_az_104_certification_as_early_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16k97q1/how_to_clear_az_104_certification_as_early_as/", "subreddit_subscribers": 128818, "created_utc": 1694875315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is most of this towards compute on Databricks, Snowflake, or OS engines like Spark? On licenses for transform tools like dbt or similar? Other?\n\n[View Poll](https://www.reddit.com/poll/16kojun)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does ETL / Transform contribute to your data platform costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kojun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694915750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is most of this towards compute on Databricks, Snowflake, or OS engines like Spark? On licenses for transform tools like dbt or similar? Other?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/16kojun\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kojun", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1695174950774, "options": [{"text": "Up to 30%", "id": "24827014"}, {"text": "30% to 50%", "id": "24827015"}, {"text": "50% to 70%", "id": "24827016"}, {"text": "Above 70%", "id": "24827017"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 38, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kojun/how_much_does_etl_transform_contribute_to_your/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/16kojun/how_much_does_etl_transform_contribute_to_your/", "subreddit_subscribers": 128818, "created_utc": 1694915750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI wanted to better understand how people are using ERD tools in their daily work.\n\nIf you have time I'd be really grateful if you could fill in this form asking some questions around if and how you're currently using ERD software :\n\n[https://forms.gle/c6CyrjhjtgACGQXy9](https://forms.gle/c6CyrjhjtgACGQXy9)\n\nThanks!", "author_fullname": "t2_a39uitkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ERD Tools - seeking feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k0wt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694848322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I wanted to better understand how people are using ERD tools in their daily work.&lt;/p&gt;\n\n&lt;p&gt;If you have time I&amp;#39;d be really grateful if you could fill in this form asking some questions around if and how you&amp;#39;re currently using ERD software :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://forms.gle/c6CyrjhjtgACGQXy9\"&gt;https://forms.gle/c6CyrjhjtgACGQXy9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?auto=webp&amp;s=e67bcfb8bbfbb6c787d641b669e44765dd1ee979", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=13172bd5fa8cda348a0de0bd74b16ea77d24fbdc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cca98ccacf26166b8529174a011189b08bb8f1ac", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3499f0e7a38234e5b2840a31acb9b911c11ef28a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b2898e0c9ab6439c0cb677fd29534557b81e294f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f90c96cdd409646b91ca24c9aea49479f3379fdc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a3a8d8a4e29ab700d0c2425462d767115e51f2d9", "width": 1080, "height": 567}], "variants": {}, "id": "tSVJF_x9Xgf_v7OmqQVgCGhK3gKuRoGGlx-CEgkuUMA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16k0wt1", "is_robot_indexable": true, "report_reasons": null, "author": "Tizniti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16k0wt1/erd_tools_seeking_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16k0wt1/erd_tools_seeking_feedback/", "subreddit_subscribers": 128818, "created_utc": 1694848322.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}