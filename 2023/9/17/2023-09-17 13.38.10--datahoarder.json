{"kind": "Listing", "data": {"after": "t3_16kgnr7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can de prevent this with a DataHoard?", "author_fullname": "t2_lxpfqyl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Incalculable Loss - Thousands of Classic Anime Are Close to Being Lost Forever", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16kd9kr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 327, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 327, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nY-wv-4TDM49A1qCjwI9whs-P42bkGith8crdqZsyYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694885814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "screenrant.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can de prevent this with a DataHoard?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://screenrant.com/classic-anime-lost-forever-tokyo-laboratory/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ghO57q9oZHt5sQ1h0IqRY5OwDp8oZNbQ5ZKhAwUG3K8.jpg?auto=webp&amp;s=8a608401d00c693567ebd1ba820ac1e0e51020e4", "width": 1400, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/ghO57q9oZHt5sQ1h0IqRY5OwDp8oZNbQ5ZKhAwUG3K8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c20edabeffe34768d0059b67cd9067016b776a8d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ghO57q9oZHt5sQ1h0IqRY5OwDp8oZNbQ5ZKhAwUG3K8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=87f2e3396e0953d52bac54adf95f711809edec17", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ghO57q9oZHt5sQ1h0IqRY5OwDp8oZNbQ5ZKhAwUG3K8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=135e3a8683467585c9cce664e03feaeb338ffa78", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ghO57q9oZHt5sQ1h0IqRY5OwDp8oZNbQ5ZKhAwUG3K8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=beec15ac30cf9cd56dda3d76af5eb557927bd5f1", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ghO57q9oZHt5sQ1h0IqRY5OwDp8oZNbQ5ZKhAwUG3K8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=864247ae7baa5b14c90d4c5a1bbb746670aec2e0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ghO57q9oZHt5sQ1h0IqRY5OwDp8oZNbQ5ZKhAwUG3K8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=231e3a5e8e18e61de7ce0fe5454a1f12152b81c3", "width": 1080, "height": 540}], "variants": {}, "id": "5evLg7bugmR_ZfUQLRXeflJJfhOqN3LLWnwcTgUcARg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kd9kr", "is_robot_indexable": true, "report_reasons": null, "author": "MOHdennisNL", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kd9kr/an_incalculable_loss_thousands_of_classic_anime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://screenrant.com/classic-anime-lost-forever-tokyo-laboratory/", "subreddit_subscribers": 702530, "created_utc": 1694885814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Comparing the eBay stores of ServerPartDeals and goHardDrive, why do people favor the former over the latter, despite the latter looking significantly better overall?\n\ngoHardDrive has a better positive feedback percentage (100% vs 99.7%), while selling over 4 times the volume. I know that the ServerPartDeals company also does business under Tech on Tech and Water Panther, but those are way less reputable. \n\nWhile ServerPartDeals offers 2 year warranty through their site, they only offer 1 year warranty, if you buy refurbished on eBay. Meanwhile, for around the same price, goHardDrive offers 5 year warranty. Both eBay stores have been open since 2005 and will likely stick around for longer (so warranty is something to take into account).\n\nOn this sub, I see ServerPartDeals a lot, but never goHardDrive. Why is this so?", "author_fullname": "t2_1kp811dz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there an specific reason why this sub favors Server Part Deals over goHardDrive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k8yjj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694874641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Comparing the eBay stores of ServerPartDeals and goHardDrive, why do people favor the former over the latter, despite the latter looking significantly better overall?&lt;/p&gt;\n\n&lt;p&gt;goHardDrive has a better positive feedback percentage (100% vs 99.7%), while selling over 4 times the volume. I know that the ServerPartDeals company also does business under Tech on Tech and Water Panther, but those are way less reputable. &lt;/p&gt;\n\n&lt;p&gt;While ServerPartDeals offers 2 year warranty through their site, they only offer 1 year warranty, if you buy refurbished on eBay. Meanwhile, for around the same price, goHardDrive offers 5 year warranty. Both eBay stores have been open since 2005 and will likely stick around for longer (so warranty is something to take into account).&lt;/p&gt;\n\n&lt;p&gt;On this sub, I see ServerPartDeals a lot, but never goHardDrive. Why is this so?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16k8yjj", "is_robot_indexable": true, "report_reasons": null, "author": "ThatsSoTrudeau", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16k8yjj/is_there_an_specific_reason_why_this_sub_favors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16k8yjj/is_there_an_specific_reason_why_this_sub_favors/", "subreddit_subscribers": 702530, "created_utc": 1694874641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Joined this sub a couple of days ago and I must say, I get it how repetitive it gets with some questions. Some of you are just absolute saints. The patience it takes to answer those repetitive questions knowing the post is gonna be deleted anyway is so much underappreciated. It's not even this sub but most other subs as well. Yall are angels to our confused souls.\n\nShoutout to those gentlemen and ladies!", "author_fullname": "t2_5eyz2f3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Appreciation Post", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k8ujn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "\u2665", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694874348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Joined this sub a couple of days ago and I must say, I get it how repetitive it gets with some questions. Some of you are just absolute saints. The patience it takes to answer those repetitive questions knowing the post is gonna be deleted anyway is so much underappreciated. It&amp;#39;s not even this sub but most other subs as well. Yall are angels to our confused souls.&lt;/p&gt;\n\n&lt;p&gt;Shoutout to those gentlemen and ladies!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16k8ujn", "is_robot_indexable": true, "report_reasons": null, "author": "Aegon2020", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16k8ujn/appreciation_post/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16k8ujn/appreciation_post/", "subreddit_subscribers": 702530, "created_utc": 1694874348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I just picked up a Asustor Lockstor 4 gen 2 which has 2.5gbe.  My desktop also has it which would be nice to leverage that speed if possible.  Do I spend about $100 on a 2.5gbe router or should I spring for a 10gbe for \u201cfutureproof\u201d?  \n\nI already have investments into Unifi, should I just get their 10gbe switch for $279 or whatever it is and spring for it?", "author_fullname": "t2_d65h6qka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Skip 2.5gbe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kqb71", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694921224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I just picked up a Asustor Lockstor 4 gen 2 which has 2.5gbe.  My desktop also has it which would be nice to leverage that speed if possible.  Do I spend about $100 on a 2.5gbe router or should I spring for a 10gbe for \u201cfutureproof\u201d?  &lt;/p&gt;\n\n&lt;p&gt;I already have investments into Unifi, should I just get their 10gbe switch for $279 or whatever it is and spring for it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kqb71", "is_robot_indexable": true, "report_reasons": null, "author": "Maciluminous", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kqb71/skip_25gbe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kqb71/skip_25gbe/", "subreddit_subscribers": 702530, "created_utc": 1694921224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have some old game-related websites, largely html, that I'd just like to back up in entirety. [Example](https://guides.gamercorner.net/ff/weapons/vorpal)\n\nDoes anyone have a good doc for how to get started on backing up websites like this? The priority is just to retain the data, I don't necessarily need the website to \"work\" locally. But I would like to retain that too, if possible.", "author_fullname": "t2_7t5o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any basic guides on how to back up a small website?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kk1z8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694903274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some old game-related websites, largely html, that I&amp;#39;d just like to back up in entirety. &lt;a href=\"https://guides.gamercorner.net/ff/weapons/vorpal\"&gt;Example&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Does anyone have a good doc for how to get started on backing up websites like this? The priority is just to retain the data, I don&amp;#39;t necessarily need the website to &amp;quot;work&amp;quot; locally. But I would like to retain that too, if possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5EGQUkpUPM3uwepxae38WuRqm_0970zYHFBQRXAncSI.jpg?auto=webp&amp;s=a2ada9abeb618f917c8f13fd83beb7e99d3cd3a0", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/5EGQUkpUPM3uwepxae38WuRqm_0970zYHFBQRXAncSI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7fb42e3fab6f75b3d7142357fcc7c4e18f140700", "width": 108, "height": 108}], "variants": {}, "id": "Z4KLyRlzmp1JjHF9FeImzCwDhbtkFzOfF1wmT8cvuCs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kk1z8", "is_robot_indexable": true, "report_reasons": null, "author": "KevinCarbonara", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kk1z8/are_there_any_basic_guides_on_how_to_back_up_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kk1z8/are_there_any_basic_guides_on_how_to_back_up_a/", "subreddit_subscribers": 702530, "created_utc": 1694903274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a ton of saved/bookmarked posts on Linkedin but I don't know the limit Linkedin sets for these. Sites like Reddit, restrict it to 1000 so I'm guessing it should be around the same but I couldn't find any information on that on the net. So I wanted to port this information elsewhere (preferably as bookmarks in Chrome). Do any of you know how to do this?", "author_fullname": "t2_hqgdk4x1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way to migrate saved/bookmarked posts on Linkedin?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16krdyl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694924812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a ton of saved/bookmarked posts on Linkedin but I don&amp;#39;t know the limit Linkedin sets for these. Sites like Reddit, restrict it to 1000 so I&amp;#39;m guessing it should be around the same but I couldn&amp;#39;t find any information on that on the net. So I wanted to port this information elsewhere (preferably as bookmarks in Chrome). Do any of you know how to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16krdyl", "is_robot_indexable": true, "report_reasons": null, "author": "PenguinHegemony", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16krdyl/is_there_any_way_to_migrate_savedbookmarked_posts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16krdyl/is_there_any_way_to_migrate_savedbookmarked_posts/", "subreddit_subscribers": 702530, "created_utc": 1694924812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Archive.today has been down for the last 24 hours or so, anyone know why that is?", "author_fullname": "t2_llgyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know why Archive.today is down?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kq9pn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694921088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Archive.today has been down for the last 24 hours or so, anyone know why that is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kq9pn", "is_robot_indexable": true, "report_reasons": null, "author": "he3544", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16kq9pn/does_anyone_know_why_archivetoday_is_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kq9pn/does_anyone_know_why_archivetoday_is_down/", "subreddit_subscribers": 702530, "created_utc": 1694921088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been \"hoarding\" data for a while, but I'm fairly new to a lot of concepts that are discussed here, like data-protection practices (redunancy, rendundancies for your redundancies, drive health checks with 3rd party software, etc) -- the one I'd like to ask about is replacing your storage drives altogether (specifically HDDs). \n\nMy understanding is it's important to replace your hard disk drives every 5 years or so, since like with batteries and appliances they are not designed to last forever. Well, I've had a couple cheap-ish 2TB HDDs in my PC for about 8 years now; both work fine, though 1 tends to make a click-ity racket when it revs up (this started 1-2 years ago). I mostly just use my SSDs now, so the HDDs have been demoted to storage of old ebooks and such; most days my HDDs don't even get accessed, and therefore lay dormant for days, or even weeks at a time, so maybe the lack of wear and tear is why they've been so reliable for 8+ years\n\nSo here's my question: can I wait to replace my HDDs until they start becoming unreliable, or showing errors/signs of failure? Or is this playing a dangerous game with the fate of the data on the drives? My assumption was that in a worst-case scenario, the drive would just crap out some day and I'd have to have its data professionally recovered by geek squad or something; not having had to deal with this yet, personally, I don't know if failed drive data recovery has a reasonable rate of success.\n\nWhat are your thoughts, and what's your policy on replacing hard drives? If you'd like to share your personal experiences with semi-failed drives, completely dead drives, or recovery, etc. I would really appreciate it as it'd be educational for me and inform my decisions on the issue! Thanks!!", "author_fullname": "t2_nrowderg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replacing your drives: Routinely or as-needed basis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kf8n7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694890998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been &amp;quot;hoarding&amp;quot; data for a while, but I&amp;#39;m fairly new to a lot of concepts that are discussed here, like data-protection practices (redunancy, rendundancies for your redundancies, drive health checks with 3rd party software, etc) -- the one I&amp;#39;d like to ask about is replacing your storage drives altogether (specifically HDDs). &lt;/p&gt;\n\n&lt;p&gt;My understanding is it&amp;#39;s important to replace your hard disk drives every 5 years or so, since like with batteries and appliances they are not designed to last forever. Well, I&amp;#39;ve had a couple cheap-ish 2TB HDDs in my PC for about 8 years now; both work fine, though 1 tends to make a click-ity racket when it revs up (this started 1-2 years ago). I mostly just use my SSDs now, so the HDDs have been demoted to storage of old ebooks and such; most days my HDDs don&amp;#39;t even get accessed, and therefore lay dormant for days, or even weeks at a time, so maybe the lack of wear and tear is why they&amp;#39;ve been so reliable for 8+ years&lt;/p&gt;\n\n&lt;p&gt;So here&amp;#39;s my question: can I wait to replace my HDDs until they start becoming unreliable, or showing errors/signs of failure? Or is this playing a dangerous game with the fate of the data on the drives? My assumption was that in a worst-case scenario, the drive would just crap out some day and I&amp;#39;d have to have its data professionally recovered by geek squad or something; not having had to deal with this yet, personally, I don&amp;#39;t know if failed drive data recovery has a reasonable rate of success.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts, and what&amp;#39;s your policy on replacing hard drives? If you&amp;#39;d like to share your personal experiences with semi-failed drives, completely dead drives, or recovery, etc. I would really appreciate it as it&amp;#39;d be educational for me and inform my decisions on the issue! Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kf8n7", "is_robot_indexable": true, "report_reasons": null, "author": "jtbrownell", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kf8n7/replacing_your_drives_routinely_or_asneeded_basis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kf8n7/replacing_your_drives_routinely_or_asneeded_basis/", "subreddit_subscribers": 702530, "created_utc": 1694890998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Saw this on Hackaday.\n\n[https://hackaday.com/2023/09/08/cerabyte-one-terabyte-per-square-centimeter/](https://hackaday.com/2023/09/08/cerabyte-one-terabyte-per-square-centimeter/)\n\nThe company\n\n[https://www.cerabyte.com/](https://www.cerabyte.com/)\n\nHow long until everybody can Archive whatever on glass pieces and have them shipped to him/her? The readout part seams more diy friendly. Just spend a lot of money on a good microscope. Would make hard drives more or less obsolete for long term cold archives.\n\nI tried to find out, how the technology actually works in detail, but could not find anything.\n\nWhat other similar technologies/companies are out there? \n\nI know for quite some money you can store data on cinema film with a claimed 300 year lifespan, but with very low data density.\n\n&amp;#x200B;", "author_fullname": "t2_18p3nf14", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long until somebody DIYs something like this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kbg8k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694881089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Saw this on Hackaday.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://hackaday.com/2023/09/08/cerabyte-one-terabyte-per-square-centimeter/\"&gt;https://hackaday.com/2023/09/08/cerabyte-one-terabyte-per-square-centimeter/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The company&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.cerabyte.com/\"&gt;https://www.cerabyte.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;How long until everybody can Archive whatever on glass pieces and have them shipped to him/her? The readout part seams more diy friendly. Just spend a lot of money on a good microscope. Would make hard drives more or less obsolete for long term cold archives.&lt;/p&gt;\n\n&lt;p&gt;I tried to find out, how the technology actually works in detail, but could not find anything.&lt;/p&gt;\n\n&lt;p&gt;What other similar technologies/companies are out there? &lt;/p&gt;\n\n&lt;p&gt;I know for quite some money you can store data on cinema film with a claimed 300 year lifespan, but with very low data density.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Budwq1tXFXQtVtcRqnUsd5skqoJL8ll8ad3qhfhFFy8.jpg?auto=webp&amp;s=1e8b8a74df325770c673844a233f2ad3023fa0c8", "width": 1600, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/Budwq1tXFXQtVtcRqnUsd5skqoJL8ll8ad3qhfhFFy8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf1bacf7c296ed77c4efc24787855a6b78590f85", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Budwq1tXFXQtVtcRqnUsd5skqoJL8ll8ad3qhfhFFy8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8edff01e5a1c0064c47ace5c5dde8e49eb7ecbd3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Budwq1tXFXQtVtcRqnUsd5skqoJL8ll8ad3qhfhFFy8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=742f7277a587de67a1b78a7ecb556c2a8743f448", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Budwq1tXFXQtVtcRqnUsd5skqoJL8ll8ad3qhfhFFy8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=50902f273d1026ffc0760750b27101bb5f99037d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Budwq1tXFXQtVtcRqnUsd5skqoJL8ll8ad3qhfhFFy8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=13d19dd464401b4ff1a22b9a659816f1a6958ea3", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Budwq1tXFXQtVtcRqnUsd5skqoJL8ll8ad3qhfhFFy8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4691efe5a13288f099093babf406171bd13c0f23", "width": 1080, "height": 540}], "variants": {}, "id": "Ofb465u0D7CkCans_-TiAWniFB00ALEjFduyxTAMG7U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16kbg8k", "is_robot_indexable": true, "report_reasons": null, "author": "thx997", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kbg8k/how_long_until_somebody_diys_something_like_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kbg8k/how_long_until_somebody_diys_something_like_this/", "subreddit_subscribers": 702530, "created_utc": 1694881089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_w2ys9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New York Times Doesn\u2019t Want Its Stories Archived", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16kxk6k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/yKBux5KnXp2qs8xERTFq19WkJ81QXB7zs0bCoe669V0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694947751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theintercept.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://theintercept.com/2023/09/17/new-york-times-website-internet-archive/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vpnhKqBnxMfDqh6k2loL3cYriW9fl9jmAA09ZFAtosg.jpg?auto=webp&amp;s=dbc7882ee14f8543d382389568690f629f09f424", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/vpnhKqBnxMfDqh6k2loL3cYriW9fl9jmAA09ZFAtosg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe6128fb0ed328f0d4e151101af383176dde1940", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/vpnhKqBnxMfDqh6k2loL3cYriW9fl9jmAA09ZFAtosg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cde3d1d79a3501d0e3d02de944292dccc170e02e", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/vpnhKqBnxMfDqh6k2loL3cYriW9fl9jmAA09ZFAtosg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4008c096c80a0967d49cfc7b39bc3bd4775dfd09", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/vpnhKqBnxMfDqh6k2loL3cYriW9fl9jmAA09ZFAtosg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4cc5680180142cf7f199eb155de81c77ff7919f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/vpnhKqBnxMfDqh6k2loL3cYriW9fl9jmAA09ZFAtosg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7e83180e976fbc8df569aaee83e17a94db1860fa", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/vpnhKqBnxMfDqh6k2loL3cYriW9fl9jmAA09ZFAtosg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=63640bc534e345e4ec639688ce93b61f1b501fe1", "width": 1080, "height": 540}], "variants": {}, "id": "7JXTdtcS16ra-8VEZP_UKrbYsLAIJsxyLt-CkKk2u0w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kxk6k", "is_robot_indexable": true, "report_reasons": null, "author": "777fer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kxk6k/new_york_times_doesnt_want_its_stories_archived/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://theintercept.com/2023/09/17/new-york-times-website-internet-archive/", "subreddit_subscribers": 702530, "created_utc": 1694947751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently bought an additional external hard drive and noticed it was preformatted into two partitions, a 200MB EFI System Partition, and a exFAT Basic Data Partition. From what I understand the EFI System Partition is if I ever want to boot from the drive, and it being in exFAT was for MAC compatible. Each of my other external hard drives are in just one NTFS Basic Data Partition. I don't ever plan to boot off of it, just store bulk files.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/skbe6ufxhrob1.jpg?width=2557&amp;format=pjpg&amp;auto=webp&amp;s=4e641a136bd5a72aad1b9a3a4e1f9d5afb62cfc0\n\nI was wondering on a few options,\n\n&amp;#x200B;\n\n1. Is it worth it to delete both partitions and format it to a single NTFS Basic Data Partition (If so, can I do all that in Windows 10)? I never plan on it being used on a MAC.\n2. Keep the EFI System Partition and format the exFAT Basic Data Partition to NTFS.\n3. Leave it as is.\n\n&amp;#x200B;\n\nThanks for any advice.", "author_fullname": "t2_ov1ou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EFI System Partition on external hard drive.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 5, "top_awarded_type": null, "hide_score": false, "media_metadata": {"skbe6ufxhrob1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 4, "x": 108, "u": "https://preview.redd.it/skbe6ufxhrob1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0354486284a6551b2977636db70046bc36592b79"}, {"y": 8, "x": 216, "u": "https://preview.redd.it/skbe6ufxhrob1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ceed81cd9dfa50aaf4914dfc3a83f5a5649b6e8"}, {"y": 11, "x": 320, "u": "https://preview.redd.it/skbe6ufxhrob1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2422848b284da4e17fc4f914d60258ec488bfcd1"}, {"y": 23, "x": 640, "u": "https://preview.redd.it/skbe6ufxhrob1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a7761534f91a12c8c44b9a5b8afdac9f50ce432f"}, {"y": 35, "x": 960, "u": "https://preview.redd.it/skbe6ufxhrob1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f2d9c92faaa9490d21a4e89a3790fa59347f5dc3"}, {"y": 40, "x": 1080, "u": "https://preview.redd.it/skbe6ufxhrob1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49a9500c2da1843f32de101477e2859db9a97bee"}], "s": {"y": 95, "x": 2557, "u": "https://preview.redd.it/skbe6ufxhrob1.jpg?width=2557&amp;format=pjpg&amp;auto=webp&amp;s=4e641a136bd5a72aad1b9a3a4e1f9d5afb62cfc0"}, "id": "skbe6ufxhrob1"}}, "name": "t3_16ktnsz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lza3k9bPvv0Z69_56oy5z_92P2K-3ixLvpz-U0dMs_w.jpg", "edited": 1694934033.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694933142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently bought an additional external hard drive and noticed it was preformatted into two partitions, a 200MB EFI System Partition, and a exFAT Basic Data Partition. From what I understand the EFI System Partition is if I ever want to boot from the drive, and it being in exFAT was for MAC compatible. Each of my other external hard drives are in just one NTFS Basic Data Partition. I don&amp;#39;t ever plan to boot off of it, just store bulk files.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/skbe6ufxhrob1.jpg?width=2557&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4e641a136bd5a72aad1b9a3a4e1f9d5afb62cfc0\"&gt;https://preview.redd.it/skbe6ufxhrob1.jpg?width=2557&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4e641a136bd5a72aad1b9a3a4e1f9d5afb62cfc0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I was wondering on a few options,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is it worth it to delete both partitions and format it to a single NTFS Basic Data Partition (If so, can I do all that in Windows 10)? I never plan on it being used on a MAC.&lt;/li&gt;\n&lt;li&gt;Keep the EFI System Partition and format the exFAT Basic Data Partition to NTFS.&lt;/li&gt;\n&lt;li&gt;Leave it as is.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ktnsz", "is_robot_indexable": true, "report_reasons": null, "author": "poopyface-tomatonose", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ktnsz/efi_system_partition_on_external_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ktnsz/efi_system_partition_on_external_hard_drive/", "subreddit_subscribers": 702530, "created_utc": 1694933142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m preferencing this by saying the first part made me think of the question I\u2019m trying to give a tad bit of context on how I came up with a crazy question.\n\nSo I download a good amount of pictures and videos from my Amazon account to have at home and sometimes the vm dies on me marking the damn app redownload everything again which doesn\u2019t make sense but that is not the question.  It made me think would a surveillance hdd that is meant to be constantly written to be a good download drive for my sonarr and what not and use nas drives for the archive and storage per say of everything ?", "author_fullname": "t2_3ffp78kr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A hard drive question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kpb6f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694918023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m preferencing this by saying the first part made me think of the question I\u2019m trying to give a tad bit of context on how I came up with a crazy question.&lt;/p&gt;\n\n&lt;p&gt;So I download a good amount of pictures and videos from my Amazon account to have at home and sometimes the vm dies on me marking the damn app redownload everything again which doesn\u2019t make sense but that is not the question.  It made me think would a surveillance hdd that is meant to be constantly written to be a good download drive for my sonarr and what not and use nas drives for the archive and storage per say of everything ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "22tb TrueNas", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kpb6f", "is_robot_indexable": true, "report_reasons": null, "author": "Affectionate_Use8825", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16kpb6f/a_hard_drive_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kpb6f/a_hard_drive_question/", "subreddit_subscribers": 702530, "created_utc": 1694918023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm moving a large amount of data to a new drive with more space, and many of the files are hardlinked to each other.  In the copy process I want to ensure the hardlink structure is maintained, instead of hardlinked files being copied as separate files (which would greatly increase the total space used by duplicating files unecessarily).  I'd also like a way to verify that that the destination files match the originals and no errors were made.  Ideally it would also be something that could be resumed I'd the process is interrupted, as it's a big job and will take some time.\n\nI'm on windows and have been using teracopy, because I like it's ability to verify each file and pause/resume, but it doesn't seem to have an option to preserve hardlinks.  I would prefer a windows solution if possible, but can do linux if necessary, I'm just not very good at linux.\n\nHas anyone used a tool that successfully preserves hardlinks on a large copy job?", "author_fullname": "t2_11hqze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplest way to copy data to a new drive and preserve hardlinks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kmywz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694911040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m moving a large amount of data to a new drive with more space, and many of the files are hardlinked to each other.  In the copy process I want to ensure the hardlink structure is maintained, instead of hardlinked files being copied as separate files (which would greatly increase the total space used by duplicating files unecessarily).  I&amp;#39;d also like a way to verify that that the destination files match the originals and no errors were made.  Ideally it would also be something that could be resumed I&amp;#39;d the process is interrupted, as it&amp;#39;s a big job and will take some time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on windows and have been using teracopy, because I like it&amp;#39;s ability to verify each file and pause/resume, but it doesn&amp;#39;t seem to have an option to preserve hardlinks.  I would prefer a windows solution if possible, but can do linux if necessary, I&amp;#39;m just not very good at linux.&lt;/p&gt;\n\n&lt;p&gt;Has anyone used a tool that successfully preserves hardlinks on a large copy job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kmywz", "is_robot_indexable": true, "report_reasons": null, "author": "Illeazar", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kmywz/simplest_way_to_copy_data_to_a_new_drive_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kmywz/simplest_way_to_copy_data_to_a_new_drive_and/", "subreddit_subscribers": 702530, "created_utc": 1694911040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently picked up an Optiplex 7010 MT and a couple of 16TB Toshiba N300s for a new NAS. I had a 128GB SSD laying around that I put in for the OS.  \n    \nFor some reason, the bios only detects the N300s intermittently. When they are detected, I'm able to boot into TrueNas Core and they work fine. I created a pool and transferred a few GBs without issue.  \n    \nThings I've tried:  \n- Using different SATA ports and cables  \n- Using the SATA power / cable the SSD was using  \n- Plugging the SSD into the ports / cables the N300s were using  \n- Using only 1 of the drives at a time  \n- Updating the BIOS to version A29  \n- Switching between \"SATA\" mode and \"ACHI\"  \n- Switching between \"BIOS\" and \"UEFI\"  \n    \nThe SDD and all USB drives I've used are detected every time. Also, the bios either detects both N300s or neither. I haven't seen it only pick up 1 drive.  \n  \nAny ideas or suggestions here would be great, because I'm out of them.", "author_fullname": "t2_2zur6r36", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dell Optiplex 7010 Intermittent Recognition of Large Drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kf07x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694891203.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694890384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently picked up an Optiplex 7010 MT and a couple of 16TB Toshiba N300s for a new NAS. I had a 128GB SSD laying around that I put in for the OS.  &lt;/p&gt;\n\n&lt;p&gt;For some reason, the bios only detects the N300s intermittently. When they are detected, I&amp;#39;m able to boot into TrueNas Core and they work fine. I created a pool and transferred a few GBs without issue.  &lt;/p&gt;\n\n&lt;p&gt;Things I&amp;#39;ve tried:&lt;br/&gt;\n- Using different SATA ports and cables&lt;br/&gt;\n- Using the SATA power / cable the SSD was using&lt;br/&gt;\n- Plugging the SSD into the ports / cables the N300s were using&lt;br/&gt;\n- Using only 1 of the drives at a time&lt;br/&gt;\n- Updating the BIOS to version A29&lt;br/&gt;\n- Switching between &amp;quot;SATA&amp;quot; mode and &amp;quot;ACHI&amp;quot;&lt;br/&gt;\n- Switching between &amp;quot;BIOS&amp;quot; and &amp;quot;UEFI&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;The SDD and all USB drives I&amp;#39;ve used are detected every time. Also, the bios either detects both N300s or neither. I haven&amp;#39;t seen it only pick up 1 drive.  &lt;/p&gt;\n\n&lt;p&gt;Any ideas or suggestions here would be great, because I&amp;#39;m out of them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kf07x", "is_robot_indexable": true, "report_reasons": null, "author": "JayLandish", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kf07x/dell_optiplex_7010_intermittent_recognition_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kf07x/dell_optiplex_7010_intermittent_recognition_of/", "subreddit_subscribers": 702530, "created_utc": 1694890384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Recently I bought two different models of hard drive in order to compare their noise level. After I chose which one to keep, I formatted and returned the other hard drive that I didn't need to the vendor. (and stated that it was not returned due to a defect.)\n\nBut now I'm wondering what happens to the perfectly functional hard drive I returned. \n\nWill it be destroyed? \n\nReturned to the manufacturer and then sold as refurbished? \n\nOr just be put into new packaging by the vendor? \n\nI would feel really guilty if the perfectly functional hard drive is destroyed or refurbished needlessly. Not only because it's a waste but also the cost to the vendor. The only thing it needs is a new anti-static bag and format of the file system.", "author_fullname": "t2_3ka8sash", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happens to FUNCTIONAL returned hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kerip", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694889757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently I bought two different models of hard drive in order to compare their noise level. After I chose which one to keep, I formatted and returned the other hard drive that I didn&amp;#39;t need to the vendor. (and stated that it was not returned due to a defect.)&lt;/p&gt;\n\n&lt;p&gt;But now I&amp;#39;m wondering what happens to the perfectly functional hard drive I returned. &lt;/p&gt;\n\n&lt;p&gt;Will it be destroyed? &lt;/p&gt;\n\n&lt;p&gt;Returned to the manufacturer and then sold as refurbished? &lt;/p&gt;\n\n&lt;p&gt;Or just be put into new packaging by the vendor? &lt;/p&gt;\n\n&lt;p&gt;I would feel really guilty if the perfectly functional hard drive is destroyed or refurbished needlessly. Not only because it&amp;#39;s a waste but also the cost to the vendor. The only thing it needs is a new anti-static bag and format of the file system.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kerip", "is_robot_indexable": true, "report_reasons": null, "author": "GroundBreakingRow72", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kerip/what_happens_to_functional_returned_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kerip/what_happens_to_functional_returned_hard_drives/", "subreddit_subscribers": 702530, "created_utc": 1694889757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What are the best HDDs for a NAS? I'm trying to save some money by using used drives.\n\nIs ***HGST Ultrastar 7K4000 HUS724040ALE641 4TB 64MB Cache 7200RPM SATA III 6.0Gb/s 3.5*** a good choice? ", "author_fullname": "t2_i5ldbq630", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for used HDDs for a NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kdo1h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694886889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best HDDs for a NAS? I&amp;#39;m trying to save some money by using used drives.&lt;/p&gt;\n\n&lt;p&gt;Is &lt;strong&gt;&lt;em&gt;HGST Ultrastar 7K4000 HUS724040ALE641 4TB 64MB Cache 7200RPM SATA III 6.0Gb/s 3.5&lt;/em&gt;&lt;/strong&gt; a good choice? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "12TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kdo1h", "is_robot_indexable": true, "report_reasons": null, "author": "Material-XS", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16kdo1h/recommendations_for_used_hdds_for_a_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kdo1h/recommendations_for_used_hdds_for_a_nas/", "subreddit_subscribers": 702530, "created_utc": 1694886889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm out of SATA connectors and looking to add several more hard drives to my build.  \n\nI asked about PCIe SATA expansion card [yesterday](https://www.reddit.com/r/DataHoarder/comments/16jtyy0/what_factors_should_i_consider_when_selecting_a/), and some helpful folks told me in no uncertain terms that what I needed was an LSI SAS HBA.  \n\nI'm currently looking at [this](https://www.amazon.com/gp/product/B0BVTJPZSG) or [this](https://www.amazon.com/SXTAIGOOD-9211-8i-6Gbps-HBA-LSI/dp/B0BWY1VH3V). [This](https://www.ebay.com/itm/153073494030) also looks like it would do, but the low price makes me think I might be overlooking something.\n\nAny potential pitfalls in those options?  How much should I expect to pay for something of reasonable quality?  I'm not running a datacenter here, but I do want to build something reliable.  \n\nAlso, does PCIe 2.0 vs 3.0 matter for my purposes?  Someone yesterday [suggested](https://www.reddit.com/r/DataHoarder/comments/16jtyy0/what_factors_should_i_consider_when_selecting_a/k0sg3t1/) an older SAS2008.  Any concerns about using that instead of something newer?\n\nAny other general advice?\n\n---\n\nEDIT - Some additional details about my NAS box, since folks are asking.  I recently built a new machine and then  rebuilt my old one in a new case as a server, so this is pretty outdated stuff.\n\n**Hardware:**\n\n* Case: Fractal Design Meshify 2\n* Motherboard: ASRock Z77 Extreme 4\n* CPU: Intel i5-3570k, 4 cores @ 3.4 GHz\n* RAM: 32 GB DDR3 @ 1866 MHz\n\n**Drives:**\n\n* 128 GB SSD (Ancient SanDisk, running my TrueNAS OS)\n\n* 2 4TB HDDs (Both Western Digital Greens)\n\n* 2 6TB HDDs (1 Western Digital Green, 1 Western Digital Blue)\n\n* 2 12TB HDDs (Western Digital, model unknown, soon to be shucked from their Elements external drive enclosures)\n\n* 2 22TB HDDs (Both Western Digital Red Pros.  Obviously the core of my storage system!)\n\n* 1 500 GB SSD (Ancient Samsung, just because I have nowhere else to put it)", "author_fullname": "t2_vqak2uq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice for adding more hard drives to my first NAS build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k8mzu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694876894.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694873781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m out of SATA connectors and looking to add several more hard drives to my build.  &lt;/p&gt;\n\n&lt;p&gt;I asked about PCIe SATA expansion card &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/16jtyy0/what_factors_should_i_consider_when_selecting_a/\"&gt;yesterday&lt;/a&gt;, and some helpful folks told me in no uncertain terms that what I needed was an LSI SAS HBA.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking at &lt;a href=\"https://www.amazon.com/gp/product/B0BVTJPZSG\"&gt;this&lt;/a&gt; or &lt;a href=\"https://www.amazon.com/SXTAIGOOD-9211-8i-6Gbps-HBA-LSI/dp/B0BWY1VH3V\"&gt;this&lt;/a&gt;. &lt;a href=\"https://www.ebay.com/itm/153073494030\"&gt;This&lt;/a&gt; also looks like it would do, but the low price makes me think I might be overlooking something.&lt;/p&gt;\n\n&lt;p&gt;Any potential pitfalls in those options?  How much should I expect to pay for something of reasonable quality?  I&amp;#39;m not running a datacenter here, but I do want to build something reliable.  &lt;/p&gt;\n\n&lt;p&gt;Also, does PCIe 2.0 vs 3.0 matter for my purposes?  Someone yesterday &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/16jtyy0/what_factors_should_i_consider_when_selecting_a/k0sg3t1/\"&gt;suggested&lt;/a&gt; an older SAS2008.  Any concerns about using that instead of something newer?&lt;/p&gt;\n\n&lt;p&gt;Any other general advice?&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;EDIT - Some additional details about my NAS box, since folks are asking.  I recently built a new machine and then  rebuilt my old one in a new case as a server, so this is pretty outdated stuff.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Hardware:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Case: Fractal Design Meshify 2&lt;/li&gt;\n&lt;li&gt;Motherboard: ASRock Z77 Extreme 4&lt;/li&gt;\n&lt;li&gt;CPU: Intel i5-3570k, 4 cores @ 3.4 GHz&lt;/li&gt;\n&lt;li&gt;RAM: 32 GB DDR3 @ 1866 MHz&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Drives:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;128 GB SSD (Ancient SanDisk, running my TrueNAS OS)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;2 4TB HDDs (Both Western Digital Greens)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;2 6TB HDDs (1 Western Digital Green, 1 Western Digital Blue)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;2 12TB HDDs (Western Digital, model unknown, soon to be shucked from their Elements external drive enclosures)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;2 22TB HDDs (Both Western Digital Red Pros.  Obviously the core of my storage system!)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;1 500 GB SSD (Ancient Samsung, just because I have nowhere else to put it)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16k8mzu", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyForSomeThings", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16k8mzu/seeking_advice_for_adding_more_hard_drives_to_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16k8mzu/seeking_advice_for_adding_more_hard_drives_to_my/", "subreddit_subscribers": 702530, "created_utc": 1694873781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been having big slowdowns from unraid recently and am going to try truenas instead since I don't need alot of the unraid features anyway. However this means moving all my storage off of the unraid box and onto a single drive. What's my best software for this? Stick the drive in the unraid box and use ___ or put it in a networked box and use rsync or ____ ?\n\nWould love to hear your recommendations!", "author_fullname": "t2_jybuw5nh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File migration from UnRaid to single HD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16kzbbd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694953334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been having big slowdowns from unraid recently and am going to try truenas instead since I don&amp;#39;t need alot of the unraid features anyway. However this means moving all my storage off of the unraid box and onto a single drive. What&amp;#39;s my best software for this? Stick the drive in the unraid box and use ___ or put it in a networked box and use rsync or ____ ?&lt;/p&gt;\n\n&lt;p&gt;Would love to hear your recommendations!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kzbbd", "is_robot_indexable": true, "report_reasons": null, "author": "adv3ntur3_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kzbbd/file_migration_from_unraid_to_single_hd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kzbbd/file_migration_from_unraid_to_single_hd/", "subreddit_subscribers": 702530, "created_utc": 1694953334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello\n\nI have few old IDE drives. How to connect them to modern desktop PC to copy data or create image? Most of cheap adapter have problems like drive is not recognizable or work very slow. What do you recommend?", "author_fullname": "t2_c1a06oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which IDE adapter buy to copy data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kxuok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694948731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I have few old IDE drives. How to connect them to modern desktop PC to copy data or create image? Most of cheap adapter have problems like drive is not recognizable or work very slow. What do you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kxuok", "is_robot_indexable": true, "report_reasons": null, "author": "locarnos", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kxuok/which_ide_adapter_buy_to_copy_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kxuok/which_ide_adapter_buy_to_copy_data/", "subreddit_subscribers": 702530, "created_utc": 1694948731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, \n\nI tried downloading [erowid.org](https://erowid.org) with wget but i only got blocked by the site. \n\nI used this:  wget --mirror --convert-links --adjust-extension --page-requisites --no-clobber --no-parent --domains erowid.org [http://www.erowid.org](http://www.erowid.org/) \n\nAfter 20 minutes of downloading i get blocked every time. Does anyone have the entire site downloaded and can share it. Or does anyone know how to improve the wget download so i dont get blocked.\n\nThanks", "author_fullname": "t2_cbrfrfql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download entire Erowid Vault with functional navigation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kxkmq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694947801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;I tried downloading &lt;a href=\"https://erowid.org\"&gt;erowid.org&lt;/a&gt; with wget but i only got blocked by the site. &lt;/p&gt;\n\n&lt;p&gt;I used this:  wget --mirror --convert-links --adjust-extension --page-requisites --no-clobber --no-parent --domains erowid.org &lt;a href=\"http://www.erowid.org/\"&gt;http://www.erowid.org&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;After 20 minutes of downloading i get blocked every time. Does anyone have the entire site downloaded and can share it. Or does anyone know how to improve the wget download so i dont get blocked.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kxkmq", "is_robot_indexable": true, "report_reasons": null, "author": "Okoknogga", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kxkmq/download_entire_erowid_vault_with_functional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kxkmq/download_entire_erowid_vault_with_functional/", "subreddit_subscribers": 702530, "created_utc": 1694947801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey!\n\nI have started an experiment for archiving websites on your own server! The initial thought that started it was \"what if [web.archive.org](https://web.archive.org) (the Internet Archive) shuts down?\", which led me to the idea of making a web archiving system that duplicates itself onto others' servers and also communicates with other servers (1. The system has built-in instructions for setting it up somewhere else, and 2. If you search for archived files on one server, it also searches for files on all the other servers - assuming I come up with a good system for keeping all servers updated on which servers that exists, kind of like the \"hosts.txt\" file in the 80s that pre-dated DNS).\n\nMy server is on:\n\n[https://kissobajs.se/saved](https://kissobajs.se/saved)\n\nAnd it contains instruction for setting up the system on your own server. It's super simple, BUT it requires PHP and an already working web server (so no, no Docker). Right now it's made to only save HTML files, so it's very simple but I think that could make it powerful. And, if you think the site looks ugly, yes it may be, the most important thing here is for the system to have robust code without anything unnecessary, so it can be stable in communicating with \"itself\" on other servers for a long time.\n\nSo, what do you think? Could this be useful for any of you?", "author_fullname": "t2_hf9niuda", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An idea for a decentralized archive system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kr4fq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694923888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey!&lt;/p&gt;\n\n&lt;p&gt;I have started an experiment for archiving websites on your own server! The initial thought that started it was &amp;quot;what if &lt;a href=\"https://web.archive.org\"&gt;web.archive.org&lt;/a&gt; (the Internet Archive) shuts down?&amp;quot;, which led me to the idea of making a web archiving system that duplicates itself onto others&amp;#39; servers and also communicates with other servers (1. The system has built-in instructions for setting it up somewhere else, and 2. If you search for archived files on one server, it also searches for files on all the other servers - assuming I come up with a good system for keeping all servers updated on which servers that exists, kind of like the &amp;quot;hosts.txt&amp;quot; file in the 80s that pre-dated DNS).&lt;/p&gt;\n\n&lt;p&gt;My server is on:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://kissobajs.se/saved\"&gt;https://kissobajs.se/saved&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And it contains instruction for setting up the system on your own server. It&amp;#39;s super simple, BUT it requires PHP and an already working web server (so no, no Docker). Right now it&amp;#39;s made to only save HTML files, so it&amp;#39;s very simple but I think that could make it powerful. And, if you think the site looks ugly, yes it may be, the most important thing here is for the system to have robust code without anything unnecessary, so it can be stable in communicating with &amp;quot;itself&amp;quot; on other servers for a long time.&lt;/p&gt;\n\n&lt;p&gt;So, what do you think? Could this be useful for any of you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kr4fq", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Ad_7821", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kr4fq/an_idea_for_a_decentralized_archive_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kr4fq/an_idea_for_a_decentralized_archive_system/", "subreddit_subscribers": 702530, "created_utc": 1694923888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Link to the 8i](https://www.amazon.com/gp/product/B0C16QHJTZ/) for $105,  [link to the 16i](https://www.amazon.com/gp/product/B0C6T5ZLPL) for $120.  \n\nThese are both 12Gbps PCIe 3.0 cards, so it seems fishy to me that they're so close in price. \n\nAt face value, obviously the 16i is the better deal, right?  Am I missing something here?", "author_fullname": "t2_vqak2uq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Found a 16i LSI HBA for only a few dollars more than an 8i. Seems too good to be true?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16koe8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694915265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.com/gp/product/B0C16QHJTZ/\"&gt;Link to the 8i&lt;/a&gt; for $105,  &lt;a href=\"https://www.amazon.com/gp/product/B0C6T5ZLPL\"&gt;link to the 16i&lt;/a&gt; for $120.  &lt;/p&gt;\n\n&lt;p&gt;These are both 12Gbps PCIe 3.0 cards, so it seems fishy to me that they&amp;#39;re so close in price. &lt;/p&gt;\n\n&lt;p&gt;At face value, obviously the 16i is the better deal, right?  Am I missing something here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16koe8m", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyForSomeThings", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16koe8m/found_a_16i_lsi_hba_for_only_a_few_dollars_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16koe8m/found_a_16i_lsi_hba_for_only_a_few_dollars_more/", "subreddit_subscribers": 702530, "created_utc": 1694915265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i was using the twitter downloader extensions since forever but it has since been discontinued so im asking if anybody knows any other program or extensions to mass download all media from twitter profiles i don't really need anything else just the images and videos. if tried wfdownloader but all i get is 404 error message and even if i did i don't like how they put the date before anything else i perfer author followed by name", "author_fullname": "t2_e3442br6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "download all twitter images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kjykz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694903043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i was using the twitter downloader extensions since forever but it has since been discontinued so im asking if anybody knows any other program or extensions to mass download all media from twitter profiles i don&amp;#39;t really need anything else just the images and videos. if tried wfdownloader but all i get is 404 error message and even if i did i don&amp;#39;t like how they put the date before anything else i perfer author followed by name&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kjykz", "is_robot_indexable": true, "report_reasons": null, "author": "2qup20", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kjykz/download_all_twitter_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kjykz/download_all_twitter_images/", "subreddit_subscribers": 702530, "created_utc": 1694903043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nI have a massive amount of data that I have accumulated on a NAS. I am currently in the process of copying all of this data to a second NAS in a different physical location as an off-site backup. To do this, I am using Teracopy, and the devices are communicating with each other over a Tailscale network.\n\nThe copying process itself has been pretty robust, and unlike Windows' built-in file transferring, TeraCopy seems to be able to handle transient network interruptions without just straight up failing.\n\nBut when I tried to use TeraCopy to \\*verify\\* the copied files, it is insanely tedious. Because more often than not, verification fails due to an unknown network error. Unlike copying, verifying seems to not have any resilience to interruptions, and it's rare to be able to get through a 5GB+ file without one of them hitting. But what is interesting is that if I just keep running through the verification process over and over for a given batch after copying, only repeating on the files where the unknown error caused verification to fail, it will eventually work. And several hundred files in, I haven't hit a single instance where verification wasn't successful as long as it pushes through between network errors.\n\nSo my question is this. How critical \\*is\\* verification in a situation like this? Is it safe to assume that, as long as TeraCopy makes it through the copy process itself without throwing an error, the files are sound? Or do I really need to play it safe by running through the verification process (which sometimes takes more than a dozen tries per file) every time?", "author_fullname": "t2_ib5ir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about copy integrity and the necessity of validation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kgyde", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694895507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I have a massive amount of data that I have accumulated on a NAS. I am currently in the process of copying all of this data to a second NAS in a different physical location as an off-site backup. To do this, I am using Teracopy, and the devices are communicating with each other over a Tailscale network.&lt;/p&gt;\n\n&lt;p&gt;The copying process itself has been pretty robust, and unlike Windows&amp;#39; built-in file transferring, TeraCopy seems to be able to handle transient network interruptions without just straight up failing.&lt;/p&gt;\n\n&lt;p&gt;But when I tried to use TeraCopy to *verify* the copied files, it is insanely tedious. Because more often than not, verification fails due to an unknown network error. Unlike copying, verifying seems to not have any resilience to interruptions, and it&amp;#39;s rare to be able to get through a 5GB+ file without one of them hitting. But what is interesting is that if I just keep running through the verification process over and over for a given batch after copying, only repeating on the files where the unknown error caused verification to fail, it will eventually work. And several hundred files in, I haven&amp;#39;t hit a single instance where verification wasn&amp;#39;t successful as long as it pushes through between network errors.&lt;/p&gt;\n\n&lt;p&gt;So my question is this. How critical *is* verification in a situation like this? Is it safe to assume that, as long as TeraCopy makes it through the copy process itself without throwing an error, the files are sound? Or do I really need to play it safe by running through the verification process (which sometimes takes more than a dozen tries per file) every time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kgyde", "is_robot_indexable": true, "report_reasons": null, "author": "ElTres", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kgyde/question_about_copy_integrity_and_the_necessity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kgyde/question_about_copy_integrity_and_the_necessity/", "subreddit_subscribers": 702530, "created_utc": 1694895507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've tried Media Harvest which doesn't work and the best one, Twitter Media Downloader, has been removed.", "author_fullname": "t2_9bci9al5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a Firefox extension to download pictures and video from Twitter profiles and likes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kgnr7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694894731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried Media Harvest which doesn&amp;#39;t work and the best one, Twitter Media Downloader, has been removed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16kgnr7", "is_robot_indexable": true, "report_reasons": null, "author": "CompleteMoron_203", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16kgnr7/is_there_a_firefox_extension_to_download_pictures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16kgnr7/is_there_a_firefox_extension_to_download_pictures/", "subreddit_subscribers": 702530, "created_utc": 1694894731.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}