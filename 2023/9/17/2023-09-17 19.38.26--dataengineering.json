{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious on everyone's thoughts here. You're now officially responsible for the entire team, not just the code you're deploying. How do things change? You aren't primarily writing code/designing solutions anymore. Where is your focus now? How do you 'improve' and measure success?", "author_fullname": "t2_43fb03vm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do after you make it to management?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l1drf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694959125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious on everyone&amp;#39;s thoughts here. You&amp;#39;re now officially responsible for the entire team, not just the code you&amp;#39;re deploying. How do things change? You aren&amp;#39;t primarily writing code/designing solutions anymore. Where is your focus now? How do you &amp;#39;improve&amp;#39; and measure success?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16l1drf", "is_robot_indexable": true, "report_reasons": null, "author": "idiotlog", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l1drf/what_do_you_do_after_you_make_it_to_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l1drf/what_do_you_do_after_you_make_it_to_management/", "subreddit_subscribers": 128905, "created_utc": 1694959125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It\u2019s the same shit over and over, and it\u2019s getting a little tiring. There is some great content and interesting discussions from time to time \u2014 I look forward to occasional article or post with lots of comments, usually get inspired by or learn something in there. But these newbie/career advice are the same thing over and over and over and over again. Do people not search prior posts? Do they just need some validation or words of encouragement for **their** particular situation? \n\nThat\u2019s it, rant over.", "author_fullname": "t2_3qlqubb2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Every other post in this sub seems to be \u201cgoing from DA to DE?\u201d or \u201cshould I learn X?\u201d.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l4r9l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694967248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s the same shit over and over, and it\u2019s getting a little tiring. There is some great content and interesting discussions from time to time \u2014 I look forward to occasional article or post with lots of comments, usually get inspired by or learn something in there. But these newbie/career advice are the same thing over and over and over and over again. Do people not search prior posts? Do they just need some validation or words of encouragement for &lt;strong&gt;their&lt;/strong&gt; particular situation? &lt;/p&gt;\n\n&lt;p&gt;That\u2019s it, rant over.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l4r9l", "is_robot_indexable": true, "report_reasons": null, "author": "EarthGoddessDude", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l4r9l/every_other_post_in_this_sub_seems_to_be_going/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l4r9l/every_other_post_in_this_sub_seems_to_be_going/", "subreddit_subscribers": 128905, "created_utc": 1694967248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw the other post which reduced my guilt a lot about using Chat-GPT! I\u2019m currently working as a the only data engineer in a startup and building everything from scratch so it\u2019s certainly been useful!\n\nI wonder if a lot of you are using Chat-GPT 4 or if you are using the free (3.5) version. \n\nMy company could pay the premium price but I would need good arguments and I\u2019m currently unsure if Chat-GPT 4 would be a significant improvement, although I feel like 3.5 suffers from significant hallucinations and I often have to write several prompts to get a working answer. \n\nDoes Chat-GPT 4 make significantly less of these mistakes?", "author_fullname": "t2_84vkp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any feedback on Chat-GPT 4 vs 3.5 for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kurdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694937663.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694937467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw the other post which reduced my guilt a lot about using Chat-GPT! I\u2019m currently working as a the only data engineer in a startup and building everything from scratch so it\u2019s certainly been useful!&lt;/p&gt;\n\n&lt;p&gt;I wonder if a lot of you are using Chat-GPT 4 or if you are using the free (3.5) version. &lt;/p&gt;\n\n&lt;p&gt;My company could pay the premium price but I would need good arguments and I\u2019m currently unsure if Chat-GPT 4 would be a significant improvement, although I feel like 3.5 suffers from significant hallucinations and I often have to write several prompts to get a working answer. &lt;/p&gt;\n\n&lt;p&gt;Does Chat-GPT 4 make significantly less of these mistakes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kurdj", "is_robot_indexable": true, "report_reasons": null, "author": "Faskill", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kurdj/any_feedback_on_chatgpt_4_vs_35_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kurdj/any_feedback_on_chatgpt_4_vs_35_for_data/", "subreddit_subscribers": 128905, "created_utc": 1694937467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wasn't sure how to best word the title here, and most probably worded things wrong...\n\nBut to exemplify my question, say I'm a data engineer working with an analyst, getting them access to some CDC data. Their requirement is that they want to be able to query the dataset on day 1 and get some result A. days later, after multiple updates to the table, they want to be able to query the dataset again and get result B (the new up-to-date data); however, they also want to be able to run a separate query on the same dataset and get result A (the original result) using some timestamp.\n\nI think that the only way to accomplish this is to have the CDC change operation and timestamp in the dataset itself. And when running any query you would need to:\n\n1. select records where timestamps are less than some input timestamp\n2. group by some primary key\n3. select records with max timestamp of each group\n4. select records where operation is insert or update (i.e. drop deletes)\n\nAm I thinking about this the correct way? It seems like the logic is getting a bit complicated here for something that might be rather common, so I wasn't sure if I was going in the wrong direction. Any help is appreciated!", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to query point-in-time state when working with transformed CDC data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kmaas", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694909108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wasn&amp;#39;t sure how to best word the title here, and most probably worded things wrong...&lt;/p&gt;\n\n&lt;p&gt;But to exemplify my question, say I&amp;#39;m a data engineer working with an analyst, getting them access to some CDC data. Their requirement is that they want to be able to query the dataset on day 1 and get some result A. days later, after multiple updates to the table, they want to be able to query the dataset again and get result B (the new up-to-date data); however, they also want to be able to run a separate query on the same dataset and get result A (the original result) using some timestamp.&lt;/p&gt;\n\n&lt;p&gt;I think that the only way to accomplish this is to have the CDC change operation and timestamp in the dataset itself. And when running any query you would need to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;select records where timestamps are less than some input timestamp&lt;/li&gt;\n&lt;li&gt;group by some primary key&lt;/li&gt;\n&lt;li&gt;select records with max timestamp of each group&lt;/li&gt;\n&lt;li&gt;select records where operation is insert or update (i.e. drop deletes)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I thinking about this the correct way? It seems like the logic is getting a bit complicated here for something that might be rather common, so I wasn&amp;#39;t sure if I was going in the wrong direction. Any help is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16kmaas", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kmaas/how_to_query_pointintime_state_when_working_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kmaas/how_to_query_pointintime_state_when_working_with/", "subreddit_subscribers": 128905, "created_utc": 1694909108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a data engineering job interview for a company in the UK tomorrow. I've been told that there will be a 30 minute coding challenge, where I will be asked to code an algorithm in Python. I haven't previously completed a coding challenge. \n\nWhich algorithms are DEs commonly expected to solve in interviews? Does anyone have any advice on how best to prepare? Thank you :) ", "author_fullname": "t2_ckc5vxa27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Interview - Coding Challenge - Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kyug2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694951945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data engineering job interview for a company in the UK tomorrow. I&amp;#39;ve been told that there will be a 30 minute coding challenge, where I will be asked to code an algorithm in Python. I haven&amp;#39;t previously completed a coding challenge. &lt;/p&gt;\n\n&lt;p&gt;Which algorithms are DEs commonly expected to solve in interviews? Does anyone have any advice on how best to prepare? Thank you :) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16kyug2", "is_robot_indexable": true, "report_reasons": null, "author": "Funny_Duck2429", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kyug2/data_engineering_interview_coding_challenge_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kyug2/data_engineering_interview_coding_challenge_advice/", "subreddit_subscribers": 128905, "created_utc": 1694951945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In this example, say that you're ingesting some highly denormalized data files from some source. These files break 1NF, 2NF and 3NF and as a data engineer your goal is to bring this data into an analytical database for querying by data scientists.\n\nMy first question **is normalization even needed in 2023?** Maybe this is a hot take, but in my mind, one of the main reasons to normalize is to reduce database size. But nowadays storage is so cheap, you the tradeoff in development time may be worth the extra storage!?\n\nSecondly, but after that, assuming normalization is required, **how much normalization is required?** Maybe only 1NF is required? Maybe 2NF as well? What questions would I need to ask myself to know the extent of what's needed for the use case?\n\nFinally, **when should you normalize?** In a traditional ELT pipeline, should it be somewhere between E and L to prevent denormalized data from getting into the DB at the tradeoff of time? Or is this better done as a later transform step?\n\nThe reason I'm asking all of this is because I came into the industry from application development where I worked with highly normalized transactional DBs. At first I assumed that a database is a database and I should treat analytical DBs and related ELT pipelines the same way, but I want to check those assumptions :)", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data normalization needed in 2023? How much normalization is actually required and when should it be done?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l4y6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694967688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this example, say that you&amp;#39;re ingesting some highly denormalized data files from some source. These files break 1NF, 2NF and 3NF and as a data engineer your goal is to bring this data into an analytical database for querying by data scientists.&lt;/p&gt;\n\n&lt;p&gt;My first question &lt;strong&gt;is normalization even needed in 2023?&lt;/strong&gt; Maybe this is a hot take, but in my mind, one of the main reasons to normalize is to reduce database size. But nowadays storage is so cheap, you the tradeoff in development time may be worth the extra storage!?&lt;/p&gt;\n\n&lt;p&gt;Secondly, but after that, assuming normalization is required, &lt;strong&gt;how much normalization is required?&lt;/strong&gt; Maybe only 1NF is required? Maybe 2NF as well? What questions would I need to ask myself to know the extent of what&amp;#39;s needed for the use case?&lt;/p&gt;\n\n&lt;p&gt;Finally, &lt;strong&gt;when should you normalize?&lt;/strong&gt; In a traditional ELT pipeline, should it be somewhere between E and L to prevent denormalized data from getting into the DB at the tradeoff of time? Or is this better done as a later transform step?&lt;/p&gt;\n\n&lt;p&gt;The reason I&amp;#39;m asking all of this is because I came into the industry from application development where I worked with highly normalized transactional DBs. At first I assumed that a database is a database and I should treat analytical DBs and related ELT pipelines the same way, but I want to check those assumptions :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l4y6e", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l4y6e/is_data_normalization_needed_in_2023_how_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l4y6e/is_data_normalization_needed_in_2023_how_much/", "subreddit_subscribers": 128905, "created_utc": 1694967688.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any data engineers working remotely from Asia in US based companies? How did you get the remote job? What is the salary range? How many experience did you have? What is the data stack you are working? What was the interview process like?\n\nRecently I applied for a company have reached 4th round but did not hear anything from them. I want to try Turing but it has questions related to Distributed system which I have not have any experience. My tech stack\n\n\\-Snowflake, AWS, Python, DBT, Docker, Airflow(beginner), Mostly orchestration is done using CRON in my current project\n\n\\- I am very good at SQL and PL/SQL and Python. \n\n\\- I have also basic understanding of Spark.\n\nMy ultimate goal is to work in Toptal as i heard their minimum pay starts from 25$ and they hire only top 3% of global talents. But their interview process is quite tough.\n\nI am very confident in problem solving using SQL.  But I do not have much data structure and algorithm knowledge.\n\n&amp;#x200B;", "author_fullname": "t2_txl4izdo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Remote Data Engineer Role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16l7xrp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694976039.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694974716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any data engineers working remotely from Asia in US based companies? How did you get the remote job? What is the salary range? How many experience did you have? What is the data stack you are working? What was the interview process like?&lt;/p&gt;\n\n&lt;p&gt;Recently I applied for a company have reached 4th round but did not hear anything from them. I want to try Turing but it has questions related to Distributed system which I have not have any experience. My tech stack&lt;/p&gt;\n\n&lt;p&gt;-Snowflake, AWS, Python, DBT, Docker, Airflow(beginner), Mostly orchestration is done using CRON in my current project&lt;/p&gt;\n\n&lt;p&gt;- I am very good at SQL and PL/SQL and Python. &lt;/p&gt;\n\n&lt;p&gt;- I have also basic understanding of Spark.&lt;/p&gt;\n\n&lt;p&gt;My ultimate goal is to work in Toptal as i heard their minimum pay starts from 25$ and they hire only top 3% of global talents. But their interview process is quite tough.&lt;/p&gt;\n\n&lt;p&gt;I am very confident in problem solving using SQL.  But I do not have much data structure and algorithm knowledge.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16l7xrp", "is_robot_indexable": true, "report_reasons": null, "author": "__1l0__", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l7xrp/remote_data_engineer_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l7xrp/remote_data_engineer_role/", "subreddit_subscribers": 128905, "created_utc": 1694974716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI have been working a lot with Azure technology and I made Databricks the primary tool for my organization. I noticed that Azure Synapse has Data Studio which provides a free, lightweight, cross-platform data management and development tool that supports a wide range of database platforms.  \n\n\nI would love to know if Databricks offers a similar feature/product.  \n\n\nThanks.", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Databricks Similar to Synapse Azure Data Studio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kfrbq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694892385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been working a lot with Azure technology and I made Databricks the primary tool for my organization. I noticed that Azure Synapse has Data Studio which provides a free, lightweight, cross-platform data management and development tool that supports a wide range of database platforms.  &lt;/p&gt;\n\n&lt;p&gt;I would love to know if Databricks offers a similar feature/product.  &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kfrbq", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kfrbq/azure_databricks_similar_to_synapse_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kfrbq/azure_databricks_similar_to_synapse_azure_data/", "subreddit_subscribers": 128905, "created_utc": 1694892385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I keep on getting pushed adds for restack .io on Reddit. It looks an interesting concept, but can\u2019t find much info online about it, beyond their own marketing.\n\nWe currently manage all our open source tools like dbt, airflow and airbyte between the various members of the data engineering team with internal IT monitoring our infrastructure security and compliance. But interested in a semi managed solution and what that looks like.\n\nHas anyone had any first hand experience deploying it in their own cloud environment.", "author_fullname": "t2_16jnqh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on restack .io", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16l7oai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694974093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I keep on getting pushed adds for restack .io on Reddit. It looks an interesting concept, but can\u2019t find much info online about it, beyond their own marketing.&lt;/p&gt;\n\n&lt;p&gt;We currently manage all our open source tools like dbt, airflow and airbyte between the various members of the data engineering team with internal IT monitoring our infrastructure security and compliance. But interested in a semi managed solution and what that looks like.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had any first hand experience deploying it in their own cloud environment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l7oai", "is_robot_indexable": true, "report_reasons": null, "author": "dave_8", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l7oai/thoughts_on_restack_io/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l7oai/thoughts_on_restack_io/", "subreddit_subscribers": 128905, "created_utc": 1694974093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to setup a pipeline that takes in daily snapshots of user data (in json), which needs to be parsed and normalized before being inserted into a set of mysql tables. Because these are snapshots, its likely that a lot of data already exists in the mysql tables and does not need to be reinserted. We use aws rds.\n\nI have two questions:\n\n- Is there a tool that would take the json and automatically do the parsing and the normalization?\n\n- What's an efficient way of inserting/updating data without needing to do a SELECT to check to see if the data already exists. These daily snapshots mean that most of the data should already be there with only a few new or updated attributes.\n\nThank you.", "author_fullname": "t2_gi9hjxmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about json -&gt; mysql loading.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16l74lf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694972795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to setup a pipeline that takes in daily snapshots of user data (in json), which needs to be parsed and normalized before being inserted into a set of mysql tables. Because these are snapshots, its likely that a lot of data already exists in the mysql tables and does not need to be reinserted. We use aws rds.&lt;/p&gt;\n\n&lt;p&gt;I have two questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Is there a tool that would take the json and automatically do the parsing and the normalization?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What&amp;#39;s an efficient way of inserting/updating data without needing to do a SELECT to check to see if the data already exists. These daily snapshots mean that most of the data should already be there with only a few new or updated attributes.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l74lf", "is_robot_indexable": true, "report_reasons": null, "author": "lets2021", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l74lf/question_about_json_mysql_loading/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l74lf/question_about_json_mysql_loading/", "subreddit_subscribers": 128905, "created_utc": 1694972795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am running a data quality testing program, and we have legacy data quality tests for system generated values. We can assume with a high degree of confidence that the system generated values will never be inaccurate or of insufficient data quality. \n\nThe question is - do we perform data quality checks on the system generated fields anyway? On one hand, why not? Something \\*could\\* go wrong (although highly unlikely). On the other, simplicity is a benefit for any DQ testing program, and we don't want to inundate ourselves with unimportant tests when we should be focusing on the actual risk with fields that are free text or user populated, as an example.\n\nAny thoughts from anyone? Do you perform data quality tests on system generated fields?", "author_fullname": "t2_6f5ggoc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality Tests for System Generated Values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l3rfu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694965310.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694964946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am running a data quality testing program, and we have legacy data quality tests for system generated values. We can assume with a high degree of confidence that the system generated values will never be inaccurate or of insufficient data quality. &lt;/p&gt;\n\n&lt;p&gt;The question is - do we perform data quality checks on the system generated fields anyway? On one hand, why not? Something *could* go wrong (although highly unlikely). On the other, simplicity is a benefit for any DQ testing program, and we don&amp;#39;t want to inundate ourselves with unimportant tests when we should be focusing on the actual risk with fields that are free text or user populated, as an example.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts from anyone? Do you perform data quality tests on system generated fields?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l3rfu", "is_robot_indexable": true, "report_reasons": null, "author": "wackomama", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l3rfu/data_quality_tests_for_system_generated_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l3rfu/data_quality_tests_for_system_generated_values/", "subreddit_subscribers": 128905, "created_utc": 1694964946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am a fresh graduate that recently joined a company as an embedded software engineer. To be honest, I never really knew if that was what I wanted to pursue, but it was one of the few job offers that I got so I thought it would be good to start working instead of just sitting at home until I got the job I wanted (which I didn\u2019t know). Anyways, it\u2019s been about 4 months and I am struggling to enjoy my job. I feel like the people with me are not driven. This might be company specific as opposed to the whole industry. Also, most of the code we develop is reused from previous models which means the work is redundant. No client interactions at all and even if there was any the client does not change. So for the past few weeks I\u2019ve been researching new skills and I started with SQL which has been really interesting so far. The problem is practicing a skill online is very different than actually doing it in real life situations which is why I feel like it is difficult to base my opinion solely off what I have learned online. My question is has anyone here transitioned from a software role to a data/analytics role? If so, what were the major differences? What did you enjoy? What did you not enjoy? What do you feel would be important to point out to someone in my case? Again I am not saying this field is my passion but I am still young and with no responsibilities so I feel like now is the time to try a bunch of different things until I get to a place where I don\u2019t want to try anything different anymore. \n\n Thank you!", "author_fullname": "t2_6n13dky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l1r6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694965892.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694960018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am a fresh graduate that recently joined a company as an embedded software engineer. To be honest, I never really knew if that was what I wanted to pursue, but it was one of the few job offers that I got so I thought it would be good to start working instead of just sitting at home until I got the job I wanted (which I didn\u2019t know). Anyways, it\u2019s been about 4 months and I am struggling to enjoy my job. I feel like the people with me are not driven. This might be company specific as opposed to the whole industry. Also, most of the code we develop is reused from previous models which means the work is redundant. No client interactions at all and even if there was any the client does not change. So for the past few weeks I\u2019ve been researching new skills and I started with SQL which has been really interesting so far. The problem is practicing a skill online is very different than actually doing it in real life situations which is why I feel like it is difficult to base my opinion solely off what I have learned online. My question is has anyone here transitioned from a software role to a data/analytics role? If so, what were the major differences? What did you enjoy? What did you not enjoy? What do you feel would be important to point out to someone in my case? Again I am not saying this field is my passion but I am still young and with no responsibilities so I feel like now is the time to try a bunch of different things until I get to a place where I don\u2019t want to try anything different anymore. &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16l1r6e", "is_robot_indexable": true, "report_reasons": null, "author": "Whatuphomie112", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l1r6e/software_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l1r6e/software_to_data/", "subreddit_subscribers": 128905, "created_utc": 1694960018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nNewbie in streaming. I need to design a PySpark program that reads the incoming streaming orders, and compare the total amount between last 24 hours data with last 30 days data.\n\nIn this way, what would be the better idea?\n\n1. Read the streaming data by grouping them in 24 hour window and aggregate on amount then save. Then, create another dataframe that reads from saved location (the historical data) and made the comparison.\n2. Read the steaming data without grouping and directly save it to a location. Then, create another dataframe that reads data from saved location and made the grouping (aggregate on amount) and comparison.\n\nOr, is there a better way to do it? In above mentioned way, it will become a batch job, it will not continuously compare last 24 with last 30 days.", "author_fullname": "t2_2x81kpwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming Architecture Advise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kulfi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694937428.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694936778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;Newbie in streaming. I need to design a PySpark program that reads the incoming streaming orders, and compare the total amount between last 24 hours data with last 30 days data.&lt;/p&gt;\n\n&lt;p&gt;In this way, what would be the better idea?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Read the streaming data by grouping them in 24 hour window and aggregate on amount then save. Then, create another dataframe that reads from saved location (the historical data) and made the comparison.&lt;/li&gt;\n&lt;li&gt;Read the steaming data without grouping and directly save it to a location. Then, create another dataframe that reads data from saved location and made the grouping (aggregate on amount) and comparison.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Or, is there a better way to do it? In above mentioned way, it will become a batch job, it will not continuously compare last 24 with last 30 days.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16kulfi", "is_robot_indexable": true, "report_reasons": null, "author": "Disastrous-State-503", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kulfi/streaming_architecture_advise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kulfi/streaming_architecture_advise/", "subreddit_subscribers": 128905, "created_utc": 1694936778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are in need for an analytics system that ingests customer json data every hour into a relational form for querying. We will be receiving the complete data for each customer as a giant json blob. And because we are getting it every hour, most of the data should already be in the system with only some attributes added/updated (unless its a new customer). There is some time-series data in it as well. The system should be able to handle this.\n\nWe need to run some specific queries for a customer dashboard. They need to be near realtime and will be run often. We also want the flexibility to run other queries (in SQL) for ad-hoc BI stuff and/or add it to the customer dashboard. Going forward, analytics is going to be a core offering and competitive advantage.\n\nWe are an AWS shop and not opposed to paying so long as the pricing is reasonable. For context, I'm a backend engineer that's only dabbled with DE here and there. A friend recommended Snowflake but I'm not sure how to calculate pricing. The SQL queries will involve a lot of joins.\n\nThoughts/Advice? Thanks.", "author_fullname": "t2_rz22aza", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be a good analytics setup for this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kh0p9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694895675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are in need for an analytics system that ingests customer json data every hour into a relational form for querying. We will be receiving the complete data for each customer as a giant json blob. And because we are getting it every hour, most of the data should already be in the system with only some attributes added/updated (unless its a new customer). There is some time-series data in it as well. The system should be able to handle this.&lt;/p&gt;\n\n&lt;p&gt;We need to run some specific queries for a customer dashboard. They need to be near realtime and will be run often. We also want the flexibility to run other queries (in SQL) for ad-hoc BI stuff and/or add it to the customer dashboard. Going forward, analytics is going to be a core offering and competitive advantage.&lt;/p&gt;\n\n&lt;p&gt;We are an AWS shop and not opposed to paying so long as the pricing is reasonable. For context, I&amp;#39;m a backend engineer that&amp;#39;s only dabbled with DE here and there. A friend recommended Snowflake but I&amp;#39;m not sure how to calculate pricing. The SQL queries will involve a lot of joins.&lt;/p&gt;\n\n&lt;p&gt;Thoughts/Advice? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kh0p9", "is_robot_indexable": true, "report_reasons": null, "author": "grchelp2018", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kh0p9/what_would_be_a_good_analytics_setup_for_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kh0p9/what_would_be_a_good_analytics_setup_for_this/", "subreddit_subscribers": 128905, "created_utc": 1694895675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am interested in experience of Delta table modeling. \n\nDo you have productive examples or learning resources that you can share?\n\nThanks in advance!", "author_fullname": "t2_h8o6jb9k1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta table modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l6vhz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694972197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am interested in experience of Delta table modeling. &lt;/p&gt;\n\n&lt;p&gt;Do you have productive examples or learning resources that you can share?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l6vhz", "is_robot_indexable": true, "report_reasons": null, "author": "volvoboy-85", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l6vhz/delta_table_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l6vhz/delta_table_modeling/", "subreddit_subscribers": 128905, "created_utc": 1694972197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will make a quick post, since time is valuable to all of us.\n\nSo I am looking to graduate after a 5 years long Bachelor pursuit, from a decent University in my home country (Vietnam). During the last 2 years of this time I started learning and tried taking jobs relating to Data, ML/DL, all engineering, starting from small lab-environment experiment conducting to number crunching DA and infra for a ML-oriented-system mocking (I got exposed to MLOps tech and principles in a while \\~ 1yr, but never got serious since my old company was not deploying any users-facing model). Then got bored of all the ML-sys PoC making/testing and started working for a relatively big data center which made uses of both good big-data engineers and math-heavy journal-printing data scientists, I was one of the more heavy lifting engineers in the data science team who code random APIs and backend for our ML system. Around this time I started to feel the need to be come a DE (I kinda liked engineering stuffs more than all the ML model tuning craps, and I believe Data comes first before any ML systems, or even a model deployment) and slowly decided to stop working about AI models and infras and start looking into data flow, quality and whats not. I started to write a lot more Spark, HiveQL queries, designing new ETL flows and start picking up books about data-intensive systems.\n\nThen all of a sudden, I quit and went back to school for 6 months. My grades was degrading and I still have a Ms to follow, so bit of a paranoid back then, I decided to focus on this final Bachelor sprint. During that half a year of running around to fix my grades I did nothing Data-related.\n\nNow I am back, with a financial burden (very personal so I ain't telling) and all-in-all just a lot of free time and wanting to pick up any Data Engineering entry level pos to start working in the field again. Here is when I started to terrify again. \n\nI don't even know how to start, my friends suggested me some remote job boards but the listings are few and far between and mostly for Sr. positions, I am starting to think that this whole remote thing is for big-brain best-of-the-bunch star engineers. Applied for around 50+ entry to mid level and barely getting even a reply. Besides the fact that I don't exactly have any credential as a Data Engineer, my experiences are all over the places with random tech and looked like I had career-related second thoughts every year. This might be my biggest shame if I had to name one.\n\nFinally, what I pose here is a question: How can I, as a CS graduate can start looking, and preparing for a DE position. Is there any courses, certificates, books serving as a hidden requirement that I am not meeting. And most importantly, how can I even start remote working (some of my friends are remote workers and some friends of them are remote DEs, and I have no clue how they started doing it). I would love to hear about your experiences starting working as a remote DE.\n\nThank you for your time and attention. And I am terribly sorry for my tones if it comes off weird or off-putting, as English is only my second language and sometimes it's hard for me to articulate what's on my mind.", "author_fullname": "t2_8udlbwqs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CS grad looking for remote DE entry pos but almost no reply. Plz help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l4mj0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694966951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will make a quick post, since time is valuable to all of us.&lt;/p&gt;\n\n&lt;p&gt;So I am looking to graduate after a 5 years long Bachelor pursuit, from a decent University in my home country (Vietnam). During the last 2 years of this time I started learning and tried taking jobs relating to Data, ML/DL, all engineering, starting from small lab-environment experiment conducting to number crunching DA and infra for a ML-oriented-system mocking (I got exposed to MLOps tech and principles in a while ~ 1yr, but never got serious since my old company was not deploying any users-facing model). Then got bored of all the ML-sys PoC making/testing and started working for a relatively big data center which made uses of both good big-data engineers and math-heavy journal-printing data scientists, I was one of the more heavy lifting engineers in the data science team who code random APIs and backend for our ML system. Around this time I started to feel the need to be come a DE (I kinda liked engineering stuffs more than all the ML model tuning craps, and I believe Data comes first before any ML systems, or even a model deployment) and slowly decided to stop working about AI models and infras and start looking into data flow, quality and whats not. I started to write a lot more Spark, HiveQL queries, designing new ETL flows and start picking up books about data-intensive systems.&lt;/p&gt;\n\n&lt;p&gt;Then all of a sudden, I quit and went back to school for 6 months. My grades was degrading and I still have a Ms to follow, so bit of a paranoid back then, I decided to focus on this final Bachelor sprint. During that half a year of running around to fix my grades I did nothing Data-related.&lt;/p&gt;\n\n&lt;p&gt;Now I am back, with a financial burden (very personal so I ain&amp;#39;t telling) and all-in-all just a lot of free time and wanting to pick up any Data Engineering entry level pos to start working in the field again. Here is when I started to terrify again. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t even know how to start, my friends suggested me some remote job boards but the listings are few and far between and mostly for Sr. positions, I am starting to think that this whole remote thing is for big-brain best-of-the-bunch star engineers. Applied for around 50+ entry to mid level and barely getting even a reply. Besides the fact that I don&amp;#39;t exactly have any credential as a Data Engineer, my experiences are all over the places with random tech and looked like I had career-related second thoughts every year. This might be my biggest shame if I had to name one.&lt;/p&gt;\n\n&lt;p&gt;Finally, what I pose here is a question: How can I, as a CS graduate can start looking, and preparing for a DE position. Is there any courses, certificates, books serving as a hidden requirement that I am not meeting. And most importantly, how can I even start remote working (some of my friends are remote workers and some friends of them are remote DEs, and I have no clue how they started doing it). I would love to hear about your experiences starting working as a remote DE.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time and attention. And I am terribly sorry for my tones if it comes off weird or off-putting, as English is only my second language and sometimes it&amp;#39;s hard for me to articulate what&amp;#39;s on my mind.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16l4mj0", "is_robot_indexable": true, "report_reasons": null, "author": "Rich-Abbreviations27", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l4mj0/cs_grad_looking_for_remote_de_entry_pos_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l4mj0/cs_grad_looking_for_remote_de_entry_pos_but/", "subreddit_subscribers": 128905, "created_utc": 1694966951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is most of this towards compute on Databricks, Snowflake, or OS engines like Spark? On licenses for transform tools like dbt or similar? Other?\n\n[View Poll](https://www.reddit.com/poll/16kojun)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does ETL / Transform contribute to your data platform costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kojun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694915750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is most of this towards compute on Databricks, Snowflake, or OS engines like Spark? On licenses for transform tools like dbt or similar? Other?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/16kojun\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kojun", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1695174950774, "options": [{"text": "Up to 30%", "id": "24827014"}, {"text": "30% to 50%", "id": "24827015"}, {"text": "50% to 70%", "id": "24827016"}, {"text": "Above 70%", "id": "24827017"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 88, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kojun/how_much_does_etl_transform_contribute_to_your/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/16kojun/how_much_does_etl_transform_contribute_to_your/", "subreddit_subscribers": 128905, "created_utc": 1694915750.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}