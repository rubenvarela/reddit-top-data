{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It\u2019s the same shit over and over, and it\u2019s getting a little tiring. There is some great content and interesting discussions from time to time \u2014 I look forward to occasional article or post with lots of comments, usually get inspired by or learn something in there. But these newbie/career advice are the same thing over and over and over and over again. Do people not search prior posts? Do they just need some validation or words of encouragement for **their** particular situation? \n\nThat\u2019s it, rant over.", "author_fullname": "t2_3qlqubb2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Every other post in this sub seems to be \u201cgoing from DA to DE?\u201d or \u201cshould I learn X?\u201d.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l4r9l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694967248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s the same shit over and over, and it\u2019s getting a little tiring. There is some great content and interesting discussions from time to time \u2014 I look forward to occasional article or post with lots of comments, usually get inspired by or learn something in there. But these newbie/career advice are the same thing over and over and over and over again. Do people not search prior posts? Do they just need some validation or words of encouragement for &lt;strong&gt;their&lt;/strong&gt; particular situation? &lt;/p&gt;\n\n&lt;p&gt;That\u2019s it, rant over.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l4r9l", "is_robot_indexable": true, "report_reasons": null, "author": "EarthGoddessDude", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l4r9l/every_other_post_in_this_sub_seems_to_be_going/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l4r9l/every_other_post_in_this_sub_seems_to_be_going/", "subreddit_subscribers": 128924, "created_utc": 1694967248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious on everyone's thoughts here. You're now officially responsible for the entire team, not just the code you're deploying. How do things change? You aren't primarily writing code/designing solutions anymore. Where is your focus now? How do you 'improve' and measure success?", "author_fullname": "t2_43fb03vm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do after you make it to management?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l1drf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694959125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious on everyone&amp;#39;s thoughts here. You&amp;#39;re now officially responsible for the entire team, not just the code you&amp;#39;re deploying. How do things change? You aren&amp;#39;t primarily writing code/designing solutions anymore. Where is your focus now? How do you &amp;#39;improve&amp;#39; and measure success?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16l1drf", "is_robot_indexable": true, "report_reasons": null, "author": "idiotlog", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l1drf/what_do_you_do_after_you_make_it_to_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l1drf/what_do_you_do_after_you_make_it_to_management/", "subreddit_subscribers": 128924, "created_utc": 1694959125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw the other post which reduced my guilt a lot about using Chat-GPT! I\u2019m currently working as a the only data engineer in a startup and building everything from scratch so it\u2019s certainly been useful!\n\nI wonder if a lot of you are using Chat-GPT 4 or if you are using the free (3.5) version. \n\nMy company could pay the premium price but I would need good arguments and I\u2019m currently unsure if Chat-GPT 4 would be a significant improvement, although I feel like 3.5 suffers from significant hallucinations and I often have to write several prompts to get a working answer. \n\nDoes Chat-GPT 4 make significantly less of these mistakes?", "author_fullname": "t2_84vkp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any feedback on Chat-GPT 4 vs 3.5 for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kurdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694937663.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694937467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw the other post which reduced my guilt a lot about using Chat-GPT! I\u2019m currently working as a the only data engineer in a startup and building everything from scratch so it\u2019s certainly been useful!&lt;/p&gt;\n\n&lt;p&gt;I wonder if a lot of you are using Chat-GPT 4 or if you are using the free (3.5) version. &lt;/p&gt;\n\n&lt;p&gt;My company could pay the premium price but I would need good arguments and I\u2019m currently unsure if Chat-GPT 4 would be a significant improvement, although I feel like 3.5 suffers from significant hallucinations and I often have to write several prompts to get a working answer. &lt;/p&gt;\n\n&lt;p&gt;Does Chat-GPT 4 make significantly less of these mistakes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kurdj", "is_robot_indexable": true, "report_reasons": null, "author": "Faskill", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kurdj/any_feedback_on_chatgpt_4_vs_35_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kurdj/any_feedback_on_chatgpt_4_vs_35_for_data/", "subreddit_subscribers": 128924, "created_utc": 1694937467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In this example, say that you're ingesting some highly denormalized data files from some source. These files break 1NF, 2NF and 3NF and as a data engineer your goal is to bring this data into an analytical database for querying by data scientists.\n\nMy first question **is normalization even needed in 2023?** Maybe this is a hot take, but in my mind, one of the main reasons to normalize is to reduce database size. But nowadays storage is so cheap, you the tradeoff in development time may be worth the extra storage!?\n\nSecondly, but after that, assuming normalization is required, **how much normalization is required?** Maybe only 1NF is required? Maybe 2NF as well? What questions would I need to ask myself to know the extent of what's needed for the use case?\n\nFinally, **when should you normalize?** In a traditional ELT pipeline, should it be somewhere between E and L to prevent denormalized data from getting into the DB at the tradeoff of time? Or is this better done as a later transform step?\n\nThe reason I'm asking all of this is because I came into the industry from application development where I worked with highly normalized transactional DBs. At first I assumed that a database is a database and I should treat analytical DBs and related ELT pipelines the same way, but I want to check those assumptions :)", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data normalization needed in 2023? How much normalization is actually required and when should it be done?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l4y6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694967688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this example, say that you&amp;#39;re ingesting some highly denormalized data files from some source. These files break 1NF, 2NF and 3NF and as a data engineer your goal is to bring this data into an analytical database for querying by data scientists.&lt;/p&gt;\n\n&lt;p&gt;My first question &lt;strong&gt;is normalization even needed in 2023?&lt;/strong&gt; Maybe this is a hot take, but in my mind, one of the main reasons to normalize is to reduce database size. But nowadays storage is so cheap, you the tradeoff in development time may be worth the extra storage!?&lt;/p&gt;\n\n&lt;p&gt;Secondly, but after that, assuming normalization is required, &lt;strong&gt;how much normalization is required?&lt;/strong&gt; Maybe only 1NF is required? Maybe 2NF as well? What questions would I need to ask myself to know the extent of what&amp;#39;s needed for the use case?&lt;/p&gt;\n\n&lt;p&gt;Finally, &lt;strong&gt;when should you normalize?&lt;/strong&gt; In a traditional ELT pipeline, should it be somewhere between E and L to prevent denormalized data from getting into the DB at the tradeoff of time? Or is this better done as a later transform step?&lt;/p&gt;\n\n&lt;p&gt;The reason I&amp;#39;m asking all of this is because I came into the industry from application development where I worked with highly normalized transactional DBs. At first I assumed that a database is a database and I should treat analytical DBs and related ELT pipelines the same way, but I want to check those assumptions :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l4y6e", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l4y6e/is_data_normalization_needed_in_2023_how_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l4y6e/is_data_normalization_needed_in_2023_how_much/", "subreddit_subscribers": 128924, "created_utc": 1694967688.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wasn't sure how to best word the title here, and most probably worded things wrong...\n\nBut to exemplify my question, say I'm a data engineer working with an analyst, getting them access to some CDC data. Their requirement is that they want to be able to query the dataset on day 1 and get some result A. days later, after multiple updates to the table, they want to be able to query the dataset again and get result B (the new up-to-date data); however, they also want to be able to run a separate query on the same dataset and get result A (the original result) using some timestamp.\n\nI think that the only way to accomplish this is to have the CDC change operation and timestamp in the dataset itself. And when running any query you would need to:\n\n1. select records where timestamps are less than some input timestamp\n2. group by some primary key\n3. select records with max timestamp of each group\n4. select records where operation is insert or update (i.e. drop deletes)\n\nAm I thinking about this the correct way? It seems like the logic is getting a bit complicated here for something that might be rather common, so I wasn't sure if I was going in the wrong direction. Any help is appreciated!", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to query point-in-time state when working with transformed CDC data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kmaas", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694909108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wasn&amp;#39;t sure how to best word the title here, and most probably worded things wrong...&lt;/p&gt;\n\n&lt;p&gt;But to exemplify my question, say I&amp;#39;m a data engineer working with an analyst, getting them access to some CDC data. Their requirement is that they want to be able to query the dataset on day 1 and get some result A. days later, after multiple updates to the table, they want to be able to query the dataset again and get result B (the new up-to-date data); however, they also want to be able to run a separate query on the same dataset and get result A (the original result) using some timestamp.&lt;/p&gt;\n\n&lt;p&gt;I think that the only way to accomplish this is to have the CDC change operation and timestamp in the dataset itself. And when running any query you would need to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;select records where timestamps are less than some input timestamp&lt;/li&gt;\n&lt;li&gt;group by some primary key&lt;/li&gt;\n&lt;li&gt;select records with max timestamp of each group&lt;/li&gt;\n&lt;li&gt;select records where operation is insert or update (i.e. drop deletes)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I thinking about this the correct way? It seems like the logic is getting a bit complicated here for something that might be rather common, so I wasn&amp;#39;t sure if I was going in the wrong direction. Any help is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16kmaas", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kmaas/how_to_query_pointintime_state_when_working_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kmaas/how_to_query_pointintime_state_when_working_with/", "subreddit_subscribers": 128924, "created_utc": 1694909108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a data engineering job interview for a company in the UK tomorrow. I've been told that there will be a 30 minute coding challenge, where I will be asked to code an algorithm in Python. I haven't previously completed a coding challenge. \n\nWhich algorithms are DEs commonly expected to solve in interviews? Does anyone have any advice on how best to prepare? Thank you :) ", "author_fullname": "t2_ckc5vxa27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Interview - Coding Challenge - Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kyug2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694951945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data engineering job interview for a company in the UK tomorrow. I&amp;#39;ve been told that there will be a 30 minute coding challenge, where I will be asked to code an algorithm in Python. I haven&amp;#39;t previously completed a coding challenge. &lt;/p&gt;\n\n&lt;p&gt;Which algorithms are DEs commonly expected to solve in interviews? Does anyone have any advice on how best to prepare? Thank you :) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16kyug2", "is_robot_indexable": true, "report_reasons": null, "author": "Funny_Duck2429", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kyug2/data_engineering_interview_coding_challenge_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kyug2/data_engineering_interview_coding_challenge_advice/", "subreddit_subscribers": 128924, "created_utc": 1694951945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any data engineers working remotely from Asia in US based companies? How did you get the remote job? What is the salary range? How many experience did you have? What is the data stack you are working? What was the interview process like?\n\nRecently I applied for a company have reached 4th round but did not hear anything from them. I want to try Turing but it has questions related to Distributed system which I have not have any experience. My tech stack\n\n\\-Snowflake, AWS, Python, DBT, Docker, Airflow(beginner), Mostly orchestration is done using CRON in my current project\n\n\\- I am very good at SQL and PL/SQL and Python. \n\n\\- I have also basic understanding of Spark.\n\nMy ultimate goal is to work in Toptal as i heard their minimum pay starts from 25$ and they hire only top 3% of global talents. But their interview process is quite tough.\n\nI am very confident in problem solving using SQL.  But I do not have much data structure and algorithm knowledge.\n\n&amp;#x200B;", "author_fullname": "t2_txl4izdo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Remote Data Engineer Role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l7xrp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694976039.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694974716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any data engineers working remotely from Asia in US based companies? How did you get the remote job? What is the salary range? How many experience did you have? What is the data stack you are working? What was the interview process like?&lt;/p&gt;\n\n&lt;p&gt;Recently I applied for a company have reached 4th round but did not hear anything from them. I want to try Turing but it has questions related to Distributed system which I have not have any experience. My tech stack&lt;/p&gt;\n\n&lt;p&gt;-Snowflake, AWS, Python, DBT, Docker, Airflow(beginner), Mostly orchestration is done using CRON in my current project&lt;/p&gt;\n\n&lt;p&gt;- I am very good at SQL and PL/SQL and Python. &lt;/p&gt;\n\n&lt;p&gt;- I have also basic understanding of Spark.&lt;/p&gt;\n\n&lt;p&gt;My ultimate goal is to work in Toptal as i heard their minimum pay starts from 25$ and they hire only top 3% of global talents. But their interview process is quite tough.&lt;/p&gt;\n\n&lt;p&gt;I am very confident in problem solving using SQL.  But I do not have much data structure and algorithm knowledge.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16l7xrp", "is_robot_indexable": true, "report_reasons": null, "author": "__1l0__", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l7xrp/remote_data_engineer_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l7xrp/remote_data_engineer_role/", "subreddit_subscribers": 128924, "created_utc": 1694974716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to setup a pipeline that takes in daily snapshots of user data (in json), which needs to be parsed and normalized before being inserted into a set of mysql tables. Because these are snapshots, its likely that a lot of data already exists in the mysql tables and does not need to be reinserted. We use aws rds.\n\nI have two questions:\n\n- Is there a tool that would take the json and automatically do the parsing and the normalization?\n\n- What's an efficient way of inserting/updating data without needing to do a SELECT to check to see if the data already exists. These daily snapshots mean that most of the data should already be there with only a few new or updated attributes.\n\nThank you.", "author_fullname": "t2_gi9hjxmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about json -&gt; mysql loading.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l74lf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694972795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to setup a pipeline that takes in daily snapshots of user data (in json), which needs to be parsed and normalized before being inserted into a set of mysql tables. Because these are snapshots, its likely that a lot of data already exists in the mysql tables and does not need to be reinserted. We use aws rds.&lt;/p&gt;\n\n&lt;p&gt;I have two questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Is there a tool that would take the json and automatically do the parsing and the normalization?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What&amp;#39;s an efficient way of inserting/updating data without needing to do a SELECT to check to see if the data already exists. These daily snapshots mean that most of the data should already be there with only a few new or updated attributes.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l74lf", "is_robot_indexable": true, "report_reasons": null, "author": "lets2021", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l74lf/question_about_json_mysql_loading/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l74lf/question_about_json_mysql_loading/", "subreddit_subscribers": 128924, "created_utc": 1694972795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I'm new to DE and new to Databricks and I need help in my assignment. So far I've ingested the data, created a delta live table pipeline till the silver layer. Next I'll be moving to the aggregation part but before that I'm still unable to figure out what does the last point here mean. Please help is this related to SQL warehouse and unity catalog or something? Also I've been told to implement Unity Catalog in this assignment.\n\nThis is what I've been told to do after ingesting the data in bronze.\nThe client has requested for data exploration solution as a part of the pipeline itself. There will be such data exploration needs as a part of the production pipeline too. You need to check for data quality issues as well while exploring the data. If any data quality issues are identified they have to be cleaned. The client has also asked to address the problem of several ad-hoc queries in the pipeline which they prefer to answer using SQL\n\nThanks.", "author_fullname": "t2_i8dt9vbo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to DE and Databricks. HELP.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16lc13v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694984451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m new to DE and new to Databricks and I need help in my assignment. So far I&amp;#39;ve ingested the data, created a delta live table pipeline till the silver layer. Next I&amp;#39;ll be moving to the aggregation part but before that I&amp;#39;m still unable to figure out what does the last point here mean. Please help is this related to SQL warehouse and unity catalog or something? Also I&amp;#39;ve been told to implement Unity Catalog in this assignment.&lt;/p&gt;\n\n&lt;p&gt;This is what I&amp;#39;ve been told to do after ingesting the data in bronze.\nThe client has requested for data exploration solution as a part of the pipeline itself. There will be such data exploration needs as a part of the production pipeline too. You need to check for data quality issues as well while exploring the data. If any data quality issues are identified they have to be cleaned. The client has also asked to address the problem of several ad-hoc queries in the pipeline which they prefer to answer using SQL&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16lc13v", "is_robot_indexable": true, "report_reasons": null, "author": "sorryinternet_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lc13v/new_to_de_and_databricks_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lc13v/new_to_de_and_databricks_help/", "subreddit_subscribers": 128924, "created_utc": 1694984451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello amazing data engineering community,\nI work as a data analyst and I am working towards transitioning to data engineering, I have pretty good SQL knowledge and average Python knowledge.\nI was wondering how much time should I invest in learning data structures and algorithms and how important are they for someone who's just starting their careers in data engineering? Because you know, knowing Python itself doesn't necessarily mean you actually know DSA pretty well.\nThanks a lot in advance!", "author_fullname": "t2_17tlmhub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much is DSA required to get into data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16lbt18", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694983910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello amazing data engineering community,\nI work as a data analyst and I am working towards transitioning to data engineering, I have pretty good SQL knowledge and average Python knowledge.\nI was wondering how much time should I invest in learning data structures and algorithms and how important are they for someone who&amp;#39;s just starting their careers in data engineering? Because you know, knowing Python itself doesn&amp;#39;t necessarily mean you actually know DSA pretty well.\nThanks a lot in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16lbt18", "is_robot_indexable": true, "report_reasons": null, "author": "wajeehz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lbt18/how_much_is_dsa_required_to_get_into_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lbt18/how_much_is_dsa_required_to_get_into_data/", "subreddit_subscribers": 128924, "created_utc": 1694983910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which one to choose when? Even though this information, would really appreciate an answer who has worked with both the products.", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataproc vs Dataflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16la78r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694980074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which one to choose when? Even though this information, would really appreciate an answer who has worked with both the products.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16la78r", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16la78r/dataproc_vs_dataflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16la78r/dataproc_vs_dataflow/", "subreddit_subscribers": 128924, "created_utc": 1694980074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For the most part, users connect to our Redshift cluster using a SQL client and either username/password or SSO. Sometimes reporting tools connect to it using whatever method is required from the specific reporting tool. Internal processes (e.g. ETL jobs) connect using the psycopg2 Python library.\n\nAn internal web application will now need access to our Redshift data. Is it bad practice for this application to access the Redshift data \"directly\" using a Javascript library like \"node-redshift\" or \"pg\"? Should it instead use either the Redshift Data API or, even more indirectly, a REST API to access the data? Since many users/applications already access the data directly (i.e. configuring JDBC URL, access tables by name), does it matter if this web application also accesses the Redshift data in the same way? Or are there different standards since the web application is part of a programmatic process and owned by a team external to the team which owns the Redshift cluster? Though the team is part of the same company and the web application is private to the company.\n\nAre there risks to allowing the web application to access the Redshift data directly using a library rather than building out a REST API? What are Best Practices?", "author_fullname": "t2_jx5l6r0ay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When should I develop a REST API to access Redshift data rather than using either a library to connect to Redshift or the Redshift Data API?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l8lnn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694976287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the most part, users connect to our Redshift cluster using a SQL client and either username/password or SSO. Sometimes reporting tools connect to it using whatever method is required from the specific reporting tool. Internal processes (e.g. ETL jobs) connect using the psycopg2 Python library.&lt;/p&gt;\n\n&lt;p&gt;An internal web application will now need access to our Redshift data. Is it bad practice for this application to access the Redshift data &amp;quot;directly&amp;quot; using a Javascript library like &amp;quot;node-redshift&amp;quot; or &amp;quot;pg&amp;quot;? Should it instead use either the Redshift Data API or, even more indirectly, a REST API to access the data? Since many users/applications already access the data directly (i.e. configuring JDBC URL, access tables by name), does it matter if this web application also accesses the Redshift data in the same way? Or are there different standards since the web application is part of a programmatic process and owned by a team external to the team which owns the Redshift cluster? Though the team is part of the same company and the web application is private to the company.&lt;/p&gt;\n\n&lt;p&gt;Are there risks to allowing the web application to access the Redshift data directly using a library rather than building out a REST API? What are Best Practices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l8lnn", "is_robot_indexable": true, "report_reasons": null, "author": "IllRepresentative858", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l8lnn/when_should_i_develop_a_rest_api_to_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l8lnn/when_should_i_develop_a_rest_api_to_access/", "subreddit_subscribers": 128924, "created_utc": 1694976287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I keep on getting pushed adds for restack .io on Reddit. It looks an interesting concept, but can\u2019t find much info online about it, beyond their own marketing.\n\nWe currently manage all our open source tools like dbt, airflow and airbyte between the various members of the data engineering team with internal IT monitoring our infrastructure security and compliance. But interested in a semi managed solution and what that looks like.\n\nHas anyone had any first hand experience deploying it in their own cloud environment.", "author_fullname": "t2_16jnqh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on restack .io", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l7oai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694974093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I keep on getting pushed adds for restack .io on Reddit. It looks an interesting concept, but can\u2019t find much info online about it, beyond their own marketing.&lt;/p&gt;\n\n&lt;p&gt;We currently manage all our open source tools like dbt, airflow and airbyte between the various members of the data engineering team with internal IT monitoring our infrastructure security and compliance. But interested in a semi managed solution and what that looks like.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had any first hand experience deploying it in their own cloud environment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l7oai", "is_robot_indexable": true, "report_reasons": null, "author": "dave_8", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l7oai/thoughts_on_restack_io/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l7oai/thoughts_on_restack_io/", "subreddit_subscribers": 128924, "created_utc": 1694974093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am running a data quality testing program, and we have legacy data quality tests for system generated values. We can assume with a high degree of confidence that the system generated values will never be inaccurate or of insufficient data quality. \n\nThe question is - do we perform data quality checks on the system generated fields anyway? On one hand, why not? Something \\*could\\* go wrong (although highly unlikely). On the other, simplicity is a benefit for any DQ testing program, and we don't want to inundate ourselves with unimportant tests when we should be focusing on the actual risk with fields that are free text or user populated, as an example.\n\nAny thoughts from anyone? Do you perform data quality tests on system generated fields?", "author_fullname": "t2_6f5ggoc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality Tests for System Generated Values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l3rfu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694965310.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694964946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am running a data quality testing program, and we have legacy data quality tests for system generated values. We can assume with a high degree of confidence that the system generated values will never be inaccurate or of insufficient data quality. &lt;/p&gt;\n\n&lt;p&gt;The question is - do we perform data quality checks on the system generated fields anyway? On one hand, why not? Something *could* go wrong (although highly unlikely). On the other, simplicity is a benefit for any DQ testing program, and we don&amp;#39;t want to inundate ourselves with unimportant tests when we should be focusing on the actual risk with fields that are free text or user populated, as an example.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts from anyone? Do you perform data quality tests on system generated fields?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l3rfu", "is_robot_indexable": true, "report_reasons": null, "author": "wackomama", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l3rfu/data_quality_tests_for_system_generated_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l3rfu/data_quality_tests_for_system_generated_values/", "subreddit_subscribers": 128924, "created_utc": 1694964946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am a fresh graduate that recently joined a company as an embedded software engineer. To be honest, I never really knew if that was what I wanted to pursue, but it was one of the few job offers that I got so I thought it would be good to start working instead of just sitting at home until I got the job I wanted (which I didn\u2019t know). Anyways, it\u2019s been about 4 months and I am struggling to enjoy my job. I feel like the people with me are not driven. This might be company specific as opposed to the whole industry. Also, most of the code we develop is reused from previous models which means the work is redundant. No client interactions at all and even if there was any the client does not change. So for the past few weeks I\u2019ve been researching new skills and I started with SQL which has been really interesting so far. The problem is practicing a skill online is very different than actually doing it in real life situations which is why I feel like it is difficult to base my opinion solely off what I have learned online. My question is has anyone here transitioned from a software role to a data/analytics role? If so, what were the major differences? What did you enjoy? What did you not enjoy? What do you feel would be important to point out to someone in my case? Again I am not saying this field is my passion but I am still young and with no responsibilities so I feel like now is the time to try a bunch of different things until I get to a place where I don\u2019t want to try anything different anymore. \n\n Thank you!", "author_fullname": "t2_6n13dky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l1r6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694965892.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694960018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am a fresh graduate that recently joined a company as an embedded software engineer. To be honest, I never really knew if that was what I wanted to pursue, but it was one of the few job offers that I got so I thought it would be good to start working instead of just sitting at home until I got the job I wanted (which I didn\u2019t know). Anyways, it\u2019s been about 4 months and I am struggling to enjoy my job. I feel like the people with me are not driven. This might be company specific as opposed to the whole industry. Also, most of the code we develop is reused from previous models which means the work is redundant. No client interactions at all and even if there was any the client does not change. So for the past few weeks I\u2019ve been researching new skills and I started with SQL which has been really interesting so far. The problem is practicing a skill online is very different than actually doing it in real life situations which is why I feel like it is difficult to base my opinion solely off what I have learned online. My question is has anyone here transitioned from a software role to a data/analytics role? If so, what were the major differences? What did you enjoy? What did you not enjoy? What do you feel would be important to point out to someone in my case? Again I am not saying this field is my passion but I am still young and with no responsibilities so I feel like now is the time to try a bunch of different things until I get to a place where I don\u2019t want to try anything different anymore. &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16l1r6e", "is_robot_indexable": true, "report_reasons": null, "author": "Whatuphomie112", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l1r6e/software_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l1r6e/software_to_data/", "subreddit_subscribers": 128924, "created_utc": 1694960018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nNewbie in streaming. I need to design a PySpark program that reads the incoming streaming orders, and compare the total amount between last 24 hours data with last 30 days data.\n\nIn this way, what would be the better idea?\n\n1. Read the streaming data by grouping them in 24 hour window and aggregate on amount then save. Then, create another dataframe that reads from saved location (the historical data) and made the comparison.\n2. Read the steaming data without grouping and directly save it to a location. Then, create another dataframe that reads data from saved location and made the grouping (aggregate on amount) and comparison.\n\nOr, is there a better way to do it? In above mentioned way, it will become a batch job, it will not continuously compare last 24 with last 30 days.", "author_fullname": "t2_2x81kpwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming Architecture Advise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kulfi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694937428.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694936778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;Newbie in streaming. I need to design a PySpark program that reads the incoming streaming orders, and compare the total amount between last 24 hours data with last 30 days data.&lt;/p&gt;\n\n&lt;p&gt;In this way, what would be the better idea?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Read the streaming data by grouping them in 24 hour window and aggregate on amount then save. Then, create another dataframe that reads from saved location (the historical data) and made the comparison.&lt;/li&gt;\n&lt;li&gt;Read the steaming data without grouping and directly save it to a location. Then, create another dataframe that reads data from saved location and made the grouping (aggregate on amount) and comparison.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Or, is there a better way to do it? In above mentioned way, it will become a batch job, it will not continuously compare last 24 with last 30 days.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16kulfi", "is_robot_indexable": true, "report_reasons": null, "author": "Disastrous-State-503", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kulfi/streaming_architecture_advise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kulfi/streaming_architecture_advise/", "subreddit_subscribers": 128924, "created_utc": 1694936778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What does it actually mean?", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does BigQuery decouple compute and storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l9fey", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694978256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What does it actually mean?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l9fey", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l9fey/how_does_bigquery_decouple_compute_and_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l9fey/how_does_bigquery_decouple_compute_and_storage/", "subreddit_subscribers": 128924, "created_utc": 1694978256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am interested in experience of Delta table modeling. \n\nDo you have productive examples or learning resources that you can share?\n\nThanks in advance!", "author_fullname": "t2_h8o6jb9k1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta table modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l6vhz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694972197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am interested in experience of Delta table modeling. &lt;/p&gt;\n\n&lt;p&gt;Do you have productive examples or learning resources that you can share?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16l6vhz", "is_robot_indexable": true, "report_reasons": null, "author": "volvoboy-85", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l6vhz/delta_table_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l6vhz/delta_table_modeling/", "subreddit_subscribers": 128924, "created_utc": 1694972197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is most of this towards compute on Databricks, Snowflake, or OS engines like Spark? On licenses for transform tools like dbt or similar? Other?\n\n[View Poll](https://www.reddit.com/poll/16kojun)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does ETL / Transform contribute to your data platform costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kojun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694915750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is most of this towards compute on Databricks, Snowflake, or OS engines like Spark? On licenses for transform tools like dbt or similar? Other?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/16kojun\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kojun", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1695174950774, "options": [{"text": "Up to 30%", "id": "24827014"}, {"text": "30% to 50%", "id": "24827015"}, {"text": "50% to 70%", "id": "24827016"}, {"text": "Above 70%", "id": "24827017"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 93, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kojun/how_much_does_etl_transform_contribute_to_your/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/16kojun/how_much_does_etl_transform_contribute_to_your/", "subreddit_subscribers": 128924, "created_utc": 1694915750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will make a quick post, since time is valuable to all of us.\n\nSo I am looking to graduate after a 5 years long Bachelor pursuit, from a decent University in my home country (Vietnam). During the last 2 years of this time I started learning and tried taking jobs relating to Data, ML/DL, all engineering, starting from small lab-environment experiment conducting to number crunching DA and infra for a ML-oriented-system mocking (I got exposed to MLOps tech and principles in a while \\~ 1yr, but never got serious since my old company was not deploying any users-facing model). Then got bored of all the ML-sys PoC making/testing and started working for a relatively big data center which made uses of both good big-data engineers and math-heavy journal-printing data scientists, I was one of the more heavy lifting engineers in the data science team who code random APIs and backend for our ML system. Around this time I started to feel the need to be come a DE (I kinda liked engineering stuffs more than all the ML model tuning craps, and I believe Data comes first before any ML systems, or even a model deployment) and slowly decided to stop working about AI models and infras and start looking into data flow, quality and whats not. I started to write a lot more Spark, HiveQL queries, designing new ETL flows and start picking up books about data-intensive systems.\n\nThen all of a sudden, I quit and went back to school for 6 months. My grades was degrading and I still have a Ms to follow, so bit of a paranoid back then, I decided to focus on this final Bachelor sprint. During that half a year of running around to fix my grades I did nothing Data-related.\n\nNow I am back, with a financial burden (very personal so I ain't telling) and all-in-all just a lot of free time and wanting to pick up any Data Engineering entry level pos to start working in the field again. Here is when I started to terrify again. \n\nI don't even know how to start, my friends suggested me some remote job boards but the listings are few and far between and mostly for Sr. positions, I am starting to think that this whole remote thing is for big-brain best-of-the-bunch star engineers. Applied for around 50+ entry to mid level and barely getting even a reply. Besides the fact that I don't exactly have any credential as a Data Engineer, my experiences are all over the places with random tech and looked like I had career-related second thoughts every year. This might be my biggest shame if I had to name one.\n\nFinally, what I pose here is a question: How can I, as a CS graduate can start looking, and preparing for a DE position. Is there any courses, certificates, books serving as a hidden requirement that I am not meeting. And most importantly, how can I even start remote working (some of my friends are remote workers and some friends of them are remote DEs, and I have no clue how they started doing it). I would love to hear about your experiences starting working as a remote DE.\n\nThank you for your time and attention. And I am terribly sorry for my tones if it comes off weird or off-putting, as English is only my second language and sometimes it's hard for me to articulate what's on my mind.", "author_fullname": "t2_8udlbwqs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CS grad looking for remote DE entry pos but almost no reply. Plz help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16l4mj0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694966951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will make a quick post, since time is valuable to all of us.&lt;/p&gt;\n\n&lt;p&gt;So I am looking to graduate after a 5 years long Bachelor pursuit, from a decent University in my home country (Vietnam). During the last 2 years of this time I started learning and tried taking jobs relating to Data, ML/DL, all engineering, starting from small lab-environment experiment conducting to number crunching DA and infra for a ML-oriented-system mocking (I got exposed to MLOps tech and principles in a while ~ 1yr, but never got serious since my old company was not deploying any users-facing model). Then got bored of all the ML-sys PoC making/testing and started working for a relatively big data center which made uses of both good big-data engineers and math-heavy journal-printing data scientists, I was one of the more heavy lifting engineers in the data science team who code random APIs and backend for our ML system. Around this time I started to feel the need to be come a DE (I kinda liked engineering stuffs more than all the ML model tuning craps, and I believe Data comes first before any ML systems, or even a model deployment) and slowly decided to stop working about AI models and infras and start looking into data flow, quality and whats not. I started to write a lot more Spark, HiveQL queries, designing new ETL flows and start picking up books about data-intensive systems.&lt;/p&gt;\n\n&lt;p&gt;Then all of a sudden, I quit and went back to school for 6 months. My grades was degrading and I still have a Ms to follow, so bit of a paranoid back then, I decided to focus on this final Bachelor sprint. During that half a year of running around to fix my grades I did nothing Data-related.&lt;/p&gt;\n\n&lt;p&gt;Now I am back, with a financial burden (very personal so I ain&amp;#39;t telling) and all-in-all just a lot of free time and wanting to pick up any Data Engineering entry level pos to start working in the field again. Here is when I started to terrify again. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t even know how to start, my friends suggested me some remote job boards but the listings are few and far between and mostly for Sr. positions, I am starting to think that this whole remote thing is for big-brain best-of-the-bunch star engineers. Applied for around 50+ entry to mid level and barely getting even a reply. Besides the fact that I don&amp;#39;t exactly have any credential as a Data Engineer, my experiences are all over the places with random tech and looked like I had career-related second thoughts every year. This might be my biggest shame if I had to name one.&lt;/p&gt;\n\n&lt;p&gt;Finally, what I pose here is a question: How can I, as a CS graduate can start looking, and preparing for a DE position. Is there any courses, certificates, books serving as a hidden requirement that I am not meeting. And most importantly, how can I even start remote working (some of my friends are remote workers and some friends of them are remote DEs, and I have no clue how they started doing it). I would love to hear about your experiences starting working as a remote DE.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time and attention. And I am terribly sorry for my tones if it comes off weird or off-putting, as English is only my second language and sometimes it&amp;#39;s hard for me to articulate what&amp;#39;s on my mind.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16l4mj0", "is_robot_indexable": true, "report_reasons": null, "author": "Rich-Abbreviations27", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16l4mj0/cs_grad_looking_for_remote_de_entry_pos_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16l4mj0/cs_grad_looking_for_remote_de_entry_pos_but/", "subreddit_subscribers": 128924, "created_utc": 1694966951.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}