{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wanted to hear data quality-related horror stories and also how people fixed them (like [https://www.reddit.com/r/dataengineering/comments/130rfc2/whats\\_your\\_favorite\\_data\\_quality\\_horror\\_story/](https://www.reddit.com/r/dataengineering/comments/130rfc2/whats_your_favorite_data_quality_horror_story/) but also with solutions that people can learn from)\n\n&amp;#x200B;\n\nMy story: Last year, I was handed a dataset to analyze and forecast our Q4 sales. I didn't double-check the data source and ran my models. Predictions were off the charts, and the team was ecstatic. But a week before the big presentation, I realized the dataset had duplicate rows, and some dates were formatted MM/DD and others DD/MM. The \"huge\" sales spike? Just a data mirage. I had to pull several all-nighters to clean the data and re-run the models. The team was not too happy", "author_fullname": "t2_dcdt0mh5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality: Horror Stories (And How You Fixed It)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16jqwut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694816879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to hear data quality-related horror stories and also how people fixed them (like &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/130rfc2/whats_your_favorite_data_quality_horror_story/\"&gt;https://www.reddit.com/r/dataengineering/comments/130rfc2/whats_your_favorite_data_quality_horror_story/&lt;/a&gt; but also with solutions that people can learn from)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My story: Last year, I was handed a dataset to analyze and forecast our Q4 sales. I didn&amp;#39;t double-check the data source and ran my models. Predictions were off the charts, and the team was ecstatic. But a week before the big presentation, I realized the dataset had duplicate rows, and some dates were formatted MM/DD and others DD/MM. The &amp;quot;huge&amp;quot; sales spike? Just a data mirage. I had to pull several all-nighters to clean the data and re-run the models. The team was not too happy&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16jqwut", "is_robot_indexable": true, "report_reasons": null, "author": "gnahznavia", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16jqwut/data_quality_horror_stories_and_how_you_fixed_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16jqwut/data_quality_horror_stories_and_how_you_fixed_it/", "subreddit_subscribers": 128764, "created_utc": 1694816879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious. I was thinking about the DBT packages I couldn't live without and Elementary is the the one. It gives you stored metadata about your models, runs, tests and test results. Slack notification on test failures. Various custom tests. A test dashboard.  I could live without dbt_utils, but not Elementary. Just a ton of useful stuff we'd have to create on our own.", "author_fullname": "t2_8ov8i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Users - What Single Package Could You Not Live Without?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k8qaw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694874034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious. I was thinking about the DBT packages I couldn&amp;#39;t live without and Elementary is the the one. It gives you stored metadata about your models, runs, tests and test results. Slack notification on test failures. Various custom tests. A test dashboard.  I could live without dbt_utils, but not Elementary. Just a ton of useful stuff we&amp;#39;d have to create on our own.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16k8qaw", "is_robot_indexable": true, "report_reasons": null, "author": "leogodin217", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16k8qaw/dbt_users_what_single_package_could_you_not_live/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16k8qaw/dbt_users_what_single_package_could_you_not_live/", "subreddit_subscribers": 128764, "created_utc": 1694874034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last week, I got laid off because my employer decided to lay off approx 7% of the workforce which amounts to more than 1000 employees in the US. \n\nNonetheless, I have my first technical round for the Sr. Data Engineer interview with Amazon Pharmacy next week. I would be glad and grateful if people out here could help me in preparing for that. The first round is the live coding round (80% data structure and algorithms, 20 % SQL). Due to layoffs, I am feeling underconfident but this is probably my best chance to bounce back.  \n\n\nThank you in advance!", "author_fullname": "t2_c2efbhzn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in preparing for Sr. Data Engineer at Amazon Pharmacy || Impacted by recent layoff last week.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k9n58", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694876419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week, I got laid off because my employer decided to lay off approx 7% of the workforce which amounts to more than 1000 employees in the US. &lt;/p&gt;\n\n&lt;p&gt;Nonetheless, I have my first technical round for the Sr. Data Engineer interview with Amazon Pharmacy next week. I would be glad and grateful if people out here could help me in preparing for that. The first round is the live coding round (80% data structure and algorithms, 20 % SQL). Due to layoffs, I am feeling underconfident but this is probably my best chance to bounce back.  &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16k9n58", "is_robot_indexable": true, "report_reasons": null, "author": "Professional_Bug_729", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16k9n58/need_help_in_preparing_for_sr_data_engineer_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16k9n58/need_help_in_preparing_for_sr_data_engineer_at/", "subreddit_subscribers": 128764, "created_utc": 1694876419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all. Looking for some recommendations on next steps. I am a junior data engineer who has primarily worked as a data analyst with companies that had established databases.  I recently got hired on for a company that is using excel sheets for data storage and loading those to power bi for analysis. The issues I am facing are that data is stored in various places with redundant data in excel sheets, the company is scaling up making the excel sheets used for project management and resource allocation unstable and also having multiple users access/update is causing data integrity issues.\u00a0\n\nI would like to implement an rdbms and doing some research there, but since there is no application or gui for user input would also need to secure or build an application. Looking for ideas. My first thought is build a powerapp for the project management/resource allocation and leverage the data verse for data storage that can easily connect to power bi.\u00a0 This would be my first application but feel confident I could get it done and the company would allow me the time and maybe even training budget to learn how to build the custom application.\n\nWhat do you think? Are there other solutions that would be recommended?\n\nPrimary requirements are to track and schedule resource capacity by week and by project. Also, be able to connect to power bi for reporting.\n\nThanks!\u00a0", "author_fullname": "t2_b3ib25ho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No DB or PM Application Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16jxljd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694836501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. Looking for some recommendations on next steps. I am a junior data engineer who has primarily worked as a data analyst with companies that had established databases.  I recently got hired on for a company that is using excel sheets for data storage and loading those to power bi for analysis. The issues I am facing are that data is stored in various places with redundant data in excel sheets, the company is scaling up making the excel sheets used for project management and resource allocation unstable and also having multiple users access/update is causing data integrity issues.\u00a0&lt;/p&gt;\n\n&lt;p&gt;I would like to implement an rdbms and doing some research there, but since there is no application or gui for user input would also need to secure or build an application. Looking for ideas. My first thought is build a powerapp for the project management/resource allocation and leverage the data verse for data storage that can easily connect to power bi.\u00a0 This would be my first application but feel confident I could get it done and the company would allow me the time and maybe even training budget to learn how to build the custom application.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Are there other solutions that would be recommended?&lt;/p&gt;\n\n&lt;p&gt;Primary requirements are to track and schedule resource capacity by week and by project. Also, be able to connect to power bi for reporting.&lt;/p&gt;\n\n&lt;p&gt;Thanks!\u00a0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16jxljd", "is_robot_indexable": true, "report_reasons": null, "author": "Mediocre-Band-9929", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16jxljd/no_db_or_pm_application_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16jxljd/no_db_or_pm_application_help/", "subreddit_subscribers": 128764, "created_utc": 1694836501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Or am I missing something and is there a better way to do this? Also - any suggestions for when the  number of attributes (say across 1st party, 2nd party, and other data) goes is around 15,000 - 20,000? ", "author_fullname": "t2_eajtr4nz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In user journey tracking, segmentation, audience sizing and similar use cases, is it common to create and query tables with 1000+ columns. e.g. where past behavior / preferences / attributes are encoded into individual columns.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16joh9o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694811052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Or am I missing something and is there a better way to do this? Also - any suggestions for when the  number of attributes (say across 1st party, 2nd party, and other data) goes is around 15,000 - 20,000? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16joh9o", "is_robot_indexable": true, "report_reasons": null, "author": "alneuman", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16joh9o/in_user_journey_tracking_segmentation_audience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16joh9o/in_user_journey_tracking_segmentation_audience/", "subreddit_subscribers": 128764, "created_utc": 1694811052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, first time posting here, sorry if this question was already answered. If so, please point me to those answers.\n\nI've been a Data Engineer for the last 4 years, but I have zero academic backgroud, all my knowledge is from my job, as you might imagine, my theoretical knowledge is limited and contained to the tools I've been using.\n\nI think my SQL is pretty good, and I've been working on cloud environment (Azure) for the last 18 months, so my Python is still evolving.\n\nI wanted to enroll into a good online course that would give a good overview of the main topics for a Data Engineer and I've seen the IBM Data Engineering Professional Certificate from edx that talks about a lot of different things that I would like to learn. However, I've read here in some posts that this course is not what it looks like and it's not worth it. I've also seen the Udacity one, but it's too expensive for me.\n\n&amp;#x200B;\n\nSo, my question is: What is the best and most in-depth course you guys know that makes sense for someone like me?\n\n&amp;#x200B;\n\nThanks a lot!", "author_fullname": "t2_194b6jwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to upgrade my skills, but don't know where to start.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16jnbn2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694808264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, first time posting here, sorry if this question was already answered. If so, please point me to those answers.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been a Data Engineer for the last 4 years, but I have zero academic backgroud, all my knowledge is from my job, as you might imagine, my theoretical knowledge is limited and contained to the tools I&amp;#39;ve been using.&lt;/p&gt;\n\n&lt;p&gt;I think my SQL is pretty good, and I&amp;#39;ve been working on cloud environment (Azure) for the last 18 months, so my Python is still evolving.&lt;/p&gt;\n\n&lt;p&gt;I wanted to enroll into a good online course that would give a good overview of the main topics for a Data Engineer and I&amp;#39;ve seen the IBM Data Engineering Professional Certificate from edx that talks about a lot of different things that I would like to learn. However, I&amp;#39;ve read here in some posts that this course is not what it looks like and it&amp;#39;s not worth it. I&amp;#39;ve also seen the Udacity one, but it&amp;#39;s too expensive for me.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So, my question is: What is the best and most in-depth course you guys know that makes sense for someone like me?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16jnbn2", "is_robot_indexable": true, "report_reasons": null, "author": "nunomnt12", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16jnbn2/i_want_to_upgrade_my_skills_but_dont_know_where/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16jnbn2/i_want_to_upgrade_my_skills_but_dont_know_where/", "subreddit_subscribers": 128764, "created_utc": 1694808264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u9bnox3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone looking to learn Azure Data Factory? Here is my introduction video to Azure Data Factory.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16ka9bx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xBJbvTAi5lY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Azure Data Factory | Introduction\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Azure Data Factory | Introduction", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xBJbvTAi5lY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Azure Data Factory | Introduction\"&gt;&lt;/iframe&gt;", "author_name": "Aleksi Partanen Tech", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xBJbvTAi5lY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@AleksiPartanenTech"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xBJbvTAi5lY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Azure Data Factory | Introduction\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16ka9bx", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FKeEuNNSruSnCC6To09w28ojpVFNxdjGdbteplEfVNE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694878002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xBJbvTAi5lY", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3036-VBJK6hj5tduHFLBI40yzkmgpPWrD08pljZYDK0.jpg?auto=webp&amp;s=34679e520bdd4300038a8b6504f24639b57abac3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/3036-VBJK6hj5tduHFLBI40yzkmgpPWrD08pljZYDK0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da229ee7498fd3071489e3e26efa528437a95553", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/3036-VBJK6hj5tduHFLBI40yzkmgpPWrD08pljZYDK0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=735f4314e784b4c2a708f3dc60d81387160fb9ae", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/3036-VBJK6hj5tduHFLBI40yzkmgpPWrD08pljZYDK0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2b29fbf1c5701423ac04992f94e087aa5c820a8", "width": 320, "height": 240}], "variants": {}, "id": "RqHZKoU-tPSLU13wCGokSe0IKcQImAAcwtz5ECvsrSE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16ka9bx", "is_robot_indexable": true, "report_reasons": null, "author": "aleks1ck", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ka9bx/anyone_looking_to_learn_azure_data_factory_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xBJbvTAi5lY", "subreddit_subscribers": 128764, "created_utc": 1694878002.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Azure Data Factory | Introduction", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xBJbvTAi5lY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Azure Data Factory | Introduction\"&gt;&lt;/iframe&gt;", "author_name": "Aleksi Partanen Tech", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xBJbvTAi5lY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@AleksiPartanenTech"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm a Junior in computer science who is minoring in math.\n\nDue to my interest in data science and Machine Learning, I have decided to substitute network and security class for Calculus 3 class.\n\nHowever, I'm also interested in doing data engineering.\n\nConsidering my situation, between Network Security and Calculus 3 class,\n\nwhat would be more beneficial to take in university?", "author_fullname": "t2_d6vpygwb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Math VS Network and Security for Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16jxf77", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694835924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m a Junior in computer science who is minoring in math.&lt;/p&gt;\n\n&lt;p&gt;Due to my interest in data science and Machine Learning, I have decided to substitute network and security class for Calculus 3 class.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;m also interested in doing data engineering.&lt;/p&gt;\n\n&lt;p&gt;Considering my situation, between Network Security and Calculus 3 class,&lt;/p&gt;\n\n&lt;p&gt;what would be more beneficial to take in university?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16jxf77", "is_robot_indexable": true, "report_reasons": null, "author": "softhardwareIT", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16jxf77/math_vs_network_and_security_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16jxf77/math_vs_network_and_security_for_data_engineering/", "subreddit_subscribers": 128764, "created_utc": 1694835924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there fellow data engineers,\nI've been working a data engineering gig for the last year and a half\u2013 unfortunately, like many, I was recently laid off. An observation I've made during my job hunt, is that many more postings for data engineering positions as of late are geared towards having 5+ years of experience\u2013 which starkly contrasts how many entry level positions I was seeing in 2021 (makes sense). I am continuing my own search for the right position, and figured it may be worth asking here\u2013 does anybody know of companies that are hiring earlier-career data engineers currently?", "author_fullname": "t2_4jj3uzbb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Early-career Lead Suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16jrpzc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694835597.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694818919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there fellow data engineers,\nI&amp;#39;ve been working a data engineering gig for the last year and a half\u2013 unfortunately, like many, I was recently laid off. An observation I&amp;#39;ve made during my job hunt, is that many more postings for data engineering positions as of late are geared towards having 5+ years of experience\u2013 which starkly contrasts how many entry level positions I was seeing in 2021 (makes sense). I am continuing my own search for the right position, and figured it may be worth asking here\u2013 does anybody know of companies that are hiring earlier-career data engineers currently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16jrpzc", "is_robot_indexable": true, "report_reasons": null, "author": "TheBeastWithTheYeast", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16jrpzc/earlycareer_lead_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16jrpzc/earlycareer_lead_suggestions/", "subreddit_subscribers": 128764, "created_utc": 1694818919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It has become mandatory to get cert\u00edfication in AZ 104 to stay in my current project and my manager is asking me to clear AZ 400 certification as early as possible. So please suggest any course or any website or any Youtube channel or any platform to gain the required knowledge to clear this AZ 104 certification as early as possible.\n\nThose who cleared this AZ 104 certification or those who have knowledge in this, Please guide me where and how to learn and clear the certification as early as possible.", "author_fullname": "t2_ljqmevrg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to clear AZ 104 certification as early as poss\u00edble ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k97q1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694875315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It has become mandatory to get cert\u00edfication in AZ 104 to stay in my current project and my manager is asking me to clear AZ 400 certification as early as possible. So please suggest any course or any website or any Youtube channel or any platform to gain the required knowledge to clear this AZ 104 certification as early as possible.&lt;/p&gt;\n\n&lt;p&gt;Those who cleared this AZ 104 certification or those who have knowledge in this, Please guide me where and how to learn and clear the certification as early as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16k97q1", "is_robot_indexable": true, "report_reasons": null, "author": "viking_spartan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16k97q1/how_to_clear_az_104_certification_as_early_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16k97q1/how_to_clear_az_104_certification_as_early_as/", "subreddit_subscribers": 128764, "created_utc": 1694875315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, \nIn my team we run Hive query through Dbeaver. The hive job is submitted through a single userid and application name that is generated is random but it starts with HIVE-*. \nI want to customize this depending who is submitting. For example if I am submitting the query. I should be able see a name that in YARN UI. \nI tried two methods\n1. set tez.job.name = \u2018job_name\u2019\n2. Set mapreduce.job.name = \u2018job\u2019\n\nBoth of them throwing error saying \n\u201cthese parameters cant be changed during run time\u201d.\nIs there a way in which i can set a name?\n\nThank you in advance.", "author_fullname": "t2_76h7jr47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting Job name in Hive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16jpdfj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694813931.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694813124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, \nIn my team we run Hive query through Dbeaver. The hive job is submitted through a single userid and application name that is generated is random but it starts with HIVE-*. \nI want to customize this depending who is submitting. For example if I am submitting the query. I should be able see a name that in YARN UI. \nI tried two methods\n1. set tez.job.name = \u2018job_name\u2019\n2. Set mapreduce.job.name = \u2018job\u2019&lt;/p&gt;\n\n&lt;p&gt;Both of them throwing error saying \n\u201cthese parameters cant be changed during run time\u201d.\nIs there a way in which i can set a name?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16jpdfj", "is_robot_indexable": true, "report_reasons": null, "author": "s1va1209", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16jpdfj/setting_job_name_in_hive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16jpdfj/setting_job_name_in_hive/", "subreddit_subscribers": 128764, "created_utc": 1694813124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  \nI'm learning Airflow and have some simple tasks running.  I am having a very serious problem with the  update task running successfully, but, no changes in the database.    \n\n\nThis is all just running on my laptop, so, there aren't networking complications.  It's just a way to get my feet wet with airflow.  \n\n\nThis task finds files in the pickup directory.  The file has a query in it.  like so:  \n*UPDATE public.public\\_statistics set date\\_exported = CURRENT\\_TIMESTAMP where county\\_fips in (31109); COMMIT;*\n\nRunning the query in psql and the update occurs.  So, there's no syntax issues.  Also, it appears that the PostgresOperator and PostgresHandler are being deprecated in favor of SQLExecuteQueryOperator??  Not sure if that has anything to do with my issue.  \n\n\nPretty sure I am missing something small.  Any advice is welcome.\n\n    import json\n    import sys\n    import os\n    from airflow.models import Variable\n    from airflow.models.xcom import XCom\n    #from airflow.operators.postgres_operator import PostgresOperator\n    from airflow import AirflowException\n    from airflow.exceptions import AirflowProviderDeprecationWarning\n    from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator\n    \n    def update_pg_row():\n    \n     os.chdir('/home/sandbox/airflow/dags/datasets/pickup')\n     process_file_list = list()\n    \n     all_files_list = os.listdir(\"./\")\n     #KISS any file here has not been imported to snowflake\n    \n     for i in all_files_list:\n      if i.startswith('update_row_'):\n        process_file_list.append(i)\n    \n    \n     if len(process_file_list) == 0:\n       print(\"no fips update files to process\")\n       return()\n    \n     print(process_file_list)\n     print(\"length of file_list {}\".format(len(process_file_list)))\n     for f in process_file_list:\n      file_stats = os.stat(f)\n      print(\"processing {}\".format(f))\n      if file_stats.st_size &gt; 10:\n       fh = open(f, \"r+\")\n       qry = fh.read()\n       print(\"!!!!!!!!!!!! DEBUG !!!!!!!!!!!!!!!\")\n       print(qry)\n       try:\n        conn_op = SQLExecuteQueryOperator(\n         conn_id='pg_for_me',\n         task_id='update-pg-row-as-synced',\n         autocommit=True,\n         sql=f\n         )\n       except Exception as e:\n        print('cannot get queryoperator')\n        raise AirflowException(e)\n      else:\n       #should never be here.\n       print(\"{} is too small??  {}\".format(f,file_stats.st_size))\n    \n\n&amp;#x200B;", "author_fullname": "t2_km4f2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Airflow PostgreSQL not Committing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16kev5p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694890026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;br/&gt;\nI&amp;#39;m learning Airflow and have some simple tasks running.  I am having a very serious problem with the  update task running successfully, but, no changes in the database.    &lt;/p&gt;\n\n&lt;p&gt;This is all just running on my laptop, so, there aren&amp;#39;t networking complications.  It&amp;#39;s just a way to get my feet wet with airflow.  &lt;/p&gt;\n\n&lt;p&gt;This task finds files in the pickup directory.  The file has a query in it.  like so:&lt;br/&gt;\n&lt;em&gt;UPDATE public.public_statistics set date_exported = CURRENT_TIMESTAMP where county_fips in (31109); COMMIT;&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Running the query in psql and the update occurs.  So, there&amp;#39;s no syntax issues.  Also, it appears that the PostgresOperator and PostgresHandler are being deprecated in favor of SQLExecuteQueryOperator??  Not sure if that has anything to do with my issue.  &lt;/p&gt;\n\n&lt;p&gt;Pretty sure I am missing something small.  Any advice is welcome.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import json\nimport sys\nimport os\nfrom airflow.models import Variable\nfrom airflow.models.xcom import XCom\n#from airflow.operators.postgres_operator import PostgresOperator\nfrom airflow import AirflowException\nfrom airflow.exceptions import AirflowProviderDeprecationWarning\nfrom airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator\n\ndef update_pg_row():\n\n os.chdir(&amp;#39;/home/sandbox/airflow/dags/datasets/pickup&amp;#39;)\n process_file_list = list()\n\n all_files_list = os.listdir(&amp;quot;./&amp;quot;)\n #KISS any file here has not been imported to snowflake\n\n for i in all_files_list:\n  if i.startswith(&amp;#39;update_row_&amp;#39;):\n    process_file_list.append(i)\n\n\n if len(process_file_list) == 0:\n   print(&amp;quot;no fips update files to process&amp;quot;)\n   return()\n\n print(process_file_list)\n print(&amp;quot;length of file_list {}&amp;quot;.format(len(process_file_list)))\n for f in process_file_list:\n  file_stats = os.stat(f)\n  print(&amp;quot;processing {}&amp;quot;.format(f))\n  if file_stats.st_size &amp;gt; 10:\n   fh = open(f, &amp;quot;r+&amp;quot;)\n   qry = fh.read()\n   print(&amp;quot;!!!!!!!!!!!! DEBUG !!!!!!!!!!!!!!!&amp;quot;)\n   print(qry)\n   try:\n    conn_op = SQLExecuteQueryOperator(\n     conn_id=&amp;#39;pg_for_me&amp;#39;,\n     task_id=&amp;#39;update-pg-row-as-synced&amp;#39;,\n     autocommit=True,\n     sql=f\n     )\n   except Exception as e:\n    print(&amp;#39;cannot get queryoperator&amp;#39;)\n    raise AirflowException(e)\n  else:\n   #should never be here.\n   print(&amp;quot;{} is too small??  {}&amp;quot;.format(f,file_stats.st_size))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16kev5p", "is_robot_indexable": true, "report_reasons": null, "author": "chock-a-block", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kev5p/apache_airflow_postgresql_not_committing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kev5p/apache_airflow_postgresql_not_committing/", "subreddit_subscribers": 128764, "created_utc": 1694890026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I'm planning to build a new microservice where I'm going to execute an athena query and send the query results as response after doing some transformations through pandas.\n\nAnd I'm having limitations with Athena since max results I can get from athena is 1000 and I need to implement pagination. And most of the queries going to be have more than 150k results.. so paginations gonna take alot time and I feels like its a hectic process as well.\n\nIs there any other way we can do it much simpler ? Where I get complete query result in one go ?", "author_fullname": "t2_5s0b87mm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complete Athena Query results", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16kec3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694888634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I&amp;#39;m planning to build a new microservice where I&amp;#39;m going to execute an athena query and send the query results as response after doing some transformations through pandas.&lt;/p&gt;\n\n&lt;p&gt;And I&amp;#39;m having limitations with Athena since max results I can get from athena is 1000 and I need to implement pagination. And most of the queries going to be have more than 150k results.. so paginations gonna take alot time and I feels like its a hectic process as well.&lt;/p&gt;\n\n&lt;p&gt;Is there any other way we can do it much simpler ? Where I get complete query result in one go ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16kec3d", "is_robot_indexable": true, "report_reasons": null, "author": "imameeer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kec3d/complete_athena_query_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kec3d/complete_athena_query_results/", "subreddit_subscribers": 128764, "created_utc": 1694888634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All\n\nI\u2019m working on a side project, where I want to have a simple website, that displays the top x categories based on some use cases. I want to deploy it to AWS. I want your help.\n\nCurrently I thought the following arch:\n\n1. Write a simple python code with fast api to handle the requests.\n2. Use lambda function with api gateway for the rest calls.\n3. When the rest api request is sent, the lambda function would be called, does some validations and trigger step functions.\n4. Step functions acts as orchestration, which calls the glue job for processing the data. The raw data would be in s3. Glue job does some processing on raw data ( computes the top x categories.\n5. The transformed data is stored in Dynamo DB ( I want more advice here ).\n6. Another lambda would be triggered to push the response to the rest api.\n\nI\u2019m working for first time on rest api. I want to understand how does results are pushed to the client? And also using Dynamodb is worth? I want to achieve low latency. Aiming to have 4000-5000 requests per second.\nAny suggestions are welcome :) \nThanks in advance.\n\nEdit-1 : 4K-5k per seconds too much, so thought of 60-80 requests per second.\nAlso want to understand how can I run sql ( that\u2019s the reason I had spark job in place )", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Architecture help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kd1ku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694890835.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694885238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;/p&gt;\n\n&lt;p&gt;I\u2019m working on a side project, where I want to have a simple website, that displays the top x categories based on some use cases. I want to deploy it to AWS. I want your help.&lt;/p&gt;\n\n&lt;p&gt;Currently I thought the following arch:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Write a simple python code with fast api to handle the requests.&lt;/li&gt;\n&lt;li&gt;Use lambda function with api gateway for the rest calls.&lt;/li&gt;\n&lt;li&gt;When the rest api request is sent, the lambda function would be called, does some validations and trigger step functions.&lt;/li&gt;\n&lt;li&gt;Step functions acts as orchestration, which calls the glue job for processing the data. The raw data would be in s3. Glue job does some processing on raw data ( computes the top x categories.&lt;/li&gt;\n&lt;li&gt;The transformed data is stored in Dynamo DB ( I want more advice here ).&lt;/li&gt;\n&lt;li&gt;Another lambda would be triggered to push the response to the rest api.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I\u2019m working for first time on rest api. I want to understand how does results are pushed to the client? And also using Dynamodb is worth? I want to achieve low latency. Aiming to have 4000-5000 requests per second.\nAny suggestions are welcome :) \nThanks in advance.&lt;/p&gt;\n\n&lt;p&gt;Edit-1 : 4K-5k per seconds too much, so thought of 60-80 requests per second.\nAlso want to understand how can I run sql ( that\u2019s the reason I had spark job in place )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16kd1ku", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16kd1ku/architecture_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kd1ku/architecture_help/", "subreddit_subscribers": 128764, "created_utc": 1694885238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a data engineer, I like to spend my free time building data pipelines. This is a data pipeline I built using streaming databases and Formula 1 data because I find it very interesting. What do you think about it, any input is highly appreciated.\n\n[https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave](https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave)", "author_fullname": "t2_nvvyzf8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Formula 1 streaming pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16kcti2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694884654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data engineer, I like to spend my free time building data pipelines. This is a data pipeline I built using streaming databases and Formula 1 data because I find it very interesting. What do you think about it, any input is highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave\"&gt;https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?auto=webp&amp;s=c75a4459630fbf2ba807d871253197c73fee84b3", "width": 1640, "height": 924}, "resolutions": [{"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78c5e8ca5e715c2b45977bc797a53958df5e5350", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f65b3fc49964ecea50d1415b3f430435adf1e443", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e670fb69551dd0234d86517fc6806afd11c931fd", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b92f03ec856f8721ee28ab2329bf6d974ecd2861", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93b4bebf3215729b045c167284a40639a5933735", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/fDSy2NGsau5lULLUL185s1PzHxU46WWwzhzATg9TEVw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=493c7ec70ca522c3536bc6164c8d5e6ca3602be1", "width": 1080, "height": 608}], "variants": {}, "id": "4o0Esqv7Gv1mS0Up9bOubHnnI0tJen4dv1w3Mvm0BfE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16kcti2", "is_robot_indexable": true, "report_reasons": null, "author": "WhiteLionGr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16kcti2/formula_1_streaming_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16kcti2/formula_1_streaming_pipeline/", "subreddit_subscribers": 128764, "created_utc": 1694884654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey we have a use case to bring data from GBQ into Kafka to use it further downstream onto a 3rd service. Checking if anyone worked on a similar use case or can guide me how we can begin building a custom plugin that can work. \n\n#Airflow #Kafka #GoogleBigQuery", "author_fullname": "t2_a1kfssrv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow Operator - Gbq to Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16jpy56", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694814484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey we have a use case to bring data from GBQ into Kafka to use it further downstream onto a 3rd service. Checking if anyone worked on a similar use case or can guide me how we can begin building a custom plugin that can work. &lt;/p&gt;\n\n&lt;h1&gt;Airflow #Kafka #GoogleBigQuery&lt;/h1&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16jpy56", "is_robot_indexable": true, "report_reasons": null, "author": "III-Coast-R1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16jpy56/airflow_operator_gbq_to_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16jpy56/airflow_operator_gbq_to_kafka/", "subreddit_subscribers": 128764, "created_utc": 1694814484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone getting Tax Credit Screening Questionnaires in their job apps?", "author_fullname": "t2_11lit3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Apps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16jppta", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694813924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone getting Tax Credit Screening Questionnaires in their job apps?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16jppta", "is_robot_indexable": true, "report_reasons": null, "author": "window2525", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16jppta/job_apps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16jppta/job_apps/", "subreddit_subscribers": 128764, "created_utc": 1694813924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI wanted to better understand how people are using ERD tools in their daily work.\n\nIf you have time I'd be really grateful if you could fill in this form asking some questions around if and how you're currently using ERD software :\n\n[https://forms.gle/c6CyrjhjtgACGQXy9](https://forms.gle/c6CyrjhjtgACGQXy9)\n\nThanks!", "author_fullname": "t2_a39uitkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ERD Tools - seeking feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16k0wt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694848322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I wanted to better understand how people are using ERD tools in their daily work.&lt;/p&gt;\n\n&lt;p&gt;If you have time I&amp;#39;d be really grateful if you could fill in this form asking some questions around if and how you&amp;#39;re currently using ERD software :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://forms.gle/c6CyrjhjtgACGQXy9\"&gt;https://forms.gle/c6CyrjhjtgACGQXy9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?auto=webp&amp;s=e67bcfb8bbfbb6c787d641b669e44765dd1ee979", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=13172bd5fa8cda348a0de0bd74b16ea77d24fbdc", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cca98ccacf26166b8529174a011189b08bb8f1ac", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3499f0e7a38234e5b2840a31acb9b911c11ef28a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b2898e0c9ab6439c0cb677fd29534557b81e294f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f90c96cdd409646b91ca24c9aea49479f3379fdc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Gu8VCd3Tlr_suwR5l5AJgv0JzvUSsFETd1OH4ldlzdA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a3a8d8a4e29ab700d0c2425462d767115e51f2d9", "width": 1080, "height": 567}], "variants": {}, "id": "tSVJF_x9Xgf_v7OmqQVgCGhK3gKuRoGGlx-CEgkuUMA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16k0wt1", "is_robot_indexable": true, "report_reasons": null, "author": "Tizniti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16k0wt1/erd_tools_seeking_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16k0wt1/erd_tools_seeking_feedback/", "subreddit_subscribers": 128764, "created_utc": 1694848322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hi All,\n\nWhen you have a chance can you give my AI/ML dev tool a look? I'm trying to get feedback and figure out what other use cases it could address.\n\nThe name of the python package is called [Burla](https://www.burla.dev/docs), the goal is to make it simple to run any python function, on thousands of CPUs/GPUs, with zero setup and just one line of code. I just got it running at 4k CPU concurrency and 500 GPU concurrency per user (I think).\n\nI built this for batch inference because I've been working on a data science team at a logistics company where I constantly need to pass millions of rail, truck, and ocean freight routes through ML pricing inference models. If you can think of any other solid use cases or if you think the product is shit please let me know. All feedback is wanted even if you think the project is a dud.\n\n**Command line setup**\n\n    pip install burla    \n    burla login   \n\n**Python Code Example**\n\n    from burla import remote_parallel_map   \n    from time import sleep     \n    \n    my_inputs = list(range(1000))  \u200b    \n    \n    def my_function(my_input):              \n        sleep(60) # &lt;- Pretend this is some complex code!               \n        print(f\"Processed Input #{my_input}\")               \n        return my_input \u200b     \n    \n    results = remote_parallel_map(my_function, my_inputs)   \n\n**FYI: For feedback purposes anyone who uses Burla has 10k CPU and 1k GPU hours free.**", "author_fullname": "t2_7iyeps3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Break My LLM Batch Inference Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16jqgc9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694815713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;When you have a chance can you give my AI/ML dev tool a look? I&amp;#39;m trying to get feedback and figure out what other use cases it could address.&lt;/p&gt;\n\n&lt;p&gt;The name of the python package is called &lt;a href=\"https://www.burla.dev/docs\"&gt;Burla&lt;/a&gt;, the goal is to make it simple to run any python function, on thousands of CPUs/GPUs, with zero setup and just one line of code. I just got it running at 4k CPU concurrency and 500 GPU concurrency per user (I think).&lt;/p&gt;\n\n&lt;p&gt;I built this for batch inference because I&amp;#39;ve been working on a data science team at a logistics company where I constantly need to pass millions of rail, truck, and ocean freight routes through ML pricing inference models. If you can think of any other solid use cases or if you think the product is shit please let me know. All feedback is wanted even if you think the project is a dud.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Command line setup&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pip install burla    \nburla login   \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;Python Code Example&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from burla import remote_parallel_map   \nfrom time import sleep     \n\nmy_inputs = list(range(1000))  \u200b    \n\ndef my_function(my_input):              \n    sleep(60) # &amp;lt;- Pretend this is some complex code!               \n    print(f&amp;quot;Processed Input #{my_input}&amp;quot;)               \n    return my_input \u200b     \n\nresults = remote_parallel_map(my_function, my_inputs)   \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;FYI: For feedback purposes anyone who uses Burla has 10k CPU and 1k GPU hours free.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/laQ7zqbpqgTwOLHZvWuG_U6a93HNqko8DR9V9Mz0W18.jpg?auto=webp&amp;s=3accd7ccb7e3bd611dd668afa7970a4698483811", "width": 1680, "height": 930}, "resolutions": [{"url": "https://external-preview.redd.it/laQ7zqbpqgTwOLHZvWuG_U6a93HNqko8DR9V9Mz0W18.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=869e6b2c58d87065b4dd8059f2281d18e8c3b943", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/laQ7zqbpqgTwOLHZvWuG_U6a93HNqko8DR9V9Mz0W18.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=547dee6870e939a9b5a7d432f4bdffd6cab3d8ce", "width": 216, "height": 119}, {"url": "https://external-preview.redd.it/laQ7zqbpqgTwOLHZvWuG_U6a93HNqko8DR9V9Mz0W18.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=47613ec19527a2b843f6614d99542f1414950ca2", "width": 320, "height": 177}, {"url": "https://external-preview.redd.it/laQ7zqbpqgTwOLHZvWuG_U6a93HNqko8DR9V9Mz0W18.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=326cb22591b246fe96d8abdd1518e2b85fce4aeb", "width": 640, "height": 354}, {"url": "https://external-preview.redd.it/laQ7zqbpqgTwOLHZvWuG_U6a93HNqko8DR9V9Mz0W18.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f28625920970ac5a070d0380f71639d0ce5f6f41", "width": 960, "height": 531}, {"url": "https://external-preview.redd.it/laQ7zqbpqgTwOLHZvWuG_U6a93HNqko8DR9V9Mz0W18.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87123c872bd1cbe48c9d0a8d16d186d77c40a279", "width": 1080, "height": 597}], "variants": {}, "id": "Kiqp2qSYAsdXNVRwSruvpl5EypAguomERaUQfzeF_PM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16jqgc9", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Post_149", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16jqgc9/break_my_llm_batch_inference_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16jqgc9/break_my_llm_batch_inference_tool/", "subreddit_subscribers": 128764, "created_utc": 1694815713.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}