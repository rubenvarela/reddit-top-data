{"kind": "Listing", "data": {"after": "t3_16ihhv3", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is one of the most helpful subs I have come across personally. For me, I have learnt about how to progress in my career, help for interviews and certs also.\nSo, thank you to everyone who keeps commenting and figuring out ways to help others with their queries.", "author_fullname": "t2_5on7s1v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Love you guys!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16iaaku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 95, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694671175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is one of the most helpful subs I have come across personally. For me, I have learnt about how to progress in my career, help for interviews and certs also.\nSo, thank you to everyone who keeps commenting and figuring out ways to help others with their queries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16iaaku", "is_robot_indexable": true, "report_reasons": null, "author": "xander800", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16iaaku/love_you_guys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16iaaku/love_you_guys/", "subreddit_subscribers": 128430, "created_utc": 1694671175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked as a data scientist / engineer for the last 9 years but always at a scale a bit below where you really need distributed computing (i.e. SQL databases of a few terabytes). I'm interested in developing the skills that can take me to the next level of scale, but at my job we simply don't have that amount of data. Launching and running a cluster just for fun also seems like it would be a bit expensive. And if I'd want to make a shift to a senior data engineering role at this larger scale, they're going to want me to have some of this experience _before_ I get hired.\n\nWhat's a good way to expose myself to problems that I can solve with Kafka / Spark (i.e. I'm interested in streaming algorithms and mapreduce-like problems)? I'm wondering if there are (for example) open source geo datasets and public servers that you can do some work on (though obviously those cost money as well, so maybe I'm naive to think that).\n\nObviously I'm a bit new to this area so please do let me know if I said anything dumb :) I read \"Designing Data-Intensive Applications\" and have a decent grasp of CS fundamentals, but obviously there's some specialized expertise to be had here.", "author_fullname": "t2_23t9wnbf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to build experience in Kafka and Spark if not in a data engineering job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16i3u4l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694651454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked as a data scientist / engineer for the last 9 years but always at a scale a bit below where you really need distributed computing (i.e. SQL databases of a few terabytes). I&amp;#39;m interested in developing the skills that can take me to the next level of scale, but at my job we simply don&amp;#39;t have that amount of data. Launching and running a cluster just for fun also seems like it would be a bit expensive. And if I&amp;#39;d want to make a shift to a senior data engineering role at this larger scale, they&amp;#39;re going to want me to have some of this experience &lt;em&gt;before&lt;/em&gt; I get hired.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s a good way to expose myself to problems that I can solve with Kafka / Spark (i.e. I&amp;#39;m interested in streaming algorithms and mapreduce-like problems)? I&amp;#39;m wondering if there are (for example) open source geo datasets and public servers that you can do some work on (though obviously those cost money as well, so maybe I&amp;#39;m naive to think that).&lt;/p&gt;\n\n&lt;p&gt;Obviously I&amp;#39;m a bit new to this area so please do let me know if I said anything dumb :) I read &amp;quot;Designing Data-Intensive Applications&amp;quot; and have a decent grasp of CS fundamentals, but obviously there&amp;#39;s some specialized expertise to be had here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16i3u4l", "is_robot_indexable": true, "report_reasons": null, "author": "failarmyworm", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16i3u4l/how_to_build_experience_in_kafka_and_spark_if_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16i3u4l/how_to_build_experience_in_kafka_and_spark_if_not/", "subreddit_subscribers": 128430, "created_utc": 1694651454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\nI'm Matteo, one of the co-founder of Dozer. I have posted here before about our project, but we were very early and only had just a bit more of a prototype. The project has evolved quite a lot and I'm quite happy with the experience we are building.\n\nFundamentally, with Dozer it's now possible to define all connections to your databases, data warehouses or object stores, provide some SQL transformations (WASM and TypeScript coming soon) and declare how data should be exposed as APIs. We take care of pretty much anything in the middle: sourcing the data, transforming in real time (we have built our own streaming SQL engine) and exposing it as REST and gRPC APIs.\n\nWe have built a full UI experience that allow a user to inspect the transformations and the data in real-time. Our vision is for Dozer to become a full data-application backend. Imagine you have multiple sources of data and you need to stitch them together to create a webapp. Connecting to the data sources, moving the data, keeping it fresh, cache in an a low latency store is a lot of work. That is what we want to solve with Dozer.\n\nI'm sharing a short video of our latest release ([https://www.youtube.com/watch?v=jS-Rdqn1NYw](https://www.youtube.com/watch?v=jS-Rdqn1NYw)) and I'd be really interested to know your thoughts and how you would use it.\n\nThanks  \nMatteo", "author_fullname": "t2_5efs1s7d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How we are trying to reduce the pains of building a data application using Dozer: real-time sourcing, stitching, transformations and serving APIs all in a single Rust binary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16i821c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694663690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m Matteo, one of the co-founder of Dozer. I have posted here before about our project, but we were very early and only had just a bit more of a prototype. The project has evolved quite a lot and I&amp;#39;m quite happy with the experience we are building.&lt;/p&gt;\n\n&lt;p&gt;Fundamentally, with Dozer it&amp;#39;s now possible to define all connections to your databases, data warehouses or object stores, provide some SQL transformations (WASM and TypeScript coming soon) and declare how data should be exposed as APIs. We take care of pretty much anything in the middle: sourcing the data, transforming in real time (we have built our own streaming SQL engine) and exposing it as REST and gRPC APIs.&lt;/p&gt;\n\n&lt;p&gt;We have built a full UI experience that allow a user to inspect the transformations and the data in real-time. Our vision is for Dozer to become a full data-application backend. Imagine you have multiple sources of data and you need to stitch them together to create a webapp. Connecting to the data sources, moving the data, keeping it fresh, cache in an a low latency store is a lot of work. That is what we want to solve with Dozer.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sharing a short video of our latest release (&lt;a href=\"https://www.youtube.com/watch?v=jS-Rdqn1NYw\"&gt;https://www.youtube.com/watch?v=jS-Rdqn1NYw&lt;/a&gt;) and I&amp;#39;d be really interested to know your thoughts and how you would use it.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;br/&gt;\nMatteo&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m9Dyyw7SVKKXWh6rgWEmkpJQb1Z2qb-rUb5sRmLAoYI.jpg?auto=webp&amp;s=e491c63737cf75d665a21ee3e758d32f86197552", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/m9Dyyw7SVKKXWh6rgWEmkpJQb1Z2qb-rUb5sRmLAoYI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=10efdbbaf9e9dd94976a4c2cd124329f3c8a6e1a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/m9Dyyw7SVKKXWh6rgWEmkpJQb1Z2qb-rUb5sRmLAoYI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b96e203701420d0612b30c78a6baa67706d4a86", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/m9Dyyw7SVKKXWh6rgWEmkpJQb1Z2qb-rUb5sRmLAoYI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6c66e31a49cd0e8eec343fa182d1d131348215bf", "width": 320, "height": 240}], "variants": {}, "id": "XCBKCwSo6DEVWkTvplN3stagQ71OOqNepQxK2naykq4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16i821c", "is_robot_indexable": true, "report_reasons": null, "author": "matteopelati76", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16i821c/how_we_are_trying_to_reduce_the_pains_of_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16i821c/how_we_are_trying_to_reduce_the_pains_of_building/", "subreddit_subscribers": 128430, "created_utc": 1694663690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a 27-year-old data practitioner with experience in both data analytics and engineering. I graduated in 2019 and initially worked as a machine learning engineer for four months. Unfortunately, I had to resign due to family health issues, which took precedence.\n\nI was determined to continue my career journey, so I joined Omdena as a volunteer, where I honed my skills and recently completed a data engineering internship. I also obtained the DataBricks certification for Data Engineer Associate, believing it would open doors to full-time employment.\n\nHowever, my current situation has left me feeling lost and uncertain. Despite my efforts, I've been unable to secure a full-time position, while my peers in my friend circle have progressed to senior roles. This has left me feeling both disheartened and anxious about my future.\n\nI don't seek pity but rather any guidance or advice you can offer that might help me change the course of my career. Thank you for your assistance.", "author_fullname": "t2_84ztczxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "27 year old data practitioner, no job .", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ibao1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694674751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a 27-year-old data practitioner with experience in both data analytics and engineering. I graduated in 2019 and initially worked as a machine learning engineer for four months. Unfortunately, I had to resign due to family health issues, which took precedence.&lt;/p&gt;\n\n&lt;p&gt;I was determined to continue my career journey, so I joined Omdena as a volunteer, where I honed my skills and recently completed a data engineering internship. I also obtained the DataBricks certification for Data Engineer Associate, believing it would open doors to full-time employment.&lt;/p&gt;\n\n&lt;p&gt;However, my current situation has left me feeling lost and uncertain. Despite my efforts, I&amp;#39;ve been unable to secure a full-time position, while my peers in my friend circle have progressed to senior roles. This has left me feeling both disheartened and anxious about my future.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t seek pity but rather any guidance or advice you can offer that might help me change the course of my career. Thank you for your assistance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ibao1", "is_robot_indexable": true, "report_reasons": null, "author": "chaachans", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ibao1/27_year_old_data_practitioner_no_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ibao1/27_year_old_data_practitioner_no_job/", "subreddit_subscribers": 128430, "created_utc": 1694674751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we have several tens of cronjobs in our k8s cluster which everyone has different schedule. We were discussing that maybe we should put most of the cronjobs into the Airflow because of easier rerunning failed jobs and because of easier to see history of runs. On the other hand it would mean we would have tens/hundreds of dags consisting of one single task as every one has different schedule. \n\nIs there any recommendation for such case? Yes or no and why?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cronjobs vs Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hugdx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694629043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we have several tens of cronjobs in our k8s cluster which everyone has different schedule. We were discussing that maybe we should put most of the cronjobs into the Airflow because of easier rerunning failed jobs and because of easier to see history of runs. On the other hand it would mean we would have tens/hundreds of dags consisting of one single task as every one has different schedule. &lt;/p&gt;\n\n&lt;p&gt;Is there any recommendation for such case? Yes or no and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16hugdx", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hugdx/cronjobs_vs_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hugdx/cronjobs_vs_airflow/", "subreddit_subscribers": 128430, "created_utc": 1694629043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The whole thing is classic, honestly. Ancient, 750 lines long SQL query written in an esoteric dialect. No documentation, of course. I need to take this thing and rewrite it for Spark, but I have a hard time even approaching it, like, getting a mental image of what goes where.\n\nHow would you go about this task? Try to create a diagram? Miro, whiteboard, pen and paper?", "author_fullname": "t2_e5hzso", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to approach an long SQL query with no documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16imcbc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694707606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The whole thing is classic, honestly. Ancient, 750 lines long SQL query written in an esoteric dialect. No documentation, of course. I need to take this thing and rewrite it for Spark, but I have a hard time even approaching it, like, getting a mental image of what goes where.&lt;/p&gt;\n\n&lt;p&gt;How would you go about this task? Try to create a diagram? Miro, whiteboard, pen and paper?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16imcbc", "is_robot_indexable": true, "report_reasons": null, "author": "a1ic3_g1a55", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16imcbc/how_to_approach_an_long_sql_query_with_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16imcbc/how_to_approach_an_long_sql_query_with_no/", "subreddit_subscribers": 128430, "created_utc": 1694707606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is just something that I\u2019ve been contemplating lately. I just started a second degree in CS. Before starting the degree, I was, and still interested, in data analytics. I learned Excel, SQL (basic to intermediate), and basic Python. I also learned web development and know JavaScript, and know basic Java. I definitely feel like I\u2019m jumping around a lot because I have interests in different areas in technology.\n\nI\u2019m planning on graduating in 2 and a half years. My goal is to become a Data Engineer. I\u2019m wondering if I should focus my limited free time on creating projects that specifically targets software engineer positions or projects that target data analyst roles? \n\nReading this subreddit, some people said that to be a great data engineer, you need to have experience as a software engineer. But I\u2019ve also seen and connected with quite a few people that started off as a Data Analyst and eventually became a Data Engineer, without having any professional background as a Software Engineer. I feel like I want to learn everything to be qualified for both roles but I\u2019m not sure \ud83d\ude05", "author_fullname": "t2_816e80tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst\u2014&gt; DE or SWE \u2014&gt; DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ikqsx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694703743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is just something that I\u2019ve been contemplating lately. I just started a second degree in CS. Before starting the degree, I was, and still interested, in data analytics. I learned Excel, SQL (basic to intermediate), and basic Python. I also learned web development and know JavaScript, and know basic Java. I definitely feel like I\u2019m jumping around a lot because I have interests in different areas in technology.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m planning on graduating in 2 and a half years. My goal is to become a Data Engineer. I\u2019m wondering if I should focus my limited free time on creating projects that specifically targets software engineer positions or projects that target data analyst roles? &lt;/p&gt;\n\n&lt;p&gt;Reading this subreddit, some people said that to be a great data engineer, you need to have experience as a software engineer. But I\u2019ve also seen and connected with quite a few people that started off as a Data Analyst and eventually became a Data Engineer, without having any professional background as a Software Engineer. I feel like I want to learn everything to be qualified for both roles but I\u2019m not sure \ud83d\ude05&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ikqsx", "is_robot_indexable": true, "report_reasons": null, "author": "Humble-Ad-2280", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ikqsx/data_analyst_de_or_swe_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ikqsx/data_analyst_de_or_swe_de/", "subreddit_subscribers": 128430, "created_utc": 1694703743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have my final interview upcoming with a wells fargo panel. I have been preparing, but I wanted to ask if anyone has gone through the interview process and how did it go?\n\nAny advice would be appreciated. I am graduating soon and would love to have a job for when I graduate.", "author_fullname": "t2_ts5ccrmt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone interviewed at Wells Fargo for an entry level data engineer role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hyzx3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694639545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have my final interview upcoming with a wells fargo panel. I have been preparing, but I wanted to ask if anyone has gone through the interview process and how did it go?&lt;/p&gt;\n\n&lt;p&gt;Any advice would be appreciated. I am graduating soon and would love to have a job for when I graduate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16hyzx3", "is_robot_indexable": true, "report_reasons": null, "author": "Much-Series1120", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hyzx3/has_anyone_interviewed_at_wells_fargo_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hyzx3/has_anyone_interviewed_at_wells_fargo_for_an/", "subreddit_subscribers": 128430, "created_utc": 1694639545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what have you done to bolster your knowledge, we recently hired a staff engineer and the dude isn't out of his 20s and hole leeeeeee chit does he know his stuff.", "author_fullname": "t2_vtm8z2o0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like my knowledge is just surface level what have you done to bolster the depth of your knowledge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16i6zh8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694660427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what have you done to bolster your knowledge, we recently hired a staff engineer and the dude isn&amp;#39;t out of his 20s and hole leeeeeee chit does he know his stuff.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16i6zh8", "is_robot_indexable": true, "report_reasons": null, "author": "Action_Maxim", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16i6zh8/i_feel_like_my_knowledge_is_just_surface_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16i6zh8/i_feel_like_my_knowledge_is_just_surface_level/", "subreddit_subscribers": 128430, "created_utc": 1694660427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are some best practices for developing data applications/pipelines using Spark? I'll be using PySpark, if there's any specific to that on top of Spark. Looking for any tips, from how to write code, to designing pipelines. A few I've learned from what I've gathered are to chain commands/functions in the code.\n\nI'm not very experienced in performance tuning and partitioning, so I'd love anything related to those topics as well!", "author_fullname": "t2_1k8fjdz5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some best practices for developing Spark data applications/pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hup03", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694629597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some best practices for developing data applications/pipelines using Spark? I&amp;#39;ll be using PySpark, if there&amp;#39;s any specific to that on top of Spark. Looking for any tips, from how to write code, to designing pipelines. A few I&amp;#39;ve learned from what I&amp;#39;ve gathered are to chain commands/functions in the code.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not very experienced in performance tuning and partitioning, so I&amp;#39;d love anything related to those topics as well!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hup03", "is_robot_indexable": true, "report_reasons": null, "author": "jbnpoc", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hup03/what_are_some_best_practices_for_developing_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hup03/what_are_some_best_practices_for_developing_spark/", "subreddit_subscribers": 128430, "created_utc": 1694629597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\nContext : im a 4y xp data engineer. In my last job i enjoyed building pipelines, configuring the infrastructure (iac) , programming spark jobs (dataproc) optimising queries and jobs ..etc. i have passed also GCPDE certification lately. \nI recently started with a consulting company that pays well and seems to have a great reputation being expert in the cloud fields.\nAs soon as i started my contract with them i received my first \u201cmission\u201d (that i can refuse, the company seems cool with it as long as it doesn\u2019t match your profile). The thing is, its a data analytics engineer role working mostly with dbt, sql/bigquery and airflow for the orchestration. At first i said to my self dbt seems to gain a lot of popularity and it\u2019ll be good to master sql once and for all. But then i felt like i could miss the dataops part of data engineering.. so do you think it\u2019s a good idea to accept the mission. Is data analytics  part of a data architect path? Your thoughts are welcome!", "author_fullname": "t2_dgduwpzjf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data analytics part of data engineering ? Can data analytics be in the scope of a data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ijykz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694701780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nContext : im a 4y xp data engineer. In my last job i enjoyed building pipelines, configuring the infrastructure (iac) , programming spark jobs (dataproc) optimising queries and jobs ..etc. i have passed also GCPDE certification lately. \nI recently started with a consulting company that pays well and seems to have a great reputation being expert in the cloud fields.\nAs soon as i started my contract with them i received my first \u201cmission\u201d (that i can refuse, the company seems cool with it as long as it doesn\u2019t match your profile). The thing is, its a data analytics engineer role working mostly with dbt, sql/bigquery and airflow for the orchestration. At first i said to my self dbt seems to gain a lot of popularity and it\u2019ll be good to master sql once and for all. But then i felt like i could miss the dataops part of data engineering.. so do you think it\u2019s a good idea to accept the mission. Is data analytics  part of a data architect path? Your thoughts are welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ijykz", "is_robot_indexable": true, "report_reasons": null, "author": "Xx_Tz_xX", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ijykz/is_data_analytics_part_of_data_engineering_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ijykz/is_data_analytics_part_of_data_engineering_can/", "subreddit_subscribers": 128430, "created_utc": 1694701780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all, what is your prefered or best way to set secrets for systems that are multi-tenant and also have dev/prod etc environments?\n\nA little bit of background. As a backend dev, I used to always set secrets as environment variables through CI/CD. Or, either using a config yml/json file (for Go projects) or by creating the environment variables while building the Docker container (for Python/Node projects). This hasn't been a big problem as we rarely changed the  values.\n\nNow a days I am working on a multi-tenant data pipeline platform based on Airflow, essentially we have created our data models once but auto generated the pipelines for different customer tenants (which are Neo4j databases). This means if we have 3 customers, and dev, staging and prod environments, we essentially have 3x3 set of database creds alone.\n\nRight now we bake our dags into an Airflow Docker image and deploy the workers, webserver, dag processor etc separately. The problem we are facing right now is regarding changing the destination databases on the fly. For example, if we want to do a new load but want to do it to a new database instance, we would have to rebuild and redeploy the whole thing. Admittedly this is not the indented way to use Airflow, since we are not separating the software Airflow provides from the code we produce and the DAGs. The closest we went for separation is to use GitSync to update the DAGs is anything changes in the path for it. \n\nIf we want to ingest a dataset without affecting the existing db, we would need to get a new db instance, set the password in AWS Secrets manager and the hostname on the Kubernetes config (don't ask why two places, our devops wants to keep these separate for some reason). Then rebuild+redeploy the Docker image so that the new creds are used for the new push.   \n\n\nI feel like we are doing a ton of extra stuff here and cannot but feel a bit sluggish because of this process. How do you handle your secrets?", "author_fullname": "t2_12lkky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you store secrets for multi-tenant systems, for dev/staging/prod envs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ih83o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694694764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, what is your prefered or best way to set secrets for systems that are multi-tenant and also have dev/prod etc environments?&lt;/p&gt;\n\n&lt;p&gt;A little bit of background. As a backend dev, I used to always set secrets as environment variables through CI/CD. Or, either using a config yml/json file (for Go projects) or by creating the environment variables while building the Docker container (for Python/Node projects). This hasn&amp;#39;t been a big problem as we rarely changed the  values.&lt;/p&gt;\n\n&lt;p&gt;Now a days I am working on a multi-tenant data pipeline platform based on Airflow, essentially we have created our data models once but auto generated the pipelines for different customer tenants (which are Neo4j databases). This means if we have 3 customers, and dev, staging and prod environments, we essentially have 3x3 set of database creds alone.&lt;/p&gt;\n\n&lt;p&gt;Right now we bake our dags into an Airflow Docker image and deploy the workers, webserver, dag processor etc separately. The problem we are facing right now is regarding changing the destination databases on the fly. For example, if we want to do a new load but want to do it to a new database instance, we would have to rebuild and redeploy the whole thing. Admittedly this is not the indented way to use Airflow, since we are not separating the software Airflow provides from the code we produce and the DAGs. The closest we went for separation is to use GitSync to update the DAGs is anything changes in the path for it. &lt;/p&gt;\n\n&lt;p&gt;If we want to ingest a dataset without affecting the existing db, we would need to get a new db instance, set the password in AWS Secrets manager and the hostname on the Kubernetes config (don&amp;#39;t ask why two places, our devops wants to keep these separate for some reason). Then rebuild+redeploy the Docker image so that the new creds are used for the new push.   &lt;/p&gt;\n\n&lt;p&gt;I feel like we are doing a ton of extra stuff here and cannot but feel a bit sluggish because of this process. How do you handle your secrets?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Plumber", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ih83o", "is_robot_indexable": true, "report_reasons": null, "author": "ratulotron", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16ih83o/how_do_you_store_secrets_for_multitenant_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ih83o/how_do_you_store_secrets_for_multitenant_systems/", "subreddit_subscribers": 128430, "created_utc": 1694694764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious how people in the community are setting up vector embeddings pipelines to ingest large GBs of data at once.\n\n  \nWhen I was working for a LegalTech startup and we had to ingest millions of litigation documents into a single vector database collection, we used celery + kubernetes with GPU nodes to embed with an open source embedding model (sentence-transformers/sentence-t5-xxl) instead of OpenAI ADA. We eventually added Argo on top of it.\n\n  \nWhat other techniques do you see for scaling the pipeline? Where are you ingesting data from?\n\n  \nWe are building VectorFlow an open-source vector embedding pipeline that is containerized to run on kubernetes in any cloud and want to know what other features we should build next. Check out our Github repo:\u00a0[https://github.com/dgarnitz/vectorflow\u00a0to](https://github.com/dgarnitz/vectorflow%C2%A0to) install VectorFlow locally or t\\*ry it out in the playground (\\*[https://app.getvectorflow.com/](https://app.getvectorflow.com/)).", "author_fullname": "t2_8dgpjm0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Challenges with LLM + Vector searches with Large Data Volume", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hufnh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694628993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious how people in the community are setting up vector embeddings pipelines to ingest large GBs of data at once.&lt;/p&gt;\n\n&lt;p&gt;When I was working for a LegalTech startup and we had to ingest millions of litigation documents into a single vector database collection, we used celery + kubernetes with GPU nodes to embed with an open source embedding model (sentence-transformers/sentence-t5-xxl) instead of OpenAI ADA. We eventually added Argo on top of it.&lt;/p&gt;\n\n&lt;p&gt;What other techniques do you see for scaling the pipeline? Where are you ingesting data from?&lt;/p&gt;\n\n&lt;p&gt;We are building VectorFlow an open-source vector embedding pipeline that is containerized to run on kubernetes in any cloud and want to know what other features we should build next. Check out our Github repo:\u00a0&lt;a href=\"https://github.com/dgarnitz/vectorflow%C2%A0to\"&gt;https://github.com/dgarnitz/vectorflow\u00a0to&lt;/a&gt; install VectorFlow locally or t*ry it out in the playground (*&lt;a href=\"https://app.getvectorflow.com/\"&gt;https://app.getvectorflow.com/&lt;/a&gt;).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16hufnh", "is_robot_indexable": true, "report_reasons": null, "author": "Fast_Homework_3323", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hufnh/data_engineering_challenges_with_llm_vector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hufnh/data_engineering_challenges_with_llm_vector/", "subreddit_subscribers": 128430, "created_utc": 1694628993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With so many tools and options, it is incredibly confusing which are preferred, or may not be possible given technical requirements. \n\nI'd like to make an expansive list of questions which would help someone figure even what they need help with, to how to implement it, to what typical charges would be. \n\nIdeally, I'd like to make a website with questions that would branch from general to specific, based on responses. Remember that game Akinator, where the genie plays 20 questions with you and usually guesses what you are thinking? Well, this would narrow your choices with each question, and provide details on why they are viable option, and how they interact with the next piece of your pipeline.\n\nSo, what questions would you ask if someone asked you to help architect their new data pipeline?", "author_fullname": "t2_djjvfxs96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What questions would you ask if someone asked your help to architect a full data pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16inrch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694710959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With so many tools and options, it is incredibly confusing which are preferred, or may not be possible given technical requirements. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to make an expansive list of questions which would help someone figure even what they need help with, to how to implement it, to what typical charges would be. &lt;/p&gt;\n\n&lt;p&gt;Ideally, I&amp;#39;d like to make a website with questions that would branch from general to specific, based on responses. Remember that game Akinator, where the genie plays 20 questions with you and usually guesses what you are thinking? Well, this would narrow your choices with each question, and provide details on why they are viable option, and how they interact with the next piece of your pipeline.&lt;/p&gt;\n\n&lt;p&gt;So, what questions would you ask if someone asked you to help architect their new data pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16inrch", "is_robot_indexable": true, "report_reasons": null, "author": "Oh_Another_Thing", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16inrch/what_questions_would_you_ask_if_someone_asked/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16inrch/what_questions_would_you_ask_if_someone_asked/", "subreddit_subscribers": 128430, "created_utc": 1694710959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nI'm a developer at a startup working on a product that requires integrating our user's third-party SaaS application data into our platform.\n\nAs I have not built any integrations before I am feeling a little lost in this space. Thus this post. I have a few doubts and scourging the web didn't help much.\n\nSpecifically:\n\n- Integration Tools: What tools or libraries have you found effective for setting up integrations with SaaS apps? I have seen a few including Merge, Paragon etc, but as I lack prior experience, I don't know on which factors should I assess them.\n\n  Due to the shortage of staff, I don't think a self managed ETL solution such as airbyte would be feasible in my usecase.\n\n- Data Retrieval: How do you efficiently retrieve data from SaaS apps, especially dealing with rate limits and data consistency?\n\n   Also I assume the authentications would be managed by such a platform. \n\n- Workflow Setup: How can I implement customizable automated workflows? How do I manage user configurations and workflow orchestration?\n\n\n\nI'd appreciate any insights, tips, or resources you can share.\n\nThanks for your help!", "author_fullname": "t2_w82f2h6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Seeking Advice) Integrating Third-party SaaS Apps for Automated Workflows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16igxlm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694693972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a developer at a startup working on a product that requires integrating our user&amp;#39;s third-party SaaS application data into our platform.&lt;/p&gt;\n\n&lt;p&gt;As I have not built any integrations before I am feeling a little lost in this space. Thus this post. I have a few doubts and scourging the web didn&amp;#39;t help much.&lt;/p&gt;\n\n&lt;p&gt;Specifically:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Integration Tools: What tools or libraries have you found effective for setting up integrations with SaaS apps? I have seen a few including Merge, Paragon etc, but as I lack prior experience, I don&amp;#39;t know on which factors should I assess them.&lt;/p&gt;\n\n&lt;p&gt;Due to the shortage of staff, I don&amp;#39;t think a self managed ETL solution such as airbyte would be feasible in my usecase.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data Retrieval: How do you efficiently retrieve data from SaaS apps, especially dealing with rate limits and data consistency?&lt;/p&gt;\n\n&lt;p&gt;Also I assume the authentications would be managed by such a platform. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Workflow Setup: How can I implement customizable automated workflows? How do I manage user configurations and workflow orchestration?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any insights, tips, or resources you can share.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16igxlm", "is_robot_indexable": true, "report_reasons": null, "author": "ChangesOfTheMoonman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16igxlm/seeking_advice_integrating_thirdparty_saas_apps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16igxlm/seeking_advice_integrating_thirdparty_saas_apps/", "subreddit_subscribers": 128430, "created_utc": 1694693972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI was wondering what would be better in terms of cost reduction between these two solutions to serve CDC data as latest record snapshot:\n\n- take the delta, calculate the latest record versions with row number and the do a merge into the table\n\n- insert the delta inside the target table as is and serve data with a view applying at runtime the row number filtering to the whole table, periodically compact the table by only keeping latest record versions\n\n\nMy goal is to reduce latency but also to reduce credit consumption, but I feel like to reduce latency I should pursue option 2 and to reduce credit consumption, or to have more predictable credit consumption, I should pursue option 1.\n\nHow do you handle similar scenarios in your company?", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling CDC in Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ifpzt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694690331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I was wondering what would be better in terms of cost reduction between these two solutions to serve CDC data as latest record snapshot:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;take the delta, calculate the latest record versions with row number and the do a merge into the table&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;insert the delta inside the target table as is and serve data with a view applying at runtime the row number filtering to the whole table, periodically compact the table by only keeping latest record versions&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My goal is to reduce latency but also to reduce credit consumption, but I feel like to reduce latency I should pursue option 2 and to reduce credit consumption, or to have more predictable credit consumption, I should pursue option 1.&lt;/p&gt;\n\n&lt;p&gt;How do you handle similar scenarios in your company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ifpzt", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16ifpzt/handling_cdc_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ifpzt/handling_cdc_in_snowflake/", "subreddit_subscribers": 128430, "created_utc": 1694690331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to process either Excel files, API data, or CSV's that have different forms of similar data. The raw files will get saved as they are in S3. In this layer, we will also convert all of these to parquet.\n\nIn the next layer, we are going to take these parquet files, conform them to the same schema, and normalize any data into the appropriate staging tables.\n\nIn the final layer, we will use these normalized tables to denormalize and create any business level, easy-to-query tables.\n\nSo in S3, we'll save layer 1 data in the raw folder, layer 2 data in the stage folder, and layer 3 data in the bi folder. Is this organization reasonable? I feel like the first layer's conversion of the raw data into parquet is some form of transformation and therefore not \"raw.\" But maybe it's just semantics?", "author_fullname": "t2_5pjz5m35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raw vs Stage vs BI - Planning Things Correctly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16i3vab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694651539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to process either Excel files, API data, or CSV&amp;#39;s that have different forms of similar data. The raw files will get saved as they are in S3. In this layer, we will also convert all of these to parquet.&lt;/p&gt;\n\n&lt;p&gt;In the next layer, we are going to take these parquet files, conform them to the same schema, and normalize any data into the appropriate staging tables.&lt;/p&gt;\n\n&lt;p&gt;In the final layer, we will use these normalized tables to denormalize and create any business level, easy-to-query tables.&lt;/p&gt;\n\n&lt;p&gt;So in S3, we&amp;#39;ll save layer 1 data in the raw folder, layer 2 data in the stage folder, and layer 3 data in the bi folder. Is this organization reasonable? I feel like the first layer&amp;#39;s conversion of the raw data into parquet is some form of transformation and therefore not &amp;quot;raw.&amp;quot; But maybe it&amp;#39;s just semantics?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16i3vab", "is_robot_indexable": true, "report_reasons": null, "author": "maraskooknah", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16i3vab/raw_vs_stage_vs_bi_planning_things_correctly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16i3vab/raw_vs_stage_vs_bi_planning_things_correctly/", "subreddit_subscribers": 128430, "created_utc": 1694651539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI have some raw tables in BigQuery that contains live data, with a cdc connected to it. \n\nI need to do some analytics queries for an API, and to reduce the compute time, I tought it would be a good idea to store everything in a incremental table using **dbt** to run my model each time the raw table gets an update. It works when testing, but I noticed each dbt run takes 10 sec and that's too long for me. What other options do I have? Thank you\n\nTried materialized views but it does not support my query. ", "author_fullname": "t2_40sshxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bigquery quick query.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hzeug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694640496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I have some raw tables in BigQuery that contains live data, with a cdc connected to it. &lt;/p&gt;\n\n&lt;p&gt;I need to do some analytics queries for an API, and to reduce the compute time, I tought it would be a good idea to store everything in a incremental table using &lt;strong&gt;dbt&lt;/strong&gt; to run my model each time the raw table gets an update. It works when testing, but I noticed each dbt run takes 10 sec and that&amp;#39;s too long for me. What other options do I have? Thank you&lt;/p&gt;\n\n&lt;p&gt;Tried materialized views but it does not support my query. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hzeug", "is_robot_indexable": true, "report_reasons": null, "author": "LinweZ", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hzeug/bigquery_quick_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hzeug/bigquery_quick_query/", "subreddit_subscribers": 128430, "created_utc": 1694640496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Everything that was simply done with Spark jobs or Flink jobs are now bespoke projects and services. Such tiny Microservices like open source projects for the basic things is so annoying to see. Modern Data Stack is just a bad way to do things.\n\nThis makes it so hard to formulate or do something if you are starting new. You have to review a lot of tools that may or may not do everything that you ask for. But now you are stuck adopting a tool that you didn\u2019t want entirely.\n\nI believe most of the people using heavy MDS oriented products have a large sunk cost that they can\u2019t get themselves out of. All of your data is in Snowflake, BQ, Redshift and you need 10 wrenches to do basic analytics. \n\nI\u2019m not saying bring back the Hadoop days but this has gotten out of hand. Sometimes I wonder if we are just being scammed collectively as an industry for these substandard tools. It seems like someone got angry at their inability to write a Spark job and went ahead to build tools that no one needed.\n\nI can\u2019t say this is a healthy state but we aren\u2019t going in the right direction unless some major corrections happen quick.", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MDS is ruining Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16iou2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694713452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Everything that was simply done with Spark jobs or Flink jobs are now bespoke projects and services. Such tiny Microservices like open source projects for the basic things is so annoying to see. Modern Data Stack is just a bad way to do things.&lt;/p&gt;\n\n&lt;p&gt;This makes it so hard to formulate or do something if you are starting new. You have to review a lot of tools that may or may not do everything that you ask for. But now you are stuck adopting a tool that you didn\u2019t want entirely.&lt;/p&gt;\n\n&lt;p&gt;I believe most of the people using heavy MDS oriented products have a large sunk cost that they can\u2019t get themselves out of. All of your data is in Snowflake, BQ, Redshift and you need 10 wrenches to do basic analytics. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not saying bring back the Hadoop days but this has gotten out of hand. Sometimes I wonder if we are just being scammed collectively as an industry for these substandard tools. It seems like someone got angry at their inability to write a Spark job and went ahead to build tools that no one needed.&lt;/p&gt;\n\n&lt;p&gt;I can\u2019t say this is a healthy state but we aren\u2019t going in the right direction unless some major corrections happen quick.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16iou2h", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16iou2h/mds_is_ruining_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16iou2h/mds_is_ruining_data_engineering/", "subreddit_subscribers": 128430, "created_utc": 1694713452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working as a django developer. I got a project where  i got a chance to work with DE team. Unfortunately the whole team was laid off and i have no connection with them. I also started learning the concepts from youtube but I had to waste a lot of time to find a good resource to learn a simple thing. Hence I decided to join a bootcamp.\n\nI came across a Data Engineering bootcamp by datatalks which is free. But its week 1 was so hard for me that I gave up. And then I came up with two other bootcamps in which the first one is taught by a Data engineer 3 working at amazon (this one is just launched) and the 2nd one is (azure DE focused) taught by a guy who is microsoft certified trainer (been there for a very long time and proven placement records)\n\nThe price of that amazon guy bootcamp is 1/3 rd of the other one. I am confused should I really go for the bootcamps or just learn the things from udemy courses and appear for any certified data engineer certificate (GCP, AWS, AZURE)? I already have wasted 1 month just to decide and can't figure out a way to start my journey. \n\n\nLink for the DE zoomcamp\nhttps://github.com/DataTalksClub/data-engineering-zoomcamp", "author_fullname": "t2_ko3363l6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on DE Bootcamps.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ior69", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694713261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working as a django developer. I got a project where  i got a chance to work with DE team. Unfortunately the whole team was laid off and i have no connection with them. I also started learning the concepts from youtube but I had to waste a lot of time to find a good resource to learn a simple thing. Hence I decided to join a bootcamp.&lt;/p&gt;\n\n&lt;p&gt;I came across a Data Engineering bootcamp by datatalks which is free. But its week 1 was so hard for me that I gave up. And then I came up with two other bootcamps in which the first one is taught by a Data engineer 3 working at amazon (this one is just launched) and the 2nd one is (azure DE focused) taught by a guy who is microsoft certified trainer (been there for a very long time and proven placement records)&lt;/p&gt;\n\n&lt;p&gt;The price of that amazon guy bootcamp is 1/3 rd of the other one. I am confused should I really go for the bootcamps or just learn the things from udemy courses and appear for any certified data engineer certificate (GCP, AWS, AZURE)? I already have wasted 1 month just to decide and can&amp;#39;t figure out a way to start my journey. &lt;/p&gt;\n\n&lt;p&gt;Link for the DE zoomcamp\n&lt;a href=\"https://github.com/DataTalksClub/data-engineering-zoomcamp\"&gt;https://github.com/DataTalksClub/data-engineering-zoomcamp&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6IkRCEYiLgeOr1qLjqXKfmKc6RfAh6xyI4dXsVpl8Po.jpg?auto=webp&amp;s=a84fe8f3c464e8facc160a78b3c778beda7db503", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/6IkRCEYiLgeOr1qLjqXKfmKc6RfAh6xyI4dXsVpl8Po.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e57f5e78520f537da1308d2031ad270d2674b73b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/6IkRCEYiLgeOr1qLjqXKfmKc6RfAh6xyI4dXsVpl8Po.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=626f1490086e890799002210e82a2546c80c4797", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/6IkRCEYiLgeOr1qLjqXKfmKc6RfAh6xyI4dXsVpl8Po.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c856828be9a6dcc486504fd8969bbd672f23aaa3", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/6IkRCEYiLgeOr1qLjqXKfmKc6RfAh6xyI4dXsVpl8Po.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=21611f9e402229bcc98ad7ffb1bd19fb91ad7cdf", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/6IkRCEYiLgeOr1qLjqXKfmKc6RfAh6xyI4dXsVpl8Po.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=32014d5d6495f45ce0a6b0385484dc690ea2ee58", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/6IkRCEYiLgeOr1qLjqXKfmKc6RfAh6xyI4dXsVpl8Po.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e0af9d3223e56915ba2dcce52931560cc2601ca7", "width": 1080, "height": 540}], "variants": {}, "id": "AiVp8Uw9iuW5r3bEQ_8tqWqaJC9dJ5nTjtCvK6_l3P8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ior69", "is_robot_indexable": true, "report_reasons": null, "author": "paklupapito007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ior69/advice_on_de_bootcamps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ior69/advice_on_de_bootcamps/", "subreddit_subscribers": 128430, "created_utc": 1694713261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1s3gnjad", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applied to 200+ jobs but can't even land an interview. Can you please critique my resume", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_16in8gg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MMY5wbH5B1w29tfNn8E8X_B-sQifnRV8wy6o10Vk0dk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694709700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tkdpsjc029ob1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tkdpsjc029ob1.png?auto=webp&amp;s=88b5bfd56d96dc8d2dbe4d2ec44b32f31c87f04e", "width": 1700, "height": 2200}, "resolutions": [{"url": "https://preview.redd.it/tkdpsjc029ob1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=98d1a6a2db9b8113870776fad8e2d7214d25051e", "width": 108, "height": 139}, {"url": "https://preview.redd.it/tkdpsjc029ob1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=398661fa1081b967d227c8b9d86872af831019e9", "width": 216, "height": 279}, {"url": "https://preview.redd.it/tkdpsjc029ob1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a47b0bd21dd62c8792374278d369a88452192576", "width": 320, "height": 414}, {"url": "https://preview.redd.it/tkdpsjc029ob1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ea4e811d8c9e3fad3d1da0d00a282ab2a1796b55", "width": 640, "height": 828}, {"url": "https://preview.redd.it/tkdpsjc029ob1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=604acea48301c74827af2466cf2f806b987b903d", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/tkdpsjc029ob1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4e0357d4b3a4133b8c710f5ca7a86c604b207d28", "width": 1080, "height": 1397}], "variants": {}, "id": "SNFW0AXYwYXiDG0u5qk5JPkcmoZlbpiUJxjja5WTHXw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16in8gg", "is_robot_indexable": true, "report_reasons": null, "author": "QueryRIT", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16in8gg/applied_to_200_jobs_but_cant_even_land_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tkdpsjc029ob1.png", "subreddit_subscribers": 128430, "created_utc": 1694709700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious after reading this thread: [https://www.reddit.com/r/dataengineering/comments/16dgffb/data\\_pipelines\\_with\\_make/](https://www.reddit.com/r/dataengineering/comments/16dgffb/data_pipelines_with_make/)\n\nSeems like data pipelines with make aren't super popular but curious if people have productive uses for make in their daily workflow that leverage makefiles?\n\nI definitely have shell aliases functions that stitch together some command line stuff like just creating a new folder, git cloning, creating a venv, activating it, installing requirements if there is one etc. But that's something that's available to me globally in my shell. Makefiles seem localized.\n\n&amp;#x200B;", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any non-compilation but productive use cases for Make?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ikgzy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694703091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious after reading this thread: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/16dgffb/data_pipelines_with_make/\"&gt;https://www.reddit.com/r/dataengineering/comments/16dgffb/data_pipelines_with_make/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Seems like data pipelines with make aren&amp;#39;t super popular but curious if people have productive uses for make in their daily workflow that leverage makefiles?&lt;/p&gt;\n\n&lt;p&gt;I definitely have shell aliases functions that stitch together some command line stuff like just creating a new folder, git cloning, creating a venv, activating it, installing requirements if there is one etc. But that&amp;#39;s something that&amp;#39;s available to me globally in my shell. Makefiles seem localized.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ikgzy", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ikgzy/any_noncompilation_but_productive_use_cases_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ikgzy/any_noncompilation_but_productive_use_cases_for/", "subreddit_subscribers": 128430, "created_utc": 1694703091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mxj2oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on PgBouncer From a Support Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_16iimn3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RYFbXQFPYeQuK8xAOCeX44IC8TFDvmrHQroLXIu4luI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694698373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "timescale.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.timescale.com/blog/p/cb5598ff-d5a2-4405-842e-2608ba109202/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?auto=webp&amp;s=f558a87f5972307efe62a377fd84d58981da3439", "width": 2000, "height": 1179}, "resolutions": [{"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=57a9554ee404b499f8b3f49be10c3fda0254e55d", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ee8ae187434b112e717155587c1277e1b2391e83", "width": 216, "height": 127}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f6ffb502bea59a69d336853ab8120a2584962a7c", "width": 320, "height": 188}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d72465fef513f97e1adc945437911ff6de66ed9a", "width": 640, "height": 377}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ca7227bbd977dfe9ab16675b911bcbe2d6938d9b", "width": 960, "height": 565}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a8e940f75a08d6cddb15667225aa1b87fb68fa0", "width": 1080, "height": 636}], "variants": {}, "id": "Y3tB9NrWKmEpf7IHHJv0SKXo-7usHMSGxkasQoCO6gM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16iimn3", "is_robot_indexable": true, "report_reasons": null, "author": "carlotasoto", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16iimn3/advice_on_pgbouncer_from_a_support_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.timescale.com/blog/p/cb5598ff-d5a2-4405-842e-2608ba109202/", "subreddit_subscribers": 128430, "created_utc": 1694698373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event-Driven Architecture with Serverless Functions \u2014 Part 1", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16iifa7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/uXwdZJTGvRd7R0NZamK_FKP-yWub52n1YKMUlMiGyn8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694697858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@memphis-dev/event-driven-architecture-with-serverless-functions-part-1-d2b54babc193", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?auto=webp&amp;s=44310b4df96fcff8a4c60e0b77bd53ccbe69a9a8", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a3eb237e3111b2265078e4a03dbe68ae4649180", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ad13ff8b60f8b10e1ed8391a8934a78f271e58d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c473785bca234c87498a2605fec78a3c7e4edd99", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d9e31e54a5db31daa35632cbeb5e764b4c5a6b89", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=569d3b24a54fe3a1464d63c7db40530636a77433", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77c80d739d7d449f12290d8b77d6a7b023d89bd9", "width": 1080, "height": 607}], "variants": {}, "id": "_1gzao2guJDarba8auEOHTBsHMBx1uXbpiaoKpXsgrs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16iifa7", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16iifa7/eventdriven_architecture_with_serverless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@memphis-dev/event-driven-architecture-with-serverless-functions-part-1-d2b54babc193", "subreddit_subscribers": 128430, "created_utc": 1694697858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers vs Data Scientists: A Comparative Exploration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16ihhv3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TF3n3FXFdRwmjGvp3jBT8TL5-pOJqpA1K7jl2OInEr8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694695522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "albertchristopherr.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://albertchristopherr.medium.com/data-engineers-vs-data-scientists-a-comparative-exploration-4290ef09ff5e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vrcdJFd2Kpo65agdzLS1eDKtqsQm128gex3DmpH88DY.jpg?auto=webp&amp;s=ca9d2b985092821cbe9767bbf107f91d5b711323", "width": 940, "height": 528}, "resolutions": [{"url": "https://external-preview.redd.it/vrcdJFd2Kpo65agdzLS1eDKtqsQm128gex3DmpH88DY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c09cc1372e1902af74ec96835c413f3a9ad69667", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/vrcdJFd2Kpo65agdzLS1eDKtqsQm128gex3DmpH88DY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=58808319575c430e1b0545ffd3ce4c362dc3901e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/vrcdJFd2Kpo65agdzLS1eDKtqsQm128gex3DmpH88DY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c84886a9cd3d5d65ac05b3ed62146b626c32cd15", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/vrcdJFd2Kpo65agdzLS1eDKtqsQm128gex3DmpH88DY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=511e2b4bd3b6ccdabc69fc7f9855abfa02957c54", "width": 640, "height": 359}], "variants": {}, "id": "HClPY-8gMIbXBd_7wwoso2ULMM-KaSpV_mwVD5tiHzg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16ihhv3", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ihhv3/data_engineers_vs_data_scientists_a_comparative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://albertchristopherr.medium.com/data-engineers-vs-data-scientists-a-comparative-exploration-4290ef09ff5e", "subreddit_subscribers": 128430, "created_utc": 1694695522.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}