{"kind": "Listing", "data": {"after": "t3_16iifa7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked as a data scientist / engineer for the last 9 years but always at a scale a bit below where you really need distributed computing (i.e. SQL databases of a few terabytes). I'm interested in developing the skills that can take me to the next level of scale, but at my job we simply don't have that amount of data. Launching and running a cluster just for fun also seems like it would be a bit expensive. And if I'd want to make a shift to a senior data engineering role at this larger scale, they're going to want me to have some of this experience _before_ I get hired.\n\nWhat's a good way to expose myself to problems that I can solve with Kafka / Spark (i.e. I'm interested in streaming algorithms and mapreduce-like problems)? I'm wondering if there are (for example) open source geo datasets and public servers that you can do some work on (though obviously those cost money as well, so maybe I'm naive to think that).\n\nObviously I'm a bit new to this area so please do let me know if I said anything dumb :) I read \"Designing Data-Intensive Applications\" and have a decent grasp of CS fundamentals, but obviously there's some specialized expertise to be had here.", "author_fullname": "t2_23t9wnbf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to build experience in Kafka and Spark if not in a data engineering job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16i3u4l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694651454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked as a data scientist / engineer for the last 9 years but always at a scale a bit below where you really need distributed computing (i.e. SQL databases of a few terabytes). I&amp;#39;m interested in developing the skills that can take me to the next level of scale, but at my job we simply don&amp;#39;t have that amount of data. Launching and running a cluster just for fun also seems like it would be a bit expensive. And if I&amp;#39;d want to make a shift to a senior data engineering role at this larger scale, they&amp;#39;re going to want me to have some of this experience &lt;em&gt;before&lt;/em&gt; I get hired.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s a good way to expose myself to problems that I can solve with Kafka / Spark (i.e. I&amp;#39;m interested in streaming algorithms and mapreduce-like problems)? I&amp;#39;m wondering if there are (for example) open source geo datasets and public servers that you can do some work on (though obviously those cost money as well, so maybe I&amp;#39;m naive to think that).&lt;/p&gt;\n\n&lt;p&gt;Obviously I&amp;#39;m a bit new to this area so please do let me know if I said anything dumb :) I read &amp;quot;Designing Data-Intensive Applications&amp;quot; and have a decent grasp of CS fundamentals, but obviously there&amp;#39;s some specialized expertise to be had here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16i3u4l", "is_robot_indexable": true, "report_reasons": null, "author": "failarmyworm", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16i3u4l/how_to_build_experience_in_kafka_and_spark_if_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16i3u4l/how_to_build_experience_in_kafka_and_spark_if_not/", "subreddit_subscribers": 128402, "created_utc": 1694651454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is one of the most helpful subs I have come across personally. For me, I have learnt about how to progress in my career, help for interviews and certs also.\nSo, thank you to everyone who keeps commenting and figuring out ways to help others with their queries.", "author_fullname": "t2_5on7s1v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Love you guys!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16iaaku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694671175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is one of the most helpful subs I have come across personally. For me, I have learnt about how to progress in my career, help for interviews and certs also.\nSo, thank you to everyone who keeps commenting and figuring out ways to help others with their queries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16iaaku", "is_robot_indexable": true, "report_reasons": null, "author": "xander800", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16iaaku/love_you_guys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16iaaku/love_you_guys/", "subreddit_subscribers": 128402, "created_utc": 1694671175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm wondering if a good portfolio (I don't know yet how good) and certificates can cover the 4 years gap I have. Knowing that I didn't choose to chill for 4 years (and it was far away from that anyway). Employers don't seem to care about why I was hit hard by life to the point of discontinuing my career. Anyway, I'm not asking for their pitty but I'm determined to make my profile succeed in getting me good jobs despite of the gap. I've been autolearning for a year now and I built some projects from scratch. How can I show my motivation by exposing these projects ?", "author_fullname": "t2_um2qwii8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do with a 4 years gap in an IT resume", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hpyf2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694618742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering if a good portfolio (I don&amp;#39;t know yet how good) and certificates can cover the 4 years gap I have. Knowing that I didn&amp;#39;t choose to chill for 4 years (and it was far away from that anyway). Employers don&amp;#39;t seem to care about why I was hit hard by life to the point of discontinuing my career. Anyway, I&amp;#39;m not asking for their pitty but I&amp;#39;m determined to make my profile succeed in getting me good jobs despite of the gap. I&amp;#39;ve been autolearning for a year now and I built some projects from scratch. How can I show my motivation by exposing these projects ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16hpyf2", "is_robot_indexable": true, "report_reasons": null, "author": "NoChemical1223", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hpyf2/what_to_do_with_a_4_years_gap_in_an_it_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hpyf2/what_to_do_with_a_4_years_gap_in_an_it_resume/", "subreddit_subscribers": 128402, "created_utc": 1694618742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\nI'm Matteo, one of the co-founder of Dozer. I have posted here before about our project, but we were very early and only had just a bit more of a prototype. The project has evolved quite a lot and I'm quite happy with the experience we are building.\n\nFundamentally, with Dozer it's now possible to define all connections to your databases, data warehouses or object stores, provide some SQL transformations (WASM and TypeScript coming soon) and declare how data should be exposed as APIs. We take care of pretty much anything in the middle: sourcing the data, transforming in real time (we have built our own streaming SQL engine) and exposing it as REST and gRPC APIs.\n\nWe have built a full UI experience that allow a user to inspect the transformations and the data in real-time. Our vision is for Dozer to become a full data-application backend. Imagine you have multiple sources of data and you need to stitch them together to create a webapp. Connecting to the data sources, moving the data, keeping it fresh, cache in an a low latency store is a lot of work. That is what we want to solve with Dozer.\n\nI'm sharing a short video of our latest release ([https://www.youtube.com/watch?v=jS-Rdqn1NYw](https://www.youtube.com/watch?v=jS-Rdqn1NYw)) and I'd be really interested to know your thoughts and how you would use it.\n\nThanks  \nMatteo", "author_fullname": "t2_5efs1s7d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How we are trying to reduce the pains of building a data application using Dozer: real-time sourcing, stitching, transformations and serving APIs all in a single Rust binary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16i821c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694663690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m Matteo, one of the co-founder of Dozer. I have posted here before about our project, but we were very early and only had just a bit more of a prototype. The project has evolved quite a lot and I&amp;#39;m quite happy with the experience we are building.&lt;/p&gt;\n\n&lt;p&gt;Fundamentally, with Dozer it&amp;#39;s now possible to define all connections to your databases, data warehouses or object stores, provide some SQL transformations (WASM and TypeScript coming soon) and declare how data should be exposed as APIs. We take care of pretty much anything in the middle: sourcing the data, transforming in real time (we have built our own streaming SQL engine) and exposing it as REST and gRPC APIs.&lt;/p&gt;\n\n&lt;p&gt;We have built a full UI experience that allow a user to inspect the transformations and the data in real-time. Our vision is for Dozer to become a full data-application backend. Imagine you have multiple sources of data and you need to stitch them together to create a webapp. Connecting to the data sources, moving the data, keeping it fresh, cache in an a low latency store is a lot of work. That is what we want to solve with Dozer.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sharing a short video of our latest release (&lt;a href=\"https://www.youtube.com/watch?v=jS-Rdqn1NYw\"&gt;https://www.youtube.com/watch?v=jS-Rdqn1NYw&lt;/a&gt;) and I&amp;#39;d be really interested to know your thoughts and how you would use it.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;br/&gt;\nMatteo&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m9Dyyw7SVKKXWh6rgWEmkpJQb1Z2qb-rUb5sRmLAoYI.jpg?auto=webp&amp;s=e491c63737cf75d665a21ee3e758d32f86197552", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/m9Dyyw7SVKKXWh6rgWEmkpJQb1Z2qb-rUb5sRmLAoYI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=10efdbbaf9e9dd94976a4c2cd124329f3c8a6e1a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/m9Dyyw7SVKKXWh6rgWEmkpJQb1Z2qb-rUb5sRmLAoYI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b96e203701420d0612b30c78a6baa67706d4a86", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/m9Dyyw7SVKKXWh6rgWEmkpJQb1Z2qb-rUb5sRmLAoYI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6c66e31a49cd0e8eec343fa182d1d131348215bf", "width": 320, "height": 240}], "variants": {}, "id": "XCBKCwSo6DEVWkTvplN3stagQ71OOqNepQxK2naykq4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16i821c", "is_robot_indexable": true, "report_reasons": null, "author": "matteopelati76", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16i821c/how_we_are_trying_to_reduce_the_pains_of_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16i821c/how_we_are_trying_to_reduce_the_pains_of_building/", "subreddit_subscribers": 128402, "created_utc": 1694663690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I joined a data engineering team that the previous team of 5 had all left in the previous year with 4 walking out on the same day due to the work from home policy change.\n\nThey had replaced the team with me as  a lead.  1 sr software engineer who was a problem employee and 3 contract employees from south america that were all very young ... 22-24 ish.\n\nThe issue started with the problem employee refusing to answer the teams request for 2 months. She was the teams databricks admin and stalled the teams plans for 2 months as i was unable to bring data into databricks myself.\n\nI got pretty frustrated that this continued on for 2 months despite daily scrums.  like she would make up her own work that was all administrative. like submit support tickets for the team and just sit there and not do anything.  \n\ni have never seen anyone stonewall a group of people like that for 2 months and literally do nothing in return.\n\nThen we had one of the contract workers admit to admitting to not attending work after scrum to another employee for a month and do no work.  they took no action other than to require attendance during scrum.  the other two contractors were pretty sub par due to their age for a data engineering job and needed a ton of hand holding.\n\nI was a director of engineering paid 140k in a city with a high cost of living.   In my opinion the company was taking advantage by putting me into that situation and felt like they were just using me to maintain a dysfunctional product for existing clients before it was sunset.\n\nIt was a company with 50k employees. but i did not feel like this situation would improve due to the fact that i have never seen a company allow for someone to just do nothing for two months like that and abandon her role. \n\n i thought they had planned to sunset the product and were running out a replacement squad for the time being and i was just going to work my ass off to get beat up\n\nthoughts on this situation?", "author_fullname": "t2_grbdwzn7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leaving a role soon after hire, thoughts on this Data Engineering situaton?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hrg3c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694622163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined a data engineering team that the previous team of 5 had all left in the previous year with 4 walking out on the same day due to the work from home policy change.&lt;/p&gt;\n\n&lt;p&gt;They had replaced the team with me as  a lead.  1 sr software engineer who was a problem employee and 3 contract employees from south america that were all very young ... 22-24 ish.&lt;/p&gt;\n\n&lt;p&gt;The issue started with the problem employee refusing to answer the teams request for 2 months. She was the teams databricks admin and stalled the teams plans for 2 months as i was unable to bring data into databricks myself.&lt;/p&gt;\n\n&lt;p&gt;I got pretty frustrated that this continued on for 2 months despite daily scrums.  like she would make up her own work that was all administrative. like submit support tickets for the team and just sit there and not do anything.  &lt;/p&gt;\n\n&lt;p&gt;i have never seen anyone stonewall a group of people like that for 2 months and literally do nothing in return.&lt;/p&gt;\n\n&lt;p&gt;Then we had one of the contract workers admit to admitting to not attending work after scrum to another employee for a month and do no work.  they took no action other than to require attendance during scrum.  the other two contractors were pretty sub par due to their age for a data engineering job and needed a ton of hand holding.&lt;/p&gt;\n\n&lt;p&gt;I was a director of engineering paid 140k in a city with a high cost of living.   In my opinion the company was taking advantage by putting me into that situation and felt like they were just using me to maintain a dysfunctional product for existing clients before it was sunset.&lt;/p&gt;\n\n&lt;p&gt;It was a company with 50k employees. but i did not feel like this situation would improve due to the fact that i have never seen a company allow for someone to just do nothing for two months like that and abandon her role. &lt;/p&gt;\n\n&lt;p&gt;i thought they had planned to sunset the product and were running out a replacement squad for the time being and i was just going to work my ass off to get beat up&lt;/p&gt;\n\n&lt;p&gt;thoughts on this situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16hrg3c", "is_robot_indexable": true, "report_reasons": null, "author": "Electrical-End-1524", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hrg3c/leaving_a_role_soon_after_hire_thoughts_on_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hrg3c/leaving_a_role_soon_after_hire_thoughts_on_this/", "subreddit_subscribers": 128402, "created_utc": 1694622163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we have several tens of cronjobs in our k8s cluster which everyone has different schedule. We were discussing that maybe we should put most of the cronjobs into the Airflow because of easier rerunning failed jobs and because of easier to see history of runs. On the other hand it would mean we would have tens/hundreds of dags consisting of one single task as every one has different schedule. \n\nIs there any recommendation for such case? Yes or no and why?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cronjobs vs Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hugdx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694629043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we have several tens of cronjobs in our k8s cluster which everyone has different schedule. We were discussing that maybe we should put most of the cronjobs into the Airflow because of easier rerunning failed jobs and because of easier to see history of runs. On the other hand it would mean we would have tens/hundreds of dags consisting of one single task as every one has different schedule. &lt;/p&gt;\n\n&lt;p&gt;Is there any recommendation for such case? Yes or no and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16hugdx", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hugdx/cronjobs_vs_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hugdx/cronjobs_vs_airflow/", "subreddit_subscribers": 128402, "created_utc": 1694629043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a 27-year-old data practitioner with experience in both data analytics and engineering. I graduated in 2019 and initially worked as a machine learning engineer for four months. Unfortunately, I had to resign due to family health issues, which took precedence.\n\nI was determined to continue my career journey, so I joined Omdena as a volunteer, where I honed my skills and recently completed a data engineering internship. I also obtained the DataBricks certification for Data Engineer Associate, believing it would open doors to full-time employment.\n\nHowever, my current situation has left me feeling lost and uncertain. Despite my efforts, I've been unable to secure a full-time position, while my peers in my friend circle have progressed to senior roles. This has left me feeling both disheartened and anxious about my future.\n\nI don't seek pity but rather any guidance or advice you can offer that might help me change the course of my career. Thank you for your assistance.", "author_fullname": "t2_84ztczxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "27 year old data practitioner, no job .", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ibao1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694674751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a 27-year-old data practitioner with experience in both data analytics and engineering. I graduated in 2019 and initially worked as a machine learning engineer for four months. Unfortunately, I had to resign due to family health issues, which took precedence.&lt;/p&gt;\n\n&lt;p&gt;I was determined to continue my career journey, so I joined Omdena as a volunteer, where I honed my skills and recently completed a data engineering internship. I also obtained the DataBricks certification for Data Engineer Associate, believing it would open doors to full-time employment.&lt;/p&gt;\n\n&lt;p&gt;However, my current situation has left me feeling lost and uncertain. Despite my efforts, I&amp;#39;ve been unable to secure a full-time position, while my peers in my friend circle have progressed to senior roles. This has left me feeling both disheartened and anxious about my future.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t seek pity but rather any guidance or advice you can offer that might help me change the course of my career. Thank you for your assistance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ibao1", "is_robot_indexable": true, "report_reasons": null, "author": "chaachans", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ibao1/27_year_old_data_practitioner_no_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ibao1/27_year_old_data_practitioner_no_job/", "subreddit_subscribers": 128402, "created_utc": 1694674751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6lg1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte made huge progress on Postgres replication performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_16hqwpl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/kglnFOYWzScHGih_8jeM5cATAPWNE1KPTslylXHtl70.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694620926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/postgres-replication-performance-benchmark-airbyte-vs-fivetran", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AKXPMDZFH6bJKRjK6Jjb7PQX0IAdVCxTBAXJ-1Zz1lc.jpg?auto=webp&amp;s=056537f6f2992c8852f6cb95bbc4c00c1e229c51", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/AKXPMDZFH6bJKRjK6Jjb7PQX0IAdVCxTBAXJ-1Zz1lc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3e03d950d72419b87f9d5aae966a4c768510ad3d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/AKXPMDZFH6bJKRjK6Jjb7PQX0IAdVCxTBAXJ-1Zz1lc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=51611433beec1d0c28d0a3b19f660558679b5c93", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/AKXPMDZFH6bJKRjK6Jjb7PQX0IAdVCxTBAXJ-1Zz1lc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1ae364d8a384ecdcaa7b33b103f56ac454efde0e", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/AKXPMDZFH6bJKRjK6Jjb7PQX0IAdVCxTBAXJ-1Zz1lc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ea1404c8fa73aa64041ee85644b9820989de6df0", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/AKXPMDZFH6bJKRjK6Jjb7PQX0IAdVCxTBAXJ-1Zz1lc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f13c773843bfa750b7b0898f0d5469e9d1693f65", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/AKXPMDZFH6bJKRjK6Jjb7PQX0IAdVCxTBAXJ-1Zz1lc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e18e53e06677f7d693f436caaa78f11e99b2664b", "width": 1080, "height": 565}], "variants": {}, "id": "WV3P-nqqnUiqFMV44_ujfp4HcBKISrl5GlfKY6P3V70"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16hqwpl", "is_robot_indexable": true, "report_reasons": null, "author": "evantahler", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hqwpl/airbyte_made_huge_progress_on_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/postgres-replication-performance-benchmark-airbyte-vs-fivetran", "subreddit_subscribers": 128402, "created_utc": 1694620926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have my final interview upcoming with a wells fargo panel. I have been preparing, but I wanted to ask if anyone has gone through the interview process and how did it go?\n\nAny advice would be appreciated. I am graduating soon and would love to have a job for when I graduate.", "author_fullname": "t2_ts5ccrmt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone interviewed at Wells Fargo for an entry level data engineer role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hyzx3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694639545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have my final interview upcoming with a wells fargo panel. I have been preparing, but I wanted to ask if anyone has gone through the interview process and how did it go?&lt;/p&gt;\n\n&lt;p&gt;Any advice would be appreciated. I am graduating soon and would love to have a job for when I graduate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16hyzx3", "is_robot_indexable": true, "report_reasons": null, "author": "Much-Series1120", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hyzx3/has_anyone_interviewed_at_wells_fargo_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hyzx3/has_anyone_interviewed_at_wells_fargo_for_an/", "subreddit_subscribers": 128402, "created_utc": 1694639545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are some best practices for developing data applications/pipelines using Spark? I'll be using PySpark, if there's any specific to that on top of Spark. Looking for any tips, from how to write code, to designing pipelines. A few I've learned from what I've gathered are to chain commands/functions in the code.\n\nI'm not very experienced in performance tuning and partitioning, so I'd love anything related to those topics as well!", "author_fullname": "t2_1k8fjdz5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some best practices for developing Spark data applications/pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hup03", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694629597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some best practices for developing data applications/pipelines using Spark? I&amp;#39;ll be using PySpark, if there&amp;#39;s any specific to that on top of Spark. Looking for any tips, from how to write code, to designing pipelines. A few I&amp;#39;ve learned from what I&amp;#39;ve gathered are to chain commands/functions in the code.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not very experienced in performance tuning and partitioning, so I&amp;#39;d love anything related to those topics as well!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hup03", "is_robot_indexable": true, "report_reasons": null, "author": "jbnpoc", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hup03/what_are_some_best_practices_for_developing_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hup03/what_are_some_best_practices_for_developing_spark/", "subreddit_subscribers": 128402, "created_utc": 1694629597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what have you done to bolster your knowledge, we recently hired a staff engineer and the dude isn't out of his 20s and hole leeeeeee chit does he know his stuff.", "author_fullname": "t2_vtm8z2o0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like my knowledge is just surface level what have you done to bolster the depth of your knowledge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16i6zh8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694660427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what have you done to bolster your knowledge, we recently hired a staff engineer and the dude isn&amp;#39;t out of his 20s and hole leeeeeee chit does he know his stuff.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16i6zh8", "is_robot_indexable": true, "report_reasons": null, "author": "Action_Maxim", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16i6zh8/i_feel_like_my_knowledge_is_just_surface_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16i6zh8/i_feel_like_my_knowledge_is_just_surface_level/", "subreddit_subscribers": 128402, "created_utc": 1694660427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious how people in the community are setting up vector embeddings pipelines to ingest large GBs of data at once.\n\n  \nWhen I was working for a LegalTech startup and we had to ingest millions of litigation documents into a single vector database collection, we used celery + kubernetes with GPU nodes to embed with an open source embedding model (sentence-transformers/sentence-t5-xxl) instead of OpenAI ADA. We eventually added Argo on top of it.\n\n  \nWhat other techniques do you see for scaling the pipeline? Where are you ingesting data from?\n\n  \nWe are building VectorFlow an open-source vector embedding pipeline that is containerized to run on kubernetes in any cloud and want to know what other features we should build next. Check out our Github repo:\u00a0[https://github.com/dgarnitz/vectorflow\u00a0to](https://github.com/dgarnitz/vectorflow%C2%A0to) install VectorFlow locally or t\\*ry it out in the playground (\\*[https://app.getvectorflow.com/](https://app.getvectorflow.com/)).", "author_fullname": "t2_8dgpjm0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Challenges with LLM + Vector searches with Large Data Volume", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hufnh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694628993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious how people in the community are setting up vector embeddings pipelines to ingest large GBs of data at once.&lt;/p&gt;\n\n&lt;p&gt;When I was working for a LegalTech startup and we had to ingest millions of litigation documents into a single vector database collection, we used celery + kubernetes with GPU nodes to embed with an open source embedding model (sentence-transformers/sentence-t5-xxl) instead of OpenAI ADA. We eventually added Argo on top of it.&lt;/p&gt;\n\n&lt;p&gt;What other techniques do you see for scaling the pipeline? Where are you ingesting data from?&lt;/p&gt;\n\n&lt;p&gt;We are building VectorFlow an open-source vector embedding pipeline that is containerized to run on kubernetes in any cloud and want to know what other features we should build next. Check out our Github repo:\u00a0&lt;a href=\"https://github.com/dgarnitz/vectorflow%C2%A0to\"&gt;https://github.com/dgarnitz/vectorflow\u00a0to&lt;/a&gt; install VectorFlow locally or t*ry it out in the playground (*&lt;a href=\"https://app.getvectorflow.com/\"&gt;https://app.getvectorflow.com/&lt;/a&gt;).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16hufnh", "is_robot_indexable": true, "report_reasons": null, "author": "Fast_Homework_3323", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hufnh/data_engineering_challenges_with_llm_vector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hufnh/data_engineering_challenges_with_llm_vector/", "subreddit_subscribers": 128402, "created_utc": 1694628993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Productionizing Jupyter Notebooks with Versatile Data Kit - Community Meeting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16hrrvy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/U6M6UzsoiqY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Productionizing Jupyter Notebooks with Versatile Data Kit\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Productionizing Jupyter Notebooks with Versatile Data Kit", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/U6M6UzsoiqY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Productionizing Jupyter Notebooks with Versatile Data Kit\"&gt;&lt;/iframe&gt;", "author_name": "Versatile Data Kit", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/U6M6UzsoiqY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@versatiledatakit8891"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/U6M6UzsoiqY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Productionizing Jupyter Notebooks with Versatile Data Kit\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16hrrvy", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wwy8STXGYk3eFYtkKVCCiwO1LuhhPYm_i6GoqP4yLHU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694622955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/U6M6UzsoiqY?si=mKrqwMmWEuqusVOM", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VsejW1FKtamHdvUVTIpW-gTRqIkBQcuZi0OxYehZ6-U.jpg?auto=webp&amp;s=5d7226c1dedff591489ca5fc151a0983ba9ce944", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/VsejW1FKtamHdvUVTIpW-gTRqIkBQcuZi0OxYehZ6-U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9936eaac16fea2f670d88b4c5ca6e8315e5cf665", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/VsejW1FKtamHdvUVTIpW-gTRqIkBQcuZi0OxYehZ6-U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e903a678622b2cd7f42295037b8558b142ffbf7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/VsejW1FKtamHdvUVTIpW-gTRqIkBQcuZi0OxYehZ6-U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b912542a5f22be369282022a5bd02586c30a0a6", "width": 320, "height": 240}], "variants": {}, "id": "W_DojcQEFVtCorjVwTlUBo5COWFMPEZ1rd2CU-Yy9bM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16hrrvy", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hrrvy/productionizing_jupyter_notebooks_with_versatile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/U6M6UzsoiqY?si=mKrqwMmWEuqusVOM", "subreddit_subscribers": 128402, "created_utc": 1694622955.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Productionizing Jupyter Notebooks with Versatile Data Kit", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/U6M6UzsoiqY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Productionizing Jupyter Notebooks with Versatile Data Kit\"&gt;&lt;/iframe&gt;", "author_name": "Versatile Data Kit", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/U6M6UzsoiqY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@versatiledatakit8891"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all, what is your prefered or best way to set secrets for systems that are multi-tenant and also have dev/prod etc environments?\n\nA little bit of background. As a backend dev, I used to always set secrets as environment variables through CI/CD. Or, either using a config yml/json file (for Go projects) or by creating the environment variables while building the Docker container (for Python/Node projects). This hasn't been a big problem as we rarely changed the  values.\n\nNow a days I am working on a multi-tenant data pipeline platform based on Airflow, essentially we have created our data models once but auto generated the pipelines for different customer tenants (which are Neo4j databases). This means if we have 3 customers, and dev, staging and prod environments, we essentially have 3x3 set of database creds alone.\n\nRight now we bake our dags into an Airflow Docker image and deploy the workers, webserver, dag processor etc separately. The problem we are facing right now is regarding changing the destination databases on the fly. For example, if we want to do a new load but want to do it to a new database instance, we would have to rebuild and redeploy the whole thing. Admittedly this is not the indented way to use Airflow, since we are not separating the software Airflow provides from the code we produce and the DAGs. The closest we went for separation is to use GitSync to update the DAGs is anything changes in the path for it. \n\nIf we want to ingest a dataset without affecting the existing db, we would need to get a new db instance, set the password in AWS Secrets manager and the hostname on the Kubernetes config (don't ask why two places, our devops wants to keep these separate for some reason). Then rebuild+redeploy the Docker image so that the new creds are used for the new push.   \n\n\nI feel like we are doing a ton of extra stuff here and cannot but feel a bit sluggish because of this process. How do you handle your secrets?", "author_fullname": "t2_12lkky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you store secrets for multi-tenant systems, for dev/staging/prod envs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ih83o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694694764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, what is your prefered or best way to set secrets for systems that are multi-tenant and also have dev/prod etc environments?&lt;/p&gt;\n\n&lt;p&gt;A little bit of background. As a backend dev, I used to always set secrets as environment variables through CI/CD. Or, either using a config yml/json file (for Go projects) or by creating the environment variables while building the Docker container (for Python/Node projects). This hasn&amp;#39;t been a big problem as we rarely changed the  values.&lt;/p&gt;\n\n&lt;p&gt;Now a days I am working on a multi-tenant data pipeline platform based on Airflow, essentially we have created our data models once but auto generated the pipelines for different customer tenants (which are Neo4j databases). This means if we have 3 customers, and dev, staging and prod environments, we essentially have 3x3 set of database creds alone.&lt;/p&gt;\n\n&lt;p&gt;Right now we bake our dags into an Airflow Docker image and deploy the workers, webserver, dag processor etc separately. The problem we are facing right now is regarding changing the destination databases on the fly. For example, if we want to do a new load but want to do it to a new database instance, we would have to rebuild and redeploy the whole thing. Admittedly this is not the indented way to use Airflow, since we are not separating the software Airflow provides from the code we produce and the DAGs. The closest we went for separation is to use GitSync to update the DAGs is anything changes in the path for it. &lt;/p&gt;\n\n&lt;p&gt;If we want to ingest a dataset without affecting the existing db, we would need to get a new db instance, set the password in AWS Secrets manager and the hostname on the Kubernetes config (don&amp;#39;t ask why two places, our devops wants to keep these separate for some reason). Then rebuild+redeploy the Docker image so that the new creds are used for the new push.   &lt;/p&gt;\n\n&lt;p&gt;I feel like we are doing a ton of extra stuff here and cannot but feel a bit sluggish because of this process. How do you handle your secrets?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Plumber", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ih83o", "is_robot_indexable": true, "report_reasons": null, "author": "ratulotron", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16ih83o/how_do_you_store_secrets_for_multitenant_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ih83o/how_do_you_store_secrets_for_multitenant_systems/", "subreddit_subscribers": 128402, "created_utc": 1694694764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Interpolating bathymetry point dataset using python](https://preview.redd.it/r0kar94bl1ob1.png?width=579&amp;format=png&amp;auto=webp&amp;s=5c8318def79ec710e66262a8798ed6a44f58b287)\n\n[Interpolating bathymetry point dataset using python](https://spatial-dev.guru/2023/07/31/interpolating-bathymetry-point-dataset/)", "author_fullname": "t2_avt84u4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interpolating bathymetry point dataset using python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 109, "top_awarded_type": null, "hide_score": false, "media_metadata": {"r0kar94bl1ob1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 84, "x": 108, "u": "https://preview.redd.it/r0kar94bl1ob1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cdaa0e7a97e4305853bdc423ebed05e4dacd4e7f"}, {"y": 168, "x": 216, "u": "https://preview.redd.it/r0kar94bl1ob1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c34ff1006fba71eb8faf790439f55e79b7cd06d0"}, {"y": 250, "x": 320, "u": "https://preview.redd.it/r0kar94bl1ob1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7bc02bf1a5afd1dae0160d1b7b854f67bc0514a"}], "s": {"y": 453, "x": 579, "u": "https://preview.redd.it/r0kar94bl1ob1.png?width=579&amp;format=png&amp;auto=webp&amp;s=5c8318def79ec710e66262a8798ed6a44f58b287"}, "id": "r0kar94bl1ob1"}}, "name": "t3_16hq7w5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jClx3X7WaOtwOX6nI2hW7emqQsKDfLLMP_PckjmEhno.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1694619352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/r0kar94bl1ob1.png?width=579&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5c8318def79ec710e66262a8798ed6a44f58b287\"&gt;Interpolating bathymetry point dataset using python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spatial-dev.guru/2023/07/31/interpolating-bathymetry-point-dataset/\"&gt;Interpolating bathymetry point dataset using python&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/S2275Z_UMEPbiKImFbLlXX9h39FlXNTlcb6989F63yA.jpg?auto=webp&amp;s=f39e97e0b90fcbaefbae3ec238427e62993e320c", "width": 579, "height": 453}, "resolutions": [{"url": "https://external-preview.redd.it/S2275Z_UMEPbiKImFbLlXX9h39FlXNTlcb6989F63yA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4f830d5d1374f9dbc3935d6b442c42f9a792edea", "width": 108, "height": 84}, {"url": "https://external-preview.redd.it/S2275Z_UMEPbiKImFbLlXX9h39FlXNTlcb6989F63yA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=631694a70e28d6f7bb3c6f4089fd377236c36d39", "width": 216, "height": 168}, {"url": "https://external-preview.redd.it/S2275Z_UMEPbiKImFbLlXX9h39FlXNTlcb6989F63yA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7bcf0bebba2340e734f5f201184344b41e475bc", "width": 320, "height": 250}], "variants": {}, "id": "gXs2eFzpnnyKOsdl5OI3jff2o2ddJeEQgbGsCoKon8A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16hq7w5", "is_robot_indexable": true, "report_reasons": null, "author": "iamgeoknight", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hq7w5/interpolating_bathymetry_point_dataset_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hq7w5/interpolating_bathymetry_point_dataset_using/", "subreddit_subscribers": 128402, "created_utc": 1694619352.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\nContext : im a 4y xp data engineer. In my last job i enjoyed building pipelines, configuring the infrastructure (iac) , programming spark jobs (dataproc) optimising queries and jobs ..etc. i have passed also GCPDE certification lately. \nI recently started with a consulting company that pays well and seems to have a great reputation being expert in the cloud fields.\nAs soon as i started my contract with them i received my first \u201cmission\u201d (that i can refuse, the company seems cool with it as long as it doesn\u2019t match your profile). The thing is, its a data analytics engineer role working mostly with dbt, sql/bigquery and airflow for the orchestration. At first i said to my self dbt seems to gain a lot of popularity and it\u2019ll be good to master sql once and for all. But then i felt like i could miss the dataops part of data engineering.. so do you think it\u2019s a good idea to accept the mission. Is data analytics  part of a data architect path? Your thoughts are welcome!", "author_fullname": "t2_dgduwpzjf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data analytics part of data engineering ? Can data analytics be in the scope of a data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ijykz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694701780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nContext : im a 4y xp data engineer. In my last job i enjoyed building pipelines, configuring the infrastructure (iac) , programming spark jobs (dataproc) optimising queries and jobs ..etc. i have passed also GCPDE certification lately. \nI recently started with a consulting company that pays well and seems to have a great reputation being expert in the cloud fields.\nAs soon as i started my contract with them i received my first \u201cmission\u201d (that i can refuse, the company seems cool with it as long as it doesn\u2019t match your profile). The thing is, its a data analytics engineer role working mostly with dbt, sql/bigquery and airflow for the orchestration. At first i said to my self dbt seems to gain a lot of popularity and it\u2019ll be good to master sql once and for all. But then i felt like i could miss the dataops part of data engineering.. so do you think it\u2019s a good idea to accept the mission. Is data analytics  part of a data architect path? Your thoughts are welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ijykz", "is_robot_indexable": true, "report_reasons": null, "author": "Xx_Tz_xX", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ijykz/is_data_analytics_part_of_data_engineering_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ijykz/is_data_analytics_part_of_data_engineering_can/", "subreddit_subscribers": 128402, "created_utc": 1694701780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nI'm a developer at a startup working on a product that requires integrating our user's third-party SaaS application data into our platform.\n\nAs I have not built any integrations before I am feeling a little lost in this space. Thus this post. I have a few doubts and scourging the web didn't help much.\n\nSpecifically:\n\n- Integration Tools: What tools or libraries have you found effective for setting up integrations with SaaS apps? I have seen a few including Merge, Paragon etc, but as I lack prior experience, I don't know on which factors should I assess them.\n\n  Due to the shortage of staff, I don't think a self managed ETL solution such as airbyte would be feasible in my usecase.\n\n- Data Retrieval: How do you efficiently retrieve data from SaaS apps, especially dealing with rate limits and data consistency?\n\n   Also I assume the authentications would be managed by such a platform. \n\n- Workflow Setup: How can I implement customizable automated workflows? How do I manage user configurations and workflow orchestration?\n\n\n\nI'd appreciate any insights, tips, or resources you can share.\n\nThanks for your help!", "author_fullname": "t2_w82f2h6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Seeking Advice) Integrating Third-party SaaS Apps for Automated Workflows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16igxlm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694693972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a developer at a startup working on a product that requires integrating our user&amp;#39;s third-party SaaS application data into our platform.&lt;/p&gt;\n\n&lt;p&gt;As I have not built any integrations before I am feeling a little lost in this space. Thus this post. I have a few doubts and scourging the web didn&amp;#39;t help much.&lt;/p&gt;\n\n&lt;p&gt;Specifically:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Integration Tools: What tools or libraries have you found effective for setting up integrations with SaaS apps? I have seen a few including Merge, Paragon etc, but as I lack prior experience, I don&amp;#39;t know on which factors should I assess them.&lt;/p&gt;\n\n&lt;p&gt;Due to the shortage of staff, I don&amp;#39;t think a self managed ETL solution such as airbyte would be feasible in my usecase.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data Retrieval: How do you efficiently retrieve data from SaaS apps, especially dealing with rate limits and data consistency?&lt;/p&gt;\n\n&lt;p&gt;Also I assume the authentications would be managed by such a platform. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Workflow Setup: How can I implement customizable automated workflows? How do I manage user configurations and workflow orchestration?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any insights, tips, or resources you can share.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16igxlm", "is_robot_indexable": true, "report_reasons": null, "author": "ChangesOfTheMoonman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16igxlm/seeking_advice_integrating_thirdparty_saas_apps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16igxlm/seeking_advice_integrating_thirdparty_saas_apps/", "subreddit_subscribers": 128402, "created_utc": 1694693972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to process either Excel files, API data, or CSV's that have different forms of similar data. The raw files will get saved as they are in S3. In this layer, we will also convert all of these to parquet.\n\nIn the next layer, we are going to take these parquet files, conform them to the same schema, and normalize any data into the appropriate staging tables.\n\nIn the final layer, we will use these normalized tables to denormalize and create any business level, easy-to-query tables.\n\nSo in S3, we'll save layer 1 data in the raw folder, layer 2 data in the stage folder, and layer 3 data in the bi folder. Is this organization reasonable? I feel like the first layer's conversion of the raw data into parquet is some form of transformation and therefore not \"raw.\" But maybe it's just semantics?", "author_fullname": "t2_5pjz5m35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raw vs Stage vs BI - Planning Things Correctly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16i3vab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694651539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to process either Excel files, API data, or CSV&amp;#39;s that have different forms of similar data. The raw files will get saved as they are in S3. In this layer, we will also convert all of these to parquet.&lt;/p&gt;\n\n&lt;p&gt;In the next layer, we are going to take these parquet files, conform them to the same schema, and normalize any data into the appropriate staging tables.&lt;/p&gt;\n\n&lt;p&gt;In the final layer, we will use these normalized tables to denormalize and create any business level, easy-to-query tables.&lt;/p&gt;\n\n&lt;p&gt;So in S3, we&amp;#39;ll save layer 1 data in the raw folder, layer 2 data in the stage folder, and layer 3 data in the bi folder. Is this organization reasonable? I feel like the first layer&amp;#39;s conversion of the raw data into parquet is some form of transformation and therefore not &amp;quot;raw.&amp;quot; But maybe it&amp;#39;s just semantics?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16i3vab", "is_robot_indexable": true, "report_reasons": null, "author": "maraskooknah", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16i3vab/raw_vs_stage_vs_bi_planning_things_correctly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16i3vab/raw_vs_stage_vs_bi_planning_things_correctly/", "subreddit_subscribers": 128402, "created_utc": 1694651539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI have some raw tables in BigQuery that contains live data, with a cdc connected to it. \n\nI need to do some analytics queries for an API, and to reduce the compute time, I tought it would be a good idea to store everything in a incremental table using **dbt** to run my model each time the raw table gets an update. It works when testing, but I noticed each dbt run takes 10 sec and that's too long for me. What other options do I have? Thank you\n\nTried materialized views but it does not support my query. ", "author_fullname": "t2_40sshxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bigquery quick query.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hzeug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694640496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I have some raw tables in BigQuery that contains live data, with a cdc connected to it. &lt;/p&gt;\n\n&lt;p&gt;I need to do some analytics queries for an API, and to reduce the compute time, I tought it would be a good idea to store everything in a incremental table using &lt;strong&gt;dbt&lt;/strong&gt; to run my model each time the raw table gets an update. It works when testing, but I noticed each dbt run takes 10 sec and that&amp;#39;s too long for me. What other options do I have? Thank you&lt;/p&gt;\n\n&lt;p&gt;Tried materialized views but it does not support my query. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hzeug", "is_robot_indexable": true, "report_reasons": null, "author": "LinweZ", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hzeug/bigquery_quick_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hzeug/bigquery_quick_query/", "subreddit_subscribers": 128402, "created_utc": 1694640496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am in an analyst role but I need to build data engineering skills. I have a project in front of me but no idea where to start. I need to build a platform that runs daily comparisons and real-time monitoring across different systems (Kafka, Graph, SQL, NoSQL). The main goals are to make sure systems are in sync (daily comparisons between system A &amp; B), and make sure contracts/rules are not broken (real time monitoring of events from system C). The daily comparisons can land in a database to be used later or generate a daily report. The real-time monitoring would result in an alert sent through slack if something broke a rule. But ultimately these comparisons will be very different across systems.\n\nMy DE knowledge is very limited so I was planning to run custom python scripts on a server but I'm sure there are better ways to orchestrate this. I don't have any problem integrating with the various data sources via Python, setting up a database to read/write, and writing alerts to slack. I just don't think this is the best way. What tools should I look into?", "author_fullname": "t2_b3bhj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need suggestions on tech to look into", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hq7rk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694619344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in an analyst role but I need to build data engineering skills. I have a project in front of me but no idea where to start. I need to build a platform that runs daily comparisons and real-time monitoring across different systems (Kafka, Graph, SQL, NoSQL). The main goals are to make sure systems are in sync (daily comparisons between system A &amp;amp; B), and make sure contracts/rules are not broken (real time monitoring of events from system C). The daily comparisons can land in a database to be used later or generate a daily report. The real-time monitoring would result in an alert sent through slack if something broke a rule. But ultimately these comparisons will be very different across systems.&lt;/p&gt;\n\n&lt;p&gt;My DE knowledge is very limited so I was planning to run custom python scripts on a server but I&amp;#39;m sure there are better ways to orchestrate this. I don&amp;#39;t have any problem integrating with the various data sources via Python, setting up a database to read/write, and writing alerts to slack. I just don&amp;#39;t think this is the best way. What tools should I look into?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hq7rk", "is_robot_indexable": true, "report_reasons": null, "author": "FeltZ85", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hq7rk/i_need_suggestions_on_tech_to_look_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hq7rk/i_need_suggestions_on_tech_to_look_into/", "subreddit_subscribers": 128402, "created_utc": 1694619344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is just something that I\u2019ve been contemplating lately. I just started a second degree in CS. Before starting the degree, I was, and still interested, in data analytics. I learned Excel, SQL (basic to intermediate), and basic Python. I also learned web development and know JavaScript, and know basic Java. I definitely feel like I\u2019m jumping around a lot because I have interests in different areas in technology.\n\nI\u2019m planning on graduating in 2 and a half years. My goal is to become a Data Engineer. I\u2019m wondering if I should focus my limited free time on creating projects that specifically targets software engineer positions or projects that target data analyst roles? \n\nReading this subreddit, some people said that to be a great data engineer, you need to have experience as a software engineer. But I\u2019ve also seen and connected with quite a few people that started off as a Data Analyst and eventually became a Data Engineer, without having any professional background as a Software Engineer. I feel like I want to learn everything to be qualified for both roles but I\u2019m not sure \ud83d\ude05", "author_fullname": "t2_816e80tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst\u2014&gt; DE or SWE \u2014&gt; DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ikqsx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694703743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is just something that I\u2019ve been contemplating lately. I just started a second degree in CS. Before starting the degree, I was, and still interested, in data analytics. I learned Excel, SQL (basic to intermediate), and basic Python. I also learned web development and know JavaScript, and know basic Java. I definitely feel like I\u2019m jumping around a lot because I have interests in different areas in technology.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m planning on graduating in 2 and a half years. My goal is to become a Data Engineer. I\u2019m wondering if I should focus my limited free time on creating projects that specifically targets software engineer positions or projects that target data analyst roles? &lt;/p&gt;\n\n&lt;p&gt;Reading this subreddit, some people said that to be a great data engineer, you need to have experience as a software engineer. But I\u2019ve also seen and connected with quite a few people that started off as a Data Analyst and eventually became a Data Engineer, without having any professional background as a Software Engineer. I feel like I want to learn everything to be qualified for both roles but I\u2019m not sure \ud83d\ude05&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ikqsx", "is_robot_indexable": true, "report_reasons": null, "author": "Humble-Ad-2280", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ikqsx/data_analyst_de_or_swe_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ikqsx/data_analyst_de_or_swe_de/", "subreddit_subscribers": 128402, "created_utc": 1694703743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious after reading this thread: [https://www.reddit.com/r/dataengineering/comments/16dgffb/data\\_pipelines\\_with\\_make/](https://www.reddit.com/r/dataengineering/comments/16dgffb/data_pipelines_with_make/)\n\nSeems like data pipelines with make aren't super popular but curious if people have productive uses for make in their daily workflow that leverage makefiles?\n\nI definitely have shell aliases functions that stitch together some command line stuff like just creating a new folder, git cloning, creating a venv, activating it, installing requirements if there is one etc. But that's something that's available to me globally in my shell. Makefiles seem localized.\n\n&amp;#x200B;", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any non-compilation but productive use cases for Make?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ikgzy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694703091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious after reading this thread: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/16dgffb/data_pipelines_with_make/\"&gt;https://www.reddit.com/r/dataengineering/comments/16dgffb/data_pipelines_with_make/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Seems like data pipelines with make aren&amp;#39;t super popular but curious if people have productive uses for make in their daily workflow that leverage makefiles?&lt;/p&gt;\n\n&lt;p&gt;I definitely have shell aliases functions that stitch together some command line stuff like just creating a new folder, git cloning, creating a venv, activating it, installing requirements if there is one etc. But that&amp;#39;s something that&amp;#39;s available to me globally in my shell. Makefiles seem localized.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ikgzy", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ikgzy/any_noncompilation_but_productive_use_cases_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ikgzy/any_noncompilation_but_productive_use_cases_for/", "subreddit_subscribers": 128402, "created_utc": 1694703091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have a technical interview with a potential peer. The position would be a Data Engineer, but my vibe is that it's more of an Analytics Engineer position. I don't think I'll be creating dashboards, (which I do have experience with using Domo/PowerBI). But as an Engineer, I would be helping the Data Analysts get the data they need and potentially steering them in the right direction. I don't have any direct experience with Tableau. Can you guys advise me on what I could try to prep for?  ", "author_fullname": "t2_1afmkbx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to prep for an interview involving Tableau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ike2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694702882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a technical interview with a potential peer. The position would be a Data Engineer, but my vibe is that it&amp;#39;s more of an Analytics Engineer position. I don&amp;#39;t think I&amp;#39;ll be creating dashboards, (which I do have experience with using Domo/PowerBI). But as an Engineer, I would be helping the Data Analysts get the data they need and potentially steering them in the right direction. I don&amp;#39;t have any direct experience with Tableau. Can you guys advise me on what I could try to prep for?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer \u200d\u2699\ufe0f", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16ike2t", "is_robot_indexable": true, "report_reasons": null, "author": "w_savage", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16ike2t/need_to_prep_for_an_interview_involving_tableau/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ike2t/need_to_prep_for_an_interview_involving_tableau/", "subreddit_subscribers": 128402, "created_utc": 1694702882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mxj2oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on PgBouncer From a Support Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_16iimn3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RYFbXQFPYeQuK8xAOCeX44IC8TFDvmrHQroLXIu4luI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694698373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "timescale.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.timescale.com/blog/p/cb5598ff-d5a2-4405-842e-2608ba109202/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?auto=webp&amp;s=f558a87f5972307efe62a377fd84d58981da3439", "width": 2000, "height": 1179}, "resolutions": [{"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=57a9554ee404b499f8b3f49be10c3fda0254e55d", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ee8ae187434b112e717155587c1277e1b2391e83", "width": 216, "height": 127}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f6ffb502bea59a69d336853ab8120a2584962a7c", "width": 320, "height": 188}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d72465fef513f97e1adc945437911ff6de66ed9a", "width": 640, "height": 377}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ca7227bbd977dfe9ab16675b911bcbe2d6938d9b", "width": 960, "height": 565}, {"url": "https://external-preview.redd.it/ssNhsDR_W5knl8CBmmQkE1NRx76sZfpM3-eGS5lT5zE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a8e940f75a08d6cddb15667225aa1b87fb68fa0", "width": 1080, "height": 636}], "variants": {}, "id": "Y3tB9NrWKmEpf7IHHJv0SKXo-7usHMSGxkasQoCO6gM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16iimn3", "is_robot_indexable": true, "report_reasons": null, "author": "carlotasoto", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16iimn3/advice_on_pgbouncer_from_a_support_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.timescale.com/blog/p/cb5598ff-d5a2-4405-842e-2608ba109202/", "subreddit_subscribers": 128402, "created_utc": 1694698373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event-Driven Architecture with Serverless Functions \u2014 Part 1", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16iifa7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/uXwdZJTGvRd7R0NZamK_FKP-yWub52n1YKMUlMiGyn8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694697858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@memphis-dev/event-driven-architecture-with-serverless-functions-part-1-d2b54babc193", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?auto=webp&amp;s=44310b4df96fcff8a4c60e0b77bd53ccbe69a9a8", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a3eb237e3111b2265078e4a03dbe68ae4649180", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ad13ff8b60f8b10e1ed8391a8934a78f271e58d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c473785bca234c87498a2605fec78a3c7e4edd99", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d9e31e54a5db31daa35632cbeb5e764b4c5a6b89", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=569d3b24a54fe3a1464d63c7db40530636a77433", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/0GyTUkBV6_SkgX64xR1VQKFmiRlGQHAxVzQaGsZAeB8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77c80d739d7d449f12290d8b77d6a7b023d89bd9", "width": 1080, "height": 607}], "variants": {}, "id": "_1gzao2guJDarba8auEOHTBsHMBx1uXbpiaoKpXsgrs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16iifa7", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16iifa7/eventdriven_architecture_with_serverless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@memphis-dev/event-driven-architecture-with-serverless-functions-part-1-d2b54babc193", "subreddit_subscribers": 128402, "created_utc": 1694697858.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}