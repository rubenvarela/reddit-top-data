{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was described as a stellar employee at my last company, but laid off with half my department with the good old \"unprecedented in times\" spiel that lots of companies are using right now. They tried to \"help me\" by offering a position that paid about 30K less than my previous position, as well as no longer being remote, so I would have to commute a full 5 days of the week. In order to find a new position, I studied my arse off every single day of the week Monday through Sunday drilling interview questions, coding question, everything under the sun I might possibly be asked, did that every single day of the week until I finally got a job offer from another large company. Admittedly, it's a step down from my previous position, but it's the only thing I've been offered so far or heard back on, and was only 10K less than my previous job....\n\nSince accepting this position, I have heard nothing from any other company that I've applied for, only denials and thanks for applying. The new position I accepted was data analyst. Before, I was senior data analyst in Data Engineering Dept, and there were no data engineers by title there, so If I was to be totally fair and honest, I would have described myself as junior data engineer. I didn't do anything as advanced as Hadoop or snowflake or spark, But I was setting up data lake, warehouse, pipelines, data marks, performance tuning of queries, using Python and SQL to set up data sources and retrieve data, as well as a lot of the reporting aspects that come with a data analyst position. I am in no way lazy, unmotivated, combative, unskilled, etc.  I'm your typical passionate, works hard and always researching and staying relevant data professional.\n\nNow I know a lot of people here don't believe that the job market is in a bad shape right now. But I have tried everything under the sun, and I have never, ever heard a single thing about an actual data engineering role. Never. The only thing I heard was that I'm overqualified for one data analyst role, hiring manager told me that longevity was the problem, I would probably be gone soon because my skill set is more of a data engineer. I agreed completely. But I get no call backs from them, and I would love to remain alive and keep living on planet Earth, so naturally, best way to do that is to have a job so you can pay bills.\n\n&amp;#x200B;\n\n(Note: this is in the USA. May be different in other countries)", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The job market is so bad that I had to take a demotion in order to survive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167g1t5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693596129.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693595330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was described as a stellar employee at my last company, but laid off with half my department with the good old &amp;quot;unprecedented in times&amp;quot; spiel that lots of companies are using right now. They tried to &amp;quot;help me&amp;quot; by offering a position that paid about 30K less than my previous position, as well as no longer being remote, so I would have to commute a full 5 days of the week. In order to find a new position, I studied my arse off every single day of the week Monday through Sunday drilling interview questions, coding question, everything under the sun I might possibly be asked, did that every single day of the week until I finally got a job offer from another large company. Admittedly, it&amp;#39;s a step down from my previous position, but it&amp;#39;s the only thing I&amp;#39;ve been offered so far or heard back on, and was only 10K less than my previous job....&lt;/p&gt;\n\n&lt;p&gt;Since accepting this position, I have heard nothing from any other company that I&amp;#39;ve applied for, only denials and thanks for applying. The new position I accepted was data analyst. Before, I was senior data analyst in Data Engineering Dept, and there were no data engineers by title there, so If I was to be totally fair and honest, I would have described myself as junior data engineer. I didn&amp;#39;t do anything as advanced as Hadoop or snowflake or spark, But I was setting up data lake, warehouse, pipelines, data marks, performance tuning of queries, using Python and SQL to set up data sources and retrieve data, as well as a lot of the reporting aspects that come with a data analyst position. I am in no way lazy, unmotivated, combative, unskilled, etc.  I&amp;#39;m your typical passionate, works hard and always researching and staying relevant data professional.&lt;/p&gt;\n\n&lt;p&gt;Now I know a lot of people here don&amp;#39;t believe that the job market is in a bad shape right now. But I have tried everything under the sun, and I have never, ever heard a single thing about an actual data engineering role. Never. The only thing I heard was that I&amp;#39;m overqualified for one data analyst role, hiring manager told me that longevity was the problem, I would probably be gone soon because my skill set is more of a data engineer. I agreed completely. But I get no call backs from them, and I would love to remain alive and keep living on planet Earth, so naturally, best way to do that is to have a job so you can pay bills.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(Note: this is in the USA. May be different in other countries)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167g1t5", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 88, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167g1t5/the_job_market_is_so_bad_that_i_had_to_take_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167g1t5/the_job_market_is_so_bad_that_i_had_to_take_a/", "subreddit_subscribers": 126345, "created_utc": 1693595330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a DE with a few years under my belt, I am starting to believe that with the glutt of tools available, the industry is now over-saturated to the point that we are making it un-needlessly overcomplicated for ourselves. Trying to automate everything and get a one size fits all solution for data that is anything but. What is wrong with having one tool for one thing, and one for another? Why have an airflow instance that calls 150 different dependencies? Make 10 that call 15. Getting bored of the whole \"my airflow instance launches 300 notebooks and can't find the root cause\" posts. \n\nLet's get back to basics, simplify data, write good documentation and spend time managing 30 DPL's that work rather than unpicking one fucking giant one that never does.", "author_fullname": "t2_8p2u7cmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers overcomplicate things", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167x47m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693643748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a DE with a few years under my belt, I am starting to believe that with the glutt of tools available, the industry is now over-saturated to the point that we are making it un-needlessly overcomplicated for ourselves. Trying to automate everything and get a one size fits all solution for data that is anything but. What is wrong with having one tool for one thing, and one for another? Why have an airflow instance that calls 150 different dependencies? Make 10 that call 15. Getting bored of the whole &amp;quot;my airflow instance launches 300 notebooks and can&amp;#39;t find the root cause&amp;quot; posts. &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s get back to basics, simplify data, write good documentation and spend time managing 30 DPL&amp;#39;s that work rather than unpicking one fucking giant one that never does.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167x47m", "is_robot_indexable": true, "report_reasons": null, "author": "Jamese0", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167x47m/data_engineers_overcomplicate_things/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167x47m/data_engineers_overcomplicate_things/", "subreddit_subscribers": 126345, "created_utc": 1693643748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been doing Data Engineering for a while now, and understand the cloud based Data Engineering tools from AWS, CGP, Azure, etc. I keep seeing a lot of job descriptions requiring or preferring knowledge of Snowflake, which I've never had to use in my career.\n\nI've read about it a few times and I think I generally understand the concept, but what I guess I don't understand is why you would use it?\n\nFrom what I have read and watched some videos of (please correct me if I'm wrong), Snowflake works as a SaaS Data Warehouse that integrates with the big three cloud providers. For AWS, for example, you would host the data in AWS S3, and the processing comes from AWS EC2 containers that it would instantiate for you. So it seems to do a lot of the orchestration?\n\nSo in this case, why wouldn't you just use Glue, Athena, RedShift, etc to do this? It seems like you'd be paying AWS for their services, plus Snowflake. I know that you could potentially integrate data from the different cloud platforms together, but I know there are at least ways of bringing in, for example Google Analytics data into AWS through things like AWS Appflow, if not programmatically.\n\nSo I've been wondering, is it cheaper, more abstracted and easier to use, more performant? A lot of companies seem to be using it. I thought I'd ask this here so I had the advantages in mind before I sign up for a free trial or something.", "author_fullname": "t2_ivjxpztcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've been trying to wrap my head around the use of Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168208y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693659814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been doing Data Engineering for a while now, and understand the cloud based Data Engineering tools from AWS, CGP, Azure, etc. I keep seeing a lot of job descriptions requiring or preferring knowledge of Snowflake, which I&amp;#39;ve never had to use in my career.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read about it a few times and I think I generally understand the concept, but what I guess I don&amp;#39;t understand is why you would use it?&lt;/p&gt;\n\n&lt;p&gt;From what I have read and watched some videos of (please correct me if I&amp;#39;m wrong), Snowflake works as a SaaS Data Warehouse that integrates with the big three cloud providers. For AWS, for example, you would host the data in AWS S3, and the processing comes from AWS EC2 containers that it would instantiate for you. So it seems to do a lot of the orchestration?&lt;/p&gt;\n\n&lt;p&gt;So in this case, why wouldn&amp;#39;t you just use Glue, Athena, RedShift, etc to do this? It seems like you&amp;#39;d be paying AWS for their services, plus Snowflake. I know that you could potentially integrate data from the different cloud platforms together, but I know there are at least ways of bringing in, for example Google Analytics data into AWS through things like AWS Appflow, if not programmatically.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve been wondering, is it cheaper, more abstracted and easier to use, more performant? A lot of companies seem to be using it. I thought I&amp;#39;d ask this here so I had the advantages in mind before I sign up for a free trial or something.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "168208y", "is_robot_indexable": true, "report_reasons": null, "author": "DEDumbQuestions", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/168208y/ive_been_trying_to_wrap_my_head_around_the_use_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/168208y/ive_been_trying_to_wrap_my_head_around_the_use_of/", "subreddit_subscribers": 126345, "created_utc": 1693659814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "beginner here, using vanilla databricks platform. the project currently I'm doing is just pulling from api ELT  and perhaps some transformation and views for dashboard consumption . perhaps experts here can point to maybe basic to intermediate type of tests. perhaps for the first iteration I'd be doing basic ones first.\n\nyoutube videos or links would be helpful too. Thanks. ", "author_fullname": "t2_ecope", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to do unit testing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167qmrm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693622101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;beginner here, using vanilla databricks platform. the project currently I&amp;#39;m doing is just pulling from api ELT  and perhaps some transformation and views for dashboard consumption . perhaps experts here can point to maybe basic to intermediate type of tests. perhaps for the first iteration I&amp;#39;d be doing basic ones first.&lt;/p&gt;\n\n&lt;p&gt;youtube videos or links would be helpful too. Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "167qmrm", "is_robot_indexable": true, "report_reasons": null, "author": "snip3r77", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167qmrm/how_to_do_unit_testing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167qmrm/how_to_do_unit_testing/", "subreddit_subscribers": 126345, "created_utc": 1693622101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys! Hope You all are doing fine.\n\nGiving You some context on what I'm through right now. I asked my manager to migrate from Data Analyst role to Data Engineer as I'm practicing a lot of Data Engineering activities on a day-to-day basis inside GCP, mainly with BigQuery (SQL intensive role as a data analyst, preparing sandbox queries to be put in production in raw/trusted/refined zones by engineering team). He told me that this carreer transition can be done but one of the recommendations was that I need to pass the PDE exam and get the certification as a prerequisite to turn into Data Engineering with a better position in the team as they want me to jump from Mid-Level Data Analyst to Mid-Level Data Engineer (I know it seems strange but it is what it is).\n\nI'm studying GCP since June this year by reading documentations and practicing with my free credits setting up some pipelines with Dataflow, Pub/Sub, loading data into BigQuery and just building simple ETL processes with PySpark, Apache Beam and Kafka on local environment and messing with basic CLI commands. I'm also practicing with mock exams from testprep, passnexam and examtopics, which average results are up to 80%-95% of correct answers. \n\n&amp;#x200B;\n\nMy greatest insecurity is about the mock exams, some people say they are a great measure of possible success, some say the questions from the actual exam are a lot harder.\n\nDo You think that I have great chances of passing the exam or it is too risky?\n\n&amp;#x200B;\n\nThanks in advance for your responses, wish you the best of luck!", "author_fullname": "t2_epxr11c18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Taking GCP Professional Data Engineer as an Analyst, what are your thoughts??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167mcub", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693610295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys! Hope You all are doing fine.&lt;/p&gt;\n\n&lt;p&gt;Giving You some context on what I&amp;#39;m through right now. I asked my manager to migrate from Data Analyst role to Data Engineer as I&amp;#39;m practicing a lot of Data Engineering activities on a day-to-day basis inside GCP, mainly with BigQuery (SQL intensive role as a data analyst, preparing sandbox queries to be put in production in raw/trusted/refined zones by engineering team). He told me that this carreer transition can be done but one of the recommendations was that I need to pass the PDE exam and get the certification as a prerequisite to turn into Data Engineering with a better position in the team as they want me to jump from Mid-Level Data Analyst to Mid-Level Data Engineer (I know it seems strange but it is what it is).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m studying GCP since June this year by reading documentations and practicing with my free credits setting up some pipelines with Dataflow, Pub/Sub, loading data into BigQuery and just building simple ETL processes with PySpark, Apache Beam and Kafka on local environment and messing with basic CLI commands. I&amp;#39;m also practicing with mock exams from testprep, passnexam and examtopics, which average results are up to 80%-95% of correct answers. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My greatest insecurity is about the mock exams, some people say they are a great measure of possible success, some say the questions from the actual exam are a lot harder.&lt;/p&gt;\n\n&lt;p&gt;Do You think that I have great chances of passing the exam or it is too risky?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your responses, wish you the best of luck!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "167mcub", "is_robot_indexable": true, "report_reasons": null, "author": "khemei", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167mcub/taking_gcp_professional_data_engineer_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167mcub/taking_gcp_professional_data_engineer_as_an/", "subreddit_subscribers": 126345, "created_utc": 1693610295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I accepted an offer to become a first data hire in a startup. It means I will be responsible for implementing data infrastructure.\n\nDuring the technical interview, I discovered that their current analytics is a Python script that exports data from MySQL/Mongo and sends it over to the reverse ETL platform. Which means the team has no control over their data. The best they have is a giant CSV file they can wrangle in Spreadsheets.\n\nMy proposal for implementing a data infrastructure was the following:\n\n1. Bring Data Warehouse. It will centralize all data sources and eventually give access to the data for the whole team. I suggested Snowflake because I worked with it and liked it.\n2. Bring data transformation tool, dbt. It's used for data cleaning, modeling, testing, and documentation. This is a foundation for BI analytics and further reverse ETL processes.\n3. Bring some simple BI tool, like Metabase. It's a very simple tool that allows for quick data visualization and exploration. Alternatively, we could try Lightdash because it tightly integrates with dbt.\n\nI still can't decide on:\n\n* What should we do for data integration? Airbyte? Fivetran?\n* Do we need a general ETL tool, like Airflow? (I don't like Airflow tbh)\n\nWhat can you recommend on the mentioned topics? And maybe I'm missing something, or overthinking?", "author_fullname": "t2_4679pe1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you build analytics infrastructure in a startup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167woqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693642138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I accepted an offer to become a first data hire in a startup. It means I will be responsible for implementing data infrastructure.&lt;/p&gt;\n\n&lt;p&gt;During the technical interview, I discovered that their current analytics is a Python script that exports data from MySQL/Mongo and sends it over to the reverse ETL platform. Which means the team has no control over their data. The best they have is a giant CSV file they can wrangle in Spreadsheets.&lt;/p&gt;\n\n&lt;p&gt;My proposal for implementing a data infrastructure was the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Bring Data Warehouse. It will centralize all data sources and eventually give access to the data for the whole team. I suggested Snowflake because I worked with it and liked it.&lt;/li&gt;\n&lt;li&gt;Bring data transformation tool, dbt. It&amp;#39;s used for data cleaning, modeling, testing, and documentation. This is a foundation for BI analytics and further reverse ETL processes.&lt;/li&gt;\n&lt;li&gt;Bring some simple BI tool, like Metabase. It&amp;#39;s a very simple tool that allows for quick data visualization and exploration. Alternatively, we could try Lightdash because it tightly integrates with dbt.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I still can&amp;#39;t decide on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What should we do for data integration? Airbyte? Fivetran?&lt;/li&gt;\n&lt;li&gt;Do we need a general ETL tool, like Airflow? (I don&amp;#39;t like Airflow tbh)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What can you recommend on the mentioned topics? And maybe I&amp;#39;m missing something, or overthinking?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167woqw", "is_robot_indexable": true, "report_reasons": null, "author": "oleg_agapov", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167woqw/how_would_you_build_analytics_infrastructure_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167woqw/how_would_you_build_analytics_infrastructure_in_a/", "subreddit_subscribers": 126345, "created_utc": 1693642138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. Does your team have on-call rotation for any failures after hours or on weekends? Primarily those who work with critical data pipelines. \n2. How frequent do you have issues in a week/month?  \n   1. we have issues maybe twice a month (sometimes just bc we didn't get a file from the client and have to wait for them to resend it, which can be hours later)\n3. Have you encountered issues with knowledge being siloed that multiple have to jump on regardless of who's on-call? We're working on better documentation and knowledge sharing so other people aren't required to jump in but it's a challenge. \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On-call rotation and frequency of support off-hours?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167eqrd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693592278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;Does your team have on-call rotation for any failures after hours or on weekends? Primarily those who work with critical data pipelines. &lt;/li&gt;\n&lt;li&gt;How frequent do you have issues in a week/month?&lt;br/&gt;\n\n&lt;ol&gt;\n&lt;li&gt;we have issues maybe twice a month (sometimes just bc we didn&amp;#39;t get a file from the client and have to wait for them to resend it, which can be hours later)&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Have you encountered issues with knowledge being siloed that multiple have to jump on regardless of who&amp;#39;s on-call? We&amp;#39;re working on better documentation and knowledge sharing so other people aren&amp;#39;t required to jump in but it&amp;#39;s a challenge. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167eqrd", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167eqrd/oncall_rotation_and_frequency_of_support_offhours/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167eqrd/oncall_rotation_and_frequency_of_support_offhours/", "subreddit_subscribers": 126345, "created_utc": 1693592278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am confused about the way my company operates. It seems like everyone does not know how to operationalize analytics. There was a case where a manager simply asked our team to aggregate transactional data and told us to create a visualization of thousands of rows of data. That does not make any sense.\n\nIs there a good framework you use to determine what's worth creating (analytics use cases)?", "author_fullname": "t2_44nfhvhnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is worth analyzing? How do we decide which analysis pipeline is worth the effort?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167pc1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693618361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am confused about the way my company operates. It seems like everyone does not know how to operationalize analytics. There was a case where a manager simply asked our team to aggregate transactional data and told us to create a visualization of thousands of rows of data. That does not make any sense.&lt;/p&gt;\n\n&lt;p&gt;Is there a good framework you use to determine what&amp;#39;s worth creating (analytics use cases)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167pc1h", "is_robot_indexable": true, "report_reasons": null, "author": "Personal_Tennis_466", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167pc1h/what_is_worth_analyzing_how_do_we_decide_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167pc1h/what_is_worth_analyzing_how_do_we_decide_which/", "subreddit_subscribers": 126345, "created_utc": 1693618361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working on a LLM proposal for a smaller size organization and currently researching data pipelines. Initially, I was looking into Airflow but while doing so, I came across Dagster and Prefect but still trying to determine which is the best fit for the project. With that being said, I\u2019m looking for guidance on which platform works (or might work) better when dealing with vector embeddings and vector stores/databases. \n\nNote: proposal requirements for the project is utilizing free open-source platforms whenever possible in addition to cloud-based deployment capabilities. \n\nThank you in advance!", "author_fullname": "t2_7kiosw8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster, Prefect, and Vector Stores", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167gzns", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693597478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working on a LLM proposal for a smaller size organization and currently researching data pipelines. Initially, I was looking into Airflow but while doing so, I came across Dagster and Prefect but still trying to determine which is the best fit for the project. With that being said, I\u2019m looking for guidance on which platform works (or might work) better when dealing with vector embeddings and vector stores/databases. &lt;/p&gt;\n\n&lt;p&gt;Note: proposal requirements for the project is utilizing free open-source platforms whenever possible in addition to cloud-based deployment capabilities. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167gzns", "is_robot_indexable": true, "report_reasons": null, "author": "Few_Percentage2630", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167gzns/dagster_prefect_and_vector_stores/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167gzns/dagster_prefect_and_vector_stores/", "subreddit_subscribers": 126345, "created_utc": 1693597478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. This is the first post I'm creating in this channel. To give a background about myself, I work as a data engineer.\n\nI joined a startup company around 1.5-2 years ago as a software engineer. Initially, I used to work as a software engineer and then after few months the need for a data warehouse arose but we didn't had any data engineers back then. So I was asked to work on the DE stuff where I was supposed to build the data warehouse using Python/Airflow/Postgres stack(yes you read right!)\nMy manager's focus was just to get this DWH project started to serve the purpose of analytics and research's model training.\n\nFast forward to 6 months down the line, we noticed some bottlenecks related to some database design decisions that we had made earlier and also there were performance bottlenecks coming into the picture as our data set grew in size. We started to think and plan to overcome those issues but till now we have not yet gotten started(it's been more than 5 months since we had done the planning of resolution of these issues).\n\n\nEverytime we start to think of working on the resolution there are ad-hoc requests which keeps in flowing and they term them as blocker/critical. There's very little of data quality checks implemented in these pipelines which keeps us haunting. On top of that I'm expected to deliver them resources which would be useful for them in their analytical purpose. These resources are something which I think should be created by the data analysts as they know the exact metrics what they need. It could be the case that since they don't want to write complex SQL queries they ask me to give them the data in a structured format which would make their life easier.\n\nI'm still the only data engineer working in there and we are tight on budget to get more resources. I'm now constantly getting held responsible for data related issues which I don't have control over or there's not enough bandwidth for me to work and get everything fixed at once.\n\nI feel like I'm not growing and only resolving the bugs and issues which could have been taken care of if I was given enough time rather than those ad-hoc requests which kept on flowing to me. I need some suggestions and if anyone has gone through this then please let me know what was your experience like. Thanks!", "author_fullname": "t2_bt39kjks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I look lost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167e18k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693625463.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693590693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. This is the first post I&amp;#39;m creating in this channel. To give a background about myself, I work as a data engineer.&lt;/p&gt;\n\n&lt;p&gt;I joined a startup company around 1.5-2 years ago as a software engineer. Initially, I used to work as a software engineer and then after few months the need for a data warehouse arose but we didn&amp;#39;t had any data engineers back then. So I was asked to work on the DE stuff where I was supposed to build the data warehouse using Python/Airflow/Postgres stack(yes you read right!)\nMy manager&amp;#39;s focus was just to get this DWH project started to serve the purpose of analytics and research&amp;#39;s model training.&lt;/p&gt;\n\n&lt;p&gt;Fast forward to 6 months down the line, we noticed some bottlenecks related to some database design decisions that we had made earlier and also there were performance bottlenecks coming into the picture as our data set grew in size. We started to think and plan to overcome those issues but till now we have not yet gotten started(it&amp;#39;s been more than 5 months since we had done the planning of resolution of these issues).&lt;/p&gt;\n\n&lt;p&gt;Everytime we start to think of working on the resolution there are ad-hoc requests which keeps in flowing and they term them as blocker/critical. There&amp;#39;s very little of data quality checks implemented in these pipelines which keeps us haunting. On top of that I&amp;#39;m expected to deliver them resources which would be useful for them in their analytical purpose. These resources are something which I think should be created by the data analysts as they know the exact metrics what they need. It could be the case that since they don&amp;#39;t want to write complex SQL queries they ask me to give them the data in a structured format which would make their life easier.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m still the only data engineer working in there and we are tight on budget to get more resources. I&amp;#39;m now constantly getting held responsible for data related issues which I don&amp;#39;t have control over or there&amp;#39;s not enough bandwidth for me to work and get everything fixed at once.&lt;/p&gt;\n\n&lt;p&gt;I feel like I&amp;#39;m not growing and only resolving the bugs and issues which could have been taken care of if I was given enough time rather than those ad-hoc requests which kept on flowing to me. I need some suggestions and if anyone has gone through this then please let me know what was your experience like. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "167e18k", "is_robot_indexable": true, "report_reasons": null, "author": "tradax", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167e18k/i_look_lost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167e18k/i_look_lost/", "subreddit_subscribers": 126345, "created_utc": 1693590693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I'm interested in start a career on Data Engineering and other areas related to Data. \n\nI have a background on QA, some python programming skills and basic SQL. Currently I'm in a project where I have a lot of contact with AWS Glue jobs and other services and I see they use PySpark a lot.\n\nI don't know if it's better to start learning PySpark or Pandas first to acquire the basic concepts of ETL.\n\nI found that Pandas tutorials and other libraries are easier to follow that PySpark ones and the installation on local machines seems easier too\n\nWich do you think is best to start learning?", "author_fullname": "t2_5de0ws6n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark or Pandas to start", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1682v44", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693662161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I&amp;#39;m interested in start a career on Data Engineering and other areas related to Data. &lt;/p&gt;\n\n&lt;p&gt;I have a background on QA, some python programming skills and basic SQL. Currently I&amp;#39;m in a project where I have a lot of contact with AWS Glue jobs and other services and I see they use PySpark a lot.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if it&amp;#39;s better to start learning PySpark or Pandas first to acquire the basic concepts of ETL.&lt;/p&gt;\n\n&lt;p&gt;I found that Pandas tutorials and other libraries are easier to follow that PySpark ones and the installation on local machines seems easier too&lt;/p&gt;\n\n&lt;p&gt;Wich do you think is best to start learning?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1682v44", "is_robot_indexable": true, "report_reasons": null, "author": "cfulanitto", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1682v44/pyspark_or_pandas_to_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1682v44/pyspark_or_pandas_to_start/", "subreddit_subscribers": 126345, "created_utc": 1693662161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I understand data catalog is the central metadata , but I don\u2019t understand why is it that important? I see lots of posts on LinkedIn, saying data catalog is important to implement, but never understood why. Can some help me in understanding?", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is data catalog that important ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167uqpv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693635083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand data catalog is the central metadata , but I don\u2019t understand why is it that important? I see lots of posts on LinkedIn, saying data catalog is important to implement, but never understood why. Can some help me in understanding?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167uqpv", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/167uqpv/why_is_data_catalog_that_important/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167uqpv/why_is_data_catalog_that_important/", "subreddit_subscribers": 126345, "created_utc": 1693635083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Next week I will have my tech interview and I really appreciate some tips based on your experience.\nIt is for a data engineer position. Thank you so much for your help.", "author_fullname": "t2_802hx5xi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need tips for data warehousing SQL interview (wizeline)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167rtae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693627872.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693625634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Next week I will have my tech interview and I really appreciate some tips based on your experience.\nIt is for a data engineer position. Thank you so much for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "167rtae", "is_robot_indexable": true, "report_reasons": null, "author": "NationOfSheeps", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167rtae/need_tips_for_data_warehousing_sql_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167rtae/need_tips_for_data_warehousing_sql_interview/", "subreddit_subscribers": 126345, "created_utc": 1693625634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been into DE for about 8 years now, loosely. Much of that time was actually spent doing BA/BI work, but got my foot into the door and allowed me to really fine tune my sql skills and to gain an understanding of our domain data. I do DE work too, build ETL pipelines, monitor jobs, optimize then etc but my by biggest concern has always been business facing.\n\nMy org has a few different data groups that have popped up over the years, and the skillsets vary quite a bit. The other groups seemed very focused on the tech aspect and didn\u2019t ever seem to know anything about the business that we support. Whereas my group is sort of the opposite - we\u2019re quite good with the tools we have but have been far more focused on implementing solutions to help the business, and to do that effectively, we have to understand what they want. It\u2019s not that we don\u2019t care about technology, it\u2019s that it was a secondary concern to us.\n\nIt\u2019s recently dawned on me - the distinction that I\u2019m seeing is probably DE vs AE, and both are necessarily roles which are quite important in their own right. As I\u2019ve been working closer with the other groups, we complement each other quite nicely and there is actually quite a big overlap in terms of skills.\n\nAnyone work somewhere with a title distinction between DE and AE? What has your experience been like, and what are the differences you see in terms of roles, responsibility, and skill sets?", "author_fullname": "t2_asecovey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I think I\u2019m actually an Analytics Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16868f5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693670570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been into DE for about 8 years now, loosely. Much of that time was actually spent doing BA/BI work, but got my foot into the door and allowed me to really fine tune my sql skills and to gain an understanding of our domain data. I do DE work too, build ETL pipelines, monitor jobs, optimize then etc but my by biggest concern has always been business facing.&lt;/p&gt;\n\n&lt;p&gt;My org has a few different data groups that have popped up over the years, and the skillsets vary quite a bit. The other groups seemed very focused on the tech aspect and didn\u2019t ever seem to know anything about the business that we support. Whereas my group is sort of the opposite - we\u2019re quite good with the tools we have but have been far more focused on implementing solutions to help the business, and to do that effectively, we have to understand what they want. It\u2019s not that we don\u2019t care about technology, it\u2019s that it was a secondary concern to us.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s recently dawned on me - the distinction that I\u2019m seeing is probably DE vs AE, and both are necessarily roles which are quite important in their own right. As I\u2019ve been working closer with the other groups, we complement each other quite nicely and there is actually quite a big overlap in terms of skills.&lt;/p&gt;\n\n&lt;p&gt;Anyone work somewhere with a title distinction between DE and AE? What has your experience been like, and what are the differences you see in terms of roles, responsibility, and skill sets?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16868f5", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableLadder5336", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16868f5/i_think_im_actually_an_analytics_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16868f5/i_think_im_actually_an_analytics_engineer/", "subreddit_subscribers": 126345, "created_utc": 1693670570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, everyone. Hope you guys are doing alright.\n\nThought I should share a project I have been working on recently as it might help someone. It's an end to end data pipeline that models and visualizes customer churn. I am not a complete beginner as I have a background in CS, so I have tried to integrate the concepts that I have learnt from machine learning, data engineering, and analytics engineering. I'll go ahead and rip the rest of this post from the readme.\n\n&amp;#x200B;\n\n[Dashboard Preview](https://preview.redd.it/mnwihcrc1vlb1.png?width=1883&amp;format=png&amp;auto=webp&amp;s=9c6e0970a7054faf8f641eb89946603a62bf0679)\n\nThis project was developed to:\n\n\\- Employ various elements of the modern data stack\n\n\\- Be applied to a somewhat realistic business use case\n\n\\- Serve as a template for others to learn from and use via extensive documentation\n\n&amp;#x200B;\n\n[Project Architecture](https://preview.redd.it/c2ha0g6g1vlb1.png?width=672&amp;format=png&amp;auto=webp&amp;s=05fc73a8b33ead310b958833a0315939d5f8ef62)\n\nFor this project, the Telco Customer Churn data module which is a sample dataset on IBM's Cognos Analytics platform is used. This seemed like the best representative considering the difficulty in finding a decent dataset for the use case.\n\nThe dataset is then used to train two models. The first is a Gaussian Copula Synthesizer to produce synthetic data with characteristics similar to the original. This is done since there is not much data to go around and serves as a rudimentary imitation of data entering the database, The second is an LGBModel which is a product of using FLAML's AutoML implementation on the data, and its purpose is to predict churn status for a particular user.\n\nBoth models are hosted via FastAPI and are accessed this way. Airflow is then used to orchestrate the pulling of data from the Synthesizer, obtaining churn status prediction for said data from the classification model, generating a ULID for each user, and writing it all to a Postgres database. Airflow is also used to trigger dbt afterward to run tests and apply necessary transformations. The data is modeled after the star schema and is finally visualized as a dashboard using Metabase.\n\n&amp;#x200B;\n\n[Data Model Diagram](https://preview.redd.it/dju7uz4i1vlb1.png?width=773&amp;format=png&amp;auto=webp&amp;s=bddfc3fdf1d0aa570dcec5c77dec0ffde61e8dbf)\n\nAlmost all of the services above run in their own docker containers, as seen in the diagram. These containers are running on a GCP VM, provisioned via Terraform. Finally, GitHub Actions facilitates CD, as changes made to this repo are reflected in the VM.\n\n&amp;#x200B;\n\nI know that the use case is kinda boring, but it helps provide a decent perspective as to the work that usually exists in the industry. I have also elaborated more on the technicalities of this project in the GitHub readme, so check that out if you want a bigger picture of things. As already mentioned, looking to hear from you guys on any improvements that can be made, or details that must be considered.\n\nAccess [the dashboard here.](http://34.134.216.50:3000/public/dashboard/085f43f1-3301-45e2-b4f5-5bd0d789d1f3)\n\nLink to [the project here.](https://github.com/raashidsalih/churn-pipeline)\n\n&amp;#x200B;\n\n**Quick question for the experienced folk here:** *What would be the best way to showcase this project on a CV? What aspects should I ensure I convey, and what should I leave out?*  \nGreatly appreciate your insights and your time.\n\n&amp;#x200B;\n\nFinally, major shoutout to our neighborhood resident Joseph Machado (u/joseph_machado) from StartDataEngineering for his educational content, and also for spending his valuable time initially with some of my questions.\n\nHope you guys have a good day.", "author_fullname": "t2_34bck2h6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Project - Customer Churn with Synthetic Data, Criticism welcome!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": true, "media_metadata": {"c2ha0g6g1vlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 64, "x": 108, "u": "https://preview.redd.it/c2ha0g6g1vlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ed3312c42edd3900ac17cceaaeb8a8c05da0e5b"}, {"y": 129, "x": 216, "u": "https://preview.redd.it/c2ha0g6g1vlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=77bcffc62aaf07714ae966b21e2518ccff3cf9d2"}, {"y": 191, "x": 320, "u": "https://preview.redd.it/c2ha0g6g1vlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ca485a3eb8a1fc88dd091be209b740973b2ccdd1"}, {"y": 382, "x": 640, "u": "https://preview.redd.it/c2ha0g6g1vlb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bb812cc6be8f1a0c77e62189ba669534dadffbed"}], "s": {"y": 402, "x": 672, "u": "https://preview.redd.it/c2ha0g6g1vlb1.png?width=672&amp;format=png&amp;auto=webp&amp;s=05fc73a8b33ead310b958833a0315939d5f8ef62"}, "id": "c2ha0g6g1vlb1"}, "mnwihcrc1vlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/mnwihcrc1vlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f694f45f632cffce8009ab76a117d5ac032bc2f6"}, {"y": 99, "x": 216, "u": "https://preview.redd.it/mnwihcrc1vlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e226edd2e120d061c33e6ac36dd309c2c68df744"}, {"y": 147, "x": 320, "u": "https://preview.redd.it/mnwihcrc1vlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=be46e8b85668959879d5a45885471c4c1bb4d3f3"}, {"y": 294, "x": 640, "u": "https://preview.redd.it/mnwihcrc1vlb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7c6c1f0304c80568ed97f3d861dea1e9a236597"}, {"y": 442, "x": 960, "u": "https://preview.redd.it/mnwihcrc1vlb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fd45ec7ad70d88df5a91c34ce80dc18880e9a7e2"}, {"y": 497, "x": 1080, "u": "https://preview.redd.it/mnwihcrc1vlb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=88383772127ef85bb27159b1e70a9edb5274bda8"}], "s": {"y": 867, "x": 1883, "u": "https://preview.redd.it/mnwihcrc1vlb1.png?width=1883&amp;format=png&amp;auto=webp&amp;s=9c6e0970a7054faf8f641eb89946603a62bf0679"}, "id": "mnwihcrc1vlb1"}, "dju7uz4i1vlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 116, "x": 108, "u": "https://preview.redd.it/dju7uz4i1vlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d1383d36040f177c356807907462d830a2a9401e"}, {"y": 232, "x": 216, "u": "https://preview.redd.it/dju7uz4i1vlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cfc35135348f9619f02db2e19477456adb834ef8"}, {"y": 344, "x": 320, "u": "https://preview.redd.it/dju7uz4i1vlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cae3807e97ceca3df1e4cde7f1eed5b882507db0"}, {"y": 689, "x": 640, "u": "https://preview.redd.it/dju7uz4i1vlb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=074c33d236f9714cca4da0c9393ca00eb364adf6"}], "s": {"y": 833, "x": 773, "u": "https://preview.redd.it/dju7uz4i1vlb1.png?width=773&amp;format=png&amp;auto=webp&amp;s=bddfc3fdf1d0aa570dcec5c77dec0ffde61e8dbf"}, "id": "dju7uz4i1vlb1"}}, "name": "t3_1685dax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i-f9SH2v1O0csVVMzPP7yO1MK9PHfiYMlov-yVHzUDE.jpg", "edited": 1693671123.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693668473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, everyone. Hope you guys are doing alright.&lt;/p&gt;\n\n&lt;p&gt;Thought I should share a project I have been working on recently as it might help someone. It&amp;#39;s an end to end data pipeline that models and visualizes customer churn. I am not a complete beginner as I have a background in CS, so I have tried to integrate the concepts that I have learnt from machine learning, data engineering, and analytics engineering. I&amp;#39;ll go ahead and rip the rest of this post from the readme.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/mnwihcrc1vlb1.png?width=1883&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9c6e0970a7054faf8f641eb89946603a62bf0679\"&gt;Dashboard Preview&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This project was developed to:&lt;/p&gt;\n\n&lt;p&gt;- Employ various elements of the modern data stack&lt;/p&gt;\n\n&lt;p&gt;- Be applied to a somewhat realistic business use case&lt;/p&gt;\n\n&lt;p&gt;- Serve as a template for others to learn from and use via extensive documentation&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/c2ha0g6g1vlb1.png?width=672&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=05fc73a8b33ead310b958833a0315939d5f8ef62\"&gt;Project Architecture&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For this project, the Telco Customer Churn data module which is a sample dataset on IBM&amp;#39;s Cognos Analytics platform is used. This seemed like the best representative considering the difficulty in finding a decent dataset for the use case.&lt;/p&gt;\n\n&lt;p&gt;The dataset is then used to train two models. The first is a Gaussian Copula Synthesizer to produce synthetic data with characteristics similar to the original. This is done since there is not much data to go around and serves as a rudimentary imitation of data entering the database, The second is an LGBModel which is a product of using FLAML&amp;#39;s AutoML implementation on the data, and its purpose is to predict churn status for a particular user.&lt;/p&gt;\n\n&lt;p&gt;Both models are hosted via FastAPI and are accessed this way. Airflow is then used to orchestrate the pulling of data from the Synthesizer, obtaining churn status prediction for said data from the classification model, generating a ULID for each user, and writing it all to a Postgres database. Airflow is also used to trigger dbt afterward to run tests and apply necessary transformations. The data is modeled after the star schema and is finally visualized as a dashboard using Metabase.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dju7uz4i1vlb1.png?width=773&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bddfc3fdf1d0aa570dcec5c77dec0ffde61e8dbf\"&gt;Data Model Diagram&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Almost all of the services above run in their own docker containers, as seen in the diagram. These containers are running on a GCP VM, provisioned via Terraform. Finally, GitHub Actions facilitates CD, as changes made to this repo are reflected in the VM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know that the use case is kinda boring, but it helps provide a decent perspective as to the work that usually exists in the industry. I have also elaborated more on the technicalities of this project in the GitHub readme, so check that out if you want a bigger picture of things. As already mentioned, looking to hear from you guys on any improvements that can be made, or details that must be considered.&lt;/p&gt;\n\n&lt;p&gt;Access &lt;a href=\"http://34.134.216.50:3000/public/dashboard/085f43f1-3301-45e2-b4f5-5bd0d789d1f3\"&gt;the dashboard here.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Link to &lt;a href=\"https://github.com/raashidsalih/churn-pipeline\"&gt;the project here.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick question for the experienced folk here:&lt;/strong&gt; &lt;em&gt;What would be the best way to showcase this project on a CV? What aspects should I ensure I convey, and what should I leave out?&lt;/em&gt;&lt;br/&gt;\nGreatly appreciate your insights and your time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Finally, major shoutout to our neighborhood resident Joseph Machado (&lt;a href=\"/u/joseph_machado\"&gt;u/joseph_machado&lt;/a&gt;) from StartDataEngineering for his educational content, and also for spending his valuable time initially with some of my questions.&lt;/p&gt;\n\n&lt;p&gt;Hope you guys have a good day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1685dax", "is_robot_indexable": true, "report_reasons": null, "author": "Impartial_Bystander", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1685dax/first_project_customer_churn_with_synthetic_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1685dax/first_project_customer_churn_with_synthetic_data/", "subreddit_subscribers": 126345, "created_utc": 1693668473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4zpyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instacart\u2019s IPO filing sparked an online spat between cloud rivals Snowflake and Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_1684ni0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/R-OKQTYg7UIw3jRl5AETkKlWwQRgDg5FelyoKq6oUbo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693666730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cnbc.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cnbc.com/2023/09/02/instacart-ipo-filing-fans-controversy-between-snowflake-databricks-.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wibQk1mzT4ROsNhgG0VWv23eYkbQEkl7k2EjtgF3HGo.jpg?auto=webp&amp;s=2edd3ab5c648359ff5e75fc1d4058e6a76e7d493", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/wibQk1mzT4ROsNhgG0VWv23eYkbQEkl7k2EjtgF3HGo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78988bec79b0473e86206616415d64efd603ce6a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/wibQk1mzT4ROsNhgG0VWv23eYkbQEkl7k2EjtgF3HGo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3ee210035a837fee4d27fa2baad0609adff497d2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/wibQk1mzT4ROsNhgG0VWv23eYkbQEkl7k2EjtgF3HGo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=203e8c2df19534e23659ef31b1e2d8de4cf6e96c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/wibQk1mzT4ROsNhgG0VWv23eYkbQEkl7k2EjtgF3HGo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e68d572126ad74b5a0343093b848f7bee6a7fb47", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/wibQk1mzT4ROsNhgG0VWv23eYkbQEkl7k2EjtgF3HGo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=23d3dc6028f27defbd62c72a5b7f111ef5b7f119", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/wibQk1mzT4ROsNhgG0VWv23eYkbQEkl7k2EjtgF3HGo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9bc4ac0ff6b3d37de75c38cd5722518aa4e9f0b7", "width": 1080, "height": 607}], "variants": {}, "id": "GphFmCX3coviZ87qoTnWre3rf9hKvnDxObk-49Y3g3E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1684ni0", "is_robot_indexable": true, "report_reasons": null, "author": "beyphy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1684ni0/instacarts_ipo_filing_sparked_an_online_spat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cnbc.com/2023/09/02/instacart-ipo-filing-fans-controversy-between-snowflake-databricks-.html", "subreddit_subscribers": 126345, "created_utc": 1693666730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a way to figure out who created a table or view in Athena? Can I use metadata to do so?", "author_fullname": "t2_fwqwbjia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Athena Table Ownership", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167vqbh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693638602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to figure out who created a table or view in Athena? Can I use metadata to do so?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167vqbh", "is_robot_indexable": true, "report_reasons": null, "author": "space-trader-92", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167vqbh/athena_table_ownership/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167vqbh/athena_table_ownership/", "subreddit_subscribers": 126345, "created_utc": 1693638602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've never used dbt core at an organization. I've only used the closed-source versions (dbt cloud, paradime)  \n\n\nIf you've used dbt core at your organization (ex. Used dbt core w/ VS code + Airflow) what are the pros and cons?  \n\n\nOnce dbt core is set up properly in an organization, do you spend a lot of time updating and fixing the setup? Or does it run smoothly for the most part?", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pros &amp; cons of running dbt core at scale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167czoc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693588341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve never used dbt core at an organization. I&amp;#39;ve only used the closed-source versions (dbt cloud, paradime)  &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve used dbt core at your organization (ex. Used dbt core w/ VS code + Airflow) what are the pros and cons?  &lt;/p&gt;\n\n&lt;p&gt;Once dbt core is set up properly in an organization, do you spend a lot of time updating and fixing the setup? Or does it run smoothly for the most part?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167czoc", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167czoc/pros_cons_of_running_dbt_core_at_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167czoc/pros_cons_of_running_dbt_core_at_scale/", "subreddit_subscribers": 126345, "created_utc": 1693588341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello everyone,\n\nI hope you're all doing well. Currently, I am working as a Data Analyst with three years of experience. I am considering transitioning to a Data Engineer role. However, before making that move, I want to strengthen my Python scripting skills. While I have a basic understanding of Python and have worked with it on a few occasions, including making changes to production code, I lack confidence in my Python skills. I would appreciate any advice on how to improve my Python scripting abilities. Please feel free to share your insights and recommendations.   \nThank you.", "author_fullname": "t2_860dhvbl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to improve my python scripting.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1684fpy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693666190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well. Currently, I am working as a Data Analyst with three years of experience. I am considering transitioning to a Data Engineer role. However, before making that move, I want to strengthen my Python scripting skills. While I have a basic understanding of Python and have worked with it on a few occasions, including making changes to production code, I lack confidence in my Python skills. I would appreciate any advice on how to improve my Python scripting abilities. Please feel free to share your insights and recommendations.&lt;br/&gt;\nThank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1684fpy", "is_robot_indexable": true, "report_reasons": null, "author": "SaltCommand58", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1684fpy/how_to_improve_my_python_scripting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1684fpy/how_to_improve_my_python_scripting/", "subreddit_subscribers": 126345, "created_utc": 1693666190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Reddit. At work I'm dealing with a reoccurring pattern of how I need to process data but I just cannot find a way how to do it in an elegant way using PySpark:\n\n* Read data from multiple sources into individual data frames\n* Group all data frames by a common column (let's say a product id)\n* Feed each group (product) into a function, e.g. as multiple Pandas dfs. Only here the data from the different sources is supposed to be combined using arbitrary Python code.\n* Combine the return values back to a Spark data frame (or an rdd)\n\nThe closest I could find is [cogroup().applyInPandas](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.PandasCogroupedOps.applyInPandas.html) but this only works for two data frames, I need the general case. So far my only solution is to convert everything to rdds and use the rdd.cogroup(), but this (the rdd conversion already) seems to be extremely inefficient and slow.\n\nAm I missing a better way? Is this kind of workflow so unusual? Thanks", "author_fullname": "t2_kguv0t9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark: groupby multiple data frames, feed each group to a function", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168404z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693665094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Reddit. At work I&amp;#39;m dealing with a reoccurring pattern of how I need to process data but I just cannot find a way how to do it in an elegant way using PySpark:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Read data from multiple sources into individual data frames&lt;/li&gt;\n&lt;li&gt;Group all data frames by a common column (let&amp;#39;s say a product id)&lt;/li&gt;\n&lt;li&gt;Feed each group (product) into a function, e.g. as multiple Pandas dfs. Only here the data from the different sources is supposed to be combined using arbitrary Python code.&lt;/li&gt;\n&lt;li&gt;Combine the return values back to a Spark data frame (or an rdd)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The closest I could find is &lt;a href=\"https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.PandasCogroupedOps.applyInPandas.html\"&gt;cogroup().applyInPandas&lt;/a&gt; but this only works for two data frames, I need the general case. So far my only solution is to convert everything to rdds and use the rdd.cogroup(), but this (the rdd conversion already) seems to be extremely inefficient and slow.&lt;/p&gt;\n\n&lt;p&gt;Am I missing a better way? Is this kind of workflow so unusual? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "168404z", "is_robot_indexable": true, "report_reasons": null, "author": "JPyoris", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/168404z/pyspark_groupby_multiple_data_frames_feed_each/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/168404z/pyspark_groupby_multiple_data_frames_feed_each/", "subreddit_subscribers": 126345, "created_utc": 1693665094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I was scouring this sub reddit to try and find  the best laptop for data engineering a few months ago. I use a point and click ETL program in my day to day, and wanted to learn how to build data pipelines by writing code. The top rated one I could find was the Macbook, so i brought the Mac air M2. I come from a windows only background and was excited to learn a new system.\n\n&amp;#x200B;\n\nI've had the mac for three months and am struggling to get through basic SQL tutorials using python in that time. It seems like every library I have try to use isn't compatible with the Mac chips (Throws a random error). sqlalchemy/pyodbc just straight up won't work, and I can't find any other way to connect python to SQL. This thing has been an all around nightmare. I tried to stand up a local version of SSMS which I managed through docker, but when I tried to use a .bak file to load data into it, it doesn't have access to see my hardrive so that's another dead end.\n\nI feel like every time I try to start a new tutorial, or do a basic function that i'd have no issue with on windows- I have to do some ridiculous workaround to get it running on Mac, and then apply fix after fix after fix as the ever-present error show themselves.\n\n&amp;#x200B;\n\nI guess my question is, does anyone have any Mac specific, data engineering tutorials? I'm at a bit of a loss with this thing and it's starting to gather dust. If anyone can recommend material to set this thing up too. It's entirely I botched the setup when installing the interpreters.\n\n&amp;#x200B;\n\nTIA\n\n\\-Definitely not a windows employee\n\n\\-Also definitely not someone that spent 30 minutes trying to find the /usr/local folder\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_140q1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the Mac worthless, or is it me? (Rant)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167lv2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.48, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693609037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I was scouring this sub reddit to try and find  the best laptop for data engineering a few months ago. I use a point and click ETL program in my day to day, and wanted to learn how to build data pipelines by writing code. The top rated one I could find was the Macbook, so i brought the Mac air M2. I come from a windows only background and was excited to learn a new system.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had the mac for three months and am struggling to get through basic SQL tutorials using python in that time. It seems like every library I have try to use isn&amp;#39;t compatible with the Mac chips (Throws a random error). sqlalchemy/pyodbc just straight up won&amp;#39;t work, and I can&amp;#39;t find any other way to connect python to SQL. This thing has been an all around nightmare. I tried to stand up a local version of SSMS which I managed through docker, but when I tried to use a .bak file to load data into it, it doesn&amp;#39;t have access to see my hardrive so that&amp;#39;s another dead end.&lt;/p&gt;\n\n&lt;p&gt;I feel like every time I try to start a new tutorial, or do a basic function that i&amp;#39;d have no issue with on windows- I have to do some ridiculous workaround to get it running on Mac, and then apply fix after fix after fix as the ever-present error show themselves.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I guess my question is, does anyone have any Mac specific, data engineering tutorials? I&amp;#39;m at a bit of a loss with this thing and it&amp;#39;s starting to gather dust. If anyone can recommend material to set this thing up too. It&amp;#39;s entirely I botched the setup when installing the interpreters.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n\n&lt;p&gt;-Definitely not a windows employee&lt;/p&gt;\n\n&lt;p&gt;-Also definitely not someone that spent 30 minutes trying to find the /usr/local folder&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "167lv2m", "is_robot_indexable": true, "report_reasons": null, "author": "kiwikid47", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167lv2m/is_the_mac_worthless_or_is_it_me_rant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/167lv2m/is_the_mac_worthless_or_is_it_me_rant/", "subreddit_subscribers": 126345, "created_utc": 1693609037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time analytics with stream processing and OLAP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_167c86t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693586611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.ycombinator.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://news.ycombinator.com/item?id=37353112", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "167c86t", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/167c86t/realtime_analytics_with_stream_processing_and_olap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.ycombinator.com/item?id=37353112", "subreddit_subscribers": 126345, "created_utc": 1693586611.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}