{"kind": "Listing", "data": {"after": "t3_16ra2yz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'll be having a job interview in a few days and I think this question might come up and I personally don't know how to explain it to a layperson. Black box methods may come in handy one day, but I realized just now that I can't briefly explain how it works without making it sound like magic. What's your workaround for this? Have you been in a situation where you presented your results and you had to explain how neural networks operate in detail? Any similar experiences?", "author_fullname": "t2_bmbqthh3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For people in the industry, how do you explain the poor interpretability of some ML techniques to bosses who are not data scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qtywk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695549905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll be having a job interview in a few days and I think this question might come up and I personally don&amp;#39;t know how to explain it to a layperson. Black box methods may come in handy one day, but I realized just now that I can&amp;#39;t briefly explain how it works without making it sound like magic. What&amp;#39;s your workaround for this? Have you been in a situation where you presented your results and you had to explain how neural networks operate in detail? Any similar experiences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qtywk", "is_robot_indexable": true, "report_reasons": null, "author": "krabbypatty-o-fish", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qtywk/for_people_in_the_industry_how_do_you_explain_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qtywk/for_people_in_the_industry_how_do_you_explain_the/", "subreddit_subscribers": 1059932, "created_utc": 1695549905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working in a data science Consulting startup as a data scientist. All I've done is write sql tables. I've started job hunting. I want to build AI products. What job description would that be? I know this sounds stupid but I don't want to be an analyst anymore", "author_fullname": "t2_5gr8xljt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do data scientists do anyway?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16r5v0j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695582446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working in a data science Consulting startup as a data scientist. All I&amp;#39;ve done is write sql tables. I&amp;#39;ve started job hunting. I want to build AI products. What job description would that be? I know this sounds stupid but I don&amp;#39;t want to be an analyst anymore&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16r5v0j", "is_robot_indexable": true, "report_reasons": null, "author": "wonko_the_sane__", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16r5v0j/what_do_data_scientists_do_anyway/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16r5v0j/what_do_data_scientists_do_anyway/", "subreddit_subscribers": 1059932, "created_utc": 1695582446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Often you hear people saying that understanding the inner workings of models and algorithms is irrelevant and a waste of time. I am currently a MS student and struggle to understand some of the inner workings of things such as M-estimation for robust regression and I believe it\u2019s due to my poor statical background (CS undergrad). \n\nShould I put the time into going back and getting proper statistical credentials (I want to frankly) or is it a nice to have that isnt worth the time and money?", "author_fullname": "t2_pdclzxln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Poor statistical/Linear Algebra foundation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16r1881", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695571158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Often you hear people saying that understanding the inner workings of models and algorithms is irrelevant and a waste of time. I am currently a MS student and struggle to understand some of the inner workings of things such as M-estimation for robust regression and I believe it\u2019s due to my poor statical background (CS undergrad). &lt;/p&gt;\n\n&lt;p&gt;Should I put the time into going back and getting proper statistical credentials (I want to frankly) or is it a nice to have that isnt worth the time and money?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16r1881", "is_robot_indexable": true, "report_reasons": null, "author": "LongjumpingWheel11", "discussion_type": null, "num_comments": 28, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16r1881/poor_statisticallinear_algebra_foundation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16r1881/poor_statisticallinear_algebra_foundation/", "subreddit_subscribers": 1059932, "created_utc": 1695571158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I've been assigned an AI/ML project, and I've identified that the data quality is not good. It's within a large organization, which makes it challenging to find a straightforward solution to the data quality problem. Personally, I'm feeling uncomfortable about proceeding further. Interestingly, my manager and other colleagues don't seem to share the same level of concern as I do. They are more inclined to continue the project and generate \"output\". Their primary worried about what to delivery to CIO. Given this situation, what would I do in my place?", "author_fullname": "t2_5fbmh3va", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you do when data quality is bad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ra88t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695592973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been assigned an AI/ML project, and I&amp;#39;ve identified that the data quality is not good. It&amp;#39;s within a large organization, which makes it challenging to find a straightforward solution to the data quality problem. Personally, I&amp;#39;m feeling uncomfortable about proceeding further. Interestingly, my manager and other colleagues don&amp;#39;t seem to share the same level of concern as I do. They are more inclined to continue the project and generate &amp;quot;output&amp;quot;. Their primary worried about what to delivery to CIO. Given this situation, what would I do in my place?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16ra88t", "is_robot_indexable": true, "report_reasons": null, "author": "Excellent_Cost170", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16ra88t/what_do_you_do_when_data_quality_is_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16ra88t/what_do_you_do_when_data_quality_is_bad/", "subreddit_subscribers": 1059932, "created_utc": 1695592973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I browse through post often and general have limited understanding of what is being discussed. I can understand the very basics but the more indepth the convo goes the less I'm able to follow.\n\nI currently work as a BI developer, use SQL quite a bit and PowerBI, power automate.\n\nMy goal is to eventually dive into Data Science. At this time I would say I am no where close to being ready. I am enrolled amd planning to start Georgia Tech OMSA this upcoming spring. My question is.. did academics prepare you adequately to where you're able converse and function well as a DS?\n\nTIA!", "author_fullname": "t2_m8a5u0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did academics prepare you for your role, or for the DS/ML/AI field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qxfo0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695561104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I browse through post often and general have limited understanding of what is being discussed. I can understand the very basics but the more indepth the convo goes the less I&amp;#39;m able to follow.&lt;/p&gt;\n\n&lt;p&gt;I currently work as a BI developer, use SQL quite a bit and PowerBI, power automate.&lt;/p&gt;\n\n&lt;p&gt;My goal is to eventually dive into Data Science. At this time I would say I am no where close to being ready. I am enrolled amd planning to start Georgia Tech OMSA this upcoming spring. My question is.. did academics prepare you adequately to where you&amp;#39;re able converse and function well as a DS?&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qxfo0", "is_robot_indexable": true, "report_reasons": null, "author": "AwkWORD47", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qxfo0/did_academics_prepare_you_for_your_role_or_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qxfo0/did_academics_prepare_you_for_your_role_or_for/", "subreddit_subscribers": 1059932, "created_utc": 1695561104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I find it to be a very useful tool.  However, only my current employer is using it.  If I change jobs, I won't have access to Alteryx anymore and my skill with deteriorate with non-use.     \nIt is unlike Excel where I'm sharpening my skills with it every place I work.  Any software is worth learning for your career, but we humans tend to forget knowledge what don't use.  Or I do at least, maybe it is just me.  Your thoughts?  \n", "author_fullname": "t2_duzivvbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Alteryx a practical skill to learn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16r9lfj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695591476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I find it to be a very useful tool.  However, only my current employer is using it.  If I change jobs, I won&amp;#39;t have access to Alteryx anymore and my skill with deteriorate with non-use.&lt;br/&gt;\nIt is unlike Excel where I&amp;#39;m sharpening my skills with it every place I work.  Any software is worth learning for your career, but we humans tend to forget knowledge what don&amp;#39;t use.  Or I do at least, maybe it is just me.  Your thoughts?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16r9lfj", "is_robot_indexable": true, "report_reasons": null, "author": "How_Much2", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16r9lfj/is_alteryx_a_practical_skill_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16r9lfj/is_alteryx_a_practical_skill_to_learn/", "subreddit_subscribers": 1059932, "created_utc": 1695591476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Enhancing your data analysis performance with Python's Numexpr and Pandas' eval/query functions \n\n This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/) \n\n&amp;#x200B;\n\n[ Use Numexpr to help me find the most livable city. Photo Credit: Created by Author, Canva ](https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=238da4465da17bd301b49112d574444b16d4113c)\n\n This article will introduce you to the Python library [Numexpr](https://numexpr.readthedocs.io/en/latest/intro.html?ref=dataleadsfuture.com#), a tool that boosts the computational performance of Numpy Arrays. The eval and query methods of Pandas are also based on this library.\n\n This article also includes a hands-on weather data analysis project. \n\n By reading this article, you will understand the principles of Numexpr and how to use this powerful tool to speed up your calculations in reality. \n\n# Introduction \n\n# Recalling Numpy Arrays\n\n In a previous article discussing Numpy Arrays, I used a library example to explain why Numpy's Cache Locality is so efficient: \n\n[https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/](https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/)\n\n Each time you go to the library to search for materials, you take out a few books related to the content and place them next to your desk. \n\n This way, you can quickly check related materials without having to run to the shelf each time you need to read a book. \n\n This method saves a lot of time, especially when you need to consult many related books. \n\n In this scenario, the shelf is like your memory, the desk is equivalent to the CPU's L1 cache, and you, the reader, are the CPU's core. \n\n&amp;#x200B;\n\n[ When the CPU accesses RAM, the cache loads the entire cache line into the high-speed cache. Image by Author ](https://preview.redd.it/3k7gdxywr5qb1.png?width=625&amp;format=png&amp;auto=webp&amp;s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049)\n\n### The limitations of Numpy\n\n Suppose you are unfortunate enough to encounter a demanding professor who wants you to take out Shakespeare and Tolstoy's works for a cross-comparison. \n\n At this point, taking out related books in advance will not work well. \n\n First, your desk space is limited and cannot hold all the books of these two masters at the same time, not to mention the reading notes that will be generated during the comparison process. \n\n Second, you're just one person, and comparing so many works would take too long. It would be nice if you could find a few more people to help. \n\n This is the current situation when we use Numpy to deal with large amounts of data: \n\n* The number of elements in the Array is too large to fit into the CPU's L1 cache.\n* Numpy's element-level operations are single-threaded and cannot utilize the computing power of multi-core CPUs.\n\n What should we do? \n\n Don't worry. When you really encounter a problem with too much data, you can call on our protagonist today, Numexpr, to help. \n\n## Understanding Numexpr: What and Why\n\n### How it works\n\n When Numpy encounters large arrays, element-wise calculations will experience two extremes. \n\n Let me give you an example to illustrate. Suppose there are two large Numpy ndarrays: \n\n    import numpy as np \n    import numexpr as ne  \n    \n    a = np.random.rand(100_000_000) \n    b = np.random.rand(100_000_000)\n\n When calculating the result of the expression a\\*\\*5 + 2 \\* b, there are generally two methods:\n\n One way is Numpy's vectorized calculation method, which uses two temporary arrays to store the results of a\\*\\*5 and 2\\*b separately.  \n\n    In: %timeit a**5 + 2 * b\n    \n    Out:2.11 s \u00b1 31.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n At this time, you have four arrays in your memory: a, b, a\\*\\*5, and 2 \\* b. This method will cause a lot of memory waste. \n\n Moreover, since each Array's size exceeds the CPU cache's capacity, it cannot use it well. \n\n Another way is to traverse each element in two arrays and calculate them separately. \n\n    c = np.empty(100_000_000, dtype=np.uint32)\n    \n    def calcu_elements(a, b, c):\n        for i in range(0, len(a), 1):\n            c[i] = a[i] ** 5 + 2 * b[i]\n            \n    %timeit calcu_elements(a, b, c)\n    \n    \n    Out: 24.6 s \u00b1 48.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n This method performs even worse. The calculation will be very slow because it cannot use vectorized calculations and only partially utilize the CPU cache. \n\n### Numexpr's calculation\n\n Numexpr commonly uses only one evaluate method. This method will receive an expression string each time and then compile it into bytecode using Python's compile method. \n\n Numexpr also has a virtual machine program. The virtual machine contains multiple vector registers, each using a chunk size of 4096. \n\n When Numexpr starts to calculate, it sends the data in one or more registers to the CPU's L1 cache each time. This way, there won't be a situation where the memory is too slow, and the CPU waits for data. \n\n At the same time, Numexpr's virtual machine is written in C, removing Python's GIL. It can utilize the computing power of multi-core CPUs. \n\n So, Numexpr is faster when calculating large arrays than using Numpy alone. We can make a comparison: \n\n    In:  %timeit ne.evaluate('a**5 + 2 * b')\n    Out: 258 ms \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n### Summary of Numexpr's working principle\n\n Let's summarize the working principle of Numexpr and see why Numexpr is so fast: \n\n **Executing bytecode through a virtual machine.** Numexpr uses bytecode to execute expressions, which can fully utilize the [branch prediction](https://en.wikipedia.org/wiki/Branch_predictor?ref=dataleadsfuture.com) ability of the CPU, which is faster than using Python expressions. \n\n **Vectorized calculation.** Numexpr will use [SIMD (Single Instruction, Multiple Data)](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data?ref=dataleadsfuture.com) technology to improve computing efficiency significantly for the same operation on the data in each register. \n\n **Multi-core parallel computing.** Numexpr's virtual machine can decompose each task into multiple subtasks. They are executed in parallel on multiple CPU cores. \n\n **Less memory usage.** Unlike Numpy, which needs to generate intermediate arrays, Numexpr only loads a small amount of data when necessary, significantly reducing memory usage. \n\n&amp;#x200B;\n\n[ Workflow diagram of Numexpr. Image by Author ](https://preview.redd.it/46plaxk6t5qb1.png?width=863&amp;format=png&amp;auto=webp&amp;s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3)\n\n## Numexpr and Pandas: A Powerful Combination\n\n You might be wondering: We usually do data analysis with pandas. I understand the performance improvements Numexpr offers for Numpy, but does it have the same improvement for Pandas? \n\n The answer is Yes. \n\n The eval and query methods in pandas are implemented based on Numexpr. Let's look at some examples: \n\n### Pandas.eval for Cross-DataFrame operations\n\n When you have multiple pandas DataFrames, you can use pandas.eval to perform operations between DataFrame objects, for example: \n\n    import pandas as pd\n    \n    nrows, ncols = 1_000_000, 100\n    df1, df2, df3, df4 = (pd.DataFrame(rng.random((nrows, ncols))) for i in range(4))\n\n If you calculate the sum of these DataFrames using the traditional pandas method, the time consumed is: \n\n    In:  %timeit df1+df2+df3+df4\n    Out: 1.18 s \u00b1 65.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n You can also use pandas.eval for calculation. The time consumed is: \n\n The calculation of the eval version can improve performance by 50%, and the results are precisely the same: \n\n    In:  np.allclose(df1+df2+df3+df4, pd.eval('df1+df2+df3+df4'))\n    Out: True\n\n### DataFrame.eval for column-level operations\n\n Just like pandas.eval, DataFrame also has its own eval method. We can use this method for column-level operations within DataFrame, for example: \n\n    df = pd.DataFrame(rng.random((1000, 3)), columns=['A', 'B', 'C'])\n    \n    result1 = (df['A'] + df['B']) / (df['C'] - 1)\n    result2 = df.eval('(A + B) / (C - 1)')\n\n The results of using the traditional pandas method and the eval method are precisely the same: \n\n    In:  np.allclose(result1, result2)\n    Out: True\n\n Of course, you can also directly use the eval expression to add new columns to the DataFrame, which is very convenient: \n\n    df.eval('D = (A + B) / C', inplace=True)\n    df.head()\n\n[ Directly use the eval expression to add new columns. Image by Author ](https://preview.redd.it/ykotgj0ut5qb1.png?width=495&amp;format=png&amp;auto=webp&amp;s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751)\n\n### Using DataFrame.query to quickly find data\n\n If the eval method of DataFrame executes comparison expressions, the returned result is a boolean result that meets the conditions. You need to use Mask Indexing to get the desired data: \n\n    mask = df.eval('(A &lt; 0.5) &amp; (B &lt; 0.5)')\n    result1 = df[mask]\n    result\n\n[ When filtering data only with DataFrame.query, it is necessary to use a boolean mask. Image by Author ](https://preview.redd.it/izwngwizt5qb1.png?width=469&amp;format=png&amp;auto=webp&amp;s=c7f0e4806977ccdcf3c588a67a6c913255f47091)\n\n The DataFrame.query method encapsulates this process, and you can directly obtain the desired data with the query method: \n\n    In:   result2 = df.query('A &lt; 0.5 and B &lt; 0.5')\n          np.allclose(result1, result2)\n    Out:  True\n\n When you need to use scalars in expressions, you can use the @  to indicate: \n\n    In:  Cmean = df['C'].mean()\n         result1 = df[(df.A &lt; Cmean) &amp; (df.B &lt; Cmean)]\n         result2 = df.query('A &lt; @Cmean and B &lt; @Cmean')\n         np.allclose(result1, result2)\n    Out: True\n\n This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/) ", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Numexpr: A Powerful Engine Behind Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ykotgj0ut5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=45b2ace70cdc23065c16c4c7ecb49451067d5824"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ae1f3d972bbe64cc07341d2a7e32e66da793a7f"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=04db3f2e444bdb6b7cb6c9558407dc42561b74f2"}], "s": {"y": 179, "x": 495, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=495&amp;format=png&amp;auto=webp&amp;s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751"}, "id": "ykotgj0ut5qb1"}, "izwngwizt5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2dadbb151f50fa5dbfbf14272d1860c079d94f89"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=184931d673c0227709ad80639f3cd20da70977d4"}, {"y": 197, "x": 320, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ce4336dee4ce5c9bbedc261e3a277e72d6fa47e"}], "s": {"y": 289, "x": 469, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=469&amp;format=png&amp;auto=webp&amp;s=c7f0e4806977ccdcf3c588a67a6c913255f47091"}, "id": "izwngwizt5qb1"}, "3k7gdxywr5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 45, "x": 108, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a502f085a43ef5ac8f1f50599161b6d8ccfe1dc5"}, {"y": 91, "x": 216, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fedccce3dc9866fbb52b62237eb1d362917e2eb3"}, {"y": 135, "x": 320, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=77080ec0cc0d4b7202892c1035780ef145694726"}], "s": {"y": 264, "x": 625, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=625&amp;format=png&amp;auto=webp&amp;s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049"}, "id": "3k7gdxywr5qb1"}, "46plaxk6t5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d31e4cb8f3f2da53d3c291af37ecc489c082e5d"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b292a546e21eea92bccc123befff21806f751ad"}, {"y": 226, "x": 320, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e63cb3e19ed9c368e8e297b1842854b459247ac6"}, {"y": 453, "x": 640, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=059bc7da3ab967ae8670b846e24da717ccfa6bb0"}], "s": {"y": 611, "x": 863, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=863&amp;format=png&amp;auto=webp&amp;s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3"}, "id": "46plaxk6t5qb1"}, "29ec8ukgr5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=827a05e29b961a5494a0a7bef09e05406e2e2d0e"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7eda37aee46f7ac0e032a1d6986c84364e634243"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c421de1631ab305d9297cb110c5bc7e6f8fa84ee"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=56aac32c3c80921dcb8d1294b3284c961c3fc4f4"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4bf6231e0d1b715918aa8904b0dc7a8bdae05633"}, {"y": 719, "x": 1080, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a94c2abbd9a3ade8f23648b82905877f75b5bede"}], "s": {"y": 799, "x": 1200, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=238da4465da17bd301b49112d574444b16d4113c"}, "id": "29ec8ukgr5qb1"}}, "name": "t3_16qrxs4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ARL0vsBWFf7vstunNTahhEgCBgMGr53RAUJlwDu0dAc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1695542470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Enhancing your data analysis performance with Python&amp;#39;s Numexpr and Pandas&amp;#39; eval/query functions &lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/\"&gt;Data Leads Future.&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=238da4465da17bd301b49112d574444b16d4113c\"&gt; Use Numexpr to help me find the most livable city. Photo Credit: Created by Author, Canva &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This article will introduce you to the Python library &lt;a href=\"https://numexpr.readthedocs.io/en/latest/intro.html?ref=dataleadsfuture.com#\"&gt;Numexpr&lt;/a&gt;, a tool that boosts the computational performance of Numpy Arrays. The eval and query methods of Pandas are also based on this library.&lt;/p&gt;\n\n&lt;p&gt;This article also includes a hands-on weather data analysis project. &lt;/p&gt;\n\n&lt;p&gt;By reading this article, you will understand the principles of Numexpr and how to use this powerful tool to speed up your calculations in reality. &lt;/p&gt;\n\n&lt;h1&gt;Introduction&lt;/h1&gt;\n\n&lt;h1&gt;Recalling Numpy Arrays&lt;/h1&gt;\n\n&lt;p&gt;In a previous article discussing Numpy Arrays, I used a library example to explain why Numpy&amp;#39;s Cache Locality is so efficient: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/\"&gt;https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Each time you go to the library to search for materials, you take out a few books related to the content and place them next to your desk. &lt;/p&gt;\n\n&lt;p&gt;This way, you can quickly check related materials without having to run to the shelf each time you need to read a book. &lt;/p&gt;\n\n&lt;p&gt;This method saves a lot of time, especially when you need to consult many related books. &lt;/p&gt;\n\n&lt;p&gt;In this scenario, the shelf is like your memory, the desk is equivalent to the CPU&amp;#39;s L1 cache, and you, the reader, are the CPU&amp;#39;s core. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3k7gdxywr5qb1.png?width=625&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049\"&gt; When the CPU accesses RAM, the cache loads the entire cache line into the high-speed cache. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h3&gt;The limitations of Numpy&lt;/h3&gt;\n\n&lt;p&gt;Suppose you are unfortunate enough to encounter a demanding professor who wants you to take out Shakespeare and Tolstoy&amp;#39;s works for a cross-comparison. &lt;/p&gt;\n\n&lt;p&gt;At this point, taking out related books in advance will not work well. &lt;/p&gt;\n\n&lt;p&gt;First, your desk space is limited and cannot hold all the books of these two masters at the same time, not to mention the reading notes that will be generated during the comparison process. &lt;/p&gt;\n\n&lt;p&gt;Second, you&amp;#39;re just one person, and comparing so many works would take too long. It would be nice if you could find a few more people to help. &lt;/p&gt;\n\n&lt;p&gt;This is the current situation when we use Numpy to deal with large amounts of data: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The number of elements in the Array is too large to fit into the CPU&amp;#39;s L1 cache.&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Numpy&amp;#39;s element-level operations are single-threaded and cannot utilize the computing power of multi-core CPUs.&lt;/p&gt;\n\n&lt;p&gt;What should we do? &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t worry. When you really encounter a problem with too much data, you can call on our protagonist today, Numexpr, to help. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Understanding Numexpr: What and Why&lt;/h2&gt;\n\n&lt;h3&gt;How it works&lt;/h3&gt;\n\n&lt;p&gt;When Numpy encounters large arrays, element-wise calculations will experience two extremes. &lt;/p&gt;\n\n&lt;p&gt;Let me give you an example to illustrate. Suppose there are two large Numpy ndarrays: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import numpy as np \nimport numexpr as ne  \n\na = np.random.rand(100_000_000) \nb = np.random.rand(100_000_000)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When calculating the result of the expression a**5 + 2 * b, there are generally two methods:&lt;/p&gt;\n\n&lt;p&gt;One way is Numpy&amp;#39;s vectorized calculation method, which uses two temporary arrays to store the results of a**5 and 2*b separately.  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In: %timeit a**5 + 2 * b\n\nOut:2.11 s \u00b1 31.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;At this time, you have four arrays in your memory: a, b, a**5, and 2 * b. This method will cause a lot of memory waste. &lt;/p&gt;\n\n&lt;p&gt;Moreover, since each Array&amp;#39;s size exceeds the CPU cache&amp;#39;s capacity, it cannot use it well. &lt;/p&gt;\n\n&lt;p&gt;Another way is to traverse each element in two arrays and calculate them separately. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;c = np.empty(100_000_000, dtype=np.uint32)\n\ndef calcu_elements(a, b, c):\n    for i in range(0, len(a), 1):\n        c[i] = a[i] ** 5 + 2 * b[i]\n\n%timeit calcu_elements(a, b, c)\n\n\nOut: 24.6 s \u00b1 48.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This method performs even worse. The calculation will be very slow because it cannot use vectorized calculations and only partially utilize the CPU cache. &lt;/p&gt;\n\n&lt;h3&gt;Numexpr&amp;#39;s calculation&lt;/h3&gt;\n\n&lt;p&gt;Numexpr commonly uses only one evaluate method. This method will receive an expression string each time and then compile it into bytecode using Python&amp;#39;s compile method. &lt;/p&gt;\n\n&lt;p&gt;Numexpr also has a virtual machine program. The virtual machine contains multiple vector registers, each using a chunk size of 4096. &lt;/p&gt;\n\n&lt;p&gt;When Numexpr starts to calculate, it sends the data in one or more registers to the CPU&amp;#39;s L1 cache each time. This way, there won&amp;#39;t be a situation where the memory is too slow, and the CPU waits for data. &lt;/p&gt;\n\n&lt;p&gt;At the same time, Numexpr&amp;#39;s virtual machine is written in C, removing Python&amp;#39;s GIL. It can utilize the computing power of multi-core CPUs. &lt;/p&gt;\n\n&lt;p&gt;So, Numexpr is faster when calculating large arrays than using Numpy alone. We can make a comparison: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  %timeit ne.evaluate(&amp;#39;a**5 + 2 * b&amp;#39;)\nOut: 258 ms \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h3&gt;Summary of Numexpr&amp;#39;s working principle&lt;/h3&gt;\n\n&lt;p&gt;Let&amp;#39;s summarize the working principle of Numexpr and see why Numexpr is so fast: &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Executing bytecode through a virtual machine.&lt;/strong&gt; Numexpr uses bytecode to execute expressions, which can fully utilize the &lt;a href=\"https://en.wikipedia.org/wiki/Branch_predictor?ref=dataleadsfuture.com\"&gt;branch prediction&lt;/a&gt; ability of the CPU, which is faster than using Python expressions. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Vectorized calculation.&lt;/strong&gt; Numexpr will use &lt;a href=\"https://en.wikipedia.org/wiki/Single_instruction,_multiple_data?ref=dataleadsfuture.com\"&gt;SIMD (Single Instruction, Multiple Data)&lt;/a&gt; technology to improve computing efficiency significantly for the same operation on the data in each register. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Multi-core parallel computing.&lt;/strong&gt; Numexpr&amp;#39;s virtual machine can decompose each task into multiple subtasks. They are executed in parallel on multiple CPU cores. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Less memory usage.&lt;/strong&gt; Unlike Numpy, which needs to generate intermediate arrays, Numexpr only loads a small amount of data when necessary, significantly reducing memory usage. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/46plaxk6t5qb1.png?width=863&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3\"&gt; Workflow diagram of Numexpr. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Numexpr and Pandas: A Powerful Combination&lt;/h2&gt;\n\n&lt;p&gt;You might be wondering: We usually do data analysis with pandas. I understand the performance improvements Numexpr offers for Numpy, but does it have the same improvement for Pandas? &lt;/p&gt;\n\n&lt;p&gt;The answer is Yes. &lt;/p&gt;\n\n&lt;p&gt;The eval and query methods in pandas are implemented based on Numexpr. Let&amp;#39;s look at some examples: &lt;/p&gt;\n\n&lt;h3&gt;Pandas.eval for Cross-DataFrame operations&lt;/h3&gt;\n\n&lt;p&gt;When you have multiple pandas DataFrames, you can use pandas.eval to perform operations between DataFrame objects, for example: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd\n\nnrows, ncols = 1_000_000, 100\ndf1, df2, df3, df4 = (pd.DataFrame(rng.random((nrows, ncols))) for i in range(4))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;If you calculate the sum of these DataFrames using the traditional pandas method, the time consumed is: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  %timeit df1+df2+df3+df4\nOut: 1.18 s \u00b1 65.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;You can also use pandas.eval for calculation. The time consumed is: &lt;/p&gt;\n\n&lt;p&gt;The calculation of the eval version can improve performance by 50%, and the results are precisely the same: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  np.allclose(df1+df2+df3+df4, pd.eval(&amp;#39;df1+df2+df3+df4&amp;#39;))\nOut: True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h3&gt;DataFrame.eval for column-level operations&lt;/h3&gt;\n\n&lt;p&gt;Just like pandas.eval, DataFrame also has its own eval method. We can use this method for column-level operations within DataFrame, for example: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df = pd.DataFrame(rng.random((1000, 3)), columns=[&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;])\n\nresult1 = (df[&amp;#39;A&amp;#39;] + df[&amp;#39;B&amp;#39;]) / (df[&amp;#39;C&amp;#39;] - 1)\nresult2 = df.eval(&amp;#39;(A + B) / (C - 1)&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The results of using the traditional pandas method and the eval method are precisely the same: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  np.allclose(result1, result2)\nOut: True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Of course, you can also directly use the eval expression to add new columns to the DataFrame, which is very convenient: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df.eval(&amp;#39;D = (A + B) / C&amp;#39;, inplace=True)\ndf.head()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ykotgj0ut5qb1.png?width=495&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751\"&gt; Directly use the eval expression to add new columns. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h3&gt;Using DataFrame.query to quickly find data&lt;/h3&gt;\n\n&lt;p&gt;If the eval method of DataFrame executes comparison expressions, the returned result is a boolean result that meets the conditions. You need to use Mask Indexing to get the desired data: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;mask = df.eval(&amp;#39;(A &amp;lt; 0.5) &amp;amp; (B &amp;lt; 0.5)&amp;#39;)\nresult1 = df[mask]\nresult\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/izwngwizt5qb1.png?width=469&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7f0e4806977ccdcf3c588a67a6c913255f47091\"&gt; When filtering data only with DataFrame.query, it is necessary to use a boolean mask. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The DataFrame.query method encapsulates this process, and you can directly obtain the desired data with the query method: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:   result2 = df.query(&amp;#39;A &amp;lt; 0.5 and B &amp;lt; 0.5&amp;#39;)\n      np.allclose(result1, result2)\nOut:  True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When you need to use scalars in expressions, you can use the @  to indicate: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  Cmean = df[&amp;#39;C&amp;#39;].mean()\n     result1 = df[(df.A &amp;lt; Cmean) &amp;amp; (df.B &amp;lt; Cmean)]\n     result2 = df.query(&amp;#39;A &amp;lt; @Cmean and B &amp;lt; @Cmean&amp;#39;)\n     np.allclose(result1, result2)\nOut: True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/\"&gt;Data Leads Future.&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?auto=webp&amp;s=4f4c5a16af6b6d5e954c2bd0d6ec11d253a3f16f", "width": 1387, "height": 924}, "resolutions": [{"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3216385c481210e323283ae6e03a16e14245f2a1", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a6a3bbf3191c78cddfbd87af49e76d6667ca85fd", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=202ec313e2baa2ef1670e9cfd24d6c2560d1cd21", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff3e49cdb7d8d0746f47c590240ce1fc893bc917", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=33dc2fd6c45c6a3cc3cbd721fe9ad6a9f5ab7779", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bf7b49d72586c5ef89b6b8f7dc0d9c7de09de4b8", "width": 1080, "height": 719}], "variants": {}, "id": "Bjw_Y7mZr_m-tfiX4fEkjjZrKlokqny6OjPxyctYkDg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qrxs4", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qrxs4/exploring_numexpr_a_powerful_engine_behind_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qrxs4/exploring_numexpr_a_powerful_engine_behind_pandas/", "subreddit_subscribers": 1059932, "created_utc": 1695542470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 25 Sep, 2023 - 02 Oct, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rhw3q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695614509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rhw3q", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rhw3q/weekly_entering_transitioning_thread_25_sep_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/16rhw3q/weekly_entering_transitioning_thread_25_sep_2023/", "subreddit_subscribers": 1059932, "created_utc": 1695614509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Folks,\n\nFor context:\n\nI've been tasked with planning capacity for our helpdesk team at work.  There is it total 4 agents and they solve \\~50 tickets a month.  The business question I have been tasked with answering is \"At what point do we hire more agents.\n\nI have access to the data from Tableau for both tickets closed and created over a 2 year period, these are however separate data sets so will need to merge them together. \n\nI'm currently now familiar with any forecasting models but from my research might select ARIMA.\n\nAny advice on how to tackle this? currently also using chatgpt for some brainstorming. \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_b3b9wr8r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "capacity forecasting planning advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16r00gq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695568135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Folks,&lt;/p&gt;\n\n&lt;p&gt;For context:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been tasked with planning capacity for our helpdesk team at work.  There is it total 4 agents and they solve ~50 tickets a month.  The business question I have been tasked with answering is &amp;quot;At what point do we hire more agents.&lt;/p&gt;\n\n&lt;p&gt;I have access to the data from Tableau for both tickets closed and created over a 2 year period, these are however separate data sets so will need to merge them together. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently now familiar with any forecasting models but from my research might select ARIMA.&lt;/p&gt;\n\n&lt;p&gt;Any advice on how to tackle this? currently also using chatgpt for some brainstorming. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16r00gq", "is_robot_indexable": true, "report_reasons": null, "author": "oaklandcruser", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16r00gq/capacity_forecasting_planning_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16r00gq/capacity_forecasting_planning_advice/", "subreddit_subscribers": 1059932, "created_utc": 1695568135.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am a **Data Scientist**, I am looking for **open source collaborative projects (not computer vision)** in this domain. I got free time on my had, I just want to be a bit more productive with my free time.\n\nCheers !!", "author_fullname": "t2_uf5otczq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open source Data Science projects.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16rk1lw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695621799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a &lt;strong&gt;Data Scientist&lt;/strong&gt;, I am looking for &lt;strong&gt;open source collaborative projects (not computer vision)&lt;/strong&gt; in this domain. I got free time on my had, I just want to be a bit more productive with my free time.&lt;/p&gt;\n\n&lt;p&gt;Cheers !!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rk1lw", "is_robot_indexable": true, "report_reasons": null, "author": "Mission_Tough_3123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rk1lw/open_source_data_science_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16rk1lw/open_source_data_science_projects/", "subreddit_subscribers": 1059932, "created_utc": 1695621799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, so I'm a senior in university. The job market posts have honestly scared me and I could use some advice from those of you with experience. I have a 2.7 GPA (I was told GPA does not matter much but half the jobs/internships I apply to have been asking me).\n\nI have three python data science projects in my github: A simple linear regression model, a-b hypothesis testing, and k-nearest neighbor model. I have done an article for my school paper as a \"data editor\" where I made graphs. I have done a remote unpaid internship from another country for 5 months where I learned flask and git and eda. I am currently doing an unpaid data science internship as well. I've applied to 50+ internships and only heard back from the one I am doing now, and 50+ jobs and heard from none. I finish my bachelors in 6 months.\n\nHere are some potential things I could do:\n\n1. Network and reach out to some individuals, like my dad's friend who works in Dell, another friend who is a computer scientist, my friends uncle who also works in a tech company. Nobody else really comes to mind.\n2. Start another data science project using R, it would be a Multiple Linear Regression project using properties and prices\n3. Keep applying to jobs and internships, which honestly, I am so tired of doing and hearing nothing back\n4. Just focus on my current unpaid internship and class\n5. Start learning about data analysis, like teaching myself more about SQL than the basics and Power BI and Tableau\n6. Pray and cry\n\nPlease anyone can give me some path? Thanks ", "author_fullname": "t2_k9cm6k85o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some career advice and where to go from here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16rjscj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695620895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, so I&amp;#39;m a senior in university. The job market posts have honestly scared me and I could use some advice from those of you with experience. I have a 2.7 GPA (I was told GPA does not matter much but half the jobs/internships I apply to have been asking me).&lt;/p&gt;\n\n&lt;p&gt;I have three python data science projects in my github: A simple linear regression model, a-b hypothesis testing, and k-nearest neighbor model. I have done an article for my school paper as a &amp;quot;data editor&amp;quot; where I made graphs. I have done a remote unpaid internship from another country for 5 months where I learned flask and git and eda. I am currently doing an unpaid data science internship as well. I&amp;#39;ve applied to 50+ internships and only heard back from the one I am doing now, and 50+ jobs and heard from none. I finish my bachelors in 6 months.&lt;/p&gt;\n\n&lt;p&gt;Here are some potential things I could do:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Network and reach out to some individuals, like my dad&amp;#39;s friend who works in Dell, another friend who is a computer scientist, my friends uncle who also works in a tech company. Nobody else really comes to mind.&lt;/li&gt;\n&lt;li&gt;Start another data science project using R, it would be a Multiple Linear Regression project using properties and prices&lt;/li&gt;\n&lt;li&gt;Keep applying to jobs and internships, which honestly, I am so tired of doing and hearing nothing back&lt;/li&gt;\n&lt;li&gt;Just focus on my current unpaid internship and class&lt;/li&gt;\n&lt;li&gt;Start learning about data analysis, like teaching myself more about SQL than the basics and Power BI and Tableau&lt;/li&gt;\n&lt;li&gt;Pray and cry&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Please anyone can give me some path? Thanks &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rjscj", "is_robot_indexable": true, "report_reasons": null, "author": "Jaded_Masterpiece_12", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rjscj/need_some_career_advice_and_where_to_go_from_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16rjscj/need_some_career_advice_and_where_to_go_from_here/", "subreddit_subscribers": 1059932, "created_utc": 1695620895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Graduate in December with MS and have a career fair opportunity this week. As I attend remotely, campus is 4 hours away. I'd have to do the drive there and back in the same day, so I want to know if there's potential for me to actually get value, or if I'll likely be wasting my time. I understand I'll have to make the best of it, and I'm confident I will, but I really just want to know if success stories in this field happen from networking at career fairs.\n\nI don't have any leads yet, just been blindly applying online. A couple of rejections, but haven't heard back from a majority of applications which are probably ghost. Not much relevant experience in the field, trying to start out as a DA. Thoughts?", "author_fullname": "t2_hmt8h5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are career fairs worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16rjh59", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695619773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Graduate in December with MS and have a career fair opportunity this week. As I attend remotely, campus is 4 hours away. I&amp;#39;d have to do the drive there and back in the same day, so I want to know if there&amp;#39;s potential for me to actually get value, or if I&amp;#39;ll likely be wasting my time. I understand I&amp;#39;ll have to make the best of it, and I&amp;#39;m confident I will, but I really just want to know if success stories in this field happen from networking at career fairs.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have any leads yet, just been blindly applying online. A couple of rejections, but haven&amp;#39;t heard back from a majority of applications which are probably ghost. Not much relevant experience in the field, trying to start out as a DA. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rjh59", "is_robot_indexable": true, "report_reasons": null, "author": "Imaginesafety", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rjh59/are_career_fairs_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16rjh59/are_career_fairs_worth_it/", "subreddit_subscribers": 1059932, "created_utc": 1695619773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For the data scientists/applied scientists/research scientists - What kind of projects are you working on now that the economy has shifted and companies are focusing more on profitability than on growth? \n\nWhat techniques have worked for you and what are you looking into as potential solutions?\n\nAn example would be - optimizing your marketing campaign spend in channels that give you the most bang for your buck vs just spending arbitrarily to acquire new users.", "author_fullname": "t2_jrhff4f29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How has work changed for you given the shift from growth to profitability?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rihec", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695616397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the data scientists/applied scientists/research scientists - What kind of projects are you working on now that the economy has shifted and companies are focusing more on profitability than on growth? &lt;/p&gt;\n\n&lt;p&gt;What techniques have worked for you and what are you looking into as potential solutions?&lt;/p&gt;\n\n&lt;p&gt;An example would be - optimizing your marketing campaign spend in channels that give you the most bang for your buck vs just spending arbitrarily to acquire new users.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rihec", "is_robot_indexable": true, "report_reasons": null, "author": "Terrible-Hamster-342", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rihec/how_has_work_changed_for_you_given_the_shift_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16rihec/how_has_work_changed_for_you_given_the_shift_from/", "subreddit_subscribers": 1059932, "created_utc": 1695616397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is there a way to calculate jitter or smoothness in motion capture movement, that result in numbers/values? if so, is there any standard to it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_16rgkxa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_cdt81y6f", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8TL8SLdj4BY6EtbmXIJYWQOE1dxhaZaO7zP_xwaYFMY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "computervision", "selftext": "So, i create a real time motion capture system that translate into an animated character movement and add a kalman filter to smooth the captured movement, since it's jitter/shaking so much without it.\n\nthe thing is, i can't find a way to compare the raw and filtered that result in numbers that prove the filtered movement is smoother than the raw movement. only the graphs and character animation that show it is smoother.\n\nthen i try to calculate both of their standard deviation by creating a predefined animation to be compared and it resulted in the following graphs and table.but ultimately, that only result in accuracy, which doesn't show significant difference anyway. that mean the filter did make the movement smoother but not increase it accuracy.\n\nnow my professor ask if maybe there's a standard to how smooth or jittery the movement is? maybe standard in animation, or games.\n\nso far i can't find a way to get the jitter or smoothness values, let alone the standard. can someone deny or confirm if there's way to calculate it and standard for it? or should i just proof the smoothness improvement with only the graphs?\n\nthanks\n\nhttps://preview.redd.it/xmy78l6gbbqb1.png?width=5693&amp;format=png&amp;auto=webp&amp;s=dde3f9801662a59670c867d111c5e12fd7dd96bf\n\nhttps://preview.redd.it/uveapdedcbqb1.png?width=849&amp;format=png&amp;auto=webp&amp;s=485dd8a5714987110b0b14bdc6de21e12d74cbb5\n\n&amp;#x200B;", "author_fullname": "t2_cdt81y6f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is there a way to calculate jitter or smoothness in motion capture movement, that result in numbers/values? if so, is there any standard to it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/computervision", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xmy78l6gbbqb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 129, "x": 108, "u": "https://preview.redd.it/xmy78l6gbbqb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=efe73ddd0ffa5a8a6415394ee0412f68d0137cd8"}, {"y": 258, "x": 216, "u": "https://preview.redd.it/xmy78l6gbbqb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ee2ea2dea15893929c966edfb3a5a9feffbdea1"}, {"y": 383, "x": 320, "u": "https://preview.redd.it/xmy78l6gbbqb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d66b363ad2544fa687807ffb92723c9e812ed1e8"}, {"y": 766, "x": 640, "u": "https://preview.redd.it/xmy78l6gbbqb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4dc6bc0ebbec7c56f02a88d3153f29e8c4333e37"}, {"y": 1149, "x": 960, "u": "https://preview.redd.it/xmy78l6gbbqb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa23be98c1663a3fc30e38a43828b917de74b80d"}, {"y": 1292, "x": 1080, "u": "https://preview.redd.it/xmy78l6gbbqb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0138b36d29587aac58a730e27d0f3d81ed4b5928"}], "s": {"y": 6814, "x": 5693, "u": "https://preview.redd.it/xmy78l6gbbqb1.png?width=5693&amp;format=png&amp;auto=webp&amp;s=dde3f9801662a59670c867d111c5e12fd7dd96bf"}, "id": "xmy78l6gbbqb1"}, "uveapdedcbqb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 41, "x": 108, "u": "https://preview.redd.it/uveapdedcbqb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=50c12036aef4dd789404178bdc12623256e6ca26"}, {"y": 82, "x": 216, "u": "https://preview.redd.it/uveapdedcbqb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2f8645efd54675d7d66cb5b4b0e3cc247af884c2"}, {"y": 122, "x": 320, "u": "https://preview.redd.it/uveapdedcbqb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1a7eed1103fa6504230edaef3a8b0d1f2ece6fb"}, {"y": 244, "x": 640, "u": "https://preview.redd.it/uveapdedcbqb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6ed794675dccefbe06afc84fdd9c45be52993c96"}], "s": {"y": 325, "x": 849, "u": "https://preview.redd.it/uveapdedcbqb1.png?width=849&amp;format=png&amp;auto=webp&amp;s=485dd8a5714987110b0b14bdc6de21e12d74cbb5"}, "id": "uveapdedcbqb1"}}, "name": "t3_16rgcfh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help: Project", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8TL8SLdj4BY6EtbmXIJYWQOE1dxhaZaO7zP_xwaYFMY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695609811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.computervision", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i create a real time motion capture system that translate into an animated character movement and add a kalman filter to smooth the captured movement, since it&amp;#39;s jitter/shaking so much without it.&lt;/p&gt;\n\n&lt;p&gt;the thing is, i can&amp;#39;t find a way to compare the raw and filtered that result in numbers that prove the filtered movement is smoother than the raw movement. only the graphs and character animation that show it is smoother.&lt;/p&gt;\n\n&lt;p&gt;then i try to calculate both of their standard deviation by creating a predefined animation to be compared and it resulted in the following graphs and table.but ultimately, that only result in accuracy, which doesn&amp;#39;t show significant difference anyway. that mean the filter did make the movement smoother but not increase it accuracy.&lt;/p&gt;\n\n&lt;p&gt;now my professor ask if maybe there&amp;#39;s a standard to how smooth or jittery the movement is? maybe standard in animation, or games.&lt;/p&gt;\n\n&lt;p&gt;so far i can&amp;#39;t find a way to get the jitter or smoothness values, let alone the standard. can someone deny or confirm if there&amp;#39;s way to calculate it and standard for it? or should i just proof the smoothness improvement with only the graphs?&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xmy78l6gbbqb1.png?width=5693&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dde3f9801662a59670c867d111c5e12fd7dd96bf\"&gt;https://preview.redd.it/xmy78l6gbbqb1.png?width=5693&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dde3f9801662a59670c867d111c5e12fd7dd96bf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uveapdedcbqb1.png?width=849&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=485dd8a5714987110b0b14bdc6de21e12d74cbb5\"&gt;https://preview.redd.it/uveapdedcbqb1.png?width=849&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=485dd8a5714987110b0b14bdc6de21e12d74cbb5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2be07b9a-850c-11eb-9ef0-0e67fd476361", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rfzn", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#fdff99", "id": "16rgcfh", "is_robot_indexable": true, "report_reasons": null, "author": "UniversityOk378", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/computervision/comments/16rgcfh/is_there_a_way_to_calculate_jitter_or_smoothness/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/computervision/comments/16rgcfh/is_there_a_way_to_calculate_jitter_or_smoothness/", "subreddit_subscribers": 79728, "created_utc": 1695609811.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1695610517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.computervision", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/computervision/comments/16rgcfh/is_there_a_way_to_calculate_jitter_or_smoothness/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rgkxa", "is_robot_indexable": true, "report_reasons": null, "author": "UniversityOk378", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_16rgcfh", "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rgkxa/is_there_a_way_to_calculate_jitter_or_smoothness/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/computervision/comments/16rgcfh/is_there_a_way_to_calculate_jitter_or_smoothness/", "subreddit_subscribers": 1059932, "created_utc": 1695610517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_e2yfk59o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Andreas Kretz on LinkedIn: Data Science AMA. Maybe this will help you cover the basics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_16rfm2h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2E0HZn11hcveJE4dTTSoOEh-mrgJd3TsYRT2d1LG8OI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695607656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/posts/andreas-kretz_tomorrow-im-doing-a-live-stream-with-my-activity-7111781783221719041-nvr6?utm_source=share&amp;utm_medium=member_ios", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HXoO2jOmLFHYLOp5uqz0uMk2GNP7Gqo8zf2a1hzURE4.jpg?auto=webp&amp;s=18689041ed1ad1829e19b3f16bdf0619c3add354", "width": 1400, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/HXoO2jOmLFHYLOp5uqz0uMk2GNP7Gqo8zf2a1hzURE4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd3104eb2954de61b63b4aded5889d7f481667e4", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/HXoO2jOmLFHYLOp5uqz0uMk2GNP7Gqo8zf2a1hzURE4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c971a4bc289c8f96921326f627cebe12f3ac1660", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/HXoO2jOmLFHYLOp5uqz0uMk2GNP7Gqo8zf2a1hzURE4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4aa8c0a35a98b8aba18c141f215320d65e017724", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/HXoO2jOmLFHYLOp5uqz0uMk2GNP7Gqo8zf2a1hzURE4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b4185fb0b2f226c0a0e3e33b8be8f2575bf9ab5", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/HXoO2jOmLFHYLOp5uqz0uMk2GNP7Gqo8zf2a1hzURE4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f9aebe95893f1568f8433661797ed06581b8b5b", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/HXoO2jOmLFHYLOp5uqz0uMk2GNP7Gqo8zf2a1hzURE4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4632741c44875873f4766540a85113c0e703b906", "width": 1080, "height": 617}], "variants": {}, "id": "CjbMbFq2MEqSKWpNCjv-ipCLADmRBQ1ZCG3w2yy71f0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rfm2h", "is_robot_indexable": true, "report_reasons": null, "author": "samjenkins377", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rfm2h/andreas_kretz_on_linkedin_data_science_ama_maybe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/posts/andreas-kretz_tomorrow-im-doing-a-live-stream-with-my-activity-7111781783221719041-nvr6?utm_source=share&amp;utm_medium=member_ios", "subreddit_subscribers": 1059932, "created_utc": 1695607656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Can someone guide as to how I derive the optimal cost and gamma values in R.\n\nDo you use tune.svm() ?", "author_fullname": "t2_tir3dln2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hyperparameter Tuning for SVM, stuck!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rfar3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695606755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone guide as to how I derive the optimal cost and gamma values in R.&lt;/p&gt;\n\n&lt;p&gt;Do you use tune.svm() ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rfar3", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Elevator_814", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rfar3/hyperparameter_tuning_for_svm_stuck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16rfar3/hyperparameter_tuning_for_svm_stuck/", "subreddit_subscribers": 1059932, "created_utc": 1695606755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I see a large amount of relevant open source tools and libraries to assist in peripheral (not the actual data processing or modeling) areas of data science. I mean tools that make certain important tasks easier. For instance: kedro, hydra-conf, nannyml, streamlit, docker, devpod, black, ruff, pandera, mage, fugue, datapane, adn probably a lot more.\n\nWhat do you guys use for your data science project?", "author_fullname": "t2_hji49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools do you use on your data science projects from proof of concept to production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16r7elg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695586274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see a large amount of relevant open source tools and libraries to assist in peripheral (not the actual data processing or modeling) areas of data science. I mean tools that make certain important tasks easier. For instance: kedro, hydra-conf, nannyml, streamlit, docker, devpod, black, ruff, pandera, mage, fugue, datapane, adn probably a lot more.&lt;/p&gt;\n\n&lt;p&gt;What do you guys use for your data science project?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16r7elg", "is_robot_indexable": true, "report_reasons": null, "author": "vmgustavo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16r7elg/what_tools_do_you_use_on_your_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16r7elg/what_tools_do_you_use_on_your_data_science/", "subreddit_subscribers": 1059932, "created_utc": 1695586274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've found the troves of data from the department of education on undergraduate admissions. School acceptance rates, ACT / SATs, etc. \n\nIs there any such data for graduate schools or programs? For example, GRE / GMAT data, or simply acceptance rates. Any help would be greatly appreciated!", "author_fullname": "t2_lrgivisy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for graduate admissions data, DoED", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16r1z2f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695572951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve found the troves of data from the department of education on undergraduate admissions. School acceptance rates, ACT / SATs, etc. &lt;/p&gt;\n\n&lt;p&gt;Is there any such data for graduate schools or programs? For example, GRE / GMAT data, or simply acceptance rates. Any help would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16r1z2f", "is_robot_indexable": true, "report_reasons": null, "author": "crimefog", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16r1z2f/looking_for_graduate_admissions_data_doed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16r1z2f/looking_for_graduate_admissions_data_doed/", "subreddit_subscribers": 1059932, "created_utc": 1695572951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi\nI've wrote a CRM for shipyards, and other professionals that do boat maintenance.\n\nEach customer of this software will enter data about work orders, products costs and labour...\nThose data will be tied to boat makes, end customers and so on ...\n\nI'd like to be able to provide some useful data to the shipyards from this data. I'm pretty new to data analysis and don't know of there are tools that can help me to do so ?\nI.e. I can imagine when creating a new work order for some task (let's say an engine periodical maintenance), I could provide historical data about how much time it does take for this kind of task... or even when a special engine is concerned, this one is specifically harder to work with, so the  planned hour count should be higher and so on...\n\nIs there models that could be trained against the customer data to provide those features?\n\nSorry if it's in the wrong place or If my question seems dumb !\n\nThanks", "author_fullname": "t2_u3p6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing a CRM : how to extract valued data to customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qvvl0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695556386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi\nI&amp;#39;ve wrote a CRM for shipyards, and other professionals that do boat maintenance.&lt;/p&gt;\n\n&lt;p&gt;Each customer of this software will enter data about work orders, products costs and labour...\nThose data will be tied to boat makes, end customers and so on ...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to be able to provide some useful data to the shipyards from this data. I&amp;#39;m pretty new to data analysis and don&amp;#39;t know of there are tools that can help me to do so ?\nI.e. I can imagine when creating a new work order for some task (let&amp;#39;s say an engine periodical maintenance), I could provide historical data about how much time it does take for this kind of task... or even when a special engine is concerned, this one is specifically harder to work with, so the  planned hour count should be higher and so on...&lt;/p&gt;\n\n&lt;p&gt;Is there models that could be trained against the customer data to provide those features?&lt;/p&gt;\n\n&lt;p&gt;Sorry if it&amp;#39;s in the wrong place or If my question seems dumb !&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qvvl0", "is_robot_indexable": true, "report_reasons": null, "author": "Napo7", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qvvl0/writing_a_crm_how_to_extract_valued_data_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qvvl0/writing_a_crm_how_to_extract_valued_data_to/", "subreddit_subscribers": 1059932, "created_utc": 1695556386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am an aspiring data scientist currently pursuing a BCs in CS (2nd year). Lately, I've been actively searching for remote data science internships to gain practical experience and make my resume strong. I've come across several online virtual internship programs that are open to anyone. I am wondering if these opportunities are worth the time and if it's appropriate to include them in my work experience. Here are a few examples of such programs:\n\n1. [iNeuron](https://internship.ineuron.ai/)\n2. [OpenWeaver](https://community.openweaver.com/t/virtual-internship-in-data-science-apply-now/114521)\n3. [The Spark Foundation](https://internship.thesparksfoundation.info/)\n4. [Let's Grown More](https://letsgrowmore.in/vip/)", "author_fullname": "t2_6oagcr1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these DS Virtual Internships good to get started?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qt2n3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695546597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an aspiring data scientist currently pursuing a BCs in CS (2nd year). Lately, I&amp;#39;ve been actively searching for remote data science internships to gain practical experience and make my resume strong. I&amp;#39;ve come across several online virtual internship programs that are open to anyone. I am wondering if these opportunities are worth the time and if it&amp;#39;s appropriate to include them in my work experience. Here are a few examples of such programs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://internship.ineuron.ai/\"&gt;iNeuron&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://community.openweaver.com/t/virtual-internship-in-data-science-apply-now/114521\"&gt;OpenWeaver&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://internship.thesparksfoundation.info/\"&gt;The Spark Foundation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://letsgrowmore.in/vip/\"&gt;Let&amp;#39;s Grown More&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qt2n3", "is_robot_indexable": true, "report_reasons": null, "author": "hashirbhatti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qt2n3/are_these_ds_virtual_internships_good_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qt2n3/are_these_ds_virtual_internships_good_to_get/", "subreddit_subscribers": 1059932, "created_utc": 1695546597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\nNavigating some unexpected twists in my data science journey and could really benefit from the collective wisdom of this community.\n\nFor about 2.5 years, I delved deep into predictive modeling within the heavy industry sector, leveraging my physics degree for a robust quantitative approach. Things took an unforeseen turn when my company closed its data science department. Though it was a jolt, I was offered a lifeline in the form of an analyst role within the fintech BaaS segment of our company. Here, I've been testing mobile apps, setting up APIs for clients, and gaining a different perspective.\n\nYet, as intriguing as fintech is, I've felt a drift from the heart of data science that once ignited my passion, and it's been a hurdle trying to relocate to a role that resonates more with my prior expertise.\n\nI'm at a juncture and could use some insights on these potential pathways:\n\n1. **Dive Deeper into Fintech**: Given my recent experiences, should I immerse myself further in fintech? I'm contemplating gaining a richer understanding of finance and then scouting for a data science role within this arena.\n2. **Physics and Data Science Fusion**: My love for physics remains undiminished. Could a focus on intertwining data science with physics be a promising avenue? Has anyone ventured this path and can share their experience?\n3. **Returning to Familiar Grounds or Exploring Fresh Horizons**: Is it more pragmatic to gravitate back to industries with which I'm acquainted or explore entirely new terrains where my data science prowess might be a good fit?\n\nYour experiences, advice, and reflections would be a beacon for me during this transitional phase.\n\nHeartfelt thanks for reading and offering your perspective!", "author_fullname": "t2_cyno6wxa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Career Guidance: From Heavy Industry to Fintech, with a Physics Twist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qsg1r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695544336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;Navigating some unexpected twists in my data science journey and could really benefit from the collective wisdom of this community.&lt;/p&gt;\n\n&lt;p&gt;For about 2.5 years, I delved deep into predictive modeling within the heavy industry sector, leveraging my physics degree for a robust quantitative approach. Things took an unforeseen turn when my company closed its data science department. Though it was a jolt, I was offered a lifeline in the form of an analyst role within the fintech BaaS segment of our company. Here, I&amp;#39;ve been testing mobile apps, setting up APIs for clients, and gaining a different perspective.&lt;/p&gt;\n\n&lt;p&gt;Yet, as intriguing as fintech is, I&amp;#39;ve felt a drift from the heart of data science that once ignited my passion, and it&amp;#39;s been a hurdle trying to relocate to a role that resonates more with my prior expertise.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m at a juncture and could use some insights on these potential pathways:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Dive Deeper into Fintech&lt;/strong&gt;: Given my recent experiences, should I immerse myself further in fintech? I&amp;#39;m contemplating gaining a richer understanding of finance and then scouting for a data science role within this arena.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Physics and Data Science Fusion&lt;/strong&gt;: My love for physics remains undiminished. Could a focus on intertwining data science with physics be a promising avenue? Has anyone ventured this path and can share their experience?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Returning to Familiar Grounds or Exploring Fresh Horizons&lt;/strong&gt;: Is it more pragmatic to gravitate back to industries with which I&amp;#39;m acquainted or explore entirely new terrains where my data science prowess might be a good fit?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Your experiences, advice, and reflections would be a beacon for me during this transitional phase.&lt;/p&gt;\n\n&lt;p&gt;Heartfelt thanks for reading and offering your perspective!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qsg1r", "is_robot_indexable": true, "report_reasons": null, "author": "MachineSilly576", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qsg1r/seeking_career_guidance_from_heavy_industry_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qsg1r/seeking_career_guidance_from_heavy_industry_to/", "subreddit_subscribers": 1059932, "created_utc": 1695544336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\nSo I'm a student and will be graduating Dec 2023 with a master's degree in computer science. Before my master's I worked for 3 years in an IT company only on tool informatica. Basically I have no background in data science. But I want to be a data scientist and get a job in same field within 2-3 months(as I'm on f1 visa in US). Can you guide me how and where do I start to become a data scientist. (I started with creating projects related to ml and data such as prediction models and classifiers.)", "author_fullname": "t2_81gppsav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you guide me to get a data scientist job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16rjqna", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695620727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,\nSo I&amp;#39;m a student and will be graduating Dec 2023 with a master&amp;#39;s degree in computer science. Before my master&amp;#39;s I worked for 3 years in an IT company only on tool informatica. Basically I have no background in data science. But I want to be a data scientist and get a job in same field within 2-3 months(as I&amp;#39;m on f1 visa in US). Can you guide me how and where do I start to become a data scientist. (I started with creating projects related to ml and data such as prediction models and classifiers.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rjqna", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Cut_802", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rjqna/can_you_guide_me_to_get_a_data_scientist_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16rjqna/can_you_guide_me_to_get_a_data_scientist_job/", "subreddit_subscribers": 1059932, "created_utc": 1695620727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Greetings everyone! \n\nI am a junior in college who aspire to become a data scientist or a data personal. I am studying finance (I switched from computer science because my college doesn\u2019t have a good computer science or mathematics college, but it has an excellent business school). My GPA is a 2.6 and I will need to stay an extra semester to get my Bachelors. The reason my GPA is low (to make a long story short) is because of financial hardships and because my scholarship placed a cap on how much I can earn. I live off campus and I am on my own, my parent wasn\u2019t able to contribute because they too were through financial hardships due to the COVID-19 pandemic. I work on campus with data to gain experience because I knew I couldn\u2019t apply for internships since I am not at 3.0. I have worked on projects for the university (like inventory/assisting GA or PhD students/assist faculty on research, etc.), and instructed at national conferences. I saved up to attended a summer data camp at a reputable university because I am a finance major and my college doesn\u2019t offer classes for Data Science. I need advice on what I should do. Currently, my plan is to continue studying data on my own by reading books and enrolling in certification like IBM, AWS, and Microsoft (I completed the IBM Data Science Professional). Since this is my last full year, I don\u2019t have a cap on how much I earn. I plan to work as a server to get to some to pay for these certification and be able to get groceries. However, I would like someone to tell me steps I should do get an internship or a part time job in data. What my priorities should be ? I guess I need someone to give me directions. Any feedback would be appreciated or suggestion or words of encouragement. I feel lost and could use something right now. Thank you for reading and have a great day! \n\nFrom,\nA random person on the internet", "author_fullname": "t2_6npgrd5e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice or suggestions for me as a student", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16rj52g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695618613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings everyone! &lt;/p&gt;\n\n&lt;p&gt;I am a junior in college who aspire to become a data scientist or a data personal. I am studying finance (I switched from computer science because my college doesn\u2019t have a good computer science or mathematics college, but it has an excellent business school). My GPA is a 2.6 and I will need to stay an extra semester to get my Bachelors. The reason my GPA is low (to make a long story short) is because of financial hardships and because my scholarship placed a cap on how much I can earn. I live off campus and I am on my own, my parent wasn\u2019t able to contribute because they too were through financial hardships due to the COVID-19 pandemic. I work on campus with data to gain experience because I knew I couldn\u2019t apply for internships since I am not at 3.0. I have worked on projects for the university (like inventory/assisting GA or PhD students/assist faculty on research, etc.), and instructed at national conferences. I saved up to attended a summer data camp at a reputable university because I am a finance major and my college doesn\u2019t offer classes for Data Science. I need advice on what I should do. Currently, my plan is to continue studying data on my own by reading books and enrolling in certification like IBM, AWS, and Microsoft (I completed the IBM Data Science Professional). Since this is my last full year, I don\u2019t have a cap on how much I earn. I plan to work as a server to get to some to pay for these certification and be able to get groceries. However, I would like someone to tell me steps I should do get an internship or a part time job in data. What my priorities should be ? I guess I need someone to give me directions. Any feedback would be appreciated or suggestion or words of encouragement. I feel lost and could use something right now. Thank you for reading and have a great day! &lt;/p&gt;\n\n&lt;p&gt;From,\nA random person on the internet&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16rj52g", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished_Ad_5697", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16rj52g/advice_or_suggestions_for_me_as_a_student/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16rj52g/advice_or_suggestions_for_me_as_a_student/", "subreddit_subscribers": 1059932, "created_utc": 1695618613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone!\n\nI hope you're all doing well. I'm currently working on fine-tuning my CV for a data scientist/ML Engineer or MLOps (need to acquire more skills in here) position, and I would greatly appreciate your feedback and insights.\n\nI've included all the essential details, but I want to make sure it truly reflects my skills and experience in the best possible way. If you have any tips, suggestions, or even specific areas you think I should focus on, please feel free to share them in the comments below.\n\nHere's the link to my CV: [https://ibb.co/9wL6H4N](https://ibb.co/9wL6H4N) or [https://postimg.cc/LJR3qQ2N](https://postimg.cc/LJR3qQ2N)\n\nThanks a million in advance for your help! Your expertise means a lot to me, and I'm excited to hear your thoughts. \ud83d\ude0a", "author_fullname": "t2_6fp6ab8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Feedback to Improve my Data Scientist CV", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16re6pa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695605006.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695603459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well. I&amp;#39;m currently working on fine-tuning my CV for a data scientist/ML Engineer or MLOps (need to acquire more skills in here) position, and I would greatly appreciate your feedback and insights.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve included all the essential details, but I want to make sure it truly reflects my skills and experience in the best possible way. If you have any tips, suggestions, or even specific areas you think I should focus on, please feel free to share them in the comments below.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link to my CV: &lt;a href=\"https://ibb.co/9wL6H4N\"&gt;https://ibb.co/9wL6H4N&lt;/a&gt; or &lt;a href=\"https://postimg.cc/LJR3qQ2N\"&gt;https://postimg.cc/LJR3qQ2N&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks a million in advance for your help! Your expertise means a lot to me, and I&amp;#39;m excited to hear your thoughts. \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JgmUFSu7Phck7U0zM-k96c0WdakVCANBMlS6qjIRR8s.jpg?auto=webp&amp;s=080beac32424633bb1d709ab01ddd272933b5bfb", "width": 1700, "height": 2200}, "resolutions": [{"url": "https://external-preview.redd.it/JgmUFSu7Phck7U0zM-k96c0WdakVCANBMlS6qjIRR8s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9bacb6fc374cfe1cc6f49d6ca98030c0d2025231", "width": 108, "height": 139}, {"url": "https://external-preview.redd.it/JgmUFSu7Phck7U0zM-k96c0WdakVCANBMlS6qjIRR8s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=496fff2f9dc1a1859a69056e874ba77e3fb351b6", "width": 216, "height": 279}, {"url": "https://external-preview.redd.it/JgmUFSu7Phck7U0zM-k96c0WdakVCANBMlS6qjIRR8s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e5f39d2013a02e497f0db6d7b0373edb4d4438c", "width": 320, "height": 414}, {"url": "https://external-preview.redd.it/JgmUFSu7Phck7U0zM-k96c0WdakVCANBMlS6qjIRR8s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8deb66bca79bc2d162008c0340a714a821769ac1", "width": 640, "height": 828}, {"url": "https://external-preview.redd.it/JgmUFSu7Phck7U0zM-k96c0WdakVCANBMlS6qjIRR8s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e490ce9e2c833cc5ed2803466ef03cceb4c915d2", "width": 960, "height": 1242}, {"url": "https://external-preview.redd.it/JgmUFSu7Phck7U0zM-k96c0WdakVCANBMlS6qjIRR8s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1aa922a1ca4f2788b4ad21abe2d2d744043863b8", "width": 1080, "height": 1397}], "variants": {}, "id": "25sW4H8zj0HfTiUS9jHV7peTlZlv4aagFbGWq-76o4Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16re6pa", "is_robot_indexable": true, "report_reasons": null, "author": "BlackLands123", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16re6pa/seeking_feedback_to_improve_my_data_scientist_cv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16re6pa/seeking_feedback_to_improve_my_data_scientist_cv/", "subreddit_subscribers": 1059932, "created_utc": 1695603459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm using AWS forcasting to forcast demand over different departments (fashion, home, elec, etc). Would it be suitable to do different forecasts for different departs that's have different related time series?\nSome related time series that I have tried reduce the WAPE on some departments but increase it on others", "author_fullname": "t2_7427v7db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series forcasting, when to split the target?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ra2yz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695592632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m using AWS forcasting to forcast demand over different departments (fashion, home, elec, etc). Would it be suitable to do different forecasts for different departs that&amp;#39;s have different related time series?\nSome related time series that I have tried reduce the WAPE on some departments but increase it on others&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16ra2yz", "is_robot_indexable": true, "report_reasons": null, "author": "Grovesy158", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16ra2yz/time_series_forcasting_when_to_split_the_target/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16ra2yz/time_series_forcasting_when_to_split_the_target/", "subreddit_subscribers": 1059932, "created_utc": 1695592632.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}