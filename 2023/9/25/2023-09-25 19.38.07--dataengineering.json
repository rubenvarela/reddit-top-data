{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The questions were fairly straightforward, irritatingly more wordy that most leetcode type questions, but there was only one table per question (there were joins but self joins only)\n\nReally nothing crazy about them. 4 questions, one hour. First question I finished in about 5mins as it was more of a fill in the blanks for a stored proc that'd give you the most popular product by year.\n\nNext one was a simple select, to get sum of highest salaries - sum of lowest. (This one actually failed a 1/7 test case but was it was easy I'd come back to it later. I'd find out soon though, I'd never see this question again...\n\nQuestion 3, shit hit the fan. All I needed to do was select names of fraudulent customers based on a condition that would come from time lapsed between transactions. Except, it wasn't a select. It was a procedure. I couldn't incrementally build out the query and check the output as I'd go. I needed to write the query and run it, if it was right it'd say so. If not, it's say test case n/N failed. No context as to where it'd fail. \n\nAgain, these questions were not hard. But next thing my fucking hand starts to shake. I've still got 40mins left, calm down. Start trying to visualize the solution. Panic sets in and nothing worked after that. Ok, next question, will skip this one for now.\n\nSame bloody thing. Procedure, not select. Incredibly wordy question. Easy enough question when youve [seen similar ones](https://datalemur.com/questions/pizzas-topping-cost), sincs it was similar to that pizza one I knew it was a self join and messing around with adding columns (at the time I was thinking I'd need a window function to get the lower cost combo,  but turns out for this question it was simply just needed go get the totals with no duplicates, easy stuff. But I bombed it. Of course I opened it up on my ide afterward and solved it in &lt;10mins, because I like to torture myself like that.\n\nSeems that not having the ability to see the outputs of selects/ctes etc completely through me off. I'm now wondering if I'm the only person that does this and I've gotten into a bad habit of banging the execute button to see the outputs of intermediary results??\n\nKicking myself now as it was so damn easy and a really cool job. Only consolation was thst there would have been another 4/5 rounds of technical interviews after this and probably wouldn't have gotten through ayway", "author_fullname": "t2_1w1o79i7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bombed an easy SQL prescreening assessment - have I picked up bad habits by looking at intermediate query results?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16r9swv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695591968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The questions were fairly straightforward, irritatingly more wordy that most leetcode type questions, but there was only one table per question (there were joins but self joins only)&lt;/p&gt;\n\n&lt;p&gt;Really nothing crazy about them. 4 questions, one hour. First question I finished in about 5mins as it was more of a fill in the blanks for a stored proc that&amp;#39;d give you the most popular product by year.&lt;/p&gt;\n\n&lt;p&gt;Next one was a simple select, to get sum of highest salaries - sum of lowest. (This one actually failed a 1/7 test case but was it was easy I&amp;#39;d come back to it later. I&amp;#39;d find out soon though, I&amp;#39;d never see this question again...&lt;/p&gt;\n\n&lt;p&gt;Question 3, shit hit the fan. All I needed to do was select names of fraudulent customers based on a condition that would come from time lapsed between transactions. Except, it wasn&amp;#39;t a select. It was a procedure. I couldn&amp;#39;t incrementally build out the query and check the output as I&amp;#39;d go. I needed to write the query and run it, if it was right it&amp;#39;d say so. If not, it&amp;#39;s say test case n/N failed. No context as to where it&amp;#39;d fail. &lt;/p&gt;\n\n&lt;p&gt;Again, these questions were not hard. But next thing my fucking hand starts to shake. I&amp;#39;ve still got 40mins left, calm down. Start trying to visualize the solution. Panic sets in and nothing worked after that. Ok, next question, will skip this one for now.&lt;/p&gt;\n\n&lt;p&gt;Same bloody thing. Procedure, not select. Incredibly wordy question. Easy enough question when youve &lt;a href=\"https://datalemur.com/questions/pizzas-topping-cost\"&gt;seen similar ones&lt;/a&gt;, sincs it was similar to that pizza one I knew it was a self join and messing around with adding columns (at the time I was thinking I&amp;#39;d need a window function to get the lower cost combo,  but turns out for this question it was simply just needed go get the totals with no duplicates, easy stuff. But I bombed it. Of course I opened it up on my ide afterward and solved it in &amp;lt;10mins, because I like to torture myself like that.&lt;/p&gt;\n\n&lt;p&gt;Seems that not having the ability to see the outputs of selects/ctes etc completely through me off. I&amp;#39;m now wondering if I&amp;#39;m the only person that does this and I&amp;#39;ve gotten into a bad habit of banging the execute button to see the outputs of intermediary results??&lt;/p&gt;\n\n&lt;p&gt;Kicking myself now as it was so damn easy and a really cool job. Only consolation was thst there would have been another 4/5 rounds of technical interviews after this and probably wouldn&amp;#39;t have gotten through ayway&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kvAalAMUTwVx-RWPxt7OGwpP1OeLOb3EYj0o29ZGbKM.jpg?auto=webp&amp;s=a6863d19648309b6e3176a9eee52cb8216efce69", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/kvAalAMUTwVx-RWPxt7OGwpP1OeLOb3EYj0o29ZGbKM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=47a9aa9e8f07567e2b88dac9ce4e3f7a6e23f9d7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/kvAalAMUTwVx-RWPxt7OGwpP1OeLOb3EYj0o29ZGbKM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1e137641eb770388594fd82c4e58db9cc64dd659", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/kvAalAMUTwVx-RWPxt7OGwpP1OeLOb3EYj0o29ZGbKM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c13cb4b7d66b52a4fe3bdf986a3d141d3c1d2806", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/kvAalAMUTwVx-RWPxt7OGwpP1OeLOb3EYj0o29ZGbKM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce1afb705cfcb979ee099eab554f759c2f89ef90", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/kvAalAMUTwVx-RWPxt7OGwpP1OeLOb3EYj0o29ZGbKM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c99bb17a41bdc454fc7204dcfb3e57276e4aacbc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/kvAalAMUTwVx-RWPxt7OGwpP1OeLOb3EYj0o29ZGbKM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=61054982f566d0873d25f1b69cfef7e2f3a2c7f4", "width": 1080, "height": 567}], "variants": {}, "id": "wPNS14r1J4_L3TGYUAsqCV8FmgGrMho9XjGoyEnYUAQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16r9swv", "is_robot_indexable": true, "report_reasons": null, "author": "tea_horse", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16r9swv/bombed_an_easy_sql_prescreening_assessment_have_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16r9swv/bombed_an_easy_sql_prescreening_assessment_have_i/", "subreddit_subscribers": 130384, "created_utc": 1695591968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please find the code for my stock data streaming application [here](https://github.com/JawaharRamis/stock-price-analysis-kafka-spark-influxdb-grafana).\n\nThe aim for the project was to familiarize myself with the various components involved and having a meaningful dashboard at the end of it. Kindly share your suggestions/advices. The main thing I am concerned is if I have structured the code in the best way possible or even the deployment setup/configurations. \n\nThis subreddit has been immense during my learning journey and I hope it continues to aid me.", "author_fullname": "t2_67og6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stock market streaming application", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rb1hz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695594977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please find the code for my stock data streaming application &lt;a href=\"https://github.com/JawaharRamis/stock-price-analysis-kafka-spark-influxdb-grafana\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The aim for the project was to familiarize myself with the various components involved and having a meaningful dashboard at the end of it. Kindly share your suggestions/advices. The main thing I am concerned is if I have structured the code in the best way possible or even the deployment setup/configurations. &lt;/p&gt;\n\n&lt;p&gt;This subreddit has been immense during my learning journey and I hope it continues to aid me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8sxNORt14rMIsKmWvtKK-Ip8jNrYSGXvW9jO5LHY_Jo.jpg?auto=webp&amp;s=19d09cf64df95948fd765c06fdbe5575d70e25cd", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/8sxNORt14rMIsKmWvtKK-Ip8jNrYSGXvW9jO5LHY_Jo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1f65ccd0fb28832b7a761eaeb280d99d175171c2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8sxNORt14rMIsKmWvtKK-Ip8jNrYSGXvW9jO5LHY_Jo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9d0ed9c9a8b0a63514689e32dae4436ac7a3164", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8sxNORt14rMIsKmWvtKK-Ip8jNrYSGXvW9jO5LHY_Jo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2523d023e49863736668af1bd4568e75587fb0a9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8sxNORt14rMIsKmWvtKK-Ip8jNrYSGXvW9jO5LHY_Jo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c55af923d520b5d02f6a51bf2bfed99b9cc943c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/8sxNORt14rMIsKmWvtKK-Ip8jNrYSGXvW9jO5LHY_Jo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e71295dbcac468ecadca81e9eeacce006477ed8a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/8sxNORt14rMIsKmWvtKK-Ip8jNrYSGXvW9jO5LHY_Jo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=26f4bb51218822e4328b08f224f4b41c2bec4c0f", "width": 1080, "height": 540}], "variants": {}, "id": "PyAZjXFESQEfZE9E-hmQVe5jfp1OTuXS7LpwqNAImpQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "16rb1hz", "is_robot_indexable": true, "report_reasons": null, "author": "jawz96", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rb1hz/stock_market_streaming_application/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rb1hz/stock_market_streaming_application/", "subreddit_subscribers": 130384, "created_utc": 1695594977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've read \"Fundamentals of Data Engineering\" by Reis. However, as the name says that book covers the fundamentals. There are loads of books on software engineering design patterns in general. Not for data engineering in my knowledge.\n\nI'm looking for a great book that goes through the popular data architecture patterns end-to-end. With code samples. Googled, but didn't find anything particularly exciting. Just a few blog posts. Which books do you folks suggest as essential reading for a data engineer?", "author_fullname": "t2_pblux6w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a great book on design patterns in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rxj7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695661129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve read &amp;quot;Fundamentals of Data Engineering&amp;quot; by Reis. However, as the name says that book covers the fundamentals. There are loads of books on software engineering design patterns in general. Not for data engineering in my knowledge.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a great book that goes through the popular data architecture patterns end-to-end. With code samples. Googled, but didn&amp;#39;t find anything particularly exciting. Just a few blog posts. Which books do you folks suggest as essential reading for a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16rxj7v", "is_robot_indexable": true, "report_reasons": null, "author": "newplayer12345", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rxj7v/is_there_a_great_book_on_design_patterns_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rxj7v/is_there_a_great_book_on_design_patterns_in_data/", "subreddit_subscribers": 130384, "created_utc": 1695661129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,I'm new and trying to do POC of CDC for streaming data from mysql to Kafka via debezium. What can I do in the correct way when initialize a snapshot from MySQL? If a slave or debezium connectors are down, how can I manage the Kafka cluster to recovery debezium instances from other MySQL slave or master? Do you have any specified whole pictures of CDC in the real world?Thanks for your recommendation,\n\nhttps://preview.redd.it/hzrcstb8ibqb1.png?width=1057&amp;format=png&amp;auto=webp&amp;s=ddc4b951a7a53c5fbaa804c7c75db791df143bd8", "author_fullname": "t2_kwjgg3p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CDC MySQL with debezium", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hzrcstb8ibqb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/hzrcstb8ibqb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8fb0a779962adcfb683216cfc7339411d99f29f"}, {"y": 85, "x": 216, "u": "https://preview.redd.it/hzrcstb8ibqb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=005e10db26a7c9233c4f0d800cf36b29ffc6bda1"}, {"y": 126, "x": 320, "u": "https://preview.redd.it/hzrcstb8ibqb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=39c6218748851df4499992c78693909d4b27df32"}, {"y": 253, "x": 640, "u": "https://preview.redd.it/hzrcstb8ibqb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=95f12d39a610f400ab5a0a4c98d7f3033126e3ba"}, {"y": 379, "x": 960, "u": "https://preview.redd.it/hzrcstb8ibqb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=83f6ddd8ebafb395897d525493915cd397f72422"}], "s": {"y": 418, "x": 1057, "u": "https://preview.redd.it/hzrcstb8ibqb1.png?width=1057&amp;format=png&amp;auto=webp&amp;s=ddc4b951a7a53c5fbaa804c7c75db791df143bd8"}, "id": "hzrcstb8ibqb1"}}, "name": "t3_16rgu36", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/p0onLUeK1KG8N58AlD59dqhZxHEM-uHC6adOsdvVqL0.jpg", "edited": 1695615842.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695611253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,I&amp;#39;m new and trying to do POC of CDC for streaming data from mysql to Kafka via debezium. What can I do in the correct way when initialize a snapshot from MySQL? If a slave or debezium connectors are down, how can I manage the Kafka cluster to recovery debezium instances from other MySQL slave or master? Do you have any specified whole pictures of CDC in the real world?Thanks for your recommendation,&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hzrcstb8ibqb1.png?width=1057&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ddc4b951a7a53c5fbaa804c7c75db791df143bd8\"&gt;https://preview.redd.it/hzrcstb8ibqb1.png?width=1057&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ddc4b951a7a53c5fbaa804c7c75db791df143bd8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16rgu36", "is_robot_indexable": true, "report_reasons": null, "author": "phamtanvinhme", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rgu36/cdc_mysql_with_debezium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rgu36/cdc_mysql_with_debezium/", "subreddit_subscribers": 130384, "created_utc": 1695611253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello!\n\nAt my workplace, we have a data warehouse, and we're looking to begin using the DBT tool to manage our transformations. However, from what I've gathered, DBT seems to be primarily designed for ELT pipelines. Currently, our pipeline involves a Python script managed via Airflow, which executes some SQL directly on our production DBT.\n\nMy question is, how can I implement a form of ELT with PostgreSQL as our data warehouse? I'm not sure if there's an effective way to organize this structure within PostgreSQL, or if there's something I might be overlooking.", "author_fullname": "t2_8jc0mwfh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using postgresql data warehouse with ELT pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rwtvd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695659481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;At my workplace, we have a data warehouse, and we&amp;#39;re looking to begin using the DBT tool to manage our transformations. However, from what I&amp;#39;ve gathered, DBT seems to be primarily designed for ELT pipelines. Currently, our pipeline involves a Python script managed via Airflow, which executes some SQL directly on our production DBT.&lt;/p&gt;\n\n&lt;p&gt;My question is, how can I implement a form of ELT with PostgreSQL as our data warehouse? I&amp;#39;m not sure if there&amp;#39;s an effective way to organize this structure within PostgreSQL, or if there&amp;#39;s something I might be overlooking.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16rwtvd", "is_robot_indexable": true, "report_reasons": null, "author": "Andremallmann", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rwtvd/using_postgresql_data_warehouse_with_elt_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rwtvd/using_postgresql_data_warehouse_with_elt_pipelines/", "subreddit_subscribers": 130384, "created_utc": 1695659481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, as part of my thesis I am examining, among other things, the question of whether TDD or BDD can be used to develop ETL processes and if so, then how. It shouldn't go into too much detail and should be answered more theoretically.\n\n&amp;#x200B;\n\nAccording to my understanding so far, I need unit tests for development according to TDD. Now I ask myself how unit test cases can be set up for ETL development. Several sources say that you can only check the 'T' i.e. the transformations with unit testing. The steps 'E' and 'L' require external resources such as data sources or data warehouse to test them and therefore they are automatically integration tests, right? So can unit tests only be used for the transformation process? Does anyone have experience with TDD or even BDD in ETL development?\n\n&amp;#x200B;\n\nThank you for the answers", "author_fullname": "t2_hrqrf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TDD for ETL-Development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rp3uv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695640321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, as part of my thesis I am examining, among other things, the question of whether TDD or BDD can be used to develop ETL processes and if so, then how. It shouldn&amp;#39;t go into too much detail and should be answered more theoretically.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;According to my understanding so far, I need unit tests for development according to TDD. Now I ask myself how unit test cases can be set up for ETL development. Several sources say that you can only check the &amp;#39;T&amp;#39; i.e. the transformations with unit testing. The steps &amp;#39;E&amp;#39; and &amp;#39;L&amp;#39; require external resources such as data sources or data warehouse to test them and therefore they are automatically integration tests, right? So can unit tests only be used for the transformation process? Does anyone have experience with TDD or even BDD in ETL development?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for the answers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16rp3uv", "is_robot_indexable": true, "report_reasons": null, "author": "m3xx4", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rp3uv/tdd_for_etldevelopment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rp3uv/tdd_for_etldevelopment/", "subreddit_subscribers": 130384, "created_utc": 1695640321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data Engineering friends,\n\nI would like to ask for your opinions on something that has been bothering me at work.  I work at a start up that hosts an application that uses DynamoDB as our transactional database and snowflake as our reporting/analytics engine.  We currently only have one instance of snowflake that points to our production AWS account/DynamoDb database and I am trying to convince my managers that we absolutely need a dev snowflake instance to point to our Non Prod AWS account to allow us to do end to end regression testing including our reports/analytics products.  I am basically being told that the overhead cost of replicating production to our lower environments will be too expensive, but at the same time we are being told that we need to have a highly available system and we have to meet SLA's.  I don't  find it sufficient to just do code reviews, I don't think we will ever scale if we cannot perform a set of regression tests in a safe space. \n\nAm I right here or are my standards of how development should be done outdated?  Would anyone else here find this as a red flag for management?", "author_fullname": "t2_osq93qer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Development Ops Separation for Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rrecb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695646833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data Engineering friends,&lt;/p&gt;\n\n&lt;p&gt;I would like to ask for your opinions on something that has been bothering me at work.  I work at a start up that hosts an application that uses DynamoDB as our transactional database and snowflake as our reporting/analytics engine.  We currently only have one instance of snowflake that points to our production AWS account/DynamoDb database and I am trying to convince my managers that we absolutely need a dev snowflake instance to point to our Non Prod AWS account to allow us to do end to end regression testing including our reports/analytics products.  I am basically being told that the overhead cost of replicating production to our lower environments will be too expensive, but at the same time we are being told that we need to have a highly available system and we have to meet SLA&amp;#39;s.  I don&amp;#39;t  find it sufficient to just do code reviews, I don&amp;#39;t think we will ever scale if we cannot perform a set of regression tests in a safe space. &lt;/p&gt;\n\n&lt;p&gt;Am I right here or are my standards of how development should be done outdated?  Would anyone else here find this as a red flag for management?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16rrecb", "is_robot_indexable": true, "report_reasons": null, "author": "nsq116", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rrecb/development_ops_separation_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rrecb/development_ops_separation_for_data_engineering/", "subreddit_subscribers": 130384, "created_utc": 1695646833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For those of us who believe in the power of event-driven architectures and data streaming, you might be interested in our new open-source project: LangStream. It is an open-source framework for building event-driven Gen AI applications that combines LLMs, vector databases, Kubernetes, and Apache Kafka.  \n\n\nLangStream supports all Kafka connectors out of the box. You can just point to the JAR for a connector and use it as part of a Gen AI pipeline.\n\nFind out more here:\n\n[https://langstream.ai/2023/09/13/introducing-langstream/](https://langstream.ai/2023/09/13/introducing-langstream/)\n\nIf you find it interesting, please star the repo: [https://github.com/LangStream/langstream](https://github.com/LangStream/langstream)", "author_fullname": "t2_8nsm8c43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New project: LangStream for building and running event-driven LLM applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rxyye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695662103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those of us who believe in the power of event-driven architectures and data streaming, you might be interested in our new open-source project: LangStream. It is an open-source framework for building event-driven Gen AI applications that combines LLMs, vector databases, Kubernetes, and Apache Kafka.  &lt;/p&gt;\n\n&lt;p&gt;LangStream supports all Kafka connectors out of the box. You can just point to the JAR for a connector and use it as part of a Gen AI pipeline.&lt;/p&gt;\n\n&lt;p&gt;Find out more here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://langstream.ai/2023/09/13/introducing-langstream/\"&gt;https://langstream.ai/2023/09/13/introducing-langstream/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you find it interesting, please star the repo: &lt;a href=\"https://github.com/LangStream/langstream\"&gt;https://github.com/LangStream/langstream&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NG_01PXp8iHDS_CdGx1Yq8HNtjMg7HUOlNjPoHNF0O8.jpg?auto=webp&amp;s=7d52f2f9bf64f49aae414fb6550354d29f1df798", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/NG_01PXp8iHDS_CdGx1Yq8HNtjMg7HUOlNjPoHNF0O8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8201a0b8f9ad3dfaa0dd0562f736ae1f1110d64b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/NG_01PXp8iHDS_CdGx1Yq8HNtjMg7HUOlNjPoHNF0O8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cdf3e5c6350961e9b3000a9b5f1c27665490c0e5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/NG_01PXp8iHDS_CdGx1Yq8HNtjMg7HUOlNjPoHNF0O8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b0c34ddc1ab9d49bd200f7fcac070c9b39339de0", "width": 320, "height": 320}], "variants": {}, "id": "HwttWOvzTbyp1qu4I_z2JJSOGfJjcyFvmlF5NnjzRKc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16rxyye", "is_robot_indexable": true, "report_reasons": null, "author": "Head_Reaction_6242", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rxyye/new_project_langstream_for_building_and_running/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rxyye/new_project_langstream_for_building_and_running/", "subreddit_subscribers": 130384, "created_utc": 1695662103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Alright friends, I've got a client who is dead-set on using Informatics for MDM. Anyone know off the top of their head what makes up an IPU for these guys?\n\nAlso, how angry does it make you when you try to get an answer to a question like that and their official page tells you to call a sales rep?", "author_fullname": "t2_713dpi97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Informatica and IPU", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rrn5k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695647428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Alright friends, I&amp;#39;ve got a client who is dead-set on using Informatics for MDM. Anyone know off the top of their head what makes up an IPU for these guys?&lt;/p&gt;\n\n&lt;p&gt;Also, how angry does it make you when you try to get an answer to a question like that and their official page tells you to call a sales rep?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16rrn5k", "is_robot_indexable": true, "report_reasons": null, "author": "rexicusmaximus", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16rrn5k/informatica_and_ipu/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rrn5k/informatica_and_ipu/", "subreddit_subscribers": 130384, "created_utc": 1695647428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to build a batch processing pipeline which transforms CSVs into some common JSON schema. What are good ways of achieving that? \n\nThe pipeline needs to:\n- start a job on signal (perhaps airflow/dagster)\n- process csv file (~10GB)\n- load json into document store\n- perform other tasks eventually, like validation, diffing, notifying, etc.\n\nI\u2019ve tried Apache Beam via Dataflow, using Scala scio, and this seems like a viable option, although maybe not especially user friendly. Documentation and examples are scattered across different SDKs using different languages and if I\u2019m not mistaken, they don\u2019t implement the same functionality. I\u2019d like to use Scala, or a similar statically typed language, as the project complexity will likely grow with time, and it would be great to have it all in one language.\n\nI don\u2019t have a lot of experience with data engineering specifically, so not sure if there are better options out there. What would you recommend? \n\nThank you!", "author_fullname": "t2_hc1vem", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batch processing recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16r7ths", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695587279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to build a batch processing pipeline which transforms CSVs into some common JSON schema. What are good ways of achieving that? &lt;/p&gt;\n\n&lt;p&gt;The pipeline needs to:\n- start a job on signal (perhaps airflow/dagster)\n- process csv file (~10GB)\n- load json into document store\n- perform other tasks eventually, like validation, diffing, notifying, etc.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried Apache Beam via Dataflow, using Scala scio, and this seems like a viable option, although maybe not especially user friendly. Documentation and examples are scattered across different SDKs using different languages and if I\u2019m not mistaken, they don\u2019t implement the same functionality. I\u2019d like to use Scala, or a similar statically typed language, as the project complexity will likely grow with time, and it would be great to have it all in one language.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t have a lot of experience with data engineering specifically, so not sure if there are better options out there. What would you recommend? &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16r7ths", "is_robot_indexable": true, "report_reasons": null, "author": "RustinWolf", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16r7ths/batch_processing_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16r7ths/batch_processing_recommendations/", "subreddit_subscribers": 130384, "created_utc": 1695587279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious to hear your insights and experiences with how you may handle data discrepancies that crop up between different databases in your projects?\n\nE.g. I have one excel spreadsheet full of vendors' names and contact info and a mailchimp mailing list with their info but notice from time to time that emails between both may be different. How could I sync these without manually going through thousands of entries? \n\nDo you have any specific techniques for data reconciliation or data validation? Are there any tools that have been particularly helpful? How do you maintain data consistency and accuracy as your data ecosystem grows and evolves?\n\nHoping to find answers/tools to the above q\u2019s that would be usable by a non-technical person or don't require a dedicated programmer. ", "author_fullname": "t2_kgr62d3c0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practices for Dealing with Data Discrepancies Between Databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16rza4k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695665142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious to hear your insights and experiences with how you may handle data discrepancies that crop up between different databases in your projects?&lt;/p&gt;\n\n&lt;p&gt;E.g. I have one excel spreadsheet full of vendors&amp;#39; names and contact info and a mailchimp mailing list with their info but notice from time to time that emails between both may be different. How could I sync these without manually going through thousands of entries? &lt;/p&gt;\n\n&lt;p&gt;Do you have any specific techniques for data reconciliation or data validation? Are there any tools that have been particularly helpful? How do you maintain data consistency and accuracy as your data ecosystem grows and evolves?&lt;/p&gt;\n\n&lt;p&gt;Hoping to find answers/tools to the above q\u2019s that would be usable by a non-technical person or don&amp;#39;t require a dedicated programmer. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16rza4k", "is_robot_indexable": true, "report_reasons": null, "author": "Stat58372", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rza4k/best_practices_for_dealing_with_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rza4k/best_practices_for_dealing_with_data/", "subreddit_subscribers": 130384, "created_utc": 1695665142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm looking into setting up an on prem Lake House with Kubernetes compute (&gt;1k nodes) and S3 compatible object store (multi PB).  Not interested in a Hadoop based stack or cloud based.   Must be able to run Apache Spark workloads and have a Metastore (like Hive Metastore or [Nessie](https://projectnessie.org/))  bonus if it can run multiple data processing engines (Trino, Flink...)  Apache 2 License is prefered, but I'm willing to pay if I find something to solve my needs. \n\n[DataRoaster](https://github.com/cloudcheflabs/dataroaster)  looks like a great start, but I'm looking for something that is actively being developed and maybe a little bit further along.  \n\nThanks for any suggestions!\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_ind8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for On Prem Lake House software stack using k8s and s3 compat obj.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ruspl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695654793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking into setting up an on prem Lake House with Kubernetes compute (&amp;gt;1k nodes) and S3 compatible object store (multi PB).  Not interested in a Hadoop based stack or cloud based.   Must be able to run Apache Spark workloads and have a Metastore (like Hive Metastore or &lt;a href=\"https://projectnessie.org/\"&gt;Nessie&lt;/a&gt;)  bonus if it can run multiple data processing engines (Trino, Flink...)  Apache 2 License is prefered, but I&amp;#39;m willing to pay if I find something to solve my needs. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/cloudcheflabs/dataroaster\"&gt;DataRoaster&lt;/a&gt;  looks like a great start, but I&amp;#39;m looking for something that is actively being developed and maybe a little bit further along.  &lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ruspl", "is_robot_indexable": true, "report_reasons": null, "author": "6nop_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ruspl/looking_for_on_prem_lake_house_software_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ruspl/looking_for_on_prem_lake_house_software_stack/", "subreddit_subscribers": 130384, "created_utc": 1695654793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\nI am a data engineer in Amsterdam, NL and having 2-3 years of experience. Half of it was on data warehousing in gcp and other half was on spark/scala. I am considering to work for a IT consultancy company, but I moved here 6 months ago and don\u2019t know the sector. \n\nBasically, I want to learn as much as possible in my early stage of career and have a decent income in a non-toxic environment.\n\nWhich consultancy companies do you recommend or definitely not recommend to work as a data engineer?", "author_fullname": "t2_knked3pz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consultancy company in Netherlands", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rsv5k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695650288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,\nI am a data engineer in Amsterdam, NL and having 2-3 years of experience. Half of it was on data warehousing in gcp and other half was on spark/scala. I am considering to work for a IT consultancy company, but I moved here 6 months ago and don\u2019t know the sector. &lt;/p&gt;\n\n&lt;p&gt;Basically, I want to learn as much as possible in my early stage of career and have a decent income in a non-toxic environment.&lt;/p&gt;\n\n&lt;p&gt;Which consultancy companies do you recommend or definitely not recommend to work as a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16rsv5k", "is_robot_indexable": true, "report_reasons": null, "author": "Naive-Treacle2355", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rsv5k/consultancy_company_in_netherlands/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rsv5k/consultancy_company_in_netherlands/", "subreddit_subscribers": 130384, "created_utc": 1695650288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Microsoft is making significant strides in the field of data engineering by offering a highly convenient and cost-effective pipeline for small to mid-range data sizes (less than 10 GB of data) at a monthly cost of around $50.It is important to note that while the Lake database may not be a real SQL database, it functions as one, providing users with a powerful and versatile tool for managing their data. With its promising capabilities, this technology is poised to make a significant impact on the market in the near future.\n\nhttps://preview.redd.it/rav2hxen1gqb1.png?width=2429&amp;format=png&amp;auto=webp&amp;s=148e0cbbab5403e8be8edcf43117e8b1d1e6acd3", "author_fullname": "t2_7h19x6eg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Database in Azure Synapse Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 22, "top_awarded_type": null, "hide_score": true, "media_metadata": {"rav2hxen1gqb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 16, "x": 108, "u": "https://preview.redd.it/rav2hxen1gqb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab0f6f8bddeacbf8857ff5548fe47261a1f1cb9f"}, {"y": 33, "x": 216, "u": "https://preview.redd.it/rav2hxen1gqb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5286c9109066ad21b71b49dc2a8c8c4ef6de871"}, {"y": 50, "x": 320, "u": "https://preview.redd.it/rav2hxen1gqb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=17b6c595704de064042e0567a753dc79d8261f41"}, {"y": 100, "x": 640, "u": "https://preview.redd.it/rav2hxen1gqb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5b1a8ef38d1ae09d430fe8da73e5ff28e87bb03"}, {"y": 150, "x": 960, "u": "https://preview.redd.it/rav2hxen1gqb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=785c21dcfe5d0d051dc4ad274285e0b6906190d5"}, {"y": 169, "x": 1080, "u": "https://preview.redd.it/rav2hxen1gqb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16af922443dd302399d1fc7e1f2c91c14ac44c0a"}], "s": {"y": 382, "x": 2429, "u": "https://preview.redd.it/rav2hxen1gqb1.png?width=2429&amp;format=png&amp;auto=webp&amp;s=148e0cbbab5403e8be8edcf43117e8b1d1e6acd3"}, "id": "rav2hxen1gqb1"}}, "name": "t3_16rzmh0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/C_rU88WQ_xBI5sOYDxWgwpfV3kEcVpjLQ7dnPsHw9sg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695665956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Microsoft is making significant strides in the field of data engineering by offering a highly convenient and cost-effective pipeline for small to mid-range data sizes (less than 10 GB of data) at a monthly cost of around $50.It is important to note that while the Lake database may not be a real SQL database, it functions as one, providing users with a powerful and versatile tool for managing their data. With its promising capabilities, this technology is poised to make a significant impact on the market in the near future.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rav2hxen1gqb1.png?width=2429&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=148e0cbbab5403e8be8edcf43117e8b1d1e6acd3\"&gt;https://preview.redd.it/rav2hxen1gqb1.png?width=2429&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=148e0cbbab5403e8be8edcf43117e8b1d1e6acd3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16rzmh0", "is_robot_indexable": true, "report_reasons": null, "author": "_Sir1980", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rzmh0/spark_database_in_azure_synapse_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rzmh0/spark_database_in_azure_synapse_analytics/", "subreddit_subscribers": 130384, "created_utc": 1695665956.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}