{"kind": "Listing", "data": {"after": "t3_16bmnos", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is data engineering hiring ramping up all of the sudden? Could be that LinkedIn changed the recruiter search tool algo I suppose. Curious if anyone else is seeing the same.", "author_fullname": "t2_jyzw4d7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Huge influx of recruiters messaging me on LinkedIn starting September 1st despite nothing changing on my LinkedIn\u2026 anyone else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16c0p6h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694045281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is data engineering hiring ramping up all of the sudden? Could be that LinkedIn changed the recruiter search tool algo I suppose. Curious if anyone else is seeing the same.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16c0p6h", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Positive-7272", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16c0p6h/huge_influx_of_recruiters_messaging_me_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16c0p6h/huge_influx_of_recruiters_messaging_me_on/", "subreddit_subscribers": 127248, "created_utc": 1694045281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello r/dataengineering!\n\nI'm on a quest to find the best managed EL tools out there. Our home-grown Python scripts have been a significant source of headaches, and with a small team, self-hosting just isn't viable for us. We are keenly interested in cloud-based solutions to make our life easier.\n\nSo far, here's what's on our radar:\n\n* **Fivetran:** It appears fairly production-ready and robust, but I have reservations about it being a proprietary system. Additionally, the costs seem to rise significantly given the relatively high active row count (IoT business).\n* **Airbyte:** While it seems promising, I've observed numerous issues on their GitHub. Moreover, they're in the midst of rolling out a major update with their V2 destinations.\n* **Meltano:** I recently discovered they have a \"Meltano Cloud\" offering currently in its open beta. This could be a potential game-changer, but I would love to hear experiences from anyone who has used it.\n\nGiven how rapidly the tech landscape changes, I'm sure there might be some gems out there I'm unaware of in 2023. Any insights, recommendations, or experiences with the aforementioned tools (or others) would be hugely appreciated!\n\nThanks in advance!", "author_fullname": "t2_89x2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worthwhile managed EL (Extract-Load) tools in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16cagf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694075654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on a quest to find the best managed EL tools out there. Our home-grown Python scripts have been a significant source of headaches, and with a small team, self-hosting just isn&amp;#39;t viable for us. We are keenly interested in cloud-based solutions to make our life easier.&lt;/p&gt;\n\n&lt;p&gt;So far, here&amp;#39;s what&amp;#39;s on our radar:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Fivetran:&lt;/strong&gt; It appears fairly production-ready and robust, but I have reservations about it being a proprietary system. Additionally, the costs seem to rise significantly given the relatively high active row count (IoT business).&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Airbyte:&lt;/strong&gt; While it seems promising, I&amp;#39;ve observed numerous issues on their GitHub. Moreover, they&amp;#39;re in the midst of rolling out a major update with their V2 destinations.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Meltano:&lt;/strong&gt; I recently discovered they have a &amp;quot;Meltano Cloud&amp;quot; offering currently in its open beta. This could be a potential game-changer, but I would love to hear experiences from anyone who has used it.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Given how rapidly the tech landscape changes, I&amp;#39;m sure there might be some gems out there I&amp;#39;m unaware of in 2023. Any insights, recommendations, or experiences with the aforementioned tools (or others) would be hugely appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16cagf7", "is_robot_indexable": true, "report_reasons": null, "author": "Pranasas", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16cagf7/worthwhile_managed_el_extractload_tools_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16cagf7/worthwhile_managed_el_extractload_tools_in_2023/", "subreddit_subscribers": 127248, "created_utc": 1694075654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my job as a Data Analyst we receive the same data types from each new client. For example, customers, suppliers, etc. We perform ETL and import cleaned and transformed data into our SQL Server. \n\nEach client sends us their data through SFTP in Excel files which my team and I have to manually pick out the columns we need for each data type. \n\nMy question is how do you best standardize the data we receive from clients? Knowing that you know which specific columns you need for each data type?\n\nMy initial idea is to ask clients to fill out a data collection workbook of the columns we specifically need for each data type. But this solution doesn\u2019t seem optimal.\n\nI also want to use SSIS to help automate the ETL process but I haven\u2019t delved in too much on how to use that tool yet.", "author_fullname": "t2_pz85y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to standardize data ingestion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16c2yqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694051709.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694051312.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my job as a Data Analyst we receive the same data types from each new client. For example, customers, suppliers, etc. We perform ETL and import cleaned and transformed data into our SQL Server. &lt;/p&gt;\n\n&lt;p&gt;Each client sends us their data through SFTP in Excel files which my team and I have to manually pick out the columns we need for each data type. &lt;/p&gt;\n\n&lt;p&gt;My question is how do you best standardize the data we receive from clients? Knowing that you know which specific columns you need for each data type?&lt;/p&gt;\n\n&lt;p&gt;My initial idea is to ask clients to fill out a data collection workbook of the columns we specifically need for each data type. But this solution doesn\u2019t seem optimal.&lt;/p&gt;\n\n&lt;p&gt;I also want to use SSIS to help automate the ETL process but I haven\u2019t delved in too much on how to use that tool yet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16c2yqn", "is_robot_indexable": true, "report_reasons": null, "author": "imperialka", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16c2yqn/how_to_standardize_data_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16c2yqn/how_to_standardize_data_ingestion/", "subreddit_subscribers": 127248, "created_utc": 1694051312.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company's data community is pretty much split in two. Over the past year, the majority of the company (lead by AWS ProServe) worked to build up a data mesh architecture with a custom platform used to find and share data in AWS (handling cross account roles and related infrastructure), Data storage is predominantly S3 and compute is predominantly Redshift Serverless. They're also in the final stages of buying a commercial catalog for data governance.\n\nHonestly, *A LOT* of effort was spent on this development, but at the end of the day, the custom platform isn't differentiating, and there's still a lot of manual work needed to connect to the data to run compute on it. Another half of the data community recently decided that they needed a simper out of the box solution, and decided to PoC Databricks, and they'll be building out a data lake with the Unity Catalog, nothing custom, just an out of the box implementation. \n\nHowever, I'm trying to premptivly think of how these two systems can integrate with each other? I'm very experienced in AWS, but much less-so in Databricks... I can easily imagine how S3 data could be shared with a Databricks consuming account, however, from my understanding, Databricks needs files in it's data lake to be of type Delta Lake. Does this mean that we should encourage all data producers to store their data as Delta Lake files? Doing the conversion on an as-needed basis might lead to data duplication and data silos.\n\nAlso, what challenges arise from using Unity Catalog alongside a second data catalog? It seems like a bad idea, but maybe a two-state-solution like this could work? I'm curious if anyone else ever worked around a split ecosystem like this? ", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How easily would Databricks integrate into a mostly AWS backed data ecosystem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16c4yrt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694056902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company&amp;#39;s data community is pretty much split in two. Over the past year, the majority of the company (lead by AWS ProServe) worked to build up a data mesh architecture with a custom platform used to find and share data in AWS (handling cross account roles and related infrastructure), Data storage is predominantly S3 and compute is predominantly Redshift Serverless. They&amp;#39;re also in the final stages of buying a commercial catalog for data governance.&lt;/p&gt;\n\n&lt;p&gt;Honestly, &lt;em&gt;A LOT&lt;/em&gt; of effort was spent on this development, but at the end of the day, the custom platform isn&amp;#39;t differentiating, and there&amp;#39;s still a lot of manual work needed to connect to the data to run compute on it. Another half of the data community recently decided that they needed a simper out of the box solution, and decided to PoC Databricks, and they&amp;#39;ll be building out a data lake with the Unity Catalog, nothing custom, just an out of the box implementation. &lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;m trying to premptivly think of how these two systems can integrate with each other? I&amp;#39;m very experienced in AWS, but much less-so in Databricks... I can easily imagine how S3 data could be shared with a Databricks consuming account, however, from my understanding, Databricks needs files in it&amp;#39;s data lake to be of type Delta Lake. Does this mean that we should encourage all data producers to store their data as Delta Lake files? Doing the conversion on an as-needed basis might lead to data duplication and data silos.&lt;/p&gt;\n\n&lt;p&gt;Also, what challenges arise from using Unity Catalog alongside a second data catalog? It seems like a bad idea, but maybe a two-state-solution like this could work? I&amp;#39;m curious if anyone else ever worked around a split ecosystem like this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16c4yrt", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16c4yrt/how_easily_would_databricks_integrate_into_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16c4yrt/how_easily_would_databricks_integrate_into_a/", "subreddit_subscribers": 127248, "created_utc": 1694056902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any better way to convert (my)SQL dump to parquet than spinning up fresh db instance, restoring the dump and then using something like pyarrow to query and store the data to parquet? We are getting sql dumps but would like to create a parquet for easier analysis", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL dump to parquet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bqtnu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694022521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any better way to convert (my)SQL dump to parquet than spinning up fresh db instance, restoring the dump and then using something like pyarrow to query and store the data to parquet? We are getting sql dumps but would like to create a parquet for easier analysis&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bqtnu", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bqtnu/sql_dump_to_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bqtnu/sql_dump_to_parquet/", "subreddit_subscribers": 127248, "created_utc": 1694022521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I regularly work with a variety of data sources and provide static plots to internal customers.  \n\nI'm familiar with tools like Plotly to create interactive html files, but this requires my handling of the data. I'd like to automate this a bit, but I'm not sure what tools are available for interactive plotting AND data selection. \n\nBasically, I have data that may come from \\*.sie files, \\*.blf, \\*.asc files, \\*.csv files, or other assorted data acquisition tools. Pretty much all of it is time series data.\n\nI think I'd like to create a web interface to view this, but I'm not sure what interactive tools exist to manipulate the channels. A single file may have 50 channels of data. \n\nItems that have crossed my mind:\n\n* An sql server with a database for each datafile. PowerBI to view?\n* Auto-generated web pages from Bokeh, but how do I get user selectable channels?\n* Jupyterhub/Jupyterlab notebooks? \n\n&amp;#x200B;\n\nWhat paid tools exist for engineering?\n\n* I've seen [Aqira](https://www.hbkworld.com/en/products/software/analysis-simulation/durability/aqira-standardize-global-engineering-processes) , but most tools seem to be standalone. \n\nFor reference, an idea of the data source might be a DAQ (data acquisition) tool like\n\n[https://astronovainc.com/our-businesses/test-measurement/](https://astronovainc.com/our-businesses/test-measurement/) \n\n&amp;#x200B;\n\nIf I'm posted in the wrong thread, my apologies. I'm just not really sure where to ask this.", "author_fullname": "t2_3si1p2jc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Providing interactive plots to internal customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bpt8i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694020198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I regularly work with a variety of data sources and provide static plots to internal customers.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m familiar with tools like Plotly to create interactive html files, but this requires my handling of the data. I&amp;#39;d like to automate this a bit, but I&amp;#39;m not sure what tools are available for interactive plotting AND data selection. &lt;/p&gt;\n\n&lt;p&gt;Basically, I have data that may come from *.sie files, *.blf, *.asc files, *.csv files, or other assorted data acquisition tools. Pretty much all of it is time series data.&lt;/p&gt;\n\n&lt;p&gt;I think I&amp;#39;d like to create a web interface to view this, but I&amp;#39;m not sure what interactive tools exist to manipulate the channels. A single file may have 50 channels of data. &lt;/p&gt;\n\n&lt;p&gt;Items that have crossed my mind:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;An sql server with a database for each datafile. PowerBI to view?&lt;/li&gt;\n&lt;li&gt;Auto-generated web pages from Bokeh, but how do I get user selectable channels?&lt;/li&gt;\n&lt;li&gt;Jupyterhub/Jupyterlab notebooks? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What paid tools exist for engineering?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I&amp;#39;ve seen &lt;a href=\"https://www.hbkworld.com/en/products/software/analysis-simulation/durability/aqira-standardize-global-engineering-processes\"&gt;Aqira&lt;/a&gt; , but most tools seem to be standalone. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For reference, an idea of the data source might be a DAQ (data acquisition) tool like&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://astronovainc.com/our-businesses/test-measurement/\"&gt;https://astronovainc.com/our-businesses/test-measurement/&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If I&amp;#39;m posted in the wrong thread, my apologies. I&amp;#39;m just not really sure where to ask this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?auto=webp&amp;s=3a7ccc4fed70f5fe339e0cd18b0f298f562a0dfb", "width": 1200, "height": 645}, "resolutions": [{"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ed7e248fa443fbf4a40cf842d4a3550c1e9c4f2b", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d974297f87b1449299a9ff49a4fbe2b7c19cad3", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=71b78ff8bd0bdf95c43fe90bdcd56d413f6f38e8", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7476c27f219886ac57aafaa693750c5eee321ad", "width": 640, "height": 344}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=487c05c704ee6414bc406fe96d59fafdf86ebc0b", "width": 960, "height": 516}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1b253fbe84c01e1aab3039c90fb616770eb90b2f", "width": 1080, "height": 580}], "variants": {}, "id": "VMbu5D8d3p88J0L0CDm3qmZUYWV6_kEFk-qS4gJuykM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bpt8i", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial_Coyote91", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bpt8i/providing_interactive_plots_to_internal_customers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bpt8i/providing_interactive_plots_to_internal_customers/", "subreddit_subscribers": 127248, "created_utc": 1694020198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data architect for my company and have recently been pulled in to a dept I've not worked with before that is using ADF pipelines for data ingestion through to our CRM and Analytics dbs.  I noticed that there are tables on a Azure SQL Server that have no primary/foreign keys, and no indexes at all. Is this common practice?  I've looked at the pipelines, and yes there is some use of databricks to create dataframes off of the data in the tables, but I still feel like this might be slightly inefficient. I don't have a big DE background, so I figured I'd check with you all. Common practice because you can gain efficiencies through creating python scripts to pull and manage the data from the SQL dbs?  For clarification, these are not temp tables. These are production tables attempting to manage millions of records a day.", "author_fullname": "t2_2v1p3nx2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Un-indexed Azure SQL Server tables used in ADF Pipelines (Is this common?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16c3ezp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694052533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data architect for my company and have recently been pulled in to a dept I&amp;#39;ve not worked with before that is using ADF pipelines for data ingestion through to our CRM and Analytics dbs.  I noticed that there are tables on a Azure SQL Server that have no primary/foreign keys, and no indexes at all. Is this common practice?  I&amp;#39;ve looked at the pipelines, and yes there is some use of databricks to create dataframes off of the data in the tables, but I still feel like this might be slightly inefficient. I don&amp;#39;t have a big DE background, so I figured I&amp;#39;d check with you all. Common practice because you can gain efficiencies through creating python scripts to pull and manage the data from the SQL dbs?  For clarification, these are not temp tables. These are production tables attempting to manage millions of records a day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Architect", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16c3ezp", "is_robot_indexable": true, "report_reasons": null, "author": "No-Current-7884", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16c3ezp/unindexed_azure_sql_server_tables_used_in_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16c3ezp/unindexed_azure_sql_server_tables_used_in_adf/", "subreddit_subscribers": 127248, "created_utc": 1694052533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer setting up dbt for a group of analysts and data scientists. The naming conventions for transformational layers suggested in the dbt docs are:\n\n1. staging\n2. intermediate\n3. marts\n\nTbh, I don't really like these names. Especially staging -- its generic and conflicts with the term staging as a reference to the environment. In past projects (that did not use dbt), I used different naming conventions, but were functionally the same as dbt's in terms of organization:\n\n1. crbo (common reporting business objects)\n   1. this could could be prefixed as stripe\\_crbo, and is almost always suffixed with something like \\_transactions or \\_refunds\n2. core\n   1. also can be prefixed or suffixed in the same manner as crbo\n3. any name that describes the data set, and then its aggregation level\n   1. i.e. stripe\\_transactions\\_by\\_country\\_plan\n\nHow do you structure your dbt layers and what naming conventions do you use? I will probably start out with dbt's conventions, but am interested in other approaches!", "author_fullname": "t2_1p505jz8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Layer Naming Conventions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bulr0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694031133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer setting up dbt for a group of analysts and data scientists. The naming conventions for transformational layers suggested in the dbt docs are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;staging&lt;/li&gt;\n&lt;li&gt;intermediate&lt;/li&gt;\n&lt;li&gt;marts&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Tbh, I don&amp;#39;t really like these names. Especially staging -- its generic and conflicts with the term staging as a reference to the environment. In past projects (that did not use dbt), I used different naming conventions, but were functionally the same as dbt&amp;#39;s in terms of organization:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;crbo (common reporting business objects)\n\n&lt;ol&gt;\n&lt;li&gt;this could could be prefixed as stripe_crbo, and is almost always suffixed with something like _transactions or _refunds&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;core\n\n&lt;ol&gt;\n&lt;li&gt;also can be prefixed or suffixed in the same manner as crbo&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;any name that describes the data set, and then its aggregation level\n\n&lt;ol&gt;\n&lt;li&gt;i.e. stripe_transactions_by_country_plan&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How do you structure your dbt layers and what naming conventions do you use? I will probably start out with dbt&amp;#39;s conventions, but am interested in other approaches!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bulr0", "is_robot_indexable": true, "report_reasons": null, "author": "Fredonia1988", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bulr0/dbt_layer_naming_conventions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bulr0/dbt_layer_naming_conventions/", "subreddit_subscribers": 127248, "created_utc": 1694031133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey data engineering,\n\nWanted to reach out to the community to see how other teams are solving UAT / QC process and challenges when using DBT. \n\nBackground:\n\nOne of the main challenges we run into is that we're often developing net new data sources, updating existing based on feature requests, or updating existing based on bugs found by the business/BI team. A frequent problem is that we will onboard a new data source all the way to production and then a month later the business finally reviews the source and requests changes. \n\nWe already have dev and prod targets configured in our DBT profiles and our CI/CD runs with a --target prod. The --target dev is primarily used by devs locally against a different database. Our current branching strategy is feature -&gt; develop -&gt; master with the --target prod only running on master branch.\n\nProposed Ideas:\n\nWe're thinking this could likely be solved by using a feature -&gt; develop -&gt; uat -&gt; master branching strategy. The biggest drawback here is that is a lot of PRs that have to happen in order to get code to production. And because we ultimately need different models in different databases based on the stage of the development lifecycle we're in, this seems like an \"all or nothing\" approach unless we start cherry-picking or commits to include in merges.\n\nAlternative idea: Use the DBT tagging feature to add tags=\\[\"uat\"\\] for models that still need review/sign-off by the business  and then add an --exclude tag:uat from our normal DBT runs. This way we don't have to increase the complexity of our branching process and could easily tell which step a model is in. The UAT models could either be run by using a --select tag:uat from local systems or via CI/CD.\n\nAsk:\n\nSo data engineering, how do you solve this issue? What does your process look like for going to production? How do you (or do you) wait until you get business sign off even if all dev work has been completed? Any thoughts/approaches appreciated!\n\nThanks!", "author_fullname": "t2_dvuofczh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle UAT / business QC with DBT projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bs3z4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694025452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey data engineering,&lt;/p&gt;\n\n&lt;p&gt;Wanted to reach out to the community to see how other teams are solving UAT / QC process and challenges when using DBT. &lt;/p&gt;\n\n&lt;p&gt;Background:&lt;/p&gt;\n\n&lt;p&gt;One of the main challenges we run into is that we&amp;#39;re often developing net new data sources, updating existing based on feature requests, or updating existing based on bugs found by the business/BI team. A frequent problem is that we will onboard a new data source all the way to production and then a month later the business finally reviews the source and requests changes. &lt;/p&gt;\n\n&lt;p&gt;We already have dev and prod targets configured in our DBT profiles and our CI/CD runs with a --target prod. The --target dev is primarily used by devs locally against a different database. Our current branching strategy is feature -&amp;gt; develop -&amp;gt; master with the --target prod only running on master branch.&lt;/p&gt;\n\n&lt;p&gt;Proposed Ideas:&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re thinking this could likely be solved by using a feature -&amp;gt; develop -&amp;gt; uat -&amp;gt; master branching strategy. The biggest drawback here is that is a lot of PRs that have to happen in order to get code to production. And because we ultimately need different models in different databases based on the stage of the development lifecycle we&amp;#39;re in, this seems like an &amp;quot;all or nothing&amp;quot; approach unless we start cherry-picking or commits to include in merges.&lt;/p&gt;\n\n&lt;p&gt;Alternative idea: Use the DBT tagging feature to add tags=[&amp;quot;uat&amp;quot;] for models that still need review/sign-off by the business  and then add an --exclude tag:uat from our normal DBT runs. This way we don&amp;#39;t have to increase the complexity of our branching process and could easily tell which step a model is in. The UAT models could either be run by using a --select tag:uat from local systems or via CI/CD.&lt;/p&gt;\n\n&lt;p&gt;Ask:&lt;/p&gt;\n\n&lt;p&gt;So data engineering, how do you solve this issue? What does your process look like for going to production? How do you (or do you) wait until you get business sign off even if all dev work has been completed? Any thoughts/approaches appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bs3z4", "is_robot_indexable": true, "report_reasons": null, "author": "I_Blame_DevOps", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bs3z4/how_do_you_handle_uat_business_qc_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bs3z4/how_do_you_handle_uat_business_qc_with_dbt/", "subreddit_subscribers": 127248, "created_utc": 1694025452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do any of your folks have some ideas around how I could attach some data points to my **impression** that \"Delta still 800 pound gorilla, but Iceberg has  momentum, and Hudi is more of a bespoke use case vs. wide adoption\"\n\nI've been googling / chatgpt &amp; claude-ing like crazy and not finding anything really useful to measure true adoption and momentum. There are github stars and commits, but that still is a very tenous connection to real adoption in my mind...\n\nI can't seem to swing a stick these days without hitting some sort of press release about iceberg (Snowflake, Redshift, etc.) and that seems like a leading INDICATOR for adoption, but still not a sure thing...I know I'm not going to get binary with this question, but it still feels too loosey-goosey.\n\n&amp;#x200B;", "author_fullname": "t2_cabpv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Determining Iceberg v. Delta v. Hudi adoption?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16cghib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694094854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do any of your folks have some ideas around how I could attach some data points to my &lt;strong&gt;impression&lt;/strong&gt; that &amp;quot;Delta still 800 pound gorilla, but Iceberg has  momentum, and Hudi is more of a bespoke use case vs. wide adoption&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been googling / chatgpt &amp;amp; claude-ing like crazy and not finding anything really useful to measure true adoption and momentum. There are github stars and commits, but that still is a very tenous connection to real adoption in my mind...&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t seem to swing a stick these days without hitting some sort of press release about iceberg (Snowflake, Redshift, etc.) and that seems like a leading INDICATOR for adoption, but still not a sure thing...I know I&amp;#39;m not going to get binary with this question, but it still feels too loosey-goosey.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16cghib", "is_robot_indexable": true, "report_reasons": null, "author": "JudgingYouThisSecond", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16cghib/determining_iceberg_v_delta_v_hudi_adoption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16cghib/determining_iceberg_v_delta_v_hudi_adoption/", "subreddit_subscribers": 127248, "created_utc": 1694094854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to implement my first data pipeline. I have 7 python scripts that extract and clean api data, then upload to sql server. I\u2019m trying to run these scripts every evening. Should I use Airflow or Alteryx to facilitate this?", "author_fullname": "t2_t45bb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alteryx or airflow for simple API pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bt2oe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694027665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to implement my first data pipeline. I have 7 python scripts that extract and clean api data, then upload to sql server. I\u2019m trying to run these scripts every evening. Should I use Airflow or Alteryx to facilitate this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16bt2oe", "is_robot_indexable": true, "report_reasons": null, "author": "giantdickinmyface", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bt2oe/alteryx_or_airflow_for_simple_api_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bt2oe/alteryx_or_airflow_for_simple_api_pipeline/", "subreddit_subscribers": 127248, "created_utc": 1694027665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I use activ batch for the workload automation in my organization. I used a lot sql agent but not activ batch. I searched for resources to learn this but can't find any resources. Please anybody share the resources if you have used in your job or career. Thanks a lot in advance.", "author_fullname": "t2_5prh8z7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advonsys activbatch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16chsiz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694098151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use activ batch for the workload automation in my organization. I used a lot sql agent but not activ batch. I searched for resources to learn this but can&amp;#39;t find any resources. Please anybody share the resources if you have used in your job or career. Thanks a lot in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16chsiz", "is_robot_indexable": true, "report_reasons": null, "author": "Mrmjix", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16chsiz/advonsys_activbatch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16chsiz/advonsys_activbatch/", "subreddit_subscribers": 127248, "created_utc": 1694098151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been planning to give AWS exams for certifications, although the price of it is just too high for me as a student. If anyone can help me with any sort of discount or promo codes I would highly appreciate it.", "author_fullname": "t2_7wq5o3nd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Certification Fee", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16cgkfi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694095061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been planning to give AWS exams for certifications, although the price of it is just too high for me as a student. If anyone can help me with any sort of discount or promo codes I would highly appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16cgkfi", "is_robot_indexable": true, "report_reasons": null, "author": "Little-Physics-1646", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16cgkfi/aws_certification_fee/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16cgkfi/aws_certification_fee/", "subreddit_subscribers": 127248, "created_utc": 1694095061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mbuz666f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PostgreSQL Bigger != Better", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_16ccnx7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i7r-hqAAwVBRiCAju2_g24Teu8ZLI8xOVMocvIaLqLU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694083821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "epsio.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.epsio.io/blog/postgresql-bigger-better", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fYgbjVe5AQgHOpo5Q-8w_KqpXwrPWFoszbhIDK5W_-k.jpg?auto=webp&amp;s=09671ea5df115485b7fc92f02e16bd28a6d297f2", "width": 2401, "height": 1255}, "resolutions": [{"url": "https://external-preview.redd.it/fYgbjVe5AQgHOpo5Q-8w_KqpXwrPWFoszbhIDK5W_-k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbdfd82efe983f2bb57183ac9957be96e68b301b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fYgbjVe5AQgHOpo5Q-8w_KqpXwrPWFoszbhIDK5W_-k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5c92fbe8b6643cb094fbd2bb56d7773264efa1d1", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/fYgbjVe5AQgHOpo5Q-8w_KqpXwrPWFoszbhIDK5W_-k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ecc8827dbd65aee484b5be92d534cd1d563f441", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/fYgbjVe5AQgHOpo5Q-8w_KqpXwrPWFoszbhIDK5W_-k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac2b22bc7cb5492a2ca1e7bf8d4a51e2905dd367", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/fYgbjVe5AQgHOpo5Q-8w_KqpXwrPWFoszbhIDK5W_-k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4007386a2704ce65441f7c1cf2c30b9f15177f58", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/fYgbjVe5AQgHOpo5Q-8w_KqpXwrPWFoszbhIDK5W_-k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=152fd43fbe21c72d5f2a50eaacb7bbc464f2fe55", "width": 1080, "height": 564}], "variants": {}, "id": "Far3Q5O4VaIR6aOnR3lM0C8HT_ZB-uLJdxi095KBHUU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16ccnx7", "is_robot_indexable": true, "report_reasons": null, "author": "dkgs19982", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ccnx7/postgresql_bigger_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.epsio.io/blog/postgresql-bigger-better", "subreddit_subscribers": 127248, "created_utc": 1694083821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI have a project for which I have to set up a live web scraper for a couple of websites, establish an ETL pipeline, and automate the data preprocessing to get it all into a defined format (the data from the different websites comes in different formats).\n\nI want to use open source frameworks and tools, and the solution must be scalable. Would appreciate suggestions and advice.\n\nI am considering Apache NiFi. Thoughts on this?\n\nThanks in advance :)", "author_fullname": "t2_gaxqj6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up ETL pipelines and data preprocessing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16cc57w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694082009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have a project for which I have to set up a live web scraper for a couple of websites, establish an ETL pipeline, and automate the data preprocessing to get it all into a defined format (the data from the different websites comes in different formats).&lt;/p&gt;\n\n&lt;p&gt;I want to use open source frameworks and tools, and the solution must be scalable. Would appreciate suggestions and advice.&lt;/p&gt;\n\n&lt;p&gt;I am considering Apache NiFi. Thoughts on this?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16cc57w", "is_robot_indexable": true, "report_reasons": null, "author": "yipra97", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16cc57w/setting_up_etl_pipelines_and_data_preprocessing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16cc57w/setting_up_etl_pipelines_and_data_preprocessing/", "subreddit_subscribers": 127248, "created_utc": 1694082009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I was asked to create an Audit Trail on the Master table where all the information about a specific product is stored , so I used a trigger to capture all the changes that were made on the table , the trigger was working perfectly in the testing environment but in production during the night time something happened and all the process were slowed and stopped , the db owner deleted the trigger which in turn deleted all the log history of the trigger, so no I am unable to figure out why that happened, can you guys please guide me", "author_fullname": "t2_4p2t0v0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using a trigger not the way to capture Audit Trail?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16c7ouo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694065538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I was asked to create an Audit Trail on the Master table where all the information about a specific product is stored , so I used a trigger to capture all the changes that were made on the table , the trigger was working perfectly in the testing environment but in production during the night time something happened and all the process were slowed and stopped , the db owner deleted the trigger which in turn deleted all the log history of the trigger, so no I am unable to figure out why that happened, can you guys please guide me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16c7ouo", "is_robot_indexable": true, "report_reasons": null, "author": "omghag18", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16c7ouo/using_a_trigger_not_the_way_to_capture_audit_trail/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16c7ouo/using_a_trigger_not_the_way_to_capture_audit_trail/", "subreddit_subscribers": 127248, "created_utc": 1694065538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\nIs there a way to find out who executed which query at a workspace level? Is there any logs which can be read into a dataframe to extract this  information? I can see the users in query history tab within the UI so is it possible pull this info into a dataframe?\nThank you!", "author_fullname": "t2_f1s7yw3kw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks - Identify who executed the query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16c61uw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694060162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,\nIs there a way to find out who executed which query at a workspace level? Is there any logs which can be read into a dataframe to extract this  information? I can see the users in query history tab within the UI so is it possible pull this info into a dataframe?\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16c61uw", "is_robot_indexable": true, "report_reasons": null, "author": "fusebox12345", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16c61uw/databricks_identify_who_executed_the_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16c61uw/databricks_identify_who_executed_the_query/", "subreddit_subscribers": 127248, "created_utc": 1694060162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say I have 50 tables which each need 2 tasks in a workflow. I currently have a initial bulk load workflow with the 100 tasks required. How/would this change with a near real time requirement? Workflow for each table? Continuously run the workflow I already have? Just trying to understand what best practice is here. My apologies in advance if these are dumb questions. I don't have much experience with orchestration. Thanks", "author_fullname": "t2_feymqzcjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Workflow Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bxhcj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694037536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I have 50 tables which each need 2 tasks in a workflow. I currently have a initial bulk load workflow with the 100 tasks required. How/would this change with a near real time requirement? Workflow for each table? Continuously run the workflow I already have? Just trying to understand what best practice is here. My apologies in advance if these are dumb questions. I don&amp;#39;t have much experience with orchestration. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16bxhcj", "is_robot_indexable": true, "report_reasons": null, "author": "TheConSpooky", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bxhcj/databricks_workflow_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bxhcj/databricks_workflow_question/", "subreddit_subscribers": 127248, "created_utc": 1694037536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j68228u1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Developing an Elo Based, Data-Driven Ranking System for 2v2 Multiplayer Games", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_16bvy7e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9gfc6HTFq8-nNnNMoMJBOeCQVc9o1ZcyzxfdIWTYyMk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694034075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@lazarekolebka/developing-an-elo-based-data-driven-ranking-system-for-2v2-multiplayer-games-7689f7d42a53", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hHBXFuPqYtYEmlpBVtFMA3Am5JvJ17qZ8gXVRRF8BRA.jpg?auto=webp&amp;s=c0bd3da4d3611b3e1117c469f22addc41b5df10a", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/hHBXFuPqYtYEmlpBVtFMA3Am5JvJ17qZ8gXVRRF8BRA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec62a37864fa95077a312b7028165478361ca38f", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/hHBXFuPqYtYEmlpBVtFMA3Am5JvJ17qZ8gXVRRF8BRA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff7a20bd2e5b26d2ac66339264d6e921c7162479", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/hHBXFuPqYtYEmlpBVtFMA3Am5JvJ17qZ8gXVRRF8BRA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=16b4d444ad60041d878c8baeb1c319b3897d2ab9", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/hHBXFuPqYtYEmlpBVtFMA3Am5JvJ17qZ8gXVRRF8BRA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cd5f2bac301ffdd333d8cb2e53464935edc756b2", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/hHBXFuPqYtYEmlpBVtFMA3Am5JvJ17qZ8gXVRRF8BRA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e7d8b8fd5b708813c03f8c9e45b64c30f461dd5", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/hHBXFuPqYtYEmlpBVtFMA3Am5JvJ17qZ8gXVRRF8BRA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=52f1bddb3d8d712d063ab62ad3c33e4053ef987a", "width": 1080, "height": 720}], "variants": {}, "id": "LatcCAz20Bz3Y65ssYat9EM3WANhjc5gqXqo7blclXA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16bvy7e", "is_robot_indexable": true, "report_reasons": null, "author": "Bulky-Violinist7187", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bvy7e/developing_an_elo_based_datadriven_ranking_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@lazarekolebka/developing-an-elo-based-data-driven-ranking-system-for-2v2-multiplayer-games-7689f7d42a53", "subreddit_subscribers": 127248, "created_utc": 1694034075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I'm new to Airflow and I just want to know if I'm on the right track.  \nI have an ETL project, with each step in its directory (extract, transform, load), and each directory has a Python script that runs in a Docker container. In other words, I have a docker-compose.yml for each stage, and I simply run 'docker-compose up' one by one to run each stage.  \nNow I want to automate this with Airflow. To do that, I'm running Airflow in Docker as shown in the documentation.  \nThen, to execute each stage, I was planning to use DockerOperators. However, in all the examples and tutorials I've seen, they call a pre-built image and then run it. What I wanted to do is to execute 'docker-compose up --build' for each directory without the need to build the image beforehand and publish it.  \nBut it seems that I need to mount the docker socket inside the Airflow container for this to make it work.  \nDoes that make sense, or am I making it too complicated? ", "author_fullname": "t2_y5ux0rs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "inquiry about Apache Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bp0iq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694018306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I&amp;#39;m new to Airflow and I just want to know if I&amp;#39;m on the right track.&lt;br/&gt;\nI have an ETL project, with each step in its directory (extract, transform, load), and each directory has a Python script that runs in a Docker container. In other words, I have a docker-compose.yml for each stage, and I simply run &amp;#39;docker-compose up&amp;#39; one by one to run each stage.&lt;br/&gt;\nNow I want to automate this with Airflow. To do that, I&amp;#39;m running Airflow in Docker as shown in the documentation.&lt;br/&gt;\nThen, to execute each stage, I was planning to use DockerOperators. However, in all the examples and tutorials I&amp;#39;ve seen, they call a pre-built image and then run it. What I wanted to do is to execute &amp;#39;docker-compose up --build&amp;#39; for each directory without the need to build the image beforehand and publish it.&lt;br/&gt;\nBut it seems that I need to mount the docker socket inside the Airflow container for this to make it work.&lt;br/&gt;\nDoes that make sense, or am I making it too complicated? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16bp0iq", "is_robot_indexable": true, "report_reasons": null, "author": "johnthepostman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bp0iq/inquiry_about_apache_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bp0iq/inquiry_about_apache_airflow/", "subreddit_subscribers": 127248, "created_utc": 1694018306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nThis is a throwaway from the Midwest USA.\n\nI would like you opinions on what my next move should be. I am looking for a position as a data engineer primarily to improve on my skills in Python and because I like to build systems. I have an engineering degree but not in data or computer engineering so I'm self taught in those regards. These past few months I've been interviewing with a few companies and one of them has recently sent me an offer. I cannot give the name of the company but it is a world leader in the manufacturing sector and I was offered roughly $80k in the midwest. There are three more companies that I am interviewing for and two of them have given me coding tests that should be completed this week. One of those companies is a smaller company working in clean energy and the other is a fortune 500 also in manufacturing. I know that the other two companies would pay about $15k - $25k more per year. That is mostly because I was unprepared in salary negotiations and said the number I was comfortable with instead of fair market value for my area and because the fortune 500 had their salary band posted.\n\nMy question is should I accept my first and only offer while finishing the interviews for the other three companies or just inform them that I have accepted an offer elsewhere and thank them for their time? All these positions are remote and two have headquarters within 2hrs drive of me. Also, and this is huge, I have a felony that is over 9 yrs old but I used to have problems with my background check. My records used to get mixed up because some companies only cross referenced first and last names. I was recently let go from my previous employer and I think the BG check was why, I was a data engineer for them. It was a non-violent offence. As you can imagine getting a job has been hellish for me so please do not judge me on my previous offense.\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_hodibk40d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice PLZ. Should I continue interviewing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bo4e8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694016228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;This is a throwaway from the Midwest USA.&lt;/p&gt;\n\n&lt;p&gt;I would like you opinions on what my next move should be. I am looking for a position as a data engineer primarily to improve on my skills in Python and because I like to build systems. I have an engineering degree but not in data or computer engineering so I&amp;#39;m self taught in those regards. These past few months I&amp;#39;ve been interviewing with a few companies and one of them has recently sent me an offer. I cannot give the name of the company but it is a world leader in the manufacturing sector and I was offered roughly $80k in the midwest. There are three more companies that I am interviewing for and two of them have given me coding tests that should be completed this week. One of those companies is a smaller company working in clean energy and the other is a fortune 500 also in manufacturing. I know that the other two companies would pay about $15k - $25k more per year. That is mostly because I was unprepared in salary negotiations and said the number I was comfortable with instead of fair market value for my area and because the fortune 500 had their salary band posted.&lt;/p&gt;\n\n&lt;p&gt;My question is should I accept my first and only offer while finishing the interviews for the other three companies or just inform them that I have accepted an offer elsewhere and thank them for their time? All these positions are remote and two have headquarters within 2hrs drive of me. Also, and this is huge, I have a felony that is over 9 yrs old but I used to have problems with my background check. My records used to get mixed up because some companies only cross referenced first and last names. I was recently let go from my previous employer and I think the BG check was why, I was a data engineer for them. It was a non-violent offence. As you can imagine getting a job has been hellish for me so please do not judge me on my previous offense.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16bo4e8", "is_robot_indexable": true, "report_reasons": null, "author": "Just-Example-598", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bo4e8/career_advice_plz_should_i_continue_interviewing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bo4e8/career_advice_plz_should_i_continue_interviewing/", "subreddit_subscribers": 127248, "created_utc": 1694016228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone able to help to compile the list of mirena IUD complaints by category &amp; # to the FDA? Is this a public doc record request? Pls &amp; Thank you!", "author_fullname": "t2_7t3g1vqch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data help\u2014FDA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bo28a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694016096.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone able to help to compile the list of mirena IUD complaints by category &amp;amp; # to the FDA? Is this a public doc record request? Pls &amp;amp; Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16bo28a", "is_robot_indexable": true, "report_reasons": null, "author": "NYCBoston", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bo28a/data_helpfda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bo28a/data_helpfda/", "subreddit_subscribers": 127248, "created_utc": 1694016096.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Saw this on LinkedIn, it is simple, but seems handy when trying to figure out the arguments for dbt-utils macros\n\nhttps://datacoves.com/post/dbt-utils-cheatsheet", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt-utils macros cheat sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bnjw2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694014895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Saw this on LinkedIn, it is simple, but seems handy when trying to figure out the arguments for dbt-utils macros&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datacoves.com/post/dbt-utils-cheatsheet\"&gt;https://datacoves.com/post/dbt-utils-cheatsheet&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?auto=webp&amp;s=c72294a445c689d26088117fc5fff4bb905f488d", "width": 2400, "height": 1254}, "resolutions": [{"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7997828bba9f07448ccf1bc5fc04e76033b71944", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7195abbc2a5d6cdc443796e0ed5f9086f845e24d", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=33d24d3f4487eaf5c747d62b56db72b2c8b84ebf", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=545aeb79a24b1e25d483c5cd733b6ca413f25389", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7207869fedc316bad07e0b593dcb7995e5baae33", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=42828b93ff9d50484b7639ebe782f4de5c04e40c", "width": 1080, "height": 564}], "variants": {}, "id": "fRjQkbaAYceSqHYVE-NBwTYR2ZoPUS8MUARvVnek75k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16bnjw2", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bnjw2/dbtutils_macros_cheat_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bnjw2/dbtutils_macros_cheat_sheet/", "subreddit_subscribers": 127248, "created_utc": 1694014895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have reached out to Joe Reis on a number of occasions to discuss all things data engineering, wanted to share that experience hasn't been wholly positive. Most discussions just ended up in buy my book it's the bible, or attend my event. Appreciate time is money in a capitalistic society but he's far from the authority on Data Engineering. Keen to hear other people's thoughts on this.", "author_fullname": "t2_eq09r4vmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Experience with Joe Reis is that he's only in it for book sales or conference seats", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16cgbp7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.21, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694094444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have reached out to Joe Reis on a number of occasions to discuss all things data engineering, wanted to share that experience hasn&amp;#39;t been wholly positive. Most discussions just ended up in buy my book it&amp;#39;s the bible, or attend my event. Appreciate time is money in a capitalistic society but he&amp;#39;s far from the authority on Data Engineering. Keen to hear other people&amp;#39;s thoughts on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16cgbp7", "is_robot_indexable": true, "report_reasons": null, "author": "fackingirish", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16cgbp7/my_experience_with_joe_reis_is_that_hes_only_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16cgbp7/my_experience_with_joe_reis_is_that_hes_only_in/", "subreddit_subscribers": 127248, "created_utc": 1694094444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey data friends\u00a0\ud83d\udc4b\n\nI'm super excited to to share a preview of some new stuff I'm working on: \u2728\u00a0Turntable Discover \u2728\n\nData teams struggle to keep their documentation up to date and actionable. Today they have to stitch together Notion docs, lineage tools, yaml / markdown files and maintain jobs to generate it.\n\nWe\u2019ve built a seamless way to ingest, discover, and share your warehouse's documentation all in one place. Discover is integrated with Github and dbt core, so you can get setup with a magical docs experience in only a few minutes including:\n\n\u26a1\ufe0f Super fast search - search across table names, column, descriptions and canonical sql to find the data you're looking for\n\n\u2728\ufe0f AI-powered semantic search - can't find a substring query that matches? Use semantic search to find data models that are tricky to find (ex: \"reps\" -&gt; \"sales people\")\n\n\ud83d\udd2cColumn-level lineage view - trace back the origins of a particular column and navigate across models with an inline column level lineage view\n\n\ud83d\udd17\u00a0One-click sharing - share documentation in one click with other teammates on the same OAuth domain\n\nWe\u2019re giving Discover to select teams in a private beta before rolling it out broadly. If you\u2019d like to try it out, you can DM, comment below, or sign up on our waitlist ([turntable.so](http://turntable.so/)) Looking forward to hearing your feedback \ud83d\ude4c\n\nCheck out a quick demo of how it works here:\n\n[https://www.youtube.com/watch?v=sY0NefWRpKQ](https://www.youtube.com/watch?v=sY0NefWRpKQ)", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A fast, shareable, and AI-powered docs catalog for dbt Core", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bmnos", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694012748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey data friends\u00a0\ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m super excited to to share a preview of some new stuff I&amp;#39;m working on: \u2728\u00a0Turntable Discover \u2728&lt;/p&gt;\n\n&lt;p&gt;Data teams struggle to keep their documentation up to date and actionable. Today they have to stitch together Notion docs, lineage tools, yaml / markdown files and maintain jobs to generate it.&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve built a seamless way to ingest, discover, and share your warehouse&amp;#39;s documentation all in one place. Discover is integrated with Github and dbt core, so you can get setup with a magical docs experience in only a few minutes including:&lt;/p&gt;\n\n&lt;p&gt;\u26a1\ufe0f Super fast search - search across table names, column, descriptions and canonical sql to find the data you&amp;#39;re looking for&lt;/p&gt;\n\n&lt;p&gt;\u2728\ufe0f AI-powered semantic search - can&amp;#39;t find a substring query that matches? Use semantic search to find data models that are tricky to find (ex: &amp;quot;reps&amp;quot; -&amp;gt; &amp;quot;sales people&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd2cColumn-level lineage view - trace back the origins of a particular column and navigate across models with an inline column level lineage view&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd17\u00a0One-click sharing - share documentation in one click with other teammates on the same OAuth domain&lt;/p&gt;\n\n&lt;p&gt;We\u2019re giving Discover to select teams in a private beta before rolling it out broadly. If you\u2019d like to try it out, you can DM, comment below, or sign up on our waitlist (&lt;a href=\"http://turntable.so/\"&gt;turntable.so&lt;/a&gt;) Looking forward to hearing your feedback \ud83d\ude4c&lt;/p&gt;\n\n&lt;p&gt;Check out a quick demo of how it works here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=sY0NefWRpKQ\"&gt;https://www.youtube.com/watch?v=sY0NefWRpKQ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16bmnos", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bmnos/a_fast_shareable_and_aipowered_docs_catalog_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bmnos/a_fast_shareable_and_aipowered_docs_catalog_for/", "subreddit_subscribers": 127248, "created_utc": 1694012748.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}