{"kind": "Listing", "data": {"after": "t3_16n3qwk", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Here's my list of what's missing and what can still be purchased. [https://easyupload.io/3t6upo](https://easyupload.io/3t6upo) If the link is down just PM me for it.\n\nI''ve been trying to archive all the lost DLC for years and it's important to preserve it all before it's too late.\n\nIf you want to help, Please check your download history to see if you own anything from my list.\n\nAll you need is a usb drive formatted for xbox to copy the DLC and then file share the content folder.\n\nPlease consider to donate just $1 to help me purchase lost content. [https://www.microsoft.com/en-us/p/xbox-gift-card-digital-code/cfq7ttc0k63h/0002?activetab=pivot:overviewtab](https://www.microsoft.com/en-us/p/xbox-gift-card-digital-code/cfq7ttc0k63h/0002?activetab=pivot:overviewtab)\n\nThank You!", "author_fullname": "t2_584b5xa4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time is running out! Help me preserve Xbox 360 content before the 360 Marketplace closes July 2024.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n7l0g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 100, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 100, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695171118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s my list of what&amp;#39;s missing and what can still be purchased. &lt;a href=\"https://easyupload.io/3t6upo\"&gt;https://easyupload.io/3t6upo&lt;/a&gt; If the link is down just PM me for it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;&amp;#39;ve been trying to archive all the lost DLC for years and it&amp;#39;s important to preserve it all before it&amp;#39;s too late.&lt;/p&gt;\n\n&lt;p&gt;If you want to help, Please check your download history to see if you own anything from my list.&lt;/p&gt;\n\n&lt;p&gt;All you need is a usb drive formatted for xbox to copy the DLC and then file share the content folder.&lt;/p&gt;\n\n&lt;p&gt;Please consider to donate just $1 to help me purchase lost content. &lt;a href=\"https://www.microsoft.com/en-us/p/xbox-gift-card-digital-code/cfq7ttc0k63h/0002?activetab=pivot:overviewtab\"&gt;https://www.microsoft.com/en-us/p/xbox-gift-card-digital-code/cfq7ttc0k63h/0002?activetab=pivot:overviewtab&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank You!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vshir43JRCmc4_fZluMPPDr-VXeX5S1C364cWG5uYhs.jpg?auto=webp&amp;s=cf2d46f580e043f95380b8fb0ccc5e341eba76c1", "width": 210, "height": 80}, "resolutions": [{"url": "https://external-preview.redd.it/vshir43JRCmc4_fZluMPPDr-VXeX5S1C364cWG5uYhs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5809f6ce30675ac800ee03d31191923b1b6d245b", "width": 108, "height": 41}], "variants": {}, "id": "iQQyg5CKKXH-zNe6lCGbk6MEyBjG4WNJjKWS__YzU8Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16n7l0g", "is_robot_indexable": true, "report_reasons": null, "author": "KJxbox", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n7l0g/time_is_running_out_help_me_preserve_xbox_360/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n7l0g/time_is_running_out_help_me_preserve_xbox_360/", "subreddit_subscribers": 702880, "created_utc": 1695171118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Demo of scraping Zillow, for sale listings](https://i.redd.it/7jkq3j48b9pb1.gif)\n\nHey everyone,\n\nMy friend and I put together a python real estate scraper that aggregates listings from Zillow, Realtor.com &amp; Redfin. It's requests-based, and quite fast (relative to the search size). You can search for rentals, properties for sale, or those recently sold. And it's super easy to output to csv /excel with to\\_csv() or to\\_excel()\n\nFeel free to give feedback in the comments, we would love to hear your suggestions.\n\nhttps://github.com/ZacharyHampton/HomeHarvest", "author_fullname": "t2_cqwm42f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real estate scraping library for Zillow, Realtor.com &amp; Redfin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7jkq3j48b9pb1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/7jkq3j48b9pb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=a3dcbbff20a22d059aa0ca4412327d8b304463a8"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/7jkq3j48b9pb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=4a772454f9e81b8469884058387a85b12bd98305"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/7jkq3j48b9pb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=0010f7c672d0bc5f7e6fb271c70671fa9e6374e4"}], "s": {"y": 338, "gif": "https://i.redd.it/7jkq3j48b9pb1.gif", "mp4": "https://preview.redd.it/7jkq3j48b9pb1.gif?format=mp4&amp;s=de3b40625ac9b5e2fde5381b2b26d783d8463c49", "x": 600}, "id": "7jkq3j48b9pb1"}}, "name": "t3_16myrgh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pFXwO_yHx6Rx7SOoJ3QD0Io6fpTaMHmqFEdyW85D_30.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695148753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://i.redd.it/7jkq3j48b9pb1.gif\"&gt;Demo of scraping Zillow, for sale listings&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;My friend and I put together a python real estate scraper that aggregates listings from Zillow, Realtor.com &amp;amp; Redfin. It&amp;#39;s requests-based, and quite fast (relative to the search size). You can search for rentals, properties for sale, or those recently sold. And it&amp;#39;s super easy to output to csv /excel with to_csv() or to_excel()&lt;/p&gt;\n\n&lt;p&gt;Feel free to give feedback in the comments, we would love to hear your suggestions.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ZacharyHampton/HomeHarvest\"&gt;https://github.com/ZacharyHampton/HomeHarvest&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16myrgh", "is_robot_indexable": true, "report_reasons": null, "author": "socialretro", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16myrgh/real_estate_scraping_library_for_zillow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16myrgh/real_estate_scraping_library_for_zillow/", "subreddit_subscribers": 702880, "created_utc": 1695148753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "  \n Hello all.\n\nI recently purchased 4 HC560 20TB data center hard drives. I have 4 SilverStone TS07 external USB cases 12v powered which have the Asmedia ASM1051E SATA to USB chip, connected to a Raspberry Pi4B running OMV6.\n\n3 of the HDD gets recognised correctly on OMV while 1 of them do not. Unforntunately I do not have access to a SATA interface for further testing.\n\nI have tried to swap the external cases and cables from 1 of the working HDD to the 1 of the unrecognised one. I have tried to run the unrecognised HDD as the only drive connected. None of them works.\n\nThe output of dmesg whenever I connect a working drive is as follows:\n\n[Working HDD](https://preview.redd.it/on82fbhhc8pb1.png?width=960&amp;format=png&amp;auto=webp&amp;s=50204a6882fe20ab31dd558e15b156301ad930ee)\n\n The output of dmesg whenever I connect the unrecognised drive is as follows: \n\n[Faulty HDD](https://preview.redd.it/xtln60qnc8pb1.png?width=939&amp;format=png&amp;auto=webp&amp;s=64146440907b8ae85e54625d79ec7ba823e74f3f)\n\nAs you see, at half the spinning disk operation, it gest halted and removed. The HDD \"sounds\" as it is working and gets somewhat warm as the working drives, but it does not show on fdisk or OMV disk GUI. The other 3 HDD work perfectly, they got all ext4 formatted and I have them running. I assume the controller is ok but some mechanical component is not.\n\nDo I have something left to test or should I already RMA it?\n\nThanks in advance.", "author_fullname": "t2_14jgu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just bought 4x20TB, machine does not recognise external USB HDD on fdisk and got dmesg errors (DOA?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 44, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xtln60qnc8pb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e43f96d9144d4935e509c8439c8305ed60eb586d"}, {"y": 73, "x": 216, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b76184379c961f983a98f3e42df8edebfb11a2a8"}, {"y": 109, "x": 320, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d74c8954bedaa63e8e9cd87ae9a48c1645f881b"}, {"y": 218, "x": 640, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bcb66d5e59318c4ab660bedf44a3170ba327cae7"}], "s": {"y": 320, "x": 939, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=939&amp;format=png&amp;auto=webp&amp;s=64146440907b8ae85e54625d79ec7ba823e74f3f"}, "id": "xtln60qnc8pb1"}, "on82fbhhc8pb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8284055b9b54f503f8469e567f9692825dc9924e"}, {"y": 68, "x": 216, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2f5b56d1208bf6f7d8a3d9b6758c72e840d17fc4"}, {"y": 101, "x": 320, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=33b7cdf9152cc8ed8697388359af363eb40e8405"}, {"y": 202, "x": 640, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0bd27a880403add91929630d6a0eecd401a5a9f7"}, {"y": 303, "x": 960, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=385df6bf00ec7efd8beb9bda5f2bf53c4d5d942e"}], "s": {"y": 303, "x": 960, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=960&amp;format=png&amp;auto=webp&amp;s=50204a6882fe20ab31dd558e15b156301ad930ee"}, "id": "on82fbhhc8pb1"}}, "name": "t3_16mtz19", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cTKsnFpROg3xX9j9TkOJq-SrBdBrgm9oD0B-FXIvzes.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695137092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all.&lt;/p&gt;\n\n&lt;p&gt;I recently purchased 4 HC560 20TB data center hard drives. I have 4 SilverStone TS07 external USB cases 12v powered which have the Asmedia ASM1051E SATA to USB chip, connected to a Raspberry Pi4B running OMV6.&lt;/p&gt;\n\n&lt;p&gt;3 of the HDD gets recognised correctly on OMV while 1 of them do not. Unforntunately I do not have access to a SATA interface for further testing.&lt;/p&gt;\n\n&lt;p&gt;I have tried to swap the external cases and cables from 1 of the working HDD to the 1 of the unrecognised one. I have tried to run the unrecognised HDD as the only drive connected. None of them works.&lt;/p&gt;\n\n&lt;p&gt;The output of dmesg whenever I connect a working drive is as follows:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/on82fbhhc8pb1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=50204a6882fe20ab31dd558e15b156301ad930ee\"&gt;Working HDD&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The output of dmesg whenever I connect the unrecognised drive is as follows: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xtln60qnc8pb1.png?width=939&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64146440907b8ae85e54625d79ec7ba823e74f3f\"&gt;Faulty HDD&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As you see, at half the spinning disk operation, it gest halted and removed. The HDD &amp;quot;sounds&amp;quot; as it is working and gets somewhat warm as the working drives, but it does not show on fdisk or OMV disk GUI. The other 3 HDD work perfectly, they got all ext4 formatted and I have them running. I assume the controller is ok but some mechanical component is not.&lt;/p&gt;\n\n&lt;p&gt;Do I have something left to test or should I already RMA it?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mtz19", "is_robot_indexable": true, "report_reasons": null, "author": "jfromeo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mtz19/just_bought_4x20tb_machine_does_not_recognise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mtz19/just_bought_4x20tb_machine_does_not_recognise/", "subreddit_subscribers": 702880, "created_utc": 1695137092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using FFS for over a decade and love the UI. My employer IS security team recently won't let me use FreeFileSync because they say it's a security issue. That it contains malicious files. I even tried to run it as a portable app but it's still an issue. What is a good paid alternative?", "author_fullname": "t2_4ea5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some alternatives to FreeFileSync?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mzr3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695151163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using FFS for over a decade and love the UI. My employer IS security team recently won&amp;#39;t let me use FreeFileSync because they say it&amp;#39;s a security issue. That it contains malicious files. I even tried to run it as a portable app but it&amp;#39;s still an issue. What is a good paid alternative?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mzr3a", "is_robot_indexable": true, "report_reasons": null, "author": "videonerd", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mzr3a/what_are_some_alternatives_to_freefilesync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mzr3a/what_are_some_alternatives_to_freefilesync/", "subreddit_subscribers": 702880, "created_utc": 1695151163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As in the title--what is the most durable storage available to consumers?\n\nSeveral years ago, I lost a terabyte of data on my WD portable disk. Happened overnight. One day everything worked, the next it was gone. All of it.\n\nI heard that CDs and DVDs have a lifespan of merely a few years, while SSD disks can withstand a specific number of writes after which they become useless. That leaves vinyl and floppy disks.\n\nUnless I don't know about something? Any storage robust enough to keep going for decades, preferably a lifetime?", "author_fullname": "t2_fvy5hh2jl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The most durable consumer storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n3xkq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695161329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As in the title--what is the most durable storage available to consumers?&lt;/p&gt;\n\n&lt;p&gt;Several years ago, I lost a terabyte of data on my WD portable disk. Happened overnight. One day everything worked, the next it was gone. All of it.&lt;/p&gt;\n\n&lt;p&gt;I heard that CDs and DVDs have a lifespan of merely a few years, while SSD disks can withstand a specific number of writes after which they become useless. That leaves vinyl and floppy disks.&lt;/p&gt;\n\n&lt;p&gt;Unless I don&amp;#39;t know about something? Any storage robust enough to keep going for decades, preferably a lifetime?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n3xkq", "is_robot_indexable": true, "report_reasons": null, "author": "satsumander", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n3xkq/the_most_durable_consumer_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n3xkq/the_most_durable_consumer_storage/", "subreddit_subscribers": 702880, "created_utc": 1695161329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Truenas Scale 23.10 - COBIA - RC.1 released with dRAID support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16n3bpo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_jz78l", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eD9b0eW8RaWcGHLJNaQd_MCH8jTYpS-alvz4xqJwr0w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "truenas", "selftext": "", "author_fullname": "t2_jz78l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Truenas Scale 23.10 - COBIA - RC.1 released with dRAID support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/truenas", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16n2sig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "SCALE", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eD9b0eW8RaWcGHLJNaQd_MCH8jTYpS-alvz4xqJwr0w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695158387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "truenas.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?auto=webp&amp;s=d3173fa97c4b79ffa0d7c247c564a285a3d49826", "width": 1999, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f18dee47f6658d0b8337f71005b1544365e0e2de", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb2ca363e1cb21ffd89c5ec1ec41ce65aa8dec04", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20b7079869410a7926ef0862b30d644321ae6c6c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bafa86a81d086fe1386c4a7355b81ee29e3fe5d6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6f164ac0818c91538ce9b3259ad4e8f75dd7309", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19c46d5c9b9f5b541d03eecbf1c207362186cecb", "width": 1080, "height": 540}], "variants": {}, "id": "DtooFloJDixg7EB9_jpX05nkPJvBxs1hrPittQcBWJk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "73c79b60-012a-11ec-84c2-3a09d751311e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_zna4k", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0090d5", "id": "16n2sig", "is_robot_indexable": true, "report_reasons": null, "author": "macvirii", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/truenas/comments/16n2sig/truenas_scale_2310_cobia_rc1_released_with_draid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "subreddit_subscribers": 26579, "created_utc": 1695158387.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1695159740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "truenas.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?auto=webp&amp;s=d3173fa97c4b79ffa0d7c247c564a285a3d49826", "width": 1999, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f18dee47f6658d0b8337f71005b1544365e0e2de", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb2ca363e1cb21ffd89c5ec1ec41ce65aa8dec04", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20b7079869410a7926ef0862b30d644321ae6c6c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bafa86a81d086fe1386c4a7355b81ee29e3fe5d6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6f164ac0818c91538ce9b3259ad4e8f75dd7309", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19c46d5c9b9f5b541d03eecbf1c207362186cecb", "width": 1080, "height": 540}], "variants": {}, "id": "DtooFloJDixg7EB9_jpX05nkPJvBxs1hrPittQcBWJk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n3bpo", "is_robot_indexable": true, "report_reasons": null, "author": "macvirii", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_16n2sig", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n3bpo/truenas_scale_2310_cobia_rc1_released_with_draid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "subreddit_subscribers": 702880, "created_utc": 1695159740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know it's been there decades and I've used it back in the day. But recently I've been trying to download lots of videos together and I have been having lots of issues with Internet Download Manager like downloads failing because of timeouts, security connection establishment failure, etc. so had to manually restart them by starting from scratch again. \n\nIs there anything better out there? Preferably freeware that can handle the workload of downloading lots of files at once. Also, ideally would like something that can somewhat automate the download process if I can point to it what quality of video file to capture from a login site for example 2160p, etc.\n\nWould be great to have any leads out there. I have no technical knowledge so can't do command line, unfortunately.", "author_fullname": "t2_ffjtxxr5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anything better than IDM (Internet Download Manager) out there?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n0wg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695153936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s been there decades and I&amp;#39;ve used it back in the day. But recently I&amp;#39;ve been trying to download lots of videos together and I have been having lots of issues with Internet Download Manager like downloads failing because of timeouts, security connection establishment failure, etc. so had to manually restart them by starting from scratch again. &lt;/p&gt;\n\n&lt;p&gt;Is there anything better out there? Preferably freeware that can handle the workload of downloading lots of files at once. Also, ideally would like something that can somewhat automate the download process if I can point to it what quality of video file to capture from a login site for example 2160p, etc.&lt;/p&gt;\n\n&lt;p&gt;Would be great to have any leads out there. I have no technical knowledge so can&amp;#39;t do command line, unfortunately.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n0wg6", "is_robot_indexable": true, "report_reasons": null, "author": "101az", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n0wg6/anything_better_than_idm_internet_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n0wg6/anything_better_than_idm_internet_download/", "subreddit_subscribers": 702880, "created_utc": 1695153936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone. I would like to hear the opinion from this community about choosing disks for a new NAS. To put it simply, i want to build a tiny home NAS server, and based on my budget i can go with 2 options for the storage. A) Buy 4 new 2TB disks. B) Buy 4 used 4TB disks. (they are about 40k hours old, around 5 years of usage). What option would you go for and why? Thank you!", "author_fullname": "t2_ah3xat1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Used or new drives for a small NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n09g6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695152397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I would like to hear the opinion from this community about choosing disks for a new NAS. To put it simply, i want to build a tiny home NAS server, and based on my budget i can go with 2 options for the storage. A) Buy 4 new 2TB disks. B) Buy 4 used 4TB disks. (they are about 40k hours old, around 5 years of usage). What option would you go for and why? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n09g6", "is_robot_indexable": true, "report_reasons": null, "author": "CamaronSantuchi", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n09g6/used_or_new_drives_for_a_small_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n09g6/used_or_new_drives_for_a_small_nas/", "subreddit_subscribers": 702880, "created_utc": 1695152397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "if you had varying budgets, what would be your dream setup that you would build yourself? And would be your use case for it?\n\n&amp;#x200B;\n\nif I had more money lying around then I knew what to do with this is what I'd get: [Supermicro SuperStorage Server 6049P-E1CR36L - 36x SATA/SAS - LSI 3008 12G SAS - Dual 10-Gigabit Ethernet](https://www.thinkmate.com/system/superstorage-server-6049p-e1cr36l), and throw 36 x 22TB drives in a RAID 6 and 2x 4TB NVMe drives in RAID 1, but at a whopping $40,700.00 it's out of reach \n\n&amp;#x200B;\n\nBut at the moment I'm just eyeing a [Define 7 XL case](https://www.fractal-design.com/products/cases/define/define-7-xl/black-tg-dark-tint/) that can house 18x 3.5\" HDD's + 5x 2.5\" SSD's + 2x NVMe's. I can transplant my current setup into this case. + a [24 port SATA PCI Card](https://www.amazon.com/gp/product/B09K3FT3ZZ/ref=ox_sc_saved_title_2?smid=A1MK2DD7C33I65&amp;th=1)  \nThe case ($235) and the PCI card ($143) aren't really that expensive to shift, then add all my current drives plus whatever else I buy in the future\n\n&amp;#x200B;\n\nI've also been eyeing a [Yottamaster 5 Bay](https://www.amazon.com/gp/product/B08DLTKXCP/ref=ox_sc_saved_title_3?smid=A3OLRMD4MBYEYY&amp;th=1) external case ($280) that can daisy chain up to 3 times and supposedly can get up 10Gbps, but I'm wary that if I'm doing things on multiple disks it'll diminish the speed on the other disks.\n\n&amp;#x200B;\n\nMy use case is mostly just Plex and arcade stuff, so the data is at rest most of the time  \n\n\nIn any case, I'm really curious as to what your guys' solutions would be.  \n\n\n&amp;#x200B;", "author_fullname": "t2_1c4sxc16", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your dream storage configuration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mwkrj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695143326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;if you had varying budgets, what would be your dream setup that you would build yourself? And would be your use case for it?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;if I had more money lying around then I knew what to do with this is what I&amp;#39;d get: &lt;a href=\"https://www.thinkmate.com/system/superstorage-server-6049p-e1cr36l\"&gt;Supermicro SuperStorage Server 6049P-E1CR36L - 36x SATA/SAS - LSI 3008 12G SAS - Dual 10-Gigabit Ethernet&lt;/a&gt;, and throw 36 x 22TB drives in a RAID 6 and 2x 4TB NVMe drives in RAID 1, but at a whopping $40,700.00 it&amp;#39;s out of reach &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But at the moment I&amp;#39;m just eyeing a &lt;a href=\"https://www.fractal-design.com/products/cases/define/define-7-xl/black-tg-dark-tint/\"&gt;Define 7 XL case&lt;/a&gt; that can house 18x 3.5&amp;quot; HDD&amp;#39;s + 5x 2.5&amp;quot; SSD&amp;#39;s + 2x NVMe&amp;#39;s. I can transplant my current setup into this case. + a &lt;a href=\"https://www.amazon.com/gp/product/B09K3FT3ZZ/ref=ox_sc_saved_title_2?smid=A1MK2DD7C33I65&amp;amp;th=1\"&gt;24 port SATA PCI Card&lt;/a&gt;&lt;br/&gt;\nThe case ($235) and the PCI card ($143) aren&amp;#39;t really that expensive to shift, then add all my current drives plus whatever else I buy in the future&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also been eyeing a &lt;a href=\"https://www.amazon.com/gp/product/B08DLTKXCP/ref=ox_sc_saved_title_3?smid=A3OLRMD4MBYEYY&amp;amp;th=1\"&gt;Yottamaster 5 Bay&lt;/a&gt; external case ($280) that can daisy chain up to 3 times and supposedly can get up 10Gbps, but I&amp;#39;m wary that if I&amp;#39;m doing things on multiple disks it&amp;#39;ll diminish the speed on the other disks.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My use case is mostly just Plex and arcade stuff, so the data is at rest most of the time  &lt;/p&gt;\n\n&lt;p&gt;In any case, I&amp;#39;m really curious as to what your guys&amp;#39; solutions would be.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mwkrj", "is_robot_indexable": true, "report_reasons": null, "author": "MichaeldeBlok", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mwkrj/whats_your_dream_storage_configuration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mwkrj/whats_your_dream_storage_configuration/", "subreddit_subscribers": 702880, "created_utc": 1695143326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI recently have been trying to preserve my large PC CD game collection onto my NAS, but have been running into some issues.\n\nWhat I am currently trying to do is convert the CDs to ISOs, which I can store in my NAS and also mount to my PC to play the games without the need for the physical CD.\n\nFrom what I have seen online, apparently ImgBurn can do this. I downloaded it from Ninite and have attempted it with 2 disks so far, each providing errors that look something like this:\n\n    1/0 Error!\n    Device: HL-DT-ST DVD+-RW GU90N AICS (F:) (RAID)\n    ScsiStatus: Ox02\n    Interpretation: Check Condition\n    CDS: BE 00 COCO 03 2C00C001 10 COCO\n    Interpretation: Read CD - Sector: 812\n    Sense Area: 71 00 03 CQ 00 COCO OA COCO COCO 11 COCO COCO\n    00\n    SK Interpretation: Medium Error\n    ASC/ASCQ Interpretation: Unrecovered Read Error\n\nThis is where I am getting a bit stuck, I have read online that as a form of \"DRM\", certain games on CDs have unreadable sectors (not sure if that is the right terminology), to prevent unauthorized distribution of the games contents. I have also seen this can be caused by damaged disks.\n\nFrom what I can tell, the CD doesn't seem to be damaged as I can install the game normally fine through the CD, which leads me to believe it may have some sort of \"lock\" on it.\n\nIf this is the case, is there anyway to get around these games \"DRM\" to create an ISO? Is ImgBurn not a good tool to be attempting this with? I'm assuming that these games wouldn't have really that intense of DRM as they are older games spanning from about 1996-2004.\n\nThanks and any help is really appreciated!\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nEDIT:\n\nFor anyone in the same predicament, I found online that a lot of these older CD games use a very ancient form of DRM that is easily by-passed. If they use something called SafeDisk, then all the DRM does is just create bad sectors. To bypass this, I just set ImgBurn to \"Ignore read errors\" and it worked great!", "author_fullname": "t2_lh411", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help creating ISO from older CD based games", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n89g6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695217948.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695173071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I recently have been trying to preserve my large PC CD game collection onto my NAS, but have been running into some issues.&lt;/p&gt;\n\n&lt;p&gt;What I am currently trying to do is convert the CDs to ISOs, which I can store in my NAS and also mount to my PC to play the games without the need for the physical CD.&lt;/p&gt;\n\n&lt;p&gt;From what I have seen online, apparently ImgBurn can do this. I downloaded it from Ninite and have attempted it with 2 disks so far, each providing errors that look something like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;1/0 Error!\nDevice: HL-DT-ST DVD+-RW GU90N AICS (F:) (RAID)\nScsiStatus: Ox02\nInterpretation: Check Condition\nCDS: BE 00 COCO 03 2C00C001 10 COCO\nInterpretation: Read CD - Sector: 812\nSense Area: 71 00 03 CQ 00 COCO OA COCO COCO 11 COCO COCO\n00\nSK Interpretation: Medium Error\nASC/ASCQ Interpretation: Unrecovered Read Error\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This is where I am getting a bit stuck, I have read online that as a form of &amp;quot;DRM&amp;quot;, certain games on CDs have unreadable sectors (not sure if that is the right terminology), to prevent unauthorized distribution of the games contents. I have also seen this can be caused by damaged disks.&lt;/p&gt;\n\n&lt;p&gt;From what I can tell, the CD doesn&amp;#39;t seem to be damaged as I can install the game normally fine through the CD, which leads me to believe it may have some sort of &amp;quot;lock&amp;quot; on it.&lt;/p&gt;\n\n&lt;p&gt;If this is the case, is there anyway to get around these games &amp;quot;DRM&amp;quot; to create an ISO? Is ImgBurn not a good tool to be attempting this with? I&amp;#39;m assuming that these games wouldn&amp;#39;t have really that intense of DRM as they are older games spanning from about 1996-2004.&lt;/p&gt;\n\n&lt;p&gt;Thanks and any help is really appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;For anyone in the same predicament, I found online that a lot of these older CD games use a very ancient form of DRM that is easily by-passed. If they use something called SafeDisk, then all the DRM does is just create bad sectors. To bypass this, I just set ImgBurn to &amp;quot;Ignore read errors&amp;quot; and it worked great!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n89g6", "is_robot_indexable": true, "report_reasons": null, "author": "Sir_Cupcakers", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n89g6/help_creating_iso_from_older_cd_based_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n89g6/help_creating_iso_from_older_cd_based_games/", "subreddit_subscribers": 702880, "created_utc": 1695173071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi. I have some books about aircrafts which contain some text but mostly pictures. Some of these books are no longer available in the market, so I am thinking to scan them and have them in digital form (pdf). \n\nI am completely rookie to this, and my aim is to scan those books and not lose any quality from the images they contain. \n\n&amp;#x200B;\n\nWhat would be the best resolution to scan the pages/images ? Is 300dpi enough, or will it give me low quality pictures?\n\n&amp;#x200B;\n\nthanks in advance for the help.", "author_fullname": "t2_1s0ymi9v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resolution for Scanning books with pictures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n10sh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695154224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I have some books about aircrafts which contain some text but mostly pictures. Some of these books are no longer available in the market, so I am thinking to scan them and have them in digital form (pdf). &lt;/p&gt;\n\n&lt;p&gt;I am completely rookie to this, and my aim is to scan those books and not lose any quality from the images they contain. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What would be the best resolution to scan the pages/images ? Is 300dpi enough, or will it give me low quality pictures?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks in advance for the help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n10sh", "is_robot_indexable": true, "report_reasons": null, "author": "tripialos", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n10sh/resolution_for_scanning_books_with_pictures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n10sh/resolution_for_scanning_books_with_pictures/", "subreddit_subscribers": 702880, "created_utc": 1695154224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, I just built a system yesterday with the original goal of being a Plex Server and NAS. Using some old parts as the foundation and some new drives and case:\n\n\u2022\t\u2060Intel i7 4770K\n\u2022\t\u2060EVGA z87 FTW mobo\n\u2022\t\u206016GB Crucial Ballistix RAM\n\u2022\t\u2060EVGA 2060 KO Ultra\n\u2022\t\u2060Samsung 850 EVO 500GB SSD\n\u2022\t\u20604 x 6TB WD Red Plus: WD60EFZX\n\u2022\t\u2060EVGA 700 BQ PSU\n\u2022\t\u2060Cooler Master N400\n\nPer a recommendation from a friend, I installed Windows 10 and setup Storage Spaces. I was going to set the drives up in parity but currently they\u2019re in a simple pool. He suggested getting some bigger drives later as a backup for the 21.5TB the four drives provide. The immediate next step was just to slap Plex on there and move all my media over from my current PC.\n\nAnyway, with all of that said my actual original plan was to turn the new build into a NAS / Plex server but my friend thought that was over kill. Plus I have zero experience with building a NAS so for the moment, I\u2019ve taken the easiest path.\n\nI\u2019m hoping someone would be kind enough to offer some guidance here or suggestions of how to get the most out of the current setup. Is this a short sighted setup? Would it be better to set these drives up in RAID 10? I only have about 2TB of media so far, but I am slowly backing up my DVDs and Blu-rays. One other comment, I did just pick up the Plex pass on sale this week. Right now usage would be for my main 4K tv that is hooked up to an Apple TV 4K 2nd Gen. Wife likes to watch on her phone and my mom will sometimes watch from her account on a 1080p tv. I have a mixture of 480, 1080, and 4K content.\n\nThanks for your help! I enjoy learning, not dumb, just ignorant at the moment and looking for some help and advice navigating to a useful setup.", "author_fullname": "t2_nip8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mvwr3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695141710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I just built a system yesterday with the original goal of being a Plex Server and NAS. Using some old parts as the foundation and some new drives and case:&lt;/p&gt;\n\n&lt;p&gt;\u2022 \u2060Intel i7 4770K\n\u2022 \u2060EVGA z87 FTW mobo\n\u2022 \u206016GB Crucial Ballistix RAM\n\u2022 \u2060EVGA 2060 KO Ultra\n\u2022 \u2060Samsung 850 EVO 500GB SSD\n\u2022 \u20604 x 6TB WD Red Plus: WD60EFZX\n\u2022 \u2060EVGA 700 BQ PSU\n\u2022 \u2060Cooler Master N400&lt;/p&gt;\n\n&lt;p&gt;Per a recommendation from a friend, I installed Windows 10 and setup Storage Spaces. I was going to set the drives up in parity but currently they\u2019re in a simple pool. He suggested getting some bigger drives later as a backup for the 21.5TB the four drives provide. The immediate next step was just to slap Plex on there and move all my media over from my current PC.&lt;/p&gt;\n\n&lt;p&gt;Anyway, with all of that said my actual original plan was to turn the new build into a NAS / Plex server but my friend thought that was over kill. Plus I have zero experience with building a NAS so for the moment, I\u2019ve taken the easiest path.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m hoping someone would be kind enough to offer some guidance here or suggestions of how to get the most out of the current setup. Is this a short sighted setup? Would it be better to set these drives up in RAID 10? I only have about 2TB of media so far, but I am slowly backing up my DVDs and Blu-rays. One other comment, I did just pick up the Plex pass on sale this week. Right now usage would be for my main 4K tv that is hooked up to an Apple TV 4K 2nd Gen. Wife likes to watch on her phone and my mom will sometimes watch from her account on a 1080p tv. I have a mixture of 480, 1080, and 4K content.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help! I enjoy learning, not dumb, just ignorant at the moment and looking for some help and advice navigating to a useful setup.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mvwr3", "is_robot_indexable": true, "report_reasons": null, "author": "Hayreddin", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mvwr3/looking_for_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mvwr3/looking_for_advice/", "subreddit_subscribers": 702880, "created_utc": 1695141710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone have any advice for having two geographically seprated NAS systems on separate networks back up to each other/stay in sync? For example: if one were in Denver and one were in New York, I want to be able to add/delete/modify files in New York and the changes be synced to the one in Denver or vice versa.", "author_fullname": "t2_ea47g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync geographcially seprated Synology NAS systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mx7np", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695144913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any advice for having two geographically seprated NAS systems on separate networks back up to each other/stay in sync? For example: if one were in Denver and one were in New York, I want to be able to add/delete/modify files in New York and the changes be synced to the one in Denver or vice versa.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mx7np", "is_robot_indexable": true, "report_reasons": null, "author": "buhbuhbuhbary", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mx7np/sync_geographcially_seprated_synology_nas_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mx7np/sync_geographcially_seprated_synology_nas_systems/", "subreddit_subscribers": 702880, "created_utc": 1695144913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nI've been trying to use various Hangouts JSON readers from GitHub (namely [this one](https://github.com/Jessecar96/hangouts-reader) and [this one](https://github.com/adrish96/Hangouts-JSON-Parser/blob/master/HangoutJsonParser.py)), but I can't for the life of me get them to work.\n\nI think the issue may be at least in part due to the fact that my files are backed up as Google Chat exports and NOT Hangouts -- is this common? I think the chat was migrated to Google Chat at some point in time, so that's why it was moved. I renamed the messages.json file to Hangouts.json, and it just spit out some errors.\n\nI don't have the skills to fix the script to work with the potentially different formatting of the Chat files, so I want to see if anybody else has had a similar issue and found a solution...", "author_fullname": "t2_107h5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Hangouts takeout data parser for Google Chat?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mwrod", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695143813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying to use various Hangouts JSON readers from GitHub (namely &lt;a href=\"https://github.com/Jessecar96/hangouts-reader\"&gt;this one&lt;/a&gt; and &lt;a href=\"https://github.com/adrish96/Hangouts-JSON-Parser/blob/master/HangoutJsonParser.py\"&gt;this one&lt;/a&gt;), but I can&amp;#39;t for the life of me get them to work.&lt;/p&gt;\n\n&lt;p&gt;I think the issue may be at least in part due to the fact that my files are backed up as Google Chat exports and NOT Hangouts -- is this common? I think the chat was migrated to Google Chat at some point in time, so that&amp;#39;s why it was moved. I renamed the messages.json file to Hangouts.json, and it just spit out some errors.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have the skills to fix the script to work with the potentially different formatting of the Chat files, so I want to see if anybody else has had a similar issue and found a solution...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?auto=webp&amp;s=e2b7fa2752944a9eb0a93b7df41a029ec58cb5a6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7c28d57238c1210bf3ade3e07be822d4cf57535", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e879461097e00945ef05a9fcb3b8aedd70ae5bb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b43862bb9b300a1d080d01c54b9756f5fde1001a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4e0abc4d0bd5266a3530b3a4a6f9cf5e6685ca6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f82782f62519772c4a1640db1f6fcbd976f201eb", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6406ae84cd42000b3daf2364626b0a4055a6f711", "width": 1080, "height": 540}], "variants": {}, "id": "SiLrOgT-sA9pjgWd6-jz8kfvfIH5c34B9rAL_W4UfOk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mwrod", "is_robot_indexable": true, "report_reasons": null, "author": "gts250gamer101", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mwrod/google_hangouts_takeout_data_parser_for_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mwrod/google_hangouts_takeout_data_parser_for_google/", "subreddit_subscribers": 702880, "created_utc": 1695143813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "EDIT: PHYSICAL DISCS/DVDS/BLURAYS NOT JUST A HARD DRIVE.\n\nI just recently got some BDXL 100GB disks and the proper writer so I can make some easy cold backups of important files on my NAS.\n\nI'd like to be able to back up incremental snapshots of my NAS (i.e. I added 50 files one day, 200 on the other day -- assuming pretty much no file modifications). I wonder if there's any software out there that can keep track of \"what's backed up so far\" for you so you don't have to sift through your folders manually to figure out what you put on disks and what you didn't.\n\n(The problem is that, because I won't have access to read every disk I've backed up so far when creating a new disk, I need to figure out a way to track that.)\n\nAny recommendations?", "author_fullname": "t2_7q1apdlm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I do incremental backups onto disk?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nl0co", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695215620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;EDIT: PHYSICAL DISCS/DVDS/BLURAYS NOT JUST A HARD DRIVE.&lt;/p&gt;\n\n&lt;p&gt;I just recently got some BDXL 100GB disks and the proper writer so I can make some easy cold backups of important files on my NAS.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to be able to back up incremental snapshots of my NAS (i.e. I added 50 files one day, 200 on the other day -- assuming pretty much no file modifications). I wonder if there&amp;#39;s any software out there that can keep track of &amp;quot;what&amp;#39;s backed up so far&amp;quot; for you so you don&amp;#39;t have to sift through your folders manually to figure out what you put on disks and what you didn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;(The problem is that, because I won&amp;#39;t have access to read every disk I&amp;#39;ve backed up so far when creating a new disk, I need to figure out a way to track that.)&lt;/p&gt;\n\n&lt;p&gt;Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nl0co", "is_robot_indexable": true, "report_reasons": null, "author": "ConquestLunatic", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nl0co/how_do_i_do_incremental_backups_onto_disk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nl0co/how_do_i_do_incremental_backups_onto_disk/", "subreddit_subscribers": 702880, "created_utc": 1695215620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "or its just me? i check sites like downorjustme and it is down for them. anyone knows why uptobox was down for hours now?", "author_fullname": "t2_b1kix", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is uptobox down for everyone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nkngc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695214641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;or its just me? i check sites like downorjustme and it is down for them. anyone knows why uptobox was down for hours now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nkngc", "is_robot_indexable": true, "report_reasons": null, "author": "Zaiik", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nkngc/is_uptobox_down_for_everyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nkngc/is_uptobox_down_for_everyone/", "subreddit_subscribers": 702880, "created_utc": 1695214641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "seems like it's impossible to find it nowadays, back in the day i had my extrenal hd with almost all of it, but then it failed nand now i need to download it again but it's nowhere to be found", "author_fullname": "t2_xbf9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any help where to get Dc chronology?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nkkqr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695214420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;seems like it&amp;#39;s impossible to find it nowadays, back in the day i had my extrenal hd with almost all of it, but then it failed nand now i need to download it again but it&amp;#39;s nowhere to be found&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nkkqr", "is_robot_indexable": true, "report_reasons": null, "author": "Solstar82", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nkkqr/any_help_where_to_get_dc_chronology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nkkqr/any_help_where_to_get_dc_chronology/", "subreddit_subscribers": 702880, "created_utc": 1695214420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a single 1TB WD My passport HDD and I'd like to get another one for second backup (casual photos and videos, backed up every 3-6 months).\n\nReading around in this sub, I learned a lot about dos and don'ts, but not much about what product you guys actually recommend? I need:\n\n-2TB HDD\n\n-removable USB port, as I understand they can fail and replacing them might save my stored data\n\n-2.5 inch\n\n-a model that doesn't have a long record of failures and with the lowest chance to fail within 10 years, according to statistics or your experience (I know they all fail, but I guess some model/brands fail more than others?)\n\n-decent speed. Not a priority, but I'd rather not get the lowest speeds available\n\n-possibly encryption, not a priority\n\nWhat I have easily access to:\n\nSEAGATE:\n\n-Seagate One Touch (should have replaceable USB port and encryption?)\n\n-Seagate Expansion\n\n-Seagate Backup Plus Mini\n\nWD:\n\n-WD My Passport Ultra (probably non-replaceable usb port?)\n\n-WD Elements\n\n-WD Black (I think it's more for console gaming, which I don't)\n\nWhich of these would you recommend for my needs? What other brands/models do you use and recommend?\n\nThank you!", "author_fullname": "t2_5nii2l6t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16njyt0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695214485.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695212670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a single 1TB WD My passport HDD and I&amp;#39;d like to get another one for second backup (casual photos and videos, backed up every 3-6 months).&lt;/p&gt;\n\n&lt;p&gt;Reading around in this sub, I learned a lot about dos and don&amp;#39;ts, but not much about what product you guys actually recommend? I need:&lt;/p&gt;\n\n&lt;p&gt;-2TB HDD&lt;/p&gt;\n\n&lt;p&gt;-removable USB port, as I understand they can fail and replacing them might save my stored data&lt;/p&gt;\n\n&lt;p&gt;-2.5 inch&lt;/p&gt;\n\n&lt;p&gt;-a model that doesn&amp;#39;t have a long record of failures and with the lowest chance to fail within 10 years, according to statistics or your experience (I know they all fail, but I guess some model/brands fail more than others?)&lt;/p&gt;\n\n&lt;p&gt;-decent speed. Not a priority, but I&amp;#39;d rather not get the lowest speeds available&lt;/p&gt;\n\n&lt;p&gt;-possibly encryption, not a priority&lt;/p&gt;\n\n&lt;p&gt;What I have easily access to:&lt;/p&gt;\n\n&lt;p&gt;SEAGATE:&lt;/p&gt;\n\n&lt;p&gt;-Seagate One Touch (should have replaceable USB port and encryption?)&lt;/p&gt;\n\n&lt;p&gt;-Seagate Expansion&lt;/p&gt;\n\n&lt;p&gt;-Seagate Backup Plus Mini&lt;/p&gt;\n\n&lt;p&gt;WD:&lt;/p&gt;\n\n&lt;p&gt;-WD My Passport Ultra (probably non-replaceable usb port?)&lt;/p&gt;\n\n&lt;p&gt;-WD Elements&lt;/p&gt;\n\n&lt;p&gt;-WD Black (I think it&amp;#39;s more for console gaming, which I don&amp;#39;t)&lt;/p&gt;\n\n&lt;p&gt;Which of these would you recommend for my needs? What other brands/models do you use and recommend?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16njyt0", "is_robot_indexable": true, "report_reasons": null, "author": "nskdnnm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16njyt0/advice_for_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16njyt0/advice_for_hdd/", "subreddit_subscribers": 702880, "created_utc": 1695212670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "you wouldn't download a house...\n\nactually I would like to considering I'm moving from my childhood house of 20 years and I feel like having video or photos tours of my house wouldn't be enough. Im just that sentimental.\n\nAnyone have experience in this?\n\nI was wondering if there were budget friendly options to digitise my house such as making a virtual tour like the ones you see on real estate websites or other ways you can digitise a house. Potentially if i may also want to use VR.\n\nOf course looking for best budget option with best quality (the highest quality of camera i have is an Iphone 11 pro max)\n\nAlso I'm not sure if this is the right subreddit to post it but I see people on advice on how to scan books etc so I don't see how this is different.\n\nand no minecraft or blender\n\nTL;DR: Looking for ways to \"datahoard\" my childhood house", "author_fullname": "t2_dh4hjpj4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving houses... any budget friendly options to create 360 tours or digitise my house", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16njusx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695212348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;you wouldn&amp;#39;t download a house...&lt;/p&gt;\n\n&lt;p&gt;actually I would like to considering I&amp;#39;m moving from my childhood house of 20 years and I feel like having video or photos tours of my house wouldn&amp;#39;t be enough. Im just that sentimental.&lt;/p&gt;\n\n&lt;p&gt;Anyone have experience in this?&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there were budget friendly options to digitise my house such as making a virtual tour like the ones you see on real estate websites or other ways you can digitise a house. Potentially if i may also want to use VR.&lt;/p&gt;\n\n&lt;p&gt;Of course looking for best budget option with best quality (the highest quality of camera i have is an Iphone 11 pro max)&lt;/p&gt;\n\n&lt;p&gt;Also I&amp;#39;m not sure if this is the right subreddit to post it but I see people on advice on how to scan books etc so I don&amp;#39;t see how this is different.&lt;/p&gt;\n\n&lt;p&gt;and no minecraft or blender&lt;/p&gt;\n\n&lt;p&gt;TL;DR: Looking for ways to &amp;quot;datahoard&amp;quot; my childhood house&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16njusx", "is_robot_indexable": true, "report_reasons": null, "author": "__Acedia_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16njusx/moving_houses_any_budget_friendly_options_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16njusx/moving_houses_any_budget_friendly_options_to/", "subreddit_subscribers": 702880, "created_utc": 1695212348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hoping someone can provide some clarity on this.  I started suing iDrive last year and have had no issues backing up specific drives/folders.  I'm now looking into using the Cloud Drive feature to have a working folder between my computers.  I'm running into an issue where items in the Cloud Drive are still taking up hard drive space.  Is that how it's supposed to function?  I figured it would just store all files in the cloud.", "author_fullname": "t2_4vubv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "iDrive Cloud Drive Issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16njqvw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695212418.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695212036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping someone can provide some clarity on this.  I started suing iDrive last year and have had no issues backing up specific drives/folders.  I&amp;#39;m now looking into using the Cloud Drive feature to have a working folder between my computers.  I&amp;#39;m running into an issue where items in the Cloud Drive are still taking up hard drive space.  Is that how it&amp;#39;s supposed to function?  I figured it would just store all files in the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16njqvw", "is_robot_indexable": true, "report_reasons": null, "author": "vaultfreak91", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16njqvw/idrive_cloud_drive_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16njqvw/idrive_cloud_drive_issue/", "subreddit_subscribers": 702880, "created_utc": 1695212036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I've followed a lot the suggestions of this community and I decided in June to purchase my first NAS. Excellent machine, works nicely and helps me backup everything.\n\nMy previous setup was:\n\n\\- Dropbox Plus\n\n\\- Company Google Drive\n\n\\- Academic Google Drive\n\n\\- Private iCloud+ for some small things\n\nAfter I purchased the NAS, I decided to let Dropbox go and I decided to transfer most of the Dropbox files into one of the unlimited Google Drives from the company or Uni. I did that with rclone, which worked nicely. \n\nOn the NAS, I've activated Synology Sync with Drive and Dropbox.\n\nI decided to activate Dropbox Pro (trial) to be sure that all my files were moved out efficiently from dropbox and let the trial expire without renewal.\n\nToday, after 3-4 months, I noticed that a whole folder, super important, is missing. All the remaining files on all the cloud services are there.\n\nNothing on the NAS, nothing on any could service. All the cloud services have only 30 days of deleted file history. My question is: is there a chance that my Dropbox Pro 30-day trial could have prolonged the expiration date of some of the files to 180 days and I would be able to recover them?", "author_fullname": "t2_ibpn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropbox file history", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16njjui", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695211477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve followed a lot the suggestions of this community and I decided in June to purchase my first NAS. Excellent machine, works nicely and helps me backup everything.&lt;/p&gt;\n\n&lt;p&gt;My previous setup was:&lt;/p&gt;\n\n&lt;p&gt;- Dropbox Plus&lt;/p&gt;\n\n&lt;p&gt;- Company Google Drive&lt;/p&gt;\n\n&lt;p&gt;- Academic Google Drive&lt;/p&gt;\n\n&lt;p&gt;- Private iCloud+ for some small things&lt;/p&gt;\n\n&lt;p&gt;After I purchased the NAS, I decided to let Dropbox go and I decided to transfer most of the Dropbox files into one of the unlimited Google Drives from the company or Uni. I did that with rclone, which worked nicely. &lt;/p&gt;\n\n&lt;p&gt;On the NAS, I&amp;#39;ve activated Synology Sync with Drive and Dropbox.&lt;/p&gt;\n\n&lt;p&gt;I decided to activate Dropbox Pro (trial) to be sure that all my files were moved out efficiently from dropbox and let the trial expire without renewal.&lt;/p&gt;\n\n&lt;p&gt;Today, after 3-4 months, I noticed that a whole folder, super important, is missing. All the remaining files on all the cloud services are there.&lt;/p&gt;\n\n&lt;p&gt;Nothing on the NAS, nothing on any could service. All the cloud services have only 30 days of deleted file history. My question is: is there a chance that my Dropbox Pro 30-day trial could have prolonged the expiration date of some of the files to 180 days and I would be able to recover them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16njjui", "is_robot_indexable": true, "report_reasons": null, "author": "Mollan8686", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16njjui/dropbox_file_history/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16njjui/dropbox_file_history/", "subreddit_subscribers": 702880, "created_utc": 1695211477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have started cloning a hard drive, 10TB onto an 18TB.\n\nAll I have at the end of the day is as follows\n\n1. macOS Monterey 12.6.9, iMac 5K 27 inch 2015, 3.3GHz i5, 32GB Ram\n2. Both drives plugged directly into computer\n3. Using CCC (Carbon Copy Cloner)\n4. Currently it has taken 2hr22min and 164GB has been transferred\n\nIs there anything else I can do that will make this process faster? I am not saying I am not patient, I can wait, I am in no hurry, but I mean for future reference, I don't know what I can do, to make the process faster.", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I calculate how long it will take to clone a drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nhziy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695206412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started cloning a hard drive, 10TB onto an 18TB.&lt;/p&gt;\n\n&lt;p&gt;All I have at the end of the day is as follows&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;macOS Monterey 12.6.9, iMac 5K 27 inch 2015, 3.3GHz i5, 32GB Ram&lt;/li&gt;\n&lt;li&gt;Both drives plugged directly into computer&lt;/li&gt;\n&lt;li&gt;Using CCC (Carbon Copy Cloner)&lt;/li&gt;\n&lt;li&gt;Currently it has taken 2hr22min and 164GB has been transferred&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Is there anything else I can do that will make this process faster? I am not saying I am not patient, I can wait, I am in no hurry, but I mean for future reference, I don&amp;#39;t know what I can do, to make the process faster.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nhziy", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nhziy/how_can_i_calculate_how_long_it_will_take_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nhziy/how_can_i_calculate_how_long_it_will_take_to/", "subreddit_subscribers": 702880, "created_utc": 1695206412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a bunch of hour-long videos that I each want to turn into 2 or 3 separate files - is there any program that can do that, hopefully without having to manually go through each video? Or maybe even a program that downloads and splits it automatically?\n\nThese videos were downloaded through yt-dlp (but not from Youtube) and are in mp4 format. I saw someone recommend something called MKVToolnix but I'm not sure if it's exactly what I'm looking for. Help?", "author_fullname": "t2_7t4l9rdr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Splitting videos into separate files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ngkd6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695203120.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695201138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of hour-long videos that I each want to turn into 2 or 3 separate files - is there any program that can do that, hopefully without having to manually go through each video? Or maybe even a program that downloads and splits it automatically?&lt;/p&gt;\n\n&lt;p&gt;These videos were downloaded through yt-dlp (but not from Youtube) and are in mp4 format. I saw someone recommend something called MKVToolnix but I&amp;#39;m not sure if it&amp;#39;s exactly what I&amp;#39;m looking for. Help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ngkd6", "is_robot_indexable": true, "report_reasons": null, "author": "hiraethers", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ngkd6/splitting_videos_into_separate_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ngkd6/splitting_videos_into_separate_files/", "subreddit_subscribers": 702880, "created_utc": 1695201138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got a new 20TB drive and I'm moving stuff over from my old 8TB drives + SSD. Should I copy little by little or just send it all at once? I don't need to worry about temps or anything like that over the 10 some hours it's gonna take? It's in the ballpark of 10TB. Just go to sleep and I'll be good? Thanks, just need some peace of mind lol.", "author_fullname": "t2_pi35p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving files over to a new HDD. Stupid question but should I send it all at once or by parts with breaks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n5twc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695166338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a new 20TB drive and I&amp;#39;m moving stuff over from my old 8TB drives + SSD. Should I copy little by little or just send it all at once? I don&amp;#39;t need to worry about temps or anything like that over the 10 some hours it&amp;#39;s gonna take? It&amp;#39;s in the ballpark of 10TB. Just go to sleep and I&amp;#39;ll be good? Thanks, just need some peace of mind lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16n5twc", "is_robot_indexable": true, "report_reasons": null, "author": "Schwaggaccino", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n5twc/moving_files_over_to_a_new_hdd_stupid_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n5twc/moving_files_over_to_a_new_hdd_stupid_question/", "subreddit_subscribers": 702880, "created_utc": 1695166338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, first time posting here. I'm a professional photographer who generates about a TB every week or two when on assignment, averaging about 15TB/year. Honestly the different systems and setups for storage are extremely overwhelming, so I've tried to do some reading on this but I'm struggling to figure out where to begin. \n\nRight now I have two RAID backup systems - a direct attached Promise Pegasus3 with 4x 4TB drives. It is 100% full. \n\nWhen that filled up I got a Synology DS1520+ NAS system with 5x 18TB Seagate Ironwolf drives. Probably about 20% full at the moment. \n\nMy issue is that the Synology is SLOWWWWW, like far too slow for me to edit from, and honestly excruciatingly slow even just for standard backup. Right now I come home from a trip and I'll backup my photos to the Synology and it'll take 6-18 hours, but then I still have to use an SSD (or several) with duplicate files to edit from. I just signed up for Dropbox Enterprise so I have unlimited cloud backup (and uploading to DB is easily 2x the speed of my Synology, even when plugged directly in with the ethernet cable), which effectively renders the Synology as a $5,000 paperweight.\n\nSO, I'd love to simplify my setup down into one singular RAID system that I can plug directly into with thunderbolt so it has the speed for editing and the convenience of being a local external drive. I'm fine with transferring the entirety of my Promise Pegasus to a new RAID system (4x4TB drives aren't massive so I'm probably due to upgrade that anyway), but I'd very much like to reuse the 5x218TB Seagate drives because those were not cheap. \n\nWhat would be the easiest and simplest way to move all my stuff from the Pegasus AND the Synology to a new RAID system while *hopefully* reusing the $1,500 worth of drives from the Synology? From my reading it seems that I won't be able to just pull the drives from the Synology and put them in a new system because the operating system won't be compatible and I'll likely lose all my data. \n\nOr would I be better off just buying new drives in a fully-built system and transferring everything from both current systems and then selling the Synology with my old drives in it (after formatting them, of course)? \n\n&amp;#x200B;\n\nThank you for reading this clusterf\\*ck of a question from someone who loves taking photos but doesn't know wtf to do afterwards.", "author_fullname": "t2_rc1st", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to expand/simplify my RAID system and my brain is melting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n3qwk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695160858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, first time posting here. I&amp;#39;m a professional photographer who generates about a TB every week or two when on assignment, averaging about 15TB/year. Honestly the different systems and setups for storage are extremely overwhelming, so I&amp;#39;ve tried to do some reading on this but I&amp;#39;m struggling to figure out where to begin. &lt;/p&gt;\n\n&lt;p&gt;Right now I have two RAID backup systems - a direct attached Promise Pegasus3 with 4x 4TB drives. It is 100% full. &lt;/p&gt;\n\n&lt;p&gt;When that filled up I got a Synology DS1520+ NAS system with 5x 18TB Seagate Ironwolf drives. Probably about 20% full at the moment. &lt;/p&gt;\n\n&lt;p&gt;My issue is that the Synology is SLOWWWWW, like far too slow for me to edit from, and honestly excruciatingly slow even just for standard backup. Right now I come home from a trip and I&amp;#39;ll backup my photos to the Synology and it&amp;#39;ll take 6-18 hours, but then I still have to use an SSD (or several) with duplicate files to edit from. I just signed up for Dropbox Enterprise so I have unlimited cloud backup (and uploading to DB is easily 2x the speed of my Synology, even when plugged directly in with the ethernet cable), which effectively renders the Synology as a $5,000 paperweight.&lt;/p&gt;\n\n&lt;p&gt;SO, I&amp;#39;d love to simplify my setup down into one singular RAID system that I can plug directly into with thunderbolt so it has the speed for editing and the convenience of being a local external drive. I&amp;#39;m fine with transferring the entirety of my Promise Pegasus to a new RAID system (4x4TB drives aren&amp;#39;t massive so I&amp;#39;m probably due to upgrade that anyway), but I&amp;#39;d very much like to reuse the 5x218TB Seagate drives because those were not cheap. &lt;/p&gt;\n\n&lt;p&gt;What would be the easiest and simplest way to move all my stuff from the Pegasus AND the Synology to a new RAID system while &lt;em&gt;hopefully&lt;/em&gt; reusing the $1,500 worth of drives from the Synology? From my reading it seems that I won&amp;#39;t be able to just pull the drives from the Synology and put them in a new system because the operating system won&amp;#39;t be compatible and I&amp;#39;ll likely lose all my data. &lt;/p&gt;\n\n&lt;p&gt;Or would I be better off just buying new drives in a fully-built system and transferring everything from both current systems and then selling the Synology with my old drives in it (after formatting them, of course)? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading this clusterf*ck of a question from someone who loves taking photos but doesn&amp;#39;t know wtf to do afterwards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n3qwk", "is_robot_indexable": true, "report_reasons": null, "author": "Nateloobz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n3qwk/need_to_expandsimplify_my_raid_system_and_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n3qwk/need_to_expandsimplify_my_raid_system_and_my/", "subreddit_subscribers": 702880, "created_utc": 1695160858.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}