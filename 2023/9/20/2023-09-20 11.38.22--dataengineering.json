{"kind": "Listing", "data": {"after": "t3_16n6lgb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Had one of the most bizarre interview experiences in my life recently. Interview was with one senior and one mid level DE. Senior kicked off with intro. Then mid. Mid threw all the acyronms of the day at me as if they were common knowledge (they absolutely were not) and went into all this boring technical stuff that added zero value (like it's a damn 30sec intro bro) - but I did my best to at least pretend I was interested in his current financial data migration project at x bank, for which he spent a couple minutes telling me everything but also absolutely nothing about it at the same time. I don't think I seemed uninterested at all (I was but was pretending not to be)\n\nImmediately after I begin my own intro, I can see this mid guy fidgetting on my screen. He looked like he was checking his wrist watch for the time (his elbow was up at the camera and forearm pointed inwards, probably his clock on his laptop was broken - he did that a couple times. Then starts rubbing his eyes as if he's about to fall asleep. Like damn, I'm sorry the other senior DE bummed this interview off and you got roped into it, but at least have the courtesy to pretend you're interested like I did, failing that no need to seemingly like go out of your way to express your disinterest.\n\nQuestions followed. There was a question about a project at work, I started off explaining the problem (STAR) and by the time I got to T my use of \"we\" had the mid triggered bc he somewhat aggressively jumps in with a \"who is 'we' here? Totally broke my rhythm and I was thinking to myself, \"the fucking data engineering team that I told you about 2minutes ago, who the fuck else\". I responded, myself and others from our data engineering team and he responds, big smirk on his face now, \"ok but who is \"we\" *makes a brick stacking gesture with his hands* as if that made it more clear. Senior butts in at this point to ask about the team size and roles etc.\n\nMore questions followed. Everytime I was answering a question the senior asked this mid guy was back to fidgetting, at one point outstretches his arms upwards as if he was secretly watching a football game in the background and his team just scored. Off-putting was an understatement.\n\nSafe to say I didn't get this job and knew after about 10mins into the interview it wasn't going to go well. It certainly wasn't a strong performance on my side but my only regret was not calling this guy out for being a massive arsehole.\n\nEver experienced anything similar?", "author_fullname": "t2_1w1o79i7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ever regretted biting tongue/being nice to an interviewer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mobuh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695122864.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695122589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had one of the most bizarre interview experiences in my life recently. Interview was with one senior and one mid level DE. Senior kicked off with intro. Then mid. Mid threw all the acyronms of the day at me as if they were common knowledge (they absolutely were not) and went into all this boring technical stuff that added zero value (like it&amp;#39;s a damn 30sec intro bro) - but I did my best to at least pretend I was interested in his current financial data migration project at x bank, for which he spent a couple minutes telling me everything but also absolutely nothing about it at the same time. I don&amp;#39;t think I seemed uninterested at all (I was but was pretending not to be)&lt;/p&gt;\n\n&lt;p&gt;Immediately after I begin my own intro, I can see this mid guy fidgetting on my screen. He looked like he was checking his wrist watch for the time (his elbow was up at the camera and forearm pointed inwards, probably his clock on his laptop was broken - he did that a couple times. Then starts rubbing his eyes as if he&amp;#39;s about to fall asleep. Like damn, I&amp;#39;m sorry the other senior DE bummed this interview off and you got roped into it, but at least have the courtesy to pretend you&amp;#39;re interested like I did, failing that no need to seemingly like go out of your way to express your disinterest.&lt;/p&gt;\n\n&lt;p&gt;Questions followed. There was a question about a project at work, I started off explaining the problem (STAR) and by the time I got to T my use of &amp;quot;we&amp;quot; had the mid triggered bc he somewhat aggressively jumps in with a &amp;quot;who is &amp;#39;we&amp;#39; here? Totally broke my rhythm and I was thinking to myself, &amp;quot;the fucking data engineering team that I told you about 2minutes ago, who the fuck else&amp;quot;. I responded, myself and others from our data engineering team and he responds, big smirk on his face now, &amp;quot;ok but who is &amp;quot;we&amp;quot; &lt;em&gt;makes a brick stacking gesture with his hands&lt;/em&gt; as if that made it more clear. Senior butts in at this point to ask about the team size and roles etc.&lt;/p&gt;\n\n&lt;p&gt;More questions followed. Everytime I was answering a question the senior asked this mid guy was back to fidgetting, at one point outstretches his arms upwards as if he was secretly watching a football game in the background and his team just scored. Off-putting was an understatement.&lt;/p&gt;\n\n&lt;p&gt;Safe to say I didn&amp;#39;t get this job and knew after about 10mins into the interview it wasn&amp;#39;t going to go well. It certainly wasn&amp;#39;t a strong performance on my side but my only regret was not calling this guy out for being a massive arsehole.&lt;/p&gt;\n\n&lt;p&gt;Ever experienced anything similar?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16mobuh", "is_robot_indexable": true, "report_reasons": null, "author": "tea_horse", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mobuh/ever_regretted_biting_tonguebeing_nice_to_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mobuh/ever_regretted_biting_tonguebeing_nice_to_an/", "subreddit_subscribers": 129375, "created_utc": 1695122589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been in data engineering for almost 5 years, and this job market has been much more difficult than when I was a new grad.  I'm currently employed at a great tech company, but I apply for jobs every now and to try to see the opportunities to advance my career.  Out of several job applications, I received less than a handful of first round interviews and I have not advanced past the second round.\n\n\n\n\n\nHypothetically, if you needed to find a job in this job market, what would you do?  I've mostly applied to data engineering jobs and some devops, but haven't had luck.  Would you try leaving data engineering and going into software engineering or becoming a data analyst?", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experienced data engineers, what are your backup career plans in this job market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mpors", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695126636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been in data engineering for almost 5 years, and this job market has been much more difficult than when I was a new grad.  I&amp;#39;m currently employed at a great tech company, but I apply for jobs every now and to try to see the opportunities to advance my career.  Out of several job applications, I received less than a handful of first round interviews and I have not advanced past the second round.&lt;/p&gt;\n\n&lt;p&gt;Hypothetically, if you needed to find a job in this job market, what would you do?  I&amp;#39;ve mostly applied to data engineering jobs and some devops, but haven&amp;#39;t had luck.  Would you try leaving data engineering and going into software engineering or becoming a data analyst?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16mpors", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16mpors/experienced_data_engineers_what_are_your_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mpors/experienced_data_engineers_what_are_your_backup/", "subreddit_subscribers": 129375, "created_utc": 1695126636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This job market is tough! I'm in a senior role looking to expand my skillset by applying to other senior or architect level roles but it seems like most companies are either moving very slowly/carefully through the interviewing process or only considering \"unicorn\" candidates. For those without a job looking for one my sympathies go out to you. ", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's been said before but daggum...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mw5sd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695142310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This job market is tough! I&amp;#39;m in a senior role looking to expand my skillset by applying to other senior or architect level roles but it seems like most companies are either moving very slowly/carefully through the interviewing process or only considering &amp;quot;unicorn&amp;quot; candidates. For those without a job looking for one my sympathies go out to you. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16mw5sd", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mw5sd/its_been_said_before_but_daggum/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mw5sd/its_been_said_before_but_daggum/", "subreddit_subscribers": 129375, "created_utc": 1695142310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " To celebrate the launch of my new Udemy course, \"Data Engineering for Beginners with Python and SQL,\" I'm thrilled to offer a limited-time opportunity for the first 100 Redditors to enroll for FREE! \ud83d\ude80\n\n\ud83d\udc49 Grab your free course access here: [https://www.udemy.com/course/data-engineering-for-beginners-with-python-and-sql/?couponCode=00B87430900F87EE2B4D](https://www.udemy.com/course/data-engineering-for-beginners-with-python-and-sql/?couponCode=00B87430900F87EE2B4D)\n\nIt's been a labor of love over the past three months, and I believe it's a fantastic resource for anyone interested in the data engineering field. \ud83d\udcbc\ud83d\udcbb\n\nIn exchange for this special offer, I kindly request that you consider leaving a 5-star review if you find the course valuable. Your feedback is immensely valuable and will help fellow learners discover this excellent resource. \ud83c\udf1f\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f\n\n\\#DataEngineering #Python #SQL #UdemyCourse #FreeCourse #LimitedTimeOffer #5StarReview", "author_fullname": "t2_2lt1q4pa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ms8xp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695133122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To celebrate the launch of my new Udemy course, &amp;quot;Data Engineering for Beginners with Python and SQL,&amp;quot; I&amp;#39;m thrilled to offer a limited-time opportunity for the first 100 Redditors to enroll for FREE! \ud83d\ude80&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc49 Grab your free course access here: &lt;a href=\"https://www.udemy.com/course/data-engineering-for-beginners-with-python-and-sql/?couponCode=00B87430900F87EE2B4D\"&gt;https://www.udemy.com/course/data-engineering-for-beginners-with-python-and-sql/?couponCode=00B87430900F87EE2B4D&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s been a labor of love over the past three months, and I believe it&amp;#39;s a fantastic resource for anyone interested in the data engineering field. \ud83d\udcbc\ud83d\udcbb&lt;/p&gt;\n\n&lt;p&gt;In exchange for this special offer, I kindly request that you consider leaving a 5-star review if you find the course valuable. Your feedback is immensely valuable and will help fellow learners discover this excellent resource. \ud83c\udf1f\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f\ud83c\udf1f&lt;/p&gt;\n\n&lt;p&gt;#DataEngineering #Python #SQL #UdemyCourse #FreeCourse #LimitedTimeOffer #5StarReview&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16ms8xp", "is_robot_indexable": true, "report_reasons": null, "author": "Kairo1004", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ms8xp/free_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ms8xp/free_course/", "subreddit_subscribers": 129375, "created_utc": 1695133122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Data Engineers, i\u2019ve seen this practice quite often at the company i\u2019m working at as a Data Analyst. \nIs it common to store a Json as string into the column of a table to avoid creating a new table to contain that data? :/\nTo me it feels terrible and looking for data into these Json is a mess (and slow as well).\n\nThere are no DEs, this is done by SWEs..", "author_fullname": "t2_31y2n5wv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Json in table column", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n1gyp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695155636.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695155312.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Data Engineers, i\u2019ve seen this practice quite often at the company i\u2019m working at as a Data Analyst. \nIs it common to store a Json as string into the column of a table to avoid creating a new table to contain that data? :/\nTo me it feels terrible and looking for data into these Json is a mess (and slow as well).&lt;/p&gt;\n\n&lt;p&gt;There are no DEs, this is done by SWEs..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16n1gyp", "is_robot_indexable": true, "report_reasons": null, "author": "bancaletto", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16n1gyp/json_in_table_column/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16n1gyp/json_in_table_column/", "subreddit_subscribers": 129375, "created_utc": 1695155312.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI've been working as a DE for about 3 years and still feel like a Jr\n\nOver this years I only worked with ETL/ELT proyects using datafactory and a bit of databricks (but this last one only creating simple notebooks using pyspark or sql  to explode some of the files retrieved by datafactory).\n\nThe thing is, I want a bigger challenge, I want to know better and when I take interviews for Ssr (or even some Jr roles) I do not have the minimum clue about :\n\n  \n\\- How to develop a datawarehouse (Snowflake/Redshift/Synapse) (which seems to be a basic thing for a DE )\n\n  \n\\- How to develop a datalake (which seems to be a basic thing for a DE,too )\n\n\\-Using Cloud tools and tunning them (I have no idea how spark works and what the clusters are)\n\n\\-Knowledge of managing No-SQL databases\n\n\\-Using docker or kubernetes (required more and more in the new jobs)\n\n&amp;#x200B;\n\nI am a practical person, I struggle with theory and reading about concepts of databases so I want to start (some) proyects to learn all of this by myself.\n\nSo my question is, how would you approach to get to know those things? Should I use challenges from Kaggle or I do not know , the thing is I am having a hard time trying to find a proyect that makes me more confident and say for example \"okay, now I think I can defend myself using kubernetes/developing a warehouse/datalake/etc \"\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nSorry for the long text and bad english, and thanks in advance!!\n\n&amp;#x200B;", "author_fullname": "t2_75wkfezv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel stuck as a DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mt145", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695134849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working as a DE for about 3 years and still feel like a Jr&lt;/p&gt;\n\n&lt;p&gt;Over this years I only worked with ETL/ELT proyects using datafactory and a bit of databricks (but this last one only creating simple notebooks using pyspark or sql  to explode some of the files retrieved by datafactory).&lt;/p&gt;\n\n&lt;p&gt;The thing is, I want a bigger challenge, I want to know better and when I take interviews for Ssr (or even some Jr roles) I do not have the minimum clue about :&lt;/p&gt;\n\n&lt;p&gt;- How to develop a datawarehouse (Snowflake/Redshift/Synapse) (which seems to be a basic thing for a DE )&lt;/p&gt;\n\n&lt;p&gt;- How to develop a datalake (which seems to be a basic thing for a DE,too )&lt;/p&gt;\n\n&lt;p&gt;-Using Cloud tools and tunning them (I have no idea how spark works and what the clusters are)&lt;/p&gt;\n\n&lt;p&gt;-Knowledge of managing No-SQL databases&lt;/p&gt;\n\n&lt;p&gt;-Using docker or kubernetes (required more and more in the new jobs)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am a practical person, I struggle with theory and reading about concepts of databases so I want to start (some) proyects to learn all of this by myself.&lt;/p&gt;\n\n&lt;p&gt;So my question is, how would you approach to get to know those things? Should I use challenges from Kaggle or I do not know , the thing is I am having a hard time trying to find a proyect that makes me more confident and say for example &amp;quot;okay, now I think I can defend myself using kubernetes/developing a warehouse/datalake/etc &amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Sorry for the long text and bad english, and thanks in advance!!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16mt145", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering-Branch-44", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mt145/i_feel_stuck_as_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mt145/i_feel_stuck_as_a_de/", "subreddit_subscribers": 129375, "created_utc": 1695134849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks,\n\nI need some advice from the engineers. I\u2019ve employee information that can changes over time. For example, manager and roles. That being said, using a scd type, is it a best practice to have a single table to handle those changes, or should I create a scd for manager and another one for roles. Those tables at the end, will be used into a powerbi. \n\nThanks", "author_fullname": "t2_bnqvpnvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Slowly change dimension type 2", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n2l5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695157909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,&lt;/p&gt;\n\n&lt;p&gt;I need some advice from the engineers. I\u2019ve employee information that can changes over time. For example, manager and roles. That being said, using a scd type, is it a best practice to have a single table to handle those changes, or should I create a scd for manager and another one for roles. Those tables at the end, will be used into a powerbi. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16n2l5q", "is_robot_indexable": true, "report_reasons": null, "author": "Mr-Wedge01", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16n2l5q/slowly_change_dimension_type_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16n2l5q/slowly_change_dimension_type_2/", "subreddit_subscribers": 129375, "created_utc": 1695157909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a data engineer in a team of 6 which is soon to expend. The team oversees the data of the entire business I'm in. A lot of the work involved is standard ETLs, however, there are also more complex pipelines with inter-dependencies.\n\nThe team, including the management has a good attitude towards introducing new technologies and pushes for training to bring the others up to pace. Myself and another data scientist are the only two proficient in python, while the others have only used SQL/R.\n\nI proposed the use of airflow and/or DBT as they're built to map pipelines and allow for modularised code to handle different data points. Useful tools when working with an expanding data warehouse and you want to keep track of pipelines and documentation.\n\nMy manager suggested that if I do a POC the team can move to using them.\n\nI have learned how to use both through tutorials online and find that actually coding out DAGs is straightforward.\n\nHowever, I'm finding the setup to be painful. I have read countless articles and documentation but connecting to private GitHub repositories for both DAGs and internal python packages, working with ssh keys, business data repositories makes the workload a step above firing up a quick docker image and coding out a few DAGs.\n\nNobody else in my team is as invested in the idea of introducing either Airflow or DBT, nor do they have the technical experience where I can ask them on areas I'm stuck in.\n\nHas anybody else been in a similar situation?", "author_fullname": "t2_ityxycxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Airflow/DBT into my team - Advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mrt0t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695132025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data engineer in a team of 6 which is soon to expend. The team oversees the data of the entire business I&amp;#39;m in. A lot of the work involved is standard ETLs, however, there are also more complex pipelines with inter-dependencies.&lt;/p&gt;\n\n&lt;p&gt;The team, including the management has a good attitude towards introducing new technologies and pushes for training to bring the others up to pace. Myself and another data scientist are the only two proficient in python, while the others have only used SQL/R.&lt;/p&gt;\n\n&lt;p&gt;I proposed the use of airflow and/or DBT as they&amp;#39;re built to map pipelines and allow for modularised code to handle different data points. Useful tools when working with an expanding data warehouse and you want to keep track of pipelines and documentation.&lt;/p&gt;\n\n&lt;p&gt;My manager suggested that if I do a POC the team can move to using them.&lt;/p&gt;\n\n&lt;p&gt;I have learned how to use both through tutorials online and find that actually coding out DAGs is straightforward.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;m finding the setup to be painful. I have read countless articles and documentation but connecting to private GitHub repositories for both DAGs and internal python packages, working with ssh keys, business data repositories makes the workload a step above firing up a quick docker image and coding out a few DAGs.&lt;/p&gt;\n\n&lt;p&gt;Nobody else in my team is as invested in the idea of introducing either Airflow or DBT, nor do they have the technical experience where I can ask them on areas I&amp;#39;m stuck in.&lt;/p&gt;\n\n&lt;p&gt;Has anybody else been in a similar situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16mrt0t", "is_robot_indexable": true, "report_reasons": null, "author": "icecoldfeedback", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mrt0t/introducing_airflowdbt_into_my_team_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mrt0t/introducing_airflowdbt_into_my_team_advice/", "subreddit_subscribers": 129375, "created_utc": 1695132025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\nin my practice of creating DWH core layers, I have come to the conclusion that it is a best practice to partition individual data domains into separate database schemas.\n\nData for HR is in the hr schema, data for Sales is in the sales schema, data for Logistics is in the logistics schema, etc.\n\nThis ensures better data governance, improves performance (maintenance is easier within a single schema than in the entire dbo), reduces complexity, and increases the clarity of the\n entire core layer. If you are creating a DWH in a large company with a lot of data domains and you want to have a unified core layer, then there is probably no other option. Having everything crammed into the dbo schema is quite chaotic and inflexible.\n\nWhat is your opinion on this? Are you a supporter of logical partitioning or do you see no problem with having everything in one schema?\n\nI cannot find any articles, architecture, or anything else on this topic on the web, so I am wondering if this is even a best practice or just some anomaly that I came across and adopted. :-)", "author_fullname": "t2_6bjpaig5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DWH: Partitioning data domains into separate database schemas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mqzns", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695129965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,\nin my practice of creating DWH core layers, I have come to the conclusion that it is a best practice to partition individual data domains into separate database schemas.&lt;/p&gt;\n\n&lt;p&gt;Data for HR is in the hr schema, data for Sales is in the sales schema, data for Logistics is in the logistics schema, etc.&lt;/p&gt;\n\n&lt;p&gt;This ensures better data governance, improves performance (maintenance is easier within a single schema than in the entire dbo), reduces complexity, and increases the clarity of the\n entire core layer. If you are creating a DWH in a large company with a lot of data domains and you want to have a unified core layer, then there is probably no other option. Having everything crammed into the dbo schema is quite chaotic and inflexible.&lt;/p&gt;\n\n&lt;p&gt;What is your opinion on this? Are you a supporter of logical partitioning or do you see no problem with having everything in one schema?&lt;/p&gt;\n\n&lt;p&gt;I cannot find any articles, architecture, or anything else on this topic on the web, so I am wondering if this is even a best practice or just some anomaly that I came across and adopted. :-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16mqzns", "is_robot_indexable": true, "report_reasons": null, "author": "Neat-Secretary8535", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mqzns/dwh_partitioning_data_domains_into_separate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mqzns/dwh_partitioning_data_domains_into_separate/", "subreddit_subscribers": 129375, "created_utc": 1695129965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a lakehouse. When people run queries directly (via DataGrip or similar)\n\n1. They auth via Okta\n2. The Okta groups they are a member of get passed in the request to Trino\n3. Trino has [file based access control](https://trino.io/docs/current/security/file-system-access-control.html). If any of the groups they are in have access to the tables they are querying, the query runs. Otherwise the query fails.\n\nIs there a viz tool that can do something similar? Use the Okta creds of the *viewer* (not the creator) and pass that along to the query layer. I really don't want to re-implement a permission model in the viz tool.", "author_fullname": "t2_tic2ae1k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a viz tool that can do this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n50pv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695164209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a lakehouse. When people run queries directly (via DataGrip or similar)&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;They auth via Okta&lt;/li&gt;\n&lt;li&gt;The Okta groups they are a member of get passed in the request to Trino&lt;/li&gt;\n&lt;li&gt;Trino has &lt;a href=\"https://trino.io/docs/current/security/file-system-access-control.html\"&gt;file based access control&lt;/a&gt;. If any of the groups they are in have access to the tables they are querying, the query runs. Otherwise the query fails.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Is there a viz tool that can do something similar? Use the Okta creds of the &lt;em&gt;viewer&lt;/em&gt; (not the creator) and pass that along to the query layer. I really don&amp;#39;t want to re-implement a permission model in the viz tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16n50pv", "is_robot_indexable": true, "report_reasons": null, "author": "databolica", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16n50pv/is_there_a_viz_tool_that_can_do_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16n50pv/is_there_a_viz_tool_that_can_do_this/", "subreddit_subscribers": 129375, "created_utc": 1695164209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For those with SAP experience-- what is the best way to learn about working with SAP data? My need isn't so much in working within SAP, but learning how SAP data is modeled and organized so that it can effectively be integrated into a data warehouse.", "author_fullname": "t2_rcxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to learn SAP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mtusq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695136819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those with SAP experience-- what is the best way to learn about working with SAP data? My need isn&amp;#39;t so much in working within SAP, but learning how SAP data is modeled and organized so that it can effectively be integrated into a data warehouse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16mtusq", "is_robot_indexable": true, "report_reasons": null, "author": "drothamel", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mtusq/best_way_to_learn_sap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mtusq/best_way_to_learn_sap/", "subreddit_subscribers": 129375, "created_utc": 1695136819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Obviously you can do this with scripts on an ec2, or in a serverless environment like lambda or eks, but is there a dedicated service for data migration from sftp to s3 where you just provide the sftp credentials and the s3 target?", "author_fullname": "t2_ofoc42j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What aws service can move files from sftp to s3?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mtee6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695135747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Obviously you can do this with scripts on an ec2, or in a serverless environment like lambda or eks, but is there a dedicated service for data migration from sftp to s3 where you just provide the sftp credentials and the s3 target?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16mtee6", "is_robot_indexable": true, "report_reasons": null, "author": "PangeanPrawn", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mtee6/what_aws_service_can_move_files_from_sftp_to_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mtee6/what_aws_service_can_move_files_from_sftp_to_s3/", "subreddit_subscribers": 129375, "created_utc": 1695135747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have done projects, learned necessary skills, learned the basics and made a clean resume showing that I am capable to work as a data engineer. Then why is my resume constantly get rejected by companies and I never get any interviews. Can someone give some tips, much appreciated?", "author_fullname": "t2_5tya99le", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is my resume keep getting rejected?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ni823", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695207237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have done projects, learned necessary skills, learned the basics and made a clean resume showing that I am capable to work as a data engineer. Then why is my resume constantly get rejected by companies and I never get any interviews. Can someone give some tips, much appreciated?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ni823", "is_robot_indexable": true, "report_reasons": null, "author": "zmwaris1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ni823/why_is_my_resume_keep_getting_rejected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ni823/why_is_my_resume_keep_getting_rejected/", "subreddit_subscribers": 129375, "created_utc": 1695207237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\nI'm about to start a new role, and I will be the first data hire at the company. Will mostly be using python for development, and infrastructure is all on AWS currently. I have been asked whether I want a Mac or Windows PC. In my previous role I have always had a windows PC, and mostly used either wsl+docker or Linux VM for any real development work. \nThis setup has always worked well for me, but was wondering if anyone had any thoughts on whether there would be advantages to using a Mac. Or possibly some other things that I should be considering making the choice.\nThanks", "author_fullname": "t2_1m9v0q0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac vs Windows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nghvo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695200870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,\nI&amp;#39;m about to start a new role, and I will be the first data hire at the company. Will mostly be using python for development, and infrastructure is all on AWS currently. I have been asked whether I want a Mac or Windows PC. In my previous role I have always had a windows PC, and mostly used either wsl+docker or Linux VM for any real development work. \nThis setup has always worked well for me, but was wondering if anyone had any thoughts on whether there would be advantages to using a Mac. Or possibly some other things that I should be considering making the choice.\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16nghvo", "is_robot_indexable": true, "report_reasons": null, "author": "oliverwburke", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16nghvo/mac_vs_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16nghvo/mac_vs_windows/", "subreddit_subscribers": 129375, "created_utc": 1695200870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently evaluating solutions for building a real-time feature pipeline -- ingestion, transformation/feature engineering, storage, and serving. There are about 100 data sources (Kafka and CDC) and a few thousand features, some with advanced time series transformations.\n\nI don't use Databricks, but it seems like they have offerings (including Spark) that could handle my use case.\n\nDoes anyone have any insight into whether this would be a good option?\n\nThanks!", "author_fullname": "t2_7vlz5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluating Databricks for Real-Time Feature Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nggkw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695200723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently evaluating solutions for building a real-time feature pipeline -- ingestion, transformation/feature engineering, storage, and serving. There are about 100 data sources (Kafka and CDC) and a few thousand features, some with advanced time series transformations.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t use Databricks, but it seems like they have offerings (including Spark) that could handle my use case.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any insight into whether this would be a good option?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16nggkw", "is_robot_indexable": true, "report_reasons": null, "author": "zacheism", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16nggkw/evaluating_databricks_for_realtime_feature/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16nggkw/evaluating_databricks_for_realtime_feature/", "subreddit_subscribers": 129375, "created_utc": 1695200723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nFirst post in this community, but long time lurker. I work as an SWE in my company, however the users of our products are data engineers.\n\nI'm trying to learn more about data engineers' workflows and tooling to better understand how to build useful features.\n\nMy questions are:\n\n* When you are a Data Engineer joining a big enterprise and have to learn data models/databases, how the data is structured in the 100s of databases they might have and the 1000s of tables. Do you use any tool to have an overview and understand the big picture? Or is this based on documentation the company might have? Do you go top-down (first DBs, then tables) or bottom-up (first tables in one DB and expand from there)?\n* When having to look for relations across the data between different tables/databases, is this done using some tool or is this done based on manual inspection and documentation? Imagine you want to join data from different tables potentially across databases, do you manually inspect to figure good join columns or do you have a tool telling you that?\n* If you use tools for any of the above, can you please tell me which ones? Which is your favorite?\n\nThanks a lot in advance!  \n\n\nEdit: Just FYI, I searched the subreddit for such questions but I couldn't find one that matched this use case. Happy to be sent in the right direction if I missed a post on this topic!\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_13puhj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tools for onboarding DEs or navigating data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ngd84", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695200959.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695200394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;First post in this community, but long time lurker. I work as an SWE in my company, however the users of our products are data engineers.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to learn more about data engineers&amp;#39; workflows and tooling to better understand how to build useful features.&lt;/p&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;When you are a Data Engineer joining a big enterprise and have to learn data models/databases, how the data is structured in the 100s of databases they might have and the 1000s of tables. Do you use any tool to have an overview and understand the big picture? Or is this based on documentation the company might have? Do you go top-down (first DBs, then tables) or bottom-up (first tables in one DB and expand from there)?&lt;/li&gt;\n&lt;li&gt;When having to look for relations across the data between different tables/databases, is this done using some tool or is this done based on manual inspection and documentation? Imagine you want to join data from different tables potentially across databases, do you manually inspect to figure good join columns or do you have a tool telling you that?&lt;/li&gt;\n&lt;li&gt;If you use tools for any of the above, can you please tell me which ones? Which is your favorite?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks a lot in advance!  &lt;/p&gt;\n\n&lt;p&gt;Edit: Just FYI, I searched the subreddit for such questions but I couldn&amp;#39;t find one that matched this use case. Happy to be sent in the right direction if I missed a post on this topic!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ngd84", "is_robot_indexable": true, "report_reasons": null, "author": "santiagocs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ngd84/best_tools_for_onboarding_des_or_navigating_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ngd84/best_tools_for_onboarding_des_or_navigating_data/", "subreddit_subscribers": 129375, "created_utc": 1695200394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\n**Problem:** I designed a RDB in PostgreSQL.  I have 70 tables including junctions etc and nearly 400 attributes in total. I need to keep track of those informations for each attribute (kinda historical metadata):\n\n* source (different data in attributes may come from different sources, and I need to store them)\n* transaction\\_type (is attribute inserted or updated or deleted ...)\n* valid\\_in\\_between (think of a time interval type in pg. It might be two different columns such as start\\_date and end\\_date. It doesn't matter for now.)\n* the value itself\n\n**Reason:** I am doing this because later on this enables me to validate my sources, rearrange the data, track the historical change for some attributes, undo batch insertions, etc. \n\n**Here is my way:** I definitely don't want to recopy my whole database schema, hence I thought it might be better to create a generic table with above fields, with an addition of table name, column name information, and value type. table name and column name will indicate where the data belongs essentially. And value type represents the actual type defined in the database, because the value itself should be the type of varchar to store all different kinds of data (will be converted to varchar in the trigger). Because the data will grow rapidly, I thought to move it from db to a cheaper storage using airflow, etc. \n\n**Question&amp;Help:** What do you think of the design above? What might be the improvements, risks, potential problems I may face with? There are probably some other prettier and easier ways to accomplish those. I appreciate so much the ones who enlighten those ways. I lack knowledge of data warehousing, so at this point, I could not use anchor modeling or something that helps me keep track of historized data, etc.  \n\n\nAnd for you, who read till here, thanks a lot buddy.  \n", "author_fullname": "t2_t1xjvr55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Adding Metadata for Each Attribute Crazy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mzaso", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695150046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; I designed a RDB in PostgreSQL.  I have 70 tables including junctions etc and nearly 400 attributes in total. I need to keep track of those informations for each attribute (kinda historical metadata):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;source (different data in attributes may come from different sources, and I need to store them)&lt;/li&gt;\n&lt;li&gt;transaction_type (is attribute inserted or updated or deleted ...)&lt;/li&gt;\n&lt;li&gt;valid_in_between (think of a time interval type in pg. It might be two different columns such as start_date and end_date. It doesn&amp;#39;t matter for now.)&lt;/li&gt;\n&lt;li&gt;the value itself&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Reason:&lt;/strong&gt; I am doing this because later on this enables me to validate my sources, rearrange the data, track the historical change for some attributes, undo batch insertions, etc. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here is my way:&lt;/strong&gt; I definitely don&amp;#39;t want to recopy my whole database schema, hence I thought it might be better to create a generic table with above fields, with an addition of table name, column name information, and value type. table name and column name will indicate where the data belongs essentially. And value type represents the actual type defined in the database, because the value itself should be the type of varchar to store all different kinds of data (will be converted to varchar in the trigger). Because the data will grow rapidly, I thought to move it from db to a cheaper storage using airflow, etc. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question&amp;amp;Help:&lt;/strong&gt; What do you think of the design above? What might be the improvements, risks, potential problems I may face with? There are probably some other prettier and easier ways to accomplish those. I appreciate so much the ones who enlighten those ways. I lack knowledge of data warehousing, so at this point, I could not use anchor modeling or something that helps me keep track of historized data, etc.  &lt;/p&gt;\n\n&lt;p&gt;And for you, who read till here, thanks a lot buddy.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16mzaso", "is_robot_indexable": true, "report_reasons": null, "author": "gxslash", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mzaso/is_adding_metadata_for_each_attribute_crazy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mzaso/is_adding_metadata_for_each_attribute_crazy/", "subreddit_subscribers": 129375, "created_utc": 1695150046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am gonna create on premise data platform in onpremise vm server. \nSpecs: 50 vcores, 200gb ram, and atleast 5tb disk size.\nStack: dagster, airbyte, minio, spark, trino, clickhouse\n\nHow can I deploy this? Should I create multiple VMs and setup k8s cluster? Or are there any other ways to deploy it better?", "author_fullname": "t2_5g5u53hz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need ideas in deploying data stack on-premise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mv1q3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695139647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am gonna create on premise data platform in onpremise vm server. \nSpecs: 50 vcores, 200gb ram, and atleast 5tb disk size.\nStack: dagster, airbyte, minio, spark, trino, clickhouse&lt;/p&gt;\n\n&lt;p&gt;How can I deploy this? Should I create multiple VMs and setup k8s cluster? Or are there any other ways to deploy it better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16mv1q3", "is_robot_indexable": true, "report_reasons": null, "author": "chanchan_delier", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mv1q3/need_ideas_in_deploying_data_stack_onpremise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mv1q3/need_ideas_in_deploying_data_stack_onpremise/", "subreddit_subscribers": 129375, "created_utc": 1695139647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on an application with a Django REST API that will sit on a massive central table of \\~250B rows of data. This central table will be constantly queried by every user for random sets of 10-50 values on an indexed column to return the whole row. The rest of the API is built on Postgres but seeing as this table doesn't really need to have a relationship to the other tables and could grow substantially in size over time, I'm considering building it in ScyllaDB. Discord moved their message store to ScyllaDB citing its write performance but I'm wondering if the overall goal is **highly concurrent fast single-record lookups** if ScyllaDB still is the best/cheapest option to handle this scale over Postgres more gracefully.", "author_fullname": "t2_fq4ggg7xc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ScyllaDB vs Postgres for massive central table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mtoar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695136388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on an application with a Django REST API that will sit on a massive central table of ~250B rows of data. This central table will be constantly queried by every user for random sets of 10-50 values on an indexed column to return the whole row. The rest of the API is built on Postgres but seeing as this table doesn&amp;#39;t really need to have a relationship to the other tables and could grow substantially in size over time, I&amp;#39;m considering building it in ScyllaDB. Discord moved their message store to ScyllaDB citing its write performance but I&amp;#39;m wondering if the overall goal is &lt;strong&gt;highly concurrent fast single-record lookups&lt;/strong&gt; if ScyllaDB still is the best/cheapest option to handle this scale over Postgres more gracefully.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16mtoar", "is_robot_indexable": true, "report_reasons": null, "author": "FrontendSchmacktend", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mtoar/scylladb_vs_postgres_for_massive_central_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mtoar/scylladb_vs_postgres_for_massive_central_table/", "subreddit_subscribers": 129375, "created_utc": 1695136388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a use case of mobility analytics related stuff where we need to gather a lot of information about device movements and we want to run some pretty rich (as yet unknown) analytics on it and ideally potentially push some sort of other events out the other end (Kafka we already have but anything else is fine too we can integrate whatever) e.g one would be \"someone is stealing our units\" or \"this  is being driven by a complete lunatic\".\n\nOur current set up is there's a few different setups across the business with various flavours of handrolled legacy applications sitting on PostGIS + Cassandra instances of various levels of disrepair that we'll probably need to dig through. This has worked ok up to now but adding on more sophisticated analytics and reacting to things is getting a little bit labour intensive to work on. So I'm wondering if anyone is working in the connected devices/vehicles/spatiotemporal etc space has some solutions that are working ok for them + what they're doing with it?\n\nHalf the stuff I see appears to be marketingware and the other half seems to fall over/go to the stratosphere in costs the moment you're looking at more than a few hundred things moving around (e.g we get ArcGIS suggested at least twice a week). For now we're patching up a lot of the performance stuff with H3 which got us a long way (our biggest tables are 15 Billion Records of data in a PostGIS Instance that's partitioned by Date for about 3 months)  but that seems to bring a ton of kludging for operating across different resolutions that then needs to be built into everything. And creating new topics for different events etc without configuration while also not having sudden weird data patterns have everything die on its arse is a bit clunky at best.\n\nStuff looked at\n\n\\- ArcGIS (Insane costs the moment we talk about decent amounts of data, very limited deployment models, some other teams have it and it's more helpful for mapping/BI stuff than operational usage)\n\n\\- HiveKit (No idea if this is real or not but looks a bit vague on what it can do/scales?)\n\n\\- Looked at Wejo's stack which seemed to be a flavour of Spark + Cassandra but they seem to have gone bust so maybe that was too expensive? And it seems to have been mostly oriented around BI use cases rather than operational software doing \"live stuff\".\n\nSo yeah, what have you actually tried for geospatial/spatiotemporal type data and what actually worked or what was crap for your world? Ideally if it's able to be run in Docker relatively easily to do some prototyping and try out some queries against a stream then  that would be nice but managed platforms etc we can work with if it plugs into anything normal.", "author_fullname": "t2_9u69ulzs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are people actually using for Real time/Geospatial events?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16niae8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695207983.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695207457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a use case of mobility analytics related stuff where we need to gather a lot of information about device movements and we want to run some pretty rich (as yet unknown) analytics on it and ideally potentially push some sort of other events out the other end (Kafka we already have but anything else is fine too we can integrate whatever) e.g one would be &amp;quot;someone is stealing our units&amp;quot; or &amp;quot;this  is being driven by a complete lunatic&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Our current set up is there&amp;#39;s a few different setups across the business with various flavours of handrolled legacy applications sitting on PostGIS + Cassandra instances of various levels of disrepair that we&amp;#39;ll probably need to dig through. This has worked ok up to now but adding on more sophisticated analytics and reacting to things is getting a little bit labour intensive to work on. So I&amp;#39;m wondering if anyone is working in the connected devices/vehicles/spatiotemporal etc space has some solutions that are working ok for them + what they&amp;#39;re doing with it?&lt;/p&gt;\n\n&lt;p&gt;Half the stuff I see appears to be marketingware and the other half seems to fall over/go to the stratosphere in costs the moment you&amp;#39;re looking at more than a few hundred things moving around (e.g we get ArcGIS suggested at least twice a week). For now we&amp;#39;re patching up a lot of the performance stuff with H3 which got us a long way (our biggest tables are 15 Billion Records of data in a PostGIS Instance that&amp;#39;s partitioned by Date for about 3 months)  but that seems to bring a ton of kludging for operating across different resolutions that then needs to be built into everything. And creating new topics for different events etc without configuration while also not having sudden weird data patterns have everything die on its arse is a bit clunky at best.&lt;/p&gt;\n\n&lt;p&gt;Stuff looked at&lt;/p&gt;\n\n&lt;p&gt;- ArcGIS (Insane costs the moment we talk about decent amounts of data, very limited deployment models, some other teams have it and it&amp;#39;s more helpful for mapping/BI stuff than operational usage)&lt;/p&gt;\n\n&lt;p&gt;- HiveKit (No idea if this is real or not but looks a bit vague on what it can do/scales?)&lt;/p&gt;\n\n&lt;p&gt;- Looked at Wejo&amp;#39;s stack which seemed to be a flavour of Spark + Cassandra but they seem to have gone bust so maybe that was too expensive? And it seems to have been mostly oriented around BI use cases rather than operational software doing &amp;quot;live stuff&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;So yeah, what have you actually tried for geospatial/spatiotemporal type data and what actually worked or what was crap for your world? Ideally if it&amp;#39;s able to be run in Docker relatively easily to do some prototyping and try out some queries against a stream then  that would be nice but managed platforms etc we can work with if it plugs into anything normal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16niae8", "is_robot_indexable": true, "report_reasons": null, "author": "tdatas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16niae8/what_are_people_actually_using_for_real/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16niae8/what_are_people_actually_using_for_real/", "subreddit_subscribers": 129375, "created_utc": 1695207457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cb5j4xjcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Improve Cloud Data Warehouse Performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_16nelg7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eeMG12wDxXCCMI0ME2N0qPtqFOp-rQqNdrX7YbXqVmM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695193491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "selectfrom.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://selectfrom.dev/how-to-improve-cloud-data-warehouse-performance-firebolt-9ae705224f82", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CyAlwux3cVhIVSMlCvUICW79v9Gu6zPJqFtjB0Omb9o.jpg?auto=webp&amp;s=df2a53c8f035d2da2660811689a23d1ea5331e78", "width": 1200, "height": 792}, "resolutions": [{"url": "https://external-preview.redd.it/CyAlwux3cVhIVSMlCvUICW79v9Gu6zPJqFtjB0Omb9o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a6f5fca9f3523e0ebfb223f5db8a59f0255877e0", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/CyAlwux3cVhIVSMlCvUICW79v9Gu6zPJqFtjB0Omb9o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=01c962732e28565068a2437c74e829e3b34e3e8b", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/CyAlwux3cVhIVSMlCvUICW79v9Gu6zPJqFtjB0Omb9o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2513730409b5adbf8b9d9726380fbf3fa7248fcf", "width": 320, "height": 211}, {"url": "https://external-preview.redd.it/CyAlwux3cVhIVSMlCvUICW79v9Gu6zPJqFtjB0Omb9o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=88833476c7169d54788a80ccf8602229163bf6b9", "width": 640, "height": 422}, {"url": "https://external-preview.redd.it/CyAlwux3cVhIVSMlCvUICW79v9Gu6zPJqFtjB0Omb9o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=954e1bffe9f058246e1f89e2a4322a81b4b321ab", "width": 960, "height": 633}, {"url": "https://external-preview.redd.it/CyAlwux3cVhIVSMlCvUICW79v9Gu6zPJqFtjB0Omb9o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f545fdabf615c2cf56fa873ff03bbea676389c0", "width": 1080, "height": 712}], "variants": {}, "id": "kHtoQeRsihcHXVZDBDN6C6timpdSpK7pEGjEk2HORBU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16nelg7", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous-Surround882", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16nelg7/how_to_improve_cloud_data_warehouse_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://selectfrom.dev/how-to-improve-cloud-data-warehouse-performance-firebolt-9ae705224f82", "subreddit_subscribers": 129375, "created_utc": 1695193491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, hope everything is well. I have a DAG running in the Google Cloud Composer. But, I am having an issue connecting sql db for the DAG.\n\n- One way I tried was to export my local SQLite db file to Google Cloud Bucket. Then add the URL of this to the Airflow Web UI connections by selecting type as SQLite and host as link to the db file in bucket. But the DAG is getting failed stating that it can\u2019t find the database. Where test button in the connections tab in Airflow Web UI is saying that it cannot open the database.\n\n- Another way I tried was by launching a Google Cloud SQL instance and imported the db to that. But I am not sure what option to select in the Airflow Web UI connections tab for this. \n\nAppreciate your time.", "author_fullname": "t2_l03mtt4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connecting SQL database to Airflow in Google Cloud Composer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ne52w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695191822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, hope everything is well. I have a DAG running in the Google Cloud Composer. But, I am having an issue connecting sql db for the DAG.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;One way I tried was to export my local SQLite db file to Google Cloud Bucket. Then add the URL of this to the Airflow Web UI connections by selecting type as SQLite and host as link to the db file in bucket. But the DAG is getting failed stating that it can\u2019t find the database. Where test button in the connections tab in Airflow Web UI is saying that it cannot open the database.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Another way I tried was by launching a Google Cloud SQL instance and imported the db to that. But I am not sure what option to select in the Airflow Web UI connections tab for this. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Appreciate your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ne52w", "is_robot_indexable": true, "report_reasons": null, "author": "_its_all_goodman", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ne52w/connecting_sql_database_to_airflow_in_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ne52w/connecting_sql_database_to_airflow_in_google/", "subreddit_subscribers": 129375, "created_utc": 1695191822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a dataset with billions of lines of unstructured text, marked by inconsistent delimiters and mixed-format fields detailing personal and transactional data.  \n\nMy friend is leaning towards Alteryx Design Cloud, but I've found it doesn't handle the data well unless it's in a typical CSV format.  \n\nI have been suggested Apache Spark due to its capabilities with large datasets, but our coding skills are limited.  \n\nWhat is your opinion?  \n\nAlso, our local machines can't handle the data size, so we're in need of a cloud solution. ", "author_fullname": "t2_841oovm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nbvq3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695183862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a dataset with billions of lines of unstructured text, marked by inconsistent delimiters and mixed-format fields detailing personal and transactional data.  &lt;/p&gt;\n\n&lt;p&gt;My friend is leaning towards Alteryx Design Cloud, but I&amp;#39;ve found it doesn&amp;#39;t handle the data well unless it&amp;#39;s in a typical CSV format.  &lt;/p&gt;\n\n&lt;p&gt;I have been suggested Apache Spark due to its capabilities with large datasets, but our coding skills are limited.  &lt;/p&gt;\n\n&lt;p&gt;What is your opinion?  &lt;/p&gt;\n\n&lt;p&gt;Also, our local machines can&amp;#39;t handle the data size, so we&amp;#39;re in need of a cloud solution. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16nbvq3", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Consideration-74", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16nbvq3/what_would_you_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16nbvq3/what_would_you_do/", "subreddit_subscribers": 129375, "created_utc": 1695183862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was trying to create a project, where i would need to get the most played songs or popular songs in a city for a given time, lets say the past hour, or past 15 minute. I was not sure if chartmetric could do this. Any help or ideas would be greatly appreciated.", "author_fullname": "t2_3tvvi4on", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to get the most listened to songs (can be whichever music vendor) for a given location for a given period of time frame?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nbj62", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695182676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to create a project, where i would need to get the most played songs or popular songs in a city for a given time, lets say the past hour, or past 15 minute. I was not sure if chartmetric could do this. Any help or ideas would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16nbj62", "is_robot_indexable": true, "report_reasons": null, "author": "prince_grg", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16nbj62/is_there_a_way_to_get_the_most_listened_to_songs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16nbj62/is_there_a_way_to_get_the_most_listened_to_songs/", "subreddit_subscribers": 129375, "created_utc": 1695182676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, we recently just set up all of our streaming applications as ETL jobs in Azure Databricks using Unity Catalog and we were looking at implementing a basic DR plan to secure and back up our data. We know we can replicate individual tables, but what is the best practice for backing up everything in the metastore Storage Account? Is Operational Backups on Azure sufficient for this? Can metastore data just be point in time restored from previous blob versions without any issues on the Workspace side? I couldn\u2019t find any examples of what people currently do for this, so any insight would be much appreciated. Thanks!", "author_fullname": "t2_h6617mxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Unity Catalog backup + restore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n6lgb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695169141.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695168382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, we recently just set up all of our streaming applications as ETL jobs in Azure Databricks using Unity Catalog and we were looking at implementing a basic DR plan to secure and back up our data. We know we can replicate individual tables, but what is the best practice for backing up everything in the metastore Storage Account? Is Operational Backups on Azure sufficient for this? Can metastore data just be point in time restored from previous blob versions without any issues on the Workspace side? I couldn\u2019t find any examples of what people currently do for this, so any insight would be much appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16n6lgb", "is_robot_indexable": true, "report_reasons": null, "author": "SignificantNobody504", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16n6lgb/databricks_unity_catalog_backup_restore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16n6lgb/databricks_unity_catalog_backup_restore/", "subreddit_subscribers": 129375, "created_utc": 1695168382.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}