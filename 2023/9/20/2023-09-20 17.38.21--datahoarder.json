{"kind": "Listing", "data": {"after": "t3_16ngnol", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Here's my list of what's missing and what can still be purchased. [https://easyupload.io/3t6upo](https://easyupload.io/3t6upo) If the link is down just PM me for it.\n\nI''ve been trying to archive all the lost DLC for years and it's important to preserve it all before it's too late.\n\nIf you want to help, Please check your download history to see if you own anything from my list.\n\nAll you need is a usb drive formatted for xbox to copy the DLC and then file share the content folder.\n\nPlease consider to donate just $1 to help me purchase lost content. [https://www.microsoft.com/en-us/p/xbox-gift-card-digital-code/cfq7ttc0k63h/0002?activetab=pivot:overviewtab](https://www.microsoft.com/en-us/p/xbox-gift-card-digital-code/cfq7ttc0k63h/0002?activetab=pivot:overviewtab)\n\nThank You!", "author_fullname": "t2_584b5xa4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time is running out! Help me preserve Xbox 360 content before the 360 Marketplace closes July 2024.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n7l0g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 118, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 118, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695171118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s my list of what&amp;#39;s missing and what can still be purchased. &lt;a href=\"https://easyupload.io/3t6upo\"&gt;https://easyupload.io/3t6upo&lt;/a&gt; If the link is down just PM me for it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;&amp;#39;ve been trying to archive all the lost DLC for years and it&amp;#39;s important to preserve it all before it&amp;#39;s too late.&lt;/p&gt;\n\n&lt;p&gt;If you want to help, Please check your download history to see if you own anything from my list.&lt;/p&gt;\n\n&lt;p&gt;All you need is a usb drive formatted for xbox to copy the DLC and then file share the content folder.&lt;/p&gt;\n\n&lt;p&gt;Please consider to donate just $1 to help me purchase lost content. &lt;a href=\"https://www.microsoft.com/en-us/p/xbox-gift-card-digital-code/cfq7ttc0k63h/0002?activetab=pivot:overviewtab\"&gt;https://www.microsoft.com/en-us/p/xbox-gift-card-digital-code/cfq7ttc0k63h/0002?activetab=pivot:overviewtab&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank You!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vshir43JRCmc4_fZluMPPDr-VXeX5S1C364cWG5uYhs.jpg?auto=webp&amp;s=cf2d46f580e043f95380b8fb0ccc5e341eba76c1", "width": 210, "height": 80}, "resolutions": [{"url": "https://external-preview.redd.it/vshir43JRCmc4_fZluMPPDr-VXeX5S1C364cWG5uYhs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5809f6ce30675ac800ee03d31191923b1b6d245b", "width": 108, "height": 41}], "variants": {}, "id": "iQQyg5CKKXH-zNe6lCGbk6MEyBjG4WNJjKWS__YzU8Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16n7l0g", "is_robot_indexable": true, "report_reasons": null, "author": "KJxbox", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n7l0g/time_is_running_out_help_me_preserve_xbox_360/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n7l0g/time_is_running_out_help_me_preserve_xbox_360/", "subreddit_subscribers": 702885, "created_utc": 1695171118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Demo of scraping Zillow, for sale listings](https://i.redd.it/7jkq3j48b9pb1.gif)\n\nHey everyone,\n\nMy friend and I put together a python real estate scraper that aggregates listings from Zillow, Realtor.com &amp; Redfin. It's requests-based, and quite fast (relative to the search size). You can search for rentals, properties for sale, or those recently sold. And it's super easy to output to csv /excel with to\\_csv() or to\\_excel()\n\nFeel free to give feedback in the comments, we would love to hear your suggestions.\n\nhttps://github.com/ZacharyHampton/HomeHarvest", "author_fullname": "t2_cqwm42f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real estate scraping library for Zillow, Realtor.com &amp; Redfin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7jkq3j48b9pb1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/7jkq3j48b9pb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=a3dcbbff20a22d059aa0ca4412327d8b304463a8"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/7jkq3j48b9pb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=4a772454f9e81b8469884058387a85b12bd98305"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/7jkq3j48b9pb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=0010f7c672d0bc5f7e6fb271c70671fa9e6374e4"}], "s": {"y": 338, "gif": "https://i.redd.it/7jkq3j48b9pb1.gif", "mp4": "https://preview.redd.it/7jkq3j48b9pb1.gif?format=mp4&amp;s=de3b40625ac9b5e2fde5381b2b26d783d8463c49", "x": 600}, "id": "7jkq3j48b9pb1"}}, "name": "t3_16myrgh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pFXwO_yHx6Rx7SOoJ3QD0Io6fpTaMHmqFEdyW85D_30.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695148753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://i.redd.it/7jkq3j48b9pb1.gif\"&gt;Demo of scraping Zillow, for sale listings&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;My friend and I put together a python real estate scraper that aggregates listings from Zillow, Realtor.com &amp;amp; Redfin. It&amp;#39;s requests-based, and quite fast (relative to the search size). You can search for rentals, properties for sale, or those recently sold. And it&amp;#39;s super easy to output to csv /excel with to_csv() or to_excel()&lt;/p&gt;\n\n&lt;p&gt;Feel free to give feedback in the comments, we would love to hear your suggestions.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ZacharyHampton/HomeHarvest\"&gt;https://github.com/ZacharyHampton/HomeHarvest&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16myrgh", "is_robot_indexable": true, "report_reasons": null, "author": "socialretro", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16myrgh/real_estate_scraping_library_for_zillow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16myrgh/real_estate_scraping_library_for_zillow/", "subreddit_subscribers": 702885, "created_utc": 1695148753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using FFS for over a decade and love the UI. My employer IS security team recently won't let me use FreeFileSync because they say it's a security issue. That it contains malicious files. I even tried to run it as a portable app but it's still an issue. What is a good paid alternative?", "author_fullname": "t2_4ea5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some alternatives to FreeFileSync?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mzr3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695151163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using FFS for over a decade and love the UI. My employer IS security team recently won&amp;#39;t let me use FreeFileSync because they say it&amp;#39;s a security issue. That it contains malicious files. I even tried to run it as a portable app but it&amp;#39;s still an issue. What is a good paid alternative?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mzr3a", "is_robot_indexable": true, "report_reasons": null, "author": "videonerd", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mzr3a/what_are_some_alternatives_to_freefilesync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mzr3a/what_are_some_alternatives_to_freefilesync/", "subreddit_subscribers": 702885, "created_utc": 1695151163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "you wouldn't download a house...\n\nactually I would like to considering I'm moving from my childhood house of 20 years and I feel like having video or photos tours of my house wouldn't be enough. Im just that sentimental.\n\nAnyone have experience in this?\n\nI was wondering if there were budget friendly options to digitise my house such as making a virtual tour like the ones you see on real estate websites or other ways you can digitise a house. Potentially if i may also want to use VR.\n\nOf course looking for best budget option with best quality (the highest quality of camera i have is an Iphone 11 pro max)\n\nAlso I'm not sure if this is the right subreddit to post it but I see people on advice on how to scan books etc so I don't see how this is different.\n\nand no minecraft or blender\n\nTL;DR: Looking for ways to \"datahoard\" my childhood house", "author_fullname": "t2_dh4hjpj4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving houses... any budget friendly options to create 360 tours or digitise my house", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16njusx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695212348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;you wouldn&amp;#39;t download a house...&lt;/p&gt;\n\n&lt;p&gt;actually I would like to considering I&amp;#39;m moving from my childhood house of 20 years and I feel like having video or photos tours of my house wouldn&amp;#39;t be enough. Im just that sentimental.&lt;/p&gt;\n\n&lt;p&gt;Anyone have experience in this?&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there were budget friendly options to digitise my house such as making a virtual tour like the ones you see on real estate websites or other ways you can digitise a house. Potentially if i may also want to use VR.&lt;/p&gt;\n\n&lt;p&gt;Of course looking for best budget option with best quality (the highest quality of camera i have is an Iphone 11 pro max)&lt;/p&gt;\n\n&lt;p&gt;Also I&amp;#39;m not sure if this is the right subreddit to post it but I see people on advice on how to scan books etc so I don&amp;#39;t see how this is different.&lt;/p&gt;\n\n&lt;p&gt;and no minecraft or blender&lt;/p&gt;\n\n&lt;p&gt;TL;DR: Looking for ways to &amp;quot;datahoard&amp;quot; my childhood house&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16njusx", "is_robot_indexable": true, "report_reasons": null, "author": "__Acedia_", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16njusx/moving_houses_any_budget_friendly_options_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16njusx/moving_houses_any_budget_friendly_options_to/", "subreddit_subscribers": 702885, "created_utc": 1695212348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As in the title--what is the most durable storage available to consumers?\n\nSeveral years ago, I lost a terabyte of data on my WD portable disk. Happened overnight. One day everything worked, the next it was gone. All of it.\n\nI heard that CDs and DVDs have a lifespan of merely a few years, while SSD disks can withstand a specific number of writes after which they become useless. That leaves vinyl and floppy disks.\n\nUnless I don't know about something? Any storage robust enough to keep going for decades, preferably a lifetime?", "author_fullname": "t2_fvy5hh2jl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The most durable consumer storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n3xkq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695161329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As in the title--what is the most durable storage available to consumers?&lt;/p&gt;\n\n&lt;p&gt;Several years ago, I lost a terabyte of data on my WD portable disk. Happened overnight. One day everything worked, the next it was gone. All of it.&lt;/p&gt;\n\n&lt;p&gt;I heard that CDs and DVDs have a lifespan of merely a few years, while SSD disks can withstand a specific number of writes after which they become useless. That leaves vinyl and floppy disks.&lt;/p&gt;\n\n&lt;p&gt;Unless I don&amp;#39;t know about something? Any storage robust enough to keep going for decades, preferably a lifetime?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n3xkq", "is_robot_indexable": true, "report_reasons": null, "author": "satsumander", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n3xkq/the_most_durable_consumer_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n3xkq/the_most_durable_consumer_storage/", "subreddit_subscribers": 702885, "created_utc": 1695161329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI recently have been trying to preserve my large PC CD game collection onto my NAS, but have been running into some issues.\n\nWhat I am currently trying to do is convert the CDs to ISOs, which I can store in my NAS and also mount to my PC to play the games without the need for the physical CD.\n\nFrom what I have seen online, apparently ImgBurn can do this. I downloaded it from Ninite and have attempted it with 2 disks so far, each providing errors that look something like this:\n\n    1/0 Error!\n    Device: HL-DT-ST DVD+-RW GU90N AICS (F:) (RAID)\n    ScsiStatus: Ox02\n    Interpretation: Check Condition\n    CDS: BE 00 COCO 03 2C00C001 10 COCO\n    Interpretation: Read CD - Sector: 812\n    Sense Area: 71 00 03 CQ 00 COCO OA COCO COCO 11 COCO COCO\n    00\n    SK Interpretation: Medium Error\n    ASC/ASCQ Interpretation: Unrecovered Read Error\n\nThis is where I am getting a bit stuck, I have read online that as a form of \"DRM\", certain games on CDs have unreadable sectors (not sure if that is the right terminology), to prevent unauthorized distribution of the games contents. I have also seen this can be caused by damaged disks.\n\nFrom what I can tell, the CD doesn't seem to be damaged as I can install the game normally fine through the CD, which leads me to believe it may have some sort of \"lock\" on it.\n\nIf this is the case, is there anyway to get around these games \"DRM\" to create an ISO? Is ImgBurn not a good tool to be attempting this with? I'm assuming that these games wouldn't have really that intense of DRM as they are older games spanning from about 1996-2004.\n\nThanks and any help is really appreciated!\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nEDIT:\n\nFor anyone in the same predicament, I found online that a lot of these older CD games use a very ancient form of DRM that is easily by-passed. If they use something called SafeDisk, then all the DRM does is just create bad sectors. To bypass this, I just set ImgBurn to \"Ignore read errors\" and it worked great!", "author_fullname": "t2_lh411", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help creating ISO from older CD based games", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n89g6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695217948.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695173071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I recently have been trying to preserve my large PC CD game collection onto my NAS, but have been running into some issues.&lt;/p&gt;\n\n&lt;p&gt;What I am currently trying to do is convert the CDs to ISOs, which I can store in my NAS and also mount to my PC to play the games without the need for the physical CD.&lt;/p&gt;\n\n&lt;p&gt;From what I have seen online, apparently ImgBurn can do this. I downloaded it from Ninite and have attempted it with 2 disks so far, each providing errors that look something like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;1/0 Error!\nDevice: HL-DT-ST DVD+-RW GU90N AICS (F:) (RAID)\nScsiStatus: Ox02\nInterpretation: Check Condition\nCDS: BE 00 COCO 03 2C00C001 10 COCO\nInterpretation: Read CD - Sector: 812\nSense Area: 71 00 03 CQ 00 COCO OA COCO COCO 11 COCO COCO\n00\nSK Interpretation: Medium Error\nASC/ASCQ Interpretation: Unrecovered Read Error\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This is where I am getting a bit stuck, I have read online that as a form of &amp;quot;DRM&amp;quot;, certain games on CDs have unreadable sectors (not sure if that is the right terminology), to prevent unauthorized distribution of the games contents. I have also seen this can be caused by damaged disks.&lt;/p&gt;\n\n&lt;p&gt;From what I can tell, the CD doesn&amp;#39;t seem to be damaged as I can install the game normally fine through the CD, which leads me to believe it may have some sort of &amp;quot;lock&amp;quot; on it.&lt;/p&gt;\n\n&lt;p&gt;If this is the case, is there anyway to get around these games &amp;quot;DRM&amp;quot; to create an ISO? Is ImgBurn not a good tool to be attempting this with? I&amp;#39;m assuming that these games wouldn&amp;#39;t have really that intense of DRM as they are older games spanning from about 1996-2004.&lt;/p&gt;\n\n&lt;p&gt;Thanks and any help is really appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;For anyone in the same predicament, I found online that a lot of these older CD games use a very ancient form of DRM that is easily by-passed. If they use something called SafeDisk, then all the DRM does is just create bad sectors. To bypass this, I just set ImgBurn to &amp;quot;Ignore read errors&amp;quot; and it worked great!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n89g6", "is_robot_indexable": true, "report_reasons": null, "author": "Sir_Cupcakers", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n89g6/help_creating_iso_from_older_cd_based_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n89g6/help_creating_iso_from_older_cd_based_games/", "subreddit_subscribers": 702885, "created_utc": 1695173071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Truenas Scale 23.10 - COBIA - RC.1 released with dRAID support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16n3bpo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_jz78l", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eD9b0eW8RaWcGHLJNaQd_MCH8jTYpS-alvz4xqJwr0w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "truenas", "selftext": "", "author_fullname": "t2_jz78l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Truenas Scale 23.10 - COBIA - RC.1 released with dRAID support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/truenas", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16n2sig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "SCALE", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eD9b0eW8RaWcGHLJNaQd_MCH8jTYpS-alvz4xqJwr0w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695158387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "truenas.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?auto=webp&amp;s=d3173fa97c4b79ffa0d7c247c564a285a3d49826", "width": 1999, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f18dee47f6658d0b8337f71005b1544365e0e2de", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb2ca363e1cb21ffd89c5ec1ec41ce65aa8dec04", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20b7079869410a7926ef0862b30d644321ae6c6c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bafa86a81d086fe1386c4a7355b81ee29e3fe5d6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6f164ac0818c91538ce9b3259ad4e8f75dd7309", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19c46d5c9b9f5b541d03eecbf1c207362186cecb", "width": 1080, "height": 540}], "variants": {}, "id": "DtooFloJDixg7EB9_jpX05nkPJvBxs1hrPittQcBWJk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "73c79b60-012a-11ec-84c2-3a09d751311e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_zna4k", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0090d5", "id": "16n2sig", "is_robot_indexable": true, "report_reasons": null, "author": "macvirii", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/truenas/comments/16n2sig/truenas_scale_2310_cobia_rc1_released_with_draid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "subreddit_subscribers": 26586, "created_utc": 1695158387.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1695159740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "truenas.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?auto=webp&amp;s=d3173fa97c4b79ffa0d7c247c564a285a3d49826", "width": 1999, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f18dee47f6658d0b8337f71005b1544365e0e2de", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb2ca363e1cb21ffd89c5ec1ec41ce65aa8dec04", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20b7079869410a7926ef0862b30d644321ae6c6c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bafa86a81d086fe1386c4a7355b81ee29e3fe5d6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6f164ac0818c91538ce9b3259ad4e8f75dd7309", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19c46d5c9b9f5b541d03eecbf1c207362186cecb", "width": 1080, "height": 540}], "variants": {}, "id": "DtooFloJDixg7EB9_jpX05nkPJvBxs1hrPittQcBWJk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n3bpo", "is_robot_indexable": true, "report_reasons": null, "author": "macvirii", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_16n2sig", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n3bpo/truenas_scale_2310_cobia_rc1_released_with_draid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "subreddit_subscribers": 702885, "created_utc": 1695159740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know it's been there decades and I've used it back in the day. But recently I've been trying to download lots of videos together and I have been having lots of issues with Internet Download Manager like downloads failing because of timeouts, security connection establishment failure, etc. so had to manually restart them by starting from scratch again. \n\nIs there anything better out there? Preferably freeware that can handle the workload of downloading lots of files at once. Also, ideally would like something that can somewhat automate the download process if I can point to it what quality of video file to capture from a login site for example 2160p, etc.\n\nWould be great to have any leads out there. I have no technical knowledge so can't do command line, unfortunately.", "author_fullname": "t2_ffjtxxr5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anything better than IDM (Internet Download Manager) out there?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n0wg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695153936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s been there decades and I&amp;#39;ve used it back in the day. But recently I&amp;#39;ve been trying to download lots of videos together and I have been having lots of issues with Internet Download Manager like downloads failing because of timeouts, security connection establishment failure, etc. so had to manually restart them by starting from scratch again. &lt;/p&gt;\n\n&lt;p&gt;Is there anything better out there? Preferably freeware that can handle the workload of downloading lots of files at once. Also, ideally would like something that can somewhat automate the download process if I can point to it what quality of video file to capture from a login site for example 2160p, etc.&lt;/p&gt;\n\n&lt;p&gt;Would be great to have any leads out there. I have no technical knowledge so can&amp;#39;t do command line, unfortunately.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n0wg6", "is_robot_indexable": true, "report_reasons": null, "author": "101az", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n0wg6/anything_better_than_idm_internet_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n0wg6/anything_better_than_idm_internet_download/", "subreddit_subscribers": 702885, "created_utc": 1695153936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone. I would like to hear the opinion from this community about choosing disks for a new NAS. To put it simply, i want to build a tiny home NAS server, and based on my budget i can go with 2 options for the storage. A) Buy 4 new 2TB disks. B) Buy 4 used 4TB disks. (they are about 40k hours old, around 5 years of usage). What option would you go for and why? Thank you!", "author_fullname": "t2_ah3xat1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Used or new drives for a small NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n09g6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695152397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I would like to hear the opinion from this community about choosing disks for a new NAS. To put it simply, i want to build a tiny home NAS server, and based on my budget i can go with 2 options for the storage. A) Buy 4 new 2TB disks. B) Buy 4 used 4TB disks. (they are about 40k hours old, around 5 years of usage). What option would you go for and why? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n09g6", "is_robot_indexable": true, "report_reasons": null, "author": "CamaronSantuchi", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n09g6/used_or_new_drives_for_a_small_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n09g6/used_or_new_drives_for_a_small_nas/", "subreddit_subscribers": 702885, "created_utc": 1695152397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "if you had varying budgets, what would be your dream setup that you would build yourself? And would be your use case for it?\n\n&amp;#x200B;\n\nif I had more money lying around then I knew what to do with this is what I'd get: [Supermicro SuperStorage Server 6049P-E1CR36L - 36x SATA/SAS - LSI 3008 12G SAS - Dual 10-Gigabit Ethernet](https://www.thinkmate.com/system/superstorage-server-6049p-e1cr36l), and throw 36 x 22TB drives in a RAID 6 and 2x 4TB NVMe drives in RAID 1, but at a whopping $40,700.00 it's out of reach \n\n&amp;#x200B;\n\nBut at the moment I'm just eyeing a [Define 7 XL case](https://www.fractal-design.com/products/cases/define/define-7-xl/black-tg-dark-tint/) that can house 18x 3.5\" HDD's + 5x 2.5\" SSD's + 2x NVMe's. I can transplant my current setup into this case. + a [24 port SATA PCI Card](https://www.amazon.com/gp/product/B09K3FT3ZZ/ref=ox_sc_saved_title_2?smid=A1MK2DD7C33I65&amp;th=1)  \nThe case ($235) and the PCI card ($143) aren't really that expensive to shift, then add all my current drives plus whatever else I buy in the future\n\n&amp;#x200B;\n\nI've also been eyeing a [Yottamaster 5 Bay](https://www.amazon.com/gp/product/B08DLTKXCP/ref=ox_sc_saved_title_3?smid=A3OLRMD4MBYEYY&amp;th=1) external case ($280) that can daisy chain up to 3 times and supposedly can get up 10Gbps, but I'm wary that if I'm doing things on multiple disks it'll diminish the speed on the other disks.\n\n&amp;#x200B;\n\nMy use case is mostly just Plex and arcade stuff, so the data is at rest most of the time  \n\n\nIn any case, I'm really curious as to what your guys' solutions would be.  \n\n\n&amp;#x200B;", "author_fullname": "t2_1c4sxc16", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your dream storage configuration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mwkrj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695143326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;if you had varying budgets, what would be your dream setup that you would build yourself? And would be your use case for it?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;if I had more money lying around then I knew what to do with this is what I&amp;#39;d get: &lt;a href=\"https://www.thinkmate.com/system/superstorage-server-6049p-e1cr36l\"&gt;Supermicro SuperStorage Server 6049P-E1CR36L - 36x SATA/SAS - LSI 3008 12G SAS - Dual 10-Gigabit Ethernet&lt;/a&gt;, and throw 36 x 22TB drives in a RAID 6 and 2x 4TB NVMe drives in RAID 1, but at a whopping $40,700.00 it&amp;#39;s out of reach &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But at the moment I&amp;#39;m just eyeing a &lt;a href=\"https://www.fractal-design.com/products/cases/define/define-7-xl/black-tg-dark-tint/\"&gt;Define 7 XL case&lt;/a&gt; that can house 18x 3.5&amp;quot; HDD&amp;#39;s + 5x 2.5&amp;quot; SSD&amp;#39;s + 2x NVMe&amp;#39;s. I can transplant my current setup into this case. + a &lt;a href=\"https://www.amazon.com/gp/product/B09K3FT3ZZ/ref=ox_sc_saved_title_2?smid=A1MK2DD7C33I65&amp;amp;th=1\"&gt;24 port SATA PCI Card&lt;/a&gt;&lt;br/&gt;\nThe case ($235) and the PCI card ($143) aren&amp;#39;t really that expensive to shift, then add all my current drives plus whatever else I buy in the future&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also been eyeing a &lt;a href=\"https://www.amazon.com/gp/product/B08DLTKXCP/ref=ox_sc_saved_title_3?smid=A3OLRMD4MBYEYY&amp;amp;th=1\"&gt;Yottamaster 5 Bay&lt;/a&gt; external case ($280) that can daisy chain up to 3 times and supposedly can get up 10Gbps, but I&amp;#39;m wary that if I&amp;#39;m doing things on multiple disks it&amp;#39;ll diminish the speed on the other disks.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My use case is mostly just Plex and arcade stuff, so the data is at rest most of the time  &lt;/p&gt;\n\n&lt;p&gt;In any case, I&amp;#39;m really curious as to what your guys&amp;#39; solutions would be.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mwkrj", "is_robot_indexable": true, "report_reasons": null, "author": "MichaeldeBlok", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mwkrj/whats_your_dream_storage_configuration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mwkrj/whats_your_dream_storage_configuration/", "subreddit_subscribers": 702885, "created_utc": 1695143326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On my PC, I really couldn't be bothered to fit a 3.5 inch drive in the case that I have, so instead I use an external hard drive enclosure that connects through USB 3.1 that also has to be plugged into an outlet. I use this hard drive (14tb) to store all of my shows and movies that I own to use for Plex! Thing is, what I've been doing is whenever I want to watch something, I'll turn on the PC and then turn on the drive. Once I'm done for the day, I turn the drive off, and then put my PC to sleep. Whenever I turn on the drive or when it has to \"wake up\" when it's already on, it does a bunch of click noises for a few seconds as it's booting up, which is normal. My question is, does the drive booting up put more strain on it then if I were to just keep it on? And if I were to keep it on, is there a way to prevent the drive from \"going to sleep\" while it's turned on? Or should I just stick to turning it off whenever I don't use it? Thanks!", "author_fullname": "t2_5e3g1q3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should a hard drive be powered off when not in use, or is it better to keep it on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16npix0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695226990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On my PC, I really couldn&amp;#39;t be bothered to fit a 3.5 inch drive in the case that I have, so instead I use an external hard drive enclosure that connects through USB 3.1 that also has to be plugged into an outlet. I use this hard drive (14tb) to store all of my shows and movies that I own to use for Plex! Thing is, what I&amp;#39;ve been doing is whenever I want to watch something, I&amp;#39;ll turn on the PC and then turn on the drive. Once I&amp;#39;m done for the day, I turn the drive off, and then put my PC to sleep. Whenever I turn on the drive or when it has to &amp;quot;wake up&amp;quot; when it&amp;#39;s already on, it does a bunch of click noises for a few seconds as it&amp;#39;s booting up, which is normal. My question is, does the drive booting up put more strain on it then if I were to just keep it on? And if I were to keep it on, is there a way to prevent the drive from &amp;quot;going to sleep&amp;quot; while it&amp;#39;s turned on? Or should I just stick to turning it off whenever I don&amp;#39;t use it? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16npix0", "is_robot_indexable": true, "report_reasons": null, "author": "WaldyTMS", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16npix0/should_a_hard_drive_be_powered_off_when_not_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16npix0/should_a_hard_drive_be_powered_off_when_not_in/", "subreddit_subscribers": 702885, "created_utc": 1695226990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi. I have some books about aircrafts which contain some text but mostly pictures. Some of these books are no longer available in the market, so I am thinking to scan them and have them in digital form (pdf). \n\nI am completely rookie to this, and my aim is to scan those books and not lose any quality from the images they contain. \n\n&amp;#x200B;\n\nWhat would be the best resolution to scan the pages/images ? Is 300dpi enough, or will it give me low quality pictures?\n\n&amp;#x200B;\n\nthanks in advance for the help.", "author_fullname": "t2_1s0ymi9v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resolution for Scanning books with pictures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n10sh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695154224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I have some books about aircrafts which contain some text but mostly pictures. Some of these books are no longer available in the market, so I am thinking to scan them and have them in digital form (pdf). &lt;/p&gt;\n\n&lt;p&gt;I am completely rookie to this, and my aim is to scan those books and not lose any quality from the images they contain. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What would be the best resolution to scan the pages/images ? Is 300dpi enough, or will it give me low quality pictures?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks in advance for the help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n10sh", "is_robot_indexable": true, "report_reasons": null, "author": "tripialos", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n10sh/resolution_for_scanning_books_with_pictures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n10sh/resolution_for_scanning_books_with_pictures/", "subreddit_subscribers": 702885, "created_utc": 1695154224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone have any advice for having two geographically seprated NAS systems on separate networks back up to each other/stay in sync? For example: if one were in Denver and one were in New York, I want to be able to add/delete/modify files in New York and the changes be synced to the one in Denver or vice versa.", "author_fullname": "t2_ea47g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync geographcially seprated Synology NAS systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mx7np", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695144913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any advice for having two geographically seprated NAS systems on separate networks back up to each other/stay in sync? For example: if one were in Denver and one were in New York, I want to be able to add/delete/modify files in New York and the changes be synced to the one in Denver or vice versa.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mx7np", "is_robot_indexable": true, "report_reasons": null, "author": "buhbuhbuhbary", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mx7np/sync_geographcially_seprated_synology_nas_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mx7np/sync_geographcially_seprated_synology_nas_systems/", "subreddit_subscribers": 702885, "created_utc": 1695144913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently running 3x 8tb drives in RAID 5 (Windows configuration)  with a few additional smaller drives on the side. Pretty much just an old gaming pc, because I already had it. It's served it's purpose well, but I'm at the point where the motherboard itself can't handle many more drives. Any ideas on where I should go from here? Mainly looking for ideas on how I can 'future-proof' the number of drives I'll collect and want to attach in the next couple years. I'd love to continue using most of the hardware I have if possible, considering it still works fine. Are there motherboards I should be looking for specifically with this purpose? Do they make some sort of SATA expansion slot for PCIE or any other solutions? Would like to prepare for 10-15 drives within the next 2-3 years.\n\nAlso, been looking for a different RAID solution but not too sure on what's hot these days. Are hardware RAID controllers the way to go?", "author_fullname": "t2_txa4pf2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Number of drives getting pretty high. Looking for where to upgrade next in order to expand amount of drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16nph5n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695226868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently running 3x 8tb drives in RAID 5 (Windows configuration)  with a few additional smaller drives on the side. Pretty much just an old gaming pc, because I already had it. It&amp;#39;s served it&amp;#39;s purpose well, but I&amp;#39;m at the point where the motherboard itself can&amp;#39;t handle many more drives. Any ideas on where I should go from here? Mainly looking for ideas on how I can &amp;#39;future-proof&amp;#39; the number of drives I&amp;#39;ll collect and want to attach in the next couple years. I&amp;#39;d love to continue using most of the hardware I have if possible, considering it still works fine. Are there motherboards I should be looking for specifically with this purpose? Do they make some sort of SATA expansion slot for PCIE or any other solutions? Would like to prepare for 10-15 drives within the next 2-3 years.&lt;/p&gt;\n\n&lt;p&gt;Also, been looking for a different RAID solution but not too sure on what&amp;#39;s hot these days. Are hardware RAID controllers the way to go?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nph5n", "is_robot_indexable": true, "report_reasons": null, "author": "empaw1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nph5n/number_of_drives_getting_pretty_high_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nph5n/number_of_drives_getting_pretty_high_looking_for/", "subreddit_subscribers": 702885, "created_utc": 1695226868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used to have unlimited, but never tested it out as I only had 5 TB, I\u2019m now close to 8 TB and now understand that people who are on the Old unlimited plan was moved over to a new plan, I\u2019m not sure if I have been moved or not, but when I look at my apps it says 7.5 TB out of 10.046 TB.\nIs this my true  limit or will they let me upload more? Have you moved on if so where? I heardback Blaze was a good option?", "author_fullname": "t2_ld9gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old GSuite users, what are you doing now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nhfcr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695204399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to have unlimited, but never tested it out as I only had 5 TB, I\u2019m now close to 8 TB and now understand that people who are on the Old unlimited plan was moved over to a new plan, I\u2019m not sure if I have been moved or not, but when I look at my apps it says 7.5 TB out of 10.046 TB.\nIs this my true  limit or will they let me upload more? Have you moved on if so where? I heardback Blaze was a good option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nhfcr", "is_robot_indexable": true, "report_reasons": null, "author": "AlexKLMan", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nhfcr/old_gsuite_users_what_are_you_doing_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nhfcr/old_gsuite_users_what_are_you_doing_now/", "subreddit_subscribers": 702885, "created_utc": 1695204399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm worried Elon's going to nuke this website. \n\nRecently my best friend passed away at way too young. She left behind a daughter who will one day want all of her mothers posts and truthfully I personally don't want to lose her stuff or be paywalled off from seeing her. \n\nFrom suggestions I found on this board and others I stumbled across WFDownloader. \n\nEvery time I follow the instructions i get an error \"Http error fetching URL. 404, the resource does not exist.\" \n\nI've made sure https:// is in the url. \n\nThe only thing I think may be a hindrance is my friends twitter handle has special characters at the end of it which is 2 underscores __\n\nBut that said I tried my handle, with no special characters and it's not working. \n\nI found a github of 2 programs I cant figure out how to use them https://github.com/n0madic/twitter-scraper &amp; https://github.com/mmpx12/twitter-media-downloader\n\nAny help would be appreciated. \n\n##**Tl;dr - Help me backup my deceased friends profile.**", "author_fullname": "t2_h47dy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up a deceased loved ones twitter profile. - Having issues with WFDownloader - Need help and/or alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n9mlp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695176887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m worried Elon&amp;#39;s going to nuke this website. &lt;/p&gt;\n\n&lt;p&gt;Recently my best friend passed away at way too young. She left behind a daughter who will one day want all of her mothers posts and truthfully I personally don&amp;#39;t want to lose her stuff or be paywalled off from seeing her. &lt;/p&gt;\n\n&lt;p&gt;From suggestions I found on this board and others I stumbled across WFDownloader. &lt;/p&gt;\n\n&lt;p&gt;Every time I follow the instructions i get an error &amp;quot;Http error fetching URL. 404, the resource does not exist.&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve made sure https:// is in the url. &lt;/p&gt;\n\n&lt;p&gt;The only thing I think may be a hindrance is my friends twitter handle has special characters at the end of it which is 2 underscores __&lt;/p&gt;\n\n&lt;p&gt;But that said I tried my handle, with no special characters and it&amp;#39;s not working. &lt;/p&gt;\n\n&lt;p&gt;I found a github of 2 programs I cant figure out how to use them &lt;a href=\"https://github.com/n0madic/twitter-scraper\"&gt;https://github.com/n0madic/twitter-scraper&lt;/a&gt; &amp;amp; &lt;a href=\"https://github.com/mmpx12/twitter-media-downloader\"&gt;https://github.com/mmpx12/twitter-media-downloader&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated. &lt;/p&gt;\n\n&lt;h2&gt;&lt;strong&gt;Tl;dr - Help me backup my deceased friends profile.&lt;/strong&gt;&lt;/h2&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/i6F3MghDwxwhqLNl3DxvfzLLKrdC27xXo1oR9Zhi5N0.jpg?auto=webp&amp;s=dc1a2687cf6bfb4a4714bf8667bbf06f47f454f7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/i6F3MghDwxwhqLNl3DxvfzLLKrdC27xXo1oR9Zhi5N0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=edc14030a5ddde587b9a2ea973c22dcd77a5a289", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/i6F3MghDwxwhqLNl3DxvfzLLKrdC27xXo1oR9Zhi5N0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=957b208ec9b45626d921cd0f78e217d973d99577", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/i6F3MghDwxwhqLNl3DxvfzLLKrdC27xXo1oR9Zhi5N0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a96be8326b1e78830f1b2e3fdea9e391b1f02258", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/i6F3MghDwxwhqLNl3DxvfzLLKrdC27xXo1oR9Zhi5N0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e3338b0cc9123efc0ca70dc700243108c375531a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/i6F3MghDwxwhqLNl3DxvfzLLKrdC27xXo1oR9Zhi5N0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad0ce35253b6d4d2fc957df208e794f2f171e1e0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/i6F3MghDwxwhqLNl3DxvfzLLKrdC27xXo1oR9Zhi5N0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9f7b755207187e9d0bc5a2f5ee5a1038a214ddab", "width": 1080, "height": 540}], "variants": {}, "id": "9H_i6yIsShCt3BvBc3QvIxDoy-yw1GJz9lS8Kl5Kp0E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n9mlp", "is_robot_indexable": true, "report_reasons": null, "author": "ShadowBomber", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n9mlp/backing_up_a_deceased_loved_ones_twitter_profile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n9mlp/backing_up_a_deceased_loved_ones_twitter_profile/", "subreddit_subscribers": 702885, "created_utc": 1695176887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, first time posting here. I'm a professional photographer who generates about a TB every week or two when on assignment, averaging about 15TB/year. Honestly the different systems and setups for storage are extremely overwhelming, so I've tried to do some reading on this but I'm struggling to figure out where to begin. \n\nRight now I have two RAID backup systems - a direct attached Promise Pegasus3 with 4x 4TB drives. It is 100% full. \n\nWhen that filled up I got a Synology DS1520+ NAS system with 5x 18TB Seagate Ironwolf drives. Probably about 20% full at the moment. \n\nMy issue is that the Synology is SLOWWWWW, like far too slow for me to edit from, and honestly excruciatingly slow even just for standard backup. Right now I come home from a trip and I'll backup my photos to the Synology and it'll take 6-18 hours, but then I still have to use an SSD (or several) with duplicate files to edit from. I just signed up for Dropbox Enterprise so I have unlimited cloud backup (and uploading to DB is easily 2x the speed of my Synology, even when plugged directly in with the ethernet cable), which effectively renders the Synology as a $5,000 paperweight.\n\nSO, I'd love to simplify my setup down into one singular RAID system that I can plug directly into with thunderbolt so it has the speed for editing and the convenience of being a local external drive. I'm fine with transferring the entirety of my Promise Pegasus to a new RAID system (4x4TB drives aren't massive so I'm probably due to upgrade that anyway), but I'd very much like to reuse the 5x218TB Seagate drives because those were not cheap. \n\nWhat would be the easiest and simplest way to move all my stuff from the Pegasus AND the Synology to a new RAID system while *hopefully* reusing the $1,500 worth of drives from the Synology? From my reading it seems that I won't be able to just pull the drives from the Synology and put them in a new system because the operating system won't be compatible and I'll likely lose all my data. \n\nOr would I be better off just buying new drives in a fully-built system and transferring everything from both current systems and then selling the Synology with my old drives in it (after formatting them, of course)? \n\n&amp;#x200B;\n\nThank you for reading this clusterf\\*ck of a question from someone who loves taking photos but doesn't know wtf to do afterwards.", "author_fullname": "t2_rc1st", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to expand/simplify my RAID system and my brain is melting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n3qwk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695160858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, first time posting here. I&amp;#39;m a professional photographer who generates about a TB every week or two when on assignment, averaging about 15TB/year. Honestly the different systems and setups for storage are extremely overwhelming, so I&amp;#39;ve tried to do some reading on this but I&amp;#39;m struggling to figure out where to begin. &lt;/p&gt;\n\n&lt;p&gt;Right now I have two RAID backup systems - a direct attached Promise Pegasus3 with 4x 4TB drives. It is 100% full. &lt;/p&gt;\n\n&lt;p&gt;When that filled up I got a Synology DS1520+ NAS system with 5x 18TB Seagate Ironwolf drives. Probably about 20% full at the moment. &lt;/p&gt;\n\n&lt;p&gt;My issue is that the Synology is SLOWWWWW, like far too slow for me to edit from, and honestly excruciatingly slow even just for standard backup. Right now I come home from a trip and I&amp;#39;ll backup my photos to the Synology and it&amp;#39;ll take 6-18 hours, but then I still have to use an SSD (or several) with duplicate files to edit from. I just signed up for Dropbox Enterprise so I have unlimited cloud backup (and uploading to DB is easily 2x the speed of my Synology, even when plugged directly in with the ethernet cable), which effectively renders the Synology as a $5,000 paperweight.&lt;/p&gt;\n\n&lt;p&gt;SO, I&amp;#39;d love to simplify my setup down into one singular RAID system that I can plug directly into with thunderbolt so it has the speed for editing and the convenience of being a local external drive. I&amp;#39;m fine with transferring the entirety of my Promise Pegasus to a new RAID system (4x4TB drives aren&amp;#39;t massive so I&amp;#39;m probably due to upgrade that anyway), but I&amp;#39;d very much like to reuse the 5x218TB Seagate drives because those were not cheap. &lt;/p&gt;\n\n&lt;p&gt;What would be the easiest and simplest way to move all my stuff from the Pegasus AND the Synology to a new RAID system while &lt;em&gt;hopefully&lt;/em&gt; reusing the $1,500 worth of drives from the Synology? From my reading it seems that I won&amp;#39;t be able to just pull the drives from the Synology and put them in a new system because the operating system won&amp;#39;t be compatible and I&amp;#39;ll likely lose all my data. &lt;/p&gt;\n\n&lt;p&gt;Or would I be better off just buying new drives in a fully-built system and transferring everything from both current systems and then selling the Synology with my old drives in it (after formatting them, of course)? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading this clusterf*ck of a question from someone who loves taking photos but doesn&amp;#39;t know wtf to do afterwards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n3qwk", "is_robot_indexable": true, "report_reasons": null, "author": "Nateloobz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n3qwk/need_to_expandsimplify_my_raid_system_and_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n3qwk/need_to_expandsimplify_my_raid_system_and_my/", "subreddit_subscribers": 702885, "created_utc": 1695160858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone!\n\nI'm new to this so please go easy on me. I've been trying to digitize my Hi8 tapes from my childhood.  I recently purchased a Sony DCR-TRV315 to connect it via Firewire to my PC, since the original Handycam I have and that all the tapes were recorded on a CCD-TRV99, which doesn't support Firewire. I just bought a PCIE Firewire card and installed it to my computer with the correct drivers. I go to boot up Premiere Pro and go to the Capture tab and it says that the \"capture device is offline\". I've tried messing around in the settings, making sure that it's on DV, even trying to set the device brand and type to the closest Sony handycam. Nothing works for some reason.\n\nI've tried OBS, VirtualDub, and other software but it's not popping up on there either. The IEEE 1394 driver is on legacy and my computer recognizes the Handycam as \"61883 Class Bus Device\"\n\nIf there's anything I may have missed or any other advice that could help resolve this issue, I'd greatly appreciate it. Thank you!", "author_fullname": "t2_12d3xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sony Digital 8 Handycam not able to record via Firewire", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mzjjd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695150632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to this so please go easy on me. I&amp;#39;ve been trying to digitize my Hi8 tapes from my childhood.  I recently purchased a Sony DCR-TRV315 to connect it via Firewire to my PC, since the original Handycam I have and that all the tapes were recorded on a CCD-TRV99, which doesn&amp;#39;t support Firewire. I just bought a PCIE Firewire card and installed it to my computer with the correct drivers. I go to boot up Premiere Pro and go to the Capture tab and it says that the &amp;quot;capture device is offline&amp;quot;. I&amp;#39;ve tried messing around in the settings, making sure that it&amp;#39;s on DV, even trying to set the device brand and type to the closest Sony handycam. Nothing works for some reason.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried OBS, VirtualDub, and other software but it&amp;#39;s not popping up on there either. The IEEE 1394 driver is on legacy and my computer recognizes the Handycam as &amp;quot;61883 Class Bus Device&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;If there&amp;#39;s anything I may have missed or any other advice that could help resolve this issue, I&amp;#39;d greatly appreciate it. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mzjjd", "is_robot_indexable": true, "report_reasons": null, "author": "onvang", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mzjjd/sony_digital_8_handycam_not_able_to_record_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mzjjd/sony_digital_8_handycam_not_able_to_record_via/", "subreddit_subscribers": 702885, "created_utc": 1695150632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nI've been trying to use various Hangouts JSON readers from GitHub (namely [this one](https://github.com/Jessecar96/hangouts-reader) and [this one](https://github.com/adrish96/Hangouts-JSON-Parser/blob/master/HangoutJsonParser.py)), but I can't for the life of me get them to work.\n\nI think the issue may be at least in part due to the fact that my files are backed up as Google Chat exports and NOT Hangouts -- is this common? I think the chat was migrated to Google Chat at some point in time, so that's why it was moved. I renamed the messages.json file to Hangouts.json, and it just spit out some errors.\n\nI don't have the skills to fix the script to work with the potentially different formatting of the Chat files, so I want to see if anybody else has had a similar issue and found a solution...", "author_fullname": "t2_107h5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Hangouts takeout data parser for Google Chat?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mwrod", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695143813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying to use various Hangouts JSON readers from GitHub (namely &lt;a href=\"https://github.com/Jessecar96/hangouts-reader\"&gt;this one&lt;/a&gt; and &lt;a href=\"https://github.com/adrish96/Hangouts-JSON-Parser/blob/master/HangoutJsonParser.py\"&gt;this one&lt;/a&gt;), but I can&amp;#39;t for the life of me get them to work.&lt;/p&gt;\n\n&lt;p&gt;I think the issue may be at least in part due to the fact that my files are backed up as Google Chat exports and NOT Hangouts -- is this common? I think the chat was migrated to Google Chat at some point in time, so that&amp;#39;s why it was moved. I renamed the messages.json file to Hangouts.json, and it just spit out some errors.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have the skills to fix the script to work with the potentially different formatting of the Chat files, so I want to see if anybody else has had a similar issue and found a solution...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?auto=webp&amp;s=e2b7fa2752944a9eb0a93b7df41a029ec58cb5a6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7c28d57238c1210bf3ade3e07be822d4cf57535", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e879461097e00945ef05a9fcb3b8aedd70ae5bb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b43862bb9b300a1d080d01c54b9756f5fde1001a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4e0abc4d0bd5266a3530b3a4a6f9cf5e6685ca6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f82782f62519772c4a1640db1f6fcbd976f201eb", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6406ae84cd42000b3daf2364626b0a4055a6f711", "width": 1080, "height": 540}], "variants": {}, "id": "SiLrOgT-sA9pjgWd6-jz8kfvfIH5c34B9rAL_W4UfOk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mwrod", "is_robot_indexable": true, "report_reasons": null, "author": "gts250gamer101", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mwrod/google_hangouts_takeout_data_parser_for_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mwrod/google_hangouts_takeout_data_parser_for_google/", "subreddit_subscribers": 702885, "created_utc": 1695143813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "EDIT: PHYSICAL DISCS/DVDS/BLURAYS NOT JUST A HARD DRIVE.\n\nI just recently got some BDXL 100GB disks and the proper writer so I can make some easy cold backups of important files on my NAS.\n\nI'd like to be able to back up incremental snapshots of my NAS (i.e. I added 50 files one day, 200 on the other day -- assuming pretty much no file modifications). I wonder if there's any software out there that can keep track of \"what's backed up so far\" for you so you don't have to sift through your folders manually to figure out what you put on disks and what you didn't.\n\n(The problem is that, because I won't have access to read every disk I've backed up so far when creating a new disk, I need to figure out a way to track that.)\n\nAny recommendations?", "author_fullname": "t2_7q1apdlm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I do incremental backups onto disk?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nl0co", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695215620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;EDIT: PHYSICAL DISCS/DVDS/BLURAYS NOT JUST A HARD DRIVE.&lt;/p&gt;\n\n&lt;p&gt;I just recently got some BDXL 100GB disks and the proper writer so I can make some easy cold backups of important files on my NAS.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to be able to back up incremental snapshots of my NAS (i.e. I added 50 files one day, 200 on the other day -- assuming pretty much no file modifications). I wonder if there&amp;#39;s any software out there that can keep track of &amp;quot;what&amp;#39;s backed up so far&amp;quot; for you so you don&amp;#39;t have to sift through your folders manually to figure out what you put on disks and what you didn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;(The problem is that, because I won&amp;#39;t have access to read every disk I&amp;#39;ve backed up so far when creating a new disk, I need to figure out a way to track that.)&lt;/p&gt;\n\n&lt;p&gt;Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nl0co", "is_robot_indexable": true, "report_reasons": null, "author": "ConquestLunatic", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nl0co/how_do_i_do_incremental_backups_onto_disk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nl0co/how_do_i_do_incremental_backups_onto_disk/", "subreddit_subscribers": 702885, "created_utc": 1695215620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "or its just me? i check sites like downorjustme and it is down for them. anyone knows why uptobox was down for hours now?", "author_fullname": "t2_b1kix", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is uptobox down for everyone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nkngc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695214641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;or its just me? i check sites like downorjustme and it is down for them. anyone knows why uptobox was down for hours now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nkngc", "is_robot_indexable": true, "report_reasons": null, "author": "Zaiik", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nkngc/is_uptobox_down_for_everyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nkngc/is_uptobox_down_for_everyone/", "subreddit_subscribers": 702885, "created_utc": 1695214641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hoping someone can provide some clarity on this.  I started suing iDrive last year and have had no issues backing up specific drives/folders.  I'm now looking into using the Cloud Drive feature to have a working folder between my computers.  I'm running into an issue where items in the Cloud Drive are still taking up hard drive space.  Is that how it's supposed to function?  I figured it would just store all files in the cloud.", "author_fullname": "t2_4vubv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "iDrive Cloud Drive Issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16njqvw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695212418.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695212036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping someone can provide some clarity on this.  I started suing iDrive last year and have had no issues backing up specific drives/folders.  I&amp;#39;m now looking into using the Cloud Drive feature to have a working folder between my computers.  I&amp;#39;m running into an issue where items in the Cloud Drive are still taking up hard drive space.  Is that how it&amp;#39;s supposed to function?  I figured it would just store all files in the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16njqvw", "is_robot_indexable": true, "report_reasons": null, "author": "vaultfreak91", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16njqvw/idrive_cloud_drive_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16njqvw/idrive_cloud_drive_issue/", "subreddit_subscribers": 702885, "created_utc": 1695212036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Downloading albums bigger than 500 photos\n\nHi everyone,\n\nFirst things first, I HAVE permission for these photos!\n\nI was apart of an event earlier this year that has an album on Flickr of just under 1000 photos and videos. The built in Flickr download does not allow this. Does anybody know of a reliable way to download all of these? I have tried some old python scripts on GitHub etc but these seem outdated and not working.\n\nAny help would be appreciated.\n\nThanks!", "author_fullname": "t2_bvg6pbg7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading large flickr albuns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ni7uj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695207216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Downloading albums bigger than 500 photos&lt;/p&gt;\n\n&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;First things first, I HAVE permission for these photos!&lt;/p&gt;\n\n&lt;p&gt;I was apart of an event earlier this year that has an album on Flickr of just under 1000 photos and videos. The built in Flickr download does not allow this. Does anybody know of a reliable way to download all of these? I have tried some old python scripts on GitHub etc but these seem outdated and not working.&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ni7uj", "is_robot_indexable": true, "report_reasons": null, "author": "EpicPen51429014", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ni7uj/downloading_large_flickr_albuns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ni7uj/downloading_large_flickr_albuns/", "subreddit_subscribers": 702885, "created_utc": 1695207216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have started cloning a hard drive, 10TB onto an 18TB.\n\nAll I have at the end of the day is as follows\n\n1. macOS Monterey 12.6.9, iMac 5K 27 inch 2015, 3.3GHz i5, 32GB Ram\n2. Both drives plugged directly into computer\n3. Using CCC (Carbon Copy Cloner)\n4. Currently it has taken 2hr22min and 164GB has been transferred\n\nIs there anything else I can do that will make this process faster? I am not saying I am not patient, I can wait, I am in no hurry, but I mean for future reference, I don't know what I can do, to make the process faster.", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I calculate how long it will take to clone a drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nhziy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695206412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started cloning a hard drive, 10TB onto an 18TB.&lt;/p&gt;\n\n&lt;p&gt;All I have at the end of the day is as follows&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;macOS Monterey 12.6.9, iMac 5K 27 inch 2015, 3.3GHz i5, 32GB Ram&lt;/li&gt;\n&lt;li&gt;Both drives plugged directly into computer&lt;/li&gt;\n&lt;li&gt;Using CCC (Carbon Copy Cloner)&lt;/li&gt;\n&lt;li&gt;Currently it has taken 2hr22min and 164GB has been transferred&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Is there anything else I can do that will make this process faster? I am not saying I am not patient, I can wait, I am in no hurry, but I mean for future reference, I don&amp;#39;t know what I can do, to make the process faster.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nhziy", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nhziy/how_can_i_calculate_how_long_it_will_take_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nhziy/how_can_i_calculate_how_long_it_will_take_to/", "subreddit_subscribers": 702885, "created_utc": 1695206412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've a 4TB external WD formatted as exfat, since I had to use it both on Win and Mac. Along the years I always had many problems on Mac; still now, the HDD is not recongnized by my Mac! \n\nFirstly, do you think the problem is exfat? I'm reading only now how it's NOT recommended.\n\nI use the HDD mainly on Mac (for work), rarely on Win, sometimes I connect it to a Synology NAS to transfer files.\n\nI'm considering to take two separated ones (one formatted for Mac, one for Win/NAS) or better simply keep the one I have formatted for Mac (what FS you suggest?) and using the Paragon app for using it on Win, but what about connecting to the NAS? ", "author_fullname": "t2_17ah8ykr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4TB External hard drive for Mac-Win-NAS (exFAT)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ngnol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695201499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve a 4TB external WD formatted as exfat, since I had to use it both on Win and Mac. Along the years I always had many problems on Mac; still now, the HDD is not recongnized by my Mac! &lt;/p&gt;\n\n&lt;p&gt;Firstly, do you think the problem is exfat? I&amp;#39;m reading only now how it&amp;#39;s NOT recommended.&lt;/p&gt;\n\n&lt;p&gt;I use the HDD mainly on Mac (for work), rarely on Win, sometimes I connect it to a Synology NAS to transfer files.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering to take two separated ones (one formatted for Mac, one for Win/NAS) or better simply keep the one I have formatted for Mac (what FS you suggest?) and using the Paragon app for using it on Win, but what about connecting to the NAS? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ngnol", "is_robot_indexable": true, "report_reasons": null, "author": "ducasse666", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ngnol/4tb_external_hard_drive_for_macwinnas_exfat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ngnol/4tb_external_hard_drive_for_macwinnas_exfat/", "subreddit_subscribers": 702885, "created_utc": 1695201499.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}