{"kind": "Listing", "data": {"after": "t3_14n6gui", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I know that 30TB HDDs are gonna happen and would probably cost nothing compared to 30TB SSDs, but HDDs won't hit 60TB anytime soon!", "author_fullname": "t2_9igqvq1b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just found out that the company where I work have many 60TB SSD units. Couldn't get more info from the IT guy but I'm curious how we can get those and their pricing.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n76g6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 101, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 101, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688147435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that 30TB HDDs are gonna happen and would probably cost nothing compared to 30TB SSDs, but HDDs won&amp;#39;t hit 60TB anytime soon!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "150TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14n76g6", "is_robot_indexable": true, "report_reasons": null, "author": "500xp1", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14n76g6/just_found_out_that_the_company_where_i_work_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14n76g6/just_found_out_that_the_company_where_i_work_have/", "subreddit_subscribers": 690518, "created_utc": 1688147435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I made the hard choice. I deleted my 11 TB porn Jellyfin server. Had been collecting for years. But I felt it was time to let go and focus on real life in this situation. Felt like a hard choice to make, it was a big step. But I also feel somehow clean. A new start.\n\n(Ps a small part of the decision MAY have also been that I have in on Google Drive and slowly preparing for the inevitable, lol)", "author_fullname": "t2_10fiz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I deleted stuff. I feel dirty, LOL but clean", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nqoaz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 116, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 116, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688203545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made the hard choice. I deleted my 11 TB porn Jellyfin server. Had been collecting for years. But I felt it was time to let go and focus on real life in this situation. Felt like a hard choice to make, it was a big step. But I also feel somehow clean. A new start.&lt;/p&gt;\n\n&lt;p&gt;(Ps a small part of the decision MAY have also been that I have in on Google Drive and slowly preparing for the inevitable, lol)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14nqoaz", "is_robot_indexable": true, "report_reasons": null, "author": "Boogertwilliams", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nqoaz/i_deleted_stuff_i_feel_dirty_lol_but_clean/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nqoaz/i_deleted_stuff_i_feel_dirty_lol_but_clean/", "subreddit_subscribers": 690518, "created_utc": 1688203545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, everybody. One month ago I suddenly lost a dear friend from Twitter, who was only 40 years old when she died in an accident. Now, I would like to download her entire feed to preserve her memory and give all her tweets to her family (whose members do not have Twitter), as a way to preserve her memory. I already searched on the Internet and in this very subreddit for a way to do this and found some suggestions involving Github and Python scripts. However, I have an additional problem: her account is PRIVATE, so I didn't manage to get her tweets using these methods. Is there some way of doing this directly from her page, since at least I follow her and can read what she wrote? Or is it the only way to screenshot everything? Hope someone can help me with this!", "author_fullname": "t2_91g8a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download the entire Twitter feed from a deceased friend: is it possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14njo5z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688179811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, everybody. One month ago I suddenly lost a dear friend from Twitter, who was only 40 years old when she died in an accident. Now, I would like to download her entire feed to preserve her memory and give all her tweets to her family (whose members do not have Twitter), as a way to preserve her memory. I already searched on the Internet and in this very subreddit for a way to do this and found some suggestions involving Github and Python scripts. However, I have an additional problem: her account is PRIVATE, so I didn&amp;#39;t manage to get her tweets using these methods. Is there some way of doing this directly from her page, since at least I follow her and can read what she wrote? Or is it the only way to screenshot everything? Hope someone can help me with this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14njo5z", "is_robot_indexable": true, "report_reasons": null, "author": "vitordornelles", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14njo5z/download_the_entire_twitter_feed_from_a_deceased/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14njo5z/download_the_entire_twitter_feed_from_a_deceased/", "subreddit_subscribers": 690518, "created_utc": 1688179811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With all of the concern over Reddit tightening their API, the obvious solution is for software to use the human-facing html interface (https://reddit.com/r/*) in lieu of the formal API (https://reddit.com/api/v1/*).\n\nThis has already been discussed on a handful of subreddits that I have seen, but I haven't seen anyone say that they are writing a client library like that, or that one already exists.  I've poked around some and haven't found one in any of the obvious places, yet (github, pypi, npm, etc).\n\nAre any of you aware of such a project, before I start one of my own?  I need another project like I need a hole in my head, but I want a future-proof Reddit client library, too.", "author_fullname": "t2_cpegz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone working on a human-interface Reddit crawler?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nih44", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688176129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With all of the concern over Reddit tightening their API, the obvious solution is for software to use the human-facing html interface (&lt;a href=\"https://reddit.com/r/*\"&gt;https://reddit.com/r/*&lt;/a&gt;) in lieu of the formal API (&lt;a href=\"https://reddit.com/api/v1/*\"&gt;https://reddit.com/api/v1/*&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;This has already been discussed on a handful of subreddits that I have seen, but I haven&amp;#39;t seen anyone say that they are writing a client library like that, or that one already exists.  I&amp;#39;ve poked around some and haven&amp;#39;t found one in any of the obvious places, yet (github, pypi, npm, etc).&lt;/p&gt;\n\n&lt;p&gt;Are any of you aware of such a project, before I start one of my own?  I need another project like I need a hole in my head, but I want a future-proof Reddit client library, too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nih44", "is_robot_indexable": true, "report_reasons": null, "author": "ttkciar", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nih44/is_anyone_working_on_a_humaninterface_reddit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nih44/is_anyone_working_on_a_humaninterface_reddit/", "subreddit_subscribers": 690518, "created_utc": 1688176129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I procrastinated in going back to download content from a banned NSFW sub and now have lost the ability to use PushShift to do so. \n\nI know it's possible to download all of reddit up to March of 2023, but would I be able to access the imgur/gif links of the posts that hold the content? \n\nAny information or advice would be helpful. ", "author_fullname": "t2_238c78rb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use the PushShift data dump info to pull content from old banned sub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nke6r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688182045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I procrastinated in going back to download content from a banned NSFW sub and now have lost the ability to use PushShift to do so. &lt;/p&gt;\n\n&lt;p&gt;I know it&amp;#39;s possible to download all of reddit up to March of 2023, but would I be able to access the imgur/gif links of the posts that hold the content? &lt;/p&gt;\n\n&lt;p&gt;Any information or advice would be helpful. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nke6r", "is_robot_indexable": true, "report_reasons": null, "author": "notapornalt9669", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nke6r/how_to_use_the_pushshift_data_dump_info_to_pull/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nke6r/how_to_use_the_pushshift_data_dump_info_to_pull/", "subreddit_subscribers": 690518, "created_utc": 1688182045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am archiving some data to blu-ray m-discs. I ran a checksum comparison on my burned disc and I get a single mismatch one one video file on the disc. But the video file from the disc plays just fine. Does that mean the data is ok? I have tried running the checksum multiple times, same result. I tried md5 and Sha1.", "author_fullname": "t2_b9gcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Checksum mismatch, but file still plays", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ngpkd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688170848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am archiving some data to blu-ray m-discs. I ran a checksum comparison on my burned disc and I get a single mismatch one one video file on the disc. But the video file from the disc plays just fine. Does that mean the data is ok? I have tried running the checksum multiple times, same result. I tried md5 and Sha1.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14ngpkd", "is_robot_indexable": true, "report_reasons": null, "author": "Frolikewoah", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14ngpkd/checksum_mismatch_but_file_still_plays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14ngpkd/checksum_mismatch_but_file_still_plays/", "subreddit_subscribers": 690518, "created_utc": 1688170848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As in, searching for certain text in tens of thousands of images. Not trying to OCR individual images.", "author_fullname": "t2_13mwqlw5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I search for text in a large number of images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nomwg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688196189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As in, searching for certain text in tens of thousands of images. Not trying to OCR individual images.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nomwg", "is_robot_indexable": true, "report_reasons": null, "author": "catinterpreter", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nomwg/how_can_i_search_for_text_in_a_large_number_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nomwg/how_can_i_search_for_text_in_a_large_number_of/", "subreddit_subscribers": 690518, "created_utc": 1688196189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "as per title..  \n\n\nI'm vaguely contemplating buying a unit.. I want to attach it to a LSI HBA.  \n\n\nJust wanting to confirm it will be play happily with non-Dell hardware. I only have Supermicro/Intel Xeon/ LSI gear etc ('whitebox')  \n\n\ncheers", "author_fullname": "t2_as0s5xdl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone running the Dell Power Vault MD3460 as a DAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nn3ox", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688190934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;as per title..  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m vaguely contemplating buying a unit.. I want to attach it to a LSI HBA.  &lt;/p&gt;\n\n&lt;p&gt;Just wanting to confirm it will be play happily with non-Dell hardware. I only have Supermicro/Intel Xeon/ LSI gear etc (&amp;#39;whitebox&amp;#39;)  &lt;/p&gt;\n\n&lt;p&gt;cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "0.145PB, ZFS", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nn3ox", "is_robot_indexable": true, "report_reasons": null, "author": "kaheksajalg7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14nn3ox/anyone_running_the_dell_power_vault_md3460_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nn3ox/anyone_running_the_dell_power_vault_md3460_as_a/", "subreddit_subscribers": 690518, "created_utc": 1688190934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My H310 makes an electrical noise. I'm looking for something to boost the audio, haven't had any success yet.\n\nAny tips or advice would be appreciated.\n\nThis sound occurs when the LED, which is lit up in green on the card, turns off.  \nAm I right that this is a diagnostic LED? Dell says it's rebuilding RAID when it's flashing, which can't be because I'm using Unraid.  \nIt's the sound that sounds like a metronome, unfortunately I've gotta crank up the volume on my phone to hear it.  \n\n\nIt could be a relay, but this is new.I've moved the server about a month ago by car.\nThe only recent change is a new corsair SF600 PSU about a month ago, which was around the same time this noise started. This PC is offsite so I don't hear it often.\n\nhttps://preview.redd.it/xbpuwrevu79b1.png?width=2544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5f2a3aad46425a6e16b568d85e35a390ae338d8d&amp;height=1422\n\n&amp;#x200B;\n\n[Imgur video](https://imgur.com/a/ENkDr5f)\n\nEdit: formatting and additional info", "author_fullname": "t2_dg3rb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Electrical noise from LSI 9240-8i Dell H310", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xbpuwrevu79b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/xbpuwrevu79b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d6ed05451773627327aefda6757c31fe93b89ea"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/xbpuwrevu79b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33b6c50a11acb6a93766295c1bd116a01f6cd029"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/xbpuwrevu79b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2eb545df9d5b4c2bc46525dbf01516ed3e5b071e"}, {"y": 357, "x": 640, "u": "https://preview.redd.it/xbpuwrevu79b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0cb87210512ff9a0804add2441731b1c573796f3"}, {"y": 536, "x": 960, "u": "https://preview.redd.it/xbpuwrevu79b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19bae76621119184274c8543dd7a1a510a67d7fc"}, {"y": 603, "x": 1080, "u": "https://preview.redd.it/xbpuwrevu79b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b8331c9054675174758b2a52d5a5c5567d084d4"}], "s": {"y": 1422, "x": 2544, "u": "https://preview.redd.it/xbpuwrevu79b1.png?width=2544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5f2a3aad46425a6e16b568d85e35a390ae338d8d"}, "id": "xbpuwrevu79b1"}}, "name": "t3_14nbhkk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VuqrMFj0v16PA2C4nV9nuZjW2dG1i36l8d2B7mSH3hU.jpg", "edited": 1688158258.0, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1688157628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My H310 makes an electrical noise. I&amp;#39;m looking for something to boost the audio, haven&amp;#39;t had any success yet.&lt;/p&gt;\n\n&lt;p&gt;Any tips or advice would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;This sound occurs when the LED, which is lit up in green on the card, turns off.&lt;br/&gt;\nAm I right that this is a diagnostic LED? Dell says it&amp;#39;s rebuilding RAID when it&amp;#39;s flashing, which can&amp;#39;t be because I&amp;#39;m using Unraid.&lt;br/&gt;\nIt&amp;#39;s the sound that sounds like a metronome, unfortunately I&amp;#39;ve gotta crank up the volume on my phone to hear it.  &lt;/p&gt;\n\n&lt;p&gt;It could be a relay, but this is new.I&amp;#39;ve moved the server about a month ago by car.\nThe only recent change is a new corsair SF600 PSU about a month ago, which was around the same time this noise started. This PC is offsite so I don&amp;#39;t hear it often.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xbpuwrevu79b1.png?width=2544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=5f2a3aad46425a6e16b568d85e35a390ae338d8d&amp;amp;height=1422\"&gt;https://preview.redd.it/xbpuwrevu79b1.png?width=2544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=5f2a3aad46425a6e16b568d85e35a390ae338d8d&amp;amp;height=1422&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/ENkDr5f\"&gt;Imgur video&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit: formatting and additional info&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z24eIjCtdCH6jWGPLXe2-5eG-lp840-UHqtoPnajZXY.jpg?auto=webp&amp;v=enabled&amp;s=5887b59ca4411790c986e94e4d23b9a6c88268ab", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/Z24eIjCtdCH6jWGPLXe2-5eG-lp840-UHqtoPnajZXY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de8d1da02e597a210e79a0695378bcc29828d4aa", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Z24eIjCtdCH6jWGPLXe2-5eG-lp840-UHqtoPnajZXY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a7a63b7dabc55d2762693d6a597985f24902f78c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Z24eIjCtdCH6jWGPLXe2-5eG-lp840-UHqtoPnajZXY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76cd03474dd749a759fe3e6e83ca07be81025a36", "width": 320, "height": 168}], "variants": {}, "id": "dxR8HjOIMmC0GVrnNe2-KfzIa7ycqFjSET5VtlIBEfE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "...", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nbhkk", "is_robot_indexable": true, "report_reasons": null, "author": "THEMighter", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14nbhkk/electrical_noise_from_lsi_92408i_dell_h310/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nbhkk/electrical_noise_from_lsi_92408i_dell_h310/", "subreddit_subscribers": 690518, "created_utc": 1688157628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a WD 6TB Red plus drive (model WD60EFPX).  WD's documentation says this disk is CMR.   This is a 5400 rpm, 256MB cache drive (the older model is WD60EFZX-5640rpm/128MB).    \n\nThe original drive gave me IDNF errors on writes multiple times under raid.  I RMA'ed that drive and got a replacement red plus.     I tested the replacement by creating a filesystems and writing data to it and then erasing data and writing new data.  After filling the disk about 2x I started getting IDNF errors.  The given machine has other 6TB disks in it and they are all working just fine.\n\nI have seen a lot of disks errors but the whole IDNF errors seems to make no sense on a real CMR device and should technically be impossible on a CMR disk, unless the firmware is has a serious bug.\n\nIs this a SMR disk or is this screwed up firmware, or is something else going on?  I have not yet tried it in another machine to see if the new disks are somehow more sensitive to power supply issues.\n\nI am out of ideas outside of trying it in another machine.  It has been RMA'ed and the replacement has the same issue.  This is on linux.  Ideas?", "author_fullname": "t2_dymi0cog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New 6TB WD Red Plus drives given IDNF (SMR like) errors when written to, reads always work. RME'ed and new drive gets the same errors.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14na9av", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688154677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a WD 6TB Red plus drive (model WD60EFPX).  WD&amp;#39;s documentation says this disk is CMR.   This is a 5400 rpm, 256MB cache drive (the older model is WD60EFZX-5640rpm/128MB).    &lt;/p&gt;\n\n&lt;p&gt;The original drive gave me IDNF errors on writes multiple times under raid.  I RMA&amp;#39;ed that drive and got a replacement red plus.     I tested the replacement by creating a filesystems and writing data to it and then erasing data and writing new data.  After filling the disk about 2x I started getting IDNF errors.  The given machine has other 6TB disks in it and they are all working just fine.&lt;/p&gt;\n\n&lt;p&gt;I have seen a lot of disks errors but the whole IDNF errors seems to make no sense on a real CMR device and should technically be impossible on a CMR disk, unless the firmware is has a serious bug.&lt;/p&gt;\n\n&lt;p&gt;Is this a SMR disk or is this screwed up firmware, or is something else going on?  I have not yet tried it in another machine to see if the new disks are somehow more sensitive to power supply issues.&lt;/p&gt;\n\n&lt;p&gt;I am out of ideas outside of trying it in another machine.  It has been RMA&amp;#39;ed and the replacement has the same issue.  This is on linux.  Ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14na9av", "is_robot_indexable": true, "report_reasons": null, "author": "RandomUser3777", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14na9av/new_6tb_wd_red_plus_drives_given_idnf_smr_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14na9av/new_6tb_wd_red_plus_drives_given_idnf_smr_like/", "subreddit_subscribers": 690518, "created_utc": 1688154677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I tried doing it with MakeMKV but it isn't able to read it most of the time and can't export it. I don't care about which format they're saved in as long as they can be played or at least converted. Does anyone have experience with this or have any ideas? I have a few hundred to digitize, maybe more, so I'm open to suggestions. Thanks!", "author_fullname": "t2_3lurx74i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digitizing Video CDs, how can I do it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nkcfr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688181888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried doing it with MakeMKV but it isn&amp;#39;t able to read it most of the time and can&amp;#39;t export it. I don&amp;#39;t care about which format they&amp;#39;re saved in as long as they can be played or at least converted. Does anyone have experience with this or have any ideas? I have a few hundred to digitize, maybe more, so I&amp;#39;m open to suggestions. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.5TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nkcfr", "is_robot_indexable": true, "report_reasons": null, "author": "LavaCreeperBOSSB", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14nkcfr/digitizing_video_cds_how_can_i_do_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nkcfr/digitizing_video_cds_how_can_i_do_it/", "subreddit_subscribers": 690518, "created_utc": 1688181888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nHi I have gained access to drive for a few minutes and I was able to download all files using IDM then after 2 hours it says that it needs to refrech the download link but opennig the browser leads to message acess denied\n\nis there any way I could continue downloading", "author_fullname": "t2_7st7gs73", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Refreching download link of google drive file without permission ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nj4q8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688178099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I have gained access to drive for a few minutes and I was able to download all files using IDM then after 2 hours it says that it needs to refrech the download link but opennig the browser leads to message acess denied&lt;/p&gt;\n\n&lt;p&gt;is there any way I could continue downloading&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14nj4q8", "is_robot_indexable": true, "report_reasons": null, "author": "No-Park7347", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nj4q8/refreching_download_link_of_google_drive_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nj4q8/refreching_download_link_of_google_drive_file/", "subreddit_subscribers": 690518, "created_utc": 1688178099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I remember announcements earlier this year about 24TB drives ... are they out yet?", "author_fullname": "t2_mgmtm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did 24TB Drives Come Out Yet?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nivcy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688177307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I remember announcements earlier this year about 24TB drives ... are they out yet?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nivcy", "is_robot_indexable": true, "report_reasons": null, "author": "HarryMuscle", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nivcy/did_24tb_drives_come_out_yet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nivcy/did_24tb_drives_come_out_yet/", "subreddit_subscribers": 690518, "created_utc": 1688177307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My OS (Win11) boot drive which is a newer 1TB Seagate FireCuda 530 NVMe is dropping about 2% per week in health. Now u/I 89% health with just 1,200 hours. This is compared to my SK Hynix P31 which has 30k hours at 99% health. \n\nI'd like to move my data to a new NVMe of equal size. I have a spare 1TB NVMe SSD of equal size installed in another m.2 slot and have two more available m.2 slots.\n\nI'd like to use the motherboard's onboard RAID (MSI Z790-A) to create a mirror of the new NVMe to an existing (formatted) NVMe of equal size. \n\nThen I would like to then clone the existing partitions (including Windows) from (failing) NVMe SSD to a new NVMe SSD of equal size.\n\nI have Macrium reflect, but am unclear if I clone the drive to one of the pair of mirrored disks if it will then copy to both automatically to create a mirror? (never used RAID) \n\nIs it advisable to have a mirror of the OS boot drive? What is the best way to accomplish the clone of a NVMe that has the operating system on it? I have several software programs (namely the Arr's and would like to keep the configuration and settings as they are.\n\nAny help is appreciated.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended way to clone data from NVMe SSD to NVMe SSD rapidly dropping in Health", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nhqld", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688173866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My OS (Win11) boot drive which is a newer 1TB Seagate FireCuda 530 NVMe is dropping about 2% per week in health. Now &lt;a href=\"/u/I\"&gt;u/I&lt;/a&gt; 89% health with just 1,200 hours. This is compared to my SK Hynix P31 which has 30k hours at 99% health. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to move my data to a new NVMe of equal size. I have a spare 1TB NVMe SSD of equal size installed in another m.2 slot and have two more available m.2 slots.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to use the motherboard&amp;#39;s onboard RAID (MSI Z790-A) to create a mirror of the new NVMe to an existing (formatted) NVMe of equal size. &lt;/p&gt;\n\n&lt;p&gt;Then I would like to then clone the existing partitions (including Windows) from (failing) NVMe SSD to a new NVMe SSD of equal size.&lt;/p&gt;\n\n&lt;p&gt;I have Macrium reflect, but am unclear if I clone the drive to one of the pair of mirrored disks if it will then copy to both automatically to create a mirror? (never used RAID) &lt;/p&gt;\n\n&lt;p&gt;Is it advisable to have a mirror of the OS boot drive? What is the best way to accomplish the clone of a NVMe that has the operating system on it? I have several software programs (namely the Arr&amp;#39;s and would like to keep the configuration and settings as they are.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nhqld", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nhqld/recommended_way_to_clone_data_from_nvme_ssd_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nhqld/recommended_way_to_clone_data_from_nvme_ssd_to/", "subreddit_subscribers": 690518, "created_utc": 1688173866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "in particular the open source ones?, and if there is no archive; what is the best way to make one?;\n\nhowever if there are archives, where are they?\n\nso i can see about aiding/solo-completing any of them, if its possible.", "author_fullname": "t2_2dbwmuha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "way for complete archival of the reddit bots?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n770e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688147471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;in particular the open source ones?, and if there is no archive; what is the best way to make one?;&lt;/p&gt;\n\n&lt;p&gt;however if there are archives, where are they?&lt;/p&gt;\n\n&lt;p&gt;so i can see about aiding/solo-completing any of them, if its possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14n770e", "is_robot_indexable": true, "report_reasons": null, "author": "565gta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14n770e/way_for_complete_archival_of_the_reddit_bots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14n770e/way_for_complete_archival_of_the_reddit_bots/", "subreddit_subscribers": 690518, "created_utc": 1688147471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm thinking of taking the plunge into ZFS coming from Windows 11. I routinely use the Arr apps and would like help/suggestions on whether to go with Ubuntu on ZFS or to go with Unraid or similar with BTRFS?\n\nMy present setup is a z790 chipset 13th gen Intel with onboard graphics.\n\n Is there any suggested reading or guides available for someone like me who has zero experience with Linux and wants to switch to utilize the benefits of ZFS? \n\nI currently have a 16TB, 18TB, 18TB enterprise hard drives installed internally which contain data that I would like to have on my new ZFS system. I am booting from NVMe SSD. \n\nProblem is, all of my data is on NTFS partitions. I do have external HDD's (also NTFS) which contain the same data so I can format the above three HDD's to create the raid group.\n\nI am considering buying a 3rd 18tb HDD so I have equal size drives to create my RAIDZ2 group starting with just 3 drives and not including my 16tb to start with. \n\nWould it be best for me to have equal sized drives in creating this group? Can I expand the group when I buy more drives or need more space? How will I handle copying my files from a drive with NTFS to a ZFS pool?\n\nIs it wise to create more than one pool or manage just one pool? I've read that others do daily short SMART tests, weekly long tests, and bi-weekly/monthly scrubs. Would this be sufficient? \n\nThe purpose of this build will be to do one thing. To operate the Arr apps. (Sonarr, Prowlarr, Overseerr, etc.) I will be installing Plex and using it as a HTPC - and little to nothing else. \n\nThe reason I am looking to switch to ZFS is due to it detecting/repairing bitrot. I have thought about Unraid but became confused on whether to use Ubuntu or Unraid. The idea of parity drives kind of confused me when it comes to Unraid.\n\n I am unclear on what would be best for my usage scenario. What would you recommend for ease of implementation - taking into consideration that my primary usage scenario is the Arr apps and Plex? ", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guides or tips for setting up first ZFS file/plex server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14nwq7w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688222356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of taking the plunge into ZFS coming from Windows 11. I routinely use the Arr apps and would like help/suggestions on whether to go with Ubuntu on ZFS or to go with Unraid or similar with BTRFS?&lt;/p&gt;\n\n&lt;p&gt;My present setup is a z790 chipset 13th gen Intel with onboard graphics.&lt;/p&gt;\n\n&lt;p&gt;Is there any suggested reading or guides available for someone like me who has zero experience with Linux and wants to switch to utilize the benefits of ZFS? &lt;/p&gt;\n\n&lt;p&gt;I currently have a 16TB, 18TB, 18TB enterprise hard drives installed internally which contain data that I would like to have on my new ZFS system. I am booting from NVMe SSD. &lt;/p&gt;\n\n&lt;p&gt;Problem is, all of my data is on NTFS partitions. I do have external HDD&amp;#39;s (also NTFS) which contain the same data so I can format the above three HDD&amp;#39;s to create the raid group.&lt;/p&gt;\n\n&lt;p&gt;I am considering buying a 3rd 18tb HDD so I have equal size drives to create my RAIDZ2 group starting with just 3 drives and not including my 16tb to start with. &lt;/p&gt;\n\n&lt;p&gt;Would it be best for me to have equal sized drives in creating this group? Can I expand the group when I buy more drives or need more space? How will I handle copying my files from a drive with NTFS to a ZFS pool?&lt;/p&gt;\n\n&lt;p&gt;Is it wise to create more than one pool or manage just one pool? I&amp;#39;ve read that others do daily short SMART tests, weekly long tests, and bi-weekly/monthly scrubs. Would this be sufficient? &lt;/p&gt;\n\n&lt;p&gt;The purpose of this build will be to do one thing. To operate the Arr apps. (Sonarr, Prowlarr, Overseerr, etc.) I will be installing Plex and using it as a HTPC - and little to nothing else. &lt;/p&gt;\n\n&lt;p&gt;The reason I am looking to switch to ZFS is due to it detecting/repairing bitrot. I have thought about Unraid but became confused on whether to use Ubuntu or Unraid. The idea of parity drives kind of confused me when it comes to Unraid.&lt;/p&gt;\n\n&lt;p&gt;I am unclear on what would be best for my usage scenario. What would you recommend for ease of implementation - taking into consideration that my primary usage scenario is the Arr apps and Plex? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nwq7w", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nwq7w/guides_or_tips_for_setting_up_first_zfs_fileplex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nwq7w/guides_or_tips_for_setting_up_first_zfs_fileplex/", "subreddit_subscribers": 690518, "created_utc": 1688222356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are there ways to reuse random hard drive you got for free without much work? I'd image a small computer, you find a free hard drive, attach it to the computer and it will be automatically added to the Nas as a raid or so?", "author_fullname": "t2_jp3bv4xk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ghetto-NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14nwaqu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688221205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there ways to reuse random hard drive you got for free without much work? I&amp;#39;d image a small computer, you find a free hard drive, attach it to the computer and it will be automatically added to the Nas as a raid or so?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nwaqu", "is_robot_indexable": true, "report_reasons": null, "author": "CryptographerOdd299", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nwaqu/ghettonas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nwaqu/ghettonas/", "subreddit_subscribers": 690518, "created_utc": 1688221205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\n&amp;#x200B;\n\nI have a Google workspace enterprise account with 10tb of used storage.  Paying \u00a315 a month and over my limit by 5tb.\n\n&amp;#x200B;\n\nHave data backed up on a HD at home.\n\n&amp;#x200B;\n\nData in cloud is for my Plex server using netdrive on a Windows server hosted in the cloud.\n\n&amp;#x200B;\n\nMy options are.\n\n&amp;#x200B;\n\nAdd another user and pay a total of \u00a330 a month for Google storage.\n\n&amp;#x200B;\n\nOr\n\n&amp;#x200B;\n\nUse my existing office 365 account, set up 5 users with 1 tb of OneDrive\n\n&amp;#x200B;\n\nMake several drives on my server from the OneDrive accounts using netdrive.\n\n&amp;#x200B;\n\nCopy over 1tb of data per account using multcloud.\n\n&amp;#x200B;\n\nThen create a Plex library combing the drives together.\n\n&amp;#x200B;\n\nGet another office 365 account and set up another 5 users to handle another 5TB of data.\n\n&amp;#x200B;\n\nThat way I'll spend \u00a3100 a year on 2x office 365 accounts and 12tb of OneDrive storage instead over \u00a3300 with Google for 10tb storage.\n\n&amp;#x200B;\n\nI've done a test using the OneDrive scenario and it seems to work ok with Plex.\n\n&amp;#x200B;\n\nHas anyone done this and any disadvantages apart from having to manage several OneDrive accounts?", "author_fullname": "t2_rco24", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just want to check before I implement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14nvoru", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688219542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have a Google workspace enterprise account with 10tb of used storage.  Paying \u00a315 a month and over my limit by 5tb.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Have data backed up on a HD at home.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Data in cloud is for my Plex server using netdrive on a Windows server hosted in the cloud.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My options are.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Add another user and pay a total of \u00a330 a month for Google storage.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Use my existing office 365 account, set up 5 users with 1 tb of OneDrive&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Make several drives on my server from the OneDrive accounts using netdrive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Copy over 1tb of data per account using multcloud.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Then create a Plex library combing the drives together.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Get another office 365 account and set up another 5 users to handle another 5TB of data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;That way I&amp;#39;ll spend \u00a3100 a year on 2x office 365 accounts and 12tb of OneDrive storage instead over \u00a3300 with Google for 10tb storage.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done a test using the OneDrive scenario and it seems to work ok with Plex.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Has anyone done this and any disadvantages apart from having to manage several OneDrive accounts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nvoru", "is_robot_indexable": true, "report_reasons": null, "author": "richarduklon", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nvoru/just_want_to_check_before_i_implement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nvoru/just_want_to_check_before_i_implement/", "subreddit_subscribers": 690518, "created_utc": 1688219542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there, I recently upgraded from a M5015 to a Adaptec 71605. I have the new card connected to a IBM X3400 SAS Expander. The problem I'm having is that the new card does not detect the drives connected to the expander. 2 drives connected directly to the card via backplane are detected. The old card with the expander did and still does show all drives when reconnected. I have attached an image of the cards boot screen showing it detects the expander but finds no logical drives. There also appears to be a no bios warning but I'm not sure if that's relevant. Any help that you can provide would be appreciated, Thanks.\n\nhttps://preview.redd.it/yx9bf9s0tc9b1.jpg?width=1851&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2443fa2e91da638387a2aeeb9a0903f9c6940c19", "author_fullname": "t2_zm7dz8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adaptec 71605 + ServeRAID X3400 HDD Detection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yx9bf9s0tc9b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 75, "x": 108, "u": "https://preview.redd.it/yx9bf9s0tc9b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5dd973a07f3d3404327497dcf8df18df791604e9"}, {"y": 151, "x": 216, "u": "https://preview.redd.it/yx9bf9s0tc9b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdd64a9184cd125321cae0109d41c0f7bb807d1a"}, {"y": 224, "x": 320, "u": "https://preview.redd.it/yx9bf9s0tc9b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=375773e9db8f6e60828e377e563b2d63697be333"}, {"y": 449, "x": 640, "u": "https://preview.redd.it/yx9bf9s0tc9b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=173a9de5d16c07498c6183c509b3826a64a20c34"}, {"y": 673, "x": 960, "u": "https://preview.redd.it/yx9bf9s0tc9b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a7946c3a27212e91b9e4f2589e5eaf5ca574f21"}, {"y": 757, "x": 1080, "u": "https://preview.redd.it/yx9bf9s0tc9b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4aaefe93f24cb16e6239efe08e6876dbb999fab9"}], "s": {"y": 1299, "x": 1851, "u": "https://preview.redd.it/yx9bf9s0tc9b1.jpg?width=1851&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2443fa2e91da638387a2aeeb9a0903f9c6940c19"}, "id": "yx9bf9s0tc9b1"}}, "name": "t3_14nuwfj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fD3BXNmxibK2pJO_WwL5hBfguRsIiOTUPcZVOU_orpo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688217333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I recently upgraded from a M5015 to a Adaptec 71605. I have the new card connected to a IBM X3400 SAS Expander. The problem I&amp;#39;m having is that the new card does not detect the drives connected to the expander. 2 drives connected directly to the card via backplane are detected. The old card with the expander did and still does show all drives when reconnected. I have attached an image of the cards boot screen showing it detects the expander but finds no logical drives. There also appears to be a no bios warning but I&amp;#39;m not sure if that&amp;#39;s relevant. Any help that you can provide would be appreciated, Thanks.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yx9bf9s0tc9b1.jpg?width=1851&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2443fa2e91da638387a2aeeb9a0903f9c6940c19\"&gt;https://preview.redd.it/yx9bf9s0tc9b1.jpg?width=1851&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2443fa2e91da638387a2aeeb9a0903f9c6940c19&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nuwfj", "is_robot_indexable": true, "report_reasons": null, "author": "smorgisborg1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nuwfj/adaptec_71605_serveraid_x3400_hdd_detection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nuwfj/adaptec_71605_serveraid_x3400_hdd_detection/", "subreddit_subscribers": 690518, "created_utc": 1688217333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I have found several old CD-R, DVD-R and DVD+R discs. Since they provide only little storage by modern standards, I wonder what I can for example record to these CD-R/DVD-R discs.\n\nIf they are from a brand that doesn't exist anymore or are they a 650 MB variety (which are practically not made anymore), are they worth more? What about slightly scratched disks?", "author_fullname": "t2_rej6q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do with several old CD-R/DVD-R blank discs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ntca7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688212792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have found several old CD-R, DVD-R and DVD+R discs. Since they provide only little storage by modern standards, I wonder what I can for example record to these CD-R/DVD-R discs.&lt;/p&gt;\n\n&lt;p&gt;If they are from a brand that doesn&amp;#39;t exist anymore or are they a 650 MB variety (which are practically not made anymore), are they worth more? What about slightly scratched disks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14ntca7", "is_robot_indexable": true, "report_reasons": null, "author": "smsaczek", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14ntca7/what_to_do_with_several_old_cdrdvdr_blank_discs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14ntca7/what_to_do_with_several_old_cdrdvdr_blank_discs/", "subreddit_subscribers": 690518, "created_utc": 1688212792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently added a large hdd to my Raspberry pi setup in order to download media on it. I don't know if this counts as data hoarding but this seems like a sub who knows an answer to my problem.\n\nMy old 2tb drive listens to hdparm and hd-idle. However this drive I can definitely spin down manually however it seems to go into standby after only 3 minutes. Which is just too little. It let's me set the time and APM but it just changes back after a bit. I know I can probably get a cronjob to touch a file but I don't want to lose sleep, just set it to something more reasonable.\n\nSo so you guys know some larger current hdd's that let you set/disable sleep in their firmware. Or at least have a 20+ minute sleep period. The one I'm having trouble with is an Intenso drive which got good reviews and seems fine otherwise. Thanks!", "author_fullname": "t2_p59vu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recent external hdd that obeys sleep settings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nrmra", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688206990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently added a large hdd to my Raspberry pi setup in order to download media on it. I don&amp;#39;t know if this counts as data hoarding but this seems like a sub who knows an answer to my problem.&lt;/p&gt;\n\n&lt;p&gt;My old 2tb drive listens to hdparm and hd-idle. However this drive I can definitely spin down manually however it seems to go into standby after only 3 minutes. Which is just too little. It let&amp;#39;s me set the time and APM but it just changes back after a bit. I know I can probably get a cronjob to touch a file but I don&amp;#39;t want to lose sleep, just set it to something more reasonable.&lt;/p&gt;\n\n&lt;p&gt;So so you guys know some larger current hdd&amp;#39;s that let you set/disable sleep in their firmware. Or at least have a 20+ minute sleep period. The one I&amp;#39;m having trouble with is an Intenso drive which got good reviews and seems fine otherwise. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nrmra", "is_robot_indexable": true, "report_reasons": null, "author": "MrRenegado", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nrmra/recent_external_hdd_that_obeys_sleep_settings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nrmra/recent_external_hdd_that_obeys_sleep_settings/", "subreddit_subscribers": 690518, "created_utc": 1688206990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure where else to ask this, I've been trying to find an external enclosure for my very old Seagate Freeplay drive. The old enclosure broke so I've been kinda lugging it around without one. The problem is it has significantly more height than most 2.5-inch enclosures and so I can't find one that fits it. I mainly use a laptop so can't stick it in a PC. Is my only option to get a 3.5-inch enclosure?", "author_fullname": "t2_v6gyu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there enclosures for a Seagate Freeplay HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14noemt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688195380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure where else to ask this, I&amp;#39;ve been trying to find an external enclosure for my very old Seagate Freeplay drive. The old enclosure broke so I&amp;#39;ve been kinda lugging it around without one. The problem is it has significantly more height than most 2.5-inch enclosures and so I can&amp;#39;t find one that fits it. I mainly use a laptop so can&amp;#39;t stick it in a PC. Is my only option to get a 3.5-inch enclosure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14noemt", "is_robot_indexable": true, "report_reasons": null, "author": "philinsaniachen", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14noemt/are_there_enclosures_for_a_seagate_freeplay_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14noemt/are_there_enclosures_for_a_seagate_freeplay_hdd/", "subreddit_subscribers": 690518, "created_utc": 1688195380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI have a web app that accepts uploads from users and serves files to users. I set it up with backblaze via the API and the upload speeds were 300Kbps. So i switched to Wasabi, but they no longer allow public access for buckets as Wasabi is intended for backup and archiving.\n\nWhat are my best options for file hosting services with API access?\n\nThanks,\n\nAlbert", "author_fullname": "t2_npfxa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File hosting for web app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nfyol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688168802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have a web app that accepts uploads from users and serves files to users. I set it up with backblaze via the API and the upload speeds were 300Kbps. So i switched to Wasabi, but they no longer allow public access for buckets as Wasabi is intended for backup and archiving.&lt;/p&gt;\n\n&lt;p&gt;What are my best options for file hosting services with API access?&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n\n&lt;p&gt;Albert&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nfyol", "is_robot_indexable": true, "report_reasons": null, "author": "u2nyr", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nfyol/file_hosting_for_web_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nfyol/file_hosting_for_web_app/", "subreddit_subscribers": 690518, "created_utc": 1688168802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a network drive mapped in windows and I logged in with an account with full permissions, I'm wondering if this is a wise choice though. I'm careful but I worry that maybe if my computer becomes compromised it could affect my nas in some way through this network mapped drive. Should I log in with an account with read only perms? or would that not do anything in the event of malware or similar. Thanks", "author_fullname": "t2_gjxw27zv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "question about mapping network drives from nas in windows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nfqhc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688168188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a network drive mapped in windows and I logged in with an account with full permissions, I&amp;#39;m wondering if this is a wise choice though. I&amp;#39;m careful but I worry that maybe if my computer becomes compromised it could affect my nas in some way through this network mapped drive. Should I log in with an account with read only perms? or would that not do anything in the event of malware or similar. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14nfqhc", "is_robot_indexable": true, "report_reasons": null, "author": "KarinAppreciator", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14nfqhc/question_about_mapping_network_drives_from_nas_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14nfqhc/question_about_mapping_network_drives_from_nas_in/", "subreddit_subscribers": 690518, "created_utc": 1688168188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am using this to connect\n\n[https://www.amazon.com/VENTION-Adapter-Charging-Supported-Devices/dp/B08QZB4NQ9?ref\\_=ast\\_sto\\_dp&amp;th=1&amp;psc=1](https://www.amazon.com/VENTION-Adapter-Charging-Supported-Devices/dp/B08QZB4NQ9?ref_=ast_sto_dp&amp;th=1&amp;psc=1)\n\n Crucial X8 Portable SSD 1TB\n\n WD My Passport SSD 2TB  \n\n SSD Samsung T7 1TB\n\nand a sound tech mic USB input\n\nthis all powered with the hub micro USB power input\n\nI used to put that sound tech mic into a similar Vention USB-A hub powered with a micro USB\n\nbut that USB A hub carries a 2 4TB HDD and I keep hearing clicking on them I read it somewhere that is a sign that the HDD lacks power so I move it to the SSD hub  ", "author_fullname": "t2_727v9dea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do I know if SSD lacks power from a USB C hub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n6gui", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688145729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using this to connect&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/VENTION-Adapter-Charging-Supported-Devices/dp/B08QZB4NQ9?ref_=ast_sto_dp&amp;amp;th=1&amp;amp;psc=1\"&gt;https://www.amazon.com/VENTION-Adapter-Charging-Supported-Devices/dp/B08QZB4NQ9?ref_=ast_sto_dp&amp;amp;th=1&amp;amp;psc=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Crucial X8 Portable SSD 1TB&lt;/p&gt;\n\n&lt;p&gt;WD My Passport SSD 2TB  &lt;/p&gt;\n\n&lt;p&gt;SSD Samsung T7 1TB&lt;/p&gt;\n\n&lt;p&gt;and a sound tech mic USB input&lt;/p&gt;\n\n&lt;p&gt;this all powered with the hub micro USB power input&lt;/p&gt;\n\n&lt;p&gt;I used to put that sound tech mic into a similar Vention USB-A hub powered with a micro USB&lt;/p&gt;\n\n&lt;p&gt;but that USB A hub carries a 2 4TB HDD and I keep hearing clicking on them I read it somewhere that is a sign that the HDD lacks power so I move it to the SSD hub  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14n6gui", "is_robot_indexable": true, "report_reasons": null, "author": "OkAd5119", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14n6gui/how_do_i_know_if_ssd_lacks_power_from_a_usb_c_hub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14n6gui/how_do_i_know_if_ssd_lacks_power_from_a_usb_c_hub/", "subreddit_subscribers": 690518, "created_utc": 1688145729.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}