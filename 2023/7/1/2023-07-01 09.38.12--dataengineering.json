{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of day to day is working with python scripts (with a smattering of spark, pandas, etc) with pipelines moving data to/from Postgres/SQL server/Snowflake. The team I'm on is very comfortable with python, but we're exploring using duckdb or glaredb in some spots for data transformation, both for performance and how well sql maps to these transformations.\n\nWe're still hammering out what exactly this would look like, but I thought we could get some outside opinions on using either of these projects in our pipelines. Concretely, has anyone introduced either of these projects into their pipelines, and how did that go? Any pitfalls?\n\nFor reference:\n\nDuckdb: [https://github.com/duckdb/duckdb](https://github.com/duckdb/duckdb) \\- seems pretty popular, been keeping an eye on this for close to a year now.\n\nGlaredb: [https://github.com/GlareDB/glaredb](https://github.com/GlareDB/glaredb) \\- just heard about this last week. We played around with hooking directly into snowflake, so that was cool, but I haven't heard of anyone else using it.\n\nAny other projects like this that I'm missing?", "author_fullname": "t2_tlibil3a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using SQL inside Python pipelines with Duckdb, Glaredb (and others?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n1xjw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688135234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of day to day is working with python scripts (with a smattering of spark, pandas, etc) with pipelines moving data to/from Postgres/SQL server/Snowflake. The team I&amp;#39;m on is very comfortable with python, but we&amp;#39;re exploring using duckdb or glaredb in some spots for data transformation, both for performance and how well sql maps to these transformations.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re still hammering out what exactly this would look like, but I thought we could get some outside opinions on using either of these projects in our pipelines. Concretely, has anyone introduced either of these projects into their pipelines, and how did that go? Any pitfalls?&lt;/p&gt;\n\n&lt;p&gt;For reference:&lt;/p&gt;\n\n&lt;p&gt;Duckdb: &lt;a href=\"https://github.com/duckdb/duckdb\"&gt;https://github.com/duckdb/duckdb&lt;/a&gt; - seems pretty popular, been keeping an eye on this for close to a year now.&lt;/p&gt;\n\n&lt;p&gt;Glaredb: &lt;a href=\"https://github.com/GlareDB/glaredb\"&gt;https://github.com/GlareDB/glaredb&lt;/a&gt; - just heard about this last week. We played around with hooking directly into snowflake, so that was cool, but I haven&amp;#39;t heard of anyone else using it.&lt;/p&gt;\n\n&lt;p&gt;Any other projects like this that I&amp;#39;m missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CMNIDTw44_ZkcOXcAsz9eSr0xJJk21Rp4sDzSmpPEqg.jpg?auto=webp&amp;v=enabled&amp;s=bd710c3ad880e33fa51723bcf550c6b3dbc30b58", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/CMNIDTw44_ZkcOXcAsz9eSr0xJJk21Rp4sDzSmpPEqg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d599b1eb06cee45320e07eb1dd0713dc5549d11", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/CMNIDTw44_ZkcOXcAsz9eSr0xJJk21Rp4sDzSmpPEqg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=496239147ca765153ea290ae11411ba76b498cfb", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/CMNIDTw44_ZkcOXcAsz9eSr0xJJk21Rp4sDzSmpPEqg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=651acaced3eca5a85485b6977a917726b31cf098", "width": 320, "height": 320}], "variants": {}, "id": "tWw9eIdR80nmgZaRh-6bxdRnIteNj4-dUri_8Fs9NGg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14n1xjw", "is_robot_indexable": true, "report_reasons": null, "author": "lackbookpro", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n1xjw/using_sql_inside_python_pipelines_with_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14n1xjw/using_sql_inside_python_pipelines_with_duckdb/", "subreddit_subscribers": 113362, "created_utc": 1688135234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It\u2019s definitely been a day so I wanted to poll the community, what are some of the dumbest/most frustrating requests you\u2019ve received from end users or dumbest queries etc from coworkers? Can\u2019t wait to hear these responses.", "author_fullname": "t2_bfa6tlx6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dumbest requests from end users or code you\u2019ve seen.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n7vya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688149044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s definitely been a day so I wanted to poll the community, what are some of the dumbest/most frustrating requests you\u2019ve received from end users or dumbest queries etc from coworkers? Can\u2019t wait to hear these responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14n7vya", "is_robot_indexable": true, "report_reasons": null, "author": "Lost_Source824", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n7vya/dumbest_requests_from_end_users_or_code_youve_seen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14n7vya/dumbest_requests_from_end_users_or_code_youve_seen/", "subreddit_subscribers": 113362, "created_utc": 1688149044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_al1087x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing English as the New Programming Language for Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14nl01c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pt2O-2YXrvh1PvS2ZNqvsDhqKOZG4LkFaovbAdTBzp4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688184028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "databricks.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.databricks.com/blog/introducing-english-new-programming-language-apache-spark", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/80FpuMKaP-uF7j-NvgbUI5Z7r1khj2YfJVE3-fz-GI8.jpg?auto=webp&amp;v=enabled&amp;s=07702af3ccbcfb45ca9ca0246ff11956a407d034", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/80FpuMKaP-uF7j-NvgbUI5Z7r1khj2YfJVE3-fz-GI8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94745d07ed74df5060f4a5ec13f5d4c4772b6799", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/80FpuMKaP-uF7j-NvgbUI5Z7r1khj2YfJVE3-fz-GI8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf88a51c7a8a1026f7039142233eacac3b090be2", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/80FpuMKaP-uF7j-NvgbUI5Z7r1khj2YfJVE3-fz-GI8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee1d2efc25fec8f150d98bd439b41b3544464ec9", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/80FpuMKaP-uF7j-NvgbUI5Z7r1khj2YfJVE3-fz-GI8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2f8f4a08c330da70ff1921abe6c7c9dcff8ae28", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/80FpuMKaP-uF7j-NvgbUI5Z7r1khj2YfJVE3-fz-GI8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd149b2f8b4ab02f257c861959ec52860e8646dc", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/80FpuMKaP-uF7j-NvgbUI5Z7r1khj2YfJVE3-fz-GI8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=048373236a1eca4e14922ba32189012cdab346c2", "width": 1080, "height": 565}], "variants": {}, "id": "-GPKg0u5dq3hDp5gpC5cw1mkM8UDz08oLmsytjlET5M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14nl01c", "is_robot_indexable": true, "report_reasons": null, "author": "OverratedDataScience", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14nl01c/introducing_english_as_the_new_programming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.databricks.com/blog/introducing-english-new-programming-language-apache-spark", "subreddit_subscribers": 113362, "created_utc": 1688184028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8jh75ko4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing the Data Engineering Discord Server with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ngd5z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1688169877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "xyz.jackbonatakis.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://xyz.jackbonatakis.com/blog/analyzing-the-data-engineering-discord-server-with-duckdb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14ngd5z", "is_robot_indexable": true, "report_reasons": null, "author": "Mission-Sector-1696", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ngd5z/analyzing_the_data_engineering_discord_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://xyz.jackbonatakis.com/blog/analyzing-the-data-engineering-discord-server-with-duckdb/", "subreddit_subscribers": 113362, "created_utc": 1688169877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I just got my first data engineering position. During the interview I asked about how the company contributes to employees wanting to further their education. They said that they cover all certification exams.\n\nThe certs I am thinking of getting:\n\n* Azure DP-203\n* An industry recognized Docker/Kubernetes certification\n* Maybe a Spark Cert?\n\nWhat would some of you more experienced DEs do if you were just starting out your career like I am?", "author_fullname": "t2_71x5v4dp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My New Job Pays for All My Wanted Certifications. Recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n67sd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688145129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I just got my first data engineering position. During the interview I asked about how the company contributes to employees wanting to further their education. They said that they cover all certification exams.&lt;/p&gt;\n\n&lt;p&gt;The certs I am thinking of getting:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Azure DP-203&lt;/li&gt;\n&lt;li&gt;An industry recognized Docker/Kubernetes certification&lt;/li&gt;\n&lt;li&gt;Maybe a Spark Cert?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What would some of you more experienced DEs do if you were just starting out your career like I am?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14n67sd", "is_robot_indexable": true, "report_reasons": null, "author": "Emosk8rboi42969", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n67sd/my_new_job_pays_for_all_my_wanted_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14n67sd/my_new_job_pays_for_all_my_wanted_certifications/", "subreddit_subscribers": 113362, "created_utc": 1688145129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cqvp4nt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It do be like that", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 133, "top_awarded_type": null, "hide_score": false, "name": "t3_14n9sfi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1yPW61O4MaaRd4Cmwm-N8tVCoH0lw5hmHZhz7V-TGmg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688153541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/a3cwwt9ni79b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/a3cwwt9ni79b1.jpg?auto=webp&amp;v=enabled&amp;s=6bf6dc650a879dba6751a39b1b8f549e8c7b0703", "width": 524, "height": 500}, "resolutions": [{"url": "https://preview.redd.it/a3cwwt9ni79b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9609e51d84b18f8cc89add1b5eb80c10fa8d8a3a", "width": 108, "height": 103}, {"url": "https://preview.redd.it/a3cwwt9ni79b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a195278a865b404b1103cf28cc1c96a609d4b9eb", "width": 216, "height": 206}, {"url": "https://preview.redd.it/a3cwwt9ni79b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80acf3f81137509ba82132a6913adaf66a66b2b8", "width": 320, "height": 305}], "variants": {}, "id": "yynBC3qUuaPh_lMMDVsGJHvTicJSjJG_sS7z0alqA5o"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14n9sfi", "is_robot_indexable": true, "report_reasons": null, "author": "udonthave2call", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n9sfi/it_do_be_like_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/a3cwwt9ni79b1.jpg", "subreddit_subscribers": 113362, "created_utc": 1688153541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There was a [discussion post this week about expensive tools](https://www.reddit.com/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/) where Fivetran came up with some [comments about Estuary being an option](https://www.reddit.com/r/dataengineering/comments/14ltv6p/comment/jpzbbsk/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3).\n\nWhile it is definitely a newer tool/service, there are a few features which look very interesting: realtime syncs, inline transforms for EtLT (t = estuary, T = dbt) both stateful and non-stateful, cost savings, materializing the same enriched data to multiple places (which starts to function a bit like reverse etl... tbd).\n\nCan anyone speak to [estuary.dev](https://estuary.dev) and their thoughts on it?\n\nNote: I have found estuary's docs to be slightly scattered, but I found these two interviews to be quite good: [DemoHub Youtube interview](https://www.youtube.com/watch?v=ARk7b2_dh_Q),  [data engineering podcast interview](https://www.dataengineeringpodcast.com/estuary-real-time-streaming-data-lake-episode-375), and this [postgres demo video](https://www.youtube.com/watch?v=4VOgmb3Vnts) helpful as well.", "author_fullname": "t2_1qwjj2kn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran vs Estuary.dev", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n8c4y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688150128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There was a &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/\"&gt;discussion post this week about expensive tools&lt;/a&gt; where Fivetran came up with some &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14ltv6p/comment/jpzbbsk/?utm_source=reddit&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;comments about Estuary being an option&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;While it is definitely a newer tool/service, there are a few features which look very interesting: realtime syncs, inline transforms for EtLT (t = estuary, T = dbt) both stateful and non-stateful, cost savings, materializing the same enriched data to multiple places (which starts to function a bit like reverse etl... tbd).&lt;/p&gt;\n\n&lt;p&gt;Can anyone speak to &lt;a href=\"https://estuary.dev\"&gt;estuary.dev&lt;/a&gt; and their thoughts on it?&lt;/p&gt;\n\n&lt;p&gt;Note: I have found estuary&amp;#39;s docs to be slightly scattered, but I found these two interviews to be quite good: &lt;a href=\"https://www.youtube.com/watch?v=ARk7b2_dh_Q\"&gt;DemoHub Youtube interview&lt;/a&gt;,  &lt;a href=\"https://www.dataengineeringpodcast.com/estuary-real-time-streaming-data-lake-episode-375\"&gt;data engineering podcast interview&lt;/a&gt;, and this &lt;a href=\"https://www.youtube.com/watch?v=4VOgmb3Vnts\"&gt;postgres demo video&lt;/a&gt; helpful as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14n8c4y", "is_robot_indexable": true, "report_reasons": null, "author": "tomhallett", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n8c4y/fivetran_vs_estuarydev/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14n8c4y/fivetran_vs_estuarydev/", "subreddit_subscribers": 113362, "created_utc": 1688150128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a fintech, where my primary responsibilities revolve around data quality, dashboards, and automation.\n\nGiven the state of the databases within the company, my dashboards require extensive transformation and data preparation. To address this, I have created a datalake in Google Cloud Platform (GCP) that consolidates all the necessary data sources. Subsequently, I have built a data warehouse using BigQuery to facilitate efficient querying and analysis.\n\nSince the company's database cannot be directly accessed from the Power BI service, BigQuery also serves the purpose of scheduling data refreshes, ensuring up-to-date information for reporting.\n\nTo streamline the data pipeline, I leverage Prefect and Python, utilizing automation techniques.\n\nFurthermore, I engage in system development activities, such as creating simple scripts that evaluate whether a client is overdue and sending email alerts accordingly.\n\nI also perform basic analyses, such as cohort analysis and turnover calculation, primarily to present relevant metrics in the reports.\n\nWhat are your thoughts on my role and responsibilities? How can i improve my portfolio and experience? Do you think my role qualify as a role of a data engineer or would be more of a analytics engineer?", "author_fullname": "t2_17f19lgj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can i improve?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nc62n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688159236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a fintech, where my primary responsibilities revolve around data quality, dashboards, and automation.&lt;/p&gt;\n\n&lt;p&gt;Given the state of the databases within the company, my dashboards require extensive transformation and data preparation. To address this, I have created a datalake in Google Cloud Platform (GCP) that consolidates all the necessary data sources. Subsequently, I have built a data warehouse using BigQuery to facilitate efficient querying and analysis.&lt;/p&gt;\n\n&lt;p&gt;Since the company&amp;#39;s database cannot be directly accessed from the Power BI service, BigQuery also serves the purpose of scheduling data refreshes, ensuring up-to-date information for reporting.&lt;/p&gt;\n\n&lt;p&gt;To streamline the data pipeline, I leverage Prefect and Python, utilizing automation techniques.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, I engage in system development activities, such as creating simple scripts that evaluate whether a client is overdue and sending email alerts accordingly.&lt;/p&gt;\n\n&lt;p&gt;I also perform basic analyses, such as cohort analysis and turnover calculation, primarily to present relevant metrics in the reports.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on my role and responsibilities? How can i improve my portfolio and experience? Do you think my role qualify as a role of a data engineer or would be more of a analytics engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14nc62n", "is_robot_indexable": true, "report_reasons": null, "author": "Seyrenz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14nc62n/how_can_i_improve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14nc62n/how_can_i_improve/", "subreddit_subscribers": 113362, "created_utc": 1688159236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI'm a 27/M data engineer based in Europe, and I could really use some guidance in my career journey. As an immigrant and the only one in my family in the industry, I often find myself unsure of where to turn for advice.\n\nI'm on the lookout for an experienced professional who has successfully navigated the data engineering industry and can lend me some insights to make better decisions.\n\nIf any of you have been in a similar position, I'd love to hear your stories. How did you manage to find that mentor figure who provided you with the guidance you needed?", "author_fullname": "t2_73mpr6fx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I find a mentor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mxlvn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688123976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a 27/M data engineer based in Europe, and I could really use some guidance in my career journey. As an immigrant and the only one in my family in the industry, I often find myself unsure of where to turn for advice.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on the lookout for an experienced professional who has successfully navigated the data engineering industry and can lend me some insights to make better decisions.&lt;/p&gt;\n\n&lt;p&gt;If any of you have been in a similar position, I&amp;#39;d love to hear your stories. How did you manage to find that mentor figure who provided you with the guidance you needed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14mxlvn", "is_robot_indexable": true, "report_reasons": null, "author": "Maxtasis", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14mxlvn/how_can_i_find_a_mentor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14mxlvn/how_can_i_find_a_mentor/", "subreddit_subscribers": 113362, "created_utc": 1688123976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm here seeking your valuable insights and opinions on data strategies, particularly in the context of my organization's current situation. We have made some progress so far, but we're eager to explore what more we can do to enhance our data practices.\n\nHere's a summary of our current data setup: We have sourced data from multiple channels, applied cleansing techniques (such as duplicate removal), and implemented SCD2 (Slowly Changing Dimensions) in our data layer. Our tech stack includes AWS, Glue, DBT, and Redshift, where the final cleansed data resides.\n\n&amp;#x200B;\n\n1. What additional steps can my organization take to improve our data strategy?\n\n&amp;#x200B;\n\n2. How can we maximize the value of our cleansed data in Redshift?\n\n&amp;#x200B;\n\n3. What are open sources available to add more value to the data, infra , DevOps, etc..\n\n&amp;#x200B;\n\n4. Are there any cost-effective solutions or techniques that we should consider implementing to improve data quality, data governance, or data management? I.e Open Source\n\n&amp;#x200B;\n\n5. Data observability, Precise Alerts, and notifications.  \n\n\n6. AI on Data and analytics. \n\nI'm good to hear about your experiences, suggestions, and success stories related to data strategies.\n\n&amp;#x200B;", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's Your Data Strategy? Help us take it to the next level! :)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n38qz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688138256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m here seeking your valuable insights and opinions on data strategies, particularly in the context of my organization&amp;#39;s current situation. We have made some progress so far, but we&amp;#39;re eager to explore what more we can do to enhance our data practices.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a summary of our current data setup: We have sourced data from multiple channels, applied cleansing techniques (such as duplicate removal), and implemented SCD2 (Slowly Changing Dimensions) in our data layer. Our tech stack includes AWS, Glue, DBT, and Redshift, where the final cleansed data resides.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What additional steps can my organization take to improve our data strategy?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How can we maximize the value of our cleansed data in Redshift?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What are open sources available to add more value to the data, infra , DevOps, etc..&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Are there any cost-effective solutions or techniques that we should consider implementing to improve data quality, data governance, or data management? I.e Open Source&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Data observability, Precise Alerts, and notifications.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;AI on Data and analytics. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m good to hear about your experiences, suggestions, and success stories related to data strategies.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14n38qz", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n38qz/whats_your_data_strategy_help_us_take_it_to_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14n38qz/whats_your_data_strategy_help_us_take_it_to_the/", "subreddit_subscribers": 113362, "created_utc": 1688138256.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have experience with the flink-cdc-connector project? I'm trying to determine whether it's production ready. What are the advantages and disadvantages of using it, compared to deploying Flink and Debezium separately?\n\nI'm considering this solution mainly due to its simplicity. My source database has a total volume of less than 100GB (will probably grow in the future), I need real-time data for fraud detection. Perhaps there are alternative technologies available that I've overlooked?\n\nThe datalake is supposed to serve as the main storage, while MySQL and MongoDB are used for latest webapp data only. Any insights or suggestions would be greatly appreciated.\n\nAll the assumptions were imposed by the backend team.", "author_fullname": "t2_zo2qv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink CDC / alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14npfpt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688199005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have experience with the flink-cdc-connector project? I&amp;#39;m trying to determine whether it&amp;#39;s production ready. What are the advantages and disadvantages of using it, compared to deploying Flink and Debezium separately?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering this solution mainly due to its simplicity. My source database has a total volume of less than 100GB (will probably grow in the future), I need real-time data for fraud detection. Perhaps there are alternative technologies available that I&amp;#39;ve overlooked?&lt;/p&gt;\n\n&lt;p&gt;The datalake is supposed to serve as the main storage, while MySQL and MongoDB are used for latest webapp data only. Any insights or suggestions would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;All the assumptions were imposed by the backend team.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14npfpt", "is_robot_indexable": true, "report_reasons": null, "author": "zakpaw", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14npfpt/flink_cdc_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14npfpt/flink_cdc_alternatives/", "subreddit_subscribers": 113362, "created_utc": 1688199005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Still a newbie here.\n\nWe use Fivetran as a data ingestion tool. But we want to pull data from Source A, which doesn\u2019t have a native connection in Fivetran yet.\n\nIs it possible to schedule a task using snowflake that pulls data from source A\u2019s API, copies it to an internal staging table, create a stream on that table, and use tasks to run that to a production table? Would appreciate the help!", "author_fullname": "t2_3jp600u4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to pull data from Source A to Snowflake using all Snowflake resources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nf0en", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688166283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Still a newbie here.&lt;/p&gt;\n\n&lt;p&gt;We use Fivetran as a data ingestion tool. But we want to pull data from Source A, which doesn\u2019t have a native connection in Fivetran yet.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to schedule a task using snowflake that pulls data from source A\u2019s API, copies it to an internal staging table, create a stream on that table, and use tasks to run that to a production table? Would appreciate the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14nf0en", "is_robot_indexable": true, "report_reasons": null, "author": "bay654", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14nf0en/is_it_possible_to_pull_data_from_source_a_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14nf0en/is_it_possible_to_pull_data_from_source_a_to/", "subreddit_subscribers": 113362, "created_utc": 1688166283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am setting up our company's databricks environment and I am wondering how you guys go about naming the catalog.schema.table? \n\n\\- Is catalog by business unit, project, connection? \n\n\\- For bronze/silver/gold is that delineated at the catalog, schema, or table level?", "author_fullname": "t2_81ywblydd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you organizing data in databricks metastore?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14naf0x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688155068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am setting up our company&amp;#39;s databricks environment and I am wondering how you guys go about naming the catalog.schema.table? &lt;/p&gt;\n\n&lt;p&gt;- Is catalog by business unit, project, connection? &lt;/p&gt;\n\n&lt;p&gt;- For bronze/silver/gold is that delineated at the catalog, schema, or table level?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14naf0x", "is_robot_indexable": true, "report_reasons": null, "author": "DataDoyle", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14naf0x/how_are_you_organizing_data_in_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14naf0x/how_are_you_organizing_data_in_databricks/", "subreddit_subscribers": 113362, "created_utc": 1688155068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's the best design for providing access to users to the current state of data in a source in a Data Lake architecture, given a source with keyed /entity data that might change.\n\n**Use Case:**\n\nYou are replicating table A from a source (maybe it's an API or table or whatever). Table A has an insert/update date. Rows are occasionally deleted. Table A grows over time.\n\nYou do an extract into your lake's object storage each day of the prior day's inserted updated data. So you have an entry for each day's worth of data.\n\nSo now different versions of a given entity are in different files. **An end user would have to know this and would have to setup their queries in such a way to make sure they got the latest / correct version.**\n\n**Comments**:\n\nMy guess would be that you'd have another tier in your lake, where you'd have a process that gets the latest and organizes that in a different way (e.g., insert date, latest version)\n\nWith infinite resources, you could do a full extract every day, but that seems overkill, and the source might not support that.", "author_fullname": "t2_ahf8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replicating Changing Data for Accurate End User Access in a Lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n210w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688135465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the best design for providing access to users to the current state of data in a source in a Data Lake architecture, given a source with keyed /entity data that might change.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Use Case:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;You are replicating table A from a source (maybe it&amp;#39;s an API or table or whatever). Table A has an insert/update date. Rows are occasionally deleted. Table A grows over time.&lt;/p&gt;\n\n&lt;p&gt;You do an extract into your lake&amp;#39;s object storage each day of the prior day&amp;#39;s inserted updated data. So you have an entry for each day&amp;#39;s worth of data.&lt;/p&gt;\n\n&lt;p&gt;So now different versions of a given entity are in different files. &lt;strong&gt;An end user would have to know this and would have to setup their queries in such a way to make sure they got the latest / correct version.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Comments&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;p&gt;My guess would be that you&amp;#39;d have another tier in your lake, where you&amp;#39;d have a process that gets the latest and organizes that in a different way (e.g., insert date, latest version)&lt;/p&gt;\n\n&lt;p&gt;With infinite resources, you could do a full extract every day, but that seems overkill, and the source might not support that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14n210w", "is_robot_indexable": true, "report_reasons": null, "author": "PencilBoy99", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n210w/replicating_changing_data_for_accurate_end_user/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14n210w/replicating_changing_data_for_accurate_end_user/", "subreddit_subscribers": 113362, "created_utc": 1688135465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI'm newish to database normalization.\n\nI took notes on 1NF, 2NF and 3NF. However my notes for 2NF are confusing.\n\nAfter re-looking it up, I understand that 2NF means:  \n\n\n&gt;Each column must pertain to the entire primary key, and not just part of it.\n\nThat seems simple enough, however, my notes from years ago seem much more complicated. I wrote something along the lines of:  \n\n\n&gt;Create  a new table for a column if A) An individual record can have more than  one value for that column or  B) Multiple records can refer to one  particular value in a column.\n\nThese  seem like two different rules and I'm wondering what I was thinking  describing the latter one as 2NF, or am I missing something showing they  are the same? Which is the correct 2NF and what does the other actually  refer to?\n\nthanks", "author_fullname": "t2_4hqxtpw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clarification on 2NF database normalization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14np11w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688197574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m newish to database normalization.&lt;/p&gt;\n\n&lt;p&gt;I took notes on 1NF, 2NF and 3NF. However my notes for 2NF are confusing.&lt;/p&gt;\n\n&lt;p&gt;After re-looking it up, I understand that 2NF means:  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Each column must pertain to the entire primary key, and not just part of it.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;That seems simple enough, however, my notes from years ago seem much more complicated. I wrote something along the lines of:  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Create  a new table for a column if A) An individual record can have more than  one value for that column or  B) Multiple records can refer to one  particular value in a column.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;These  seem like two different rules and I&amp;#39;m wondering what I was thinking  describing the latter one as 2NF, or am I missing something showing they  are the same? Which is the correct 2NF and what does the other actually  refer to?&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14np11w", "is_robot_indexable": true, "report_reasons": null, "author": "codeyCode", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14np11w/clarification_on_2nf_database_normalization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14np11w/clarification_on_2nf_database_normalization/", "subreddit_subscribers": 113362, "created_utc": 1688197574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Who was at summit? What do you think was most interesting? What were your favorite sessions? Recordings will be up next week, so I'd love to know what sessions I might have missed in person.", "author_fullname": "t2_3iwv58me", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake Summit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nim8s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688176559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Who was at summit? What do you think was most interesting? What were your favorite sessions? Recordings will be up next week, so I&amp;#39;d love to know what sessions I might have missed in person.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14nim8s", "is_robot_indexable": true, "report_reasons": null, "author": "vaporandlies", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14nim8s/snowflake_summit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14nim8s/snowflake_summit/", "subreddit_subscribers": 113362, "created_utc": 1688176559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Guys  which do you advice me to do . (Computer science major + artificial intelligence specialization) or (Data engineering major + artificial intelligence specialization) , plus who makes more a software engineer or data engineer?", "author_fullname": "t2_66m9v5u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(P.S )these are for a bachelors degree", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nezz0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688166252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys  which do you advice me to do . (Computer science major + artificial intelligence specialization) or (Data engineering major + artificial intelligence specialization) , plus who makes more a software engineer or data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14nezz0", "is_robot_indexable": true, "report_reasons": null, "author": "Carefull_eater", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14nezz0/ps_these_are_for_a_bachelors_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14nezz0/ps_these_are_for_a_bachelors_degree/", "subreddit_subscribers": 113362, "created_utc": 1688166252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Langchain : Concept and Getting Started", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14n2bgm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tfbRV25S6cFuc-ENmMyDd7uBGiZfa9DY6iXb7rJ8xyo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688136136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/decube/p/langchain-intro-and-getting-started?r=25kgne&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d79OLUmyA7yvteBzKIrEKnXMn_L870SjIr7vIvbTm9M.jpg?auto=webp&amp;v=enabled&amp;s=1fb34136490b3e39934bb6964d1430e48156e892", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/d79OLUmyA7yvteBzKIrEKnXMn_L870SjIr7vIvbTm9M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93666014c97e23bd880ef3cecc4aa764463eed68", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/d79OLUmyA7yvteBzKIrEKnXMn_L870SjIr7vIvbTm9M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f914d8c0538e929dd21545935537f9398cd254a8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/d79OLUmyA7yvteBzKIrEKnXMn_L870SjIr7vIvbTm9M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22c8456202b974eb865284dbd91b4540c2835eed", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/d79OLUmyA7yvteBzKIrEKnXMn_L870SjIr7vIvbTm9M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae559b666725261352efc49155d83f26eb763d0b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/d79OLUmyA7yvteBzKIrEKnXMn_L870SjIr7vIvbTm9M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f57ca200ff65fd5801f49dd471330e8c208f754", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/d79OLUmyA7yvteBzKIrEKnXMn_L870SjIr7vIvbTm9M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=222e9b5469af9785b6fc5cdd0a21b139e14b14bb", "width": 1080, "height": 540}], "variants": {}, "id": "WRF214u5L6bDWjpH-4CR096ZLtXOZYMkjkT3FC4xkPs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14n2bgm", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n2bgm/langchain_concept_and_getting_started/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/decube/p/langchain-intro-and-getting-started?r=25kgne&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 113362, "created_utc": 1688136136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nI am using awswrangler to write two pandas DataFrames to an iceberg table. For some reason both tables have \\~900k rows, most of the rows are empty. The dataframes only contains 200k rows.\n\nI also write this to Impala and there it is fine? What is going on? Is this a bug in awswrangler?", "author_fullname": "t2_5o9ebpsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AwsWrangler Athena Iceberg writes empty rows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14n1jrr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688134353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I am using awswrangler to write two pandas DataFrames to an iceberg table. For some reason both tables have ~900k rows, most of the rows are empty. The dataframes only contains 200k rows.&lt;/p&gt;\n\n&lt;p&gt;I also write this to Impala and there it is fine? What is going on? Is this a bug in awswrangler?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14n1jrr", "is_robot_indexable": true, "report_reasons": null, "author": "mosquitsch", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n1jrr/awswrangler_athena_iceberg_writes_empty_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14n1jrr/awswrangler_athena_iceberg_writes_empty_rows/", "subreddit_subscribers": 113362, "created_utc": 1688134353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I developed an open source OLAP multidimensional database, its name is EuclidOLAP, and its most unique feature is the automatic real-time aggregation capability, if you use it for data analysis then you can focus more on the semantic model that is close to the actual business, and do not need to think about how the detailed data is aggregated upward.\n\nIt also has the following features:\n\n* The deployment is very simple to run;\n* It can run stand-alone or in a distributed architecture;\n* Using SQL-like language MDX, it has more powerful multi-dimensional query capabilities.\n\nThis project can be accessed on [Github](https://github.com/EuclidOLAP/EuclidOLAP).\n\n&amp;#x200B;\n\nNext, you can learn about the logical model of a multidimensional database through the following.\n\nMultidimensional databases organize and present data in the structure of hyper-cubes, and you can imagine that these cubes exist in a multidimensional space, and each cube can be associated with several dimensions. Dimensions are similar to axes, while a dimension represents a specific business perspective, such as the date dimension and the region dimension. The interior of a cube is filled with some quantifiable data, which is called measure.\n\n# Dimension\n\nDimensions are similar to axes, and a dimension also represents a business perspective. For example, an airline can analyze its turnover data through three business perspectives: classes of service dimension, aircraft models dimension and date dimension.\n\n[dimension](https://preview.redd.it/i0eu7owrs59b1.png?width=793&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=97237e2b26963ddc1a05e5c2763fad16e2261ef4)\n\n# Member\n\nA member represents a definite value under the business perspective that a dimension represents. For example, there are members such as economy plus, business suite and first class suite under the classes of service dimension, A380 and Boeing 787 members under the aircraft models dimension, and members such as 2022, the first quarter of 2022, and January 2022 under the date dimension. Similar to thinking of dimensions as axes, you can think of members as scales on axes. Members under a dimension have parent-child relationships with each other, and they form a tree-like structure, the tree has a default root member.\n\n[member](https://preview.redd.it/o1thzn3vs59b1.png?width=767&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c552e779f8fc9ce7614efc4afdda72b6d668e5b5)\n\n# Cube\n\nCubes model represent data marts oriented to business topics, which are associated with several dimensions that describe some business perspectives. You can think of an 1D cube and a 2D cube as a line segment and a plane, and a 3D cube as a Rubik's cube in a Cartesian coordinate system. For cubes associated with more dimensions, they are multidimensional structures that exist in higher dimensional space, but you don't need to imagine what they look like, they are just described from more business perspectives, they have exactly the same characters as 3D cubes, as long as you understand 3D cubes you can understand higher dimensional cubes.\n\nSome data called measure is populated inside cubes, such as revenue and cost.\n\nHere's a cube about an airline, it has two measures revenue and cost, and associates three dimensions classes of service, aircraft models, and date.\n\n[cube](https://preview.redd.it/p17p2glys59b1.png?width=532&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ec605e1a94ff32f6589c9ccb61b391b34f0aafac)\n\n# Measure\n\nFor a cube, dimensions representing business perspectives are descriptive information, and measures represent values that can be quantified.\n\nJust as selecting a scale on each axis of a coordinate system determines a point, selecting a member on all dimensions of a cube determines a measure position that represents one or more measures.\n\nIn the cube shown in the figure below, the marked measure represents the revenue and cost of business suite service on the A380 aircraft in 2022.\n\n[measure](https://preview.redd.it/s64hogh1t59b1.png?width=810&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0e77a6796243147e5e85e51f7e4798426860cf8b)\n\n# Level\n\nLevels represent that members of the same level in the dimension tree structure, for example, the date dimension has four levels, one default root level represents the root member, and the other three levels represent the year, quarter, and month.\n\n[level](https://preview.redd.it/9pmuz3l4t59b1.png?width=953&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=25a7d0dcb421234bd6f86d6013a336bf4abe262b)\n\n# Hierarchy\n\nA hierarchy is a tree structure composed of dimension members, and a dimension will have a default hierarchy, and its name is generally the same as the dimension name.\n\nA dimension may have multiple hierarchies, such as the aircraft models dimension, which has two hierarchies, one that categorizes aircraft models by aircraft manufacturer and one that categorizes aircraft models by aircraft size.\n\n[hierarchy](https://preview.redd.it/x559iv88t59b1.png?width=1057&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8bd5df4e7cabe96e671706ee60fad606a73b33d3)\n\nIt should be noted that members with the same name under different hierarchies are not the same member, such as \\[Airbus\\]. \\[A320\\] and \\[Medium\\]. \\[A320\\] is two different members, and a non-default hierarchy member is generally associated with a default hierarchy member.\n\nDate dimension also have two hierarchies, one is the calendar hierarchy and the other is the financial hierarchy. Because some companies' fiscal years do not coincide with calendar years, for example, fiscal year 2022 starts in April 2022 and ends in March 2023, a separate date dimension hierarchy suitable for financial analysis needs to be designed.\n\nThe date dimension financial hierarchy is three months behind the calendar hierarchy.\n\n[hierarchy of date dimension](https://preview.redd.it/6le8slzbt59b1.png?width=846&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=15e9a0c242e0c5ca33c09bd01f836f16da44126f)\n\n# Dimension Role\n\nAn airline builds a cube for analyzing turnover data, which not only correlates the three dimensions of classes of service, aircraft models, and date, but also needs to analyze it from the perspective of flight starting point and flight ending point. Flight starting point and ending point are describing the region, they can be represented by the region dimension, this cube needs to be associated with the region dimension twice, so the concept of dimension role is introduced in EuclidOLAP, and the region dimension plays two dimension roles on this cube, flight starting point and flight ending point.\n\n[dimension role](https://preview.redd.it/2fvvh39ht59b1.png?width=863&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2fcfd959226f8fc6845c0428a11b9d7bb851bf7d)\n\nFor a dimension itself, it does not have a role attribute, and only when the dimension is associated by a cube, the association relationship is a dimensional role.\n\nIf a dimension is associated with a cube, it plays at least one dimension role, and if it plays multiple dimension roles, we need to indicate the specific dimension role when analyzing.\n\nSince the hierarchy, level and member models all belong to a specific dimension, when this dimension is associated with a cube to form a dimensional role, these models under the dimensions will also form corresponding role information, which are hierarchy role, level role and member role.\n\n[dimension role 2](https://preview.redd.it/j6x09c0kt59b1.png?width=1316&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fbd2179adba025314451460b1770d03431f1bbf3)\n\n# Tuple\n\nA tuple consists of several dimension members associated with a cube, and the following are two tuples:\n\n* (\\[Date\\].\\[2022\\].\\[Q1\\].\\[M2\\], \\[Measures\\].\\[Revenue\\])\n* (\\[Classes of Service\\].\\[Economy Plus\\], \\[Aircraft Models\\].\\[Airbus\\].\\[A380\\])\n\nA dimension member can also be treated as a tuple, for example: \\[Measures\\].\\[Cost\\] can be equated with (\\[Measures\\].\\[Cost\\]).\n\nWhen a tuple contains members of all dimensions to which the cube is associated, it is a complete tuple, otherwise it is a tuple fragment.\n\n(\\[Classes of Service\\].\\[Economy Plus\\], \\[Aircraft Models\\].\\[Boeing\\], \\[Date\\].\\[2022\\], \\[Measures\\].\\[Cost\\]) is a complete tuple.\n\n(\\[Aircraft Models\\].\\[Boeing\\], \\[Date\\].\\[2022\\]) is a tuple fragment.\n\nWhen performing multidimensional queries, a tuple fragment can be equated to a complete tuple in combination with context information.\n\nIf a complete tuple is composed of all leaf members, then it represents a specific detail measure of a cube, and if a complete tuple contains aggregate members, it corresponds to a aggregate measure, which is automatically summarized from some detail measures.\n\n[tuple](https://preview.redd.it/auia6wiot59b1.png?width=1019&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7daf15c01f645805e9c85652fb08e912f8b8be2c)\n\n# Set\n\nA Set consists of several tuples, and here are two sets:\n\n* { Tuple\\_1, Tuple\\_2 }\n* { Tuple\\_1, Tuple\\_2, Tuple\\_3, Tuple\\_4 }\n\nA single tuple can also be thought of as a set, for example: Tuple\\_1 equivalent to { Tuple\\_1 }.\n\nSimilarly, since a single dimension member can be thought of as a tuple, a single member can also be thought of as a set, \\[Date\\].\\[2022\\].\\[Q1\\] is equivalent to { ( \\[Date\\].\\[2022\\].\\[Q1\\] ) }.\n\nSet is generally used to define the display of a multidimensional query result, such as the following multidimensional query expression:\n\n    select\n    {\n        [Date]. [2020],\n        [Date]. [2021]\n    } on rows,\n    {\n        [Measures]. [Revenue], [Measures]. [Cost]\n    } on columns\n    from [Airline A];\n\nIt defines two sets, { \\[Date\\].\\[ 2020\\], \\[Date\\]. \\[2021\\] } will be displayed on row position, { \\[Measures\\].\\[ Revenue\\], \\[Measures\\]. \\[Cost\\] } will be displayed on column position.\n\nExecute this MDX(Multidimensional Expressions), and you will see the query result similar to the following table:\n\n&amp;#x200B;\n\n|| Revenue |Cost|\n|:-|:-|:-|\n|2020| 494849380 | 415181710 |\n|2021| 590103250 | 497682690 |\n\n&amp;#x200B;", "author_fullname": "t2_ecwgpeq01", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logical model of OLAP multidimensional database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"j6x09c0kt59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/j6x09c0kt59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=920fa2fb98205417f50925e36819050b1ff1f48f"}, {"y": 72, "x": 216, "u": "https://preview.redd.it/j6x09c0kt59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=238aee7c0866f74f7f9cf2f4c95192c308d8b0be"}, {"y": 107, "x": 320, "u": "https://preview.redd.it/j6x09c0kt59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c5ee370d4fdae1e437dc6b760d60d5db52ae940"}, {"y": 214, "x": 640, "u": "https://preview.redd.it/j6x09c0kt59b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7413350ccb6f95082bea141b1bbe31abacd7a119"}, {"y": 321, "x": 960, "u": "https://preview.redd.it/j6x09c0kt59b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd55b0dd7b6a08099221ebbe8cfc4e951ff0a26a"}, {"y": 361, "x": 1080, "u": "https://preview.redd.it/j6x09c0kt59b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=892c450a2e54b28fbfc154096c8c684cd662b08b"}], "s": {"y": 441, "x": 1316, "u": "https://preview.redd.it/j6x09c0kt59b1.png?width=1316&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fbd2179adba025314451460b1770d03431f1bbf3"}, "id": "j6x09c0kt59b1"}, "x559iv88t59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 29, "x": 108, "u": "https://preview.redd.it/x559iv88t59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4444ca06e1db88e45bc4025a9b23b95cee42afb6"}, {"y": 59, "x": 216, "u": "https://preview.redd.it/x559iv88t59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb0c22625cec89526e630b8728e2fb45ede2bb33"}, {"y": 87, "x": 320, "u": "https://preview.redd.it/x559iv88t59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6af16a8df739dd77a5fff79501061a68ab70628e"}, {"y": 175, "x": 640, "u": "https://preview.redd.it/x559iv88t59b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f90ee1e1d9879a3085a45884fa17c8e8e88fc98"}, {"y": 263, "x": 960, "u": "https://preview.redd.it/x559iv88t59b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ce072bf7be6060c9967e1de35c276a86415c793"}], "s": {"y": 290, "x": 1057, "u": "https://preview.redd.it/x559iv88t59b1.png?width=1057&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8bd5df4e7cabe96e671706ee60fad606a73b33d3"}, "id": "x559iv88t59b1"}, "i0eu7owrs59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/i0eu7owrs59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3551c4bd3a836702ae881064c0ba3e8c0e2094f"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/i0eu7owrs59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f10fd80e5caf9877e790786df5a129346674e5a"}, {"y": 114, "x": 320, "u": "https://preview.redd.it/i0eu7owrs59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d36c740a6260f4f71066b5f3161233525c58a052"}, {"y": 228, "x": 640, "u": "https://preview.redd.it/i0eu7owrs59b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2a7f6caac89922665054145b30500f1cc7f13be"}], "s": {"y": 283, "x": 793, "u": "https://preview.redd.it/i0eu7owrs59b1.png?width=793&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=97237e2b26963ddc1a05e5c2763fad16e2261ef4"}, "id": "i0eu7owrs59b1"}, "6le8slzbt59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/6le8slzbt59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc6df2b3d95b95b650796aec538f314c0fe6a9d0"}, {"y": 166, "x": 216, "u": "https://preview.redd.it/6le8slzbt59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80ca5865a2e55e48e6b6db92b5b6145327a1284e"}, {"y": 246, "x": 320, "u": "https://preview.redd.it/6le8slzbt59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38d009d30c9473195226b2946890277632b7ccf1"}, {"y": 492, "x": 640, "u": "https://preview.redd.it/6le8slzbt59b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9fec79f3d982bf4ad14274c7b41d511c50d44f1"}], "s": {"y": 651, "x": 846, "u": "https://preview.redd.it/6le8slzbt59b1.png?width=846&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=15e9a0c242e0c5ca33c09bd01f836f16da44126f"}, "id": "6le8slzbt59b1"}, "p17p2glys59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/p17p2glys59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4afdf0ef900cca9e0f2fb62c28a7a0ec9e175eac"}, {"y": 112, "x": 216, "u": "https://preview.redd.it/p17p2glys59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb6b7340e3db391f5c3f13b5a72ad86eb980b5e4"}, {"y": 166, "x": 320, "u": "https://preview.redd.it/p17p2glys59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b364b38953b4b67000ed1d64ab3fef8bafbc1ae"}], "s": {"y": 277, "x": 532, "u": "https://preview.redd.it/p17p2glys59b1.png?width=532&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ec605e1a94ff32f6589c9ccb61b391b34f0aafac"}, "id": "p17p2glys59b1"}, "s64hogh1t59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 41, "x": 108, "u": "https://preview.redd.it/s64hogh1t59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2790d20fec1f99faa5d084f85da361de1de35c38"}, {"y": 82, "x": 216, "u": "https://preview.redd.it/s64hogh1t59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=222a201ebe9298f6905e7fbe55bb758add0bd9c7"}, {"y": 122, "x": 320, "u": "https://preview.redd.it/s64hogh1t59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b4dbe4d44c6ed773978a9c42595d3a7e5b6febb"}, {"y": 244, "x": 640, "u": "https://preview.redd.it/s64hogh1t59b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4dc018104afe5df11fd60d48d754478032b4af71"}], "s": {"y": 310, "x": 810, "u": "https://preview.redd.it/s64hogh1t59b1.png?width=810&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0e77a6796243147e5e85e51f7e4798426860cf8b"}, "id": "s64hogh1t59b1"}, "9pmuz3l4t59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 23, "x": 108, "u": "https://preview.redd.it/9pmuz3l4t59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adc8c64ea2a8c1b155d7fbf93429fb9f5968b49d"}, {"y": 46, "x": 216, "u": "https://preview.redd.it/9pmuz3l4t59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b01880aff2ad2593c4d00013391a3f3d776f969"}, {"y": 68, "x": 320, "u": "https://preview.redd.it/9pmuz3l4t59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c975156bbc2c1e28f759fd127fe506e3a787ad72"}, {"y": 137, "x": 640, "u": "https://preview.redd.it/9pmuz3l4t59b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cd6c30a68856fda9477f27dc1e0570597129b22"}], "s": {"y": 205, "x": 953, "u": "https://preview.redd.it/9pmuz3l4t59b1.png?width=953&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=25a7d0dcb421234bd6f86d6013a336bf4abe262b"}, "id": "9pmuz3l4t59b1"}, "2fvvh39ht59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 33, "x": 108, "u": "https://preview.redd.it/2fvvh39ht59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4cf83618e894677e9a7ad2c0a5cd1772a9a870da"}, {"y": 67, "x": 216, "u": "https://preview.redd.it/2fvvh39ht59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d86132f629b1522eec65ce8cdba57ada62f21d2b"}, {"y": 99, "x": 320, "u": "https://preview.redd.it/2fvvh39ht59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b23ef3b867829d84d9e7a461c70016bee2273f17"}, {"y": 199, "x": 640, "u": "https://preview.redd.it/2fvvh39ht59b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aeff170e69106a5511f53338348005dffe705381"}], "s": {"y": 269, "x": 863, "u": "https://preview.redd.it/2fvvh39ht59b1.png?width=863&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2fcfd959226f8fc6845c0428a11b9d7bb851bf7d"}, "id": "2fvvh39ht59b1"}, "auia6wiot59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 57, "x": 108, "u": "https://preview.redd.it/auia6wiot59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d747a9097bf296315214c2e9863e2b5a7c9d8c28"}, {"y": 114, "x": 216, "u": "https://preview.redd.it/auia6wiot59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e910e2aacb40235d9e792229b21360b5e8044d7"}, {"y": 169, "x": 320, "u": "https://preview.redd.it/auia6wiot59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac173d448e2ba7bab19d67bd6c2fb3318e9bfdb8"}, {"y": 339, "x": 640, "u": "https://preview.redd.it/auia6wiot59b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9133efcc77a2fb957e43a59b98ceb5348d65bbef"}, {"y": 509, "x": 960, "u": "https://preview.redd.it/auia6wiot59b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40a09e13cb115e74520639ec1daad1fa76284d3a"}], "s": {"y": 541, "x": 1019, "u": "https://preview.redd.it/auia6wiot59b1.png?width=1019&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7daf15c01f645805e9c85652fb08e912f8b8be2c"}, "id": "auia6wiot59b1"}, "o1thzn3vs59b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 29, "x": 108, "u": "https://preview.redd.it/o1thzn3vs59b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0acc9208ef0f456721b61a14919ec79b5ef66645"}, {"y": 58, "x": 216, "u": "https://preview.redd.it/o1thzn3vs59b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f688dd02d883c17d4bbc630d6549d9fc88c431a"}, {"y": 86, "x": 320, "u": "https://preview.redd.it/o1thzn3vs59b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=430bb990a88a382f9d3cd4bada05bfd1ed6122ba"}, {"y": 173, "x": 640, "u": "https://preview.redd.it/o1thzn3vs59b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=063f9c31207548afc775b0d25b1db3a01ab952b7"}], "s": {"y": 208, "x": 767, "u": "https://preview.redd.it/o1thzn3vs59b1.png?width=767&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c552e779f8fc9ce7614efc4afdda72b6d668e5b5"}, "id": "o1thzn3vs59b1"}}, "name": "t3_14n0zo0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_PyZo50T3dowaNmDDDzgTYpsQqX1ZUs_VSxeD0uMdLI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1688133048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I developed an open source OLAP multidimensional database, its name is EuclidOLAP, and its most unique feature is the automatic real-time aggregation capability, if you use it for data analysis then you can focus more on the semantic model that is close to the actual business, and do not need to think about how the detailed data is aggregated upward.&lt;/p&gt;\n\n&lt;p&gt;It also has the following features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The deployment is very simple to run;&lt;/li&gt;\n&lt;li&gt;It can run stand-alone or in a distributed architecture;&lt;/li&gt;\n&lt;li&gt;Using SQL-like language MDX, it has more powerful multi-dimensional query capabilities.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This project can be accessed on &lt;a href=\"https://github.com/EuclidOLAP/EuclidOLAP\"&gt;Github&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Next, you can learn about the logical model of a multidimensional database through the following.&lt;/p&gt;\n\n&lt;p&gt;Multidimensional databases organize and present data in the structure of hyper-cubes, and you can imagine that these cubes exist in a multidimensional space, and each cube can be associated with several dimensions. Dimensions are similar to axes, while a dimension represents a specific business perspective, such as the date dimension and the region dimension. The interior of a cube is filled with some quantifiable data, which is called measure.&lt;/p&gt;\n\n&lt;h1&gt;Dimension&lt;/h1&gt;\n\n&lt;p&gt;Dimensions are similar to axes, and a dimension also represents a business perspective. For example, an airline can analyze its turnover data through three business perspectives: classes of service dimension, aircraft models dimension and date dimension.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/i0eu7owrs59b1.png?width=793&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=97237e2b26963ddc1a05e5c2763fad16e2261ef4\"&gt;dimension&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Member&lt;/h1&gt;\n\n&lt;p&gt;A member represents a definite value under the business perspective that a dimension represents. For example, there are members such as economy plus, business suite and first class suite under the classes of service dimension, A380 and Boeing 787 members under the aircraft models dimension, and members such as 2022, the first quarter of 2022, and January 2022 under the date dimension. Similar to thinking of dimensions as axes, you can think of members as scales on axes. Members under a dimension have parent-child relationships with each other, and they form a tree-like structure, the tree has a default root member.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/o1thzn3vs59b1.png?width=767&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c552e779f8fc9ce7614efc4afdda72b6d668e5b5\"&gt;member&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Cube&lt;/h1&gt;\n\n&lt;p&gt;Cubes model represent data marts oriented to business topics, which are associated with several dimensions that describe some business perspectives. You can think of an 1D cube and a 2D cube as a line segment and a plane, and a 3D cube as a Rubik&amp;#39;s cube in a Cartesian coordinate system. For cubes associated with more dimensions, they are multidimensional structures that exist in higher dimensional space, but you don&amp;#39;t need to imagine what they look like, they are just described from more business perspectives, they have exactly the same characters as 3D cubes, as long as you understand 3D cubes you can understand higher dimensional cubes.&lt;/p&gt;\n\n&lt;p&gt;Some data called measure is populated inside cubes, such as revenue and cost.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a cube about an airline, it has two measures revenue and cost, and associates three dimensions classes of service, aircraft models, and date.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/p17p2glys59b1.png?width=532&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ec605e1a94ff32f6589c9ccb61b391b34f0aafac\"&gt;cube&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Measure&lt;/h1&gt;\n\n&lt;p&gt;For a cube, dimensions representing business perspectives are descriptive information, and measures represent values that can be quantified.&lt;/p&gt;\n\n&lt;p&gt;Just as selecting a scale on each axis of a coordinate system determines a point, selecting a member on all dimensions of a cube determines a measure position that represents one or more measures.&lt;/p&gt;\n\n&lt;p&gt;In the cube shown in the figure below, the marked measure represents the revenue and cost of business suite service on the A380 aircraft in 2022.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/s64hogh1t59b1.png?width=810&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0e77a6796243147e5e85e51f7e4798426860cf8b\"&gt;measure&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Level&lt;/h1&gt;\n\n&lt;p&gt;Levels represent that members of the same level in the dimension tree structure, for example, the date dimension has four levels, one default root level represents the root member, and the other three levels represent the year, quarter, and month.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9pmuz3l4t59b1.png?width=953&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=25a7d0dcb421234bd6f86d6013a336bf4abe262b\"&gt;level&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Hierarchy&lt;/h1&gt;\n\n&lt;p&gt;A hierarchy is a tree structure composed of dimension members, and a dimension will have a default hierarchy, and its name is generally the same as the dimension name.&lt;/p&gt;\n\n&lt;p&gt;A dimension may have multiple hierarchies, such as the aircraft models dimension, which has two hierarchies, one that categorizes aircraft models by aircraft manufacturer and one that categorizes aircraft models by aircraft size.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/x559iv88t59b1.png?width=1057&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8bd5df4e7cabe96e671706ee60fad606a73b33d3\"&gt;hierarchy&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It should be noted that members with the same name under different hierarchies are not the same member, such as [Airbus]. [A320] and [Medium]. [A320] is two different members, and a non-default hierarchy member is generally associated with a default hierarchy member.&lt;/p&gt;\n\n&lt;p&gt;Date dimension also have two hierarchies, one is the calendar hierarchy and the other is the financial hierarchy. Because some companies&amp;#39; fiscal years do not coincide with calendar years, for example, fiscal year 2022 starts in April 2022 and ends in March 2023, a separate date dimension hierarchy suitable for financial analysis needs to be designed.&lt;/p&gt;\n\n&lt;p&gt;The date dimension financial hierarchy is three months behind the calendar hierarchy.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6le8slzbt59b1.png?width=846&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=15e9a0c242e0c5ca33c09bd01f836f16da44126f\"&gt;hierarchy of date dimension&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Dimension Role&lt;/h1&gt;\n\n&lt;p&gt;An airline builds a cube for analyzing turnover data, which not only correlates the three dimensions of classes of service, aircraft models, and date, but also needs to analyze it from the perspective of flight starting point and flight ending point. Flight starting point and ending point are describing the region, they can be represented by the region dimension, this cube needs to be associated with the region dimension twice, so the concept of dimension role is introduced in EuclidOLAP, and the region dimension plays two dimension roles on this cube, flight starting point and flight ending point.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2fvvh39ht59b1.png?width=863&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2fcfd959226f8fc6845c0428a11b9d7bb851bf7d\"&gt;dimension role&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For a dimension itself, it does not have a role attribute, and only when the dimension is associated by a cube, the association relationship is a dimensional role.&lt;/p&gt;\n\n&lt;p&gt;If a dimension is associated with a cube, it plays at least one dimension role, and if it plays multiple dimension roles, we need to indicate the specific dimension role when analyzing.&lt;/p&gt;\n\n&lt;p&gt;Since the hierarchy, level and member models all belong to a specific dimension, when this dimension is associated with a cube to form a dimensional role, these models under the dimensions will also form corresponding role information, which are hierarchy role, level role and member role.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j6x09c0kt59b1.png?width=1316&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fbd2179adba025314451460b1770d03431f1bbf3\"&gt;dimension role 2&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Tuple&lt;/h1&gt;\n\n&lt;p&gt;A tuple consists of several dimension members associated with a cube, and the following are two tuples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;([Date].[2022].[Q1].[M2], [Measures].[Revenue])&lt;/li&gt;\n&lt;li&gt;([Classes of Service].[Economy Plus], [Aircraft Models].[Airbus].[A380])&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;A dimension member can also be treated as a tuple, for example: [Measures].[Cost] can be equated with ([Measures].[Cost]).&lt;/p&gt;\n\n&lt;p&gt;When a tuple contains members of all dimensions to which the cube is associated, it is a complete tuple, otherwise it is a tuple fragment.&lt;/p&gt;\n\n&lt;p&gt;([Classes of Service].[Economy Plus], [Aircraft Models].[Boeing], [Date].[2022], [Measures].[Cost]) is a complete tuple.&lt;/p&gt;\n\n&lt;p&gt;([Aircraft Models].[Boeing], [Date].[2022]) is a tuple fragment.&lt;/p&gt;\n\n&lt;p&gt;When performing multidimensional queries, a tuple fragment can be equated to a complete tuple in combination with context information.&lt;/p&gt;\n\n&lt;p&gt;If a complete tuple is composed of all leaf members, then it represents a specific detail measure of a cube, and if a complete tuple contains aggregate members, it corresponds to a aggregate measure, which is automatically summarized from some detail measures.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/auia6wiot59b1.png?width=1019&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7daf15c01f645805e9c85652fb08e912f8b8be2c\"&gt;tuple&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Set&lt;/h1&gt;\n\n&lt;p&gt;A Set consists of several tuples, and here are two sets:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;{ Tuple_1, Tuple_2 }&lt;/li&gt;\n&lt;li&gt;{ Tuple_1, Tuple_2, Tuple_3, Tuple_4 }&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;A single tuple can also be thought of as a set, for example: Tuple_1 equivalent to { Tuple_1 }.&lt;/p&gt;\n\n&lt;p&gt;Similarly, since a single dimension member can be thought of as a tuple, a single member can also be thought of as a set, [Date].[2022].[Q1] is equivalent to { ( [Date].[2022].[Q1] ) }.&lt;/p&gt;\n\n&lt;p&gt;Set is generally used to define the display of a multidimensional query result, such as the following multidimensional query expression:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select\n{\n    [Date]. [2020],\n    [Date]. [2021]\n} on rows,\n{\n    [Measures]. [Revenue], [Measures]. [Cost]\n} on columns\nfrom [Airline A];\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;It defines two sets, { [Date].[ 2020], [Date]. [2021] } will be displayed on row position, { [Measures].[ Revenue], [Measures]. [Cost] } will be displayed on column position.&lt;/p&gt;\n\n&lt;p&gt;Execute this MDX(Multidimensional Expressions), and you will see the query result similar to the following table:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;Revenue&lt;/th&gt;\n&lt;th align=\"left\"&gt;Cost&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2020&lt;/td&gt;\n&lt;td align=\"left\"&gt;494849380&lt;/td&gt;\n&lt;td align=\"left\"&gt;415181710&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2021&lt;/td&gt;\n&lt;td align=\"left\"&gt;590103250&lt;/td&gt;\n&lt;td align=\"left\"&gt;497682690&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fhZ57UzOnoTc-yAbyku-wufw3Ztpn4PMgitew8ZqGuA.jpg?auto=webp&amp;v=enabled&amp;s=7c824e2978cdafc08d226af3c01bf1e18256e773", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/fhZ57UzOnoTc-yAbyku-wufw3Ztpn4PMgitew8ZqGuA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29698ad079f1bb9ee5a83c087964fc937cf6daf5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/fhZ57UzOnoTc-yAbyku-wufw3Ztpn4PMgitew8ZqGuA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c56f0191c26ae202f07ca2649793ec39edc99213", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/fhZ57UzOnoTc-yAbyku-wufw3Ztpn4PMgitew8ZqGuA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d394cb94412e3a47c626e35f9a1c6fdf47ed4cb8", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/fhZ57UzOnoTc-yAbyku-wufw3Ztpn4PMgitew8ZqGuA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2009b7c9ec6e903bf3e932ed679fc9b913911ddb", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/fhZ57UzOnoTc-yAbyku-wufw3Ztpn4PMgitew8ZqGuA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c9be6fc8e438b34bfa2462a9b0e2bfe39873c53", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/fhZ57UzOnoTc-yAbyku-wufw3Ztpn4PMgitew8ZqGuA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a6fb339501b991943af73234394ba22e5b91778", "width": 1080, "height": 540}], "variants": {}, "id": "5TPQbzaqLgN2NReWbhF5x5KeogyPiqzmXTS0CYpGTHE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14n0zo0", "is_robot_indexable": true, "report_reasons": null, "author": "czg715", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n0zo0/logical_model_of_olap_multidimensional_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14n0zo0/logical_model_of_olap_multidimensional_database/", "subreddit_subscribers": 113362, "created_utc": 1688133048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI come seeking your valuable insights and suggestions on utilizing Dataform for dependency management and automating table creation in a data pipeline.\n\nMy team and I have recently started exploring Dataform as a solution for managing dependencies between our data tables in BigQuery. We believe that Dataform can help us eliminate redundancies in queries and facilitate smoother data pipeline management.\n\nHere are a few specific things we have trouble understanding:\n\n1. **Dependency Management**: We would like to understand how to effectively use Dataform to manage dependencies between different tables. How can we set up these dependencies so that when one table is created after executing a query, the next layer of dependent tables is automatically generated, is that done automatically or do we have to setup something here(like workflow configurations).\n2. **Partial Updates Handling**: If in some cases, only a few source tables are updated, while others remain unchanged. We are curious to know how Dataform handles partial updates and ensures that our data pipeline stays consistent even when some source tables change.\n3. **Managing Automation**: We want to explore automation possibilities with Dataform. How can we ensure that once a query is executed and a table is created, the subsequent layers of dependent tables are automatically generated without manual intervention?\n\nI would greatly appreciate any advice, best practices, or architectural suggestions from those who have experience with Dataform or a similar dependency management tool. We want to optimize our data pipeline and streamline the process as much as possible.\n\nThank you in advance for your time and expertise. Looking forward to your valuable responses!", "author_fullname": "t2_cu6opso3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions/Advice on Dataform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mwa32", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688119740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I come seeking your valuable insights and suggestions on utilizing Dataform for dependency management and automating table creation in a data pipeline.&lt;/p&gt;\n\n&lt;p&gt;My team and I have recently started exploring Dataform as a solution for managing dependencies between our data tables in BigQuery. We believe that Dataform can help us eliminate redundancies in queries and facilitate smoother data pipeline management.&lt;/p&gt;\n\n&lt;p&gt;Here are a few specific things we have trouble understanding:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Dependency Management&lt;/strong&gt;: We would like to understand how to effectively use Dataform to manage dependencies between different tables. How can we set up these dependencies so that when one table is created after executing a query, the next layer of dependent tables is automatically generated, is that done automatically or do we have to setup something here(like workflow configurations).&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Partial Updates Handling&lt;/strong&gt;: If in some cases, only a few source tables are updated, while others remain unchanged. We are curious to know how Dataform handles partial updates and ensures that our data pipeline stays consistent even when some source tables change.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Managing Automation&lt;/strong&gt;: We want to explore automation possibilities with Dataform. How can we ensure that once a query is executed and a table is created, the subsequent layers of dependent tables are automatically generated without manual intervention?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I would greatly appreciate any advice, best practices, or architectural suggestions from those who have experience with Dataform or a similar dependency management tool. We want to optimize our data pipeline and streamline the process as much as possible.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your time and expertise. Looking forward to your valuable responses!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14mwa32", "is_robot_indexable": true, "report_reasons": null, "author": "bha159", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14mwa32/suggestionsadvice_on_dataform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14mwa32/suggestionsadvice_on_dataform/", "subreddit_subscribers": 113362, "created_utc": 1688119740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am running a pipeline from source to staging (output: flat-file, csv), from staging to data lake and lastly to the target database at BQ.\n\nWhat do I check at staging and how do I do it?", "author_fullname": "t2_55thi7w8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Output check at each layer. What metrics should I use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mvtwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688118202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running a pipeline from source to staging (output: flat-file, csv), from staging to data lake and lastly to the target database at BQ.&lt;/p&gt;\n\n&lt;p&gt;What do I check at staging and how do I do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14mvtwh", "is_robot_indexable": true, "report_reasons": null, "author": "faizfablillah", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14mvtwh/output_check_at_each_layer_what_metrics_should_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14mvtwh/output_check_at_each_layer_what_metrics_should_i/", "subreddit_subscribers": 113362, "created_utc": 1688118202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title", "author_fullname": "t2_2x32e84y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How valuable is the Databricks Associate Data Engineering certificate in finding jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14nmdx4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688188477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14nmdx4", "is_robot_indexable": true, "report_reasons": null, "author": "traderdrakor", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14nmdx4/how_valuable_is_the_databricks_associate_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14nmdx4/how_valuable_is_the_databricks_associate_data/", "subreddit_subscribers": 113362, "created_utc": 1688188477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First time seeing a company making hardware for running SQL", "author_fullname": "t2_57e44nxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing the SQL Processing Unit (SPU) | NeuroBlade", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14n4uz4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/l-tAaPFSwXKao_WV51axWfT_dpNDlEKRBMrtd81Kyq8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688141947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "neuroblade.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First time seeing a company making hardware for running SQL&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.neuroblade.com/product/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0j7MuGpTKSnWA0xTqOEiAHLiMeRGQdrb5tLUXDzx_lU.jpg?auto=webp&amp;v=enabled&amp;s=c6ede938bf4256458aef5f361495ed2cc3287ac8", "width": 1208, "height": 636}, "resolutions": [{"url": "https://external-preview.redd.it/0j7MuGpTKSnWA0xTqOEiAHLiMeRGQdrb5tLUXDzx_lU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdaf5ce9f2a24f1f48f8dd2949e6b99b7ba0f1fe", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/0j7MuGpTKSnWA0xTqOEiAHLiMeRGQdrb5tLUXDzx_lU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c60c89894ee83055ffbc2bd9044b256ae6907710", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/0j7MuGpTKSnWA0xTqOEiAHLiMeRGQdrb5tLUXDzx_lU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=994dae05c210046ab1948fef03a8faade747d7c5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/0j7MuGpTKSnWA0xTqOEiAHLiMeRGQdrb5tLUXDzx_lU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e6723cd3db6adc2c6781dd4cd256cb506490f52", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/0j7MuGpTKSnWA0xTqOEiAHLiMeRGQdrb5tLUXDzx_lU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9b4e0fbbdba486af9b7800a201e182a8c7b4b52", "width": 960, "height": 505}, {"url": "https://external-preview.redd.it/0j7MuGpTKSnWA0xTqOEiAHLiMeRGQdrb5tLUXDzx_lU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7214a1ee1185b5b968d55d5ec954c1a47f4bba1", "width": 1080, "height": 568}], "variants": {}, "id": "1VzBNVIlk8V6-JjT3FYbe12fh_-VAVIp6fBUo8kE4o8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14n4uz4", "is_robot_indexable": true, "report_reasons": null, "author": "RstarPhoneix", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14n4uz4/introducing_the_sql_processing_unit_spu_neuroblade/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.neuroblade.com/product/", "subreddit_subscribers": 113362, "created_utc": 1688141947.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}