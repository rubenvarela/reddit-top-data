{"kind": "Listing", "data": {"after": "t3_14w24v5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fueo9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Typical interview with Airflow enjoyer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14vw6y3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 216, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 216, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nFtBLzVUZc_MKeTvdeaWA9HSUY_SBCVxLtBw7MoJWU4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689000632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/2231e36jh5bb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/2231e36jh5bb1.jpg?auto=webp&amp;s=c6b7be94fb85ebe894c4e0e283f89c3d71185a72", "width": 640, "height": 360}, "resolutions": [{"url": "https://preview.redd.it/2231e36jh5bb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8a00a57fa8e286ebae0958514fc973a5971ede4d", "width": 108, "height": 60}, {"url": "https://preview.redd.it/2231e36jh5bb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5c3983fd1c720db328fbcc1b274024087b335a9", "width": 216, "height": 121}, {"url": "https://preview.redd.it/2231e36jh5bb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c083c1a40a938e24547adda2f218b478ad596207", "width": 320, "height": 180}, {"url": "https://preview.redd.it/2231e36jh5bb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d14170407eacb42e7834de7fb1ea0fed822a765c", "width": 640, "height": 360}], "variants": {}, "id": "8yR-Xf8HU2hnJSw9jemnyK3ZGXK0kpMExbXKJOkR5PA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14vw6y3", "is_robot_indexable": true, "report_reasons": null, "author": "ponkipo", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vw6y3/typical_interview_with_airflow_enjoyer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/2231e36jh5bb1.jpg", "subreddit_subscribers": 115175, "created_utc": 1689000632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was doing backend internship with nodejs and I got to know that I don't like doing frontend and enjoying backend comparatively more.\n\nI got a Junior data engineer job offer which I have accepted, But when I asked someone about how much programming does a DE gets to do.\n\nHe said \" DE does not include much Coding.the main work is to building pipeline and databases and some views may be. I will not considered it a coding stuff\"\n\nI do enjoy programming, so can anyone here in this space share their views that do you guys as DEs code enough , how much percent of your work is really programming stuff? \n\nI have heard that Data engineering is software engineering specialising in data.", "author_fullname": "t2_jh44nvdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do Data Engineers get Enough Programming/Coding opportunity ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vz8k1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689007514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was doing backend internship with nodejs and I got to know that I don&amp;#39;t like doing frontend and enjoying backend comparatively more.&lt;/p&gt;\n\n&lt;p&gt;I got a Junior data engineer job offer which I have accepted, But when I asked someone about how much programming does a DE gets to do.&lt;/p&gt;\n\n&lt;p&gt;He said &amp;quot; DE does not include much Coding.the main work is to building pipeline and databases and some views may be. I will not considered it a coding stuff&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I do enjoy programming, so can anyone here in this space share their views that do you guys as DEs code enough , how much percent of your work is really programming stuff? &lt;/p&gt;\n\n&lt;p&gt;I have heard that Data engineering is software engineering specialising in data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vz8k1", "is_robot_indexable": true, "report_reasons": null, "author": "micky_357000", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vz8k1/do_data_engineers_get_enough_programmingcoding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vz8k1/do_data_engineers_get_enough_programmingcoding/", "subreddit_subscribers": 115175, "created_utc": 1689007514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im seeking interesting ideas for two portfolio projects related to the broad field of electrical energy or neurobiology/biology. For these projects, I would primarily like to utilize **AWS** and **Apache Airflow**. They will be semester-long projects for students. For example, they could include:\n\n1. **Predicting energy demand using meteorological data**\n2. **Optimizing the utilization of renewable energy based on weather forecasts**\n3. **Multidimensional Brain Data Analysis for Neuronal Activity Pattern Identification**\n\nSo I'm looking for an interesting idea, mainly using AWS and at least a bit of Airflow .\n\nDo you have any interesting suggestions? The key factor for me is selecting projects that will engage the students, as they will only be motivated if the projects are meaningful. They are proficient in Python, SQL, and have a basic understanding of AWS.", "author_fullname": "t2_7yv0lkcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Energy or Neurobiology-related Portfolio Projects for cognitive science students.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vrw8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688991230.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688990015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im seeking interesting ideas for two portfolio projects related to the broad field of electrical energy or neurobiology/biology. For these projects, I would primarily like to utilize &lt;strong&gt;AWS&lt;/strong&gt; and &lt;strong&gt;Apache Airflow&lt;/strong&gt;. They will be semester-long projects for students. For example, they could include:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Predicting energy demand using meteorological data&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Optimizing the utilization of renewable energy based on weather forecasts&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Multidimensional Brain Data Analysis for Neuronal Activity Pattern Identification&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for an interesting idea, mainly using AWS and at least a bit of Airflow .&lt;/p&gt;\n\n&lt;p&gt;Do you have any interesting suggestions? The key factor for me is selecting projects that will engage the students, as they will only be motivated if the projects are meaningful. They are proficient in Python, SQL, and have a basic understanding of AWS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vrw8x", "is_robot_indexable": true, "report_reasons": null, "author": "International-Shirt5", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vrw8x/looking_for_energy_or_neurobiologyrelated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vrw8x/looking_for_energy_or_neurobiologyrelated/", "subreddit_subscribers": 115175, "created_utc": 1688990015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At my company we developed our own metrics layer, over time we've started using it to build our views. It works, but having the same service handle both missions has increasingly complicated development. We toyed around with writing materialized views directly in SQL, but having no source control or CI/CD is simply not something I'm willing to do.\n\nAfter a good amount of research, we decided to move our views to dbt. I've heard a lot of consistent complaints about dbt cloud and how it's not worth the money, we have the manpower to self-host and CTO backing, so it feels like the reasonable way to go.\n\nI'm just trying to minimize unknown unknowns, and appreciate any 2 cents.", "author_fullname": "t2_44mw8sqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anything one should know before going for self-hosted dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w832y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": 1689036352.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689026969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At my company we developed our own metrics layer, over time we&amp;#39;ve started using it to build our views. It works, but having the same service handle both missions has increasingly complicated development. We toyed around with writing materialized views directly in SQL, but having no source control or CI/CD is simply not something I&amp;#39;m willing to do.&lt;/p&gt;\n\n&lt;p&gt;After a good amount of research, we decided to move our views to dbt. I&amp;#39;ve heard a lot of consistent complaints about dbt cloud and how it&amp;#39;s not worth the money, we have the manpower to self-host and CTO backing, so it feels like the reasonable way to go.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just trying to minimize unknown unknowns, and appreciate any 2 cents.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14w832y", "is_robot_indexable": true, "report_reasons": null, "author": "verysmolpupperino", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w832y/anything_one_should_know_before_going_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w832y/anything_one_should_know_before_going_for/", "subreddit_subscribers": 115175, "created_utc": 1689026969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nI'm reaching out to this community for some advice regarding my current career situation. Here's a brief overview:\n\n* Graduated with High Distinction from University of Sydney with majors in Computer Science and Data Science.\n* Over 1.5 years of experience as a Data Engineer, proficient in Python, SQL, IaC (Terraform, Puppet), and CI/CD.\n* Currently  on a Grad Working Visa in Sydney, expiring end of next year. Working  towards Permanent Residency (PR) application but it is always uncertain.\n* Recently  switched jobs to a company (XX) as a Data Engineer, but the actual role  differs significantly from the job description. My team mainly use Alteryx for data wrangling, not the Python and ETL work I expected.\n* After  a month at XX, no technical projects have come my way despite me asking  my manager for more coding related tasks. Started looking for new jobs  but facing constant rejections (not even interviews/coding tests),  making me doubt my abilities or if my visa status is hindering me.\n* Losing hope for employer sponsorship due to inability to even secure a job in the first place.\n\nSeeking  advice/suggestions for next steps or insights from anyone who has been  through a similar situation. Please share your thoughts.\n\nThank you in advance.", "author_fullname": "t2_f5yhhz77u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Advice: Struggling with Career as a Data Engineer (Sydney)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vp78r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688981815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out to this community for some advice regarding my current career situation. Here&amp;#39;s a brief overview:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Graduated with High Distinction from University of Sydney with majors in Computer Science and Data Science.&lt;/li&gt;\n&lt;li&gt;Over 1.5 years of experience as a Data Engineer, proficient in Python, SQL, IaC (Terraform, Puppet), and CI/CD.&lt;/li&gt;\n&lt;li&gt;Currently  on a Grad Working Visa in Sydney, expiring end of next year. Working  towards Permanent Residency (PR) application but it is always uncertain.&lt;/li&gt;\n&lt;li&gt;Recently  switched jobs to a company (XX) as a Data Engineer, but the actual role  differs significantly from the job description. My team mainly use Alteryx for data wrangling, not the Python and ETL work I expected.&lt;/li&gt;\n&lt;li&gt;After  a month at XX, no technical projects have come my way despite me asking  my manager for more coding related tasks. Started looking for new jobs  but facing constant rejections (not even interviews/coding tests),  making me doubt my abilities or if my visa status is hindering me.&lt;/li&gt;\n&lt;li&gt;Losing hope for employer sponsorship due to inability to even secure a job in the first place.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Seeking  advice/suggestions for next steps or insights from anyone who has been  through a similar situation. Please share your thoughts.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vp78r", "is_robot_indexable": true, "report_reasons": null, "author": "Many-Local-765", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vp78r/need_advice_struggling_with_career_as_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vp78r/need_advice_struggling_with_career_as_a_data/", "subreddit_subscribers": 115175, "created_utc": 1688981815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on modeling and organizing data in Databricks. We created 2 workspaces - one for non-prod and one for prod and are using unity catalog. I am going to go with the Databricks recommended medallion architecture for storing data in 3 zones based on the readiness/transformation. \nMy questions are as follows,\n1. How do I organize these 3 zones? Would that be 3 different catalogs or 3 different schemas under one catalog? We currently have \u201cnon-prod\u201d catalog and \u201cprod\u201d catalog created for non-prod and prod env respectively.\n2. Do I have to name them bronze, silver and gold or can I name them whatever makes sense for us? For ex: raw, refined and enriched\n3. From my understand, the first zone maintains data as-is from the SOR, second zone has necessary transformations, cleansing or mapping based on business needs. And the data modeling actually happens in the last zone where business systems consume this data. I.e Data Marts\n\nIs my understanding right? \n\nAnything else I should be considering while modeling the data? \n\nThanks in advance!", "author_fullname": "t2_qwfq9dcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modeling in Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14we9ye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689042714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on modeling and organizing data in Databricks. We created 2 workspaces - one for non-prod and one for prod and are using unity catalog. I am going to go with the Databricks recommended medallion architecture for storing data in 3 zones based on the readiness/transformation. \nMy questions are as follows,\n1. How do I organize these 3 zones? Would that be 3 different catalogs or 3 different schemas under one catalog? We currently have \u201cnon-prod\u201d catalog and \u201cprod\u201d catalog created for non-prod and prod env respectively.\n2. Do I have to name them bronze, silver and gold or can I name them whatever makes sense for us? For ex: raw, refined and enriched\n3. From my understand, the first zone maintains data as-is from the SOR, second zone has necessary transformations, cleansing or mapping based on business needs. And the data modeling actually happens in the last zone where business systems consume this data. I.e Data Marts&lt;/p&gt;\n\n&lt;p&gt;Is my understanding right? &lt;/p&gt;\n\n&lt;p&gt;Anything else I should be considering while modeling the data? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14we9ye", "is_robot_indexable": true, "report_reasons": null, "author": "Aromatic-Owl1264", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14we9ye/data_modeling_in_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14we9ye/data_modeling_in_databricks/", "subreddit_subscribers": 115175, "created_utc": 1689042714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I\u2019m a field engineer at Materialize and thought I would share a little pattern we\u2019ve seen come up a few times. Hope you find it useful!\n\nhttps://materialize.com/docs/transform-data/patterns/rules-engine/", "author_fullname": "t2_5p00kusf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rules execution engine using LATERAL joins", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w4thx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689019835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I\u2019m a field engineer at Materialize and thought I would share a little pattern we\u2019ve seen come up a few times. Hope you find it useful!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://materialize.com/docs/transform-data/patterns/rules-engine/\"&gt;https://materialize.com/docs/transform-data/patterns/rules-engine/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?auto=webp&amp;s=6a5dca93dafea1727487ba2900d43839b14e802c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=91f6da7a00141be57f9924de9aab6e5e857124ca", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=72ff43ca2022a30e9934b374fdb20ae6c3b0c4d5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c05d794f5e3a10ae3e711edd7197207ac671ec19", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f05c747eb71a49f4ef03604ca05dd0a021eade95", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c9781774515d890e8e2d73b13a36e23287de2a2", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7b1db2b0977bf7935243dbc818db8124d116f2ca", "width": 1080, "height": 567}], "variants": {}, "id": "bUusx0wZzzF_XmBpeasJ3TLKk0AsM3dnnnxC7yOn5JI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14w4thx", "is_robot_indexable": true, "report_reasons": null, "author": "Chuck-Alt-Delete", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w4thx/rules_execution_engine_using_lateral_joins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w4thx/rules_execution_engine_using_lateral_joins/", "subreddit_subscribers": 115175, "created_utc": 1689019835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_nq65wse7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote a short primer on fact tables in data warehouses, let me know if I need to add anything", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w9ryg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1689031020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "anniscodes.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://anniscodes.com/posts/primer-fact-tables/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14w9ryg", "is_robot_indexable": true, "report_reasons": null, "author": "lancelot_of_camelot", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w9ryg/i_wrote_a_short_primer_on_fact_tables_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://anniscodes.com/posts/primer-fact-tables/", "subreddit_subscribers": 115175, "created_utc": 1689031020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, it's my first post on reddit\ud83e\udd73. I want to start a discussion to get a better understanding of what a good DE should dream about. So my question is which DE jobs are the best ones and which knowledge and experience should I have to get them. Also, a lot of jobs in DE are concentrated in US and I am interested in whether it is possible to get a good DE job from other countries, for example Poland; or these countries, where outsourcing is the biggest part of SWE job market, will inevitably get only the most boring things?  What I can think about is progressing in distributed systems and databases, but for some reason I don't see any demand for such knowledge, for example recently I have implemented a sharded kv store on top of Raft and it seems it hasn't changed my job market value for some reason. Is the only way for a third country national to get noticed is to contribute to spark github? Will appreciate all opinions", "author_fullname": "t2_g6ziwt5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get an interesting job in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w25nl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689014004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, it&amp;#39;s my first post on reddit\ud83e\udd73. I want to start a discussion to get a better understanding of what a good DE should dream about. So my question is which DE jobs are the best ones and which knowledge and experience should I have to get them. Also, a lot of jobs in DE are concentrated in US and I am interested in whether it is possible to get a good DE job from other countries, for example Poland; or these countries, where outsourcing is the biggest part of SWE job market, will inevitably get only the most boring things?  What I can think about is progressing in distributed systems and databases, but for some reason I don&amp;#39;t see any demand for such knowledge, for example recently I have implemented a sharded kv store on top of Raft and it seems it hasn&amp;#39;t changed my job market value for some reason. Is the only way for a third country national to get noticed is to contribute to spark github? Will appreciate all opinions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14w25nl", "is_robot_indexable": true, "report_reasons": null, "author": "fire_air", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w25nl/how_to_get_an_interesting_job_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w25nl/how_to_get_an_interesting_job_in_de/", "subreddit_subscribers": 115175, "created_utc": 1689014004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\nIve got a task to create a pipeline to replicate sap data and then get only deltas. I know that there is SAP CDC connector to which I need create self hosted integration runtime on client site. I've got a time to create a list of questions to client. What should I take into consideration? My first question is whether they do already have SHIR and we can share to reduce costs and maintainance time. If they do, do I need to install anything on my machine? Its my first commercial project, all self study was based on auto-resolve IR. After I am done with IR I guess its pretty straightforward, just need linked service pointing to this IR, server name, number, client id and dataset with proper ODP framework \n\nIf they dont, do I need to create a VM, to install SHIR there, and SAP .NET connector in there? \n\nWhat I can even ask them?", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure SAP CDC connector considerations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vvn0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688999374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello\nIve got a task to create a pipeline to replicate sap data and then get only deltas. I know that there is SAP CDC connector to which I need create self hosted integration runtime on client site. I&amp;#39;ve got a time to create a list of questions to client. What should I take into consideration? My first question is whether they do already have SHIR and we can share to reduce costs and maintainance time. If they do, do I need to install anything on my machine? Its my first commercial project, all self study was based on auto-resolve IR. After I am done with IR I guess its pretty straightforward, just need linked service pointing to this IR, server name, number, client id and dataset with proper ODP framework &lt;/p&gt;\n\n&lt;p&gt;If they dont, do I need to create a VM, to install SHIR there, and SAP .NET connector in there? &lt;/p&gt;\n\n&lt;p&gt;What I can even ask them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vvn0r", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vvn0r/azure_sap_cdc_connector_considerations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vvn0r/azure_sap_cdc_connector_considerations/", "subreddit_subscribers": 115175, "created_utc": 1688999374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what is a decent salary (per month, before taxes) in Sweden (Stockholm) for a data engineer with less than 2  YOE and no other prior technical background? I am preparing for an interview and I want to know how much to ask in case I'm asked", "author_fullname": "t2_iiiar3v5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salaries in Sweden", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vpyst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688986349.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688984233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what is a decent salary (per month, before taxes) in Sweden (Stockholm) for a data engineer with less than 2  YOE and no other prior technical background? I am preparing for an interview and I want to know how much to ask in case I&amp;#39;m asked&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14vpyst", "is_robot_indexable": true, "report_reasons": null, "author": "23reddituser", "discussion_type": null, "num_comments": 26, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vpyst/salaries_in_sweden/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vpyst/salaries_in_sweden/", "subreddit_subscribers": 115175, "created_utc": 1688984233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a fresher and I have been learning snowflake for some time now. But I wanted to take up a small project which is beginner friendly. I also have an interview coming up for an entry level position which has Snowflake as one of its requirements. I wanted to work on a small project before the interview. Any ideas or suggestions on any suitable beginner friendly projects using Snowflake?", "author_fullname": "t2_kfmm6io5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner friendly project ideas using Snowflake.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wicxy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689054820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a fresher and I have been learning snowflake for some time now. But I wanted to take up a small project which is beginner friendly. I also have an interview coming up for an entry level position which has Snowflake as one of its requirements. I wanted to work on a small project before the interview. Any ideas or suggestions on any suitable beginner friendly projects using Snowflake?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14wicxy", "is_robot_indexable": true, "report_reasons": null, "author": "smol_Caterpillar_21", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wicxy/beginner_friendly_project_ideas_using_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wicxy/beginner_friendly_project_ideas_using_snowflake/", "subreddit_subscribers": 115175, "created_utc": 1689054820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "California privacy act and similar data protection laws allows users to request that their data be hard deleted from source systems. I've been wracking my brain trying to figure out how to implement something like this. My team uses a kafka/dbt/snowflake stack, and I'm a bit lost as to how hard deletes could flow through data warehouse models. I assume others have dealt with this as it's a legal thing - has anyone implemented this? What was your approach?", "author_fullname": "t2_5e0ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you implementing CCPA compliance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vutj2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688997497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;California privacy act and similar data protection laws allows users to request that their data be hard deleted from source systems. I&amp;#39;ve been wracking my brain trying to figure out how to implement something like this. My team uses a kafka/dbt/snowflake stack, and I&amp;#39;m a bit lost as to how hard deletes could flow through data warehouse models. I assume others have dealt with this as it&amp;#39;s a legal thing - has anyone implemented this? What was your approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vutj2", "is_robot_indexable": true, "report_reasons": null, "author": "harrytrumanprimate", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vutj2/how_are_you_implementing_ccpa_compliance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vutj2/how_are_you_implementing_ccpa_compliance/", "subreddit_subscribers": 115175, "created_utc": 1688997497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nFor those of you who use the dbt framework, how do you try to keep the YAML in sync with the model? I\u2019m coming across situations where I removed a column from the model but forgot to remove it from the YAML, or added a column to the model but forgot to update the YAML.\n\nThe closest I found was the query posted in this Github issue: https://github.com/dbt-labs/dbt-core/issues/1570#issuecomment-1500395582 . \n\nThank you in advance!", "author_fullname": "t2_d883lz76p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools for keep dbt model and YAML in sync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w9syy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689031091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;For those of you who use the dbt framework, how do you try to keep the YAML in sync with the model? I\u2019m coming across situations where I removed a column from the model but forgot to remove it from the YAML, or added a column to the model but forgot to update the YAML.&lt;/p&gt;\n\n&lt;p&gt;The closest I found was the query posted in this Github issue: &lt;a href=\"https://github.com/dbt-labs/dbt-core/issues/1570#issuecomment-1500395582\"&gt;https://github.com/dbt-labs/dbt-core/issues/1570#issuecomment-1500395582&lt;/a&gt; . &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u5iW9Z_2NYELU-7A8Dcwkn_7dz06IUYe-rKjcnKkNTI.jpg?auto=webp&amp;s=dd1c6d231c8acb5f11622c213a6a33cb51b594cc", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/u5iW9Z_2NYELU-7A8Dcwkn_7dz06IUYe-rKjcnKkNTI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc2c35a239e5acf5f4003d83ddb130a2833df103", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/u5iW9Z_2NYELU-7A8Dcwkn_7dz06IUYe-rKjcnKkNTI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdb7c32433efdcd3f9e782b6124c8c7ebc490d2a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/u5iW9Z_2NYELU-7A8Dcwkn_7dz06IUYe-rKjcnKkNTI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aae643b9fd6e061151ca8e2681d4755f1f0aa8e9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/u5iW9Z_2NYELU-7A8Dcwkn_7dz06IUYe-rKjcnKkNTI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=84600c7cc35eb02bbed41d0cb01a59c43b178426", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/u5iW9Z_2NYELU-7A8Dcwkn_7dz06IUYe-rKjcnKkNTI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3d72744c62aab5b31438b6f1828a4c999383ccc", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/u5iW9Z_2NYELU-7A8Dcwkn_7dz06IUYe-rKjcnKkNTI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ddf69602b000535be7e502f9db6d87717654f985", "width": 1080, "height": 540}], "variants": {}, "id": "8TSVy0i4pjNhx1l_gWKFMbjdT9cL3RcQrhhh1ufpkKI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14w9syy", "is_robot_indexable": true, "report_reasons": null, "author": "Creative-Aside-4145", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w9syy/tools_for_keep_dbt_model_and_yaml_in_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w9syy/tools_for_keep_dbt_model_and_yaml_in_sync/", "subreddit_subscribers": 115175, "created_utc": 1689031091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a seasoned IT architect currently working with a startup, I wanted to share my journey with you all, as well as some of the valuable insights I've discovered along the way. Here's an article where I dive into how organizations can use BDA to establish a sustainable competitive advantage, and some of the strategies to effectively implement it. I hope you find this beneficial in your own journey as well.\n\n# How to Leverage Big Data Analytics for Sustainable Competitive Advantage\n\nToday's technological era generates a massive amount of data, and businesses everywhere are trying to turn this raw data into actionable insights. Big Data Analytics (BDA) has emerged as a key strategy, helping businesses gain unique insights to unlock new opportunities and differentiate from competitors. Ignoring BDA might leave you trailing behind in the competition, or missing out on potential advantages.\n\nTo achieve the strategic benefits of BDA, you need to understand the processes that allow it to add value and remain competitive. This article offers a guide on how businesses can use several frameworks to evaluate BDA\u2019s strategic value while avoiding pitfalls that come with improper implementation.\n\nThe VRIO framework (Valuable, Rare, Imitable, Organizationally embedded) can help assess the potential of BDA to create strategic business value. It prompts businesses to question if their BDA strategies offer valuable insights, are unique, challenging for competitors to copy, and supported by their organizational strategies and culture.\n\n# Value of Big Data Analytics\n\nThe key strength of Big Data Analytics lies in its ability to provide unique insights that can be used to seize new business opportunities or counter competitive threats. These insights can improve various business areas, including business processes, product innovation, customer experience, and overall organizational performance.\n\n# Uniqueness in Big Data Analytics\n\nBDA becomes unique or 'rare' when few competitors can acquire or possess similar capabilities. Rarity in BDA can be evaluated in two ways: proprietary data content and analytical capability developed through experience.\n\n# Imitating Big Data Analytics\n\nBDA can be difficult and costly for competitors to imitate due to factors like time investment, the uniqueness of proprietary algorithms, and the maturity and culture of a company's IT department.\n\n# Embedding Big Data Analytics\n\nThe final consideration is whether BDA can be organizationally embedded. It can be achieved when BDA aligns with the company's long-term business strategy and is facilitated by processes, policies, organizational structure, and corporate culture.\n\n# Creating Value from Big Data Analytics\n\nCreating strategic value with BDA requires investments in data assets, technological assets, and human talent. A conceptual framework can be proposed to describe how BDA creates strategic business value. This process can be framed by two concepts: Dynamic Capabilities and IT-Value Models. These models help in the capability building and capability realization processes.\n\n# Building Big Data Analytics Capabilities\n\nThe process of turning IT investments into valuable BDA capabilities is dynamic. It includes managing and analyzing data to generate new insights. For this, companies need to develop a BDA strategy and understand how it can create tangible and intangible value.\n\n# Realizing Big Data Analytics Capabilities\n\nThe real value of big data lies not in its volume but in the ability to derive meaningful and actionable insights from it. When utilized effectively, BDA can help refine business processes, develop initiatives, identify flaws or roadblocks, streamline supply chains, understand customers better, predict market trends, and develop new products, services, and business models.\n\nIn the end, creating value from BDA isn't just about having the right tools and capabilities. It's about using those capabilities to generate results, and then turning those results into actions that impact decision-making, improve customer relationships, enhance processes, and more.\n\nI share more articles like this in my blog. If you're interested, you can visit: https://ainsys.com/blog/2023/06/30/bda/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=data\\_engineering&amp;utm\\_content=BDA\\_analytics&amp;utm\\_term=BigData", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Leverage Big Data Analytics for Sustainable Competitive Advantage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w4sar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689019764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a seasoned IT architect currently working with a startup, I wanted to share my journey with you all, as well as some of the valuable insights I&amp;#39;ve discovered along the way. Here&amp;#39;s an article where I dive into how organizations can use BDA to establish a sustainable competitive advantage, and some of the strategies to effectively implement it. I hope you find this beneficial in your own journey as well.&lt;/p&gt;\n\n&lt;h1&gt;How to Leverage Big Data Analytics for Sustainable Competitive Advantage&lt;/h1&gt;\n\n&lt;p&gt;Today&amp;#39;s technological era generates a massive amount of data, and businesses everywhere are trying to turn this raw data into actionable insights. Big Data Analytics (BDA) has emerged as a key strategy, helping businesses gain unique insights to unlock new opportunities and differentiate from competitors. Ignoring BDA might leave you trailing behind in the competition, or missing out on potential advantages.&lt;/p&gt;\n\n&lt;p&gt;To achieve the strategic benefits of BDA, you need to understand the processes that allow it to add value and remain competitive. This article offers a guide on how businesses can use several frameworks to evaluate BDA\u2019s strategic value while avoiding pitfalls that come with improper implementation.&lt;/p&gt;\n\n&lt;p&gt;The VRIO framework (Valuable, Rare, Imitable, Organizationally embedded) can help assess the potential of BDA to create strategic business value. It prompts businesses to question if their BDA strategies offer valuable insights, are unique, challenging for competitors to copy, and supported by their organizational strategies and culture.&lt;/p&gt;\n\n&lt;h1&gt;Value of Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;The key strength of Big Data Analytics lies in its ability to provide unique insights that can be used to seize new business opportunities or counter competitive threats. These insights can improve various business areas, including business processes, product innovation, customer experience, and overall organizational performance.&lt;/p&gt;\n\n&lt;h1&gt;Uniqueness in Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;BDA becomes unique or &amp;#39;rare&amp;#39; when few competitors can acquire or possess similar capabilities. Rarity in BDA can be evaluated in two ways: proprietary data content and analytical capability developed through experience.&lt;/p&gt;\n\n&lt;h1&gt;Imitating Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;BDA can be difficult and costly for competitors to imitate due to factors like time investment, the uniqueness of proprietary algorithms, and the maturity and culture of a company&amp;#39;s IT department.&lt;/p&gt;\n\n&lt;h1&gt;Embedding Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;The final consideration is whether BDA can be organizationally embedded. It can be achieved when BDA aligns with the company&amp;#39;s long-term business strategy and is facilitated by processes, policies, organizational structure, and corporate culture.&lt;/p&gt;\n\n&lt;h1&gt;Creating Value from Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;Creating strategic value with BDA requires investments in data assets, technological assets, and human talent. A conceptual framework can be proposed to describe how BDA creates strategic business value. This process can be framed by two concepts: Dynamic Capabilities and IT-Value Models. These models help in the capability building and capability realization processes.&lt;/p&gt;\n\n&lt;h1&gt;Building Big Data Analytics Capabilities&lt;/h1&gt;\n\n&lt;p&gt;The process of turning IT investments into valuable BDA capabilities is dynamic. It includes managing and analyzing data to generate new insights. For this, companies need to develop a BDA strategy and understand how it can create tangible and intangible value.&lt;/p&gt;\n\n&lt;h1&gt;Realizing Big Data Analytics Capabilities&lt;/h1&gt;\n\n&lt;p&gt;The real value of big data lies not in its volume but in the ability to derive meaningful and actionable insights from it. When utilized effectively, BDA can help refine business processes, develop initiatives, identify flaws or roadblocks, streamline supply chains, understand customers better, predict market trends, and develop new products, services, and business models.&lt;/p&gt;\n\n&lt;p&gt;In the end, creating value from BDA isn&amp;#39;t just about having the right tools and capabilities. It&amp;#39;s about using those capabilities to generate results, and then turning those results into actions that impact decision-making, improve customer relationships, enhance processes, and more.&lt;/p&gt;\n\n&lt;p&gt;I share more articles like this in my blog. If you&amp;#39;re interested, you can visit: &lt;a href=\"https://ainsys.com/blog/2023/06/30/bda/?utm%5C_source=linkedin&amp;amp;utm%5C_medium=social&amp;amp;utm%5C_campaign=data%5C_engineering&amp;amp;utm%5C_content=BDA%5C_analytics&amp;amp;utm%5C_term=BigData\"&gt;https://ainsys.com/blog/2023/06/30/bda/?utm\\_source=linkedin&amp;amp;utm\\_medium=social&amp;amp;utm\\_campaign=data\\_engineering&amp;amp;utm\\_content=BDA\\_analytics&amp;amp;utm\\_term=BigData&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;s=8a29f85fd320507a70ec9694b971f494352d2655", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14w4sar", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w4sar/how_to_leverage_big_data_analytics_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w4sar/how_to_leverage_big_data_analytics_for/", "subreddit_subscribers": 115175, "created_utc": 1689019764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \nI'm building a CI/CD Pipeline for power bi. We have some reports which are not allowed to be exported by some users.\nI want to programmatically disable the export option of some table visual in some reports. I didn't find any API endpoint that does this operation. I also want to programmatically hide some pages in some reports during the deployment. Is there any way to achieve this?\n\nThanks in advance", "author_fullname": "t2_pp0zirow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power BI operation LS that are not supported by API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vttnt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688995073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nI&amp;#39;m building a CI/CD Pipeline for power bi. We have some reports which are not allowed to be exported by some users.\nI want to programmatically disable the export option of some table visual in some reports. I didn&amp;#39;t find any API endpoint that does this operation. I also want to programmatically hide some pages in some reports during the deployment. Is there any way to achieve this?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vttnt", "is_robot_indexable": true, "report_reasons": null, "author": "These_Rip_9327", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vttnt/power_bi_operation_ls_that_are_not_supported_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vttnt/power_bi_operation_ls_that_are_not_supported_by/", "subreddit_subscribers": 115175, "created_utc": 1688995073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the smoothest implementation of an ELT pipeline on the Azure stack (main db is azure sql server) using dbt?", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smooth implementation of dbt in Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vnzzx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688977770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the smoothest implementation of an ELT pipeline on the Azure stack (main db is azure sql server) using dbt?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vnzzx", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vnzzx/smooth_implementation_of_dbt_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vnzzx/smooth_implementation_of_dbt_in_azure/", "subreddit_subscribers": 115175, "created_utc": 1688977770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_d9bw4ufp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fluxsort: A stable quicksort, now faster than Timsort for both random and ordered data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14wkir3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1689061657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/scandum/fluxsort", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14wkir3", "is_robot_indexable": true, "report_reasons": null, "author": "codorace", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wkir3/fluxsort_a_stable_quicksort_now_faster_than/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/scandum/fluxsort", "subreddit_subscribers": 115175, "created_utc": 1689061657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/memphis-dev/comparing-message-queues-and-message-brokers-understanding-the-differences-dc776f0c3002](https://medium.com/memphis-dev/comparing-message-queues-and-message-brokers-understanding-the-differences-dc776f0c3002)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing Message Queues and Message Brokers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14wkbt4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689061041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/memphis-dev/comparing-message-queues-and-message-brokers-understanding-the-differences-dc776f0c3002\"&gt;https://medium.com/memphis-dev/comparing-message-queues-and-message-brokers-understanding-the-differences-dc776f0c3002&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/si-B8kO7y61sEKUmxwRcqcFmo4xdX1it6KOVn9uRjyg.jpg?auto=webp&amp;s=05e5274f6763ef54f47c90e9a9139eefcf7f96c1", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/si-B8kO7y61sEKUmxwRcqcFmo4xdX1it6KOVn9uRjyg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c66bb5d6f289aaa4629d3ddf18ab29add759813b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/si-B8kO7y61sEKUmxwRcqcFmo4xdX1it6KOVn9uRjyg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=99add557b3ca94101a0c851047bca446b051f396", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/si-B8kO7y61sEKUmxwRcqcFmo4xdX1it6KOVn9uRjyg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8608f8aecfb2bce3e784fb920aa9f9c1379cfdf6", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/si-B8kO7y61sEKUmxwRcqcFmo4xdX1it6KOVn9uRjyg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a41fe6babbb1108bfbaaa3007604c7b848a520a8", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/si-B8kO7y61sEKUmxwRcqcFmo4xdX1it6KOVn9uRjyg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c07458c67efc952a5847ea9b01fe98f67805754", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/si-B8kO7y61sEKUmxwRcqcFmo4xdX1it6KOVn9uRjyg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a9c2e1eb6b03be6c9c84621c2531440b32bc1e9c", "width": 1080, "height": 607}], "variants": {}, "id": "KvC5ciMsn2b2Ck171EgDFrsOxzv1I6g_BY1Dl8AO9CA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14wkbt4", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wkbt4/comparing_message_queues_and_message_brokers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wkbt4/comparing_message_queues_and_message_brokers/", "subreddit_subscribers": 115175, "created_utc": 1689061041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI'm developing an additional program for DE studies (without starting from scratch, project-based). I'm putting in quite a bit of work and considering whether to invest some resources in creating the course in my native language. There's an abundance of Data Science, ML, etc., courses available in my language, but none specifically focused on DE.\n\nI'm dedicating a significant amount of resources to program development (even though it's not financially advantageous, as I could be working for a company during this time), but I find it appealing.\n\nI always choose courses in English, but I can see that many people also prefer courses in their native language (sometimes it's easier to grasp difficult concepts that way). \n\nDo you think creating an online course in a language other than English makes sense? What should I be cautious about or pay attention to? Perhaps there are creators who would like to share their experience?", "author_fullname": "t2_7yv0lkcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating an Online Course in a Language Other Than English", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wiwjw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689056465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m developing an additional program for DE studies (without starting from scratch, project-based). I&amp;#39;m putting in quite a bit of work and considering whether to invest some resources in creating the course in my native language. There&amp;#39;s an abundance of Data Science, ML, etc., courses available in my language, but none specifically focused on DE.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m dedicating a significant amount of resources to program development (even though it&amp;#39;s not financially advantageous, as I could be working for a company during this time), but I find it appealing.&lt;/p&gt;\n\n&lt;p&gt;I always choose courses in English, but I can see that many people also prefer courses in their native language (sometimes it&amp;#39;s easier to grasp difficult concepts that way). &lt;/p&gt;\n\n&lt;p&gt;Do you think creating an online course in a language other than English makes sense? What should I be cautious about or pay attention to? Perhaps there are creators who would like to share their experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14wiwjw", "is_robot_indexable": true, "report_reasons": null, "author": "International-Shirt5", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wiwjw/creating_an_online_course_in_a_language_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wiwjw/creating_an_online_course_in_a_language_other/", "subreddit_subscribers": 115175, "created_utc": 1689056465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have four or five messy data sources which I am trying to match and merge. The resultant fields need to pass various validation rules. Some could be simple NULL/NOT NULL, some might be Regex, some might be enums, some might be conditional based on other field values. \n\nI am trying to find a methodical way to document these validation rules, such that they can be reused across various systems in future. \n\nHow have you all approached this in the past? Python snippets? SQL? What tools/libraries do you actually use to run the validations. Where do you store the rules for re-use?", "author_fullname": "t2_46gwj84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Codifying validation rules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wirv9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689056073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have four or five messy data sources which I am trying to match and merge. The resultant fields need to pass various validation rules. Some could be simple NULL/NOT NULL, some might be Regex, some might be enums, some might be conditional based on other field values. &lt;/p&gt;\n\n&lt;p&gt;I am trying to find a methodical way to document these validation rules, such that they can be reused across various systems in future. &lt;/p&gt;\n\n&lt;p&gt;How have you all approached this in the past? Python snippets? SQL? What tools/libraries do you actually use to run the validations. Where do you store the rules for re-use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14wirv9", "is_robot_indexable": true, "report_reasons": null, "author": "swanlooker", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wirv9/codifying_validation_rules/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wirv9/codifying_validation_rules/", "subreddit_subscribers": 115175, "created_utc": 1689056073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I didn't realize Delta UniForm was only 1-way directional, but now I feel like it is a lock-in trap. These format wars are just draining. I really hope Delta, Iceberg, Hudi can all get together on this new Onetable thing. Do you think they have a shot at unifying or will they always remain as translations?:\n\n[https://www.onehouse.ai/blog/the-road-to-an-open-and-interoperable-lakehouse](https://www.onehouse.ai/blog/the-road-to-an-open-and-interoperable-lakehouse)", "author_fullname": "t2_ep6emz0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Onetable and Delta Lake UniForm both going for Delta, Iceberg, Hudi interop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wffkb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689045905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I didn&amp;#39;t realize Delta UniForm was only 1-way directional, but now I feel like it is a lock-in trap. These format wars are just draining. I really hope Delta, Iceberg, Hudi can all get together on this new Onetable thing. Do you think they have a shot at unifying or will they always remain as translations?:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.onehouse.ai/blog/the-road-to-an-open-and-interoperable-lakehouse\"&gt;https://www.onehouse.ai/blog/the-road-to-an-open-and-interoperable-lakehouse&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WZwPXx_j1JOULe256V273352K0Z35MyOj4iISbDsUIM.jpg?auto=webp&amp;s=8c44247b539f81e5fcdd766ac1f5bcd861012b91", "width": 901, "height": 451}, "resolutions": [{"url": "https://external-preview.redd.it/WZwPXx_j1JOULe256V273352K0Z35MyOj4iISbDsUIM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=871a0b0ec338ad0ddee799f6f2a8d101cf445692", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/WZwPXx_j1JOULe256V273352K0Z35MyOj4iISbDsUIM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be3a35855f4f7e301798e2cf4a986cfa4a88045b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/WZwPXx_j1JOULe256V273352K0Z35MyOj4iISbDsUIM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=93218163a105e567b235d7319e8e1b1b8461ee70", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/WZwPXx_j1JOULe256V273352K0Z35MyOj4iISbDsUIM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=66c343abf47ada2d3517e291c4ccbddd27917360", "width": 640, "height": 320}], "variants": {}, "id": "2NkTbnp2vAc1Z26bE6VVkApb4nGJTX0V8FkgET_FimI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14wffkb", "is_robot_indexable": true, "report_reasons": null, "author": "InfamousPlan4992", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wffkb/onetable_and_delta_lake_uniform_both_going_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wffkb/onetable_and_delta_lake_uniform_both_going_for/", "subreddit_subscribers": 115175, "created_utc": 1689045905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data analyst learning how to be a data engineer. \n\nI've inherited a process that currently involves:\n\n1. Vendor sends a daily .csv file to an SFTP\n2. Alteryx is used to copy the file to our shared drive, run data transformations, and upload to snowflake. The file is deleted from the SFTP after a successful run in alteryx. \n\nThe process usually takes about 15 minutes daily, roughly 400k records each day. I would like to optimize this process and make it better and more secure. For example, I don't think storing files on a network share drive is smart. \n\nI have access to GCP resources such as cloud storage and cloud composer (airflow). I'm comfortable writing stored procedures and doing data transformations inside snowflake instead of alteryx. \n\nHow can I best optimize and create a data pipeline to utilize snowflake's compute resources for transformation and parallelism for ingestion? \n\nAny thoughts or ideas welcome as I'm very new to these concepts!", "author_fullname": "t2_ekec8wvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice: Setting up a data pipeline to ingest daily .csv files into snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w7r3g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689026235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst learning how to be a data engineer. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve inherited a process that currently involves:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Vendor sends a daily .csv file to an SFTP&lt;/li&gt;\n&lt;li&gt;Alteryx is used to copy the file to our shared drive, run data transformations, and upload to snowflake. The file is deleted from the SFTP after a successful run in alteryx. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The process usually takes about 15 minutes daily, roughly 400k records each day. I would like to optimize this process and make it better and more secure. For example, I don&amp;#39;t think storing files on a network share drive is smart. &lt;/p&gt;\n\n&lt;p&gt;I have access to GCP resources such as cloud storage and cloud composer (airflow). I&amp;#39;m comfortable writing stored procedures and doing data transformations inside snowflake instead of alteryx. &lt;/p&gt;\n\n&lt;p&gt;How can I best optimize and create a data pipeline to utilize snowflake&amp;#39;s compute resources for transformation and parallelism for ingestion? &lt;/p&gt;\n\n&lt;p&gt;Any thoughts or ideas welcome as I&amp;#39;m very new to these concepts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14w7r3g", "is_robot_indexable": true, "report_reasons": null, "author": "nightslikethese29", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w7r3g/need_advice_setting_up_a_data_pipeline_to_ingest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w7r3g/need_advice_setting_up_a_data_pipeline_to_ingest/", "subreddit_subscribers": 115175, "created_utc": 1689026235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_95ng5rz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turning Data into graphs/ visuals. Can someone help? I\u2019m recording chickens using various colored ramps, feeders, nipples, and balls for a school project to find out their color preference. Can someone point me to the right direction on how to turn this into a graph? Thanks :)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14w6xtj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hhuflwAk9Uppt7wXiszz7ybVX51JFjhsjhC4VqBqXuk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689024425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1r3r0h7sg7bb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1r3r0h7sg7bb1.jpg?auto=webp&amp;s=556cfe6296952dbd42e8eca758acb6f3697a591c", "width": 583, "height": 1825}, "resolutions": [{"url": "https://preview.redd.it/1r3r0h7sg7bb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=42647f83543656200c0fb2f1c024413b7d9030de", "width": 108, "height": 216}, {"url": "https://preview.redd.it/1r3r0h7sg7bb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9173a4cd47a4ea3ede67806c09d61ab3463c2d5", "width": 216, "height": 432}, {"url": "https://preview.redd.it/1r3r0h7sg7bb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=49cfdfa0d0c5c347cc71f265abfc1a6bcd75f52b", "width": 320, "height": 640}], "variants": {}, "id": "byGm1lvJpC90FTbcea0SKRStojf0CzI8_Gl1PD6hyck"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14w6xtj", "is_robot_indexable": true, "report_reasons": null, "author": "Blubberrloverr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w6xtj/turning_data_into_graphs_visuals_can_someone_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1r3r0h7sg7bb1.jpg", "subreddit_subscribers": 115175, "created_utc": 1689024425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6b0ljzqy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplify Airflow DAG Creation and Maintenance with Hamilton in 8 minutes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 46, "top_awarded_type": null, "hide_score": false, "name": "t3_14w24v5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GmnE_6tsLIFaYvicsxwEBRTCCw3zjyTde3OVC81k_5s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689013954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/simplify-airflow-dag-creation-and-maintenance-with-hamilton-in-8-minutes-e6e48c9c2cb0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?auto=webp&amp;s=6ea515e3823a63290fa133e4370c747b6a51e178", "width": 1200, "height": 399}, "resolutions": [{"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5cb91ccd2fd55f4aa3cc6838df133a4d221cfda2", "width": 108, "height": 35}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f85ddd6fd09b45e777bbc89df835d5b6b83e358", "width": 216, "height": 71}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=04dd770da3aee83f827888d757b3251f92963039", "width": 320, "height": 106}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b0959f60ca7f151c3c7abca240ed277e74bd60f3", "width": 640, "height": 212}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8e420ef4d3f8cb94ffd6a6ca001f96aebe8fb136", "width": 960, "height": 319}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8cce858ab6d3c59d6f33a4941209497b1f75f7d7", "width": 1080, "height": 359}], "variants": {}, "id": "lf_MmlWFw3vqWeN_S2r1zO1KVk616i_sXoaibmTLtYc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14w24v5", "is_robot_indexable": true, "report_reasons": null, "author": "theferalmonkey", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w24v5/simplify_airflow_dag_creation_and_maintenance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/simplify-airflow-dag-creation-and-maintenance-with-hamilton-in-8-minutes-e6e48c9c2cb0", "subreddit_subscribers": 115175, "created_utc": 1689013954.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}