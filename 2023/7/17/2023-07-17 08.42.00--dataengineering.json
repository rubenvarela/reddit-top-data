{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our data warehouse is a SQL Server. We\u2019ve been using Python to do a lot of scheduled ETL tasks. Currently I\u2019m executing the tasks on a schedule (10 minutes) using Windows Task Scheduler and batch files on the same Windows server as the SQL Server. \n\nIs there a better way to do this? I\u2019ve read that you can use stored procedures or scheduled events, but is that going to be faster? \n\nCurrently 85% of memory is allocated to SQL Server.\n\nAny pros or cons to consider?", "author_fullname": "t2_vgxtzjvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to execute Python scripts on a schedule?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151npp7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689556868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our data warehouse is a SQL Server. We\u2019ve been using Python to do a lot of scheduled ETL tasks. Currently I\u2019m executing the tasks on a schedule (10 minutes) using Windows Task Scheduler and batch files on the same Windows server as the SQL Server. &lt;/p&gt;\n\n&lt;p&gt;Is there a better way to do this? I\u2019ve read that you can use stored procedures or scheduled events, but is that going to be faster? &lt;/p&gt;\n\n&lt;p&gt;Currently 85% of memory is allocated to SQL Server.&lt;/p&gt;\n\n&lt;p&gt;Any pros or cons to consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151npp7", "is_robot_indexable": true, "report_reasons": null, "author": "BestTomatillo6197", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151npp7/best_way_to_execute_python_scripts_on_a_schedule/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151npp7/best_way_to_execute_python_scripts_on_a_schedule/", "subreddit_subscribers": 116247, "created_utc": 1689556868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Coming from a finance background, I've always been interested in trading &amp; investing.As I switch to tech and data for my career, I wanted to create my very first DE project that combines these two interests of mine:[https://github.com/hieuimba/stock-mkt-dashboard](https://github.com/hieuimba/stock-mkt-dashboard)\n\nI'm proud of how it turned out and I would appreciate any feedback &amp; improvement ideas!Also, where do I go from here? I want to get my hands on larger datasets and work with more complex tools so how do I expand given my existing stack?", "author_fullname": "t2_svuc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a Stock Market Dashboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151edrn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689554881.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689534039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Coming from a finance background, I&amp;#39;ve always been interested in trading &amp;amp; investing.As I switch to tech and data for my career, I wanted to create my very first DE project that combines these two interests of mine:&lt;a href=\"https://github.com/hieuimba/stock-mkt-dashboard\"&gt;https://github.com/hieuimba/stock-mkt-dashboard&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m proud of how it turned out and I would appreciate any feedback &amp;amp; improvement ideas!Also, where do I go from here? I want to get my hands on larger datasets and work with more complex tools so how do I expand given my existing stack?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?auto=webp&amp;s=32d077e612ecefd6faf10ea49e75e492c18e98d3", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf0640c9569bf292fd17f900ed87e5d01247c770", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4a5d75a477e23e1b71325c421978eed5394fc27", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c389594e29d6c8fbd46f916fb1406e207eb4d0f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cdc6b7a89dffc2df7f29e24167a2ce3e270c582d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f8e36aad8ae5756beed212dcaf5a0d7e7a898ac4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=29e5dbcd99562da33a9329007bf0412eeb2f40d5", "width": 1080, "height": 540}], "variants": {}, "id": "YdPea6g25mPIeHgw4yscB9-r1lXHQs-QhNTU3xR-x-U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "151edrn", "is_robot_indexable": true, "report_reasons": null, "author": "hieuimba", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151edrn/i_made_a_stock_market_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151edrn/i_made_a_stock_market_dashboard/", "subreddit_subscribers": 116247, "created_utc": 1689534039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, want to learn spark in a bit more detail with large datasets, till now I dabbled in few mb projects doing some exploratory analysis on community edition of databricks, looking for any project with huge dataset to actually learn what skewness in data mean and how to tune performance, any practical videos you know? Also anyway where I can play with huge datasets for free? AWS EMR and databricks seems to cost a lot for this.", "author_fullname": "t2_8fqzfba1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone know spark projects to work with &gt; 400 gb datasets and performance tuning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151nfbf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689556076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, want to learn spark in a bit more detail with large datasets, till now I dabbled in few mb projects doing some exploratory analysis on community edition of databricks, looking for any project with huge dataset to actually learn what skewness in data mean and how to tune performance, any practical videos you know? Also anyway where I can play with huge datasets for free? AWS EMR and databricks seems to cost a lot for this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151nfbf", "is_robot_indexable": true, "report_reasons": null, "author": "OptimistCherry", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151nfbf/anyone_know_spark_projects_to_work_with_400_gb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151nfbf/anyone_know_spark_projects_to_work_with_400_gb/", "subreddit_subscribers": 116247, "created_utc": 1689556076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Parquet is nice, but it does a bad job at compressing columns of numerical data. It's a real shame, since exabytes of data are written in Parquet and similar formats. I made a codec (https://github.com/mwlon/pcodec) that can be wrapped in as an \"encoder\" for better compression ratio at no cost to compression/decompression speed on average (compared to .zstd.parquet).\n\nI'm planning to test out a forked parquet using pcodec. Let me know if you're interested in collaborating.", "author_fullname": "t2_8cr1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone want to partake in making a cracked Parquet PoC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1518w59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1689520768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Parquet is nice, but it does a bad job at compressing columns of numerical data. It&amp;#39;s a real shame, since exabytes of data are written in Parquet and similar formats. I made a codec (&lt;a href=\"https://github.com/mwlon/pcodec\"&gt;https://github.com/mwlon/pcodec&lt;/a&gt;) that can be wrapped in as an &amp;quot;encoder&amp;quot; for better compression ratio at no cost to compression/decompression speed on average (compared to .zstd.parquet).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to test out a forked parquet using pcodec. Let me know if you&amp;#39;re interested in collaborating.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?auto=webp&amp;s=f4c89ce9020fabae5f3ac29418814bbd2f43707d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce66a1c7eb60b7356b7dd936aab79c12038ea2a5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a80230e483befadad4615e656f64d81fe2b7b5b4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31f65fb7f25f8a78b0831efa2326fbaa38721716", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=29d5192a1e1140906d55278403b0dcc460437819", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a62f960c516ced9fcbefeabcea340137cb006c6", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ba13edf9bbe1c1095e31bfbd7c24c2444b977cb5", "width": 1080, "height": 540}], "variants": {}, "id": "-gqh9jkdtisE1lLOccWycdvX2Md7OQ7SBxrc6mgpImQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1518w59", "is_robot_indexable": true, "report_reasons": null, "author": "mwlon", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1518w59/anyone_want_to_partake_in_making_a_cracked/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1518w59/anyone_want_to_partake_in_making_a_cracked/", "subreddit_subscribers": 116247, "created_utc": 1689520768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everybody,\n\nI\u2019m making a POC  using Airbyte as a spun a VM in GCP.\n\nI noticed a lot of connectors were alpha or beta. How robust is the tool? Has anyone been using it in a Fortune 500 company?", "author_fullname": "t2_851if4wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte in Production - Robust?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1510pua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689495814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m making a POC  using Airbyte as a spun a VM in GCP.&lt;/p&gt;\n\n&lt;p&gt;I noticed a lot of connectors were alpha or beta. How robust is the tool? Has anyone been using it in a Fortune 500 company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1510pua", "is_robot_indexable": true, "report_reasons": null, "author": "No-Dress-3160", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1510pua/airbyte_in_production_robust/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1510pua/airbyte_in_production_robust/", "subreddit_subscribers": 116247, "created_utc": 1689495814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, Reddit!\n\nI wanted to share my Python package called finqual that I've been working on for the past few months. It's designed to simplify your financial analysis by providing easy access to income statements, balance sheets, and cash flow information for the majority of ticker's listed on the NASDAQ or NYSE by using the SEC's data.\n\n**Features:**\n\n* Call income statements, balance sheets, or cash flow statements for the majority of companies\n* Retrieve both annual and quarterly financial statements for a specified period\n* Easily see essential financial ratios for a chosen ticker, enabling you to assess liquidity, profitability, and valuation metrics with ease.\n* Retrieve comparable companies for a chosen ticker based on SIC codes\n* Tailored balance sheet specifically for banks and other financial services firms\n* Fast calls of up to 10 requests per second\n* No call restrictions whatsoever\n\nYou can find my PyPi package here which contains more information on how to use it: [https://pypi.org/project/finqual/](https://pypi.org/project/finqual/)\n\nAnd install it with:\n\n    pip install finqual\n\n**Why have I made this?**\n\nAs someone who's interested in financial analysis and Python programming, I was interested in collating fundamental data for stocks and doing analysis on them. However, I found that the majority of free providers have a limited rate call, or an upper limit call amount for a certain time frame (usually a day).\n\n**Disclaimer**\n\nThis is my first Python project and my first time using PyPI, and it is **still very much in development**! Some of the data won't be entirely accurate, this is due to the way that the SEC's data is set-up and how each company has their own individual taxonomy. I have done my best over the past few months to create a hierarchical tree that can generalize most companies well, but this is by no means perfect.\n\nThere is definitely still work to be done, and I will be making updates when I have the time.\n\nIt would be great to get your feedback and thoughts on this!\n\nThanks!", "author_fullname": "t2_m6eev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "finqual: Python project to simplify fundamental financial research with SEC data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151ly9j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689552764.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689552187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, Reddit!&lt;/p&gt;\n\n&lt;p&gt;I wanted to share my Python package called finqual that I&amp;#39;ve been working on for the past few months. It&amp;#39;s designed to simplify your financial analysis by providing easy access to income statements, balance sheets, and cash flow information for the majority of ticker&amp;#39;s listed on the NASDAQ or NYSE by using the SEC&amp;#39;s data.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Call income statements, balance sheets, or cash flow statements for the majority of companies&lt;/li&gt;\n&lt;li&gt;Retrieve both annual and quarterly financial statements for a specified period&lt;/li&gt;\n&lt;li&gt;Easily see essential financial ratios for a chosen ticker, enabling you to assess liquidity, profitability, and valuation metrics with ease.&lt;/li&gt;\n&lt;li&gt;Retrieve comparable companies for a chosen ticker based on SIC codes&lt;/li&gt;\n&lt;li&gt;Tailored balance sheet specifically for banks and other financial services firms&lt;/li&gt;\n&lt;li&gt;Fast calls of up to 10 requests per second&lt;/li&gt;\n&lt;li&gt;No call restrictions whatsoever&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can find my PyPi package here which contains more information on how to use it: &lt;a href=\"https://pypi.org/project/finqual/\"&gt;https://pypi.org/project/finqual/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And install it with:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pip install finqual\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;Why have I made this?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;As someone who&amp;#39;s interested in financial analysis and Python programming, I was interested in collating fundamental data for stocks and doing analysis on them. However, I found that the majority of free providers have a limited rate call, or an upper limit call amount for a certain time frame (usually a day).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This is my first Python project and my first time using PyPI, and it is &lt;strong&gt;still very much in development&lt;/strong&gt;! Some of the data won&amp;#39;t be entirely accurate, this is due to the way that the SEC&amp;#39;s data is set-up and how each company has their own individual taxonomy. I have done my best over the past few months to create a hierarchical tree that can generalize most companies well, but this is by no means perfect.&lt;/p&gt;\n\n&lt;p&gt;There is definitely still work to be done, and I will be making updates when I have the time.&lt;/p&gt;\n\n&lt;p&gt;It would be great to get your feedback and thoughts on this!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;s=27b6869059bde930b8fa91e163c4a5b593a62755", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=967712caa32aa48e894a0097548ea87ec67be18c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a3c7948dff53aae03712fb7d592fa1bbddccbb4", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "151ly9j", "is_robot_indexable": true, "report_reasons": null, "author": "Myztika", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151ly9j/finqual_python_project_to_simplify_fundamental/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151ly9j/finqual_python_project_to_simplify_fundamental/", "subreddit_subscribers": 116247, "created_utc": 1689552187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nWorking on my first data warehouse project and learning online on the way using tutorials, articles, youtube videos etc.\n\nI'm using data meant to mimic an OLTP database for a dvd rental company, and I'm at the stage of implementing my dimension and fact tables.\n\nThe fact table I'm currently building out is an inventory table - I want it to be a snapshot every month of a dvd's stock, including how many dvd were lost that month,  and some other aggregates.\n\nOne thing I can't wrap my head around though is how to implement a date dimension - currently none of my other attributes capture a timestamp that can facilitate this.\n\nand tutorials online don't really go into the details of how to build a snapshot fact table so that i can define the grain as 'week', 'month' etc.\n\nI don't understand how my fact table can make a reference to a date dimension if my other dimensions don't contain a date attribute?\n\nI'm attaching a photo of my model below in case it helps paint a better picture.\n\nhttps://preview.redd.it/f957h9t15ecb1.png?width=1376&amp;format=png&amp;auto=webp&amp;s=17ffdf934ba9650196211d46ee299cf8ac86d18b", "author_fullname": "t2_96memylv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing date dimensions in DW?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"f957h9t15ecb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f653e959cba54e99034391e2444e5caab395a4cf"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3e263c73d2f0610e787959c47eab940664d0e63"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=51f9057f8f4fcee89d3d165dca32bc6c5f5d3d85"}, {"y": 357, "x": 640, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d952cbd2c1e560a63910b0a2adab488e1737369"}, {"y": 536, "x": 960, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=16528a31ec7ffaea7819e1ec9d69fba7dd8cc6f8"}, {"y": 603, "x": 1080, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0b0d59a181be5a125704636c5ec03f0e279cd858"}], "s": {"y": 769, "x": 1376, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=1376&amp;format=png&amp;auto=webp&amp;s=17ffdf934ba9650196211d46ee299cf8ac86d18b"}, "id": "f957h9t15ecb1"}}, "name": "t3_151he4d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/QdvyJoHkIcWkwy3lTWvsN9hZspFQJsSMiBH3tcpdrU8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689541032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Working on my first data warehouse project and learning online on the way using tutorials, articles, youtube videos etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using data meant to mimic an OLTP database for a dvd rental company, and I&amp;#39;m at the stage of implementing my dimension and fact tables.&lt;/p&gt;\n\n&lt;p&gt;The fact table I&amp;#39;m currently building out is an inventory table - I want it to be a snapshot every month of a dvd&amp;#39;s stock, including how many dvd were lost that month,  and some other aggregates.&lt;/p&gt;\n\n&lt;p&gt;One thing I can&amp;#39;t wrap my head around though is how to implement a date dimension - currently none of my other attributes capture a timestamp that can facilitate this.&lt;/p&gt;\n\n&lt;p&gt;and tutorials online don&amp;#39;t really go into the details of how to build a snapshot fact table so that i can define the grain as &amp;#39;week&amp;#39;, &amp;#39;month&amp;#39; etc.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t understand how my fact table can make a reference to a date dimension if my other dimensions don&amp;#39;t contain a date attribute?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m attaching a photo of my model below in case it helps paint a better picture.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/f957h9t15ecb1.png?width=1376&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17ffdf934ba9650196211d46ee299cf8ac86d18b\"&gt;https://preview.redd.it/f957h9t15ecb1.png?width=1376&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17ffdf934ba9650196211d46ee299cf8ac86d18b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151he4d", "is_robot_indexable": true, "report_reasons": null, "author": "jazzopardi203", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151he4d/implementing_date_dimensions_in_dw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151he4d/implementing_date_dimensions_in_dw/", "subreddit_subscribers": 116247, "created_utc": 1689541032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doing a practice fun project to learn DE. I can obtain a dataset from Kaggle by downloading it. But I wanted to know if there's a way to get it from API?\n\n\nAlternatively, any way to learn how to API pull data to SQL server, azure, BigQuery etc? I have all of them. Learning databases now.", "author_fullname": "t2_vnan4h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there an API to retrieve data from Kaggle for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151g1t2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689537923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doing a practice fun project to learn DE. I can obtain a dataset from Kaggle by downloading it. But I wanted to know if there&amp;#39;s a way to get it from API?&lt;/p&gt;\n\n&lt;p&gt;Alternatively, any way to learn how to API pull data to SQL server, azure, BigQuery etc? I have all of them. Learning databases now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151g1t2", "is_robot_indexable": true, "report_reasons": null, "author": "Analyst2163", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151g1t2/is_there_an_api_to_retrieve_data_from_kaggle_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151g1t2/is_there_an_api_to_retrieve_data_from_kaggle_for/", "subreddit_subscribers": 116247, "created_utc": 1689537923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've noticed a scary trend lately in this sub where every now and then someone pops out fearing for the future of this career or how we'll be replaced by AI. I know anecdotal evidence is crap, but at least I haven't seen a lower demand of dataengs, I can still find a decent number of job postings requesting dataengs for companies. Am I missing something? What's going on? I can understand that companies are demanding experienced dataengs, but for real, this field was never meant for newly grads.", "author_fullname": "t2_4cvl041d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "META: What's with the doomposting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_151uv83", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689578738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed a scary trend lately in this sub where every now and then someone pops out fearing for the future of this career or how we&amp;#39;ll be replaced by AI. I know anecdotal evidence is crap, but at least I haven&amp;#39;t seen a lower demand of dataengs, I can still find a decent number of job postings requesting dataengs for companies. Am I missing something? What&amp;#39;s going on? I can understand that companies are demanding experienced dataengs, but for real, this field was never meant for newly grads.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151uv83", "is_robot_indexable": true, "report_reasons": null, "author": "FlowOfAir", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151uv83/meta_whats_with_the_doomposting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151uv83/meta_whats_with_the_doomposting/", "subreddit_subscribers": 116247, "created_utc": 1689578738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have connected our ADF pipelines with Purview but the complete lineage is not being shown in Purview. We are able to see the flow from Stage to Interim but not from Interim to Target.", "author_fullname": "t2_3pvqv38j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft Purview not showing complete lineage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151s5fb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689570006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have connected our ADF pipelines with Purview but the complete lineage is not being shown in Purview. We are able to see the flow from Stage to Interim but not from Interim to Target.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151s5fb", "is_robot_indexable": true, "report_reasons": null, "author": "Dev-98", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151s5fb/microsoft_purview_not_showing_complete_lineage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151s5fb/microsoft_purview_not_showing_complete_lineage/", "subreddit_subscribers": 116247, "created_utc": 1689570006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello I had a question.\nI was thinking of going into data analytics/science field  and I was wondering what do you all think that field will look like in 5-10 years given the fast growth of AI.. will it dominate the field or it wont be a competition? I really wanted to get some points from insiders on what you think about the matter. Thank you so much anything helps.", "author_fullname": "t2_5uy3w8w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future of this career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151ri7k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689567974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello I had a question.\nI was thinking of going into data analytics/science field  and I was wondering what do you all think that field will look like in 5-10 years given the fast growth of AI.. will it dominate the field or it wont be a competition? I really wanted to get some points from insiders on what you think about the matter. Thank you so much anything helps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "151ri7k", "is_robot_indexable": true, "report_reasons": null, "author": "Vano1Kingdom", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151ri7k/future_of_this_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151ri7k/future_of_this_career/", "subreddit_subscribers": 116247, "created_utc": 1689567974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nOur small team has just finished the data preparation phase of our project and started data analysis in Databricks. As we go deeper into this field, we're trying to understand the distinctions and appropriate uses for a Feature Store versus a Data Catalog. On the surface, it seems to me that both are ways to manage and use tables of data.\n\nFor example, let's consider a churn prediction. We need to create a table (or several) for churn prediction and join later, which would include multiple features that could potentially influence a user's possibility to churn. It appears to me that we could just create a new table in a Data Catalog with this information. However, I am not sure if this is the right approach or if a Feature Store could be more suitable.\n\nHere are my questions\n\n1. In what situations would we prefer to use a Feature Store over a Data Catalog, or vice versa?\n2. In the context of our Churn Prediction example, would it be more beneficial to use a Feature Store? If so, why?\n3. If we were to use a Feature Store in this scenario, what would that look like in terms of setup and workflow?\n\nReally appreciate every help, ideally, any examples would be great. I'm very noob using Databricks, and a real-world approach would be very very helpful.\n\nThanks for the help in advance.", "author_fullname": "t2_akunr53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Differences between Feature Store and Data Catalog in Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_151v5uw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689579758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Our small team has just finished the data preparation phase of our project and started data analysis in Databricks. As we go deeper into this field, we&amp;#39;re trying to understand the distinctions and appropriate uses for a Feature Store versus a Data Catalog. On the surface, it seems to me that both are ways to manage and use tables of data.&lt;/p&gt;\n\n&lt;p&gt;For example, let&amp;#39;s consider a churn prediction. We need to create a table (or several) for churn prediction and join later, which would include multiple features that could potentially influence a user&amp;#39;s possibility to churn. It appears to me that we could just create a new table in a Data Catalog with this information. However, I am not sure if this is the right approach or if a Feature Store could be more suitable.&lt;/p&gt;\n\n&lt;p&gt;Here are my questions&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;In what situations would we prefer to use a Feature Store over a Data Catalog, or vice versa?&lt;/li&gt;\n&lt;li&gt;In the context of our Churn Prediction example, would it be more beneficial to use a Feature Store? If so, why?&lt;/li&gt;\n&lt;li&gt;If we were to use a Feature Store in this scenario, what would that look like in terms of setup and workflow?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Really appreciate every help, ideally, any examples would be great. I&amp;#39;m very noob using Databricks, and a real-world approach would be very very helpful.&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151v5uw", "is_robot_indexable": true, "report_reasons": null, "author": "north_pr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151v5uw/differences_between_feature_store_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151v5uw/differences_between_feature_store_and_data/", "subreddit_subscribers": 116247, "created_utc": 1689579758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team uses dbt and would like to share the documentation created with other teams in our company. Those teams don't have access to our dbt. \n\nI'm trying to figure out a way to do this that is private - only people with the link can access it. I looked into github pages but did not like that a github page is pretty easy to guess the url for. We don't have enterprise Github. \n\nWould the best option be to pay for Netlify?", "author_fullname": "t2_capkx7wn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to surface dbt docs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_151utkk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689578575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team uses dbt and would like to share the documentation created with other teams in our company. Those teams don&amp;#39;t have access to our dbt. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out a way to do this that is private - only people with the link can access it. I looked into github pages but did not like that a github page is pretty easy to guess the url for. We don&amp;#39;t have enterprise Github. &lt;/p&gt;\n\n&lt;p&gt;Would the best option be to pay for Netlify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151utkk", "is_robot_indexable": true, "report_reasons": null, "author": "Wide-Pop6050", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151utkk/best_way_to_surface_dbt_docs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151utkk/best_way_to_surface_dbt_docs/", "subreddit_subscribers": 116247, "created_utc": 1689578575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in a startup company where we develop games. My CEO has asked me to store our company data. Previously, we used to store that data in Dropbox. However, as the team is growing, we want to store the data in the cloud. Since I am familiar with AWS, I suggested storing the data there. Being new to this field, I would like to know how to store the data for approximately 20 apps, as we develop new apps every month and approximately how much does it cost? I aim to store the data so that only my CEO can access it. ", "author_fullname": "t2_a6qkcbp6y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help to store data in AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151t77t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689573377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a startup company where we develop games. My CEO has asked me to store our company data. Previously, we used to store that data in Dropbox. However, as the team is growing, we want to store the data in the cloud. Since I am familiar with AWS, I suggested storing the data there. Being new to this field, I would like to know how to store the data for approximately 20 apps, as we develop new apps every month and approximately how much does it cost? I aim to store the data so that only my CEO can access it. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151t77t", "is_robot_indexable": true, "report_reasons": null, "author": "Haunting-Canary-417", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151t77t/need_help_to_store_data_in_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151t77t/need_help_to_store_data_in_aws/", "subreddit_subscribers": 116247, "created_utc": 1689573377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that it\u2019s just a job and I should just take the pay check and do my 9-5, but I\u2019m starting to despise my non technical teammates and managers. I\u2019ve had to make all design decisions and train new hires when it comes to data. My manager does not have the technical knowledge to offer any advice or plan any forward looking strategy, when there are tons of opportunities to modernize our stack.\n\nLooking for advice from folks who\u2019s been in similar situations on ways to navigate being the only technical person supporting the entire data infrastructure of the company. How do I make the best out of my situation until I leave? Thanks!", "author_fullname": "t2_sslx78ms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to not hate your job when you\u2019re the only DE supporting a non-tech company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151svfk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689572320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that it\u2019s just a job and I should just take the pay check and do my 9-5, but I\u2019m starting to despise my non technical teammates and managers. I\u2019ve had to make all design decisions and train new hires when it comes to data. My manager does not have the technical knowledge to offer any advice or plan any forward looking strategy, when there are tons of opportunities to modernize our stack.&lt;/p&gt;\n\n&lt;p&gt;Looking for advice from folks who\u2019s been in similar situations on ways to navigate being the only technical person supporting the entire data infrastructure of the company. How do I make the best out of my situation until I leave? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "151svfk", "is_robot_indexable": true, "report_reasons": null, "author": "jadedorca", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151svfk/how_to_not_hate_your_job_when_youre_the_only_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151svfk/how_to_not_hate_your_job_when_youre_the_only_de/", "subreddit_subscribers": 116247, "created_utc": 1689572320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nAs you read it from title, I have an interview round ( which is 2nd round ) on designing the data pipelines. The interviewer told me, there wont be any live coding round, but we would design a data pipeline. Can you please help with your experience on what all should we be prepared? Any resources will help me a lot\n\nThanks in advance :)", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Interview] Data pipeline design round", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151s5ki", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689570019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;As you read it from title, I have an interview round ( which is 2nd round ) on designing the data pipelines. The interviewer told me, there wont be any live coding round, but we would design a data pipeline. Can you please help with your experience on what all should we be prepared? Any resources will help me a lot&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "151s5ki", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/151s5ki/interview_data_pipeline_design_round/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151s5ki/interview_data_pipeline_design_round/", "subreddit_subscribers": 116247, "created_utc": 1689570019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Two of the top Data warehousing vendors held summits. Both these summits happened at the same time a few weeks ago. \n\nWho went?  Why did you pick one vs the other?  What were the highlights to you?\n\nhttps://www.databricks.com/dataaisummit/\n\nhttps://www.snowflake.com/summit/livestream/", "author_fullname": "t2_jt2s1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "People who went to Snowflake Summit or Databricks Summit: what did you learn and Why did you pick one vs the other?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151qzhy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689566417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Two of the top Data warehousing vendors held summits. Both these summits happened at the same time a few weeks ago. &lt;/p&gt;\n\n&lt;p&gt;Who went?  Why did you pick one vs the other?  What were the highlights to you?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/dataaisummit/\"&gt;https://www.databricks.com/dataaisummit/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.snowflake.com/summit/livestream/\"&gt;https://www.snowflake.com/summit/livestream/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151qzhy", "is_robot_indexable": true, "report_reasons": null, "author": "haragoshi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151qzhy/people_who_went_to_snowflake_summit_or_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151qzhy/people_who_went_to_snowflake_summit_or_databricks/", "subreddit_subscribers": 116247, "created_utc": 1689566417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thought I'd post this here for review to see if others see obvious flaws or better approaches.\n\nThe larger context is this store is internal to another more complex store that has specific needs for it's permanent storage.\n\nKeys are always integers.  Values are fixed length byte arrays.  Efficiency matters but volume is fairly low 10k reads/writes second  at most.  This would be using SSD volumes dedicated for this data.\n\nOther off the shelf stores tend to have caveats.  LSM tends to scale poorly with larger data sets, and most other stores just have a lot of overhead and complexity around stuff I don't need.\n\nThe basic file format is a file is assigned a key range.  And the start of the file contains an array covering the entire range.  Each array index contains a 1 byte flag and a 4 byte value containing the block index into the actual data.\n\nThe data area starts immediately after the index array and is variable.  It's comprised of fixed length blocks that are sized in a multiple of the disk block size.\n\nInserts are just appended into the data area.  Compaction is fairly straight forward move active blocks from the end to unused blocks. Implementation probably not important so won't cover that.\n\nAllocating the index up front will always have wasted space in the file with the highest key range.  But it's a flexible design that allows for arbitrary ranges and merging files if needed.  I'm ok with the amount of wasted space here since it's relatively small.\n\nAn insert will append to the data area and return the write offset.  That is then written into the index.  An update will seek/read the index and then seek/write into the value area.\n\nReading is two seeks/reads.", "author_fullname": "t2_16rrd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Key/value store design for integer keys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151d8m7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689531306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thought I&amp;#39;d post this here for review to see if others see obvious flaws or better approaches.&lt;/p&gt;\n\n&lt;p&gt;The larger context is this store is internal to another more complex store that has specific needs for it&amp;#39;s permanent storage.&lt;/p&gt;\n\n&lt;p&gt;Keys are always integers.  Values are fixed length byte arrays.  Efficiency matters but volume is fairly low 10k reads/writes second  at most.  This would be using SSD volumes dedicated for this data.&lt;/p&gt;\n\n&lt;p&gt;Other off the shelf stores tend to have caveats.  LSM tends to scale poorly with larger data sets, and most other stores just have a lot of overhead and complexity around stuff I don&amp;#39;t need.&lt;/p&gt;\n\n&lt;p&gt;The basic file format is a file is assigned a key range.  And the start of the file contains an array covering the entire range.  Each array index contains a 1 byte flag and a 4 byte value containing the block index into the actual data.&lt;/p&gt;\n\n&lt;p&gt;The data area starts immediately after the index array and is variable.  It&amp;#39;s comprised of fixed length blocks that are sized in a multiple of the disk block size.&lt;/p&gt;\n\n&lt;p&gt;Inserts are just appended into the data area.  Compaction is fairly straight forward move active blocks from the end to unused blocks. Implementation probably not important so won&amp;#39;t cover that.&lt;/p&gt;\n\n&lt;p&gt;Allocating the index up front will always have wasted space in the file with the highest key range.  But it&amp;#39;s a flexible design that allows for arbitrary ranges and merging files if needed.  I&amp;#39;m ok with the amount of wasted space here since it&amp;#39;s relatively small.&lt;/p&gt;\n\n&lt;p&gt;An insert will append to the data area and return the write offset.  That is then written into the index.  An update will seek/read the index and then seek/write into the value area.&lt;/p&gt;\n\n&lt;p&gt;Reading is two seeks/reads.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151d8m7", "is_robot_indexable": true, "report_reasons": null, "author": "chris_ochs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151d8m7/keyvalue_store_design_for_integer_keys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151d8m7/keyvalue_store_design_for_integer_keys/", "subreddit_subscribers": 116247, "created_utc": 1689531306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm working on a project that involves storing a large combolist in a database and implementing efficient search functionality for user email addresses within the combolist. The combolist can scale to tens of gigabytes and include billions of entries, and I want to achieve the lowest search time possible.\n\nA combolist in cybersecurity terms is a collection of leaked credentials that comes in email,password pairs and it comes in this form:\n\n\\`email:password\\`\n\nIn short; I'm trying to implement a functionality similar to websites like [haveibeenpwned.com](https://haveibeenpwned.com/) and [dehashed.com](https://dehashed.com/) where a user can lookup if their email has been leaked in a data breach.\n\nWhat is the approach that I should follow here?", "author_fullname": "t2_1djg5mwi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing a functionality similar to haveibeenpwned.com", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151bfxc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689527042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project that involves storing a large combolist in a database and implementing efficient search functionality for user email addresses within the combolist. The combolist can scale to tens of gigabytes and include billions of entries, and I want to achieve the lowest search time possible.&lt;/p&gt;\n\n&lt;p&gt;A combolist in cybersecurity terms is a collection of leaked credentials that comes in email,password pairs and it comes in this form:&lt;/p&gt;\n\n&lt;p&gt;`email:password`&lt;/p&gt;\n\n&lt;p&gt;In short; I&amp;#39;m trying to implement a functionality similar to websites like &lt;a href=\"https://haveibeenpwned.com/\"&gt;haveibeenpwned.com&lt;/a&gt; and &lt;a href=\"https://dehashed.com/\"&gt;dehashed.com&lt;/a&gt; where a user can lookup if their email has been leaked in a data breach.&lt;/p&gt;\n\n&lt;p&gt;What is the approach that I should follow here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JgoK2vb5F1tWOtLBG355-_1fZe6mAd2sv-z81pzUg-E.jpg?auto=webp&amp;s=422b5268c714145f80b9ccb3aad3a035e0aeaa67", "width": 290, "height": 290}, "resolutions": [{"url": "https://external-preview.redd.it/JgoK2vb5F1tWOtLBG355-_1fZe6mAd2sv-z81pzUg-E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=88d9bb65039d93063c545092ebc2f6fa400c1752", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/JgoK2vb5F1tWOtLBG355-_1fZe6mAd2sv-z81pzUg-E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fca8a9ea885a67f855560950fa48b0114ecbb076", "width": 216, "height": 216}], "variants": {}, "id": "RLxH_r3XdD8c_M4b_l_4b30RHRm83xODkzcXGu8dSsM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151bfxc", "is_robot_indexable": true, "report_reasons": null, "author": "leShawarmaMan", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151bfxc/implementing_a_functionality_similar_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151bfxc/implementing_a_functionality_similar_to/", "subreddit_subscribers": 116247, "created_utc": 1689527042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's a simple project I have a data as hudi table in s3 partitioned on year month day \nWant to create a iceberg table of out of it partitioned on field capturedate Nd save it on another s3 bucket \nI'm using aws glue \n\nI have tried multiple ways even last resort chatgpt also failed \nI donnot have the permission to use the iceberg connector from aws market place pls suggest how to solve and an example links anything is welcomed need to submit tomorrow my job is a stake, I'm new to DE so encountering problems \n\nIf push come to shove I'll get aws connector bit if you can suggest all the possible ways with or without connector as well is welcomed !!!! \nPls help \n\nThanks in advance \nI'll ans if anyone has any queries \n\n\nThanks !!!!", "author_fullname": "t2_arz03l52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Neeed help with a project pls !!!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1519m26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689522572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a simple project I have a data as hudi table in s3 partitioned on year month day \nWant to create a iceberg table of out of it partitioned on field capturedate Nd save it on another s3 bucket \nI&amp;#39;m using aws glue &lt;/p&gt;\n\n&lt;p&gt;I have tried multiple ways even last resort chatgpt also failed \nI donnot have the permission to use the iceberg connector from aws market place pls suggest how to solve and an example links anything is welcomed need to submit tomorrow my job is a stake, I&amp;#39;m new to DE so encountering problems &lt;/p&gt;\n\n&lt;p&gt;If push come to shove I&amp;#39;ll get aws connector bit if you can suggest all the possible ways with or without connector as well is welcomed !!!! \nPls help &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance \nI&amp;#39;ll ans if anyone has any queries &lt;/p&gt;\n\n&lt;p&gt;Thanks !!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1519m26", "is_robot_indexable": true, "report_reasons": null, "author": "sam-sinister", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1519m26/neeed_help_with_a_project_pls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1519m26/neeed_help_with_a_project_pls/", "subreddit_subscribers": 116247, "created_utc": 1689522572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3gguq8q9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Profession Is Celebrated More By Society? A Data-Driven Dive into Madame Tussaud\u2019s", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1516mcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1689514940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "aazar.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://aazar.me/post/which-profession-is-celebrated-more-by-society", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1516mcp", "is_robot_indexable": true, "report_reasons": null, "author": "44za12", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1516mcp/which_profession_is_celebrated_more_by_society_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://aazar.me/post/which-profession-is-celebrated-more-by-society", "subreddit_subscribers": 116247, "created_utc": 1689514940.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}