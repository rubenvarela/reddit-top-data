{"kind": "Listing", "data": {"after": "t3_151yksz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few days ago, our data scientist gave me some of his SQL code to put in production.  I quickly glanced over it -- it was neat and tidy, well formatted, organised and filled with helpful comments.  \"Shouldn't be a big deal.  Give me a few days to review it.\"\n\nI looked at it more closely today and realised it's actually mess.  Badly written, inefficient, breaks the DRY approach repeatedly, doesn't comply with naming standards, the lot.  I get back to the guy and ask him to explain some of the SQL statements because they're confusing to me. He admits that a lot of it was actually written by ChatGPT and he isn't sure what it's doing.  But he politely asks me when will his code be put into production, thank you very much?\n\nYou have code that you can't actually explain *as the developer yourself* but you still expect it to be put in production?\n\nI tell him a need a bit more time.  And he cheerfully tells me that he'll be happy to do it himself *if I'd just give him admin access to production.*", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists -- Ok, now I get it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151xsis", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 337, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 337, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689588707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few days ago, our data scientist gave me some of his SQL code to put in production.  I quickly glanced over it -- it was neat and tidy, well formatted, organised and filled with helpful comments.  &amp;quot;Shouldn&amp;#39;t be a big deal.  Give me a few days to review it.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I looked at it more closely today and realised it&amp;#39;s actually mess.  Badly written, inefficient, breaks the DRY approach repeatedly, doesn&amp;#39;t comply with naming standards, the lot.  I get back to the guy and ask him to explain some of the SQL statements because they&amp;#39;re confusing to me. He admits that a lot of it was actually written by ChatGPT and he isn&amp;#39;t sure what it&amp;#39;s doing.  But he politely asks me when will his code be put into production, thank you very much?&lt;/p&gt;\n\n&lt;p&gt;You have code that you can&amp;#39;t actually explain &lt;em&gt;as the developer yourself&lt;/em&gt; but you still expect it to be put in production?&lt;/p&gt;\n\n&lt;p&gt;I tell him a need a bit more time.  And he cheerfully tells me that he&amp;#39;ll be happy to do it himself &lt;em&gt;if I&amp;#39;d just give him admin access to production.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151xsis", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 133, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151xsis/data_scientists_ok_now_i_get_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151xsis/data_scientists_ok_now_i_get_it/", "subreddit_subscribers": 116398, "created_utc": 1689588707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our data warehouse is a SQL Server. We\u2019ve been using Python to do a lot of scheduled ETL tasks. Currently I\u2019m executing the tasks on a schedule (10 minutes) using Windows Task Scheduler and batch files on the same Windows server as the SQL Server. \n\nIs there a better way to do this? I\u2019ve read that you can use stored procedures or scheduled events, but is that going to be faster? \n\nCurrently 85% of memory is allocated to SQL Server.\n\nAny pros or cons to consider?", "author_fullname": "t2_vgxtzjvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to execute Python scripts on a schedule?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151npp7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689556868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our data warehouse is a SQL Server. We\u2019ve been using Python to do a lot of scheduled ETL tasks. Currently I\u2019m executing the tasks on a schedule (10 minutes) using Windows Task Scheduler and batch files on the same Windows server as the SQL Server. &lt;/p&gt;\n\n&lt;p&gt;Is there a better way to do this? I\u2019ve read that you can use stored procedures or scheduled events, but is that going to be faster? &lt;/p&gt;\n\n&lt;p&gt;Currently 85% of memory is allocated to SQL Server.&lt;/p&gt;\n\n&lt;p&gt;Any pros or cons to consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151npp7", "is_robot_indexable": true, "report_reasons": null, "author": "BestTomatillo6197", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151npp7/best_way_to_execute_python_scripts_on_a_schedule/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151npp7/best_way_to_execute_python_scripts_on_a_schedule/", "subreddit_subscribers": 116398, "created_utc": 1689556868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is interested in having a no code platform so that we can democratize data access and mitigate shitty practices like shared drive hoarding. We are looking at Palantir but it's absurdly expensive. I've never really dabbled with \"tools\" like that because I've never come across something truly no code that worked well.\n\nCurious if anyone here has used Palantir's Foundry or other tools that give non technical users a place to search and see data exists, do their data manipulation, exploration and then visualization on both tabular and time series data.", "author_fullname": "t2_c10zsd9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best no-code platforms you have come across?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151yrep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689591732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is interested in having a no code platform so that we can democratize data access and mitigate shitty practices like shared drive hoarding. We are looking at Palantir but it&amp;#39;s absurdly expensive. I&amp;#39;ve never really dabbled with &amp;quot;tools&amp;quot; like that because I&amp;#39;ve never come across something truly no code that worked well.&lt;/p&gt;\n\n&lt;p&gt;Curious if anyone here has used Palantir&amp;#39;s Foundry or other tools that give non technical users a place to search and see data exists, do their data manipulation, exploration and then visualization on both tabular and time series data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151yrep", "is_robot_indexable": true, "report_reasons": null, "author": "EmoryCadet", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151yrep/what_are_the_best_nocode_platforms_you_have_come/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151yrep/what_are_the_best_nocode_platforms_you_have_come/", "subreddit_subscribers": 116398, "created_utc": 1689591732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, want to learn spark in a bit more detail with large datasets, till now I dabbled in few mb projects doing some exploratory analysis on community edition of databricks, looking for any project with huge dataset to actually learn what skewness in data mean and how to tune performance, any practical videos you know? Also anyway where I can play with huge datasets for free? AWS EMR and databricks seems to cost a lot for this.", "author_fullname": "t2_8fqzfba1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone know spark projects to work with &gt; 400 gb datasets and performance tuning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151nfbf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689556076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, want to learn spark in a bit more detail with large datasets, till now I dabbled in few mb projects doing some exploratory analysis on community edition of databricks, looking for any project with huge dataset to actually learn what skewness in data mean and how to tune performance, any practical videos you know? Also anyway where I can play with huge datasets for free? AWS EMR and databricks seems to cost a lot for this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151nfbf", "is_robot_indexable": true, "report_reasons": null, "author": "OptimistCherry", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151nfbf/anyone_know_spark_projects_to_work_with_400_gb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151nfbf/anyone_know_spark_projects_to_work_with_400_gb/", "subreddit_subscribers": 116398, "created_utc": 1689556076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've noticed a scary trend lately in this sub where every now and then someone pops out fearing for the future of this career or how we'll be replaced by AI. I know anecdotal evidence is crap, but at least I haven't seen a lower demand of dataengs, I can still find a decent number of job postings requesting dataengs for companies. Am I missing something? What's going on? I can understand that companies are demanding experienced dataengs, but for real, this field was never meant for newly grads.", "author_fullname": "t2_4cvl041d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "META: What's with the doomposting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151uv83", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689578738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed a scary trend lately in this sub where every now and then someone pops out fearing for the future of this career or how we&amp;#39;ll be replaced by AI. I know anecdotal evidence is crap, but at least I haven&amp;#39;t seen a lower demand of dataengs, I can still find a decent number of job postings requesting dataengs for companies. Am I missing something? What&amp;#39;s going on? I can understand that companies are demanding experienced dataengs, but for real, this field was never meant for newly grads.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151uv83", "is_robot_indexable": true, "report_reasons": null, "author": "FlowOfAir", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151uv83/meta_whats_with_the_doomposting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151uv83/meta_whats_with_the_doomposting/", "subreddit_subscribers": 116398, "created_utc": 1689578738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that it\u2019s just a job and I should just take the pay check and do my 9-5, but I\u2019m starting to despise my non technical teammates and managers. I\u2019ve had to make all design decisions and train new hires when it comes to data. My manager does not have the technical knowledge to offer any advice or plan any forward looking strategy, when there are tons of opportunities to modernize our stack.\n\nLooking for advice from folks who\u2019s been in similar situations on ways to navigate being the only technical person supporting the entire data infrastructure of the company. How do I make the best out of my situation until I leave? Thanks!", "author_fullname": "t2_sslx78ms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to not hate your job when you\u2019re the only DE supporting a non-tech company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151svfk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689572320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that it\u2019s just a job and I should just take the pay check and do my 9-5, but I\u2019m starting to despise my non technical teammates and managers. I\u2019ve had to make all design decisions and train new hires when it comes to data. My manager does not have the technical knowledge to offer any advice or plan any forward looking strategy, when there are tons of opportunities to modernize our stack.&lt;/p&gt;\n\n&lt;p&gt;Looking for advice from folks who\u2019s been in similar situations on ways to navigate being the only technical person supporting the entire data infrastructure of the company. How do I make the best out of my situation until I leave? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "151svfk", "is_robot_indexable": true, "report_reasons": null, "author": "jadedorca", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151svfk/how_to_not_hate_your_job_when_youre_the_only_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151svfk/how_to_not_hate_your_job_when_youre_the_only_de/", "subreddit_subscribers": 116398, "created_utc": 1689572320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nOur small team has just finished the data preparation phase of our project and started data analysis in Databricks. As we go deeper into this field, we're trying to understand the distinctions and appropriate uses for a Feature Store versus a Data Catalog. On the surface, it seems to me that both are ways to manage and use tables of data.\n\nFor example, let's consider a churn prediction. We need to create a table (or several) for churn prediction and join later, which would include multiple features that could potentially influence a user's possibility to churn. It appears to me that we could just create a new table in a Data Catalog with this information. However, I am not sure if this is the right approach or if a Feature Store could be more suitable.\n\nHere are my questions\n\n1. In what situations would we prefer to use a Feature Store over a Data Catalog, or vice versa?\n2. In the context of our Churn Prediction example, would it be more beneficial to use a Feature Store? If so, why?\n3. If we were to use a Feature Store in this scenario, what would that look like in terms of setup and workflow?\n\nReally appreciate every help, ideally, any examples would be great. I'm very noob using Databricks, and a real-world approach would be very very helpful.\n\nThanks for the help in advance.", "author_fullname": "t2_akunr53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Differences between Feature Store and Data Catalog in Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151v5uw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689579758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Our small team has just finished the data preparation phase of our project and started data analysis in Databricks. As we go deeper into this field, we&amp;#39;re trying to understand the distinctions and appropriate uses for a Feature Store versus a Data Catalog. On the surface, it seems to me that both are ways to manage and use tables of data.&lt;/p&gt;\n\n&lt;p&gt;For example, let&amp;#39;s consider a churn prediction. We need to create a table (or several) for churn prediction and join later, which would include multiple features that could potentially influence a user&amp;#39;s possibility to churn. It appears to me that we could just create a new table in a Data Catalog with this information. However, I am not sure if this is the right approach or if a Feature Store could be more suitable.&lt;/p&gt;\n\n&lt;p&gt;Here are my questions&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;In what situations would we prefer to use a Feature Store over a Data Catalog, or vice versa?&lt;/li&gt;\n&lt;li&gt;In the context of our Churn Prediction example, would it be more beneficial to use a Feature Store? If so, why?&lt;/li&gt;\n&lt;li&gt;If we were to use a Feature Store in this scenario, what would that look like in terms of setup and workflow?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Really appreciate every help, ideally, any examples would be great. I&amp;#39;m very noob using Databricks, and a real-world approach would be very very helpful.&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151v5uw", "is_robot_indexable": true, "report_reasons": null, "author": "north_pr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151v5uw/differences_between_feature_store_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151v5uw/differences_between_feature_store_and_data/", "subreddit_subscribers": 116398, "created_utc": 1689579758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, Reddit!\n\nI wanted to share my Python package called finqual that I've been working on for the past few months. It's designed to simplify your financial analysis by providing easy access to income statements, balance sheets, and cash flow information for the majority of ticker's listed on the NASDAQ or NYSE by using the SEC's data.\n\n**Features:**\n\n* Call income statements, balance sheets, or cash flow statements for the majority of companies\n* Retrieve both annual and quarterly financial statements for a specified period\n* Easily see essential financial ratios for a chosen ticker, enabling you to assess liquidity, profitability, and valuation metrics with ease.\n* Retrieve comparable companies for a chosen ticker based on SIC codes\n* Tailored balance sheet specifically for banks and other financial services firms\n* Fast calls of up to 10 requests per second\n* No call restrictions whatsoever\n\nYou can find my PyPi package here which contains more information on how to use it: [https://pypi.org/project/finqual/](https://pypi.org/project/finqual/)\n\nAnd install it with:\n\n    pip install finqual\n\n**Why have I made this?**\n\nAs someone who's interested in financial analysis and Python programming, I was interested in collating fundamental data for stocks and doing analysis on them. However, I found that the majority of free providers have a limited rate call, or an upper limit call amount for a certain time frame (usually a day).\n\n**Disclaimer**\n\nThis is my first Python project and my first time using PyPI, and it is **still very much in development**! Some of the data won't be entirely accurate, this is due to the way that the SEC's data is set-up and how each company has their own individual taxonomy. I have done my best over the past few months to create a hierarchical tree that can generalize most companies well, but this is by no means perfect.\n\nThere is definitely still work to be done, and I will be making updates when I have the time.\n\nIt would be great to get your feedback and thoughts on this!\n\nThanks!", "author_fullname": "t2_m6eev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "finqual: Python project to simplify fundamental financial research with SEC data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151ly9j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689552764.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689552187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, Reddit!&lt;/p&gt;\n\n&lt;p&gt;I wanted to share my Python package called finqual that I&amp;#39;ve been working on for the past few months. It&amp;#39;s designed to simplify your financial analysis by providing easy access to income statements, balance sheets, and cash flow information for the majority of ticker&amp;#39;s listed on the NASDAQ or NYSE by using the SEC&amp;#39;s data.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Call income statements, balance sheets, or cash flow statements for the majority of companies&lt;/li&gt;\n&lt;li&gt;Retrieve both annual and quarterly financial statements for a specified period&lt;/li&gt;\n&lt;li&gt;Easily see essential financial ratios for a chosen ticker, enabling you to assess liquidity, profitability, and valuation metrics with ease.&lt;/li&gt;\n&lt;li&gt;Retrieve comparable companies for a chosen ticker based on SIC codes&lt;/li&gt;\n&lt;li&gt;Tailored balance sheet specifically for banks and other financial services firms&lt;/li&gt;\n&lt;li&gt;Fast calls of up to 10 requests per second&lt;/li&gt;\n&lt;li&gt;No call restrictions whatsoever&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can find my PyPi package here which contains more information on how to use it: &lt;a href=\"https://pypi.org/project/finqual/\"&gt;https://pypi.org/project/finqual/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And install it with:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pip install finqual\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;Why have I made this?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;As someone who&amp;#39;s interested in financial analysis and Python programming, I was interested in collating fundamental data for stocks and doing analysis on them. However, I found that the majority of free providers have a limited rate call, or an upper limit call amount for a certain time frame (usually a day).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This is my first Python project and my first time using PyPI, and it is &lt;strong&gt;still very much in development&lt;/strong&gt;! Some of the data won&amp;#39;t be entirely accurate, this is due to the way that the SEC&amp;#39;s data is set-up and how each company has their own individual taxonomy. I have done my best over the past few months to create a hierarchical tree that can generalize most companies well, but this is by no means perfect.&lt;/p&gt;\n\n&lt;p&gt;There is definitely still work to be done, and I will be making updates when I have the time.&lt;/p&gt;\n\n&lt;p&gt;It would be great to get your feedback and thoughts on this!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;s=27b6869059bde930b8fa91e163c4a5b593a62755", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=967712caa32aa48e894a0097548ea87ec67be18c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a3c7948dff53aae03712fb7d592fa1bbddccbb4", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "151ly9j", "is_robot_indexable": true, "report_reasons": null, "author": "Myztika", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151ly9j/finqual_python_project_to_simplify_fundamental/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151ly9j/finqual_python_project_to_simplify_fundamental/", "subreddit_subscribers": 116398, "created_utc": 1689552187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?", "author_fullname": "t2_c532a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What steps to take after first role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1524trd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689607060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1524trd", "is_robot_indexable": true, "report_reasons": null, "author": "gators939", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "subreddit_subscribers": 116398, "created_utc": 1689607060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team uses dbt and would like to share the documentation created with other teams in our company. Those teams don't have access to our dbt. \n\nI'm trying to figure out a way to do this that is private - only people with the link can access it. I looked into github pages but did not like that a github page is pretty easy to guess the url for. We don't have enterprise Github. \n\nWould the best option be to pay for Netlify?", "author_fullname": "t2_capkx7wn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to surface dbt docs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151utkk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689578575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team uses dbt and would like to share the documentation created with other teams in our company. Those teams don&amp;#39;t have access to our dbt. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out a way to do this that is private - only people with the link can access it. I looked into github pages but did not like that a github page is pretty easy to guess the url for. We don&amp;#39;t have enterprise Github. &lt;/p&gt;\n\n&lt;p&gt;Would the best option be to pay for Netlify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151utkk", "is_robot_indexable": true, "report_reasons": null, "author": "Wide-Pop6050", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151utkk/best_way_to_surface_dbt_docs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151utkk/best_way_to_surface_dbt_docs/", "subreddit_subscribers": 116398, "created_utc": 1689578575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone inviting you to join our Hackathon!!  \nIn this hackathon, you are going to create a wildfire early warning system for the fictional island nation of Zakar. Zakar has been struggling with wildfires in the last few years. \n\nThe best project will get the perfect gaming package!\n\nfor more info - [Save Zakar Hackathon](https://medium.com/memphis-dev/you-have-a-chance-to-save-the-world-d789dcd55f87)\n\n[Sign up](https://www.hackathon.memphis.dev/)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time Data and AI using open source tools Hackathon!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1520dzi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689596371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone inviting you to join our Hackathon!!&lt;br/&gt;\nIn this hackathon, you are going to create a wildfire early warning system for the fictional island nation of Zakar. Zakar has been struggling with wildfires in the last few years. &lt;/p&gt;\n\n&lt;p&gt;The best project will get the perfect gaming package!&lt;/p&gt;\n\n&lt;p&gt;for more info - &lt;a href=\"https://medium.com/memphis-dev/you-have-a-chance-to-save-the-world-d789dcd55f87\"&gt;Save Zakar Hackathon&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.hackathon.memphis.dev/\"&gt;Sign up&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?auto=webp&amp;s=e410859561599d680b0aab559597ce32e4d8c6f3", "width": 1200, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ffad9c57fc8cd00aa80bce283c5f0a08db3c968c", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e25613eaa09a34d2ec37a6fffb5d7321a2424cd", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=125279964d45a8bc6fd9a8be6353524433b7c684", "width": 320, "height": 96}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a013995f51636b54e30590c6423546b212a21538", "width": 640, "height": 192}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5601c7067416e834d46c0aaa2ad77eff38d9964f", "width": 960, "height": 288}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=075957b9f1cbc341c510b446761005e7e3b4a919", "width": 1080, "height": 324}], "variants": {}, "id": "FG0dihaZdabzhgCH3l_ddvb59OmQJlKMVavnIZV_W2c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1520dzi", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1520dzi/realtime_data_and_ai_using_open_source_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1520dzi/realtime_data_and_ai_using_open_source_tools/", "subreddit_subscribers": 116398, "created_utc": 1689596371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey guys,\nWe have a table in delta format where we have enabled schema evolution. \nLets consider a table having column X which is struct and have multi level nested keys. \n\nE.g. - X.Y.Z.A\n\nNow, Databricks is trying to convert Z to struct, I want it to convert it to String\nZ has 10k keys. \n\nHow do we solve for this?\n\nWe\u2019re following this approach:\n1. get ddl for table \n2. recreate the table with schema of Z as string.", "author_fullname": "t2_3dsjwu75", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is best way to change existing schema in delta[Databricks]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151voz1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689581588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys,\nWe have a table in delta format where we have enabled schema evolution. \nLets consider a table having column X which is struct and have multi level nested keys. &lt;/p&gt;\n\n&lt;p&gt;E.g. - X.Y.Z.A&lt;/p&gt;\n\n&lt;p&gt;Now, Databricks is trying to convert Z to struct, I want it to convert it to String\nZ has 10k keys. &lt;/p&gt;\n\n&lt;p&gt;How do we solve for this?&lt;/p&gt;\n\n&lt;p&gt;We\u2019re following this approach:\n1. get ddl for table \n2. recreate the table with schema of Z as string.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151voz1", "is_robot_indexable": true, "report_reasons": null, "author": "mannu_11", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151voz1/what_is_best_way_to_change_existing_schema_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151voz1/what_is_best_way_to_change_existing_schema_in/", "subreddit_subscribers": 116398, "created_utc": 1689581588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have connected our ADF pipelines with Purview but the complete lineage is not being shown in Purview. We are able to see the flow from Stage to Interim but not from Interim to Target.", "author_fullname": "t2_3pvqv38j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft Purview not showing complete lineage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151s5fb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689570006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have connected our ADF pipelines with Purview but the complete lineage is not being shown in Purview. We are able to see the flow from Stage to Interim but not from Interim to Target.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151s5fb", "is_robot_indexable": true, "report_reasons": null, "author": "Dev-98", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151s5fb/microsoft_purview_not_showing_complete_lineage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151s5fb/microsoft_purview_not_showing_complete_lineage/", "subreddit_subscribers": 116398, "created_utc": 1689570006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would like to find some questions practicing for DE interview. I mostly use leetcode to practice DSA, and leetcode have multiple tags like 'array', 'binary tree' when I want to practice specific topics.\n\nHowever, there seems no similar tag for SQL problems on leetcode. I believe SQL have various type of questions, and I want to practice specific topics (join, aggregation, window function...etc) not wondering around and look at all kinds of problems.\n\nIs there any website that may have specific topics to practice SQL questions?  \nOr more specifically, SQL practicing websites for DE interview?  \n\n\nThanks a lot!", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there SQL questions practice website with specific topics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15226ql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689600967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to find some questions practicing for DE interview. I mostly use leetcode to practice DSA, and leetcode have multiple tags like &amp;#39;array&amp;#39;, &amp;#39;binary tree&amp;#39; when I want to practice specific topics.&lt;/p&gt;\n\n&lt;p&gt;However, there seems no similar tag for SQL problems on leetcode. I believe SQL have various type of questions, and I want to practice specific topics (join, aggregation, window function...etc) not wondering around and look at all kinds of problems.&lt;/p&gt;\n\n&lt;p&gt;Is there any website that may have specific topics to practice SQL questions?&lt;br/&gt;\nOr more specifically, SQL practicing websites for DE interview?  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15226ql", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15226ql/is_there_sql_questions_practice_website_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15226ql/is_there_sql_questions_practice_website_with/", "subreddit_subscribers": 116398, "created_utc": 1689600967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm one of the co-founders of Vertis.\n\nIn my previous role as a data engineer, I saw the daily challenges our analytics teams were facing in orchestrating, deploying and monitoring SQL pipelines.\n\nMost existing tools have a steep learning curve and often require ongoing engineering support. That's why we built Vertis. Our solution allows you to orchestrate SQL pipelines in a simple, intuitive way - all without any extra configuration, no special syntax to learn, and no infrastructure to manage.\n\nVertis offers an all-in-one platform, with features such as:\n\nGitHub Integration, logging and alerting, interactive dependency graph, and more!\n\nYou can learn more about Vertis and request early access here: [https://www.vertis.app](https://www.vertis.app/)\n\nWe're excited to share Vertis with you today, and we would appreciate your thoughts and feedback. I'll be here to answer any questions you might have.", "author_fullname": "t2_33shg0e8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The simplest way to orchestrate SQL data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152d4j2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689625944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m one of the co-founders of Vertis.&lt;/p&gt;\n\n&lt;p&gt;In my previous role as a data engineer, I saw the daily challenges our analytics teams were facing in orchestrating, deploying and monitoring SQL pipelines.&lt;/p&gt;\n\n&lt;p&gt;Most existing tools have a steep learning curve and often require ongoing engineering support. That&amp;#39;s why we built Vertis. Our solution allows you to orchestrate SQL pipelines in a simple, intuitive way - all without any extra configuration, no special syntax to learn, and no infrastructure to manage.&lt;/p&gt;\n\n&lt;p&gt;Vertis offers an all-in-one platform, with features such as:&lt;/p&gt;\n\n&lt;p&gt;GitHub Integration, logging and alerting, interactive dependency graph, and more!&lt;/p&gt;\n\n&lt;p&gt;You can learn more about Vertis and request early access here: &lt;a href=\"https://www.vertis.app/\"&gt;https://www.vertis.app&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re excited to share Vertis with you today, and we would appreciate your thoughts and feedback. I&amp;#39;ll be here to answer any questions you might have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "152d4j2", "is_robot_indexable": true, "report_reasons": null, "author": "WildShallot", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152d4j2/the_simplest_way_to_orchestrate_sql_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152d4j2/the_simplest_way_to_orchestrate_sql_data_pipelines/", "subreddit_subscribers": 116398, "created_utc": 1689625944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking of building such a tool that can\n\n\\- Aggregate all pipeline status on one page\n\n\\- Manage notifications for different systems\n\n\\- Unify incident reports\n\nI did some research only to find a 3 yo post. [https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline\\_monitoring\\_tool/](https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/)\n\nI'm wondering if there's existing tools doing this / if not, anyone has the need?", "author_fullname": "t2_6mmm3ywiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unified pipeline monitoring tool / all-in-one pipeline status page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152cldb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689624752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking of building such a tool that can&lt;/p&gt;\n\n&lt;p&gt;- Aggregate all pipeline status on one page&lt;/p&gt;\n\n&lt;p&gt;- Manage notifications for different systems&lt;/p&gt;\n\n&lt;p&gt;- Unify incident reports&lt;/p&gt;\n\n&lt;p&gt;I did some research only to find a 3 yo post. &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/\"&gt;https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if there&amp;#39;s existing tools doing this / if not, anyone has the need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152cldb", "is_robot_indexable": true, "report_reasons": null, "author": "WEI3M", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "subreddit_subscribers": 116398, "created_utc": 1689624752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to data engineering, and I like to learn by trying/building. I am very unclear what's the best way to go about it?\n\nMy ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?", "author_fullname": "t2_17d42esw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best \"free\" set-up to learn or try to build a data pipeline on my own?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152c49r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689623684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to data engineering, and I like to learn by trying/building. I am very unclear what&amp;#39;s the best way to go about it?&lt;/p&gt;\n\n&lt;p&gt;My ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152c49r", "is_robot_indexable": true, "report_reasons": null, "author": "Guyserbun007", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "subreddit_subscribers": 116398, "created_utc": 1689623684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bjg5ils96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not able to import bacpac files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1527uzc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Dh76q4CwJ1SwBvLTA5RKMdR6EwYsGVSToIYMeI51cbg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689613964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/6uixe56s5kcb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?auto=webp&amp;s=8f45aeb19cdac07b77aab83bcad493c06602fcca", "width": 1170, "height": 1507}, "resolutions": [{"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c7fddd296c024f9cc353830f149646145fd6506", "width": 108, "height": 139}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2fca7e3564f79bfe9d184d9e02734adfe7391b2", "width": 216, "height": 278}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99e838e6735aed7f783edd82c6d3475bbcb88e66", "width": 320, "height": 412}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0a7d0ed4822daaa7f6e3904d371d9da830fed104", "width": 640, "height": 824}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=70fd648c800e959184a369600afc9df1c58b8d70", "width": 960, "height": 1236}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77ff354d6f918e3477f9db4463a754a9d09dbf22", "width": 1080, "height": 1391}], "variants": {}, "id": "BITAYyr-5eJpEGr2vz0o2pzOZo9Rhxgw06bDn2nRxFc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1527uzc", "is_robot_indexable": true, "report_reasons": null, "author": "Ecstatic-Cat-5830", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1527uzc/not_able_to_import_bacpac_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/6uixe56s5kcb1.jpg", "subreddit_subscribers": 116398, "created_utc": 1689613964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9uiwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you really need exactly-once delivery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15270yt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nwqg-bA9yKtkh-5nBchWxMPm0l24EuljbLUBOPM3qYc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689612063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "streamingdata.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?auto=webp&amp;s=04d6977076f8d968368d6533d4d93bcc4e03f4d3", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=febf87d18ab938c89253d5e7d0697e337bf0e88e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c37da59f1936c995870386de473bad9a4a0c1260", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a059a8e1f66d01ae2eb0b0a1b4572e8187739f1a", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e139e12aa841bac14920bb64d92f70324e0d70d0", "width": 640, "height": 333}], "variants": {}, "id": "TL5zSeeNMw6fBGF0Ca693DL1GL7baDPqZ8ZyarYmuos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15270yt", "is_robot_indexable": true, "report_reasons": null, "author": "sap1enz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15270yt/do_you_really_need_exactlyonce_delivery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "subreddit_subscribers": 116398, "created_utc": 1689612063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a [retrieval-augmented generation](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html) use case (a.k.a. chat with your data).\n\n&amp;#x200B;\n\nMy current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like [https://www.chaindesk.ai/](https://www.chaindesk.ai/) but they feel a bit too limiting for my use case.", "author_fullname": "t2_2s6nwgck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move semi-structured data to LLMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1526j16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689610913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a &lt;a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html\"&gt;retrieval-augmented generation&lt;/a&gt; use case (a.k.a. chat with your data).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like &lt;a href=\"https://www.chaindesk.ai/\"&gt;https://www.chaindesk.ai/&lt;/a&gt; but they feel a bit too limiting for my use case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1526j16", "is_robot_indexable": true, "report_reasons": null, "author": "shrifbot", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "subreddit_subscribers": 116398, "created_utc": 1689610913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4t6cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM based pipelines with PostgresML and dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_1525yyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z3TI0arYlw4RRR3jUUbPUO2vA2egarxlpp1dP09FXtE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689609669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "postgresml.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?auto=webp&amp;s=0b690342c0b9264e580cd8629721f878d18ff954", "width": 784, "height": 519}, "resolutions": [{"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf6a365fbb7793932f29fbb28fa434d479b46d55", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0effd2b3a0537c8131fd28109ff37439457f1ddc", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d160cb4efab6957e3d11789882fe0b658cafe87e", "width": 320, "height": 211}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e154f104eedac0bc7c9e36c987df586978c19eb0", "width": 640, "height": 423}], "variants": {}, "id": "dxDnyB5RtYkyN-bX3C7E2eUqvQzE9_-FZU6xkZ1aDRQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1525yyl", "is_robot_indexable": true, "report_reasons": null, "author": "something_cleverer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525yyl/llm_based_pipelines_with_postgresml_and_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "subreddit_subscribers": 116398, "created_utc": 1689609669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse - event data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1525pib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689609082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1525pib", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525pib/lakehouse_event_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1525pib/lakehouse_event_data/", "subreddit_subscribers": 116398, "created_utc": 1689609082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my company which is a startup is hiring web scrapers to scrape data(financial data) from the websites, and load into S3 and as usual it goes to the database.\nWill this even going to work?", "author_fullname": "t2_es0ctl93", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is web scraping even an authentic data source to move forward with?or buying the data/API worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1520xun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689597849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my company which is a startup is hiring web scrapers to scrape data(financial data) from the websites, and load into S3 and as usual it goes to the database.\nWill this even going to work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1520xun", "is_robot_indexable": true, "report_reasons": null, "author": "Grand-Knowledge-4044", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1520xun/is_web_scraping_even_an_authentic_data_source_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1520xun/is_web_scraping_even_an_authentic_data_source_to/", "subreddit_subscribers": 116398, "created_utc": 1689597849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to help my wife switch her domains. she is currently a FTE at infosys with \\~6 years experience in the IT Services domain. She spent 5 years at IBM before joining Infy in same project.\n\nShe has extensive onsite experience where she worked with IBM Australia with Westpac back.\n\nAs expected, she has stagnated massively and will become completely disconnected with tech if she continues in these companies. One rather seamless switch that we feel she can pursue is moving to Snowflake platform and pursuing a career in either dev or as an analyst.\n\nShe has been following tuts from multiple resources and aiming a certification as well, but lack of enough hands-on experience is making her nervous and preventing her from focussing on studies.\n\nGiven the current market situation, job opportunities are not easy either.\n\nHow can she explore internal switch within Infy to pursue Snowflake? Otherwise, how can she overall pursue this switch? We are f9 with her taking up contract positions as well as long as she gets to work on Snowflake.", "author_fullname": "t2_11mmk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "snowflake employment help for my wife", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1520p8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689597208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to help my wife switch her domains. she is currently a FTE at infosys with ~6 years experience in the IT Services domain. She spent 5 years at IBM before joining Infy in same project.&lt;/p&gt;\n\n&lt;p&gt;She has extensive onsite experience where she worked with IBM Australia with Westpac back.&lt;/p&gt;\n\n&lt;p&gt;As expected, she has stagnated massively and will become completely disconnected with tech if she continues in these companies. One rather seamless switch that we feel she can pursue is moving to Snowflake platform and pursuing a career in either dev or as an analyst.&lt;/p&gt;\n\n&lt;p&gt;She has been following tuts from multiple resources and aiming a certification as well, but lack of enough hands-on experience is making her nervous and preventing her from focussing on studies.&lt;/p&gt;\n\n&lt;p&gt;Given the current market situation, job opportunities are not easy either.&lt;/p&gt;\n\n&lt;p&gt;How can she explore internal switch within Infy to pursue Snowflake? Otherwise, how can she overall pursue this switch? We are f9 with her taking up contract positions as well as long as she gets to work on Snowflake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1520p8f", "is_robot_indexable": true, "report_reasons": null, "author": "Pbd1194", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1520p8f/snowflake_employment_help_for_my_wife/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1520p8f/snowflake_employment_help_for_my_wife/", "subreddit_subscribers": 116398, "created_utc": 1689597208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello, everyone!\n\nI am currently working on a project to build an ETL (Extract, Transform, Load) pipeline, and I would greatly appreciate some advice and guidance from the Reddit community.\n\nHere's a brief overview of the project: I am tasked with downloading data from an AWS S3 bucket, performing transformations using Pyspark, and loading the transformed data into a Postgres database. This is my first project of this nature, and I need to schedule this task to run automatically on a weekly basis.\n\nOne specific challenge I am facing is the need to compare the last six months of data in the S3 bucket with the data already present in the Postgres database. If any changes are detected in the S3 data, I need to overwrite the corresponding data in the Postgres database. The amount of data can range between 15-20 GB.\n\nI am currently using Pyspark for data transformations, but I would appreciate any recommendations or best practices on efficiently comparing and updating the data between S3 and Postgres.\n\nAdditionally, I am in the process of selecting a suitable tool for scheduling and managing ETL tasks. I have set up Airflow, but I am uncertain whether it is the best fit for this project. I would love to hear your thoughts and experiences with scheduling ETL tasks, particularly for a scenario like mine.\n\nThank you in advance for any advice, suggestions, or insights you can provide. I am eager to learn from your expertise and make this ETL pipeline project a success!", "author_fullname": "t2_fjuwxuxxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on Building an ETL Pipeline with AWS S3, Postgres, and Pyspark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151yksz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689591190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, everyone!&lt;/p&gt;\n\n&lt;p&gt;I am currently working on a project to build an ETL (Extract, Transform, Load) pipeline, and I would greatly appreciate some advice and guidance from the Reddit community.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a brief overview of the project: I am tasked with downloading data from an AWS S3 bucket, performing transformations using Pyspark, and loading the transformed data into a Postgres database. This is my first project of this nature, and I need to schedule this task to run automatically on a weekly basis.&lt;/p&gt;\n\n&lt;p&gt;One specific challenge I am facing is the need to compare the last six months of data in the S3 bucket with the data already present in the Postgres database. If any changes are detected in the S3 data, I need to overwrite the corresponding data in the Postgres database. The amount of data can range between 15-20 GB.&lt;/p&gt;\n\n&lt;p&gt;I am currently using Pyspark for data transformations, but I would appreciate any recommendations or best practices on efficiently comparing and updating the data between S3 and Postgres.&lt;/p&gt;\n\n&lt;p&gt;Additionally, I am in the process of selecting a suitable tool for scheduling and managing ETL tasks. I have set up Airflow, but I am uncertain whether it is the best fit for this project. I would love to hear your thoughts and experiences with scheduling ETL tasks, particularly for a scenario like mine.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any advice, suggestions, or insights you can provide. I am eager to learn from your expertise and make this ETL pipeline project a success!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151yksz", "is_robot_indexable": true, "report_reasons": null, "author": "Data_is_fuel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151yksz/advice_on_building_an_etl_pipeline_with_aws_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151yksz/advice_on_building_an_etl_pipeline_with_aws_s3/", "subreddit_subscribers": 116398, "created_utc": 1689591190.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}