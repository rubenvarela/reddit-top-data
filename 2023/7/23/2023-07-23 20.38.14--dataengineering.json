{"kind": "Listing", "data": {"after": null, "dist": 15, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Related to any stage of the process. Or anything at all?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some common data engineering mistakes you\u2019ve seen in your career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1570ujm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690074320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Related to any stage of the process. Or anything at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1570ujm", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 83, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1570ujm/what_are_some_common_data_engineering_mistakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1570ujm/what_are_some_common_data_engineering_mistakes/", "subreddit_subscribers": 117547, "created_utc": 1690074320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a senior engineer, but have never had a proper code review because my managers and colleagues tend to have a data analyst/DBA background. Sometimes they ask questions about high level logic, but nobody has ever spent more than 5 minutes on reading my code or nitpicked small things which means I can't learn and grow.\n\nWhat if I join a REAL DE team in the future as a senior with REAL code reviews and everyone can see how amateurish my code looks? That's going to be quite embarrassing and it will probably take forever to ship something to production.", "author_fullname": "t2_vsf3ige5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have never had my code reviewed thoroughly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ip1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690128456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a senior engineer, but have never had a proper code review because my managers and colleagues tend to have a data analyst/DBA background. Sometimes they ask questions about high level logic, but nobody has ever spent more than 5 minutes on reading my code or nitpicked small things which means I can&amp;#39;t learn and grow.&lt;/p&gt;\n\n&lt;p&gt;What if I join a REAL DE team in the future as a senior with REAL code reviews and everyone can see how amateurish my code looks? That&amp;#39;s going to be quite embarrassing and it will probably take forever to ship something to production.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157ip1t", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated_Ad_1108", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157ip1t/i_have_never_had_my_code_reviewed_thoroughly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157ip1t/i_have_never_had_my_code_reviewed_thoroughly/", "subreddit_subscribers": 117547, "created_utc": 1690128456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seriously, I don't know where to begin. It's so annoying. I am not understanding the UI part of Microsoft fabrics. It's so click heavy. I am completely lost where to start and where to end.", "author_fullname": "t2_hnxu1e2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rant-Microsoft Fabric is most annoying POS I have ever used", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1575ma8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690088891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seriously, I don&amp;#39;t know where to begin. It&amp;#39;s so annoying. I am not understanding the UI part of Microsoft fabrics. It&amp;#39;s so click heavy. I am completely lost where to start and where to end.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1575ma8", "is_robot_indexable": true, "report_reasons": null, "author": "boogie_woogie_100", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1575ma8/rantmicrosoft_fabric_is_most_annoying_pos_i_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1575ma8/rantmicrosoft_fabric_is_most_annoying_pos_i_have/", "subreddit_subscribers": 117547, "created_utc": 1690088891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Essentially what the title says. I have an end to end pipeline that at a high level is \n* extract data\n* do some python transformations\n* export data  \n  \nI want to add a 4th step of  \n  \n* run the relevant dbt models\n\nThe thing is that I\u2019m running into problems with invoking it programmatically, as the pipeline file is in a different directory than the dbt project (so it doesn\u2019t detect the project yaml file) and I can\u2019t use absolute paths to specify which model to run, which I need to do because the pipeline is in a different directory\n\nThis is for a personal project, so I am trying to implement dbt just for the sake of learning it. The thing is though, that the pipeline runs automatically on a cron job, and I need the model to be run at the time of the pipeline\n\nIs this the wrong usage pattern for dbt? I suspect it is because it\u2019s not straightforward to do so far", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to be able to programmatically integrate dbt into an end-to-end pipeline in python. Is this the wrong usage of dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156v3fo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690059713.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690059483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially what the title says. I have an end to end pipeline that at a high level is \n* extract data\n* do some python transformations\n* export data  &lt;/p&gt;\n\n&lt;p&gt;I want to add a 4th step of  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;run the relevant dbt models&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The thing is that I\u2019m running into problems with invoking it programmatically, as the pipeline file is in a different directory than the dbt project (so it doesn\u2019t detect the project yaml file) and I can\u2019t use absolute paths to specify which model to run, which I need to do because the pipeline is in a different directory&lt;/p&gt;\n\n&lt;p&gt;This is for a personal project, so I am trying to implement dbt just for the sake of learning it. The thing is though, that the pipeline runs automatically on a cron job, and I need the model to be run at the time of the pipeline&lt;/p&gt;\n\n&lt;p&gt;Is this the wrong usage pattern for dbt? I suspect it is because it\u2019s not straightforward to do so far&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "156v3fo", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156v3fo/i_want_to_be_able_to_programmatically_integrate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156v3fo/i_want_to_be_able_to_programmatically_integrate/", "subreddit_subscribers": 117547, "created_utc": 1690059483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title, has anyone made the switch from data engineering to software dev (backend)? How was the transition (outside of internal switch)? What steps did you take to achieve this (new programming language? side projects?  Leetcode?). Any pointers on where to find side projects to collaborate with experienced backend engineers? How has this switch affected progression in your career? What level did you apply for (junior? Mid?) How\u2019s the learning curve on starting the first SWE job?\n\nBackground: I am a mid level data engineer who enjoys solving problems writing code but have found that DE domain offers less opportunities for me to improve my coding skills. I primarily use Python, SQL and spark in my day to day but feel like I could do more with Python, SQL and other languages. In my spare time, I practise by taking on leetcode challenges and reading on backend architecture and design and find it very interesting. I have also created some personal fullstack projects in the past and looking to learn better by collaborating with more experienced backend engineers on projects before applying for SWE roles.\n\nHas anyone had this experience and how did they successfully make the switch? Any recommendations will be highly appreciated.", "author_fullname": "t2_b8q6wfyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How you switched from data engineering to software Backend development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157fm9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690120905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title, has anyone made the switch from data engineering to software dev (backend)? How was the transition (outside of internal switch)? What steps did you take to achieve this (new programming language? side projects?  Leetcode?). Any pointers on where to find side projects to collaborate with experienced backend engineers? How has this switch affected progression in your career? What level did you apply for (junior? Mid?) How\u2019s the learning curve on starting the first SWE job?&lt;/p&gt;\n\n&lt;p&gt;Background: I am a mid level data engineer who enjoys solving problems writing code but have found that DE domain offers less opportunities for me to improve my coding skills. I primarily use Python, SQL and spark in my day to day but feel like I could do more with Python, SQL and other languages. In my spare time, I practise by taking on leetcode challenges and reading on backend architecture and design and find it very interesting. I have also created some personal fullstack projects in the past and looking to learn better by collaborating with more experienced backend engineers on projects before applying for SWE roles.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had this experience and how did they successfully make the switch? Any recommendations will be highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157fm9c", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent_Bad5837", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157fm9c/how_you_switched_from_data_engineering_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157fm9c/how_you_switched_from_data_engineering_to/", "subreddit_subscribers": 117547, "created_utc": 1690120905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars vs Pandas. Inside an AWS Lambda.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "name": "t3_156yqjp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Fx8866f2QhZ8_c_TlFyhszEmVt4dS0VpZuRLTL-tYvw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690068587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confessionsofadataguy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confessionsofadataguy.com/polars-vs-pandas-inside-an-aws-lambda/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?auto=webp&amp;s=984d4904683a78cd3669ec8cc95bf151ce4901d3", "width": 1030, "height": 407}, "resolutions": [{"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f316fdc66227686d49273d627574d96ef7da138f", "width": 108, "height": 42}, {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be1a70495f071a025cf357793e3847ec87acc3b6", "width": 216, "height": 85}, {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25c5dc36477503778c8153c51b033eb65c2d57dd", "width": 320, "height": 126}, {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e353cc8bc4595b3b882e83dc34ed73b07d400c1c", "width": 640, "height": 252}, {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f70a228a6f648f14e269f0bffe81e7561db75ac", "width": 960, "height": 379}], "variants": {}, "id": "-nV_x0fps6dbvy50xBKdZk_dZsYL6Rtq0vfR6doeFsU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "156yqjp", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156yqjp/polars_vs_pandas_inside_an_aws_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confessionsofadataguy.com/polars-vs-pandas-inside-an-aws-lambda/", "subreddit_subscribers": 117547, "created_utc": 1690068587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone i have a question with Glue Exclude pattern, really appreciate if anyone can help me\n\nI'm having an S3 bucket that contains many csv files in same folder and i want to run Crawlers on that folder to create some tables. The S3 bucket structure:\n\n* bucket\\_name/folder\\_name\n   * xxx-apple-xxx-1.csv\n   * xxx-apple-xxx-2.csv\n   * xxx-orange-xxx-1.csv\n   * xxx-strawberry-xxx-1.csv\n   * xxx-chicken-xxx-1.csv\n   * xxx-chicken-xxx-2.csv\n   * xxx-dog-xxx-1.csv\n   * xxx-cat-xxx-1.csv\n   * and many more....\n\nAnd i want to create Crawler to create 1 table for each category, such as 1 table for apple, 1 table for orange (1 crawler --&gt; 1 table)..... And the number of categories is over 100. I see that Glue Crawler has a property, name [Exclude](https://docs.aws.amazon.com/glue/latest/dg/define-crawler.html#crawler-data-stores-exclude) pattern (but i do not see the Include pattern property) that we use filter out files when running crawler.\n\nNow i want to create a Crawler for apple, so it should ignore all files except \\*apple\\* ones. I've tried with the Exclude but not achieve this yet. Do anyone know how to do this ?\n\nCrawler name: apple\\_crawler\n\nS3\\_path: bucket\\_name/folder\\_name\n\nExclude: i have tried things like: \\*\\[!{apple}\\]\\* or \\*!(apple)\\* or \\*\\[!apple\\]\\* but it did not work\n\n&amp;#x200B;\n\nThank you !", "author_fullname": "t2_7fyrjq8ff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue Crawler Exclude pattern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156usm1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690060211.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690058735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone i have a question with Glue Exclude pattern, really appreciate if anyone can help me&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having an S3 bucket that contains many csv files in same folder and i want to run Crawlers on that folder to create some tables. The S3 bucket structure:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;bucket_name/folder_name\n\n&lt;ul&gt;\n&lt;li&gt;xxx-apple-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-apple-xxx-2.csv&lt;/li&gt;\n&lt;li&gt;xxx-orange-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-strawberry-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-chicken-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-chicken-xxx-2.csv&lt;/li&gt;\n&lt;li&gt;xxx-dog-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-cat-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;and many more....&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And i want to create Crawler to create 1 table for each category, such as 1 table for apple, 1 table for orange (1 crawler --&amp;gt; 1 table)..... And the number of categories is over 100. I see that Glue Crawler has a property, name &lt;a href=\"https://docs.aws.amazon.com/glue/latest/dg/define-crawler.html#crawler-data-stores-exclude\"&gt;Exclude&lt;/a&gt; pattern (but i do not see the Include pattern property) that we use filter out files when running crawler.&lt;/p&gt;\n\n&lt;p&gt;Now i want to create a Crawler for apple, so it should ignore all files except *apple* ones. I&amp;#39;ve tried with the Exclude but not achieve this yet. Do anyone know how to do this ?&lt;/p&gt;\n\n&lt;p&gt;Crawler name: apple_crawler&lt;/p&gt;\n\n&lt;p&gt;S3_path: bucket_name/folder_name&lt;/p&gt;\n\n&lt;p&gt;Exclude: i have tried things like: *[!{apple}]* or *!(apple)* or *[!apple]* but it did not work&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "156usm1", "is_robot_indexable": true, "report_reasons": null, "author": "random_name_362", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156usm1/aws_glue_crawler_exclude_pattern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156usm1/aws_glue_crawler_exclude_pattern/", "subreddit_subscribers": 117547, "created_utc": 1690058735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data reporting business is generally needs a lot of humans involvement to ensure the quality of data, any traction for AI in this space &amp; recommendations please", "author_fullname": "t2_va6si3w6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any AI tools / plugins to check data accuracy and data structure ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157b6f7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690107615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data reporting business is generally needs a lot of humans involvement to ensure the quality of data, any traction for AI in this space &amp;amp; recommendations please&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157b6f7", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Pick_8431", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157b6f7/is_there_any_ai_tools_plugins_to_check_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157b6f7/is_there_any_ai_tools_plugins_to_check_data/", "subreddit_subscribers": 117547, "created_utc": 1690107615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in the market for a DE position, couldn't sleep last night and was reflecting on interviews I've had so far. In 4+ cases, the hiring manager has specifically asked how I  would use data to increase sales. I completely understand that this role requires being a liaison to every department but how far does/should that go?\n\nThis isn't verbatim, but one conversation went like this:\n\nHiring Manager (HM): \"Say for instance, we had a new director of marketing. How would you build a dashboard to help their department?\"\n\nMe: \"I would meet with the director to understand what metrics are most important for their team.\"\n\nHM: \"What if the director didn't know what metrics they should be looking at.\"\n\nMe: \"Then I would ask what goals the department has and work backwards from there. Additionally,  I would prepare some visualizations for data exploration that we could review together. \n\nHM: \"What if the director didn't have any goals?\"\n\nAt this point, I was thinking I wouldn't want to work at a company without any leadership from someone in a director role. I think I understand what he was getting at, but it was still awkward. Is this equivalent to asking a prospective hire in sales this:\n\nHR: \"How would you design a data pipeline that incorporates salesforce and hubspot data?\"\n\nSales Hire (SH): \"I would work with the analytics engineering team, outlining what I need the data for.\"\n\nHR: \"What if the analytics engineering team didn't know how to design a pipeline?\"\n\nSH: ...\n\nAnother example of a question I got verbatim for a DE position:\n\nHR: \"How should we increase air conditioner sales?\"\n\nMe (Never having sold an air conditioner): \"I would assume that air-conditioner sales are driven by new home construction. I would identify areas that are experiencing growth/new development and focus marketing there.\"\n\nMaybe it's just this market, but I feel like I keep flubbing these questions because I don't have a degree in marketing. ", "author_fullname": "t2_7ix4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scope creep in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157lwnh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690136121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in the market for a DE position, couldn&amp;#39;t sleep last night and was reflecting on interviews I&amp;#39;ve had so far. In 4+ cases, the hiring manager has specifically asked how I  would use data to increase sales. I completely understand that this role requires being a liaison to every department but how far does/should that go?&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t verbatim, but one conversation went like this:&lt;/p&gt;\n\n&lt;p&gt;Hiring Manager (HM): &amp;quot;Say for instance, we had a new director of marketing. How would you build a dashboard to help their department?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;I would meet with the director to understand what metrics are most important for their team.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;HM: &amp;quot;What if the director didn&amp;#39;t know what metrics they should be looking at.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;Then I would ask what goals the department has and work backwards from there. Additionally,  I would prepare some visualizations for data exploration that we could review together. &lt;/p&gt;\n\n&lt;p&gt;HM: &amp;quot;What if the director didn&amp;#39;t have any goals?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;At this point, I was thinking I wouldn&amp;#39;t want to work at a company without any leadership from someone in a director role. I think I understand what he was getting at, but it was still awkward. Is this equivalent to asking a prospective hire in sales this:&lt;/p&gt;\n\n&lt;p&gt;HR: &amp;quot;How would you design a data pipeline that incorporates salesforce and hubspot data?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Sales Hire (SH): &amp;quot;I would work with the analytics engineering team, outlining what I need the data for.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;HR: &amp;quot;What if the analytics engineering team didn&amp;#39;t know how to design a pipeline?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;SH: ...&lt;/p&gt;\n\n&lt;p&gt;Another example of a question I got verbatim for a DE position:&lt;/p&gt;\n\n&lt;p&gt;HR: &amp;quot;How should we increase air conditioner sales?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me (Never having sold an air conditioner): &amp;quot;I would assume that air-conditioner sales are driven by new home construction. I would identify areas that are experiencing growth/new development and focus marketing there.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Maybe it&amp;#39;s just this market, but I feel like I keep flubbing these questions because I don&amp;#39;t have a degree in marketing. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157lwnh", "is_robot_indexable": true, "report_reasons": null, "author": "jonesaphore", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157lwnh/scope_creep_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157lwnh/scope_creep_in_de/", "subreddit_subscribers": 117547, "created_utc": 1690136121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to obtain real-time data from Twitter to conduct sentiment analysis using Spark Streaming. However, I've encountered difficulties while attempting to retrieve this data through Tweepy. After some research, I believe the issue might be related to limitations with Tweepy's free access. Could you suggest alternative methods or approaches to acquire real-time data without relying on Tweepy or any other alternatives to it?", "author_fullname": "t2_feara4tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-Time Twitter Data Acquisition for Sentiment Analysis: Seeking Alternatives to Tweepy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156zpo3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690071181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to obtain real-time data from Twitter to conduct sentiment analysis using Spark Streaming. However, I&amp;#39;ve encountered difficulties while attempting to retrieve this data through Tweepy. After some research, I believe the issue might be related to limitations with Tweepy&amp;#39;s free access. Could you suggest alternative methods or approaches to acquire real-time data without relying on Tweepy or any other alternatives to it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "156zpo3", "is_robot_indexable": true, "report_reasons": null, "author": "Kratos_1412", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156zpo3/realtime_twitter_data_acquisition_for_sentiment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156zpo3/realtime_twitter_data_acquisition_for_sentiment/", "subreddit_subscribers": 117547, "created_utc": 1690071181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm fairly new to Pyarrow and parquet files, but have experience with Python.\n\nI'm working on a codebase that processes daily data. We have a Pyarrow Table with 3 columns, one of which is a date. The data goes back to 2007, so ~ 5800 unique dates. The table has 43 million rows, so avg of ~7500 rows per date. The output should be a parquet dataset, partitioned by the date column. So you have an folder with ~5800 folders, named by date. Each folder should contain a single parquet file.\n\nThe repo switches between pandas dataframes and pyarrow tables frequently, mostly pandas for data transformation and pyarrow for parquet reading and writing. The internal processing can be updated, but to work with our other processes, the output needs to remain as daily parquet files.\n\nThis has worked for a long time until we tried updating the Pandas and Pyarrow version, for performance improvements. We went Pandas 1.2 -&gt; 2.0, and Pyarrow 2 -&gt; 12. The original code, that worked:\n\n    pq.write_to_dataset(table, root_path=str(output_filepath),\n                        partition_cols=['action_date'],\n                        allow_truncated_timestamps=True)\n\nNow, with updated pandas and pyarrow on that code, I get the error:\n    pandas_to_parquet Fragment would be written into 4141 partitions. This exceeds the maximum of 1024\n\nI researched and found that pyarrow's behavior changed after version 4.0. It defaults to 1024, and must be set higher. Since I know there's 5800 partitions needed, growing every day, I set it to 7000.\n\n    pq.write_to_dataset(table, root_path=str(output_filepath),\n                        partition_cols=['action_date'],\n                        allow_truncated_timestamps=True,\n                        use_legacy_dataset=False,\n                        max_partitions=7000)\n\nThis took significantly longer to run, many times over. The output folders were correct, but inside each was many parquet files, each only about 2kb. Previously there would be a single parquet, around 20 to 80kb.\n\nI'm trying to figure out how to ensure a single parquet file per daily folder, and have similar or better performance to the previous version with older pandas and pyarrow. The original in memory table I'm trying to write to a parquet dataset is about 280mb. This runs on a larger EC2 instance, AWS Linux.\n\n\n\nTLDR: I updated Pyarrow from 2.0 to 12, and am trying to make the write_to_dataset method function as before, with at least comparable performance. \n\nThank you for any insight or help here, it's very much appreciated!", "author_fullname": "t2_xod94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with Pyarrow behavior - .write_to_dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_157mlmc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690137738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m fairly new to Pyarrow and parquet files, but have experience with Python.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a codebase that processes daily data. We have a Pyarrow Table with 3 columns, one of which is a date. The data goes back to 2007, so ~ 5800 unique dates. The table has 43 million rows, so avg of ~7500 rows per date. The output should be a parquet dataset, partitioned by the date column. So you have an folder with ~5800 folders, named by date. Each folder should contain a single parquet file.&lt;/p&gt;\n\n&lt;p&gt;The repo switches between pandas dataframes and pyarrow tables frequently, mostly pandas for data transformation and pyarrow for parquet reading and writing. The internal processing can be updated, but to work with our other processes, the output needs to remain as daily parquet files.&lt;/p&gt;\n\n&lt;p&gt;This has worked for a long time until we tried updating the Pandas and Pyarrow version, for performance improvements. We went Pandas 1.2 -&amp;gt; 2.0, and Pyarrow 2 -&amp;gt; 12. The original code, that worked:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pq.write_to_dataset(table, root_path=str(output_filepath),\n                    partition_cols=[&amp;#39;action_date&amp;#39;],\n                    allow_truncated_timestamps=True)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Now, with updated pandas and pyarrow on that code, I get the error:\n    pandas_to_parquet Fragment would be written into 4141 partitions. This exceeds the maximum of 1024&lt;/p&gt;\n\n&lt;p&gt;I researched and found that pyarrow&amp;#39;s behavior changed after version 4.0. It defaults to 1024, and must be set higher. Since I know there&amp;#39;s 5800 partitions needed, growing every day, I set it to 7000.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pq.write_to_dataset(table, root_path=str(output_filepath),\n                    partition_cols=[&amp;#39;action_date&amp;#39;],\n                    allow_truncated_timestamps=True,\n                    use_legacy_dataset=False,\n                    max_partitions=7000)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This took significantly longer to run, many times over. The output folders were correct, but inside each was many parquet files, each only about 2kb. Previously there would be a single parquet, around 20 to 80kb.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out how to ensure a single parquet file per daily folder, and have similar or better performance to the previous version with older pandas and pyarrow. The original in memory table I&amp;#39;m trying to write to a parquet dataset is about 280mb. This runs on a larger EC2 instance, AWS Linux.&lt;/p&gt;\n\n&lt;p&gt;TLDR: I updated Pyarrow from 2.0 to 12, and am trying to make the write_to_dataset method function as before, with at least comparable performance. &lt;/p&gt;\n\n&lt;p&gt;Thank you for any insight or help here, it&amp;#39;s very much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157mlmc", "is_robot_indexable": true, "report_reasons": null, "author": "bigfishindoggytown", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157mlmc/help_with_pyarrow_behavior_write_to_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157mlmc/help_with_pyarrow_behavior_write_to_dataset/", "subreddit_subscribers": 117547, "created_utc": 1690137738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have airflow on WSL but are otherwise a Windows shop. What sorts of activities would be good practice for improving my command line knowledge? Or what sorts of command line activities are most useful/common for data engineering?\n\nI am very much a learn by doing kind of person. I have to seek out ways to transform whatever I am working on to incorporate what I  am interested in learning, even if it isn't necessary. So identifying what I should be thinking to try in command line will go a long way. Thanks!", "author_fullname": "t2_f1q7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Improving at Command line", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ke6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690132544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have airflow on WSL but are otherwise a Windows shop. What sorts of activities would be good practice for improving my command line knowledge? Or what sorts of command line activities are most useful/common for data engineering?&lt;/p&gt;\n\n&lt;p&gt;I am very much a learn by doing kind of person. I have to seek out ways to transform whatever I am working on to incorporate what I  am interested in learning, even if it isn&amp;#39;t necessary. So identifying what I should be thinking to try in command line will go a long way. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157ke6v", "is_robot_indexable": true, "report_reasons": null, "author": "machinegunke11y", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157ke6v/improving_at_command_line/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157ke6v/improving_at_command_line/", "subreddit_subscribers": 117547, "created_utc": 1690132544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. \n\nWhat are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?", "author_fullname": "t2_dv159drh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does DE belong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157j46z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690129459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. &lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157j46z", "is_robot_indexable": true, "report_reasons": null, "author": "Sad-Fail-5337", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157j46z/where_does_de_belong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157j46z/where_does_de_belong/", "subreddit_subscribers": 117547, "created_utc": 1690129459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHi everyone,\n\nI am planning to switch  from data analytics/BA to data engineering.\n\nMy current skills include SQL (select statements), python pandas, power BI(data modelling and dashboarding), Azure data factory and spark using databricks.\n\nI've just got my DP 900 certificate and contemplating completing either dp203 and/or databricks DE associate.\n\n\nI will also be picking up docker with airflow and Kafka.\n\nWhich of the two certificates mentioned will be better for me ?\n\nThanks in advance for your advice.", "author_fullname": "t2_3o8uixm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DP 203 Vs databricks DE associate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157e9t5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690117215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am planning to switch  from data analytics/BA to data engineering.&lt;/p&gt;\n\n&lt;p&gt;My current skills include SQL (select statements), python pandas, power BI(data modelling and dashboarding), Azure data factory and spark using databricks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just got my DP 900 certificate and contemplating completing either dp203 and/or databricks DE associate.&lt;/p&gt;\n\n&lt;p&gt;I will also be picking up docker with airflow and Kafka.&lt;/p&gt;\n\n&lt;p&gt;Which of the two certificates mentioned will be better for me ?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157e9t5", "is_robot_indexable": true, "report_reasons": null, "author": "Leonjy92", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157e9t5/dp_203_vs_databricks_de_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157e9t5/dp_203_vs_databricks_de_associate/", "subreddit_subscribers": 117547, "created_utc": 1690117215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "found this on substack and reposting here for more reach.", "author_fullname": "t2_vi5mj54d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": true, "name": "t3_157mn03", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FDDKeJwbGLUab6btVz1qzcE0b4JSqmLUEaFYavlouFc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690137835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;found this on substack and reposting here for more reach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/o908zbyifrdb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?auto=webp&amp;s=5760b5b63c45ff2034b1053d76b21cdda69dbc24", "width": 1179, "height": 718}, "resolutions": [{"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e19db647dba910a9349807b611f66eb7b16cea18", "width": 108, "height": 65}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e69c8470d41e0d0a7f73b9235608653fa071e55b", "width": 216, "height": 131}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9b46d207118d885e3d8ab30d58e1accf87448081", "width": 320, "height": 194}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=980061a81aac3c925fec18c1f93441bd90f4c5a5", "width": 640, "height": 389}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8855e1c1ee649852826ec2f6eebfc8ac8bca21ef", "width": 960, "height": 584}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b0526230ba81f85165e34740b6f2f26fe354d20", "width": 1080, "height": 657}], "variants": {}, "id": "FD8BsKGuc9f_50KXbD-QTDIZrGjNXHpBBM-rg1ah9e0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157mn03", "is_robot_indexable": true, "report_reasons": null, "author": "mrlmld", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157mn03/rust_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/o908zbyifrdb1.jpg", "subreddit_subscribers": 117547, "created_utc": 1690137835.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}