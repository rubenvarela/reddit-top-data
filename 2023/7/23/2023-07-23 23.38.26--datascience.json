{"kind": "Listing", "data": {"after": "t3_157emen", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been stuck on the following problem for weeks now. To be clear I'm not asking the community to provide a full solution. Just a few ideas or at least confirmation on whether this problem statement is solvable with the data available at hand. Thanks.\n\n**Context:** I work for a company that rents out stuff. During user checkout, there's a rule-based risk engine that determines whether to auto-approve user (takes seconds) or send for manual approval (takes days). This engine utilizes only basic features such as credit score, rent items category, cart value etc. Lets say that around 40% of all instances go to manual approval. Actual rejection rate is around 1-2% that means most of the cases sent for manual approval could have just been auto-approved.\n\n**Objective:** Reduce dependency on manual approval as much as possible (to lets say 5%). If this was a binary classification task (manual or not) then we'd say recall is important here. Thus, deprecate legacy system as it is too rudimentary.\n\nNow, boss wants me to achieve this by creating a regression model using customer credit history, and purchase history to predict ***maximum allowed***  ^(\u2020)***active-sourcing-cost per user***. So that if a user tries checking out cart that brings their total active sourcing cost above their max allowed limit, they will be sent for manual approval instead of auto-approve.\n\n&gt;^(\u2020)*active-sourcing-cost is the total purchase cost to company of all items the user currently is renting*\n\n**Data available:** User purchase history, user credit history (experian), product details, NPA data (data of users who failed to return the items they have rented, thus defaulted)\n\n**Issues with proposed solution:**\n\n1. Max allowed sourcing cost per user unavailable as the target variable (No recorded ground truth for any samples)\n2. No relevant proxy variables available as ground truth (that I can think of)\n\nTried explaining that lack of relevant ground truth is an issue. But am being pushed for a solution so have to produce.\n\n**My alternate half-baked solution:**\n\n1. Use legacy system for auto approvals only. This acts as a filter.\n2. To the rest of the data that would otherwise be sent for manual verification we add NPA users and tag as a negative class. This would be the training data.\n3. Train binary classification model (npa vs. not npa).\n4. What the model classifies as NPA would then be sent for manual, rest will be auto approved.\n\n&amp;#x200B;", "author_fullname": "t2_40233m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Been stuck on a problem. Just need to know whether this problem statement is solvable or not.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15753qp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 90, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 90, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690087252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been stuck on the following problem for weeks now. To be clear I&amp;#39;m not asking the community to provide a full solution. Just a few ideas or at least confirmation on whether this problem statement is solvable with the data available at hand. Thanks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt; I work for a company that rents out stuff. During user checkout, there&amp;#39;s a rule-based risk engine that determines whether to auto-approve user (takes seconds) or send for manual approval (takes days). This engine utilizes only basic features such as credit score, rent items category, cart value etc. Lets say that around 40% of all instances go to manual approval. Actual rejection rate is around 1-2% that means most of the cases sent for manual approval could have just been auto-approved.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Objective:&lt;/strong&gt; Reduce dependency on manual approval as much as possible (to lets say 5%). If this was a binary classification task (manual or not) then we&amp;#39;d say recall is important here. Thus, deprecate legacy system as it is too rudimentary.&lt;/p&gt;\n\n&lt;p&gt;Now, boss wants me to achieve this by creating a regression model using customer credit history, and purchase history to predict &lt;strong&gt;&lt;em&gt;maximum allowed&lt;/em&gt;&lt;/strong&gt;  &lt;sup&gt;\u2020&lt;/sup&gt;&lt;strong&gt;&lt;em&gt;active-sourcing-cost per user&lt;/em&gt;&lt;/strong&gt;. So that if a user tries checking out cart that brings their total active sourcing cost above their max allowed limit, they will be sent for manual approval instead of auto-approve.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;sup&gt;\u2020&lt;/sup&gt;&lt;em&gt;active-sourcing-cost is the total purchase cost to company of all items the user currently is renting&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;Data available:&lt;/strong&gt; User purchase history, user credit history (experian), product details, NPA data (data of users who failed to return the items they have rented, thus defaulted)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Issues with proposed solution:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Max allowed sourcing cost per user unavailable as the target variable (No recorded ground truth for any samples)&lt;/li&gt;\n&lt;li&gt;No relevant proxy variables available as ground truth (that I can think of)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Tried explaining that lack of relevant ground truth is an issue. But am being pushed for a solution so have to produce.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My alternate half-baked solution:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use legacy system for auto approvals only. This acts as a filter.&lt;/li&gt;\n&lt;li&gt;To the rest of the data that would otherwise be sent for manual verification we add NPA users and tag as a negative class. This would be the training data.&lt;/li&gt;\n&lt;li&gt;Train binary classification model (npa vs. not npa).&lt;/li&gt;\n&lt;li&gt;What the model classifies as NPA would then be sent for manual, rest will be auto approved.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15753qp", "is_robot_indexable": true, "report_reasons": null, "author": "CrypticTac", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15753qp/been_stuck_on_a_problem_just_need_to_know_whether/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15753qp/been_stuck_on_a_problem_just_need_to_know_whether/", "subreddit_subscribers": 958561, "created_utc": 1690087252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. \n\nWhat are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?", "author_fullname": "t2_dv159drh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does Data Engineering belong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157j2zn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690129380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. &lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157j2zn", "is_robot_indexable": true, "report_reasons": null, "author": "Sad-Fail-5337", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157j2zn/where_does_data_engineering_belong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157j2zn/where_does_data_engineering_belong/", "subreddit_subscribers": 958561, "created_utc": 1690129380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working on a new implementation of Agglomerative clustering called Reciprocal Agglomerative Clustering (RAC) based off of this paper: [https://arxiv.org/abs/2105.11653](https://arxiv.org/abs/2105.11653). The short of it is Agglomerative clustering can be broken down into finding and merging pairs of reciprocal nearest neighbors in parallel, as long as the linkage function is one of the following:\n\n* Single\n* Average\n* Complete\n* Ward\n\nMost importantly, RAC *produces the exact same results as traditional Agglomerative clustering when the dataset is fully connected.* Even with connectivity constraints, the results are almost always the same.\n\nThe authors showed that RAC has a linear runtime when connectivity is limited to k and the distance matrix is precomputed. I have not added the ability to pass in the distance matrix yet, so the runtime is roughly quadratic, which is still a major improvement over the cubic runtime of Agglomerative clustering. In addition the entire algorithm is parallelized, and so can scale up to more and more cores.\n\nIt's very much in development - only average linkage works at the moment, however, I think it has a lot of potential. The benchmarks have blown me away so far:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/bbjxw0qsyodb1.png?width=850&amp;format=png&amp;auto=webp&amp;s=4bcdd014aea6ac14eca51d9c7403dadda2e4012e\n\nHere is the code: [https://github.com/porterehunley/RACplusplus](https://github.com/porterehunley/RACplusplus). It would be great to have some people try it out (and find the bugs)!", "author_fullname": "t2_n63m16v8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] I created a parallelized implementation of Agglomerative clustering that's many times faster than existing implementations and has a better runtime", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bbjxw0qsyodb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=46cd69b3b26d632620779a7b51d511769a4d6053"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=590cf437e74b1e487bc71875e5c73d606bca59be"}, {"y": 205, "x": 320, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b015a76a9ea58d78f72958eda6a493884757e4c6"}, {"y": 410, "x": 640, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=30a645af0740616051dd760751ea8c75c0a86bb2"}], "s": {"y": 545, "x": 850, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=850&amp;format=png&amp;auto=webp&amp;s=4bcdd014aea6ac14eca51d9c7403dadda2e4012e"}, "id": "bbjxw0qsyodb1"}}, "name": "t3_157bax6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QnX1OEC5i7I5fYXeuKfzrEZp-gXBNdbzXndyyLr3lUw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1690108031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on a new implementation of Agglomerative clustering called Reciprocal Agglomerative Clustering (RAC) based off of this paper: &lt;a href=\"https://arxiv.org/abs/2105.11653\"&gt;https://arxiv.org/abs/2105.11653&lt;/a&gt;. The short of it is Agglomerative clustering can be broken down into finding and merging pairs of reciprocal nearest neighbors in parallel, as long as the linkage function is one of the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Single&lt;/li&gt;\n&lt;li&gt;Average&lt;/li&gt;\n&lt;li&gt;Complete&lt;/li&gt;\n&lt;li&gt;Ward&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Most importantly, RAC &lt;em&gt;produces the exact same results as traditional Agglomerative clustering when the dataset is fully connected.&lt;/em&gt; Even with connectivity constraints, the results are almost always the same.&lt;/p&gt;\n\n&lt;p&gt;The authors showed that RAC has a linear runtime when connectivity is limited to k and the distance matrix is precomputed. I have not added the ability to pass in the distance matrix yet, so the runtime is roughly quadratic, which is still a major improvement over the cubic runtime of Agglomerative clustering. In addition the entire algorithm is parallelized, and so can scale up to more and more cores.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s very much in development - only average linkage works at the moment, however, I think it has a lot of potential. The benchmarks have blown me away so far:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bbjxw0qsyodb1.png?width=850&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4bcdd014aea6ac14eca51d9c7403dadda2e4012e\"&gt;https://preview.redd.it/bbjxw0qsyodb1.png?width=850&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4bcdd014aea6ac14eca51d9c7403dadda2e4012e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is the code: &lt;a href=\"https://github.com/porterehunley/RACplusplus\"&gt;https://github.com/porterehunley/RACplusplus&lt;/a&gt;. It would be great to have some people try it out (and find the bugs)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?auto=webp&amp;s=f1cd025aeb52ffa82fc9e5a4a2f157da0d919147", "width": 1200, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2711d572cfc6c713893cf24e8c4a7344d5ad8a4c", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6624f0c1eedc14997e7f1780efbe6e5cb50c1e2", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9db38144ef3065833b9ba158c764f7be47de3016", "width": 320, "height": 186}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075", "width": 640, "height": 373}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2637f961ee21190172b9ca6c8adf3ac9612db083", "width": 960, "height": 560}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=782eead871df2939a587ee3beae442cc59282f64", "width": 1080, "height": 630}], "variants": {}, "id": "q3evP6JeDpAC2MdSQHWYxnCYTqbJkElIQsLFqVSdkss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "157bax6", "is_robot_indexable": true, "report_reasons": null, "author": "Ridaleneas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157bax6/p_i_created_a_parallelized_implementation_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157bax6/p_i_created_a_parallelized_implementation_of/", "subreddit_subscribers": 958561, "created_utc": 1690108031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm not a Data scientist but I do have a few questions for you all. I just saw oppenheimer which, no spoilers, simply revolves around the Manhattan project and the creation of nuclear bombs. \n\nBack in the day, weren't data scientists just the physicists and chemists and mathematicians who did their own studies? Or was there a specific role for someone who handles all the data and does something else with it?", "author_fullname": "t2_f4m0dd2qo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just saw oppenheimer, did data scientists exist back then?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157m5sj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690136715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not a Data scientist but I do have a few questions for you all. I just saw oppenheimer which, no spoilers, simply revolves around the Manhattan project and the creation of nuclear bombs. &lt;/p&gt;\n\n&lt;p&gt;Back in the day, weren&amp;#39;t data scientists just the physicists and chemists and mathematicians who did their own studies? Or was there a specific role for someone who handles all the data and does something else with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157m5sj", "is_robot_indexable": true, "report_reasons": null, "author": "Sacred_Tomato", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157m5sj/just_saw_oppenheimer_did_data_scientists_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157m5sj/just_saw_oppenheimer_did_data_scientists_exist/", "subreddit_subscribers": 958561, "created_utc": 1690136715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_xj5pb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Decoding the ACL Paper: Gzip and KNN Rival BERT in Text Classification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1579qy7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ll4r9_pwUGqg72AsM1LP1Rqusl158PoU5ZvAIpQdb6A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690102828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "codeconfessions.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://codeconfessions.substack.com/p/decoding-the-acl-paper-gzip-and-knn", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?auto=webp&amp;s=8869decfb98ee3f81c132ceccdcd226bc52a1665", "width": 1080, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38fdaad8619c80598f8180411e4ad66936cf670b", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=210dc8f4fa7627f9296df82ed8dd8c1b8ff5f118", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2714fd534001d06506681c49788e47f89957eb3", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=056302bd549a22f1471808140b3511781123e059", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bcf72e791d030d9291cfd071cc82bd38468f08b8", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e972c7057a494dc0e2ff3feb0750b72ad72196b1", "width": 1080, "height": 720}], "variants": {}, "id": "nF766ThFN6J1Dv_cSr4PSjoVHitYsK4g5cWriwI18Dg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1579qy7", "is_robot_indexable": true, "report_reasons": null, "author": "abhi9u", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1579qy7/decoding_the_acl_paper_gzip_and_knn_rival_bert_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://codeconfessions.substack.com/p/decoding-the-acl-paper-gzip-and-knn", "subreddit_subscribers": 958561, "created_utc": 1690102828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1546d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know where I can find a dataset that I can use to gauge insights or use as a proxy for US sentiment towards China?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1571yaa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690077480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1571yaa", "is_robot_indexable": true, "report_reasons": null, "author": "raks1811", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1571yaa/does_anyone_know_where_i_can_find_a_dataset_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1571yaa/does_anyone_know_where_i_can_find_a_dataset_that/", "subreddit_subscribers": 958561, "created_utc": 1690077480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a data set that boils down to Three clomuns: 1.Supplier name 2. Number of transactions with supplier 3. Total value of those transaction.\n\nI'm trying to find the best way to rank all suppliers based on these two features which are equally important in this case. \nNote: -more transaction doesn't mean more value\n\nWhat I did is I normalized each feature. Making all values scale down to 0 to 1. Then I added the 2 normalized values to each other. Then used this new values to rank all suppliers. Looking at the results and  what I expected a good ranking to be, I'm happy with the result.\n\nHowever, I feel like the existing of outliers might've made the ranking.. not as accurate as it can be. Am I right or wrong? How would you suggest fixing this? Is there an entierly better way to do this?\n\nFinal note: I tried standarizing and got the exact same ranking. I'm not sure if that was supposed to happen or if it was a special case.", "author_fullname": "t2_59mf5tbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would normalizing be affected by outliers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157o4qn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690141303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data set that boils down to Three clomuns: 1.Supplier name 2. Number of transactions with supplier 3. Total value of those transaction.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to find the best way to rank all suppliers based on these two features which are equally important in this case. \nNote: -more transaction doesn&amp;#39;t mean more value&lt;/p&gt;\n\n&lt;p&gt;What I did is I normalized each feature. Making all values scale down to 0 to 1. Then I added the 2 normalized values to each other. Then used this new values to rank all suppliers. Looking at the results and  what I expected a good ranking to be, I&amp;#39;m happy with the result.&lt;/p&gt;\n\n&lt;p&gt;However, I feel like the existing of outliers might&amp;#39;ve made the ranking.. not as accurate as it can be. Am I right or wrong? How would you suggest fixing this? Is there an entierly better way to do this?&lt;/p&gt;\n\n&lt;p&gt;Final note: I tried standarizing and got the exact same ranking. I&amp;#39;m not sure if that was supposed to happen or if it was a special case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157o4qn", "is_robot_indexable": true, "report_reasons": null, "author": "kit_kaat", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157o4qn/how_would_normalizing_be_affected_by_outliers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157o4qn/how_would_normalizing_be_affected_by_outliers/", "subreddit_subscribers": 958561, "created_utc": 1690141303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lots of existing datasets contain some sort of textual data which is usually overlooked because it is hard to work with. The recent advancement in AI (GPT-like models) make it possible to extract valuable data easily (examples: various specifications, names, dates, prices, etc) - converting free texts into tabular data. Example tools: the incredible [Textraction.ai](https://www.textraction.ai/), engineered ChatGPT prompts, etc.\n\n**Have you already used such tools to do that? Which datasets have the highest potential?**\n\nSome examples that come to my mind:\n\n* Medical datasets that often contain a free text describing symptoms, diagnosis, prescriptions, etc.\n* E-commerce products descriptions.\n* Real estate posts listings.\n* Automatically filling forms for the user based on free text.\n\nThese new tools open up a wide range of new applications now made possible.", "author_fullname": "t2_mqeuzn8j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Text Data Mining to Enrich Existing Datasets Using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157fgnd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690120860.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690120509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lots of existing datasets contain some sort of textual data which is usually overlooked because it is hard to work with. The recent advancement in AI (GPT-like models) make it possible to extract valuable data easily (examples: various specifications, names, dates, prices, etc) - converting free texts into tabular data. Example tools: the incredible &lt;a href=\"https://www.textraction.ai/\"&gt;Textraction.ai&lt;/a&gt;, engineered ChatGPT prompts, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Have you already used such tools to do that? Which datasets have the highest potential?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Some examples that come to my mind:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Medical datasets that often contain a free text describing symptoms, diagnosis, prescriptions, etc.&lt;/li&gt;\n&lt;li&gt;E-commerce products descriptions.&lt;/li&gt;\n&lt;li&gt;Real estate posts listings.&lt;/li&gt;\n&lt;li&gt;Automatically filling forms for the user based on free text.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These new tools open up a wide range of new applications now made possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157fgnd", "is_robot_indexable": true, "report_reasons": null, "author": "DoorDesigner7589", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157fgnd/text_data_mining_to_enrich_existing_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157fgnd/text_data_mining_to_enrich_existing_datasets/", "subreddit_subscribers": 958561, "created_utc": 1690120509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have several datasets that share the same columns, but consist of completely different data points, and each come from a different source. All of these datasets are available on Kaggle.\n\n&amp;#x200B;\n\nI was wondering if there would be any issues that could arise from me downloading each dataset, combining them into on singular csv file, and then using that csv for a project. I understand that combining the data would be difficult as not all columns are equal, and there is a chance that I would end up with entire datasets be duplicated, but I assume this is a very good way to gather a ton of data points on one particular topic, correct?", "author_fullname": "t2_ebylq8bw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Combining Datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1575f95", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690088297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have several datasets that share the same columns, but consist of completely different data points, and each come from a different source. All of these datasets are available on Kaggle.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there would be any issues that could arise from me downloading each dataset, combining them into on singular csv file, and then using that csv for a project. I understand that combining the data would be difficult as not all columns are equal, and there is a chance that I would end up with entire datasets be duplicated, but I assume this is a very good way to gather a ton of data points on one particular topic, correct?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1575f95", "is_robot_indexable": true, "report_reasons": null, "author": "AI_rondo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1575f95/combining_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1575f95/combining_datasets/", "subreddit_subscribers": 958561, "created_utc": 1690088297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_h3a1v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] Create your Own Artificial Neural Network in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 133, "top_awarded_type": null, "hide_score": false, "name": "t3_157p1xy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-B07hLh7SWkvm-8aZcuYKPg4CEt0v9ylaDtFqXXBLzc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690143441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kjjvyye6wrdb1.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?format=png8&amp;s=dee8b32aac95f2353722253648d23e9de68aca89", "width": 400, "height": 381}, "resolutions": [{"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=3b2fcdb4900dd3899def7e3cd7f61addb33d1fc3", "width": 108, "height": 102}, {"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=becf43f69cb79e54e448725bb820d8239493286c", "width": 216, "height": 205}, {"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=724a6c49a28669d5555c103b439f506de805627c", "width": 320, "height": 304}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?s=cfba8de4c12e7e3c803e8be0a368021277520538", "width": 400, "height": 381}, "resolutions": [{"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?width=108&amp;crop=smart&amp;s=616ffeb49f0e7f535b950dc1b5fb9bb5258613a4", "width": 108, "height": 102}, {"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?width=216&amp;crop=smart&amp;s=4e6dfda62d035dc593dffc9045451c9da5061a11", "width": 216, "height": 205}, {"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?width=320&amp;crop=smart&amp;s=df724883ded6b38ace50533f4e5d3da7f74299b3", "width": 320, "height": 304}]}, "mp4": {"source": {"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?format=mp4&amp;s=69360b7f6256282bd1eae1064ce558e48bcc9574", "width": 400, "height": 381}, "resolutions": [{"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?width=108&amp;format=mp4&amp;s=d56f84fec62bb582387a03c361c6aa2646e48700", "width": 108, "height": 102}, {"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?width=216&amp;format=mp4&amp;s=9b11c2bb44a7ee57dbb111dd38a9fbd33a3e521d", "width": 216, "height": 205}, {"url": "https://preview.redd.it/kjjvyye6wrdb1.gif?width=320&amp;format=mp4&amp;s=3ee15f162795714a7df05658a1647376d2a4ce10", "width": 320, "height": 304}]}}, "id": "Xtc8PF38RpYdQrQI3yd99HMkHr8pKSFx0oQn4XWWwzM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "157p1xy", "is_robot_indexable": true, "report_reasons": null, "author": "pmocz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157p1xy/oc_create_your_own_artificial_neural_network_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kjjvyye6wrdb1.gif", "subreddit_subscribers": 958561, "created_utc": 1690143441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Cost-effective too. ", "author_fullname": "t2_44tf9ypj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Ways to Put an R Shiny Dashboard into Prod for 1000+ to view daily?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157jtbr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690131147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Cost-effective too. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157jtbr", "is_robot_indexable": true, "report_reasons": null, "author": "PSM182", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157jtbr/best_ways_to_put_an_r_shiny_dashboard_into_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157jtbr/best_ways_to_put_an_r_shiny_dashboard_into_prod/", "subreddit_subscribers": 958561, "created_utc": 1690131147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you do AI/ML stuff often? Deep learning with Neural Networks?\n\nOr do you just make charts with SQL queries? Excel and .csv files?\n\nOr something in between?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What extent is your job \"Advanced Data Science\" vs \"low-level Data Science\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_157sidi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690151635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you do AI/ML stuff often? Deep learning with Neural Networks?&lt;/p&gt;\n\n&lt;p&gt;Or do you just make charts with SQL queries? Excel and .csv files?&lt;/p&gt;\n\n&lt;p&gt;Or something in between?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157sidi", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157sidi/what_extent_is_your_job_advanced_data_science_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157sidi/what_extent_is_your_job_advanced_data_science_vs/", "subreddit_subscribers": 958561, "created_utc": 1690151635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,\n\nI will be leaving my Job at a startup in about a month to go to an organization and start a data science team. I currently run a analytics and data science team, and I like to think that I do a good job understanding the business problems and data and coming up with solutions. I have built this team up from basically scratch (my boss hasn't been very involved in analytics as he's focused on other things) and have hired all 15 people under me. Our company has been relatively successful through the pandemic and its largely because of our analytics solutions. However we are in the healthcare space which means that most of what we have done is revolving around SAS.  \n\nAs mentioned, I am going to be moving to a new organization which (seems to) have realistic expectations about applying data science.  Ill be building a team from scratch, which I have done before, but they mentioned they are primarily an R shop, which I haven't used since college. I was wondering what your best resources for learning R's applications to data analytics and Data Science were. I'm a very hands on person and as discussed in the interview 50-75% of my time will be hands on over the next year or two as I learn company and their goals so I want to be able to hit the ground running \n\nAdditionally, if anyone has any good resources on building teams (data science or non data science) I would love to read those as well. I am always looking to get better and since my last job started as analytics and grew into data science, I assume starting with data science might be different. What have you done in the past (or what did your boss do in the past) that worked really well in growing your team.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nI have found some old threads but not much activity in them: [https://www.reddit.com/r/rstats/comments/mxo6k8/what\\_are\\_the\\_best\\_resources\\_to\\_learn\\_r\\_for\\_data/](https://www.reddit.com/r/rstats/comments/mxo6k8/what_are_the_best_resources_to_learn_r_for_data/)\n\n[https://www.reddit.com/r/datascience/comments/414pek/list\\_of\\_data\\_science\\_resources/](https://www.reddit.com/r/datascience/comments/414pek/list_of_data_science_resources/)\n\n[https://www.reddit.com/r/RStudio/comments/zowii1/learning\\_r\\_resources/](https://www.reddit.com/r/RStudio/comments/zowii1/learning_r_resources/)\n\n&amp;#x200B;\n\nFrom these resources it seems like [https://r4ds.had.co.nz/](https://r4ds.had.co.nz/) is the way to go -- do people here agree?", "author_fullname": "t2_dhh8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Resources/Opinions around R and Team Building", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157pgxl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690144386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I will be leaving my Job at a startup in about a month to go to an organization and start a data science team. I currently run a analytics and data science team, and I like to think that I do a good job understanding the business problems and data and coming up with solutions. I have built this team up from basically scratch (my boss hasn&amp;#39;t been very involved in analytics as he&amp;#39;s focused on other things) and have hired all 15 people under me. Our company has been relatively successful through the pandemic and its largely because of our analytics solutions. However we are in the healthcare space which means that most of what we have done is revolving around SAS.  &lt;/p&gt;\n\n&lt;p&gt;As mentioned, I am going to be moving to a new organization which (seems to) have realistic expectations about applying data science.  Ill be building a team from scratch, which I have done before, but they mentioned they are primarily an R shop, which I haven&amp;#39;t used since college. I was wondering what your best resources for learning R&amp;#39;s applications to data analytics and Data Science were. I&amp;#39;m a very hands on person and as discussed in the interview 50-75% of my time will be hands on over the next year or two as I learn company and their goals so I want to be able to hit the ground running &lt;/p&gt;\n\n&lt;p&gt;Additionally, if anyone has any good resources on building teams (data science or non data science) I would love to read those as well. I am always looking to get better and since my last job started as analytics and grew into data science, I assume starting with data science might be different. What have you done in the past (or what did your boss do in the past) that worked really well in growing your team.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have found some old threads but not much activity in them: &lt;a href=\"https://www.reddit.com/r/rstats/comments/mxo6k8/what_are_the_best_resources_to_learn_r_for_data/\"&gt;https://www.reddit.com/r/rstats/comments/mxo6k8/what_are_the_best_resources_to_learn_r_for_data/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/datascience/comments/414pek/list_of_data_science_resources/\"&gt;https://www.reddit.com/r/datascience/comments/414pek/list_of_data_science_resources/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/RStudio/comments/zowii1/learning_r_resources/\"&gt;https://www.reddit.com/r/RStudio/comments/zowii1/learning_r_resources/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;From these resources it seems like &lt;a href=\"https://r4ds.had.co.nz/\"&gt;https://r4ds.had.co.nz/&lt;/a&gt; is the way to go -- do people here agree?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dX3T8UC_GylpVlrUMrYvH-2nM0oxTSosN0Q-7yoOac4.jpg?auto=webp&amp;s=3a730442108ffa573736d1d5f5ecd3a5a928e027", "width": 500, "height": 750}, "resolutions": [{"url": "https://external-preview.redd.it/dX3T8UC_GylpVlrUMrYvH-2nM0oxTSosN0Q-7yoOac4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e439ee362507d14f6aa9fdf48e3230c863924897", "width": 108, "height": 162}, {"url": "https://external-preview.redd.it/dX3T8UC_GylpVlrUMrYvH-2nM0oxTSosN0Q-7yoOac4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c67e132d9b81a45007aeddec0e52d26c531476fc", "width": 216, "height": 324}, {"url": "https://external-preview.redd.it/dX3T8UC_GylpVlrUMrYvH-2nM0oxTSosN0Q-7yoOac4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=560eb06cb50e433925324672ed1e5aecb14dadad", "width": 320, "height": 480}], "variants": {}, "id": "N_ZYgQxGMscE67OV4DhF9HugRbJUyzPy6u5WBBYiWc8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157pgxl", "is_robot_indexable": true, "report_reasons": null, "author": "mathblaster69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157pgxl/looking_for_resourcesopinions_around_r_and_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157pgxl/looking_for_resourcesopinions_around_r_and_team/", "subreddit_subscribers": 958561, "created_utc": 1690144386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am not a data science professional.\n\n&amp;#x200B;\n\nI work at a local government/Council department maintaining the local land and property register which is a map/database record of all the land and property with status e.g. occupied/under construction etc.\n\n&amp;#x200B;\n\nMostly i get the info for new developments from street naming and numbering department when they apply for an address. \n\n&amp;#x200B;\n\nHowever, it is the changes to status in existing properties which is hard - e.g. a business park with 50 units, when one of them becomes unnocupied or a new tenant moves in or a unit is split into two. Same with residential properties.\n\n&amp;#x200B;\n\nThe local commercial tax and residential tax departments plus the waste departmentsadminister all this but there is not much synchronisation. They don't have a common identifier for the property for and sometimes the address format might not match exactly so hard to match like for like. Talking about 100k properties.\n\n&amp;#x200B;\n\nWhat's the best way to get triggers of real world change from their data sets? Is their a smart solution here that is going to be easyish? I was thinking thingsan extract of all data sets and something like fuzzy look ups or similar to set up a common identifier so that we can baseline. I guess FME would be doable but I have only the most basic knowledge of that. I am more of a GIS person. Once we have baselined going forward what would be a good system on a weekly basis to synchronise these changes. We have different databases, formats, tools. Don't want to reinvent the wheel here, just want a solution that is practical and workable with limited technical knowledge.\n\n&amp;#x200B;\n\nMany Thanks \n\n&amp;#x200B;", "author_fullname": "t2_dzypkgpv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local Government data sets full of duplication - how to streamline/synchronise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157nvjh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690140720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not a data science professional.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I work at a local government/Council department maintaining the local land and property register which is a map/database record of all the land and property with status e.g. occupied/under construction etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Mostly i get the info for new developments from street naming and numbering department when they apply for an address. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, it is the changes to status in existing properties which is hard - e.g. a business park with 50 units, when one of them becomes unnocupied or a new tenant moves in or a unit is split into two. Same with residential properties.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The local commercial tax and residential tax departments plus the waste departmentsadminister all this but there is not much synchronisation. They don&amp;#39;t have a common identifier for the property for and sometimes the address format might not match exactly so hard to match like for like. Talking about 100k properties.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way to get triggers of real world change from their data sets? Is their a smart solution here that is going to be easyish? I was thinking thingsan extract of all data sets and something like fuzzy look ups or similar to set up a common identifier so that we can baseline. I guess FME would be doable but I have only the most basic knowledge of that. I am more of a GIS person. Once we have baselined going forward what would be a good system on a weekly basis to synchronise these changes. We have different databases, formats, tools. Don&amp;#39;t want to reinvent the wheel here, just want a solution that is practical and workable with limited technical knowledge.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Many Thanks &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157nvjh", "is_robot_indexable": true, "report_reasons": null, "author": "omura777", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157nvjh/local_government_data_sets_full_of_duplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157nvjh/local_government_data_sets_full_of_duplication/", "subreddit_subscribers": 958561, "created_utc": 1690140720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I'm working on an DataScience and ML University project, and I'd like to work  with Google Ads campaigns data. Does anyone know where I can find some  recent data? I'd like to address questions related to campaign costs,  returns, and expectations. For example, what could be my income if I  spend 100 dollars on a specific campaign? Thank you and i hope you can help me  \n", "author_fullname": "t2_7kn7dtuj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datasets de Google ads campaigns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157lxdb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690136166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I&amp;#39;m working on an DataScience and ML University project, and I&amp;#39;d like to work  with Google Ads campaigns data. Does anyone know where I can find some  recent data? I&amp;#39;d like to address questions related to campaign costs,  returns, and expectations. For example, what could be my income if I  spend 100 dollars on a specific campaign? Thank you and i hope you can help me  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157lxdb", "is_robot_indexable": true, "report_reasons": null, "author": "Ornery_Influence8875", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157lxdb/datasets_de_google_ads_campaigns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157lxdb/datasets_de_google_ads_campaigns/", "subreddit_subscribers": 958561, "created_utc": 1690136166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Keeping it short!\n\nI have a computer engineering background, 3 years as a developer, and 2 DevOps, currently working as a Project Manager for 2 years - aged 29.   \n\n\nSince I'm feeling great now as a Project Manager, I want to start specializing in a niche, and I am looking mostly into Data and/or Cloud Technologies, hence I've got 3 questions!  \n\n\n1. Can someone draw me a starting line (e.g. if it's a course send me the link)? Consider me a beginner even though I am familiar with databases, AWS Cloud mostly, etc.\n2. Can I find some project(s) or platform(s) I can even work for around 2h per day for free just to practice?\n3. Which is the cheapest cloud provider to start working with data (AWS vs. GCP vs. Azure, or something else)?\n\nYour help will be appreciated!", "author_fullname": "t2_5439wehf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Project Manager aiming on finding his specialty niche, can you help me with these 3 questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ifs9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690127863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Keeping it short!&lt;/p&gt;\n\n&lt;p&gt;I have a computer engineering background, 3 years as a developer, and 2 DevOps, currently working as a Project Manager for 2 years - aged 29.   &lt;/p&gt;\n\n&lt;p&gt;Since I&amp;#39;m feeling great now as a Project Manager, I want to start specializing in a niche, and I am looking mostly into Data and/or Cloud Technologies, hence I&amp;#39;ve got 3 questions!  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can someone draw me a starting line (e.g. if it&amp;#39;s a course send me the link)? Consider me a beginner even though I am familiar with databases, AWS Cloud mostly, etc.&lt;/li&gt;\n&lt;li&gt;Can I find some project(s) or platform(s) I can even work for around 2h per day for free just to practice?&lt;/li&gt;\n&lt;li&gt;Which is the cheapest cloud provider to start working with data (AWS vs. GCP vs. Azure, or something else)?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Your help will be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157ifs9", "is_robot_indexable": true, "report_reasons": null, "author": "albion_shala", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157ifs9/a_project_manager_aiming_on_finding_his_specialty/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157ifs9/a_project_manager_aiming_on_finding_his_specialty/", "subreddit_subscribers": 958561, "created_utc": 1690127863.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Wanting to get into data science, but not sure if the best way. I have no tech background, except for a bit of stats. Bootcamps seem very touch and go and leaning on my own might be a waste of time if I focus on the wrong stuff. Didn\u2019t know if this degree and doing some personal/volunteer projects to build up a portfolio would be the way to go. Any input appreciated. Thanks!", "author_fullname": "t2_bf6kfyxc0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WGU for data science degree worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157he0v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690125335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanting to get into data science, but not sure if the best way. I have no tech background, except for a bit of stats. Bootcamps seem very touch and go and leaning on my own might be a waste of time if I focus on the wrong stuff. Didn\u2019t know if this degree and doing some personal/volunteer projects to build up a portfolio would be the way to go. Any input appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157he0v", "is_robot_indexable": true, "report_reasons": null, "author": "vacanthorizon1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157he0v/wgu_for_data_science_degree_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157he0v/wgu_for_data_science_degree_worth_it/", "subreddit_subscribers": 958561, "created_utc": 1690125335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello fellow redditors!\n\nCan someone tell me how to deploy a streamlit app to railway?", "author_fullname": "t2_ue0qb0lb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help deploying a Streamlit app to Railway.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157b9dj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690107894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow redditors!&lt;/p&gt;\n\n&lt;p&gt;Can someone tell me how to deploy a streamlit app to railway?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157b9dj", "is_robot_indexable": true, "report_reasons": null, "author": "Soft-Wish9738", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157b9dj/need_help_deploying_a_streamlit_app_to_railway/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157b9dj/need_help_deploying_a_streamlit_app_to_railway/", "subreddit_subscribers": 958561, "created_utc": 1690107894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a beginner and know very little about python. I am looking for some online platforms to practice and learn python for data science. Any suggestions will be appreciated.", "author_fullname": "t2_6h0lwgdl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online coding practice Python - Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1571ur7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690077184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a beginner and know very little about python. I am looking for some online platforms to practice and learn python for data science. Any suggestions will be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1571ur7", "is_robot_indexable": true, "report_reasons": null, "author": "Spiralcandles", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1571ur7/online_coding_practice_python_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1571ur7/online_coding_practice_python_data_science/", "subreddit_subscribers": 958561, "created_utc": 1690077184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a CS freshman from South America and i have been getting into Data and some ML stuff recently.\n\nA big goal of mine is to be able to find remote work with US and EU companies and get paid in USD while working in SA.\n\nI heard that in this area DS, Data analytics and DE are harder to find opportunities if compared to regular development, is that true? Will it be really hard to find such opportunities and maybe data isnt for me if thats my main goal?", "author_fullname": "t2_7xe340s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opportunities for remote offshoring in DS and DE positions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157m39g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690136545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a CS freshman from South America and i have been getting into Data and some ML stuff recently.&lt;/p&gt;\n\n&lt;p&gt;A big goal of mine is to be able to find remote work with US and EU companies and get paid in USD while working in SA.&lt;/p&gt;\n\n&lt;p&gt;I heard that in this area DS, Data analytics and DE are harder to find opportunities if compared to regular development, is that true? Will it be really hard to find such opportunities and maybe data isnt for me if thats my main goal?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157m39g", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPineapples7791", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157m39g/opportunities_for_remote_offshoring_in_ds_and_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157m39g/opportunities_for_remote_offshoring_in_ds_and_de/", "subreddit_subscribers": 958561, "created_utc": 1690136545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I\u2019ve been trying to parse through Reddit and many other sources as to get a feel for how hard getting a job in Data Science will be. This Reddit is very negative in terms of expectations and chances to get a job based on scrolling through posts in here but I\u2019m sure that\u2019s due in large part to response bias, so I wanted to possibly hear other perspectives more tailored towards my specific situation.\n\nI have completed my BS in Stats and am completing my MS in Stats this upcoming school year and have had one data analyst internship. Skills wise I\u2019m fairly advanced in R, proficient in Python SQL and Tableau. Portfolio wise I have one complete end to end project and a couple other less intensive projects. Having a more heavy stats background I\u2019m definitely more solid on the theoretical side rather than the coding side.\n\nIm located in California and will look for jobs here first.", "author_fullname": "t2_55og4tpi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Realistic Job Search Expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157le7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690134949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I\u2019ve been trying to parse through Reddit and many other sources as to get a feel for how hard getting a job in Data Science will be. This Reddit is very negative in terms of expectations and chances to get a job based on scrolling through posts in here but I\u2019m sure that\u2019s due in large part to response bias, so I wanted to possibly hear other perspectives more tailored towards my specific situation.&lt;/p&gt;\n\n&lt;p&gt;I have completed my BS in Stats and am completing my MS in Stats this upcoming school year and have had one data analyst internship. Skills wise I\u2019m fairly advanced in R, proficient in Python SQL and Tableau. Portfolio wise I have one complete end to end project and a couple other less intensive projects. Having a more heavy stats background I\u2019m definitely more solid on the theoretical side rather than the coding side.&lt;/p&gt;\n\n&lt;p&gt;Im located in California and will look for jobs here first.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157le7v", "is_robot_indexable": true, "report_reasons": null, "author": "Monku5427", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157le7v/realistic_job_search_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157le7v/realistic_job_search_expectations/", "subreddit_subscribers": 958561, "created_utc": 1690134949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been analyzing a specific dataset in Tableau for work (highly retained users vs churned out). Ive reached the limits of what tableau can do, and it's time to go to linear regression to see if there's any signal here about what causes retention/churn.\nMy dataset is 3.5 million rows and 20 columns. When I try to export it to a pandas dataframe (straight from Big query) it's takes a long time.\nWhat should I do? Work with all 3.5M in pandas? Take a proportional sample from each population? 50-50 split (highly retained is only 10% of the overall population)?", "author_fullname": "t2_13b1f3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Select dataset for pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157bfv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690108467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been analyzing a specific dataset in Tableau for work (highly retained users vs churned out). Ive reached the limits of what tableau can do, and it&amp;#39;s time to go to linear regression to see if there&amp;#39;s any signal here about what causes retention/churn.\nMy dataset is 3.5 million rows and 20 columns. When I try to export it to a pandas dataframe (straight from Big query) it&amp;#39;s takes a long time.\nWhat should I do? Work with all 3.5M in pandas? Take a proportional sample from each population? 50-50 split (highly retained is only 10% of the overall population)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157bfv5", "is_robot_indexable": true, "report_reasons": null, "author": "aaquad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157bfv5/select_dataset_for_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157bfv5/select_dataset_for_pandas/", "subreddit_subscribers": 958561, "created_utc": 1690108467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, Im going for my first sem at RMIT this year, I chose the IT Major, Im considering between Software and web development or Cyper security. Can you guys give me some advices about that. Like which program or online course or which code language I should prepare from now. Thank you.", "author_fullname": "t2_g1yei4thn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IT major questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1579mnb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690102425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, Im going for my first sem at RMIT this year, I chose the IT Major, Im considering between Software and web development or Cyper security. Can you guys give me some advices about that. Like which program or online course or which code language I should prepare from now. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1579mnb", "is_robot_indexable": true, "report_reasons": null, "author": "lifeizsuk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1579mnb/it_major_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1579mnb/it_major_questions/", "subreddit_subscribers": 958561, "created_utc": 1690102425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi zusammen, \n\nIch konnte meine Bachelorarbeit nicht vorher anfangen. Leider nicht aufgrund kleiner Weltschmerz Weh Wehchen, sondern weil eine Person, die mir nahe stand gestorben ist, ich meine Wohnung verloren habe, mein Laptop und alle Daten futsch sind, meine romantische Beziehung in die Br\u00fcche gegangen ist und ich nebenbei Teilzeit arbeite. \n\nDas Problem: ich habe noch 7 Wochen Zeit alles in den Kasten zu bekommen. Ich habe eine Gliederung, solide Fragestellung und die H\u00e4lfte meiner Datenarbeit und den Methodenteil fertig. Ich muss mich jetzt vor allem an die Theorie setzen, alles schreiben und recherchieren und den Rest der Datenarbeit fertig bekommen, ich habe eine brutale Angst nicht fertig zu werden. \n\nMein Studium ist meine absolute Leidenschaft und es gibt nichts was mich mehr erf\u00fcllt, daher m\u00f6chte ich die Arbeit nicht in den Sand setzen. In mir kommen \u00c4ngste des Versagens hoch (ich habe einen Migrationshintergrund, in einem nicht-Akademiker Haushalt gro\u00df geworden). Durch mein zum Gl\u00fcck viel zu lang gewordenes Expos\u00e9 habe ich den Methdoenteil (vollst\u00e4ndig), einen Teil der Theorie und wei\u00df zumindest das ein Teil der Datenarbeit funktioniert. \n\nIch habe \u00fcber die Jahre sehr sehr hart f\u00fcr meinen Abschluss gek\u00e4mpft und komme nicht aus dem Gedanken raus nun alles verloren zu haben.. \n\nIst das in 7 Wochen zu schaffen, oder bin ich total realit\u00e4tsfremd?", "author_fullname": "t2_g3fpvnvvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "0815 Selfhelp, Bitte um Rat: Bachelor-Arbeit Dilemma", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_157sq8e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690152375.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690152186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi zusammen, &lt;/p&gt;\n\n&lt;p&gt;Ich konnte meine Bachelorarbeit nicht vorher anfangen. Leider nicht aufgrund kleiner Weltschmerz Weh Wehchen, sondern weil eine Person, die mir nahe stand gestorben ist, ich meine Wohnung verloren habe, mein Laptop und alle Daten futsch sind, meine romantische Beziehung in die Br\u00fcche gegangen ist und ich nebenbei Teilzeit arbeite. &lt;/p&gt;\n\n&lt;p&gt;Das Problem: ich habe noch 7 Wochen Zeit alles in den Kasten zu bekommen. Ich habe eine Gliederung, solide Fragestellung und die H\u00e4lfte meiner Datenarbeit und den Methodenteil fertig. Ich muss mich jetzt vor allem an die Theorie setzen, alles schreiben und recherchieren und den Rest der Datenarbeit fertig bekommen, ich habe eine brutale Angst nicht fertig zu werden. &lt;/p&gt;\n\n&lt;p&gt;Mein Studium ist meine absolute Leidenschaft und es gibt nichts was mich mehr erf\u00fcllt, daher m\u00f6chte ich die Arbeit nicht in den Sand setzen. In mir kommen \u00c4ngste des Versagens hoch (ich habe einen Migrationshintergrund, in einem nicht-Akademiker Haushalt gro\u00df geworden). Durch mein zum Gl\u00fcck viel zu lang gewordenes Expos\u00e9 habe ich den Methdoenteil (vollst\u00e4ndig), einen Teil der Theorie und wei\u00df zumindest das ein Teil der Datenarbeit funktioniert. &lt;/p&gt;\n\n&lt;p&gt;Ich habe \u00fcber die Jahre sehr sehr hart f\u00fcr meinen Abschluss gek\u00e4mpft und komme nicht aus dem Gedanken raus nun alles verloren zu haben.. &lt;/p&gt;\n\n&lt;p&gt;Ist das in 7 Wochen zu schaffen, oder bin ich total realit\u00e4tsfremd?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157sq8e", "is_robot_indexable": true, "report_reasons": null, "author": "Alone_Rush_2206", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157sq8e/0815_selfhelp_bitte_um_rat_bachelorarbeit_dilemma/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157sq8e/0815_selfhelp_bitte_um_rat_bachelorarbeit_dilemma/", "subreddit_subscribers": 958561, "created_utc": 1690152186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do i need to learn Scala as Data Scientists?", "author_fullname": "t2_qposd3eu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do i need to learn Scala as Data Scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157emen", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690122363.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690118164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do i need to learn Scala as Data Scientists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157emen", "is_robot_indexable": true, "report_reasons": null, "author": "zzzzzzyyyyyyy", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157emen/do_i_need_to_learn_scala_as_data_scientists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157emen/do_i_need_to_learn_scala_as_data_scientists/", "subreddit_subscribers": 958561, "created_utc": 1690118164.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}