{"kind": "Listing", "data": {"after": "t3_157emen", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been stuck on the following problem for weeks now. To be clear I'm not asking the community to provide a full solution. Just a few ideas or at least confirmation on whether this problem statement is solvable with the data available at hand. Thanks.\n\n**Context:** I work for a company that rents out stuff. During user checkout, there's a rule-based risk engine that determines whether to auto-approve user (takes seconds) or send for manual approval (takes days). This engine utilizes only basic features such as credit score, rent items category, cart value etc. Lets say that around 40% of all instances go to manual approval. Actual rejection rate is around 1-2% that means most of the cases sent for manual approval could have just been auto-approved.\n\n**Objective:** Reduce dependency on manual approval as much as possible (to lets say 5%). If this was a binary classification task (manual or not) then we'd say recall is important here. Thus, deprecate legacy system as it is too rudimentary.\n\nNow, boss wants me to achieve this by creating a regression model using customer credit history, and purchase history to predict ***maximum allowed***  ^(\u2020)***active-sourcing-cost per user***. So that if a user tries checking out cart that brings their total active sourcing cost above their max allowed limit, they will be sent for manual approval instead of auto-approve.\n\n&gt;^(\u2020)*active-sourcing-cost is the total purchase cost to company of all items the user currently is renting*\n\n**Data available:** User purchase history, user credit history (experian), product details, NPA data (data of users who failed to return the items they have rented, thus defaulted)\n\n**Issues with proposed solution:**\n\n1. Max allowed sourcing cost per user unavailable as the target variable (No recorded ground truth for any samples)\n2. No relevant proxy variables available as ground truth (that I can think of)\n\nTried explaining that lack of relevant ground truth is an issue. But am being pushed for a solution so have to produce.\n\n**My alternate half-baked solution:**\n\n1. Use legacy system for auto approvals only. This acts as a filter.\n2. To the rest of the data that would otherwise be sent for manual verification we add NPA users and tag as a negative class. This would be the training data.\n3. Train binary classification model (npa vs. not npa).\n4. What the model classifies as NPA would then be sent for manual, rest will be auto approved.\n\n&amp;#x200B;", "author_fullname": "t2_40233m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Been stuck on a problem. Just need to know whether this problem statement is solvable or not.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15753qp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690087252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been stuck on the following problem for weeks now. To be clear I&amp;#39;m not asking the community to provide a full solution. Just a few ideas or at least confirmation on whether this problem statement is solvable with the data available at hand. Thanks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt; I work for a company that rents out stuff. During user checkout, there&amp;#39;s a rule-based risk engine that determines whether to auto-approve user (takes seconds) or send for manual approval (takes days). This engine utilizes only basic features such as credit score, rent items category, cart value etc. Lets say that around 40% of all instances go to manual approval. Actual rejection rate is around 1-2% that means most of the cases sent for manual approval could have just been auto-approved.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Objective:&lt;/strong&gt; Reduce dependency on manual approval as much as possible (to lets say 5%). If this was a binary classification task (manual or not) then we&amp;#39;d say recall is important here. Thus, deprecate legacy system as it is too rudimentary.&lt;/p&gt;\n\n&lt;p&gt;Now, boss wants me to achieve this by creating a regression model using customer credit history, and purchase history to predict &lt;strong&gt;&lt;em&gt;maximum allowed&lt;/em&gt;&lt;/strong&gt;  &lt;sup&gt;\u2020&lt;/sup&gt;&lt;strong&gt;&lt;em&gt;active-sourcing-cost per user&lt;/em&gt;&lt;/strong&gt;. So that if a user tries checking out cart that brings their total active sourcing cost above their max allowed limit, they will be sent for manual approval instead of auto-approve.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;sup&gt;\u2020&lt;/sup&gt;&lt;em&gt;active-sourcing-cost is the total purchase cost to company of all items the user currently is renting&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;Data available:&lt;/strong&gt; User purchase history, user credit history (experian), product details, NPA data (data of users who failed to return the items they have rented, thus defaulted)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Issues with proposed solution:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Max allowed sourcing cost per user unavailable as the target variable (No recorded ground truth for any samples)&lt;/li&gt;\n&lt;li&gt;No relevant proxy variables available as ground truth (that I can think of)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Tried explaining that lack of relevant ground truth is an issue. But am being pushed for a solution so have to produce.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My alternate half-baked solution:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use legacy system for auto approvals only. This acts as a filter.&lt;/li&gt;\n&lt;li&gt;To the rest of the data that would otherwise be sent for manual verification we add NPA users and tag as a negative class. This would be the training data.&lt;/li&gt;\n&lt;li&gt;Train binary classification model (npa vs. not npa).&lt;/li&gt;\n&lt;li&gt;What the model classifies as NPA would then be sent for manual, rest will be auto approved.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15753qp", "is_robot_indexable": true, "report_reasons": null, "author": "CrypticTac", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15753qp/been_stuck_on_a_problem_just_need_to_know_whether/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15753qp/been_stuck_on_a_problem_just_need_to_know_whether/", "subreddit_subscribers": 958389, "created_utc": 1690087252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. \n\nWhat are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?", "author_fullname": "t2_dv159drh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does Data Engineering belong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157j2zn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690129380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. &lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157j2zn", "is_robot_indexable": true, "report_reasons": null, "author": "Sad-Fail-5337", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157j2zn/where_does_data_engineering_belong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157j2zn/where_does_data_engineering_belong/", "subreddit_subscribers": 958389, "created_utc": 1690129380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working on a new implementation of Agglomerative clustering called Reciprocal Agglomerative Clustering (RAC) based off of this paper: [https://arxiv.org/abs/2105.11653](https://arxiv.org/abs/2105.11653). The short of it is Agglomerative clustering can be broken down into finding and merging pairs of reciprocal nearest neighbors in parallel, as long as the linkage function is one of the following:\n\n* Single\n* Average\n* Complete\n* Ward\n\nMost importantly, RAC *produces the exact same results as traditional Agglomerative clustering when the dataset is fully connected.* Even with connectivity constraints, the results are almost always the same.\n\nThe authors showed that RAC has a linear runtime when connectivity is limited to k and the distance matrix is precomputed. I have not added the ability to pass in the distance matrix yet, so the runtime is roughly quadratic, which is still a major improvement over the cubic runtime of Agglomerative clustering. In addition the entire algorithm is parallelized, and so can scale up to more and more cores.\n\nIt's very much in development - only average linkage works at the moment, however, I think it has a lot of potential. The benchmarks have blown me away so far:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/bbjxw0qsyodb1.png?width=850&amp;format=png&amp;auto=webp&amp;s=4bcdd014aea6ac14eca51d9c7403dadda2e4012e\n\nHere is the code: [https://github.com/porterehunley/RACplusplus](https://github.com/porterehunley/RACplusplus). It would be great to have some people try it out (and find the bugs)!", "author_fullname": "t2_n63m16v8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] I created a parallelized implementation of Agglomerative clustering that's many times faster than existing implementations and has a better runtime", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bbjxw0qsyodb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=46cd69b3b26d632620779a7b51d511769a4d6053"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=590cf437e74b1e487bc71875e5c73d606bca59be"}, {"y": 205, "x": 320, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b015a76a9ea58d78f72958eda6a493884757e4c6"}, {"y": 410, "x": 640, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=30a645af0740616051dd760751ea8c75c0a86bb2"}], "s": {"y": 545, "x": 850, "u": "https://preview.redd.it/bbjxw0qsyodb1.png?width=850&amp;format=png&amp;auto=webp&amp;s=4bcdd014aea6ac14eca51d9c7403dadda2e4012e"}, "id": "bbjxw0qsyodb1"}}, "name": "t3_157bax6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QnX1OEC5i7I5fYXeuKfzrEZp-gXBNdbzXndyyLr3lUw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1690108031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on a new implementation of Agglomerative clustering called Reciprocal Agglomerative Clustering (RAC) based off of this paper: &lt;a href=\"https://arxiv.org/abs/2105.11653\"&gt;https://arxiv.org/abs/2105.11653&lt;/a&gt;. The short of it is Agglomerative clustering can be broken down into finding and merging pairs of reciprocal nearest neighbors in parallel, as long as the linkage function is one of the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Single&lt;/li&gt;\n&lt;li&gt;Average&lt;/li&gt;\n&lt;li&gt;Complete&lt;/li&gt;\n&lt;li&gt;Ward&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Most importantly, RAC &lt;em&gt;produces the exact same results as traditional Agglomerative clustering when the dataset is fully connected.&lt;/em&gt; Even with connectivity constraints, the results are almost always the same.&lt;/p&gt;\n\n&lt;p&gt;The authors showed that RAC has a linear runtime when connectivity is limited to k and the distance matrix is precomputed. I have not added the ability to pass in the distance matrix yet, so the runtime is roughly quadratic, which is still a major improvement over the cubic runtime of Agglomerative clustering. In addition the entire algorithm is parallelized, and so can scale up to more and more cores.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s very much in development - only average linkage works at the moment, however, I think it has a lot of potential. The benchmarks have blown me away so far:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bbjxw0qsyodb1.png?width=850&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4bcdd014aea6ac14eca51d9c7403dadda2e4012e\"&gt;https://preview.redd.it/bbjxw0qsyodb1.png?width=850&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4bcdd014aea6ac14eca51d9c7403dadda2e4012e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is the code: &lt;a href=\"https://github.com/porterehunley/RACplusplus\"&gt;https://github.com/porterehunley/RACplusplus&lt;/a&gt;. It would be great to have some people try it out (and find the bugs)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?auto=webp&amp;s=f1cd025aeb52ffa82fc9e5a4a2f157da0d919147", "width": 1200, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2711d572cfc6c713893cf24e8c4a7344d5ad8a4c", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6624f0c1eedc14997e7f1780efbe6e5cb50c1e2", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9db38144ef3065833b9ba158c764f7be47de3016", "width": 320, "height": 186}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075", "width": 640, "height": 373}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2637f961ee21190172b9ca6c8adf3ac9612db083", "width": 960, "height": 560}, {"url": "https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=782eead871df2939a587ee3beae442cc59282f64", "width": 1080, "height": 630}], "variants": {}, "id": "q3evP6JeDpAC2MdSQHWYxnCYTqbJkElIQsLFqVSdkss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "157bax6", "is_robot_indexable": true, "report_reasons": null, "author": "Ridaleneas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157bax6/p_i_created_a_parallelized_implementation_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157bax6/p_i_created_a_parallelized_implementation_of/", "subreddit_subscribers": 958389, "created_utc": 1690108031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_cooe3jwwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Give Me All The Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_157njgu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Xd2nkcuS1B2o5ASlY0vEuh_aweWF4zqhybvqwVwZu0U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690139933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1tk1ev1plrdb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1tk1ev1plrdb1.png?auto=webp&amp;s=224d46517d2fcbad3896cbee29b6f24983e3b1b3", "width": 1233, "height": 1280}, "resolutions": [{"url": "https://preview.redd.it/1tk1ev1plrdb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=345f0521ed9daec1d0c33b1e5c5bf3c33f0f654e", "width": 108, "height": 112}, {"url": "https://preview.redd.it/1tk1ev1plrdb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=560a0b4e5d783753e22eabc825beed4c3dff4f54", "width": 216, "height": 224}, {"url": "https://preview.redd.it/1tk1ev1plrdb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=662b803303e15644e3cfd1e133e971d3a65abdf3", "width": 320, "height": 332}, {"url": "https://preview.redd.it/1tk1ev1plrdb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=09b0b5d67492af2eb2e46728aa6d4449b777fb26", "width": 640, "height": 664}, {"url": "https://preview.redd.it/1tk1ev1plrdb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=561434bf2f1db33449e5fa0d0488bcd877cdc927", "width": 960, "height": 996}, {"url": "https://preview.redd.it/1tk1ev1plrdb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e0270af477afb972d0cc0e2efc0ef4ae98cb5d94", "width": 1080, "height": 1121}], "variants": {}, "id": "6B3ePBwXcxBhMjaTw9HFpFbCJv6gCLoSR54l9Vnco3g"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "157njgu", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent_Shape_691", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157njgu/give_me_all_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1tk1ev1plrdb1.png", "subreddit_subscribers": 958389, "created_utc": 1690139933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_xj5pb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Decoding the ACL Paper: Gzip and KNN Rival BERT in Text Classification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1579qy7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ll4r9_pwUGqg72AsM1LP1Rqusl158PoU5ZvAIpQdb6A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690102828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "codeconfessions.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://codeconfessions.substack.com/p/decoding-the-acl-paper-gzip-and-knn", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?auto=webp&amp;s=8869decfb98ee3f81c132ceccdcd226bc52a1665", "width": 1080, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38fdaad8619c80598f8180411e4ad66936cf670b", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=210dc8f4fa7627f9296df82ed8dd8c1b8ff5f118", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2714fd534001d06506681c49788e47f89957eb3", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=056302bd549a22f1471808140b3511781123e059", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bcf72e791d030d9291cfd071cc82bd38468f08b8", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/BNJNjygjI26Qzq618gBHHaEs_8q8mubtji6R2f416OM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e972c7057a494dc0e2ff3feb0750b72ad72196b1", "width": 1080, "height": 720}], "variants": {}, "id": "nF766ThFN6J1Dv_cSr4PSjoVHitYsK4g5cWriwI18Dg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1579qy7", "is_robot_indexable": true, "report_reasons": null, "author": "abhi9u", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1579qy7/decoding_the_acl_paper_gzip_and_knn_rival_bert_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://codeconfessions.substack.com/p/decoding-the-acl-paper-gzip-and-knn", "subreddit_subscribers": 958389, "created_utc": 1690102828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, so I am currently a data analyst of 3 years, and I am trying to work towards a Data Scientist / Machine Learning Engineer sort of role. \n\nIn my current role I build dashboards using Tableau and SQL to inform business decisions, and in a previous time I did the same using Python. I have some knowledge with ML models from the Boot camp I attended, and I had done a few Kaggle style DS projects. I am also going to do an online master's with Georgia Tech. \n\nObviously I know my experiences so far wouldn't be enough to land me in my dream job, but I have been aiming for Data Analyst roles in companies using with a dedicated Data team where I'd be working under a Data Scientist or otherwise helping support a ML product. However, all my applications have been turning up short so far. \n\nI am wondering if there's something I'm missing or otherwise need to work on? Or things I should do to improve my chances? What are some good ways to network beyond LinkedIn cold messaging? \n\nThanks in advance!", "author_fullname": "t2_15atwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for a data analyst hoping to progress?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156u5vq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690057149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, so I am currently a data analyst of 3 years, and I am trying to work towards a Data Scientist / Machine Learning Engineer sort of role. &lt;/p&gt;\n\n&lt;p&gt;In my current role I build dashboards using Tableau and SQL to inform business decisions, and in a previous time I did the same using Python. I have some knowledge with ML models from the Boot camp I attended, and I had done a few Kaggle style DS projects. I am also going to do an online master&amp;#39;s with Georgia Tech. &lt;/p&gt;\n\n&lt;p&gt;Obviously I know my experiences so far wouldn&amp;#39;t be enough to land me in my dream job, but I have been aiming for Data Analyst roles in companies using with a dedicated Data team where I&amp;#39;d be working under a Data Scientist or otherwise helping support a ML product. However, all my applications have been turning up short so far. &lt;/p&gt;\n\n&lt;p&gt;I am wondering if there&amp;#39;s something I&amp;#39;m missing or otherwise need to work on? Or things I should do to improve my chances? What are some good ways to network beyond LinkedIn cold messaging? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "156u5vq", "is_robot_indexable": true, "report_reasons": null, "author": "GiliGiliAi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/156u5vq/advice_for_a_data_analyst_hoping_to_progress/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/156u5vq/advice_for_a_data_analyst_hoping_to_progress/", "subreddit_subscribers": 958389, "created_utc": 1690057149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm not a Data scientist but I do have a few questions for you all. I just saw oppenheimer which, no spoilers, simply revolves around the Manhattan project and the creation of nuclear bombs. \n\nBack in the day, weren't data scientists just the physicists and chemists and mathematicians who did their own studies? Or was there a specific role for someone who handles all the data and does something else with it?", "author_fullname": "t2_f4m0dd2qo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just saw oppenheimer, did data scientists exist back then?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157m5sj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690136715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not a Data scientist but I do have a few questions for you all. I just saw oppenheimer which, no spoilers, simply revolves around the Manhattan project and the creation of nuclear bombs. &lt;/p&gt;\n\n&lt;p&gt;Back in the day, weren&amp;#39;t data scientists just the physicists and chemists and mathematicians who did their own studies? Or was there a specific role for someone who handles all the data and does something else with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157m5sj", "is_robot_indexable": true, "report_reasons": null, "author": "Sacred_Tomato", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157m5sj/just_saw_oppenheimer_did_data_scientists_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157m5sj/just_saw_oppenheimer_did_data_scientists_exist/", "subreddit_subscribers": 958389, "created_utc": 1690136715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1546d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know where I can find a dataset that I can use to gauge insights or use as a proxy for US sentiment towards China?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1571yaa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690077480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1571yaa", "is_robot_indexable": true, "report_reasons": null, "author": "raks1811", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1571yaa/does_anyone_know_where_i_can_find_a_dataset_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1571yaa/does_anyone_know_where_i_can_find_a_dataset_that/", "subreddit_subscribers": 958389, "created_utc": 1690077480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lots of existing datasets contain some sort of textual data which is usually overlooked because it is hard to work with. The recent advancement in AI (GPT-like models) make it possible to extract valuable data easily (examples: various specifications, names, dates, prices, etc) - converting free texts into tabular data. Example tools: the incredible [Textraction.ai](https://www.textraction.ai/), engineered ChatGPT prompts, etc.\n\n**Have you already used such tools to do that? Which datasets have the highest potential?**\n\nSome examples that come to my mind:\n\n* Medical datasets that often contain a free text describing symptoms, diagnosis, prescriptions, etc.\n* E-commerce products descriptions.\n* Real estate posts listings.\n* Automatically filling forms for the user based on free text.\n\nThese new tools open up a wide range of new applications now made possible.", "author_fullname": "t2_mqeuzn8j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Text Data Mining to Enrich Existing Datasets Using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157fgnd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690120860.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690120509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lots of existing datasets contain some sort of textual data which is usually overlooked because it is hard to work with. The recent advancement in AI (GPT-like models) make it possible to extract valuable data easily (examples: various specifications, names, dates, prices, etc) - converting free texts into tabular data. Example tools: the incredible &lt;a href=\"https://www.textraction.ai/\"&gt;Textraction.ai&lt;/a&gt;, engineered ChatGPT prompts, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Have you already used such tools to do that? Which datasets have the highest potential?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Some examples that come to my mind:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Medical datasets that often contain a free text describing symptoms, diagnosis, prescriptions, etc.&lt;/li&gt;\n&lt;li&gt;E-commerce products descriptions.&lt;/li&gt;\n&lt;li&gt;Real estate posts listings.&lt;/li&gt;\n&lt;li&gt;Automatically filling forms for the user based on free text.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These new tools open up a wide range of new applications now made possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157fgnd", "is_robot_indexable": true, "report_reasons": null, "author": "DoorDesigner7589", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157fgnd/text_data_mining_to_enrich_existing_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157fgnd/text_data_mining_to_enrich_existing_datasets/", "subreddit_subscribers": 958389, "created_utc": 1690120509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have several datasets that share the same columns, but consist of completely different data points, and each come from a different source. All of these datasets are available on Kaggle.\n\n&amp;#x200B;\n\nI was wondering if there would be any issues that could arise from me downloading each dataset, combining them into on singular csv file, and then using that csv for a project. I understand that combining the data would be difficult as not all columns are equal, and there is a chance that I would end up with entire datasets be duplicated, but I assume this is a very good way to gather a ton of data points on one particular topic, correct?", "author_fullname": "t2_ebylq8bw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Combining Datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1575f95", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690088297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have several datasets that share the same columns, but consist of completely different data points, and each come from a different source. All of these datasets are available on Kaggle.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there would be any issues that could arise from me downloading each dataset, combining them into on singular csv file, and then using that csv for a project. I understand that combining the data would be difficult as not all columns are equal, and there is a chance that I would end up with entire datasets be duplicated, but I assume this is a very good way to gather a ton of data points on one particular topic, correct?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1575f95", "is_robot_indexable": true, "report_reasons": null, "author": "AI_rondo", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1575f95/combining_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1575f95/combining_datasets/", "subreddit_subscribers": 958389, "created_utc": 1690088297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Cost-effective too. ", "author_fullname": "t2_44tf9ypj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Ways to Put an R Shiny Dashboard into Prod for 1000+ to view daily?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157jtbr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690131147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Cost-effective too. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157jtbr", "is_robot_indexable": true, "report_reasons": null, "author": "PSM182", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157jtbr/best_ways_to_put_an_r_shiny_dashboard_into_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157jtbr/best_ways_to_put_an_r_shiny_dashboard_into_prod/", "subreddit_subscribers": 958389, "created_utc": 1690131147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hopefully this is an easy question.\n\nI have a dataset I am playing with to learn a few items. This is all done in Python with Pandas / scikit-learn:\n\n* 5 columns, all numeric\n* Removed all nan rows - all columns have numerical values, 0 NaNs\n* Run min-max normalization on these columns so they are all between 0 and 1\n* Run PCA (`sklearn.decomposition`) on these 5 columns to reduce them to 3.\n\nWhen I look at the numpy array that is being generated, of the ~5,600 row, about ~125 of them generate rows that are `NaN` for all 3 new columns.  Again, there were 0 rows with `NaN` before I ran the `PCA()`\n\nHow could this be? Why is this? What can I do to handle this?\n\nTYIA - looking for some quick mentorship as I learn something new :)", "author_fullname": "t2_82q1dekgx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for some mentorship: Why is my PCA returning NaN for all values in just some rows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_157omaa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690142438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hopefully this is an easy question.&lt;/p&gt;\n\n&lt;p&gt;I have a dataset I am playing with to learn a few items. This is all done in Python with Pandas / scikit-learn:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;5 columns, all numeric&lt;/li&gt;\n&lt;li&gt;Removed all nan rows - all columns have numerical values, 0 NaNs&lt;/li&gt;\n&lt;li&gt;Run min-max normalization on these columns so they are all between 0 and 1&lt;/li&gt;\n&lt;li&gt;Run PCA (&lt;code&gt;sklearn.decomposition&lt;/code&gt;) on these 5 columns to reduce them to 3.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;When I look at the numpy array that is being generated, of the ~5,600 row, about ~125 of them generate rows that are &lt;code&gt;NaN&lt;/code&gt; for all 3 new columns.  Again, there were 0 rows with &lt;code&gt;NaN&lt;/code&gt; before I ran the &lt;code&gt;PCA()&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;How could this be? Why is this? What can I do to handle this?&lt;/p&gt;\n\n&lt;p&gt;TYIA - looking for some quick mentorship as I learn something new :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157omaa", "is_robot_indexable": true, "report_reasons": null, "author": "3PurpleSectors", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157omaa/looking_for_some_mentorship_why_is_my_pca/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157omaa/looking_for_some_mentorship_why_is_my_pca/", "subreddit_subscribers": 958389, "created_utc": 1690142438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys,\n\n&amp;#x200B;\n\nIm 23 and my major in university is germanistik and i hate it, i wanna be a data scientist or a data engineer and i learned the basics of python like dictionaries lists tuples , learned the loops regular expressions, learned a few libraries like Beatifulsoup, pandas , (will add numpy too) and im rn learning SQL  from a coursera class called \"SQL for data science\" but i don't know what i can do more for developing myself in this field. (Comment if you an advice, im reading everything you guys write)\n\n&amp;#x200B;\n\nI'm trying to solve real life problems to test myself but I have no idea if they will take me seriously if I apply for internships or junior jobs.\n\n&amp;#x200B;\n\nIf you had an similar or same story please let me know and give me your advice (everything works!) \n\n&amp;#x200B;\n\nPeace.", "author_fullname": "t2_q2coljj8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sorry and thanks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_157oe3z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690141899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Im 23 and my major in university is germanistik and i hate it, i wanna be a data scientist or a data engineer and i learned the basics of python like dictionaries lists tuples , learned the loops regular expressions, learned a few libraries like Beatifulsoup, pandas , (will add numpy too) and im rn learning SQL  from a coursera class called &amp;quot;SQL for data science&amp;quot; but i don&amp;#39;t know what i can do more for developing myself in this field. (Comment if you an advice, im reading everything you guys write)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to solve real life problems to test myself but I have no idea if they will take me seriously if I apply for internships or junior jobs.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you had an similar or same story please let me know and give me your advice (everything works!) &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Peace.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157oe3z", "is_robot_indexable": true, "report_reasons": null, "author": "tatarisanu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157oe3z/sorry_and_thanks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157oe3z/sorry_and_thanks/", "subreddit_subscribers": 958389, "created_utc": 1690141899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a data set that boils down to Three clomuns: 1.Supplier name 2. Number of transactions with supplier 3. Total value of those transaction.\n\nI'm trying to find the best way to rank all suppliers based on these two features which are equally important in this case. \nNote: -more transaction doesn't mean more value\n\nWhat I did is I normalized each feature. Making all values scale down to 0 to 1. Then I added the 2 normalized values to each other. Then used this new values to rank all suppliers. Looking at the results and  what I expected a good ranking to be, I'm happy with the result.\n\nHowever, I feel like the existing of outliers might've made the ranking.. not as accurate as it can be. Am I right or wrong? How would you suggest fixing this? Is there an entierly better way to do this?\n\nFinal note: I tried standarizing and got the exact same ranking. I'm not sure if that was supposed to happen or if it was a special case.", "author_fullname": "t2_59mf5tbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would normalizing be affected by outliers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_157o4qn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690141303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data set that boils down to Three clomuns: 1.Supplier name 2. Number of transactions with supplier 3. Total value of those transaction.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to find the best way to rank all suppliers based on these two features which are equally important in this case. \nNote: -more transaction doesn&amp;#39;t mean more value&lt;/p&gt;\n\n&lt;p&gt;What I did is I normalized each feature. Making all values scale down to 0 to 1. Then I added the 2 normalized values to each other. Then used this new values to rank all suppliers. Looking at the results and  what I expected a good ranking to be, I&amp;#39;m happy with the result.&lt;/p&gt;\n\n&lt;p&gt;However, I feel like the existing of outliers might&amp;#39;ve made the ranking.. not as accurate as it can be. Am I right or wrong? How would you suggest fixing this? Is there an entierly better way to do this?&lt;/p&gt;\n\n&lt;p&gt;Final note: I tried standarizing and got the exact same ranking. I&amp;#39;m not sure if that was supposed to happen or if it was a special case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157o4qn", "is_robot_indexable": true, "report_reasons": null, "author": "kit_kaat", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157o4qn/how_would_normalizing_be_affected_by_outliers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157o4qn/how_would_normalizing_be_affected_by_outliers/", "subreddit_subscribers": 958389, "created_utc": 1690141303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am not a data science professional.\n\n&amp;#x200B;\n\nI work at a local government/Council department maintaining the local land and property register which is a map/database record of all the land and property with status e.g. occupied/under construction etc.\n\n&amp;#x200B;\n\nMostly i get the info for new developments from street naming and numbering department when they apply for an address. \n\n&amp;#x200B;\n\nHowever, it is the changes to status in existing properties which is hard - e.g. a business park with 50 units, when one of them becomes unnocupied or a new tenant moves in or a unit is split into two. Same with residential properties.\n\n&amp;#x200B;\n\nThe local commercial tax and residential tax departments plus the waste departmentsadminister all this but there is not much synchronisation. They don't have a common identifier for the property for and sometimes the address format might not match exactly so hard to match like for like. Talking about 100k properties.\n\n&amp;#x200B;\n\nWhat's the best way to get triggers of real world change from their data sets? Is their a smart solution here that is going to be easyish? I was thinking thingsan extract of all data sets and something like fuzzy look ups or similar to set up a common identifier so that we can baseline. I guess FME would be doable but I have only the most basic knowledge of that. I am more of a GIS person. Once we have baselined going forward what would be a good system on a weekly basis to synchronise these changes. We have different databases, formats, tools. Don't want to reinvent the wheel here, just want a solution that is practical and workable with limited technical knowledge.\n\n&amp;#x200B;\n\nMany Thanks \n\n&amp;#x200B;", "author_fullname": "t2_dzypkgpv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local Government data sets full of duplication - how to streamline/synchronise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_157nvjh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690140720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not a data science professional.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I work at a local government/Council department maintaining the local land and property register which is a map/database record of all the land and property with status e.g. occupied/under construction etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Mostly i get the info for new developments from street naming and numbering department when they apply for an address. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, it is the changes to status in existing properties which is hard - e.g. a business park with 50 units, when one of them becomes unnocupied or a new tenant moves in or a unit is split into two. Same with residential properties.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The local commercial tax and residential tax departments plus the waste departmentsadminister all this but there is not much synchronisation. They don&amp;#39;t have a common identifier for the property for and sometimes the address format might not match exactly so hard to match like for like. Talking about 100k properties.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way to get triggers of real world change from their data sets? Is their a smart solution here that is going to be easyish? I was thinking thingsan extract of all data sets and something like fuzzy look ups or similar to set up a common identifier so that we can baseline. I guess FME would be doable but I have only the most basic knowledge of that. I am more of a GIS person. Once we have baselined going forward what would be a good system on a weekly basis to synchronise these changes. We have different databases, formats, tools. Don&amp;#39;t want to reinvent the wheel here, just want a solution that is practical and workable with limited technical knowledge.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Many Thanks &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157nvjh", "is_robot_indexable": true, "report_reasons": null, "author": "omura777", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157nvjh/local_government_data_sets_full_of_duplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157nvjh/local_government_data_sets_full_of_duplication/", "subreddit_subscribers": 958389, "created_utc": 1690140720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a CS freshman from South America and i have been getting into Data and some ML stuff recently.\n\nA big goal of mine is to be able to find remote work with US and EU companies and get paid in USD while working in SA.\n\nI heard that in this area DS, Data analytics and DE are harder to find opportunities if compared to regular development, is that true? Will it be really hard to find such opportunities and maybe data isnt for me if thats my main goal?", "author_fullname": "t2_7xe340s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opportunities for remote offshoring in DS and DE positions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157m39g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690136545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a CS freshman from South America and i have been getting into Data and some ML stuff recently.&lt;/p&gt;\n\n&lt;p&gt;A big goal of mine is to be able to find remote work with US and EU companies and get paid in USD while working in SA.&lt;/p&gt;\n\n&lt;p&gt;I heard that in this area DS, Data analytics and DE are harder to find opportunities if compared to regular development, is that true? Will it be really hard to find such opportunities and maybe data isnt for me if thats my main goal?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157m39g", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPineapples7791", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157m39g/opportunities_for_remote_offshoring_in_ds_and_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157m39g/opportunities_for_remote_offshoring_in_ds_and_de/", "subreddit_subscribers": 958389, "created_utc": 1690136545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I'm working on an DataScience and ML University project, and I'd like to work  with Google Ads campaigns data. Does anyone know where I can find some  recent data? I'd like to address questions related to campaign costs,  returns, and expectations. For example, what could be my income if I  spend 100 dollars on a specific campaign? Thank you and i hope you can help me  \n", "author_fullname": "t2_7kn7dtuj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datasets de Google ads campaigns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157lxdb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690136166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I&amp;#39;m working on an DataScience and ML University project, and I&amp;#39;d like to work  with Google Ads campaigns data. Does anyone know where I can find some  recent data? I&amp;#39;d like to address questions related to campaign costs,  returns, and expectations. For example, what could be my income if I  spend 100 dollars on a specific campaign? Thank you and i hope you can help me  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157lxdb", "is_robot_indexable": true, "report_reasons": null, "author": "Ornery_Influence8875", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157lxdb/datasets_de_google_ads_campaigns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157lxdb/datasets_de_google_ads_campaigns/", "subreddit_subscribers": 958389, "created_utc": 1690136166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I\u2019ve been trying to parse through Reddit and many other sources as to get a feel for how hard getting a job in Data Science will be. This Reddit is very negative in terms of expectations and chances to get a job based on scrolling through posts in here but I\u2019m sure that\u2019s due in large part to response bias, so I wanted to possibly hear other perspectives more tailored towards my specific situation.\n\nI have completed my BS in Stats and am completing my MS in Stats this upcoming school year and have had one data analyst internship. Skills wise I\u2019m fairly advanced in R, proficient in Python SQL and Tableau. Portfolio wise I have one complete end to end project and a couple other less intensive projects. Having a more heavy stats background I\u2019m definitely more solid on the theoretical side rather than the coding side.\n\nIm located in California and will look for jobs here first.", "author_fullname": "t2_55og4tpi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Realistic Job Search Expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157le7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690134949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I\u2019ve been trying to parse through Reddit and many other sources as to get a feel for how hard getting a job in Data Science will be. This Reddit is very negative in terms of expectations and chances to get a job based on scrolling through posts in here but I\u2019m sure that\u2019s due in large part to response bias, so I wanted to possibly hear other perspectives more tailored towards my specific situation.&lt;/p&gt;\n\n&lt;p&gt;I have completed my BS in Stats and am completing my MS in Stats this upcoming school year and have had one data analyst internship. Skills wise I\u2019m fairly advanced in R, proficient in Python SQL and Tableau. Portfolio wise I have one complete end to end project and a couple other less intensive projects. Having a more heavy stats background I\u2019m definitely more solid on the theoretical side rather than the coding side.&lt;/p&gt;\n\n&lt;p&gt;Im located in California and will look for jobs here first.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157le7v", "is_robot_indexable": true, "report_reasons": null, "author": "Monku5427", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157le7v/realistic_job_search_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157le7v/realistic_job_search_expectations/", "subreddit_subscribers": 958389, "created_utc": 1690134949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Keeping it short!\n\nI have a computer engineering background, 3 years as a developer, and 2 DevOps, currently working as a Project Manager for 2 years - aged 29.   \n\n\nSince I'm feeling great now as a Project Manager, I want to start specializing in a niche, and I am looking mostly into Data and/or Cloud Technologies, hence I've got 3 questions!  \n\n\n1. Can someone draw me a starting line (e.g. if it's a course send me the link)? Consider me a beginner even though I am familiar with databases, AWS Cloud mostly, etc.\n2. Can I find some project(s) or platform(s) I can even work for around 2h per day for free just to practice?\n3. Which is the cheapest cloud provider to start working with data (AWS vs. GCP vs. Azure, or something else)?\n\nYour help will be appreciated!", "author_fullname": "t2_5439wehf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Project Manager aiming on finding his specialty niche, can you help me with these 3 questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ifs9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690127863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Keeping it short!&lt;/p&gt;\n\n&lt;p&gt;I have a computer engineering background, 3 years as a developer, and 2 DevOps, currently working as a Project Manager for 2 years - aged 29.   &lt;/p&gt;\n\n&lt;p&gt;Since I&amp;#39;m feeling great now as a Project Manager, I want to start specializing in a niche, and I am looking mostly into Data and/or Cloud Technologies, hence I&amp;#39;ve got 3 questions!  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can someone draw me a starting line (e.g. if it&amp;#39;s a course send me the link)? Consider me a beginner even though I am familiar with databases, AWS Cloud mostly, etc.&lt;/li&gt;\n&lt;li&gt;Can I find some project(s) or platform(s) I can even work for around 2h per day for free just to practice?&lt;/li&gt;\n&lt;li&gt;Which is the cheapest cloud provider to start working with data (AWS vs. GCP vs. Azure, or something else)?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Your help will be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157ifs9", "is_robot_indexable": true, "report_reasons": null, "author": "albion_shala", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157ifs9/a_project_manager_aiming_on_finding_his_specialty/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157ifs9/a_project_manager_aiming_on_finding_his_specialty/", "subreddit_subscribers": 958389, "created_utc": 1690127863.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Wanting to get into data science, but not sure if the best way. I have no tech background, except for a bit of stats. Bootcamps seem very touch and go and leaning on my own might be a waste of time if I focus on the wrong stuff. Didn\u2019t know if this degree and doing some personal/volunteer projects to build up a portfolio would be the way to go. Any input appreciated. Thanks!", "author_fullname": "t2_bf6kfyxc0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WGU for data science degree worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157he0v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690125335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanting to get into data science, but not sure if the best way. I have no tech background, except for a bit of stats. Bootcamps seem very touch and go and leaning on my own might be a waste of time if I focus on the wrong stuff. Didn\u2019t know if this degree and doing some personal/volunteer projects to build up a portfolio would be the way to go. Any input appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157he0v", "is_robot_indexable": true, "report_reasons": null, "author": "vacanthorizon1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157he0v/wgu_for_data_science_degree_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157he0v/wgu_for_data_science_degree_worth_it/", "subreddit_subscribers": 958389, "created_utc": 1690125335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello fellow redditors!\n\nCan someone tell me how to deploy a streamlit app to railway?", "author_fullname": "t2_ue0qb0lb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help deploying a Streamlit app to Railway.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157b9dj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690107894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow redditors!&lt;/p&gt;\n\n&lt;p&gt;Can someone tell me how to deploy a streamlit app to railway?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157b9dj", "is_robot_indexable": true, "report_reasons": null, "author": "Soft-Wish9738", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157b9dj/need_help_deploying_a_streamlit_app_to_railway/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157b9dj/need_help_deploying_a_streamlit_app_to_railway/", "subreddit_subscribers": 958389, "created_utc": 1690107894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a beginner and know very little about python. I am looking for some online platforms to practice and learn python for data science. Any suggestions will be appreciated.", "author_fullname": "t2_6h0lwgdl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online coding practice Python - Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1571ur7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690077184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a beginner and know very little about python. I am looking for some online platforms to practice and learn python for data science. Any suggestions will be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1571ur7", "is_robot_indexable": true, "report_reasons": null, "author": "Spiralcandles", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1571ur7/online_coding_practice_python_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1571ur7/online_coding_practice_python_data_science/", "subreddit_subscribers": 958389, "created_utc": 1690077184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Posting for my husband. He's a LIMS specialist in biotech. He designed and manages the data/sample pipeline and works in the supply chain side. He's a great manager and programmer but likes the big picture, process, data flow end of things. Strong with validation, planning, etc.\n\nWhat other industries would use these skills? Other job titles that may not be laboratory but use the same skillset. \n\n&amp;#x200B;\n\nthank you.", "author_fullname": "t2_byjoepei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "job titles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156ve12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690060183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Posting for my husband. He&amp;#39;s a LIMS specialist in biotech. He designed and manages the data/sample pipeline and works in the supply chain side. He&amp;#39;s a great manager and programmer but likes the big picture, process, data flow end of things. Strong with validation, planning, etc.&lt;/p&gt;\n\n&lt;p&gt;What other industries would use these skills? Other job titles that may not be laboratory but use the same skillset. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "156ve12", "is_robot_indexable": true, "report_reasons": null, "author": "3devo89", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/156ve12/job_titles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/156ve12/job_titles/", "subreddit_subscribers": 958389, "created_utc": 1690060183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9wds48ugd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone guide how to start with r shiny from basics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157h6sm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690124840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157h6sm", "is_robot_indexable": true, "report_reasons": null, "author": "Frequent-Product1158", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157h6sm/can_anyone_guide_how_to_start_with_r_shiny_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157h6sm/can_anyone_guide_how_to_start_with_r_shiny_from/", "subreddit_subscribers": 958389, "created_utc": 1690124840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do i need to learn Scala as Data Scientists?", "author_fullname": "t2_qposd3eu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do i need to learn Scala as Data Scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157emen", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690122363.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690118164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do i need to learn Scala as Data Scientists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157emen", "is_robot_indexable": true, "report_reasons": null, "author": "zzzzzzyyyyyyy", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157emen/do_i_need_to_learn_scala_as_data_scientists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157emen/do_i_need_to_learn_scala_as_data_scientists/", "subreddit_subscribers": 958389, "created_utc": 1690118164.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}