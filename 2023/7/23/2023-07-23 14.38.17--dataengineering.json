{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Related to any stage of the process. Or anything at all?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some common data engineering mistakes you\u2019ve seen in your career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1570ujm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690074320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Related to any stage of the process. Or anything at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1570ujm", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1570ujm/what_are_some_common_data_engineering_mistakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1570ujm/what_are_some_common_data_engineering_mistakes/", "subreddit_subscribers": 117498, "created_utc": 1690074320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In college a lot of time I spent taking handwritten notes and then doing practice exams or problem sets for economics, but I feel like I need a better way to study since I\u2019m self teaching when not working.\n\nMy questions is\n\n- is it even worth taking handwritten notes when coding or should I just read and try to do a problem right away \n- is there any time I should taken handwritten notes? Like maybe definitions for OOP, or data structures?\n\nI\u2019m just feeling pretty dumb because I\u2019m going through a Python book and I feel like it\u2019s taking me forever to get through using my old study habits.", "author_fullname": "t2_oasgyrv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To those who are self-taught coders/data engineers, how did you study?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156sgv3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690053001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In college a lot of time I spent taking handwritten notes and then doing practice exams or problem sets for economics, but I feel like I need a better way to study since I\u2019m self teaching when not working.&lt;/p&gt;\n\n&lt;p&gt;My questions is&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;is it even worth taking handwritten notes when coding or should I just read and try to do a problem right away &lt;/li&gt;\n&lt;li&gt;is there any time I should taken handwritten notes? Like maybe definitions for OOP, or data structures?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m just feeling pretty dumb because I\u2019m going through a Python book and I feel like it\u2019s taking me forever to get through using my old study habits.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "156sgv3", "is_robot_indexable": true, "report_reasons": null, "author": "Weary-Individual-309", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156sgv3/to_those_who_are_selftaught_codersdata_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156sgv3/to_those_who_are_selftaught_codersdata_engineers/", "subreddit_subscribers": 117498, "created_utc": 1690053001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seriously, I don't know where to begin. It's so annoying. I am not understanding the UI part of Microsoft fabrics. It's so click heavy. I am completely lost where to start and where to end.", "author_fullname": "t2_hnxu1e2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rant-Microsoft Fabric is most annoying POS I have ever used", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1575ma8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690088891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seriously, I don&amp;#39;t know where to begin. It&amp;#39;s so annoying. I am not understanding the UI part of Microsoft fabrics. It&amp;#39;s so click heavy. I am completely lost where to start and where to end.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1575ma8", "is_robot_indexable": true, "report_reasons": null, "author": "boogie_woogie_100", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1575ma8/rantmicrosoft_fabric_is_most_annoying_pos_i_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1575ma8/rantmicrosoft_fabric_is_most_annoying_pos_i_have/", "subreddit_subscribers": 117498, "created_utc": 1690088891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Essentially what the title says. I have an end to end pipeline that at a high level is \n* extract data\n* do some python transformations\n* export data  \n  \nI want to add a 4th step of  \n  \n* run the relevant dbt models\n\nThe thing is that I\u2019m running into problems with invoking it programmatically, as the pipeline file is in a different directory than the dbt project (so it doesn\u2019t detect the project yaml file) and I can\u2019t use absolute paths to specify which model to run, which I need to do because the pipeline is in a different directory\n\nThis is for a personal project, so I am trying to implement dbt just for the sake of learning it. The thing is though, that the pipeline runs automatically on a cron job, and I need the model to be run at the time of the pipeline\n\nIs this the wrong usage pattern for dbt? I suspect it is because it\u2019s not straightforward to do so far", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to be able to programmatically integrate dbt into an end-to-end pipeline in python. Is this the wrong usage of dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156v3fo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690059713.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690059483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially what the title says. I have an end to end pipeline that at a high level is \n* extract data\n* do some python transformations\n* export data  &lt;/p&gt;\n\n&lt;p&gt;I want to add a 4th step of  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;run the relevant dbt models&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The thing is that I\u2019m running into problems with invoking it programmatically, as the pipeline file is in a different directory than the dbt project (so it doesn\u2019t detect the project yaml file) and I can\u2019t use absolute paths to specify which model to run, which I need to do because the pipeline is in a different directory&lt;/p&gt;\n\n&lt;p&gt;This is for a personal project, so I am trying to implement dbt just for the sake of learning it. The thing is though, that the pipeline runs automatically on a cron job, and I need the model to be run at the time of the pipeline&lt;/p&gt;\n\n&lt;p&gt;Is this the wrong usage pattern for dbt? I suspect it is because it\u2019s not straightforward to do so far&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "156v3fo", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156v3fo/i_want_to_be_able_to_programmatically_integrate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156v3fo/i_want_to_be_able_to_programmatically_integrate/", "subreddit_subscribers": 117498, "created_utc": 1690059483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars vs Pandas. Inside an AWS Lambda.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "name": "t3_156yqjp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Fx8866f2QhZ8_c_TlFyhszEmVt4dS0VpZuRLTL-tYvw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690068587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confessionsofadataguy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confessionsofadataguy.com/polars-vs-pandas-inside-an-aws-lambda/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?auto=webp&amp;s=984d4904683a78cd3669ec8cc95bf151ce4901d3", "width": 1030, "height": 407}, "resolutions": [{"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f316fdc66227686d49273d627574d96ef7da138f", "width": 108, "height": 42}, {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be1a70495f071a025cf357793e3847ec87acc3b6", "width": 216, "height": 85}, {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25c5dc36477503778c8153c51b033eb65c2d57dd", "width": 320, "height": 126}, {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e353cc8bc4595b3b882e83dc34ed73b07d400c1c", "width": 640, "height": 252}, {"url": "https://external-preview.redd.it/EsNsZvx3qiOBMBLEBuhY0nCtf8nmaJB_9vGBx1TeXTM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f70a228a6f648f14e269f0bffe81e7561db75ac", "width": 960, "height": 379}], "variants": {}, "id": "-nV_x0fps6dbvy50xBKdZk_dZsYL6Rtq0vfR6doeFsU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "156yqjp", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156yqjp/polars_vs_pandas_inside_an_aws_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confessionsofadataguy.com/polars-vs-pandas-inside-an-aws-lambda/", "subreddit_subscribers": 117498, "created_utc": 1690068587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In one of our use cases, a \"compliance alert\" must be delivered depending on guidelines found in a collection of documents.  A transactional database houses the criteria data (triggers), and some event data is streamed.\n\na) Does anybody have a **similar use case**?\n\nb) Does anybody have use cases around data pipelines for LLMs and structured data sources?  If so how do you deal with the following :\n\n1. **Context mismatch** \\-  since enterprise databases have very specific schemas and terminology that the LLM is unaware of, how do you prevent misunderstanding?\n2. **Entity ignorance -**  entities are a relational db terminology but how do you get that into the LLM world?\n3. **Compositionality** \\- LLMs lean towards a holistic view, and our database queries require hierarchical, compositional views. How do you deal with this?\n\nNot to mention other performance-related issues ...", "author_fullname": "t2_48nrgvyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use cases for LLMs on structured data (sourced from databases and streaming data)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156ltst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690074186.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690036730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In one of our use cases, a &amp;quot;compliance alert&amp;quot; must be delivered depending on guidelines found in a collection of documents.  A transactional database houses the criteria data (triggers), and some event data is streamed.&lt;/p&gt;\n\n&lt;p&gt;a) Does anybody have a &lt;strong&gt;similar use case&lt;/strong&gt;?&lt;/p&gt;\n\n&lt;p&gt;b) Does anybody have use cases around data pipelines for LLMs and structured data sources?  If so how do you deal with the following :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Context mismatch&lt;/strong&gt; -  since enterprise databases have very specific schemas and terminology that the LLM is unaware of, how do you prevent misunderstanding?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Entity ignorance -&lt;/strong&gt;  entities are a relational db terminology but how do you get that into the LLM world?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Compositionality&lt;/strong&gt; - LLMs lean towards a holistic view, and our database queries require hierarchical, compositional views. How do you deal with this?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Not to mention other performance-related issues ...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "156ltst", "is_robot_indexable": true, "report_reasons": null, "author": "anupsurendran", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156ltst/use_cases_for_llms_on_structured_data_sourced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156ltst/use_cases_for_llms_on_structured_data_sourced/", "subreddit_subscribers": 117498, "created_utc": 1690036730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use AWS at my work for ETL to work with small datasets (~5000 rows). We have multiple pipelines with the following setup.\n\n1. External systems send files using SFTP to S3 raw files folder.\n2. Lambda gets triggered and moves files to staging folder in S3.\n3. Glue job gets triggered and transforms the data and moves transformed file to transformed folder in S3.\n4. Lambda gets triggered and uploads data to Salesforce.\n\nThe painful part about all of this is that all AWS resources are created manually. All the S3 folders, lambdas, roles, glue jobs, SFTP, etc. There really is no way easy to see if a lambda or glue job failed. I usually look at the logs after the failure to find out if they failed. My question to you guys is, how do I automate this pipeline? Also, how do I get alerted when a lambda or glue job fails?", "author_fullname": "t2_cbdg7n9sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with automation and alerts in AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156nl1s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690040960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use AWS at my work for ETL to work with small datasets (~5000 rows). We have multiple pipelines with the following setup.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;External systems send files using SFTP to S3 raw files folder.&lt;/li&gt;\n&lt;li&gt;Lambda gets triggered and moves files to staging folder in S3.&lt;/li&gt;\n&lt;li&gt;Glue job gets triggered and transforms the data and moves transformed file to transformed folder in S3.&lt;/li&gt;\n&lt;li&gt;Lambda gets triggered and uploads data to Salesforce.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The painful part about all of this is that all AWS resources are created manually. All the S3 folders, lambdas, roles, glue jobs, SFTP, etc. There really is no way easy to see if a lambda or glue job failed. I usually look at the logs after the failure to find out if they failed. My question to you guys is, how do I automate this pipeline? Also, how do I get alerted when a lambda or glue job fails?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "156nl1s", "is_robot_indexable": true, "report_reasons": null, "author": "fun_coordinator", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156nl1s/need_help_with_automation_and_alerts_in_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156nl1s/need_help_with_automation_and_alerts_in_aws/", "subreddit_subscribers": 117498, "created_utc": 1690040960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone i have a question with Glue Exclude pattern, really appreciate if anyone can help me\n\nI'm having an S3 bucket that contains many csv files in same folder and i want to run Crawlers on that folder to create some tables. The S3 bucket structure:\n\n* bucket\\_name/folder\\_name\n   * xxx-apple-xxx-1.csv\n   * xxx-apple-xxx-2.csv\n   * xxx-orange-xxx-1.csv\n   * xxx-strawberry-xxx-1.csv\n   * xxx-chicken-xxx-1.csv\n   * xxx-chicken-xxx-2.csv\n   * xxx-dog-xxx-1.csv\n   * xxx-cat-xxx-1.csv\n   * and many more....\n\nAnd i want to create Crawler to create 1 table for each category, such as 1 table for apple, 1 table for orange (1 crawler --&gt; 1 table)..... And the number of categories is over 100. I see that Glue Crawler has a property, name [Exclude](https://docs.aws.amazon.com/glue/latest/dg/define-crawler.html#crawler-data-stores-exclude) pattern (but i do not see the Include pattern property) that we use filter out files when running crawler.\n\nNow i want to create a Crawler for apple, so it should ignore all files except \\*apple\\* ones. I've tried with the Exclude but not achieve this yet. Do anyone know how to do this ?\n\nCrawler name: apple\\_crawler\n\nS3\\_path: bucket\\_name/folder\\_name\n\nExclude: i have tried things like: \\*\\[!{apple}\\]\\* or \\*!(apple)\\* or \\*\\[!apple\\]\\* but it did not work\n\n&amp;#x200B;\n\nThank you !", "author_fullname": "t2_7fyrjq8ff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue Crawler Exclude pattern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156usm1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690060211.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690058735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone i have a question with Glue Exclude pattern, really appreciate if anyone can help me&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having an S3 bucket that contains many csv files in same folder and i want to run Crawlers on that folder to create some tables. The S3 bucket structure:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;bucket_name/folder_name\n\n&lt;ul&gt;\n&lt;li&gt;xxx-apple-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-apple-xxx-2.csv&lt;/li&gt;\n&lt;li&gt;xxx-orange-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-strawberry-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-chicken-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-chicken-xxx-2.csv&lt;/li&gt;\n&lt;li&gt;xxx-dog-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;xxx-cat-xxx-1.csv&lt;/li&gt;\n&lt;li&gt;and many more....&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And i want to create Crawler to create 1 table for each category, such as 1 table for apple, 1 table for orange (1 crawler --&amp;gt; 1 table)..... And the number of categories is over 100. I see that Glue Crawler has a property, name &lt;a href=\"https://docs.aws.amazon.com/glue/latest/dg/define-crawler.html#crawler-data-stores-exclude\"&gt;Exclude&lt;/a&gt; pattern (but i do not see the Include pattern property) that we use filter out files when running crawler.&lt;/p&gt;\n\n&lt;p&gt;Now i want to create a Crawler for apple, so it should ignore all files except *apple* ones. I&amp;#39;ve tried with the Exclude but not achieve this yet. Do anyone know how to do this ?&lt;/p&gt;\n\n&lt;p&gt;Crawler name: apple_crawler&lt;/p&gt;\n\n&lt;p&gt;S3_path: bucket_name/folder_name&lt;/p&gt;\n\n&lt;p&gt;Exclude: i have tried things like: *[!{apple}]* or *!(apple)* or *[!apple]* but it did not work&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "156usm1", "is_robot_indexable": true, "report_reasons": null, "author": "random_name_362", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156usm1/aws_glue_crawler_exclude_pattern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156usm1/aws_glue_crawler_exclude_pattern/", "subreddit_subscribers": 117498, "created_utc": 1690058735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data reporting business is generally needs a lot of humans involvement to ensure the quality of data, any traction for AI in this space &amp; recommendations please", "author_fullname": "t2_va6si3w6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any AI tools / plugins to check data accuracy and data structure ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157b6f7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690107615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data reporting business is generally needs a lot of humans involvement to ensure the quality of data, any traction for AI in this space &amp;amp; recommendations please&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157b6f7", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Pick_8431", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157b6f7/is_there_any_ai_tools_plugins_to_check_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157b6f7/is_there_any_ai_tools_plugins_to_check_data/", "subreddit_subscribers": 117498, "created_utc": 1690107615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to obtain real-time data from Twitter to conduct sentiment analysis using Spark Streaming. However, I've encountered difficulties while attempting to retrieve this data through Tweepy. After some research, I believe the issue might be related to limitations with Tweepy's free access. Could you suggest alternative methods or approaches to acquire real-time data without relying on Tweepy or any other alternatives to it?", "author_fullname": "t2_feara4tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-Time Twitter Data Acquisition for Sentiment Analysis: Seeking Alternatives to Tweepy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156zpo3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690071181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to obtain real-time data from Twitter to conduct sentiment analysis using Spark Streaming. However, I&amp;#39;ve encountered difficulties while attempting to retrieve this data through Tweepy. After some research, I believe the issue might be related to limitations with Tweepy&amp;#39;s free access. Could you suggest alternative methods or approaches to acquire real-time data without relying on Tweepy or any other alternatives to it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "156zpo3", "is_robot_indexable": true, "report_reasons": null, "author": "Kratos_1412", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156zpo3/realtime_twitter_data_acquisition_for_sentiment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156zpo3/realtime_twitter_data_acquisition_for_sentiment/", "subreddit_subscribers": 117498, "created_utc": 1690071181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Importing files into mysql using mysql command-line client. How do nk I modify the 'secure-file-priv' option to an empty string?.\n\nI'm unable to import files directly into mysql using the Data Import Wizard", "author_fullname": "t2_k8yx6w60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data importation issues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156ogaf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690043067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Importing files into mysql using mysql command-line client. How do nk I modify the &amp;#39;secure-file-priv&amp;#39; option to an empty string?.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m unable to import files directly into mysql using the Data Import Wizard&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "156ogaf", "is_robot_indexable": true, "report_reasons": null, "author": "GhostPrime3111", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156ogaf/data_importation_issues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156ogaf/data_importation_issues/", "subreddit_subscribers": 117498, "created_utc": 1690043067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title, has anyone made the switch from data engineering to software dev (backend)? How was the transition (outside of internal switch)? What steps did you take to achieve this (new programming language? side projects?  Leetcode?). Any pointers on where to find side projects to collaborate with experienced backend engineers? How has this switch affected progression in your career? What level did you apply for (junior? Mid?) How\u2019s the learning curve on starting the first SWE job?\n\nBackground: I am a mid level data engineer who enjoys solving problems writing code but have found that DE domain offers less opportunities for me to improve my coding skills. I primarily use Python, SQL and spark in my day to day but feel like I could do more with Python, SQL and other languages. In my spare time, I practise by taking on leetcode challenges and reading on backend architecture and design and find it very interesting. I have also created some personal fullstack projects in the past and looking to learn better by collaborating with more experienced backend engineers on projects before applying for SWE roles.\n\nHas anyone had this experience and how did they successfully make the switch? Any recommendations will be highly appreciated.", "author_fullname": "t2_b8q6wfyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How you switched from data engineering to software Backend development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_157fm9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690120905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title, has anyone made the switch from data engineering to software dev (backend)? How was the transition (outside of internal switch)? What steps did you take to achieve this (new programming language? side projects?  Leetcode?). Any pointers on where to find side projects to collaborate with experienced backend engineers? How has this switch affected progression in your career? What level did you apply for (junior? Mid?) How\u2019s the learning curve on starting the first SWE job?&lt;/p&gt;\n\n&lt;p&gt;Background: I am a mid level data engineer who enjoys solving problems writing code but have found that DE domain offers less opportunities for me to improve my coding skills. I primarily use Python, SQL and spark in my day to day but feel like I could do more with Python, SQL and other languages. In my spare time, I practise by taking on leetcode challenges and reading on backend architecture and design and find it very interesting. I have also created some personal fullstack projects in the past and looking to learn better by collaborating with more experienced backend engineers on projects before applying for SWE roles.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had this experience and how did they successfully make the switch? Any recommendations will be highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157fm9c", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent_Bad5837", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157fm9c/how_you_switched_from_data_engineering_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157fm9c/how_you_switched_from_data_engineering_to/", "subreddit_subscribers": 117498, "created_utc": 1690120905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am new to this group. I have been a data analyst since 2 years, trying to explore Data Engineering field. I am more a book reading person, can anyone suggest me good books for DE. Thanks \ud83d\ude00", "author_fullname": "t2_o8w8xdni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1579wu3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690103336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am new to this group. I have been a data analyst since 2 years, trying to explore Data Engineering field. I am more a book reading person, can anyone suggest me good books for DE. Thanks \ud83d\ude00&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1579wu3", "is_robot_indexable": true, "report_reasons": null, "author": "Late-Pollution2992", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1579wu3/data_engineering_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1579wu3/data_engineering_books/", "subreddit_subscribers": 117498, "created_utc": 1690103336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow members,\nI am a student currently doing some DS projects on my own.Also am doing a internship which was initially in DS but now transformed to DE.\nPlease share resources/guidance on the transition to DE.\nSkills to be learned:\nPyspark,Microsoft Sql server &amp; creating data pipeline.", "author_fullname": "t2_c8y6wkay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources/Guidance for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1577uk7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690096270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow members,\nI am a student currently doing some DS projects on my own.Also am doing a internship which was initially in DS but now transformed to DE.\nPlease share resources/guidance on the transition to DE.\nSkills to be learned:\nPyspark,Microsoft Sql server &amp;amp; creating data pipeline.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1577uk7", "is_robot_indexable": true, "report_reasons": null, "author": "Significant_Show_237", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1577uk7/resourcesguidance_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1577uk7/resourcesguidance_for_de/", "subreddit_subscribers": 117498, "created_utc": 1690096270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello everyone,\n\nI wanted to express my gratitude to this subreddit for helping me become a certified Data Engineer. It feels amazing to have achieved this milestone with your support.\n\nRecently, my company approached me to create a learning roadmap for aspiring Data Engineers. The goal is to provide newcomers with a clear and structured learning path to follow. Understanding that it can be overwhelming to determine which skills to develop and the right order to do so, I have carefully designed a learning roadmap that consists of recommended courses to take, arranged in a specific order.\n\nBelow, you'll find the learning roadmap I've created:\n\n[Here it is](https://imgur.com/oKh3S4r) \n\nFurthermore, I've compiled a stack of technologies that the company should prioritize and gain experience with for the Data Engineer and Data Architect department.\n\nI would greatly appreciate your feedback on this roadmap. If you feel that any modifications, additions, or removals would be beneficial, please let me know.\n\nThank you all for your continuous support and contributions to this community.\n\n&amp;#x200B;\n\n **Relevant Technologies**\n\n&amp;#x200B;\n\n|GCP|\n|:-|\n|Azure|\n|AWS|\n|Pentaho|\n|SQL|\n|Python|\n|Spark|\n|DBT|\n|Airflow|\n|Databricks|\n\n&amp;#x200B;", "author_fullname": "t2_ch1z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Certified Data Engineer Offering Learning Roadmap and Technology Stack - Seeking Community Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_156qo29", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690048500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I wanted to express my gratitude to this subreddit for helping me become a certified Data Engineer. It feels amazing to have achieved this milestone with your support.&lt;/p&gt;\n\n&lt;p&gt;Recently, my company approached me to create a learning roadmap for aspiring Data Engineers. The goal is to provide newcomers with a clear and structured learning path to follow. Understanding that it can be overwhelming to determine which skills to develop and the right order to do so, I have carefully designed a learning roadmap that consists of recommended courses to take, arranged in a specific order.&lt;/p&gt;\n\n&lt;p&gt;Below, you&amp;#39;ll find the learning roadmap I&amp;#39;ve created:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/oKh3S4r\"&gt;Here it is&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Furthermore, I&amp;#39;ve compiled a stack of technologies that the company should prioritize and gain experience with for the Data Engineer and Data Architect department.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your feedback on this roadmap. If you feel that any modifications, additions, or removals would be beneficial, please let me know.&lt;/p&gt;\n\n&lt;p&gt;Thank you all for your continuous support and contributions to this community.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Relevant Technologies&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;GCP&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Azure&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;AWS&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Pentaho&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;SQL&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Python&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Spark&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;DBT&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Airflow&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Databricks&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f7EAShxhi-FZmUuSmrZ1pQZipKdy9_6JPqCQzcGv3ts.jpg?auto=webp&amp;s=942e0caad63600129c6b89f7a0e11469a2cbd322", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/f7EAShxhi-FZmUuSmrZ1pQZipKdy9_6JPqCQzcGv3ts.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=763357754b7b888280200b747a036a160234d559", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/f7EAShxhi-FZmUuSmrZ1pQZipKdy9_6JPqCQzcGv3ts.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e38e34364f6be36022f4b5647152dbe4ce66221", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/f7EAShxhi-FZmUuSmrZ1pQZipKdy9_6JPqCQzcGv3ts.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b58280e32494ae22e122bdc0515e265b4d456f32", "width": 320, "height": 168}], "variants": {}, "id": "h1mjMrtfPMNL9exEKl_TPr4mhvRXbIZP_RvHn8J2--E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "156qo29", "is_robot_indexable": true, "report_reasons": null, "author": "lSniperwolfl", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156qo29/certified_data_engineer_offering_learning_roadmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/156qo29/certified_data_engineer_offering_learning_roadmap/", "subreddit_subscribers": 117498, "created_utc": 1690048500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently working as Associate analyst (8 months) at my firm with Redshift as warehousing tool. I am responsible for data modelling (Kimbal/dimensional), writing SQL queries and dashboarding but looking for a switch to roughly an Analytics engineer profile in company using **dbt** as a transformation tool.\n\nI also have a background in backend development (1 year), have basic familiarity with dbt.\n\nIf you work or know any such companies, please suggest or refer?\n\nThanx\n\nCountry:  **India,** looking for remote role ", "author_fullname": "t2_8fzz4h2q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Companies using dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ajgm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690110985.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690105483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working as Associate analyst (8 months) at my firm with Redshift as warehousing tool. I am responsible for data modelling (Kimbal/dimensional), writing SQL queries and dashboarding but looking for a switch to roughly an Analytics engineer profile in company using &lt;strong&gt;dbt&lt;/strong&gt; as a transformation tool.&lt;/p&gt;\n\n&lt;p&gt;I also have a background in backend development (1 year), have basic familiarity with dbt.&lt;/p&gt;\n\n&lt;p&gt;If you work or know any such companies, please suggest or refer?&lt;/p&gt;\n\n&lt;p&gt;Thanx&lt;/p&gt;\n\n&lt;p&gt;Country:  &lt;strong&gt;India,&lt;/strong&gt; looking for remote role &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157ajgm", "is_robot_indexable": true, "report_reasons": null, "author": "bhav_sagar", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157ajgm/companies_using_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157ajgm/companies_using_dbt/", "subreddit_subscribers": 117498, "created_utc": 1690105483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Machine learning in data engineer", "author_fullname": "t2_ifyv45uo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My first article focused on the field of data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_156qfc5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HbfS7HjqVgvETniMb6gWL9jLxRnuF4fFowv07d26X-E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690047884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Machine learning in data engineer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@thiago2002sr/machine-learning-in-data-engineering-turning-data-into-precious-knowledge-201224922a3c", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RKdUkwTFuP43O_0eXsYhJa2lHMIXYCX3wpg5_y9Mnfc.jpg?auto=webp&amp;s=23f2ef8ecde21ce5dbc0e521a45fc56a51f16b09", "width": 275, "height": 183}, "resolutions": [{"url": "https://external-preview.redd.it/RKdUkwTFuP43O_0eXsYhJa2lHMIXYCX3wpg5_y9Mnfc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c94c3fb99db60f720e6cd678659407e81e999bfd", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/RKdUkwTFuP43O_0eXsYhJa2lHMIXYCX3wpg5_y9Mnfc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9514fb5bae38ebb39530e61206bca40b4a73591c", "width": 216, "height": 143}], "variants": {}, "id": "YTmNATRz_IxIBno4oepJxOCZr1g122YzwyQ7ee4NlJg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "156qfc5", "is_robot_indexable": true, "report_reasons": null, "author": "adabbledragon85", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/156qfc5/my_first_article_focused_on_the_field_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@thiago2002sr/machine-learning-in-data-engineering-turning-data-into-precious-knowledge-201224922a3c", "subreddit_subscribers": 117498, "created_utc": 1690047884.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}