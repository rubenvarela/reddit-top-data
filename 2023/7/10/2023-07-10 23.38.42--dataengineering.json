{"kind": "Listing", "data": {"after": "t3_14vqf57", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fueo9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Typical interview with Airflow enjoyer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14vw6y3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 138, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 138, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nFtBLzVUZc_MKeTvdeaWA9HSUY_SBCVxLtBw7MoJWU4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689000632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/2231e36jh5bb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/2231e36jh5bb1.jpg?auto=webp&amp;v=enabled&amp;s=42a53509d2d479216cd860c6fd863c681e73b7b1", "width": 640, "height": 360}, "resolutions": [{"url": "https://preview.redd.it/2231e36jh5bb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c11244d631abc8130e3e535fce8d4c614aec28d", "width": 108, "height": 60}, {"url": "https://preview.redd.it/2231e36jh5bb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3c25bc342865b218777e99ccd332c223392b53f", "width": 216, "height": 121}, {"url": "https://preview.redd.it/2231e36jh5bb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e723f022d2b7721c65cdd0db31d283d7bb443d0", "width": 320, "height": 180}, {"url": "https://preview.redd.it/2231e36jh5bb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d311d164717b684f63d17422a66862f492fdaa5", "width": 640, "height": 360}], "variants": {}, "id": "8yR-Xf8HU2hnJSw9jemnyK3ZGXK0kpMExbXKJOkR5PA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14vw6y3", "is_robot_indexable": true, "report_reasons": null, "author": "ponkipo", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vw6y3/typical_interview_with_airflow_enjoyer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/2231e36jh5bb1.jpg", "subreddit_subscribers": 115112, "created_utc": 1689000632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "fyi I\u2019m a DE intern right now, but I\u2019m learning about dbt for the first time and it seems really cool so far\n\nThe main benefits I see are:\n* Time saving\n  * You don\u2019t have to worry about any CREATE TABLE, INSERT INTO, or UPDATE syntax. dbt takes care of all of it for you and converts your sql statement into a new table, which leads to the next point of\u2026\n* Easiness\n  * dbt seems really straightforward. there are \u201cmodels\u201d (which are literally just sql files with select statements in them) that you can chain up with other models to create transformation pipelines. Instead of having to programmatically do the T in ETL, anyone who knows sql can create the data that they need (provided all the data is present in the source table)\n\nI\u2019m working on a personal project that was using mysql, but am migrating to postgres so that I can use dbt. I figure it will simplify things for me on the data cleaning side, as a lot of the logic is heavily embedded in the script and not easily testable/accessible.\n\nI may be getting ahead of myself as I\u2019ve not had the chance to play around with it in depth, but the switch from ETL to ELT with dbt seems like such a good concept", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt seems like such a cool concept", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vcujs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688944095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;fyi I\u2019m a DE intern right now, but I\u2019m learning about dbt for the first time and it seems really cool so far&lt;/p&gt;\n\n&lt;p&gt;The main benefits I see are:\n* Time saving\n  * You don\u2019t have to worry about any CREATE TABLE, INSERT INTO, or UPDATE syntax. dbt takes care of all of it for you and converts your sql statement into a new table, which leads to the next point of\u2026\n* Easiness\n  * dbt seems really straightforward. there are \u201cmodels\u201d (which are literally just sql files with select statements in them) that you can chain up with other models to create transformation pipelines. Instead of having to programmatically do the T in ETL, anyone who knows sql can create the data that they need (provided all the data is present in the source table)&lt;/p&gt;\n\n&lt;p&gt;I\u2019m working on a personal project that was using mysql, but am migrating to postgres so that I can use dbt. I figure it will simplify things for me on the data cleaning side, as a lot of the logic is heavily embedded in the script and not easily testable/accessible.&lt;/p&gt;\n\n&lt;p&gt;I may be getting ahead of myself as I\u2019ve not had the chance to play around with it in depth, but the switch from ETL to ELT with dbt seems like such a good concept&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vcujs", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vcujs/dbt_seems_like_such_a_cool_concept/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vcujs/dbt_seems_like_such_a_cool_concept/", "subreddit_subscribers": 115112, "created_utc": 1688944095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that a lot of people say data engineering career at FAANG is not a full experience of data engineering, but it\u2019s been my dream to have a career at FAANG. I just started my career as a data engineer not long ago, but the tech stack isn\u2019t very modern and I don\u2019t use Spark and not even Python. We use Informatica to do all the work, so I imagine I would have to build up my experience in other technologies to fulfill the Data Engineer job requirement at FAANG. With that said, how should I prepare for a data engineer interview at FAANG from ground up? I am thinking of applying possibly end of next year, so I will have around ~2YOE or less if I apply earlier. I know that grinding leetcode and statascratch is a must to prepare for the interview, what are some other stuffs? Also what company among the FAANG has the best data engineering experience?", "author_fullname": "t2_cjk2xje6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to break into FAANG?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vicy3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688959306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that a lot of people say data engineering career at FAANG is not a full experience of data engineering, but it\u2019s been my dream to have a career at FAANG. I just started my career as a data engineer not long ago, but the tech stack isn\u2019t very modern and I don\u2019t use Spark and not even Python. We use Informatica to do all the work, so I imagine I would have to build up my experience in other technologies to fulfill the Data Engineer job requirement at FAANG. With that said, how should I prepare for a data engineer interview at FAANG from ground up? I am thinking of applying possibly end of next year, so I will have around ~2YOE or less if I apply earlier. I know that grinding leetcode and statascratch is a must to prepare for the interview, what are some other stuffs? Also what company among the FAANG has the best data engineering experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14vicy3", "is_robot_indexable": true, "report_reasons": null, "author": "highlifeed", "discussion_type": null, "num_comments": 80, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vicy3/how_to_break_into_faang/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vicy3/how_to_break_into_faang/", "subreddit_subscribers": 115112, "created_utc": 1688959306.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im seeking interesting ideas for two portfolio projects related to the broad field of electrical energy or neurobiology/biology. For these projects, I would primarily like to utilize **AWS** and **Apache Airflow**. They will be semester-long projects for students. For example, they could include:\n\n1. **Predicting energy demand using meteorological data**\n2. **Optimizing the utilization of renewable energy based on weather forecasts**\n3. **Multidimensional Brain Data Analysis for Neuronal Activity Pattern Identification**\n\nSo I'm looking for an interesting idea, mainly using AWS and at least a bit of Airflow .\n\nDo you have any interesting suggestions? The key factor for me is selecting projects that will engage the students, as they will only be motivated if the projects are meaningful. They are proficient in Python, SQL, and have a basic understanding of AWS.", "author_fullname": "t2_7yv0lkcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Energy or Neurobiology-related Portfolio Projects for cognitive science students.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vrw8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688991230.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688990015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im seeking interesting ideas for two portfolio projects related to the broad field of electrical energy or neurobiology/biology. For these projects, I would primarily like to utilize &lt;strong&gt;AWS&lt;/strong&gt; and &lt;strong&gt;Apache Airflow&lt;/strong&gt;. They will be semester-long projects for students. For example, they could include:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Predicting energy demand using meteorological data&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Optimizing the utilization of renewable energy based on weather forecasts&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Multidimensional Brain Data Analysis for Neuronal Activity Pattern Identification&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for an interesting idea, mainly using AWS and at least a bit of Airflow .&lt;/p&gt;\n\n&lt;p&gt;Do you have any interesting suggestions? The key factor for me is selecting projects that will engage the students, as they will only be motivated if the projects are meaningful. They are proficient in Python, SQL, and have a basic understanding of AWS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vrw8x", "is_robot_indexable": true, "report_reasons": null, "author": "International-Shirt5", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vrw8x/looking_for_energy_or_neurobiologyrelated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vrw8x/looking_for_energy_or_neurobiologyrelated/", "subreddit_subscribers": 115112, "created_utc": 1688990015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nI'm reaching out to this community for some advice regarding my current career situation. Here's a brief overview:\n\n* Graduated with High Distinction from University of Sydney with majors in Computer Science and Data Science.\n* Over 1.5 years of experience as a Data Engineer, proficient in Python, SQL, IaC (Terraform, Puppet), and CI/CD.\n* Currently  on a Grad Working Visa in Sydney, expiring end of next year. Working  towards Permanent Residency (PR) application but it is always uncertain.\n* Recently  switched jobs to a company (XX) as a Data Engineer, but the actual role  differs significantly from the job description. My team mainly use Alteryx for data wrangling, not the Python and ETL work I expected.\n* After  a month at XX, no technical projects have come my way despite me asking  my manager for more coding related tasks. Started looking for new jobs  but facing constant rejections (not even interviews/coding tests),  making me doubt my abilities or if my visa status is hindering me.\n* Losing hope for employer sponsorship due to inability to even secure a job in the first place.\n\nSeeking  advice/suggestions for next steps or insights from anyone who has been  through a similar situation. Please share your thoughts.\n\nThank you in advance.", "author_fullname": "t2_f5yhhz77u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Advice: Struggling with Career as a Data Engineer (Sydney)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vp78r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688981815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out to this community for some advice regarding my current career situation. Here&amp;#39;s a brief overview:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Graduated with High Distinction from University of Sydney with majors in Computer Science and Data Science.&lt;/li&gt;\n&lt;li&gt;Over 1.5 years of experience as a Data Engineer, proficient in Python, SQL, IaC (Terraform, Puppet), and CI/CD.&lt;/li&gt;\n&lt;li&gt;Currently  on a Grad Working Visa in Sydney, expiring end of next year. Working  towards Permanent Residency (PR) application but it is always uncertain.&lt;/li&gt;\n&lt;li&gt;Recently  switched jobs to a company (XX) as a Data Engineer, but the actual role  differs significantly from the job description. My team mainly use Alteryx for data wrangling, not the Python and ETL work I expected.&lt;/li&gt;\n&lt;li&gt;After  a month at XX, no technical projects have come my way despite me asking  my manager for more coding related tasks. Started looking for new jobs  but facing constant rejections (not even interviews/coding tests),  making me doubt my abilities or if my visa status is hindering me.&lt;/li&gt;\n&lt;li&gt;Losing hope for employer sponsorship due to inability to even secure a job in the first place.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Seeking  advice/suggestions for next steps or insights from anyone who has been  through a similar situation. Please share your thoughts.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vp78r", "is_robot_indexable": true, "report_reasons": null, "author": "Many-Local-765", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vp78r/need_advice_struggling_with_career_as_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vp78r/need_advice_struggling_with_career_as_a_data/", "subreddit_subscribers": 115112, "created_utc": 1688981815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was doing backend internship with nodejs and I got to know that I don't like doing frontend and enjoying backend comparatively more.\n\nI got a Junior data engineer job offer which I have accepted, But when I asked someone about how much programming does a DE gets to do.\n\nHe said \" DE does not include much Coding.the main work is to building pipeline and databases and some views may be. I will not considered it a coding stuff\"\n\nI do enjoy programming, so can anyone here in this space share their views that do you guys as DEs code enough , how much percent of your work is really programming stuff? \n\nI have heard that Data engineering is software engineering specialising in data.", "author_fullname": "t2_jh44nvdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do Data Engineers get Enough Programming/Coding opportunity ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vz8k1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689007514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was doing backend internship with nodejs and I got to know that I don&amp;#39;t like doing frontend and enjoying backend comparatively more.&lt;/p&gt;\n\n&lt;p&gt;I got a Junior data engineer job offer which I have accepted, But when I asked someone about how much programming does a DE gets to do.&lt;/p&gt;\n\n&lt;p&gt;He said &amp;quot; DE does not include much Coding.the main work is to building pipeline and databases and some views may be. I will not considered it a coding stuff&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I do enjoy programming, so can anyone here in this space share their views that do you guys as DEs code enough , how much percent of your work is really programming stuff? &lt;/p&gt;\n\n&lt;p&gt;I have heard that Data engineering is software engineering specialising in data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vz8k1", "is_robot_indexable": true, "report_reasons": null, "author": "micky_357000", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vz8k1/do_data_engineers_get_enough_programmingcoding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vz8k1/do_data_engineers_get_enough_programmingcoding/", "subreddit_subscribers": 115112, "created_utc": 1689007514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I\u2019m a field engineer at Materialize and thought I would share a little pattern we\u2019ve seen come up a few times. Hope you find it useful!\n\nhttps://materialize.com/docs/transform-data/patterns/rules-engine/", "author_fullname": "t2_5p00kusf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rules execution engine using LATERAL joins", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w4thx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689019835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I\u2019m a field engineer at Materialize and thought I would share a little pattern we\u2019ve seen come up a few times. Hope you find it useful!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://materialize.com/docs/transform-data/patterns/rules-engine/\"&gt;https://materialize.com/docs/transform-data/patterns/rules-engine/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?auto=webp&amp;v=enabled&amp;s=35f1813d32890db32cf8736f55cc9632b6c589ac", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=499b415518dfa3d215db5fff345fd1887f58fdaa", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f17bf0e2ff7c0f93a4b2a517193d0d4e04a6a4e1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=642404823accb64ea79bd3ef35f86790e8343e84", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f33b856c36324248a8a167bb7385d3839daaf7db", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f61c6f30ecce19d6c804dadcdec339f495fa010", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/LPzJo27P7eFcDo4DA_mAlevHcAYqNZ_A6pG8R4iC7a4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df5ce320e6d13f01a4da78f7889b3b99d085399e", "width": 1080, "height": 567}], "variants": {}, "id": "bUusx0wZzzF_XmBpeasJ3TLKk0AsM3dnnnxC7yOn5JI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14w4thx", "is_robot_indexable": true, "report_reasons": null, "author": "Chuck-Alt-Delete", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w4thx/rules_execution_engine_using_lateral_joins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w4thx/rules_execution_engine_using_lateral_joins/", "subreddit_subscribers": 115112, "created_utc": 1689019835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, it's my first post on reddit\ud83e\udd73. I want to start a discussion to get a better understanding of what a good DE should dream about. So my question is which DE jobs are the best ones and which knowledge and experience should I have to get them. Also, a lot of jobs in DE are concentrated in US and I am interested in whether it is possible to get a good DE job from other countries, for example Poland; or these countries, where outsourcing is the biggest part of SWE job market, will inevitably get only the most boring things?  What I can think about is progressing in distributed systems and databases, but for some reason I don't see any demand for such knowledge, for example recently I have implemented a sharded kv store on top of Raft and it seems it hasn't changed my job market value for some reason. Is the only way for a third country national to get noticed is to contribute to spark github? Will appreciate all opinions", "author_fullname": "t2_g6ziwt5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get an interesting job in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w25nl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689014004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, it&amp;#39;s my first post on reddit\ud83e\udd73. I want to start a discussion to get a better understanding of what a good DE should dream about. So my question is which DE jobs are the best ones and which knowledge and experience should I have to get them. Also, a lot of jobs in DE are concentrated in US and I am interested in whether it is possible to get a good DE job from other countries, for example Poland; or these countries, where outsourcing is the biggest part of SWE job market, will inevitably get only the most boring things?  What I can think about is progressing in distributed systems and databases, but for some reason I don&amp;#39;t see any demand for such knowledge, for example recently I have implemented a sharded kv store on top of Raft and it seems it hasn&amp;#39;t changed my job market value for some reason. Is the only way for a third country national to get noticed is to contribute to spark github? Will appreciate all opinions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14w25nl", "is_robot_indexable": true, "report_reasons": null, "author": "fire_air", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w25nl/how_to_get_an_interesting_job_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w25nl/how_to_get_an_interesting_job_in_de/", "subreddit_subscribers": 115112, "created_utc": 1689014004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\nIve got a task to create a pipeline to replicate sap data and then get only deltas. I know that there is SAP CDC connector to which I need create self hosted integration runtime on client site. I've got a time to create a list of questions to client. What should I take into consideration? My first question is whether they do already have SHIR and we can share to reduce costs and maintainance time. If they do, do I need to install anything on my machine? Its my first commercial project, all self study was based on auto-resolve IR. After I am done with IR I guess its pretty straightforward, just need linked service pointing to this IR, server name, number, client id and dataset with proper ODP framework \n\nIf they dont, do I need to create a VM, to install SHIR there, and SAP .NET connector in there? \n\nWhat I can even ask them?", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure SAP CDC connector considerations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vvn0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688999374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello\nIve got a task to create a pipeline to replicate sap data and then get only deltas. I know that there is SAP CDC connector to which I need create self hosted integration runtime on client site. I&amp;#39;ve got a time to create a list of questions to client. What should I take into consideration? My first question is whether they do already have SHIR and we can share to reduce costs and maintainance time. If they do, do I need to install anything on my machine? Its my first commercial project, all self study was based on auto-resolve IR. After I am done with IR I guess its pretty straightforward, just need linked service pointing to this IR, server name, number, client id and dataset with proper ODP framework &lt;/p&gt;\n\n&lt;p&gt;If they dont, do I need to create a VM, to install SHIR there, and SAP .NET connector in there? &lt;/p&gt;\n\n&lt;p&gt;What I can even ask them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vvn0r", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vvn0r/azure_sap_cdc_connector_considerations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vvn0r/azure_sap_cdc_connector_considerations/", "subreddit_subscribers": 115112, "created_utc": 1688999374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what is a decent salary (per month, before taxes) in Sweden (Stockholm) for a data engineer with less than 2  YOE and no other prior technical background? I am preparing for an interview and I want to know how much to ask in case I'm asked", "author_fullname": "t2_iiiar3v5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salaries in Sweden", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vpyst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688986349.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688984233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what is a decent salary (per month, before taxes) in Sweden (Stockholm) for a data engineer with less than 2  YOE and no other prior technical background? I am preparing for an interview and I want to know how much to ask in case I&amp;#39;m asked&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14vpyst", "is_robot_indexable": true, "report_reasons": null, "author": "23reddituser", "discussion_type": null, "num_comments": 24, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vpyst/salaries_in_sweden/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vpyst/salaries_in_sweden/", "subreddit_subscribers": 115112, "created_utc": 1688984233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello knowledgeable folks,\n\nAre there any tools out there that can upload Excel files to Snowflake with all of the following features?\n\n1) Performant: Can handle multiple files with 100's of thousands of rows in a reasonable time.\n\n2) Allows the user to pick datatypes for each columns, including various date formats (M/D/Y, D/M/Y)\n\n3) Produces basic statistics for each column: max, mean, median, histogram.\n\nI am itching to write my own, but I have a feeling that I would be reinventing the wheel. I refuse to believe that no such tool exists given the ubiquity of Excel files in every organization large and small.\n\n&amp;#x200B;\n\n\\-------\n\nMore Details:\n\n\\------\n\nI deal with a lot of small files Excel files (maximum 100 Mbs) from various clients and online resources. Our usual work flow looks something like this:\n\n1) Business analysts examine the file in Excel, manually, to see what surprise changes the client has done to the agreed file format. If the file is too bad (for example, clientID text field had all its leading zeros dropped because Excel thought it is an integer), we throw the file back to the client and ask for a replacement.\n\n2) Use a rudimentary custom webapp written in R Shiny to read the data to to memory and produce a basic report on each column: mean, max, min for float/int columns, and basic counts for each discrete value in discrete columns. The tool tries to infer datatypes automatically but it often gets this step wrong (mostly fumbles with different international date formats and confuses Int/Text for ID fields). \n\n3) The webapp loads the data to a staging table in Snowflake using ODBC driver (Super slow compared to Python's Snowflake driver).\n\n4) Append the data from step 3 to existing tables after some more quality checks are performed.\n\nI found the Excel add-in for Snowflake ([https://github.com/Snowflake-Labs/Excelerator](https://github.com/Snowflake-Labs/Excelerator)) to be performant and useful for ad-hoc files, but it keeps crashing every time there is an update to Excel. It doesn't seem like it is actively maintained. It also lacks any data quality checks and has a clunky interface.", "author_fullname": "t2_i6lqi6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool for Loading Adhoc Excel Files to Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vl0ga", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688967646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello knowledgeable folks,&lt;/p&gt;\n\n&lt;p&gt;Are there any tools out there that can upload Excel files to Snowflake with all of the following features?&lt;/p&gt;\n\n&lt;p&gt;1) Performant: Can handle multiple files with 100&amp;#39;s of thousands of rows in a reasonable time.&lt;/p&gt;\n\n&lt;p&gt;2) Allows the user to pick datatypes for each columns, including various date formats (M/D/Y, D/M/Y)&lt;/p&gt;\n\n&lt;p&gt;3) Produces basic statistics for each column: max, mean, median, histogram.&lt;/p&gt;\n\n&lt;p&gt;I am itching to write my own, but I have a feeling that I would be reinventing the wheel. I refuse to believe that no such tool exists given the ubiquity of Excel files in every organization large and small.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;-------&lt;/p&gt;\n\n&lt;p&gt;More Details:&lt;/p&gt;\n\n&lt;p&gt;------&lt;/p&gt;\n\n&lt;p&gt;I deal with a lot of small files Excel files (maximum 100 Mbs) from various clients and online resources. Our usual work flow looks something like this:&lt;/p&gt;\n\n&lt;p&gt;1) Business analysts examine the file in Excel, manually, to see what surprise changes the client has done to the agreed file format. If the file is too bad (for example, clientID text field had all its leading zeros dropped because Excel thought it is an integer), we throw the file back to the client and ask for a replacement.&lt;/p&gt;\n\n&lt;p&gt;2) Use a rudimentary custom webapp written in R Shiny to read the data to to memory and produce a basic report on each column: mean, max, min for float/int columns, and basic counts for each discrete value in discrete columns. The tool tries to infer datatypes automatically but it often gets this step wrong (mostly fumbles with different international date formats and confuses Int/Text for ID fields). &lt;/p&gt;\n\n&lt;p&gt;3) The webapp loads the data to a staging table in Snowflake using ODBC driver (Super slow compared to Python&amp;#39;s Snowflake driver).&lt;/p&gt;\n\n&lt;p&gt;4) Append the data from step 3 to existing tables after some more quality checks are performed.&lt;/p&gt;\n\n&lt;p&gt;I found the Excel add-in for Snowflake (&lt;a href=\"https://github.com/Snowflake-Labs/Excelerator\"&gt;https://github.com/Snowflake-Labs/Excelerator&lt;/a&gt;) to be performant and useful for ad-hoc files, but it keeps crashing every time there is an update to Excel. It doesn&amp;#39;t seem like it is actively maintained. It also lacks any data quality checks and has a clunky interface.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?auto=webp&amp;v=enabled&amp;s=b65829b6f00f14d8202715c94ce14e0fc76d4bcb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2a75f109eb155cf707260fae1934198eb0d300c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f76cb80f0130fccfce2d6511783dfebb5eb113f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8b34c8b078f3a3bd60775c76312445ba052e06d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a10c6f7149015bf5ad3014f687f8ee09cc30aeb", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0655042714c6f9a463a22b08139c8a1c917780d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ddd9b9664f39b73f103d51e95f847a18ff48ec5", "width": 1080, "height": 540}], "variants": {}, "id": "iF5rXm76OKp383uxb97mIrFI17Wizf7gUQ1dW--G5Ak"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vl0ga", "is_robot_indexable": true, "report_reasons": null, "author": "fgoussou", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vl0ga/tool_for_loading_adhoc_excel_files_to_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vl0ga/tool_for_loading_adhoc_excel_files_to_warehouse/", "subreddit_subscribers": 115112, "created_utc": 1688967646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Nike (Contract 6 month)\n$73/hr\nNo PTO\nTech stack and team seems solid\n\nStartup (FT)\n160k\nUnlimited PTO\nSimilar tech stack but seems to have a lot of tech debt\n\nI have 5 year of experience and have only worked for companies with size of less than 300. I feel the Nike position seems like a good experience and career stepping point. But the startup seems boring but it's fulltime offer.", "author_fullname": "t2_2m5mr2bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with deciding two offers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w3kay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689017109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Nike (Contract 6 month)\n$73/hr\nNo PTO\nTech stack and team seems solid&lt;/p&gt;\n\n&lt;p&gt;Startup (FT)\n160k\nUnlimited PTO\nSimilar tech stack but seems to have a lot of tech debt&lt;/p&gt;\n\n&lt;p&gt;I have 5 year of experience and have only worked for companies with size of less than 300. I feel the Nike position seems like a good experience and career stepping point. But the startup seems boring but it&amp;#39;s fulltime offer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14w3kay", "is_robot_indexable": true, "report_reasons": null, "author": "sorenadayo", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w3kay/help_with_deciding_two_offers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w3kay/help_with_deciding_two_offers/", "subreddit_subscribers": 115112, "created_utc": 1689017109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "California privacy act and similar data protection laws allows users to request that their data be hard deleted from source systems. I've been wracking my brain trying to figure out how to implement something like this. My team uses a kafka/dbt/snowflake stack, and I'm a bit lost as to how hard deletes could flow through data warehouse models. I assume others have dealt with this as it's a legal thing - has anyone implemented this? What was your approach?", "author_fullname": "t2_5e0ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you implementing CCPA compliance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vutj2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688997497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;California privacy act and similar data protection laws allows users to request that their data be hard deleted from source systems. I&amp;#39;ve been wracking my brain trying to figure out how to implement something like this. My team uses a kafka/dbt/snowflake stack, and I&amp;#39;m a bit lost as to how hard deletes could flow through data warehouse models. I assume others have dealt with this as it&amp;#39;s a legal thing - has anyone implemented this? What was your approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vutj2", "is_robot_indexable": true, "report_reasons": null, "author": "harrytrumanprimate", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vutj2/how_are_you_implementing_ccpa_compliance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vutj2/how_are_you_implementing_ccpa_compliance/", "subreddit_subscribers": 115112, "created_utc": 1688997497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \nI'm building a CI/CD Pipeline for power bi. We have some reports which are not allowed to be exported by some users.\nI want to programmatically disable the export option of some table visual in some reports. I didn't find any API endpoint that does this operation. I also want to programmatically hide some pages in some reports during the deployment. Is there any way to achieve this?\n\nThanks in advance", "author_fullname": "t2_pp0zirow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power BI operation LS that are not supported by API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vttnt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688995073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nI&amp;#39;m building a CI/CD Pipeline for power bi. We have some reports which are not allowed to be exported by some users.\nI want to programmatically disable the export option of some table visual in some reports. I didn&amp;#39;t find any API endpoint that does this operation. I also want to programmatically hide some pages in some reports during the deployment. Is there any way to achieve this?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vttnt", "is_robot_indexable": true, "report_reasons": null, "author": "These_Rip_9327", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vttnt/power_bi_operation_ls_that_are_not_supported_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vttnt/power_bi_operation_ls_that_are_not_supported_by/", "subreddit_subscribers": 115112, "created_utc": 1688995073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the smoothest implementation of an ELT pipeline on the Azure stack (main db is azure sql server) using dbt?", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smooth implementation of dbt in Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vnzzx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688977770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the smoothest implementation of an ELT pipeline on the Azure stack (main db is azure sql server) using dbt?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vnzzx", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vnzzx/smooth_implementation_of_dbt_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vnzzx/smooth_implementation_of_dbt_in_azure/", "subreddit_subscribers": 115112, "created_utc": 1688977770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm in Spain and there's a career called \"Science and Data Engineering\", I've been searching but I found each of them separated, either Science Engineering or Data Engineering, therefore, is this a mix of both? Would I be able to apply to the jobs a Science Engineer or Data Engineer would be able?", "author_fullname": "t2_vbavvuww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is \"Science and Data Engineering\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vdt3p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688946545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m in Spain and there&amp;#39;s a career called &amp;quot;Science and Data Engineering&amp;quot;, I&amp;#39;ve been searching but I found each of them separated, either Science Engineering or Data Engineering, therefore, is this a mix of both? Would I be able to apply to the jobs a Science Engineer or Data Engineer would be able?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vdt3p", "is_robot_indexable": true, "report_reasons": null, "author": "DismemberedBunny", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vdt3p/what_is_science_and_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vdt3p/what_is_science_and_data_engineering/", "subreddit_subscribers": 115112, "created_utc": 1688946545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At my company we developed our own metrics layer (it's cool tbqh), over time we've started using it to build our views. It works, but having the same service handle both missions has increasingly complicated development. We toyed around with writing materialized views directly in SQL, but having no source control or CI/CD is simply not something I'm willing to do. \n\nAfter a good amount of research, we decided to move our views to dbt. I've heard a lot of consistent complaints about dbt cloud and how it's not worth the money, we have the manpower to self-host and CTO backing, so it feels like the reasonable way to go.   \n\n\n I'm just trying to minimize unknown unknowns, and appreciate any 2 cents.", "author_fullname": "t2_44mw8sqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anything one should know before going for self-hosted dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14w832y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689026969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At my company we developed our own metrics layer (it&amp;#39;s cool tbqh), over time we&amp;#39;ve started using it to build our views. It works, but having the same service handle both missions has increasingly complicated development. We toyed around with writing materialized views directly in SQL, but having no source control or CI/CD is simply not something I&amp;#39;m willing to do. &lt;/p&gt;\n\n&lt;p&gt;After a good amount of research, we decided to move our views to dbt. I&amp;#39;ve heard a lot of consistent complaints about dbt cloud and how it&amp;#39;s not worth the money, we have the manpower to self-host and CTO backing, so it feels like the reasonable way to go.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just trying to minimize unknown unknowns, and appreciate any 2 cents.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14w832y", "is_robot_indexable": true, "report_reasons": null, "author": "verysmolpupperino", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w832y/anything_one_should_know_before_going_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w832y/anything_one_should_know_before_going_for/", "subreddit_subscribers": 115112, "created_utc": 1689026969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data analyst learning how to be a data engineer. \n\nI've inherited a process that currently involves:\n\n1. Vendor sends a daily .csv file to an SFTP\n2. Alteryx is used to copy the file to our shared drive, run data transformations, and upload to snowflake. The file is deleted from the SFTP after a successful run in alteryx. \n\nThe process usually takes about 15 minutes daily, roughly 400k records each day. I would like to optimize this process and make it better and more secure. For example, I don't think storing files on a network share drive is smart. \n\nI have access to GCP resources such as cloud storage and cloud composer (airflow). I'm comfortable writing stored procedures and doing data transformations inside snowflake instead of alteryx. \n\nHow can I best optimize and create a data pipeline to utilize snowflake's compute resources for transformation and parallelism for ingestion? \n\nAny thoughts or ideas welcome as I'm very new to these concepts!", "author_fullname": "t2_ekec8wvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice: Setting up a data pipeline to ingest daily .csv files into snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14w7r3g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689026235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst learning how to be a data engineer. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve inherited a process that currently involves:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Vendor sends a daily .csv file to an SFTP&lt;/li&gt;\n&lt;li&gt;Alteryx is used to copy the file to our shared drive, run data transformations, and upload to snowflake. The file is deleted from the SFTP after a successful run in alteryx. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The process usually takes about 15 minutes daily, roughly 400k records each day. I would like to optimize this process and make it better and more secure. For example, I don&amp;#39;t think storing files on a network share drive is smart. &lt;/p&gt;\n\n&lt;p&gt;I have access to GCP resources such as cloud storage and cloud composer (airflow). I&amp;#39;m comfortable writing stored procedures and doing data transformations inside snowflake instead of alteryx. &lt;/p&gt;\n\n&lt;p&gt;How can I best optimize and create a data pipeline to utilize snowflake&amp;#39;s compute resources for transformation and parallelism for ingestion? &lt;/p&gt;\n\n&lt;p&gt;Any thoughts or ideas welcome as I&amp;#39;m very new to these concepts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14w7r3g", "is_robot_indexable": true, "report_reasons": null, "author": "nightslikethese29", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w7r3g/need_advice_setting_up_a_data_pipeline_to_ingest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w7r3g/need_advice_setting_up_a_data_pipeline_to_ingest/", "subreddit_subscribers": 115112, "created_utc": 1689026235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_95ng5rz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turning Data into graphs/ visuals. Can someone help? I\u2019m recording chickens using various colored ramps, feeders, nipples, and balls for a school project to find out their color preference. Can someone point me to the right direction on how to turn this into a graph? Thanks :)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14w6xtj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hhuflwAk9Uppt7wXiszz7ybVX51JFjhsjhC4VqBqXuk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689024425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1r3r0h7sg7bb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1r3r0h7sg7bb1.jpg?auto=webp&amp;v=enabled&amp;s=2bbdf7dfa4421f531947cc9ad833c2964449ca5c", "width": 583, "height": 1825}, "resolutions": [{"url": "https://preview.redd.it/1r3r0h7sg7bb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=372c60388ebdadd23a3d274152bab89103920447", "width": 108, "height": 216}, {"url": "https://preview.redd.it/1r3r0h7sg7bb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=656579805f18f2bd3ef2b017806db23d2aed10c8", "width": 216, "height": 432}, {"url": "https://preview.redd.it/1r3r0h7sg7bb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7dc9af20d00c647ddf653b3a7454b4c947f6b85", "width": 320, "height": 640}], "variants": {}, "id": "byGm1lvJpC90FTbcea0SKRStojf0CzI8_Gl1PD6hyck"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14w6xtj", "is_robot_indexable": true, "report_reasons": null, "author": "Blubberrloverr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w6xtj/turning_data_into_graphs_visuals_can_someone_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1r3r0h7sg7bb1.jpg", "subreddit_subscribers": 115112, "created_utc": 1689024425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a seasoned IT architect currently working with a startup, I wanted to share my journey with you all, as well as some of the valuable insights I've discovered along the way. Here's an article where I dive into how organizations can use BDA to establish a sustainable competitive advantage, and some of the strategies to effectively implement it. I hope you find this beneficial in your own journey as well.\n\n# How to Leverage Big Data Analytics for Sustainable Competitive Advantage\n\nToday's technological era generates a massive amount of data, and businesses everywhere are trying to turn this raw data into actionable insights. Big Data Analytics (BDA) has emerged as a key strategy, helping businesses gain unique insights to unlock new opportunities and differentiate from competitors. Ignoring BDA might leave you trailing behind in the competition, or missing out on potential advantages.\n\nTo achieve the strategic benefits of BDA, you need to understand the processes that allow it to add value and remain competitive. This article offers a guide on how businesses can use several frameworks to evaluate BDA\u2019s strategic value while avoiding pitfalls that come with improper implementation.\n\nThe VRIO framework (Valuable, Rare, Imitable, Organizationally embedded) can help assess the potential of BDA to create strategic business value. It prompts businesses to question if their BDA strategies offer valuable insights, are unique, challenging for competitors to copy, and supported by their organizational strategies and culture.\n\n# Value of Big Data Analytics\n\nThe key strength of Big Data Analytics lies in its ability to provide unique insights that can be used to seize new business opportunities or counter competitive threats. These insights can improve various business areas, including business processes, product innovation, customer experience, and overall organizational performance.\n\n# Uniqueness in Big Data Analytics\n\nBDA becomes unique or 'rare' when few competitors can acquire or possess similar capabilities. Rarity in BDA can be evaluated in two ways: proprietary data content and analytical capability developed through experience.\n\n# Imitating Big Data Analytics\n\nBDA can be difficult and costly for competitors to imitate due to factors like time investment, the uniqueness of proprietary algorithms, and the maturity and culture of a company's IT department.\n\n# Embedding Big Data Analytics\n\nThe final consideration is whether BDA can be organizationally embedded. It can be achieved when BDA aligns with the company's long-term business strategy and is facilitated by processes, policies, organizational structure, and corporate culture.\n\n# Creating Value from Big Data Analytics\n\nCreating strategic value with BDA requires investments in data assets, technological assets, and human talent. A conceptual framework can be proposed to describe how BDA creates strategic business value. This process can be framed by two concepts: Dynamic Capabilities and IT-Value Models. These models help in the capability building and capability realization processes.\n\n# Building Big Data Analytics Capabilities\n\nThe process of turning IT investments into valuable BDA capabilities is dynamic. It includes managing and analyzing data to generate new insights. For this, companies need to develop a BDA strategy and understand how it can create tangible and intangible value.\n\n# Realizing Big Data Analytics Capabilities\n\nThe real value of big data lies not in its volume but in the ability to derive meaningful and actionable insights from it. When utilized effectively, BDA can help refine business processes, develop initiatives, identify flaws or roadblocks, streamline supply chains, understand customers better, predict market trends, and develop new products, services, and business models.\n\nIn the end, creating value from BDA isn't just about having the right tools and capabilities. It's about using those capabilities to generate results, and then turning those results into actions that impact decision-making, improve customer relationships, enhance processes, and more.\n\nI share more articles like this in my blog. If you're interested, you can visit: https://ainsys.com/blog/2023/06/30/bda/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=data\\_engineering&amp;utm\\_content=BDA\\_analytics&amp;utm\\_term=BigData", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Leverage Big Data Analytics for Sustainable Competitive Advantage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14w4sar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689019764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a seasoned IT architect currently working with a startup, I wanted to share my journey with you all, as well as some of the valuable insights I&amp;#39;ve discovered along the way. Here&amp;#39;s an article where I dive into how organizations can use BDA to establish a sustainable competitive advantage, and some of the strategies to effectively implement it. I hope you find this beneficial in your own journey as well.&lt;/p&gt;\n\n&lt;h1&gt;How to Leverage Big Data Analytics for Sustainable Competitive Advantage&lt;/h1&gt;\n\n&lt;p&gt;Today&amp;#39;s technological era generates a massive amount of data, and businesses everywhere are trying to turn this raw data into actionable insights. Big Data Analytics (BDA) has emerged as a key strategy, helping businesses gain unique insights to unlock new opportunities and differentiate from competitors. Ignoring BDA might leave you trailing behind in the competition, or missing out on potential advantages.&lt;/p&gt;\n\n&lt;p&gt;To achieve the strategic benefits of BDA, you need to understand the processes that allow it to add value and remain competitive. This article offers a guide on how businesses can use several frameworks to evaluate BDA\u2019s strategic value while avoiding pitfalls that come with improper implementation.&lt;/p&gt;\n\n&lt;p&gt;The VRIO framework (Valuable, Rare, Imitable, Organizationally embedded) can help assess the potential of BDA to create strategic business value. It prompts businesses to question if their BDA strategies offer valuable insights, are unique, challenging for competitors to copy, and supported by their organizational strategies and culture.&lt;/p&gt;\n\n&lt;h1&gt;Value of Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;The key strength of Big Data Analytics lies in its ability to provide unique insights that can be used to seize new business opportunities or counter competitive threats. These insights can improve various business areas, including business processes, product innovation, customer experience, and overall organizational performance.&lt;/p&gt;\n\n&lt;h1&gt;Uniqueness in Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;BDA becomes unique or &amp;#39;rare&amp;#39; when few competitors can acquire or possess similar capabilities. Rarity in BDA can be evaluated in two ways: proprietary data content and analytical capability developed through experience.&lt;/p&gt;\n\n&lt;h1&gt;Imitating Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;BDA can be difficult and costly for competitors to imitate due to factors like time investment, the uniqueness of proprietary algorithms, and the maturity and culture of a company&amp;#39;s IT department.&lt;/p&gt;\n\n&lt;h1&gt;Embedding Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;The final consideration is whether BDA can be organizationally embedded. It can be achieved when BDA aligns with the company&amp;#39;s long-term business strategy and is facilitated by processes, policies, organizational structure, and corporate culture.&lt;/p&gt;\n\n&lt;h1&gt;Creating Value from Big Data Analytics&lt;/h1&gt;\n\n&lt;p&gt;Creating strategic value with BDA requires investments in data assets, technological assets, and human talent. A conceptual framework can be proposed to describe how BDA creates strategic business value. This process can be framed by two concepts: Dynamic Capabilities and IT-Value Models. These models help in the capability building and capability realization processes.&lt;/p&gt;\n\n&lt;h1&gt;Building Big Data Analytics Capabilities&lt;/h1&gt;\n\n&lt;p&gt;The process of turning IT investments into valuable BDA capabilities is dynamic. It includes managing and analyzing data to generate new insights. For this, companies need to develop a BDA strategy and understand how it can create tangible and intangible value.&lt;/p&gt;\n\n&lt;h1&gt;Realizing Big Data Analytics Capabilities&lt;/h1&gt;\n\n&lt;p&gt;The real value of big data lies not in its volume but in the ability to derive meaningful and actionable insights from it. When utilized effectively, BDA can help refine business processes, develop initiatives, identify flaws or roadblocks, streamline supply chains, understand customers better, predict market trends, and develop new products, services, and business models.&lt;/p&gt;\n\n&lt;p&gt;In the end, creating value from BDA isn&amp;#39;t just about having the right tools and capabilities. It&amp;#39;s about using those capabilities to generate results, and then turning those results into actions that impact decision-making, improve customer relationships, enhance processes, and more.&lt;/p&gt;\n\n&lt;p&gt;I share more articles like this in my blog. If you&amp;#39;re interested, you can visit: &lt;a href=\"https://ainsys.com/blog/2023/06/30/bda/?utm%5C_source=linkedin&amp;amp;utm%5C_medium=social&amp;amp;utm%5C_campaign=data%5C_engineering&amp;amp;utm%5C_content=BDA%5C_analytics&amp;amp;utm%5C_term=BigData\"&gt;https://ainsys.com/blog/2023/06/30/bda/?utm\\_source=linkedin&amp;amp;utm\\_medium=social&amp;amp;utm\\_campaign=data\\_engineering&amp;amp;utm\\_content=BDA\\_analytics&amp;amp;utm\\_term=BigData&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;v=enabled&amp;s=a857d06fc3f1362c48ce1ce4e18be17b3a3dc051", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14w4sar", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w4sar/how_to_leverage_big_data_analytics_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14w4sar/how_to_leverage_big_data_analytics_for/", "subreddit_subscribers": 115112, "created_utc": 1689019764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blog - Project Nessie: A Look in the Depths", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14w4ne0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ITWX1BhUDjRPeQyZeH9WTgLYFOjh6fCMLD1832EXFKY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689019462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/amdatalakehouse/p/project-nessie-a-look-in-the-depths?r=h4f8p&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dJbrTRQwvlmdd-yuOK5lPLCXNPw9xL43G1xU8XFfmdM.jpg?auto=webp&amp;v=enabled&amp;s=fea38d15cb4cc1de6c78c964f4cdd3902216d1e8", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/dJbrTRQwvlmdd-yuOK5lPLCXNPw9xL43G1xU8XFfmdM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d0eb158ec6c544d36e536f8add914bcdf8b0a7b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/dJbrTRQwvlmdd-yuOK5lPLCXNPw9xL43G1xU8XFfmdM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d50a622a5ba891835307893d0f04193748e6ec34", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/dJbrTRQwvlmdd-yuOK5lPLCXNPw9xL43G1xU8XFfmdM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78ab09e88b6b7ef48938b65e49bd7da43cbbe439", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/dJbrTRQwvlmdd-yuOK5lPLCXNPw9xL43G1xU8XFfmdM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63baafbf79db8e533092a67fd525bc2204c24624", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/dJbrTRQwvlmdd-yuOK5lPLCXNPw9xL43G1xU8XFfmdM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f738d7ec26a6a75d7db05e784e28f392ed01d09c", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/dJbrTRQwvlmdd-yuOK5lPLCXNPw9xL43G1xU8XFfmdM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2b35bc0c2eb023fd01e501b4e86a3cffdba7692", "width": 1080, "height": 540}], "variants": {}, "id": "iGtuPJrlmOtHdLK-MoaSG2v2dTx9PXlYvsPf2NyEx08"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14w4ne0", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w4ne0/blog_project_nessie_a_look_in_the_depths/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/amdatalakehouse/p/project-nessie-a-look-in-the-depths?r=h4f8p&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 115112, "created_utc": 1689019462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6b0ljzqy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplify Airflow DAG Creation and Maintenance with Hamilton in 8 minutes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 46, "top_awarded_type": null, "hide_score": false, "name": "t3_14w24v5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GmnE_6tsLIFaYvicsxwEBRTCCw3zjyTde3OVC81k_5s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689013954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/simplify-airflow-dag-creation-and-maintenance-with-hamilton-in-8-minutes-e6e48c9c2cb0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?auto=webp&amp;v=enabled&amp;s=13e9569131364bc511c7acd4c734fc4aa5702446", "width": 1200, "height": 399}, "resolutions": [{"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a635d6c08b7e813e62896835cfd48291f01c566", "width": 108, "height": 35}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2ff3b69d44ca410ce71ef613b2ae6574740a586", "width": 216, "height": 71}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90be6c1c80fb3ca1942c70f10f3eda95e9608d62", "width": 320, "height": 106}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b3726fe137ecf0d989fa30698312b2f6d07df1a", "width": 640, "height": 212}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c830c99800831b207b27d0534259a690e0734e4", "width": 960, "height": 319}, {"url": "https://external-preview.redd.it/K8Y6wj5jxn9Kd9XS-mQHMIarX4_CC0MHU86UarMmZzA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb22c55c50b31c507e1dab5edda08f64f29f6566", "width": 1080, "height": 359}], "variants": {}, "id": "lf_MmlWFw3vqWeN_S2r1zO1KVk616i_sXoaibmTLtYc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14w24v5", "is_robot_indexable": true, "report_reasons": null, "author": "theferalmonkey", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14w24v5/simplify_airflow_dag_creation_and_maintenance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/simplify-airflow-dag-creation-and-maintenance-with-hamilton-in-8-minutes-e6e48c9c2cb0", "subreddit_subscribers": 115112, "created_utc": 1689013954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\nI've a pipeline in Azure data Factory that copies a view (14 columns * average of rows between 12k and 14k) into my DWH.\n\nIt is executed once per week with a pre-copy script as Truncate like Truncates table and insert data.\n\nThe pipelines takes very long (30 minutes) with a throughput of 5-10 kb/s and I've some doubt that doing a truncate and copying the rows is not gonna be the best solution.\nAlso I've put as hypothesis that throughput depends from how much the source is being used.\n\nWould it be time and resource friendly to adopt an Upsert or doing truncate and insert is ok but IR is not optimized ?\n\nCould you share some insights?\nWhen I should use an Upsert and when doing a truncate and insert is best to use?", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to use DataFlow vs Copy activity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vxrk0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689004185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nI&amp;#39;ve a pipeline in Azure data Factory that copies a view (14 columns * average of rows between 12k and 14k) into my DWH.&lt;/p&gt;\n\n&lt;p&gt;It is executed once per week with a pre-copy script as Truncate like Truncates table and insert data.&lt;/p&gt;\n\n&lt;p&gt;The pipelines takes very long (30 minutes) with a throughput of 5-10 kb/s and I&amp;#39;ve some doubt that doing a truncate and copying the rows is not gonna be the best solution.\nAlso I&amp;#39;ve put as hypothesis that throughput depends from how much the source is being used.&lt;/p&gt;\n\n&lt;p&gt;Would it be time and resource friendly to adopt an Upsert or doing truncate and insert is ok but IR is not optimized ?&lt;/p&gt;\n\n&lt;p&gt;Could you share some insights?\nWhen I should use an Upsert and when doing a truncate and insert is best to use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vxrk0", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vxrk0/when_to_use_dataflow_vs_copy_activity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vxrk0/when_to_use_dataflow_vs_copy_activity/", "subreddit_subscribers": 115112, "created_utc": 1689004185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a Data Engineer , I am currently looking for conferences to visit in Europe (this year or next year). Focus can be data Engineering, Analytics Engineering, etc. Any conferences you guys can recommend? Would also be interesting to here about conferences you didn\u2018t like and for what reason", "author_fullname": "t2_aqahrez2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Conferences Europe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vv4b4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688998178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a Data Engineer , I am currently looking for conferences to visit in Europe (this year or next year). Focus can be data Engineering, Analytics Engineering, etc. Any conferences you guys can recommend? Would also be interesting to here about conferences you didn\u2018t like and for what reason&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14vv4b4", "is_robot_indexable": true, "report_reasons": null, "author": "browsingpatx", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vv4b4/de_conferences_europe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vv4b4/de_conferences_europe/", "subreddit_subscribers": 115112, "created_utc": 1688998178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\u00a0\n\n\u00a0\n\nI need to start learning Informatica, IDQ to be specific as it is a new tool in my workplace. I have no experience with anything related with Informatica and my experience with Data has only been working with Tableau as a Data Analyst for a year, so I am familiar with SQL.\u00a0\n\n\u00a0\n\nWhere do you guys recommend to start? I tried youtube tutorials and some random courses but I felt quite lost. If there are any pre-requisites things to learn about first please share them.\u00a0", "author_fullname": "t2_tgljry9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning IDQ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vqf57", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688985658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u00a0&lt;/p&gt;\n\n&lt;p&gt;I need to start learning Informatica, IDQ to be specific as it is a new tool in my workplace. I have no experience with anything related with Informatica and my experience with Data has only been working with Tableau as a Data Analyst for a year, so I am familiar with SQL.\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u00a0&lt;/p&gt;\n\n&lt;p&gt;Where do you guys recommend to start? I tried youtube tutorials and some random courses but I felt quite lost. If there are any pre-requisites things to learn about first please share them.\u00a0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vqf57", "is_robot_indexable": true, "report_reasons": null, "author": "MathematicianAway453", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vqf57/learning_idq/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vqf57/learning_idq/", "subreddit_subscribers": 115112, "created_utc": 1688985658.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}