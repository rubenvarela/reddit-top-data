{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "fyi I\u2019m a DE intern right now, but I\u2019m learning about dbt for the first time and it seems really cool so far\n\nThe main benefits I see are:\n* Time saving\n  * You don\u2019t have to worry about any CREATE TABLE, INSERT INTO, or UPDATE syntax. dbt takes care of all of it for you and converts your sql statement into a new table, which leads to the next point of\u2026\n* Easiness\n  * dbt seems really straightforward. there are \u201cmodels\u201d (which are literally just sql files with select statements in them) that you can chain up with other models to create transformation pipelines. Instead of having to programmatically do the T in ETL, anyone who knows sql can create the data that they need (provided all the data is present in the source table)\n\nI\u2019m working on a personal project that was using mysql, but am migrating to postgres so that I can use dbt. I figure it will simplify things for me on the data cleaning side, as a lot of the logic is heavily embedded in the script and not easily testable/accessible.\n\nI may be getting ahead of myself as I\u2019ve not had the chance to play around with it in depth, but the switch from ETL to ELT with dbt seems like such a good concept", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt seems like such a cool concept", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vcujs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688944095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;fyi I\u2019m a DE intern right now, but I\u2019m learning about dbt for the first time and it seems really cool so far&lt;/p&gt;\n\n&lt;p&gt;The main benefits I see are:\n* Time saving\n  * You don\u2019t have to worry about any CREATE TABLE, INSERT INTO, or UPDATE syntax. dbt takes care of all of it for you and converts your sql statement into a new table, which leads to the next point of\u2026\n* Easiness\n  * dbt seems really straightforward. there are \u201cmodels\u201d (which are literally just sql files with select statements in them) that you can chain up with other models to create transformation pipelines. Instead of having to programmatically do the T in ETL, anyone who knows sql can create the data that they need (provided all the data is present in the source table)&lt;/p&gt;\n\n&lt;p&gt;I\u2019m working on a personal project that was using mysql, but am migrating to postgres so that I can use dbt. I figure it will simplify things for me on the data cleaning side, as a lot of the logic is heavily embedded in the script and not easily testable/accessible.&lt;/p&gt;\n\n&lt;p&gt;I may be getting ahead of myself as I\u2019ve not had the chance to play around with it in depth, but the switch from ETL to ELT with dbt seems like such a good concept&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vcujs", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vcujs/dbt_seems_like_such_a_cool_concept/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vcujs/dbt_seems_like_such_a_cool_concept/", "subreddit_subscribers": 115034, "created_utc": 1688944095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm analyzing large datasets of real estate transactions (CSV) and parcels (xlsx) for public policy research (I'm a CS student). The files are separate for each year and type (1.5 GB total).\n\nThe goal is to merge sales data (left join) to its associated parcel data for the year of the sale.\n\nThen, identity ownership of properties using fuzzy matching on the owner name + address columns to find the largest owners.\n\nI have 2 main challenges I'd appreciate advice on:\n\n\\- I've appended sales data for all years. However, the parcel data is too large to append easily using Pandas on my laptop (memory issues). I think it also makes sense to put these files into a more efficient database or at least file format (parquet perhaps). I might take the approach of merging each year to sales first, that way I don't have to append. But the latter point still stands.\n\n\\- Later I will also want to run fuzzy matching on the dataset, which I've already optimized a bit by comparing owner zip code first and creating smaller buckets of names.\n\nI'm thinking I want to create a database (AWS preferable), then use a lambda function for fuzzy matching. But I'm struggling a bit with the details and which service might be best, especially for the merge... I have slight experience with RDS and Lambda. Thanks!\n\n&amp;#x200B;\n\nEDIT: Thanks for the suggestions! For this instance, it seems cloud is probably overkill, and there were some great suggestions for how to avoid it right now. However, in the future, I will have much larger data, so that was part of the motivation for using this as a first example.", "author_fullname": "t2_4axj4apz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Merging Data Too Big for Pandas + Moving to Cloud for More Compute Power", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14v1nq9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688927412.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688917171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m analyzing large datasets of real estate transactions (CSV) and parcels (xlsx) for public policy research (I&amp;#39;m a CS student). The files are separate for each year and type (1.5 GB total).&lt;/p&gt;\n\n&lt;p&gt;The goal is to merge sales data (left join) to its associated parcel data for the year of the sale.&lt;/p&gt;\n\n&lt;p&gt;Then, identity ownership of properties using fuzzy matching on the owner name + address columns to find the largest owners.&lt;/p&gt;\n\n&lt;p&gt;I have 2 main challenges I&amp;#39;d appreciate advice on:&lt;/p&gt;\n\n&lt;p&gt;- I&amp;#39;ve appended sales data for all years. However, the parcel data is too large to append easily using Pandas on my laptop (memory issues). I think it also makes sense to put these files into a more efficient database or at least file format (parquet perhaps). I might take the approach of merging each year to sales first, that way I don&amp;#39;t have to append. But the latter point still stands.&lt;/p&gt;\n\n&lt;p&gt;- Later I will also want to run fuzzy matching on the dataset, which I&amp;#39;ve already optimized a bit by comparing owner zip code first and creating smaller buckets of names.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking I want to create a database (AWS preferable), then use a lambda function for fuzzy matching. But I&amp;#39;m struggling a bit with the details and which service might be best, especially for the merge... I have slight experience with RDS and Lambda. Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: Thanks for the suggestions! For this instance, it seems cloud is probably overkill, and there were some great suggestions for how to avoid it right now. However, in the future, I will have much larger data, so that was part of the motivation for using this as a first example.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14v1nq9", "is_robot_indexable": true, "report_reasons": null, "author": "waytoopunkrock", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14v1nq9/merging_data_too_big_for_pandas_moving_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14v1nq9/merging_data_too_big_for_pandas_moving_to_cloud/", "subreddit_subscribers": 115034, "created_utc": 1688917171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that a lot of people say data engineering career at FAANG is not a full experience of data engineering, but it\u2019s been my dream to have a career at FAANG. I just started my career as a data engineer not long ago, but the tech stack isn\u2019t very modern and I don\u2019t use Spark and not even Python. We use Informatica to do all the work, so I imagine I would have to build up my experience in other technologies to fulfill the Data Engineer job requirement at FAANG. With that said, how should I prepare for a data engineer interview at FAANG from ground up? I am thinking of applying possibly end of next year, so I will have around ~2YOE or less if I apply earlier. I know that grinding leetcode and statascratch is a must to prepare for the interview, what are some other stuffs? Also what company among the FAANG has the best data engineering experience?", "author_fullname": "t2_cjk2xje6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to break into FAANG?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vicy3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688959306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that a lot of people say data engineering career at FAANG is not a full experience of data engineering, but it\u2019s been my dream to have a career at FAANG. I just started my career as a data engineer not long ago, but the tech stack isn\u2019t very modern and I don\u2019t use Spark and not even Python. We use Informatica to do all the work, so I imagine I would have to build up my experience in other technologies to fulfill the Data Engineer job requirement at FAANG. With that said, how should I prepare for a data engineer interview at FAANG from ground up? I am thinking of applying possibly end of next year, so I will have around ~2YOE or less if I apply earlier. I know that grinding leetcode and statascratch is a must to prepare for the interview, what are some other stuffs? Also what company among the FAANG has the best data engineering experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14vicy3", "is_robot_indexable": true, "report_reasons": null, "author": "highlifeed", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vicy3/how_to_break_into_faang/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vicy3/how_to_break_into_faang/", "subreddit_subscribers": 115034, "created_utc": 1688959306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im seeking interesting ideas for two portfolio projects related to the broad field of electrical energy or neurobiology/biology. For these projects, I would primarily like to utilize **AWS** and **Apache Airflow**. They will be semester-long projects for students. For example, they could include:\n\n1. **Predicting energy demand using meteorological data**\n2. **Optimizing the utilization of renewable energy based on weather forecasts**\n3. **Multidimensional Brain Data Analysis for Neuronal Activity Pattern Identification**\n\nSo I'm looking for an interesting idea, mainly using AWS and at least a bit of Airflow .\n\nDo you have any interesting suggestions? The key factor for me is selecting projects that will engage the students, as they will only be motivated if the projects are meaningful. They are proficient in Python, SQL, and have a basic understanding of AWS.", "author_fullname": "t2_7yv0lkcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Energy or Neurobiology-related Portfolio Projects for cognitive science students.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vrw8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688991230.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688990015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im seeking interesting ideas for two portfolio projects related to the broad field of electrical energy or neurobiology/biology. For these projects, I would primarily like to utilize &lt;strong&gt;AWS&lt;/strong&gt; and &lt;strong&gt;Apache Airflow&lt;/strong&gt;. They will be semester-long projects for students. For example, they could include:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Predicting energy demand using meteorological data&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Optimizing the utilization of renewable energy based on weather forecasts&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Multidimensional Brain Data Analysis for Neuronal Activity Pattern Identification&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for an interesting idea, mainly using AWS and at least a bit of Airflow .&lt;/p&gt;\n\n&lt;p&gt;Do you have any interesting suggestions? The key factor for me is selecting projects that will engage the students, as they will only be motivated if the projects are meaningful. They are proficient in Python, SQL, and have a basic understanding of AWS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vrw8x", "is_robot_indexable": true, "report_reasons": null, "author": "International-Shirt5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vrw8x/looking_for_energy_or_neurobiologyrelated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vrw8x/looking_for_energy_or_neurobiologyrelated/", "subreddit_subscribers": 115034, "created_utc": 1688990015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a project to select the right tools for a centralized data platform where we bring in data from various sources, ingest them into a DW, process the data and send it to destination systems (that include the source system as well). We are exploring Fivetran, Airbyte etc for ingesting the data. However, it just feels a bit weird to know that these tools only support ETL. Isn\u2019t reverse ETL (RETL) just reversing sources and destination connectors? Why aren\u2019t there any tools that can perform both ETL and RETL especially when it\u2019s just the same connectors? For ex: Fivetran has Hubspot connector in the sources list but not in the destination lists. I was expecting these tools to perform both. \n\nAny insights?", "author_fullname": "t2_qwfq9dcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL vs Reverse ETL - why do we have 2 different sets of tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vavtv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688939294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a project to select the right tools for a centralized data platform where we bring in data from various sources, ingest them into a DW, process the data and send it to destination systems (that include the source system as well). We are exploring Fivetran, Airbyte etc for ingesting the data. However, it just feels a bit weird to know that these tools only support ETL. Isn\u2019t reverse ETL (RETL) just reversing sources and destination connectors? Why aren\u2019t there any tools that can perform both ETL and RETL especially when it\u2019s just the same connectors? For ex: Fivetran has Hubspot connector in the sources list but not in the destination lists. I was expecting these tools to perform both. &lt;/p&gt;\n\n&lt;p&gt;Any insights?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vavtv", "is_robot_indexable": true, "report_reasons": null, "author": "Aromatic-Owl1264", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vavtv/etl_vs_reverse_etl_why_do_we_have_2_different/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vavtv/etl_vs_reverse_etl_why_do_we_have_2_different/", "subreddit_subscribers": 115034, "created_utc": 1688939294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently working as a data analyst with around 2 years of experience. I majorly work in R, python, SQL, excel and Tableau with some fundamentals of spark. Though I have written some python scripts for some analysis, I never worked on \"data pipelines\" or any other sort of automation. I now want to make transition to data engineering. I saw on workday that a few DE positions were open last month and are still active. Given the background i have, should I talk to the hiring manager? Or should I prepare more (learn spark, cloud and make some projects and then try) or just talk to the hiring manager? I have already talked to my current manager that I would like to move to DE and he's ok with it. It would be for the first time that I would be going to internal job so any tips/suggestion would be highly appreciated.\nThanks!!", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help: Should I apply for internal job with python and SQL under my belt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vbdmg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688940469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working as a data analyst with around 2 years of experience. I majorly work in R, python, SQL, excel and Tableau with some fundamentals of spark. Though I have written some python scripts for some analysis, I never worked on &amp;quot;data pipelines&amp;quot; or any other sort of automation. I now want to make transition to data engineering. I saw on workday that a few DE positions were open last month and are still active. Given the background i have, should I talk to the hiring manager? Or should I prepare more (learn spark, cloud and make some projects and then try) or just talk to the hiring manager? I have already talked to my current manager that I would like to move to DE and he&amp;#39;s ok with it. It would be for the first time that I would be going to internal job so any tips/suggestion would be highly appreciated.\nThanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14vbdmg", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vbdmg/need_help_should_i_apply_for_internal_job_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vbdmg/need_help_should_i_apply_for_internal_job_with/", "subreddit_subscribers": 115034, "created_utc": 1688940469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nI'm reaching out to this community for some advice regarding my current career situation. Here's a brief overview:\n\n* Graduated with High Distinction from University of Sydney with majors in Computer Science and Data Science.\n* Over 1.5 years of experience as a Data Engineer, proficient in Python, SQL, IaC (Terraform, Puppet), and CI/CD.\n* Currently  on a Grad Working Visa in Sydney, expiring end of next year. Working  towards Permanent Residency (PR) application but it is always uncertain.\n* Recently  switched jobs to a company (XX) as a Data Engineer, but the actual role  differs significantly from the job description. My team mainly use Alteryx for data wrangling, not the Python and ETL work I expected.\n* After  a month at XX, no technical projects have come my way despite me asking  my manager for more coding related tasks. Started looking for new jobs  but facing constant rejections (not even interviews/coding tests),  making me doubt my abilities or if my visa status is hindering me.\n* Losing hope for employer sponsorship due to inability to even secure a job in the first place.\n\nSeeking  advice/suggestions for next steps or insights from anyone who has been  through a similar situation. Please share your thoughts.\n\nThank you in advance.", "author_fullname": "t2_f5yhhz77u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Advice: Struggling with Career as a Data Engineer (Sydney)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vp78r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688981815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out to this community for some advice regarding my current career situation. Here&amp;#39;s a brief overview:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Graduated with High Distinction from University of Sydney with majors in Computer Science and Data Science.&lt;/li&gt;\n&lt;li&gt;Over 1.5 years of experience as a Data Engineer, proficient in Python, SQL, IaC (Terraform, Puppet), and CI/CD.&lt;/li&gt;\n&lt;li&gt;Currently  on a Grad Working Visa in Sydney, expiring end of next year. Working  towards Permanent Residency (PR) application but it is always uncertain.&lt;/li&gt;\n&lt;li&gt;Recently  switched jobs to a company (XX) as a Data Engineer, but the actual role  differs significantly from the job description. My team mainly use Alteryx for data wrangling, not the Python and ETL work I expected.&lt;/li&gt;\n&lt;li&gt;After  a month at XX, no technical projects have come my way despite me asking  my manager for more coding related tasks. Started looking for new jobs  but facing constant rejections (not even interviews/coding tests),  making me doubt my abilities or if my visa status is hindering me.&lt;/li&gt;\n&lt;li&gt;Losing hope for employer sponsorship due to inability to even secure a job in the first place.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Seeking  advice/suggestions for next steps or insights from anyone who has been  through a similar situation. Please share your thoughts.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vp78r", "is_robot_indexable": true, "report_reasons": null, "author": "Many-Local-765", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vp78r/need_advice_struggling_with_career_as_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vp78r/need_advice_struggling_with_career_as_a_data/", "subreddit_subscribers": 115034, "created_utc": 1688981815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello knowledgeable folks,\n\nAre there any tools out there that can upload Excel files to Snowflake with all of the following features?\n\n1) Performant: Can handle multiple files with 100's of thousands of rows in a reasonable time.\n\n2) Allows the user to pick datatypes for each columns, including various date formats (M/D/Y, D/M/Y)\n\n3) Produces basic statistics for each column: max, mean, median, histogram.\n\nI am itching to write my own, but I have a feeling that I would be reinventing the wheel. I refuse to believe that no such tool exists given the ubiquity of Excel files in every organization large and small.\n\n&amp;#x200B;\n\n\\-------\n\nMore Details:\n\n\\------\n\nI deal with a lot of small files Excel files (maximum 100 Mbs) from various clients and online resources. Our usual work flow looks something like this:\n\n1) Business analysts examine the file in Excel, manually, to see what surprise changes the client has done to the agreed file format. If the file is too bad (for example, clientID text field had all its leading zeros dropped because Excel thought it is an integer), we throw the file back to the client and ask for a replacement.\n\n2) Use a rudimentary custom webapp written in R Shiny to read the data to to memory and produce a basic report on each column: mean, max, min for float/int columns, and basic counts for each discrete value in discrete columns. The tool tries to infer datatypes automatically but it often gets this step wrong (mostly fumbles with different international date formats and confuses Int/Text for ID fields). \n\n3) The webapp loads the data to a staging table in Snowflake using ODBC driver (Super slow compared to Python's Snowflake driver).\n\n4) Append the data from step 3 to existing tables after some more quality checks are performed.\n\nI found the Excel add-in for Snowflake ([https://github.com/Snowflake-Labs/Excelerator](https://github.com/Snowflake-Labs/Excelerator)) to be performant and useful for ad-hoc files, but it keeps crashing every time there is an update to Excel. It doesn't seem like it is actively maintained. It also lacks any data quality checks and has a clunky interface.", "author_fullname": "t2_i6lqi6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool for Loading Adhoc Excel Files to Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vl0ga", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688967646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello knowledgeable folks,&lt;/p&gt;\n\n&lt;p&gt;Are there any tools out there that can upload Excel files to Snowflake with all of the following features?&lt;/p&gt;\n\n&lt;p&gt;1) Performant: Can handle multiple files with 100&amp;#39;s of thousands of rows in a reasonable time.&lt;/p&gt;\n\n&lt;p&gt;2) Allows the user to pick datatypes for each columns, including various date formats (M/D/Y, D/M/Y)&lt;/p&gt;\n\n&lt;p&gt;3) Produces basic statistics for each column: max, mean, median, histogram.&lt;/p&gt;\n\n&lt;p&gt;I am itching to write my own, but I have a feeling that I would be reinventing the wheel. I refuse to believe that no such tool exists given the ubiquity of Excel files in every organization large and small.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;-------&lt;/p&gt;\n\n&lt;p&gt;More Details:&lt;/p&gt;\n\n&lt;p&gt;------&lt;/p&gt;\n\n&lt;p&gt;I deal with a lot of small files Excel files (maximum 100 Mbs) from various clients and online resources. Our usual work flow looks something like this:&lt;/p&gt;\n\n&lt;p&gt;1) Business analysts examine the file in Excel, manually, to see what surprise changes the client has done to the agreed file format. If the file is too bad (for example, clientID text field had all its leading zeros dropped because Excel thought it is an integer), we throw the file back to the client and ask for a replacement.&lt;/p&gt;\n\n&lt;p&gt;2) Use a rudimentary custom webapp written in R Shiny to read the data to to memory and produce a basic report on each column: mean, max, min for float/int columns, and basic counts for each discrete value in discrete columns. The tool tries to infer datatypes automatically but it often gets this step wrong (mostly fumbles with different international date formats and confuses Int/Text for ID fields). &lt;/p&gt;\n\n&lt;p&gt;3) The webapp loads the data to a staging table in Snowflake using ODBC driver (Super slow compared to Python&amp;#39;s Snowflake driver).&lt;/p&gt;\n\n&lt;p&gt;4) Append the data from step 3 to existing tables after some more quality checks are performed.&lt;/p&gt;\n\n&lt;p&gt;I found the Excel add-in for Snowflake (&lt;a href=\"https://github.com/Snowflake-Labs/Excelerator\"&gt;https://github.com/Snowflake-Labs/Excelerator&lt;/a&gt;) to be performant and useful for ad-hoc files, but it keeps crashing every time there is an update to Excel. It doesn&amp;#39;t seem like it is actively maintained. It also lacks any data quality checks and has a clunky interface.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?auto=webp&amp;v=enabled&amp;s=b65829b6f00f14d8202715c94ce14e0fc76d4bcb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2a75f109eb155cf707260fae1934198eb0d300c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f76cb80f0130fccfce2d6511783dfebb5eb113f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8b34c8b078f3a3bd60775c76312445ba052e06d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a10c6f7149015bf5ad3014f687f8ee09cc30aeb", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0655042714c6f9a463a22b08139c8a1c917780d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/vIoi-_0WlMOBIeA2kuzCgVW8roA87hFQqgT50hCI2bc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ddd9b9664f39b73f103d51e95f847a18ff48ec5", "width": 1080, "height": 540}], "variants": {}, "id": "iF5rXm76OKp383uxb97mIrFI17Wizf7gUQ1dW--G5Ak"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vl0ga", "is_robot_indexable": true, "report_reasons": null, "author": "fgoussou", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vl0ga/tool_for_loading_adhoc_excel_files_to_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vl0ga/tool_for_loading_adhoc_excel_files_to_warehouse/", "subreddit_subscribers": 115034, "created_utc": 1688967646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "have any of you seen environments that either completely abandoned the star schema approach or maybe followed it 1/2 way that were successful on their own and just worked? Examples could include building lots of wide tables for example that support the business and just work", "author_fullname": "t2_daehbbsip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "alternatives to the traditional star schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14v3765", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688920945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;have any of you seen environments that either completely abandoned the star schema approach or maybe followed it 1/2 way that were successful on their own and just worked? Examples could include building lots of wide tables for example that support the business and just work&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14v3765", "is_robot_indexable": true, "report_reasons": null, "author": "Tough-Error520", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14v3765/alternatives_to_the_traditional_star_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14v3765/alternatives_to_the_traditional_star_schema/", "subreddit_subscribers": 115034, "created_utc": 1688920945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4ipsx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast Joins in Apache Beam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14v23hp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1688918262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ahalbert.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ahalbert.com/technology/2023/07/08/fast_beam_joins.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14v23hp", "is_robot_indexable": true, "report_reasons": null, "author": "troikaman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14v23hp/fast_joins_in_apache_beam/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ahalbert.com/technology/2023/07/08/fast_beam_joins.html", "subreddit_subscribers": 115034, "created_utc": 1688918262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what is a decent salary (per month, before taxes) in Sweden (Stockholm) for a data engineer with less than 2  YOE and no other prior technical background? I am preparing for an interview and I want to know how much to ask in case I'm asked", "author_fullname": "t2_iiiar3v5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salaries in Sweden", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vpyst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688986349.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688984233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what is a decent salary (per month, before taxes) in Sweden (Stockholm) for a data engineer with less than 2  YOE and no other prior technical background? I am preparing for an interview and I want to know how much to ask in case I&amp;#39;m asked&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14vpyst", "is_robot_indexable": true, "report_reasons": null, "author": "23reddituser", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vpyst/salaries_in_sweden/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vpyst/salaries_in_sweden/", "subreddit_subscribers": 115034, "created_utc": 1688984233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the smoothest implementation of an ELT pipeline on the Azure stack (main db is azure sql server) using dbt?", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smooth implementation of dbt in Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vnzzx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688977770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the smoothest implementation of an ELT pipeline on the Azure stack (main db is azure sql server) using dbt?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vnzzx", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vnzzx/smooth_implementation_of_dbt_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vnzzx/smooth_implementation_of_dbt_in_azure/", "subreddit_subscribers": 115034, "created_utc": 1688977770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm in Spain and there's a career called \"Science and Data Engineering\", I've been searching but I found each of them separated, either Science Engineering or Data Engineering, therefore, is this a mix of both? Would I be able to apply to the jobs a Science Engineer or Data Engineer would be able?", "author_fullname": "t2_vbavvuww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is \"Science and Data Engineering\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vdt3p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688946545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m in Spain and there&amp;#39;s a career called &amp;quot;Science and Data Engineering&amp;quot;, I&amp;#39;ve been searching but I found each of them separated, either Science Engineering or Data Engineering, therefore, is this a mix of both? Would I be able to apply to the jobs a Science Engineer or Data Engineer would be able?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vdt3p", "is_robot_indexable": true, "report_reasons": null, "author": "DismemberedBunny", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vdt3p/what_is_science_and_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vdt3p/what_is_science_and_data_engineering/", "subreddit_subscribers": 115034, "created_utc": 1688946545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "California privacy act and similar data protection laws allows users to request that their data be hard deleted from source systems. I've been wracking my brain trying to figure out how to implement something like this. My team uses a kafka/dbt/snowflake stack, and I'm a bit lost as to how hard deletes could flow through data warehouse models. I assume others have dealt with this as it's a legal thing - has anyone implemented this? What was your approach?", "author_fullname": "t2_5e0ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you implementing CCPA compliance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14vutj2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688997497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;California privacy act and similar data protection laws allows users to request that their data be hard deleted from source systems. I&amp;#39;ve been wracking my brain trying to figure out how to implement something like this. My team uses a kafka/dbt/snowflake stack, and I&amp;#39;m a bit lost as to how hard deletes could flow through data warehouse models. I assume others have dealt with this as it&amp;#39;s a legal thing - has anyone implemented this? What was your approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14vutj2", "is_robot_indexable": true, "report_reasons": null, "author": "harrytrumanprimate", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vutj2/how_are_you_implementing_ccpa_compliance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vutj2/how_are_you_implementing_ccpa_compliance/", "subreddit_subscribers": 115034, "created_utc": 1688997497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \nI'm building a CI/CD Pipeline for power bi. We have some reports which are not allowed to be exported by some users.\nI want to programmatically disable the export option of some table visual in some reports. I didn't find any API endpoint that does this operation. I also want to programmatically hide some pages in some reports during the deployment. Is there any way to achieve this?\n\nThanks in advance", "author_fullname": "t2_pp0zirow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power BI operation LS that are not supported by API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14vttnt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688995073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nI&amp;#39;m building a CI/CD Pipeline for power bi. We have some reports which are not allowed to be exported by some users.\nI want to programmatically disable the export option of some table visual in some reports. I didn&amp;#39;t find any API endpoint that does this operation. I also want to programmatically hide some pages in some reports during the deployment. Is there any way to achieve this?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vttnt", "is_robot_indexable": true, "report_reasons": null, "author": "These_Rip_9327", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vttnt/power_bi_operation_ls_that_are_not_supported_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vttnt/power_bi_operation_ls_that_are_not_supported_by/", "subreddit_subscribers": 115034, "created_utc": 1688995073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\u00a0\n\n\u00a0\n\nI need to start learning Informatica, IDQ to be specific as it is a new tool in my workplace. I have no experience with anything related with Informatica and my experience with Data has only been working with Tableau as a Data Analyst for a year, so I am familiar with SQL.\u00a0\n\n\u00a0\n\nWhere do you guys recommend to start? I tried youtube tutorials and some random courses but I felt quite lost. If there are any pre-requisites things to learn about first please share them.\u00a0", "author_fullname": "t2_tgljry9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning IDQ", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vqf57", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688985658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u00a0&lt;/p&gt;\n\n&lt;p&gt;I need to start learning Informatica, IDQ to be specific as it is a new tool in my workplace. I have no experience with anything related with Informatica and my experience with Data has only been working with Tableau as a Data Analyst for a year, so I am familiar with SQL.\u00a0&lt;/p&gt;\n\n&lt;p&gt;\u00a0&lt;/p&gt;\n\n&lt;p&gt;Where do you guys recommend to start? I tried youtube tutorials and some random courses but I felt quite lost. If there are any pre-requisites things to learn about first please share them.\u00a0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vqf57", "is_robot_indexable": true, "report_reasons": null, "author": "MathematicianAway453", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vqf57/learning_idq/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vqf57/learning_idq/", "subreddit_subscribers": 115034, "created_utc": 1688985658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI'm seeking your input on purchasing a suitable laptop for coding purposes, specifically for practicing Hadoop and other big data tools. I would appreciate your advice on what key features to consider to ensure I make the right choice.\n\nGiven the abundance of options available, ranging from i3 to i9 processors across multiple generations, I find myself in a state of confusion. While I understand that the latest models tend to be more expensive, I am primarily looking for a budget-friendly option. \n\nBudget: \u20b945k-50k INR \n\nPS: this is for my friend.\n\n[View Poll](https://www.reddit.com/poll/14vq5gx)", "author_fullname": "t2_8h8kwca0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good Windows Laptop for Big data practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vq5gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688987172.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688984820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seeking your input on purchasing a suitable laptop for coding purposes, specifically for practicing Hadoop and other big data tools. I would appreciate your advice on what key features to consider to ensure I make the right choice.&lt;/p&gt;\n\n&lt;p&gt;Given the abundance of options available, ranging from i3 to i9 processors across multiple generations, I find myself in a state of confusion. While I understand that the latest models tend to be more expensive, I am primarily looking for a budget-friendly option. &lt;/p&gt;\n\n&lt;p&gt;Budget: \u20b945k-50k INR &lt;/p&gt;\n\n&lt;p&gt;PS: this is for my friend.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14vq5gx\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14vq5gx", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Veterinarian-45", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1689330420297, "options": [{"text": "i3", "id": "23826446"}, {"text": "i5", "id": "23826447"}, {"text": "i7", "id": "23826448"}, {"text": "i9", "id": "23826449"}, {"text": "Others (please comment)", "id": "23826450"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 126, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vq5gx/good_windows_laptop_for_big_data_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/14vq5gx/good_windows_laptop_for_big_data_practice/", "subreddit_subscribers": 115034, "created_utc": 1688984820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data Warehouses help support business intelligence activities and streamline critical decision-making processes by making data centralized and easily accessible. \n\nRead more: [https://www.dasca.org/world-of-big-data/article/what-is-a-data-warehouse-and-why-is-it-important](https://www.dasca.org/world-of-big-data/article/what-is-a-data-warehouse-and-why-is-it-important)", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a Data Warehouse and why is it Important?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14vmcuu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.13, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688972150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Warehouses help support business intelligence activities and streamline critical decision-making processes by making data centralized and easily accessible. &lt;/p&gt;\n\n&lt;p&gt;Read more: &lt;a href=\"https://www.dasca.org/world-of-big-data/article/what-is-a-data-warehouse-and-why-is-it-important\"&gt;https://www.dasca.org/world-of-big-data/article/what-is-a-data-warehouse-and-why-is-it-important&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MAJ0l11J1wYLVC4dtN5-5ecv9RdeM_XmYRDcIkRpYOI.jpg?auto=webp&amp;v=enabled&amp;s=83840873f187bd409ae18642fc1f4a70474ebec0", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/MAJ0l11J1wYLVC4dtN5-5ecv9RdeM_XmYRDcIkRpYOI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d6e39252813c0b9a459c952511db442209cfd99", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/MAJ0l11J1wYLVC4dtN5-5ecv9RdeM_XmYRDcIkRpYOI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2ab09b746fbe4cee73f5342645ac2a6c9e07f64", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/MAJ0l11J1wYLVC4dtN5-5ecv9RdeM_XmYRDcIkRpYOI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b782e8b91b8deaff617cd471c1a3c8e21edf6f10", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/MAJ0l11J1wYLVC4dtN5-5ecv9RdeM_XmYRDcIkRpYOI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efba6dd5c7db044c5f07fce2a93f57c7fd383535", "width": 640, "height": 336}], "variants": {}, "id": "Q_PvZARInfX2O9qwADHSO3s_THng07kypCHnbcydqLs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14vmcuu", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14vmcuu/what_is_a_data_warehouse_and_why_is_it_important/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14vmcuu/what_is_a_data_warehouse_and_why_is_it_important/", "subreddit_subscribers": 115034, "created_utc": 1688972150.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}