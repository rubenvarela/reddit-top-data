{"kind": "Listing", "data": {"after": "t3_151s5ki", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few days ago, our data scientist gave me some of his SQL code to put in production.  I quickly glanced over it -- it was neat and tidy, well formatted, organised and filled with helpful comments.  \"Shouldn't be a big deal.  Give me a few days to review it.\"\n\nI looked at it more closely today and realised it's actually mess.  Badly written, inefficient, breaks the DRY approach repeatedly, doesn't comply with naming standards, the lot.  I get back to the guy and ask him to explain some of the SQL statements because they're confusing to me. He admits that a lot of it was actually written by ChatGPT and he isn't sure what it's doing.  But he politely asks me when will his code be put into production, thank you very much?\n\nYou have code that you can't actually explain *as the developer yourself* but you still expect it to be put in production?\n\nI tell him a need a bit more time.  And he cheerfully tells me that he'll be happy to do it himself *if I'd just give him admin access to production.*", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists -- Ok, now I get it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151xsis", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 410, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 410, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689588707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few days ago, our data scientist gave me some of his SQL code to put in production.  I quickly glanced over it -- it was neat and tidy, well formatted, organised and filled with helpful comments.  &amp;quot;Shouldn&amp;#39;t be a big deal.  Give me a few days to review it.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I looked at it more closely today and realised it&amp;#39;s actually mess.  Badly written, inefficient, breaks the DRY approach repeatedly, doesn&amp;#39;t comply with naming standards, the lot.  I get back to the guy and ask him to explain some of the SQL statements because they&amp;#39;re confusing to me. He admits that a lot of it was actually written by ChatGPT and he isn&amp;#39;t sure what it&amp;#39;s doing.  But he politely asks me when will his code be put into production, thank you very much?&lt;/p&gt;\n\n&lt;p&gt;You have code that you can&amp;#39;t actually explain &lt;em&gt;as the developer yourself&lt;/em&gt; but you still expect it to be put in production?&lt;/p&gt;\n\n&lt;p&gt;I tell him a need a bit more time.  And he cheerfully tells me that he&amp;#39;ll be happy to do it himself &lt;em&gt;if I&amp;#39;d just give him admin access to production.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151xsis", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 175, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151xsis/data_scientists_ok_now_i_get_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151xsis/data_scientists_ok_now_i_get_it/", "subreddit_subscribers": 116447, "created_utc": 1689588707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is interested in having a no code platform so that we can democratize data access and mitigate shitty practices like shared drive hoarding. We are looking at Palantir but it's absurdly expensive. I've never really dabbled with \"tools\" like that because I've never come across something truly no code that worked well.\n\nCurious if anyone here has used Palantir's Foundry or other tools that give non technical users a place to search and see data exists, do their data manipulation, exploration and then visualization on both tabular and time series data.", "author_fullname": "t2_c10zsd9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best no-code platforms you have come across?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151yrep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689591732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is interested in having a no code platform so that we can democratize data access and mitigate shitty practices like shared drive hoarding. We are looking at Palantir but it&amp;#39;s absurdly expensive. I&amp;#39;ve never really dabbled with &amp;quot;tools&amp;quot; like that because I&amp;#39;ve never come across something truly no code that worked well.&lt;/p&gt;\n\n&lt;p&gt;Curious if anyone here has used Palantir&amp;#39;s Foundry or other tools that give non technical users a place to search and see data exists, do their data manipulation, exploration and then visualization on both tabular and time series data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151yrep", "is_robot_indexable": true, "report_reasons": null, "author": "EmoryCadet", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151yrep/what_are_the_best_nocode_platforms_you_have_come/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151yrep/what_are_the_best_nocode_platforms_you_have_come/", "subreddit_subscribers": 116447, "created_utc": 1689591732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've noticed a scary trend lately in this sub where every now and then someone pops out fearing for the future of this career or how we'll be replaced by AI. I know anecdotal evidence is crap, but at least I haven't seen a lower demand of dataengs, I can still find a decent number of job postings requesting dataengs for companies. Am I missing something? What's going on? I can understand that companies are demanding experienced dataengs, but for real, this field was never meant for newly grads.", "author_fullname": "t2_4cvl041d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "META: What's with the doomposting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151uv83", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689578738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed a scary trend lately in this sub where every now and then someone pops out fearing for the future of this career or how we&amp;#39;ll be replaced by AI. I know anecdotal evidence is crap, but at least I haven&amp;#39;t seen a lower demand of dataengs, I can still find a decent number of job postings requesting dataengs for companies. Am I missing something? What&amp;#39;s going on? I can understand that companies are demanding experienced dataengs, but for real, this field was never meant for newly grads.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151uv83", "is_robot_indexable": true, "report_reasons": null, "author": "FlowOfAir", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151uv83/meta_whats_with_the_doomposting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151uv83/meta_whats_with_the_doomposting/", "subreddit_subscribers": 116447, "created_utc": 1689578738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that it\u2019s just a job and I should just take the pay check and do my 9-5, but I\u2019m starting to despise my non technical teammates and managers. I\u2019ve had to make all design decisions and train new hires when it comes to data. My manager does not have the technical knowledge to offer any advice or plan any forward looking strategy, when there are tons of opportunities to modernize our stack.\n\nLooking for advice from folks who\u2019s been in similar situations on ways to navigate being the only technical person supporting the entire data infrastructure of the company. How do I make the best out of my situation until I leave? Thanks!", "author_fullname": "t2_sslx78ms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to not hate your job when you\u2019re the only DE supporting a non-tech company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151svfk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689572320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that it\u2019s just a job and I should just take the pay check and do my 9-5, but I\u2019m starting to despise my non technical teammates and managers. I\u2019ve had to make all design decisions and train new hires when it comes to data. My manager does not have the technical knowledge to offer any advice or plan any forward looking strategy, when there are tons of opportunities to modernize our stack.&lt;/p&gt;\n\n&lt;p&gt;Looking for advice from folks who\u2019s been in similar situations on ways to navigate being the only technical person supporting the entire data infrastructure of the company. How do I make the best out of my situation until I leave? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "151svfk", "is_robot_indexable": true, "report_reasons": null, "author": "jadedorca", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151svfk/how_to_not_hate_your_job_when_youre_the_only_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151svfk/how_to_not_hate_your_job_when_youre_the_only_de/", "subreddit_subscribers": 116447, "created_utc": 1689572320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to data engineering, and I like to learn by trying/building. I am very unclear what's the best way to go about it?\n\nMy ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?", "author_fullname": "t2_17d42esw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best \"free\" set-up to learn or try to build a data pipeline on my own?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152c49r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689623684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to data engineering, and I like to learn by trying/building. I am very unclear what&amp;#39;s the best way to go about it?&lt;/p&gt;\n\n&lt;p&gt;My ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152c49r", "is_robot_indexable": true, "report_reasons": null, "author": "Guyserbun007", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "subreddit_subscribers": 116447, "created_utc": 1689623684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nOur small team has just finished the data preparation phase of our project and started data analysis in Databricks. As we go deeper into this field, we're trying to understand the distinctions and appropriate uses for a Feature Store versus a Data Catalog. On the surface, it seems to me that both are ways to manage and use tables of data.\n\nFor example, let's consider a churn prediction. We need to create a table (or several) for churn prediction and join later, which would include multiple features that could potentially influence a user's possibility to churn. It appears to me that we could just create a new table in a Data Catalog with this information. However, I am not sure if this is the right approach or if a Feature Store could be more suitable.\n\nHere are my questions\n\n1. In what situations would we prefer to use a Feature Store over a Data Catalog, or vice versa?\n2. In the context of our Churn Prediction example, would it be more beneficial to use a Feature Store? If so, why?\n3. If we were to use a Feature Store in this scenario, what would that look like in terms of setup and workflow?\n\nReally appreciate every help, ideally, any examples would be great. I'm very noob using Databricks, and a real-world approach would be very very helpful.\n\nThanks for the help in advance.", "author_fullname": "t2_akunr53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Differences between Feature Store and Data Catalog in Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151v5uw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689579758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Our small team has just finished the data preparation phase of our project and started data analysis in Databricks. As we go deeper into this field, we&amp;#39;re trying to understand the distinctions and appropriate uses for a Feature Store versus a Data Catalog. On the surface, it seems to me that both are ways to manage and use tables of data.&lt;/p&gt;\n\n&lt;p&gt;For example, let&amp;#39;s consider a churn prediction. We need to create a table (or several) for churn prediction and join later, which would include multiple features that could potentially influence a user&amp;#39;s possibility to churn. It appears to me that we could just create a new table in a Data Catalog with this information. However, I am not sure if this is the right approach or if a Feature Store could be more suitable.&lt;/p&gt;\n\n&lt;p&gt;Here are my questions&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;In what situations would we prefer to use a Feature Store over a Data Catalog, or vice versa?&lt;/li&gt;\n&lt;li&gt;In the context of our Churn Prediction example, would it be more beneficial to use a Feature Store? If so, why?&lt;/li&gt;\n&lt;li&gt;If we were to use a Feature Store in this scenario, what would that look like in terms of setup and workflow?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Really appreciate every help, ideally, any examples would be great. I&amp;#39;m very noob using Databricks, and a real-world approach would be very very helpful.&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151v5uw", "is_robot_indexable": true, "report_reasons": null, "author": "north_pr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151v5uw/differences_between_feature_store_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151v5uw/differences_between_feature_store_and_data/", "subreddit_subscribers": 116447, "created_utc": 1689579758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?", "author_fullname": "t2_c532a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What steps to take after first role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1524trd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689607060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1524trd", "is_robot_indexable": true, "report_reasons": null, "author": "gators939", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "subreddit_subscribers": 116447, "created_utc": 1689607060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would like to find some questions practicing for DE interview. I mostly use leetcode to practice DSA, and leetcode have multiple tags like 'array', 'binary tree' when I want to practice specific topics.\n\nHowever, there seems no similar tag for SQL problems on leetcode. I believe SQL have various type of questions, and I want to practice specific topics (join, aggregation, window function...etc) not wondering around and look at all kinds of problems.\n\nIs there any website that may have specific topics to practice SQL questions?  \nOr more specifically, SQL practicing websites for DE interview?  \n\n\nThanks a lot!", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there SQL questions practice website with specific topics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15226ql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689600967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to find some questions practicing for DE interview. I mostly use leetcode to practice DSA, and leetcode have multiple tags like &amp;#39;array&amp;#39;, &amp;#39;binary tree&amp;#39; when I want to practice specific topics.&lt;/p&gt;\n\n&lt;p&gt;However, there seems no similar tag for SQL problems on leetcode. I believe SQL have various type of questions, and I want to practice specific topics (join, aggregation, window function...etc) not wondering around and look at all kinds of problems.&lt;/p&gt;\n\n&lt;p&gt;Is there any website that may have specific topics to practice SQL questions?&lt;br/&gt;\nOr more specifically, SQL practicing websites for DE interview?  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15226ql", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15226ql/is_there_sql_questions_practice_website_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15226ql/is_there_sql_questions_practice_website_with/", "subreddit_subscribers": 116447, "created_utc": 1689600967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone inviting you to join our Hackathon!!  \nIn this hackathon, you are going to create a wildfire early warning system for the fictional island nation of Zakar. Zakar has been struggling with wildfires in the last few years. \n\nThe best project will get the perfect gaming package!\n\nfor more info - [Save Zakar Hackathon](https://medium.com/memphis-dev/you-have-a-chance-to-save-the-world-d789dcd55f87)\n\n[Sign up](https://www.hackathon.memphis.dev/)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time Data and AI using open source tools Hackathon!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1520dzi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689596371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone inviting you to join our Hackathon!!&lt;br/&gt;\nIn this hackathon, you are going to create a wildfire early warning system for the fictional island nation of Zakar. Zakar has been struggling with wildfires in the last few years. &lt;/p&gt;\n\n&lt;p&gt;The best project will get the perfect gaming package!&lt;/p&gt;\n\n&lt;p&gt;for more info - &lt;a href=\"https://medium.com/memphis-dev/you-have-a-chance-to-save-the-world-d789dcd55f87\"&gt;Save Zakar Hackathon&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.hackathon.memphis.dev/\"&gt;Sign up&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?auto=webp&amp;s=e410859561599d680b0aab559597ce32e4d8c6f3", "width": 1200, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ffad9c57fc8cd00aa80bce283c5f0a08db3c968c", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e25613eaa09a34d2ec37a6fffb5d7321a2424cd", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=125279964d45a8bc6fd9a8be6353524433b7c684", "width": 320, "height": 96}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a013995f51636b54e30590c6423546b212a21538", "width": 640, "height": 192}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5601c7067416e834d46c0aaa2ad77eff38d9964f", "width": 960, "height": 288}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=075957b9f1cbc341c510b446761005e7e3b4a919", "width": 1080, "height": 324}], "variants": {}, "id": "FG0dihaZdabzhgCH3l_ddvb59OmQJlKMVavnIZV_W2c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1520dzi", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1520dzi/realtime_data_and_ai_using_open_source_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1520dzi/realtime_data_and_ai_using_open_source_tools/", "subreddit_subscribers": 116447, "created_utc": 1689596371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team uses dbt and would like to share the documentation created with other teams in our company. Those teams don't have access to our dbt. \n\nI'm trying to figure out a way to do this that is private - only people with the link can access it. I looked into github pages but did not like that a github page is pretty easy to guess the url for. We don't have enterprise Github. \n\nWould the best option be to pay for Netlify?", "author_fullname": "t2_capkx7wn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to surface dbt docs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151utkk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689578575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team uses dbt and would like to share the documentation created with other teams in our company. Those teams don&amp;#39;t have access to our dbt. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out a way to do this that is private - only people with the link can access it. I looked into github pages but did not like that a github page is pretty easy to guess the url for. We don&amp;#39;t have enterprise Github. &lt;/p&gt;\n\n&lt;p&gt;Would the best option be to pay for Netlify?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151utkk", "is_robot_indexable": true, "report_reasons": null, "author": "Wide-Pop6050", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151utkk/best_way_to_surface_dbt_docs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151utkk/best_way_to_surface_dbt_docs/", "subreddit_subscribers": 116447, "created_utc": 1689578575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4t6cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM based pipelines with PostgresML and dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_1525yyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z3TI0arYlw4RRR3jUUbPUO2vA2egarxlpp1dP09FXtE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689609669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "postgresml.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?auto=webp&amp;s=0b690342c0b9264e580cd8629721f878d18ff954", "width": 784, "height": 519}, "resolutions": [{"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf6a365fbb7793932f29fbb28fa434d479b46d55", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0effd2b3a0537c8131fd28109ff37439457f1ddc", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d160cb4efab6957e3d11789882fe0b658cafe87e", "width": 320, "height": 211}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e154f104eedac0bc7c9e36c987df586978c19eb0", "width": 640, "height": 423}], "variants": {}, "id": "dxDnyB5RtYkyN-bX3C7E2eUqvQzE9_-FZU6xkZ1aDRQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1525yyl", "is_robot_indexable": true, "report_reasons": null, "author": "something_cleverer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525yyl/llm_based_pipelines_with_postgresml_and_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "subreddit_subscribers": 116447, "created_utc": 1689609669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my company which is a startup is hiring web scrapers to scrape data(financial data) from the websites, and load into S3 and as usual it goes to the database.\nWill this even going to work?", "author_fullname": "t2_es0ctl93", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is web scraping even an authentic data source to move forward with?or buying the data/API worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1520xun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689597849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my company which is a startup is hiring web scrapers to scrape data(financial data) from the websites, and load into S3 and as usual it goes to the database.\nWill this even going to work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1520xun", "is_robot_indexable": true, "report_reasons": null, "author": "Grand-Knowledge-4044", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1520xun/is_web_scraping_even_an_authentic_data_source_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1520xun/is_web_scraping_even_an_authentic_data_source_to/", "subreddit_subscribers": 116447, "created_utc": 1689597849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey guys,\nWe have a table in delta format where we have enabled schema evolution. \nLets consider a table having column X which is struct and have multi level nested keys. \n\nE.g. - X.Y.Z.A\n\nNow, Databricks is trying to convert Z to struct, I want it to convert it to String\nZ has 10k keys. \n\nHow do we solve for this?\n\nWe\u2019re following this approach:\n1. get ddl for table \n2. recreate the table with schema of Z as string.", "author_fullname": "t2_3dsjwu75", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is best way to change existing schema in delta[Databricks]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151voz1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689581588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys,\nWe have a table in delta format where we have enabled schema evolution. \nLets consider a table having column X which is struct and have multi level nested keys. &lt;/p&gt;\n\n&lt;p&gt;E.g. - X.Y.Z.A&lt;/p&gt;\n\n&lt;p&gt;Now, Databricks is trying to convert Z to struct, I want it to convert it to String\nZ has 10k keys. &lt;/p&gt;\n\n&lt;p&gt;How do we solve for this?&lt;/p&gt;\n\n&lt;p&gt;We\u2019re following this approach:\n1. get ddl for table \n2. recreate the table with schema of Z as string.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151voz1", "is_robot_indexable": true, "report_reasons": null, "author": "mannu_11", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151voz1/what_is_best_way_to_change_existing_schema_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151voz1/what_is_best_way_to_change_existing_schema_in/", "subreddit_subscribers": 116447, "created_utc": 1689581588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have connected our ADF pipelines with Purview but the complete lineage is not being shown in Purview. We are able to see the flow from Stage to Interim but not from Interim to Target.", "author_fullname": "t2_3pvqv38j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft Purview not showing complete lineage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151s5fb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689570006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have connected our ADF pipelines with Purview but the complete lineage is not being shown in Purview. We are able to see the flow from Stage to Interim but not from Interim to Target.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151s5fb", "is_robot_indexable": true, "report_reasons": null, "author": "Dev-98", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151s5fb/microsoft_purview_not_showing_complete_lineage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151s5fb/microsoft_purview_not_showing_complete_lineage/", "subreddit_subscribers": 116447, "created_utc": 1689570006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I need some output regarding this situation.  \nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post \"submit\", as soon as that happens, the job needs to be submitted!  \nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can't really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?  \nLove to know your thoughts!  \nThanks", "author_fullname": "t2_xqvyn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink Batch Job needs to run based on a trigger", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152m3hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689648465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I need some output regarding this situation.&lt;br/&gt;\nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post &amp;quot;submit&amp;quot;, as soon as that happens, the job needs to be submitted!&lt;br/&gt;\nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can&amp;#39;t really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?&lt;br/&gt;\nLove to know your thoughts!&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152m3hr", "is_robot_indexable": true, "report_reasons": null, "author": "Salekeen01", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "subreddit_subscribers": 116447, "created_utc": 1689648465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious about how well the open source self-hosted version works, and how it compares feature-wise to the cloud version. Thanks!", "author_fullname": "t2_brgtw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have experience self-hosting Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152lvk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689647841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious about how well the open source self-hosted version works, and how it compares feature-wise to the cloud version. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152lvk5", "is_robot_indexable": true, "report_reasons": null, "author": "kdamica", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152lvk5/does_anyone_have_experience_selfhosting_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152lvk5/does_anyone_have_experience_selfhosting_airbyte/", "subreddit_subscribers": 116447, "created_utc": 1689647841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:\n\n* bucket\n   * tbl\\_1\n      * data1.csv\n      * data2.csv\n   * tbl\\_2\n      * data1.csv\n      * data2.csv\n\nI'm successfully creating a streaming live table for both tbl\\_1 and tbl\\_2 by invoking autoloader, using the `@dlt.table` decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. \n\nThe problem I'm facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I'm only able to query the data if and only if it was loaded in the previous run of the dlt workflow.", "author_fullname": "t2_789pafin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding how Delta Live Tables (DLT) and Unity Catalog work in tandem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152k8kp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689643337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;bucket\n\n&lt;ul&gt;\n&lt;li&gt;tbl_1\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;tbl_2\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m successfully creating a streaming live table for both tbl_1 and tbl_2 by invoking autoloader, using the &lt;code&gt;@dlt.table&lt;/code&gt; decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. &lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I&amp;#39;m only able to query the data if and only if it was loaded in the previous run of the dlt workflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152k8kp", "is_robot_indexable": true, "report_reasons": null, "author": "_nudist_buddhist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "subreddit_subscribers": 116447, "created_utc": 1689643337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work as an R&amp;D Test  Engineer in the Microelectronics industry and I'm looking for a title of  some type of Software/Data engineering position to search for.\n\nA little bit of background -- my current role is to process all of our data taken from our test equipment while characterizing our integrated  circuits during on-wafer probe testing. I manipulate all of our test  data into usable format where I then plot the information according to internal/external customers wants and needs.\n\nFrom here, I normalize all of our test data taken from the lab and import everything through a data pipeline via the libraries and packages below. Next, I try to find a correlation between the process control monitors (PCM) and our test data taken from the lab. Process control monitors are random data points on the wafer that gives us information on wafer oxidation thickness, capacitance values, leakage values and so on that are distributed to us from the manufacturer. I'll use different statistical methods such as Bi-Serial Point Methods, Linear Regression and the use of histograms for example. If I find something of high correlation between the PCM data our test data, I'll dive deeper and analyze it. The whole point of this is to predict wafer yield based on a PCM data range and lab collected test data.\n\nLastly, we use machine learning models to predict our next lot's yield based off the high correlation PCM data/test data. I am new to building machine learning models and machine learning as a whole, but I've enjoyed this process so much I'm thinking about getting a Masters in either Machine Learning, Applied Data Science or something along those lines.\n\n**The libraries and packages I use are:** Python, NumPy, Pandas, Matplotlib, Pytorch, Keras, SciPy, Scikit learn and not an exhaustive list.\n\nI may be looking for a new job soon if I am switched into another role in the company that I don't want to do, which I wont get into here.\n\nAnyway, if I wanted to dive deeper into this type of role or job, what job title should search for?\n\nThanks all", "author_fullname": "t2_1ra6klf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152k2qc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689642897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work as an R&amp;amp;D Test  Engineer in the Microelectronics industry and I&amp;#39;m looking for a title of  some type of Software/Data engineering position to search for.&lt;/p&gt;\n\n&lt;p&gt;A little bit of background -- my current role is to process all of our data taken from our test equipment while characterizing our integrated  circuits during on-wafer probe testing. I manipulate all of our test  data into usable format where I then plot the information according to internal/external customers wants and needs.&lt;/p&gt;\n\n&lt;p&gt;From here, I normalize all of our test data taken from the lab and import everything through a data pipeline via the libraries and packages below. Next, I try to find a correlation between the process control monitors (PCM) and our test data taken from the lab. Process control monitors are random data points on the wafer that gives us information on wafer oxidation thickness, capacitance values, leakage values and so on that are distributed to us from the manufacturer. I&amp;#39;ll use different statistical methods such as Bi-Serial Point Methods, Linear Regression and the use of histograms for example. If I find something of high correlation between the PCM data our test data, I&amp;#39;ll dive deeper and analyze it. The whole point of this is to predict wafer yield based on a PCM data range and lab collected test data.&lt;/p&gt;\n\n&lt;p&gt;Lastly, we use machine learning models to predict our next lot&amp;#39;s yield based off the high correlation PCM data/test data. I am new to building machine learning models and machine learning as a whole, but I&amp;#39;ve enjoyed this process so much I&amp;#39;m thinking about getting a Masters in either Machine Learning, Applied Data Science or something along those lines.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The libraries and packages I use are:&lt;/strong&gt; Python, NumPy, Pandas, Matplotlib, Pytorch, Keras, SciPy, Scikit learn and not an exhaustive list.&lt;/p&gt;\n\n&lt;p&gt;I may be looking for a new job soon if I am switched into another role in the company that I don&amp;#39;t want to do, which I wont get into here.&lt;/p&gt;\n\n&lt;p&gt;Anyway, if I wanted to dive deeper into this type of role or job, what job title should search for?&lt;/p&gt;\n\n&lt;p&gt;Thanks all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152k2qc", "is_robot_indexable": true, "report_reasons": null, "author": "Upgrayyedd43", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152k2qc/job_title/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152k2qc/job_title/", "subreddit_subscribers": 116447, "created_utc": 1689642897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking of building such a tool that can\n\n\\- Aggregate all pipeline status on one page\n\n\\- Manage notifications for different systems\n\n\\- Unify incident reports\n\nI did some research only to find a 3 yo post. [https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline\\_monitoring\\_tool/](https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/)\n\nI'm wondering if there's existing tools doing this / if not, anyone has the need?", "author_fullname": "t2_6mmm3ywiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unified pipeline monitoring tool / all-in-one pipeline status page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152cldb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689624752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking of building such a tool that can&lt;/p&gt;\n\n&lt;p&gt;- Aggregate all pipeline status on one page&lt;/p&gt;\n\n&lt;p&gt;- Manage notifications for different systems&lt;/p&gt;\n\n&lt;p&gt;- Unify incident reports&lt;/p&gt;\n\n&lt;p&gt;I did some research only to find a 3 yo post. &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/\"&gt;https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if there&amp;#39;s existing tools doing this / if not, anyone has the need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152cldb", "is_robot_indexable": true, "report_reasons": null, "author": "WEI3M", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "subreddit_subscribers": 116447, "created_utc": 1689624752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9uiwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you really need exactly-once delivery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15270yt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nwqg-bA9yKtkh-5nBchWxMPm0l24EuljbLUBOPM3qYc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689612063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "streamingdata.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?auto=webp&amp;s=04d6977076f8d968368d6533d4d93bcc4e03f4d3", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=febf87d18ab938c89253d5e7d0697e337bf0e88e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c37da59f1936c995870386de473bad9a4a0c1260", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a059a8e1f66d01ae2eb0b0a1b4572e8187739f1a", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e139e12aa841bac14920bb64d92f70324e0d70d0", "width": 640, "height": 333}], "variants": {}, "id": "TL5zSeeNMw6fBGF0Ca693DL1GL7baDPqZ8ZyarYmuos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15270yt", "is_robot_indexable": true, "report_reasons": null, "author": "sap1enz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15270yt/do_you_really_need_exactlyonce_delivery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "subreddit_subscribers": 116447, "created_utc": 1689612063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a [retrieval-augmented generation](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html) use case (a.k.a. chat with your data).\n\n&amp;#x200B;\n\nMy current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like [https://www.chaindesk.ai/](https://www.chaindesk.ai/) but they feel a bit too limiting for my use case.", "author_fullname": "t2_2s6nwgck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move semi-structured data to LLMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1526j16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689610913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a &lt;a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html\"&gt;retrieval-augmented generation&lt;/a&gt; use case (a.k.a. chat with your data).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like &lt;a href=\"https://www.chaindesk.ai/\"&gt;https://www.chaindesk.ai/&lt;/a&gt; but they feel a bit too limiting for my use case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1526j16", "is_robot_indexable": true, "report_reasons": null, "author": "shrifbot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "subreddit_subscribers": 116447, "created_utc": 1689610913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse - event data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1525pib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689609082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1525pib", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525pib/lakehouse_event_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1525pib/lakehouse_event_data/", "subreddit_subscribers": 116447, "created_utc": 1689609082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to help my wife switch her domains. she is currently a FTE at infosys with \\~6 years experience in the IT Services domain. She spent 5 years at IBM before joining Infy in same project.\n\nShe has extensive onsite experience where she worked with IBM Australia with Westpac back.\n\nAs expected, she has stagnated massively and will become completely disconnected with tech if she continues in these companies. One rather seamless switch that we feel she can pursue is moving to Snowflake platform and pursuing a career in either dev or as an analyst.\n\nShe has been following tuts from multiple resources and aiming a certification as well, but lack of enough hands-on experience is making her nervous and preventing her from focussing on studies.\n\nGiven the current market situation, job opportunities are not easy either.\n\nHow can she explore internal switch within Infy to pursue Snowflake? Otherwise, how can she overall pursue this switch? We are f9 with her taking up contract positions as well as long as she gets to work on Snowflake.", "author_fullname": "t2_11mmk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "snowflake employment help for my wife", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1520p8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689597208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to help my wife switch her domains. she is currently a FTE at infosys with ~6 years experience in the IT Services domain. She spent 5 years at IBM before joining Infy in same project.&lt;/p&gt;\n\n&lt;p&gt;She has extensive onsite experience where she worked with IBM Australia with Westpac back.&lt;/p&gt;\n\n&lt;p&gt;As expected, she has stagnated massively and will become completely disconnected with tech if she continues in these companies. One rather seamless switch that we feel she can pursue is moving to Snowflake platform and pursuing a career in either dev or as an analyst.&lt;/p&gt;\n\n&lt;p&gt;She has been following tuts from multiple resources and aiming a certification as well, but lack of enough hands-on experience is making her nervous and preventing her from focussing on studies.&lt;/p&gt;\n\n&lt;p&gt;Given the current market situation, job opportunities are not easy either.&lt;/p&gt;\n\n&lt;p&gt;How can she explore internal switch within Infy to pursue Snowflake? Otherwise, how can she overall pursue this switch? We are f9 with her taking up contract positions as well as long as she gets to work on Snowflake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1520p8f", "is_robot_indexable": true, "report_reasons": null, "author": "Pbd1194", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1520p8f/snowflake_employment_help_for_my_wife/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1520p8f/snowflake_employment_help_for_my_wife/", "subreddit_subscribers": 116447, "created_utc": 1689597208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello, everyone!\n\nI am currently working on a project to build an ETL (Extract, Transform, Load) pipeline, and I would greatly appreciate some advice and guidance from the Reddit community.\n\nHere's a brief overview of the project: I am tasked with downloading data from an AWS S3 bucket, performing transformations using Pyspark, and loading the transformed data into a Postgres database. This is my first project of this nature, and I need to schedule this task to run automatically on a weekly basis.\n\nOne specific challenge I am facing is the need to compare the last six months of data in the S3 bucket with the data already present in the Postgres database. If any changes are detected in the S3 data, I need to overwrite the corresponding data in the Postgres database. The amount of data can range between 15-20 GB.\n\nI am currently using Pyspark for data transformations, but I would appreciate any recommendations or best practices on efficiently comparing and updating the data between S3 and Postgres.\n\nAdditionally, I am in the process of selecting a suitable tool for scheduling and managing ETL tasks. I have set up Airflow, but I am uncertain whether it is the best fit for this project. I would love to hear your thoughts and experiences with scheduling ETL tasks, particularly for a scenario like mine.\n\nThank you in advance for any advice, suggestions, or insights you can provide. I am eager to learn from your expertise and make this ETL pipeline project a success!", "author_fullname": "t2_fjuwxuxxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on Building an ETL Pipeline with AWS S3, Postgres, and Pyspark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151yksz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689591190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, everyone!&lt;/p&gt;\n\n&lt;p&gt;I am currently working on a project to build an ETL (Extract, Transform, Load) pipeline, and I would greatly appreciate some advice and guidance from the Reddit community.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a brief overview of the project: I am tasked with downloading data from an AWS S3 bucket, performing transformations using Pyspark, and loading the transformed data into a Postgres database. This is my first project of this nature, and I need to schedule this task to run automatically on a weekly basis.&lt;/p&gt;\n\n&lt;p&gt;One specific challenge I am facing is the need to compare the last six months of data in the S3 bucket with the data already present in the Postgres database. If any changes are detected in the S3 data, I need to overwrite the corresponding data in the Postgres database. The amount of data can range between 15-20 GB.&lt;/p&gt;\n\n&lt;p&gt;I am currently using Pyspark for data transformations, but I would appreciate any recommendations or best practices on efficiently comparing and updating the data between S3 and Postgres.&lt;/p&gt;\n\n&lt;p&gt;Additionally, I am in the process of selecting a suitable tool for scheduling and managing ETL tasks. I have set up Airflow, but I am uncertain whether it is the best fit for this project. I would love to hear your thoughts and experiences with scheduling ETL tasks, particularly for a scenario like mine.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any advice, suggestions, or insights you can provide. I am eager to learn from your expertise and make this ETL pipeline project a success!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151yksz", "is_robot_indexable": true, "report_reasons": null, "author": "Data_is_fuel", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151yksz/advice_on_building_an_etl_pipeline_with_aws_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151yksz/advice_on_building_an_etl_pipeline_with_aws_s3/", "subreddit_subscribers": 116447, "created_utc": 1689591190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nAs you read it from title, I have an interview round ( which is 2nd round ) on designing the data pipelines. The interviewer told me, there wont be any live coding round, but we would design a data pipeline. Can you please help with your experience on what all should we be prepared? Any resources will help me a lot\n\nThanks in advance :)", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Interview] Data pipeline design round", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151s5ki", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689570019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;As you read it from title, I have an interview round ( which is 2nd round ) on designing the data pipelines. The interviewer told me, there wont be any live coding round, but we would design a data pipeline. Can you please help with your experience on what all should we be prepared? Any resources will help me a lot&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "151s5ki", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/151s5ki/interview_data_pipeline_design_round/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151s5ki/interview_data_pipeline_design_round/", "subreddit_subscribers": 116447, "created_utc": 1689570019.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}