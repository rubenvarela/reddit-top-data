{"kind": "Listing", "data": {"after": "t3_152rbb9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "the devs chose mongo again smh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1531jz7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1wovt-2KDMfbJTLurQgHZgiNp-IDc2CTIZY-AeUUyLM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689694124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ux9wsli3sqcb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ux9wsli3sqcb1.png?auto=webp&amp;s=3ca5ab02a97dcefb30ae3db2136e41f324562a0e", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://preview.redd.it/ux9wsli3sqcb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5d1bbf374af3b3ce4d6a5988b50fb59cf9385feb", "width": 108, "height": 108}, {"url": "https://preview.redd.it/ux9wsli3sqcb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b38fc642829334b4bb4f7cfab52bd61fa4c0d7ed", "width": 216, "height": 216}, {"url": "https://preview.redd.it/ux9wsli3sqcb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5d180dd0fbc1bd6e14abc010173bc8eed17f70bd", "width": 320, "height": 320}, {"url": "https://preview.redd.it/ux9wsli3sqcb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a7db6f2ac28cac2ad10b1f476a9b4ad8df0f46f6", "width": 640, "height": 640}, {"url": "https://preview.redd.it/ux9wsli3sqcb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=582c77ccfdb1a204e0acd12139d5cddc5571d76e", "width": 960, "height": 960}, {"url": "https://preview.redd.it/ux9wsli3sqcb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d9471b8ef9b34e31d89c891cc415cfb318d8ccfb", "width": 1080, "height": 1080}], "variants": {}, "id": "lmYt0kjBxhR8yCXlum05JPYX3_bpkaVBH7DuKoN5Grg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1531jz7", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1531jz7/the_devs_chose_mongo_again_smh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ux9wsli3sqcb1.png", "subreddit_subscribers": 116631, "created_utc": 1689694124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a big tech company as a new grad and my title is technically data engineer, however much of my work is building distributed Python applications for ML and data replication, spark, Java, devops pipelines and infrastructure automation (ansible). If I write sql, it\u2019s always within a Python application and is nothing more than an insert, table creation or simple select query. With my experience, would I be more suited to go into software engineer roles moving forward? Scared of applying to companies that use modern data stack or no-code tools and I am stuck having to re-learn SQL or failing an interview.\n\nEdit: I\u2019d consider myself average at SQL, I\u2019ve passed all-SQL interviews, just worried about my skills atrophying as it\u2019s not something I really enjoy to use and my role doesn\u2019t require it", "author_fullname": "t2_7szv7c66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am a new grad \u201cdata engineer\u201d who barely writes SQL, how will my career be impacted?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152own3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689657321.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689656717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a big tech company as a new grad and my title is technically data engineer, however much of my work is building distributed Python applications for ML and data replication, spark, Java, devops pipelines and infrastructure automation (ansible). If I write sql, it\u2019s always within a Python application and is nothing more than an insert, table creation or simple select query. With my experience, would I be more suited to go into software engineer roles moving forward? Scared of applying to companies that use modern data stack or no-code tools and I am stuck having to re-learn SQL or failing an interview.&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019d consider myself average at SQL, I\u2019ve passed all-SQL interviews, just worried about my skills atrophying as it\u2019s not something I really enjoy to use and my role doesn\u2019t require it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152own3", "is_robot_indexable": true, "report_reasons": null, "author": "aacreans", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152own3/i_am_a_new_grad_data_engineer_who_barely_writes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152own3/i_am_a_new_grad_data_engineer_who_barely_writes/", "subreddit_subscribers": 116631, "created_utc": 1689656717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vu1osuil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free copy of \"Fundamentals of Data Engineering\" to learn DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_152yp2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": "transparent", "ups": 42, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GJI0r0i8VjTz63FENoduduO-aG2eafmRRKm-m4dFnog.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689687366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "go.redpanda.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://go.redpanda.com/fundamentals-of-data-engineering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?auto=webp&amp;s=6f9d8b67339ba2e24729a4a01e4af69d6901708f", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=236e8977b4b29caf518afabda6cb27e5578688e7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=67afdf69c3c0cbf2a5888fd982265c8c751faf88", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5fecab72d37c8cfac0c5625ef320265d80e8a454", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f977129c4dd4d0d928d0ef1fd8faac749207bddf", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8cb4b8b9e83333f6fb4cf1e964fc483caf512f4f", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=62b640989f071b0f21f1905b5666d573f4193741", "width": 1080, "height": 565}], "variants": {}, "id": "DvdgYgQFkuNvhWsi5MycPv45U50YDo5lni76VGlxImw"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152yp2h", "is_robot_indexable": true, "report_reasons": null, "author": "TemporaryPoorFrench", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/152yp2h/free_copy_of_fundamentals_of_data_engineering_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://go.redpanda.com/fundamentals-of-data-engineering", "subreddit_subscribers": 116631, "created_utc": 1689687366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I study 15 hours a day 7 days a week trying to make my dream a reality. ETL, ELT, coding, learning Python, SQL, reading entire chapters of data engineering books and outlining them on paper and then on the computer to make sure it sticks... Then there are people here asking and basically bragging about having a data engineer position where they do literally nothing. No actual data engineering, maybe some light leg work or job responsibilities, and some minor SQL. \n\n\nWhat I want to know is how. How are people getting these? Where do I get one?", "author_fullname": "t2_vnan4h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are people getting into data engineering with basically no responsibilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152w0h7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689680210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I study 15 hours a day 7 days a week trying to make my dream a reality. ETL, ELT, coding, learning Python, SQL, reading entire chapters of data engineering books and outlining them on paper and then on the computer to make sure it sticks... Then there are people here asking and basically bragging about having a data engineer position where they do literally nothing. No actual data engineering, maybe some light leg work or job responsibilities, and some minor SQL. &lt;/p&gt;\n\n&lt;p&gt;What I want to know is how. How are people getting these? Where do I get one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152w0h7", "is_robot_indexable": true, "report_reasons": null, "author": "Analyst2163", "discussion_type": null, "num_comments": 78, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152w0h7/how_are_people_getting_into_data_engineering_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152w0h7/how_are_people_getting_into_data_engineering_with/", "subreddit_subscribers": 116631, "created_utc": 1689680210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Two years ago I transitioned from Systems Analyst (app dev) to Data Engineer.  I am the only Data Engineer in our company.  When I transitioned, not only did I continue maintaining all of my legacy projects, but I have since taken over all cloud app development in Azure, designed and maintained our API Management Gateways for third-party devs and vendors (multiple environments, dozens of API products), created numerous backend APIs, implemented most file/data exchange processes between our company and third-parties, created numerous ETL processes which includes many replication jobs from third-parties apps, etc.  I did much of this as a level 1 DE (I am now level 2).  I am trying to understand how much of this is actual Data Engineering and how much of it is something else (Cloud App Development?).  I also am curious what level I should be.\n\nAdditional context:  5+ years with the company.", "author_fullname": "t2_4d6r2kn6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is my role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152z2bq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689689718.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689688281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Two years ago I transitioned from Systems Analyst (app dev) to Data Engineer.  I am the only Data Engineer in our company.  When I transitioned, not only did I continue maintaining all of my legacy projects, but I have since taken over all cloud app development in Azure, designed and maintained our API Management Gateways for third-party devs and vendors (multiple environments, dozens of API products), created numerous backend APIs, implemented most file/data exchange processes between our company and third-parties, created numerous ETL processes which includes many replication jobs from third-parties apps, etc.  I did much of this as a level 1 DE (I am now level 2).  I am trying to understand how much of this is actual Data Engineering and how much of it is something else (Cloud App Development?).  I also am curious what level I should be.&lt;/p&gt;\n\n&lt;p&gt;Additional context:  5+ years with the company.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152z2bq", "is_robot_indexable": true, "report_reasons": null, "author": "1_0-0_1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152z2bq/what_is_my_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152z2bq/what_is_my_role/", "subreddit_subscribers": 116631, "created_utc": 1689688281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When you picked your data warehouse platform or if you would pick again, what are the most important themes for you in how you make that selection?For example:\n\n* Installation Simplicity\n* Simplcity of operations\n* Security\n* Query performance\n* Cost\n* Integrations\n* Migration effort\n* Cloud vs on-prem\n* anything else ???\n\nWhat was at the top of your list? Is there anything you regret about the data warehouse technology you ended up with? What questions would you have asked before making the decision in hindsight?", "author_fullname": "t2_plry86zh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What makes a good data warehouse platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1532ylc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689697307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When you picked your data warehouse platform or if you would pick again, what are the most important themes for you in how you make that selection?For example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Installation Simplicity&lt;/li&gt;\n&lt;li&gt;Simplcity of operations&lt;/li&gt;\n&lt;li&gt;Security&lt;/li&gt;\n&lt;li&gt;Query performance&lt;/li&gt;\n&lt;li&gt;Cost&lt;/li&gt;\n&lt;li&gt;Integrations&lt;/li&gt;\n&lt;li&gt;Migration effort&lt;/li&gt;\n&lt;li&gt;Cloud vs on-prem&lt;/li&gt;\n&lt;li&gt;anything else ???&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What was at the top of your list? Is there anything you regret about the data warehouse technology you ended up with? What questions would you have asked before making the decision in hindsight?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1532ylc", "is_robot_indexable": true, "report_reasons": null, "author": "doubleblair", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1532ylc/what_makes_a_good_data_warehouse_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1532ylc/what_makes_a_good_data_warehouse_platform/", "subreddit_subscribers": 116631, "created_utc": 1689697307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:\n\n* bucket\n   * tbl\\_1\n      * data1.csv\n      * data2.csv\n   * tbl\\_2\n      * data1.csv\n      * data2.csv\n\nI'm successfully creating a streaming live table for both tbl\\_1 and tbl\\_2 by invoking autoloader, using the `@dlt.table` decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. \n\nThe problem I'm facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I'm only able to query the data if and only if it was loaded in the previous run of the dlt workflow.", "author_fullname": "t2_789pafin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding how Delta Live Tables (DLT) and Unity Catalog work in tandem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152k8kp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689643337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;bucket\n\n&lt;ul&gt;\n&lt;li&gt;tbl_1\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;tbl_2\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m successfully creating a streaming live table for both tbl_1 and tbl_2 by invoking autoloader, using the &lt;code&gt;@dlt.table&lt;/code&gt; decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. &lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I&amp;#39;m only able to query the data if and only if it was loaded in the previous run of the dlt workflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152k8kp", "is_robot_indexable": true, "report_reasons": null, "author": "_nudist_buddhist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "subreddit_subscribers": 116631, "created_utc": 1689643337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR - you mini-interview, we donate: [VideoAsk Mini-Interview](https://www.videoask.com/fisb43vgs) \n\nI'm a founder at a small data startup, and we are looking for input from Data/Analytics/BI Engineers related to the problem our tool is solving; I am a DE myself and am too close to our solution to be objective. \n\n**We decided instead of paying a marketing research group, we would take a shot with the communities we are part of (like this one) and donate our small research budget to good causes instead.** (mini-interview Link is above, here it is again):\n\n[VideoAsk Mini-Interview](https://www.videoask.com/fisb43vgs) \n\nFor every completed (applicable) mini-interview we'll donate $5 to either [code.org](https://code.org) or [phillyPAWS](https://phillypaws.org/) (our local rescue here in Philadelphia) until we run out of $$ (we will shut the survey down before then, no free lunches on our part).   \nby \"applicable\" we mean the respondent is either a data or software professional or works directly with data/software professionals.", "author_fullname": "t2_dilsfh4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For every Data Professional mini-interview we'll donate $5 to dogs or code.org", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1537puk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689708241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR - you mini-interview, we donate: &lt;a href=\"https://www.videoask.com/fisb43vgs\"&gt;VideoAsk Mini-Interview&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a founder at a small data startup, and we are looking for input from Data/Analytics/BI Engineers related to the problem our tool is solving; I am a DE myself and am too close to our solution to be objective. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;We decided instead of paying a marketing research group, we would take a shot with the communities we are part of (like this one) and donate our small research budget to good causes instead.&lt;/strong&gt; (mini-interview Link is above, here it is again):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.videoask.com/fisb43vgs\"&gt;VideoAsk Mini-Interview&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;For every completed (applicable) mini-interview we&amp;#39;ll donate $5 to either &lt;a href=\"https://code.org\"&gt;code.org&lt;/a&gt; or &lt;a href=\"https://phillypaws.org/\"&gt;phillyPAWS&lt;/a&gt; (our local rescue here in Philadelphia) until we run out of $$ (we will shut the survey down before then, no free lunches on our part).&lt;br/&gt;\nby &amp;quot;applicable&amp;quot; we mean the respondent is either a data or software professional or works directly with data/software professionals.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vAgrqUzBXR6rK9eslleCs9MhwVsp2LtVbgk5LNAGvf8.jpg?auto=webp&amp;s=54eb457a178d1a2f8d5b8ec0c59601357ed9c5df", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/vAgrqUzBXR6rK9eslleCs9MhwVsp2LtVbgk5LNAGvf8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=47391c61e0302e14c4c7a003ea94a70c5327fc17", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/vAgrqUzBXR6rK9eslleCs9MhwVsp2LtVbgk5LNAGvf8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=885c32075812ee41c63f825a070b6967f1e016a0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/vAgrqUzBXR6rK9eslleCs9MhwVsp2LtVbgk5LNAGvf8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf00bd66185d4fc18e7211516a5619f9c01e1fd8", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/vAgrqUzBXR6rK9eslleCs9MhwVsp2LtVbgk5LNAGvf8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac037a629514a6c2f4b6b4fde66a556edb2db7d3", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/vAgrqUzBXR6rK9eslleCs9MhwVsp2LtVbgk5LNAGvf8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=44882261d6778024f5348d95f10764cda7f9b0bb", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/vAgrqUzBXR6rK9eslleCs9MhwVsp2LtVbgk5LNAGvf8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aca94bf69b7fd3c42ff2d3307257d37643e08a74", "width": 1080, "height": 567}], "variants": {}, "id": "_eefME0VHeiJVwdc9ToiHwgOJ9nypQUidjH9mzYLfys"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1537puk", "is_robot_indexable": true, "report_reasons": null, "author": "sprintymcsprintface", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1537puk/for_every_data_professional_miniinterview_well/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1537puk/for_every_data_professional_miniinterview_well/", "subreddit_subscribers": 116631, "created_utc": 1689708241.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are just about to build the gold layer in our data lake but unsure of how to organize the directories. We aim to have a kimball model for each project, but unsure where to store the dimension tables (are in delta format). Should we create directories inside the gold container for each model and duplicate shared dimension tables? How do you guys set this up in your orgs? We have the facts and dims in their respective delta tables.", "author_fullname": "t2_56ltry44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building the gold container in the medallion architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1537lly", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689707982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are just about to build the gold layer in our data lake but unsure of how to organize the directories. We aim to have a kimball model for each project, but unsure where to store the dimension tables (are in delta format). Should we create directories inside the gold container for each model and duplicate shared dimension tables? How do you guys set this up in your orgs? We have the facts and dims in their respective delta tables.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1537lly", "is_robot_indexable": true, "report_reasons": null, "author": "Specific-Passage", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1537lly/building_the_gold_container_in_the_medallion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1537lly/building_the_gold_container_in_the_medallion/", "subreddit_subscribers": 116631, "created_utc": 1689707982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey ya'll, Airflow builds are breaking today. Yesterday Cython jumped to version 3.0, which caused \\`pymssql\\` to break. That breakage is causing Airflow to break as well.\n\nMy company doesn't use Airflow, but it bit us because we use pymssql in our application. We had to fork pymssql and pin to an earlier version of Cython.\n\nJust hoping to save someone a couple hours of investigation", "author_fullname": "t2_hoxsyt4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow Builds Breaking", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1532mzq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689696579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey ya&amp;#39;ll, Airflow builds are breaking today. Yesterday Cython jumped to version 3.0, which caused `pymssql` to break. That breakage is causing Airflow to break as well.&lt;/p&gt;\n\n&lt;p&gt;My company doesn&amp;#39;t use Airflow, but it bit us because we use pymssql in our application. We had to fork pymssql and pin to an earlier version of Cython.&lt;/p&gt;\n\n&lt;p&gt;Just hoping to save someone a couple hours of investigation&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1532mzq", "is_robot_indexable": true, "report_reasons": null, "author": "AnySherbet", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1532mzq/airflow_builds_breaking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1532mzq/airflow_builds_breaking/", "subreddit_subscribers": 116631, "created_utc": 1689696579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI'm working at a company that needs to take data from health care records and put it into a data warehouse for machine learning and analysis.  I've never done anything like this before, and was wondering if there was anyone in the community who has accomplished a similar task and was willing to chat.\n\nWe're using Google Cloud for our data services right now.  I'm interested in using their Healthcare API as it looks promising, although I'm open to other solutions: [https://cloud.google.com/healthcare-api](https://cloud.google.com/healthcare-api).  Curious to hear what other peoples' thoughts are.", "author_fullname": "t2_aewcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice from Experts on Electronic Health Record Integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1531r59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689694564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working at a company that needs to take data from health care records and put it into a data warehouse for machine learning and analysis.  I&amp;#39;ve never done anything like this before, and was wondering if there was anyone in the community who has accomplished a similar task and was willing to chat.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re using Google Cloud for our data services right now.  I&amp;#39;m interested in using their Healthcare API as it looks promising, although I&amp;#39;m open to other solutions: &lt;a href=\"https://cloud.google.com/healthcare-api\"&gt;https://cloud.google.com/healthcare-api&lt;/a&gt;.  Curious to hear what other peoples&amp;#39; thoughts are.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?auto=webp&amp;s=ada93f0d146c09556ac26cc3fa125a0aa7102150", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=05af26b5ec35c95ed95b5c40dbde3c1cc04dce06", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f36f0de65cdcbed3b705b8446710c7c83e0475e4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4067aebaadaec227b271d9c19c7af833c230fd32", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec46bff13e5c5bc616be11b375484d9d2a7fcbe8", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5db472c15d5717384ab8f8f64e9fd89efe70fa59", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fab49c1958487e16d598ede6d81140177c5c9a31", "width": 1080, "height": 567}], "variants": {}, "id": "DsiOIzUSicS_9zIKwMDQbNT2LOE1o29sSYs49HAmO_k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1531r59", "is_robot_indexable": true, "report_reasons": null, "author": "i_am_baldilocks", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1531r59/seeking_advice_from_experts_on_electronic_health/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1531r59/seeking_advice_from_experts_on_electronic_health/", "subreddit_subscribers": 116631, "created_utc": 1689694564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, I'd like to share my current situation to understand better where to go.\n\nI started in data as a ETL developer since 2011, I did projects using DataStream (old Cognos), PowerCenter, SSIS, Talend, SAS and even VBA up to 2016 when I joined a data visualization tool company as consultant mainly focused to create conceptual DB models and reports/dashboards with this tool. However since 2018 composed by 2 periods (2016-2021 and from 2022- up-to-date)   most of my projects were related to upgrade servers to newer software versions, configuration etc. There were a couple projects here and there that were related to predictive analytics with python and/or R, NoSQL, Hadoop, Query performance, data ingestion, but summing all of this it is no more than 10% of my time.\n\nWithin 2021 I left this job for a ecommerce company which I had to work with python, Big Query, Teradata, Presto etc. But unfortunately I had to leave it to immigrate which was a bigger dream. That's why I re-joined the previously mentioned company.\n\nI feel that I have the requirements, I never stopped to study, I'm pretty good in query performance, data modeling, user specification, also know python, Scala, AWS, data bricks. a bunch of databases (SQL Server, Oracle, Teradata, MySQL, Big Query, Redshift, Snowflake, PostgreSQL) and I also know a little docker due to home projects, yet I've applied for almost 50 openings and didn't got any replies/interviews even diposed to earn a little less than I'm currently making if necessary. Sometimes I fell that the extended period working for the data viz company kinda put a stamp on me saying that I'm not capable of doing a DE job.\n\nMy question is, is it possible to go to a DE path?", "author_fullname": "t2_8c1ywuv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From data specific consultant to DE path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152y27j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689685752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I&amp;#39;d like to share my current situation to understand better where to go.&lt;/p&gt;\n\n&lt;p&gt;I started in data as a ETL developer since 2011, I did projects using DataStream (old Cognos), PowerCenter, SSIS, Talend, SAS and even VBA up to 2016 when I joined a data visualization tool company as consultant mainly focused to create conceptual DB models and reports/dashboards with this tool. However since 2018 composed by 2 periods (2016-2021 and from 2022- up-to-date)   most of my projects were related to upgrade servers to newer software versions, configuration etc. There were a couple projects here and there that were related to predictive analytics with python and/or R, NoSQL, Hadoop, Query performance, data ingestion, but summing all of this it is no more than 10% of my time.&lt;/p&gt;\n\n&lt;p&gt;Within 2021 I left this job for a ecommerce company which I had to work with python, Big Query, Teradata, Presto etc. But unfortunately I had to leave it to immigrate which was a bigger dream. That&amp;#39;s why I re-joined the previously mentioned company.&lt;/p&gt;\n\n&lt;p&gt;I feel that I have the requirements, I never stopped to study, I&amp;#39;m pretty good in query performance, data modeling, user specification, also know python, Scala, AWS, data bricks. a bunch of databases (SQL Server, Oracle, Teradata, MySQL, Big Query, Redshift, Snowflake, PostgreSQL) and I also know a little docker due to home projects, yet I&amp;#39;ve applied for almost 50 openings and didn&amp;#39;t got any replies/interviews even diposed to earn a little less than I&amp;#39;m currently making if necessary. Sometimes I fell that the extended period working for the data viz company kinda put a stamp on me saying that I&amp;#39;m not capable of doing a DE job.&lt;/p&gt;\n\n&lt;p&gt;My question is, is it possible to go to a DE path?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152y27j", "is_robot_indexable": true, "report_reasons": null, "author": "jokerxbr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152y27j/from_data_specific_consultant_to_de_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152y27j/from_data_specific_consultant_to_de_path/", "subreddit_subscribers": 116631, "created_utc": 1689685752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was hired as a DS at a scale-up company, and have implemented all data engineering pipelines using the following stack: Prefect + pandas, with .parquet files on azure datalake as final storage.\n\nI am running into some performance issues, and would possibly want to separate the orchestration and compute., using some warehouse option for the compute. Additionally, the final storage should probably also be a warehouse and not a datalake, as we are hiring analysts that would probably expect some SQL-queryable storage.\n\nI am basically looking into options for warehouses that can do the whole ELT process. Would something like SnowFlake be a good option, or is it overkill for small sizes of data?   \nDoes it handle extract/normalization of fairly complex json files, or should I use some other tool for the extract part?\n\n&amp;#x200B;", "author_fullname": "t2_lixpgvfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for warehouse options to replace pandas ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152vv4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689679785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was hired as a DS at a scale-up company, and have implemented all data engineering pipelines using the following stack: Prefect + pandas, with .parquet files on azure datalake as final storage.&lt;/p&gt;\n\n&lt;p&gt;I am running into some performance issues, and would possibly want to separate the orchestration and compute., using some warehouse option for the compute. Additionally, the final storage should probably also be a warehouse and not a datalake, as we are hiring analysts that would probably expect some SQL-queryable storage.&lt;/p&gt;\n\n&lt;p&gt;I am basically looking into options for warehouses that can do the whole ELT process. Would something like SnowFlake be a good option, or is it overkill for small sizes of data?&lt;br/&gt;\nDoes it handle extract/normalization of fairly complex json files, or should I use some other tool for the extract part?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152vv4s", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping-Nail-250", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152vv4s/looking_for_warehouse_options_to_replace_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152vv4s/looking_for_warehouse_options_to_replace_pandas/", "subreddit_subscribers": 116631, "created_utc": 1689679785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nI'm exploring the transition into a data role as the next phase of my career. Uncovering data engineering concepts and architectures make my juices flow again after a few years of stagnation in my current infrastructure solution architect role. Data science and analysis isn't my bag, I'm focused on the engineering track.\n\nMy background: I've worked in public and private cloud (primarily Azure infrastructure and micro-services) and data management (primarily protection and disaster recovery) for c. 13 years, the last 5 at a senior architect level. \n\nI've seen a few posts on 'transitioning' roles and currently looking through the wiki to understand skillsets but would loveto hear from those who have experienced a similar transition from cloud solution architect into a data role. \n\n I'm working my way through DP-203 and I envisage the most difficult aspects will include coding. However, that's something I'll just have to work on.\n\nDid you work from a data engineering starting point up to data architect? Did you face any significant hurdles or were there any skills that you found invaluable in your journey?", "author_fullname": "t2_a0k3gzpb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition from cloud architect into data role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152rnc1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689665871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m exploring the transition into a data role as the next phase of my career. Uncovering data engineering concepts and architectures make my juices flow again after a few years of stagnation in my current infrastructure solution architect role. Data science and analysis isn&amp;#39;t my bag, I&amp;#39;m focused on the engineering track.&lt;/p&gt;\n\n&lt;p&gt;My background: I&amp;#39;ve worked in public and private cloud (primarily Azure infrastructure and micro-services) and data management (primarily protection and disaster recovery) for c. 13 years, the last 5 at a senior architect level. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a few posts on &amp;#39;transitioning&amp;#39; roles and currently looking through the wiki to understand skillsets but would loveto hear from those who have experienced a similar transition from cloud solution architect into a data role. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working my way through DP-203 and I envisage the most difficult aspects will include coding. However, that&amp;#39;s something I&amp;#39;ll just have to work on.&lt;/p&gt;\n\n&lt;p&gt;Did you work from a data engineering starting point up to data architect? Did you face any significant hurdles or were there any skills that you found invaluable in your journey?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152rnc1", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Figure88", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rnc1/transition_from_cloud_architect_into_data_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152rnc1/transition_from_cloud_architect_into_data_role/", "subreddit_subscribers": 116631, "created_utc": 1689665871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I browsed through the community posts and understood that [neetcode.io](https://neetcode.io) is by far the best and the most recommended platform for practising Python for DE interviews.\n\nI work as a Data Engineer at a small startup right now, but never in my life I have done LeetCode or even touched DSA, hence requesting for help here.\n\nIn the [neetcode.io](https://neetcode.io) platform, in the practice section, if we sort by group, the questions are grouped by topic so that you can tackle them accordingly.\n\nBased on your interview experience, can you please help me prioritise the topics? I am guessing many of these topics are for SDE interviews and not all might be relevant to DE interviews, and even if they are relevant, some must be more important than others.\n\nThe topics are:\n\n1. Arrays and Hashing\n2. Two Pointers\n3. Sliding Window\n4. Stack\n5. Binary Search\n6. Linked List\n7. Trees\n8. Tries\n9. Heap / Priority Queue\n10. Backtracking\n11. Graphs\n12. Advanced Graphs\n13. 1-D dynamic programming\n14. 2-D dynamic programming\n15. Greedy\n16. Intervals\n17. Math &amp; Geometry\n18. Bit Manipulation\n\nThe reasons I have to prioritise/filter this is because I have limited time left in the interview prep hence want the important things 1st, and also because I am not specifically targeting MAANG.\n\n&amp;#x200B;\n\nThank you for the help!!", "author_fullname": "t2_cu6910tv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview preparation help - Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152ny8o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689653788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I browsed through the community posts and understood that &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; is by far the best and the most recommended platform for practising Python for DE interviews.&lt;/p&gt;\n\n&lt;p&gt;I work as a Data Engineer at a small startup right now, but never in my life I have done LeetCode or even touched DSA, hence requesting for help here.&lt;/p&gt;\n\n&lt;p&gt;In the &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; platform, in the practice section, if we sort by group, the questions are grouped by topic so that you can tackle them accordingly.&lt;/p&gt;\n\n&lt;p&gt;Based on your interview experience, can you please help me prioritise the topics? I am guessing many of these topics are for SDE interviews and not all might be relevant to DE interviews, and even if they are relevant, some must be more important than others.&lt;/p&gt;\n\n&lt;p&gt;The topics are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Arrays and Hashing&lt;/li&gt;\n&lt;li&gt;Two Pointers&lt;/li&gt;\n&lt;li&gt;Sliding Window&lt;/li&gt;\n&lt;li&gt;Stack&lt;/li&gt;\n&lt;li&gt;Binary Search&lt;/li&gt;\n&lt;li&gt;Linked List&lt;/li&gt;\n&lt;li&gt;Trees&lt;/li&gt;\n&lt;li&gt;Tries&lt;/li&gt;\n&lt;li&gt;Heap / Priority Queue&lt;/li&gt;\n&lt;li&gt;Backtracking&lt;/li&gt;\n&lt;li&gt;Graphs&lt;/li&gt;\n&lt;li&gt;Advanced Graphs&lt;/li&gt;\n&lt;li&gt;1-D dynamic programming&lt;/li&gt;\n&lt;li&gt;2-D dynamic programming&lt;/li&gt;\n&lt;li&gt;Greedy&lt;/li&gt;\n&lt;li&gt;Intervals&lt;/li&gt;\n&lt;li&gt;Math &amp;amp; Geometry&lt;/li&gt;\n&lt;li&gt;Bit Manipulation&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The reasons I have to prioritise/filter this is because I have limited time left in the interview prep hence want the important things 1st, and also because I am not specifically targeting MAANG.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for the help!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152ny8o", "is_robot_indexable": true, "report_reasons": null, "author": "table_data", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152ny8o/interview_preparation_help_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152ny8o/interview_preparation_help_python/", "subreddit_subscribers": 116631, "created_utc": 1689653788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I need some output regarding this situation.  \nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post \"submit\", as soon as that happens, the job needs to be submitted!  \nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can't really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?  \nLove to know your thoughts!  \nThanks", "author_fullname": "t2_xqvyn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink Batch Job needs to run based on a trigger", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152m3hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689648465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I need some output regarding this situation.&lt;br/&gt;\nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post &amp;quot;submit&amp;quot;, as soon as that happens, the job needs to be submitted!&lt;br/&gt;\nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can&amp;#39;t really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?&lt;br/&gt;\nLove to know your thoughts!&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152m3hr", "is_robot_indexable": true, "report_reasons": null, "author": "Salekeen01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "subreddit_subscribers": 116631, "created_utc": 1689648465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2cbhndmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why not Flink?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": true, "name": "t3_1537lsw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/DoVZotXbdsmVJKmOK8zw8LGsEWaJ8h1FqxvG72NPA50.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689707994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arroyo.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arroyo.dev/blog/why-not-flink", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p9vYTWByyn_RWfyv76gB-cIsx13GJSKrLKVQaozRgGA.jpg?auto=webp&amp;s=dbaf44dd0884335f2568c45bac1b286641f291dd", "width": 1500, "height": 938}, "resolutions": [{"url": "https://external-preview.redd.it/p9vYTWByyn_RWfyv76gB-cIsx13GJSKrLKVQaozRgGA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5035122efce19bc2c313301bb9650f47ecf2e340", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/p9vYTWByyn_RWfyv76gB-cIsx13GJSKrLKVQaozRgGA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c43c40755f82a2fda0da737c04e485514d58aee", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/p9vYTWByyn_RWfyv76gB-cIsx13GJSKrLKVQaozRgGA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e5e44026dfdeaee1962edf49402ba47f9fb319c", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/p9vYTWByyn_RWfyv76gB-cIsx13GJSKrLKVQaozRgGA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b0927a64888fa50dcfbbf100b673e9d542f96ecd", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/p9vYTWByyn_RWfyv76gB-cIsx13GJSKrLKVQaozRgGA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=864d757975e890385d83b0edd9ad2a8bf48ab632", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/p9vYTWByyn_RWfyv76gB-cIsx13GJSKrLKVQaozRgGA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8a9c5790c897e1e14771fa3417897ca4450d9142", "width": 1080, "height": 675}], "variants": {}, "id": "okhvCYUSSbhOVo3pQ6FK0konOSDUmaObUupo1lx6XNo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1537lsw", "is_robot_indexable": true, "report_reasons": null, "author": "mwylde_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1537lsw/why_not_flink/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arroyo.dev/blog/why-not-flink", "subreddit_subscribers": 116631, "created_utc": 1689707994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do you all use to monitor your ingestion pipelines in databricks?\n\nWe currently use Azure Log Analytics/Azure monitor but the SparkListener library for Log Analytics sends Spark performance metrics. \n\nBeen using databricks notebooks that do some aggregations and push data through to Log Analytics as a custom SDK rig using log analytics and data collector API's. \n\nNot great, logs are slow to arrive in LA and the authorization headers and JSON responses get fiddly when data structures differ.", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Monitoring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1537ll0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689707981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you all use to monitor your ingestion pipelines in databricks?&lt;/p&gt;\n\n&lt;p&gt;We currently use Azure Log Analytics/Azure monitor but the SparkListener library for Log Analytics sends Spark performance metrics. &lt;/p&gt;\n\n&lt;p&gt;Been using databricks notebooks that do some aggregations and push data through to Log Analytics as a custom SDK rig using log analytics and data collector API&amp;#39;s. &lt;/p&gt;\n\n&lt;p&gt;Not great, logs are slow to arrive in LA and the authorization headers and JSON responses get fiddly when data structures differ.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1537ll0", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1537ll0/databricks_monitoring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1537ll0/databricks_monitoring/", "subreddit_subscribers": 116631, "created_utc": 1689707981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHello to all Data Engineers !\n\nI'm diving into the exciting world of Apache Spark and I'm looking for the perfect video tutorial that provides a comprehensive understanding of Spark's architecture, concepts, and practical usage. With so many options out there, both free and paid, I thought it would be great to tap into the knowledge and experiences of this community.\n\nSo, my question is: Which video tutorial would you recommend as the best resource for learning Apache Spark? It could be a free tutorial available on YouTube or other platforms, or even a paid course that you found to be incredibly valuable.\n\nI'm particularly interested in a tutorial that covers the following aspects:\n\n* Spark architecture and core concepts\n* Hands-on examples and real-world use cases\n* Detailed explanations of Spark transformations and actions\n* Spark SQL, data frames, and dataset APIs\n* Integration with popular big data tools and frameworks\n\nYour insights and recommendations would be highly appreciated. Please feel free to share any personal experiences, tutorial names, links, or even the instructors who made a significant impact on your Spark learning journey.\n\nLooking forward to your valuable suggestions and thank you in advance for your help!", "author_fullname": "t2_hvt2pp4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking the Best Apache Spark Video Tutorial - Recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1535mkd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689703458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello to all Data Engineers !&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m diving into the exciting world of Apache Spark and I&amp;#39;m looking for the perfect video tutorial that provides a comprehensive understanding of Spark&amp;#39;s architecture, concepts, and practical usage. With so many options out there, both free and paid, I thought it would be great to tap into the knowledge and experiences of this community.&lt;/p&gt;\n\n&lt;p&gt;So, my question is: Which video tutorial would you recommend as the best resource for learning Apache Spark? It could be a free tutorial available on YouTube or other platforms, or even a paid course that you found to be incredibly valuable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m particularly interested in a tutorial that covers the following aspects:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Spark architecture and core concepts&lt;/li&gt;\n&lt;li&gt;Hands-on examples and real-world use cases&lt;/li&gt;\n&lt;li&gt;Detailed explanations of Spark transformations and actions&lt;/li&gt;\n&lt;li&gt;Spark SQL, data frames, and dataset APIs&lt;/li&gt;\n&lt;li&gt;Integration with popular big data tools and frameworks&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Your insights and recommendations would be highly appreciated. Please feel free to share any personal experiences, tutorial names, links, or even the instructors who made a significant impact on your Spark learning journey.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to your valuable suggestions and thank you in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1535mkd", "is_robot_indexable": true, "report_reasons": null, "author": "Loki_029", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1535mkd/seeking_the_best_apache_spark_video_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1535mkd/seeking_the_best_apache_spark_video_tutorial/", "subreddit_subscribers": 116631, "created_utc": 1689703458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a new grad and have cleared AZ-900,DP-900 and DP-203 certifications and currently working on my portfolio projects. Finding it difficult to find End-to-End Data engineering projects on Azure. But I can see there are so many such projects executed and well documented on AWS and GCP. Decided to learn AWS and GCP on side. So wondering what is the best way to learn AWS and GCP after learning Azure. And if you have any crazy data engineering projects on Azure, kindly let me know.", "author_fullname": "t2_70f26rvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cleared Azure Cloud Certifications. Wondering what is next. Need help !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1532rt2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689696882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a new grad and have cleared AZ-900,DP-900 and DP-203 certifications and currently working on my portfolio projects. Finding it difficult to find End-to-End Data engineering projects on Azure. But I can see there are so many such projects executed and well documented on AWS and GCP. Decided to learn AWS and GCP on side. So wondering what is the best way to learn AWS and GCP after learning Azure. And if you have any crazy data engineering projects on Azure, kindly let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1532rt2", "is_robot_indexable": true, "report_reasons": null, "author": "h_buddana", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1532rt2/cleared_azure_cloud_certifications_wondering_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1532rt2/cleared_azure_cloud_certifications_wondering_what/", "subreddit_subscribers": 116631, "created_utc": 1689696882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are working on setting up our databricks environment and are struggling with the pattern to implement the medallion architecture. \n\nWe currently have: catalog.schema.table as project.medallion\\_layer.table and are wondering if this is the way to go? \n\nWe have our environments split into two workspaces for dev and prod, I don't know if it makes sense to have bronze, silver, gold in each workspace? But also want to give different types of users levels of control. \n\nLittle lost and databricks doesn't seem to actually have any documentation on medallion implementation.", "author_fullname": "t2_81ywblydd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to actually implement medallion layers in databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152xzcv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689685542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are working on setting up our databricks environment and are struggling with the pattern to implement the medallion architecture. &lt;/p&gt;\n\n&lt;p&gt;We currently have: catalog.schema.table as project.medallion_layer.table and are wondering if this is the way to go? &lt;/p&gt;\n\n&lt;p&gt;We have our environments split into two workspaces for dev and prod, I don&amp;#39;t know if it makes sense to have bronze, silver, gold in each workspace? But also want to give different types of users levels of control. &lt;/p&gt;\n\n&lt;p&gt;Little lost and databricks doesn&amp;#39;t seem to actually have any documentation on medallion implementation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152xzcv", "is_robot_indexable": true, "report_reasons": null, "author": "DataDoyle", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152xzcv/how_to_actually_implement_medallion_layers_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152xzcv/how_to_actually_implement_medallion_layers_in/", "subreddit_subscribers": 116631, "created_utc": 1689685542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working for less than a year in a small IT services company as a data analyst. I'm the only one working in the data field, so I'm totally autonomous.  My job is pretty straightforward and basic: I create dashboards on Power Bi using data from the company's activities, such as accounting or human resources. The data is stored in SQL server databases on local servers.\n\nHere's my workflow, I create sql views in order to extract and process as much of the upstream data as possible directly in sql server and then import it into power bi. Thanks to a data gateway I've been able to automate the updating of the data on the dashboards that are put online. There is no real complexity or intelligence in this process and looking at this reddit every day I wondered if my practice was correct and optimal in my case or if I could optimise it with ETLs or tools/services like Databricks dbt ect.\n\nSorry for my poor English or if what I'm writing doesn't make much sense, I'm still a data science student with poor knowledge in data engineering.", "author_fullname": "t2_txt0cja7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a student data analyst in apprenticeship, what can I do to improve the data exploitation process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152xs6i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689685051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working for less than a year in a small IT services company as a data analyst. I&amp;#39;m the only one working in the data field, so I&amp;#39;m totally autonomous.  My job is pretty straightforward and basic: I create dashboards on Power Bi using data from the company&amp;#39;s activities, such as accounting or human resources. The data is stored in SQL server databases on local servers.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my workflow, I create sql views in order to extract and process as much of the upstream data as possible directly in sql server and then import it into power bi. Thanks to a data gateway I&amp;#39;ve been able to automate the updating of the data on the dashboards that are put online. There is no real complexity or intelligence in this process and looking at this reddit every day I wondered if my practice was correct and optimal in my case or if I could optimise it with ETLs or tools/services like Databricks dbt ect.&lt;/p&gt;\n\n&lt;p&gt;Sorry for my poor English or if what I&amp;#39;m writing doesn&amp;#39;t make much sense, I&amp;#39;m still a data science student with poor knowledge in data engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152xs6i", "is_robot_indexable": true, "report_reasons": null, "author": "Zuzukxd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152xs6i/as_a_student_data_analyst_in_apprenticeship_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152xs6i/as_a_student_data_analyst_in_apprenticeship_what/", "subreddit_subscribers": 116631, "created_utc": 1689685051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Max Kremer outlines real-time data streaming with Debezium and Postgres. Gone through the process before? What has your experience been?\n\n[https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/](https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/)\n\n&amp;#x200B;", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time data streaming with Debezium and Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152ws1a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689682327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Max Kremer outlines real-time data streaming with Debezium and Postgres. Gone through the process before? What has your experience been?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/\"&gt;https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?auto=webp&amp;s=c5f5a655d6864f84f08160aa3ecc6a483e366b29", "width": 2254, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77f04efc85875721aab74a0dbed87aab2166568f", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6660b3bca381afe6691fd6377052115955289b27", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15461ccea7f16f0c86fe0838ac84029482fac910", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e98a3a8fc7d6d3e1d17432c50f2e3090f4edc6e1", "width": 640, "height": 425}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=13795e652ab765a44ab68d9a18848a95426810a4", "width": 960, "height": 638}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5da9553f31250276789472e811efd60331226597", "width": 1080, "height": 718}], "variants": {}, "id": "yOcCqb_01Tcein84ljsq1UI3XyPdtH-HzgATv4P1fwg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152ws1a", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152ws1a/realtime_data_streaming_with_debezium_and_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152ws1a/realtime_data_streaming_with_debezium_and_postgres/", "subreddit_subscribers": 116631, "created_utc": 1689682327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/152rgcu)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data lakehouse table format does your team plan to use by the end of 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152rgcu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689665188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/152rgcu\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152rgcu", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1690269988727, "options": [{"text": "Delta Lake", "id": "23941798"}, {"text": "Iceberg", "id": "23941799"}, {"text": "Hudi", "id": "23941800"}, {"text": "Hive", "id": "23941801"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 84, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rgcu/what_data_lakehouse_table_format_does_your_team/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/152rgcu/what_data_lakehouse_table_format_does_your_team/", "subreddit_subscribers": 116631, "created_utc": 1689665188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c8yil9sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unleashing the power of Data: Choosing the right Storage System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_152rbb9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IIv1_fPx7mpWttOq-Jz014OPcljRrJWfbtz0MaJy0OY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689664709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "waruithemystery.hashnode.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://waruithemystery.hashnode.dev/unleashing-the-power-of-data-choosing-the-right-storage-system", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?auto=webp&amp;s=76f5feabe1088e5a7e933f706d45b03c187041a4", "width": 1200, "height": 840}, "resolutions": [{"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04e6f81d17d408d5974273992d6d90d263e8df1c", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bdad375d47b17d15ac4f0aaef826d4ed177f7506", "width": 216, "height": 151}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec45ff075400efbd48e383d3f4181f961972ee60", "width": 320, "height": 224}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4cd3a4b29aa434f12207cc6e12d887b97fe385ef", "width": 640, "height": 448}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=099ac6fd14571e30d1b1e578f8e77d563ed48493", "width": 960, "height": 672}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39e11829a7eaae13f171f3fd5685dfe26fab5322", "width": 1080, "height": 756}], "variants": {}, "id": "VAuaOqHlidZveGyq3PdjODh479ysn4eoBTpoDQbWSDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "152rbb9", "is_robot_indexable": true, "report_reasons": null, "author": "RemarkableAttempt311", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rbb9/unleashing_the_power_of_data_choosing_the_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://waruithemystery.hashnode.dev/unleashing-the-power-of-data-choosing-the-right-storage-system", "subreddit_subscribers": 116631, "created_utc": 1689664709.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}