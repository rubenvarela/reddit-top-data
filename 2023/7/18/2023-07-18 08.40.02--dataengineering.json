{"kind": "Listing", "data": {"after": "t3_151yksz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few days ago, our data scientist gave me some of his SQL code to put in production.  I quickly glanced over it -- it was neat and tidy, well formatted, organised and filled with helpful comments.  \"Shouldn't be a big deal.  Give me a few days to review it.\"\n\nI looked at it more closely today and realised it's actually mess.  Badly written, inefficient, breaks the DRY approach repeatedly, doesn't comply with naming standards, the lot.  I get back to the guy and ask him to explain some of the SQL statements because they're confusing to me. He admits that a lot of it was actually written by ChatGPT and he isn't sure what it's doing.  But he politely asks me when will his code be put into production, thank you very much?\n\nYou have code that you can't actually explain *as the developer yourself* but you still expect it to be put in production?\n\nI tell him a need a bit more time.  And he cheerfully tells me that he'll be happy to do it himself *if I'd just give him admin access to production.*", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists -- Ok, now I get it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151xsis", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 457, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 457, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689588707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few days ago, our data scientist gave me some of his SQL code to put in production.  I quickly glanced over it -- it was neat and tidy, well formatted, organised and filled with helpful comments.  &amp;quot;Shouldn&amp;#39;t be a big deal.  Give me a few days to review it.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I looked at it more closely today and realised it&amp;#39;s actually mess.  Badly written, inefficient, breaks the DRY approach repeatedly, doesn&amp;#39;t comply with naming standards, the lot.  I get back to the guy and ask him to explain some of the SQL statements because they&amp;#39;re confusing to me. He admits that a lot of it was actually written by ChatGPT and he isn&amp;#39;t sure what it&amp;#39;s doing.  But he politely asks me when will his code be put into production, thank you very much?&lt;/p&gt;\n\n&lt;p&gt;You have code that you can&amp;#39;t actually explain &lt;em&gt;as the developer yourself&lt;/em&gt; but you still expect it to be put in production?&lt;/p&gt;\n\n&lt;p&gt;I tell him a need a bit more time.  And he cheerfully tells me that he&amp;#39;ll be happy to do it himself &lt;em&gt;if I&amp;#39;d just give him admin access to production.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151xsis", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 188, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151xsis/data_scientists_ok_now_i_get_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151xsis/data_scientists_ok_now_i_get_it/", "subreddit_subscribers": 116499, "created_utc": 1689588707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is interested in having a no code platform so that we can democratize data access and mitigate shitty practices like shared drive hoarding. We are looking at Palantir but it's absurdly expensive. I've never really dabbled with \"tools\" like that because I've never come across something truly no code that worked well.\n\nCurious if anyone here has used Palantir's Foundry or other tools that give non technical users a place to search and see data exists, do their data manipulation, exploration and then visualization on both tabular and time series data.", "author_fullname": "t2_c10zsd9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best no-code platforms you have come across?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151yrep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689591732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is interested in having a no code platform so that we can democratize data access and mitigate shitty practices like shared drive hoarding. We are looking at Palantir but it&amp;#39;s absurdly expensive. I&amp;#39;ve never really dabbled with &amp;quot;tools&amp;quot; like that because I&amp;#39;ve never come across something truly no code that worked well.&lt;/p&gt;\n\n&lt;p&gt;Curious if anyone here has used Palantir&amp;#39;s Foundry or other tools that give non technical users a place to search and see data exists, do their data manipulation, exploration and then visualization on both tabular and time series data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151yrep", "is_robot_indexable": true, "report_reasons": null, "author": "EmoryCadet", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151yrep/what_are_the_best_nocode_platforms_you_have_come/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151yrep/what_are_the_best_nocode_platforms_you_have_come/", "subreddit_subscribers": 116499, "created_utc": 1689591732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to data engineering, and I like to learn by trying/building. I am very unclear what's the best way to go about it?\n\nMy ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?", "author_fullname": "t2_17d42esw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best \"free\" set-up to learn or try to build a data pipeline on my own?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152c49r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689623684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to data engineering, and I like to learn by trying/building. I am very unclear what&amp;#39;s the best way to go about it?&lt;/p&gt;\n\n&lt;p&gt;My ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152c49r", "is_robot_indexable": true, "report_reasons": null, "author": "Guyserbun007", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "subreddit_subscribers": 116499, "created_utc": 1689623684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a big tech company as a new grad and my title is technically data engineer, however much of my work is building distributed Python applications for ML and data replication, spark, Java, devops pipelines and infrastructure automation (ansible). If I write sql, it\u2019s always within a Python application and is nothing more than an insert, table creation or simple select query. With my experience, would I be more suited to go into software engineer roles moving forward? Scared of applying to companies that use modern data stack or no-code tools and I am stuck having to re-learn SQL or failing an interview.\n\nEdit: I\u2019d consider myself average at SQL, I\u2019ve passed all-SQL interviews, just worried about my skills atrophying as it\u2019s not something I really enjoy to use and my role doesn\u2019t require it", "author_fullname": "t2_7szv7c66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am a new grad \u201cdata engineer\u201d who barely writes SQL, how will my career be impacted?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152own3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689657321.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689656717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a big tech company as a new grad and my title is technically data engineer, however much of my work is building distributed Python applications for ML and data replication, spark, Java, devops pipelines and infrastructure automation (ansible). If I write sql, it\u2019s always within a Python application and is nothing more than an insert, table creation or simple select query. With my experience, would I be more suited to go into software engineer roles moving forward? Scared of applying to companies that use modern data stack or no-code tools and I am stuck having to re-learn SQL or failing an interview.&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019d consider myself average at SQL, I\u2019ve passed all-SQL interviews, just worried about my skills atrophying as it\u2019s not something I really enjoy to use and my role doesn\u2019t require it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152own3", "is_robot_indexable": true, "report_reasons": null, "author": "aacreans", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152own3/i_am_a_new_grad_data_engineer_who_barely_writes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152own3/i_am_a_new_grad_data_engineer_who_barely_writes/", "subreddit_subscribers": 116499, "created_utc": 1689656717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?", "author_fullname": "t2_c532a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What steps to take after first role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1524trd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689607060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1524trd", "is_robot_indexable": true, "report_reasons": null, "author": "gators939", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "subreddit_subscribers": 116499, "created_utc": 1689607060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4t6cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM based pipelines with PostgresML and dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_1525yyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z3TI0arYlw4RRR3jUUbPUO2vA2egarxlpp1dP09FXtE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689609669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "postgresml.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?auto=webp&amp;s=0b690342c0b9264e580cd8629721f878d18ff954", "width": 784, "height": 519}, "resolutions": [{"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf6a365fbb7793932f29fbb28fa434d479b46d55", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0effd2b3a0537c8131fd28109ff37439457f1ddc", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d160cb4efab6957e3d11789882fe0b658cafe87e", "width": 320, "height": 211}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e154f104eedac0bc7c9e36c987df586978c19eb0", "width": 640, "height": 423}], "variants": {}, "id": "dxDnyB5RtYkyN-bX3C7E2eUqvQzE9_-FZU6xkZ1aDRQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1525yyl", "is_robot_indexable": true, "report_reasons": null, "author": "something_cleverer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525yyl/llm_based_pipelines_with_postgresml_and_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "subreddit_subscribers": 116499, "created_utc": 1689609669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would like to find some questions practicing for DE interview. I mostly use leetcode to practice DSA, and leetcode have multiple tags like 'array', 'binary tree' when I want to practice specific topics.\n\nHowever, there seems no similar tag for SQL problems on leetcode. I believe SQL have various type of questions, and I want to practice specific topics (join, aggregation, window function...etc) not wondering around and look at all kinds of problems.\n\nIs there any website that may have specific topics to practice SQL questions?  \nOr more specifically, SQL practicing websites for DE interview?  \n\n\nThanks a lot!", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there SQL questions practice website with specific topics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15226ql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689600967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to find some questions practicing for DE interview. I mostly use leetcode to practice DSA, and leetcode have multiple tags like &amp;#39;array&amp;#39;, &amp;#39;binary tree&amp;#39; when I want to practice specific topics.&lt;/p&gt;\n\n&lt;p&gt;However, there seems no similar tag for SQL problems on leetcode. I believe SQL have various type of questions, and I want to practice specific topics (join, aggregation, window function...etc) not wondering around and look at all kinds of problems.&lt;/p&gt;\n\n&lt;p&gt;Is there any website that may have specific topics to practice SQL questions?&lt;br/&gt;\nOr more specifically, SQL practicing websites for DE interview?  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15226ql", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15226ql/is_there_sql_questions_practice_website_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15226ql/is_there_sql_questions_practice_website_with/", "subreddit_subscribers": 116499, "created_utc": 1689600967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone inviting you to join our Hackathon!!  \nIn this hackathon, you are going to create a wildfire early warning system for the fictional island nation of Zakar. Zakar has been struggling with wildfires in the last few years. \n\nThe best project will get the perfect gaming package!\n\nfor more info - [Save Zakar Hackathon](https://medium.com/memphis-dev/you-have-a-chance-to-save-the-world-d789dcd55f87)\n\n[Sign up](https://www.hackathon.memphis.dev/)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time Data and AI using open source tools Hackathon!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1520dzi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689596371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone inviting you to join our Hackathon!!&lt;br/&gt;\nIn this hackathon, you are going to create a wildfire early warning system for the fictional island nation of Zakar. Zakar has been struggling with wildfires in the last few years. &lt;/p&gt;\n\n&lt;p&gt;The best project will get the perfect gaming package!&lt;/p&gt;\n\n&lt;p&gt;for more info - &lt;a href=\"https://medium.com/memphis-dev/you-have-a-chance-to-save-the-world-d789dcd55f87\"&gt;Save Zakar Hackathon&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.hackathon.memphis.dev/\"&gt;Sign up&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?auto=webp&amp;s=e410859561599d680b0aab559597ce32e4d8c6f3", "width": 1200, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ffad9c57fc8cd00aa80bce283c5f0a08db3c968c", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e25613eaa09a34d2ec37a6fffb5d7321a2424cd", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=125279964d45a8bc6fd9a8be6353524433b7c684", "width": 320, "height": 96}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a013995f51636b54e30590c6423546b212a21538", "width": 640, "height": 192}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5601c7067416e834d46c0aaa2ad77eff38d9964f", "width": 960, "height": 288}, {"url": "https://external-preview.redd.it/uQKG8k4uPnx7m0X6Y3ijedesVWdxoRVXIVX8DIQLBfw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=075957b9f1cbc341c510b446761005e7e3b4a919", "width": 1080, "height": 324}], "variants": {}, "id": "FG0dihaZdabzhgCH3l_ddvb59OmQJlKMVavnIZV_W2c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1520dzi", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1520dzi/realtime_data_and_ai_using_open_source_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1520dzi/realtime_data_and_ai_using_open_source_tools/", "subreddit_subscribers": 116499, "created_utc": 1689596371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my company which is a startup is hiring web scrapers to scrape data(financial data) from the websites, and load into S3 and as usual it goes to the database.\nWill this even going to work?", "author_fullname": "t2_es0ctl93", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is web scraping even an authentic data source to move forward with?or buying the data/API worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1520xun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689597849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my company which is a startup is hiring web scrapers to scrape data(financial data) from the websites, and load into S3 and as usual it goes to the database.\nWill this even going to work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1520xun", "is_robot_indexable": true, "report_reasons": null, "author": "Grand-Knowledge-4044", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1520xun/is_web_scraping_even_an_authentic_data_source_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1520xun/is_web_scraping_even_an_authentic_data_source_to/", "subreddit_subscribers": 116499, "created_utc": 1689597849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey guys,\nWe have a table in delta format where we have enabled schema evolution. \nLets consider a table having column X which is struct and have multi level nested keys. \n\nE.g. - X.Y.Z.A\n\nNow, Databricks is trying to convert Z to struct, I want it to convert it to String\nZ has 10k keys. \n\nHow do we solve for this?\n\nWe\u2019re following this approach:\n1. get ddl for table \n2. recreate the table with schema of Z as string.", "author_fullname": "t2_3dsjwu75", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is best way to change existing schema in delta[Databricks]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151voz1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689581588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys,\nWe have a table in delta format where we have enabled schema evolution. \nLets consider a table having column X which is struct and have multi level nested keys. &lt;/p&gt;\n\n&lt;p&gt;E.g. - X.Y.Z.A&lt;/p&gt;\n\n&lt;p&gt;Now, Databricks is trying to convert Z to struct, I want it to convert it to String\nZ has 10k keys. &lt;/p&gt;\n\n&lt;p&gt;How do we solve for this?&lt;/p&gt;\n\n&lt;p&gt;We\u2019re following this approach:\n1. get ddl for table \n2. recreate the table with schema of Z as string.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151voz1", "is_robot_indexable": true, "report_reasons": null, "author": "mannu_11", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151voz1/what_is_best_way_to_change_existing_schema_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151voz1/what_is_best_way_to_change_existing_schema_in/", "subreddit_subscribers": 116499, "created_utc": 1689581588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I need some output regarding this situation.  \nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post \"submit\", as soon as that happens, the job needs to be submitted!  \nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can't really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?  \nLove to know your thoughts!  \nThanks", "author_fullname": "t2_xqvyn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink Batch Job needs to run based on a trigger", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152m3hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689648465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I need some output regarding this situation.&lt;br/&gt;\nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post &amp;quot;submit&amp;quot;, as soon as that happens, the job needs to be submitted!&lt;br/&gt;\nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can&amp;#39;t really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?&lt;br/&gt;\nLove to know your thoughts!&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152m3hr", "is_robot_indexable": true, "report_reasons": null, "author": "Salekeen01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "subreddit_subscribers": 116499, "created_utc": 1689648465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nI'm exploring the transition into a data role as the next phase of my career. Uncovering data engineering concepts and architectures make my juices flow again after a few years of stagnation in my current infrastructure solution architect role. Data science and analysis isn't my bag, I'm focused on the engineering track.\n\nMy background: I've worked in public and private cloud (primarily Azure infrastructure and micro-services) and data management (primarily protection and disaster recovery) for c. 13 years, the last 5 at a senior architect level. \n\nI've seen a few posts on 'transitioning' roles and currently looking through the wiki to understand skillsets but would loveto hear from those who have experienced a similar transition from cloud solution architect into a data role. \n\n I'm working my way through DP-203 and I envisage the most difficult aspects will include coding. However, that's something I'll just have to work on.\n\nDid you work from a data engineering starting point up to data architect? Did you face any significant hurdles or were there any skills that you found invaluable in your journey?", "author_fullname": "t2_a0k3gzpb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition from cloud architect into data role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152rnc1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689665871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m exploring the transition into a data role as the next phase of my career. Uncovering data engineering concepts and architectures make my juices flow again after a few years of stagnation in my current infrastructure solution architect role. Data science and analysis isn&amp;#39;t my bag, I&amp;#39;m focused on the engineering track.&lt;/p&gt;\n\n&lt;p&gt;My background: I&amp;#39;ve worked in public and private cloud (primarily Azure infrastructure and micro-services) and data management (primarily protection and disaster recovery) for c. 13 years, the last 5 at a senior architect level. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a few posts on &amp;#39;transitioning&amp;#39; roles and currently looking through the wiki to understand skillsets but would loveto hear from those who have experienced a similar transition from cloud solution architect into a data role. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working my way through DP-203 and I envisage the most difficult aspects will include coding. However, that&amp;#39;s something I&amp;#39;ll just have to work on.&lt;/p&gt;\n\n&lt;p&gt;Did you work from a data engineering starting point up to data architect? Did you face any significant hurdles or were there any skills that you found invaluable in your journey?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152rnc1", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Figure88", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rnc1/transition_from_cloud_architect_into_data_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152rnc1/transition_from_cloud_architect_into_data_role/", "subreddit_subscribers": 116499, "created_utc": 1689665871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/152rgcu)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data lakehouse table format does your team plan to use by the end of 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152rgcu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689665188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/152rgcu\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152rgcu", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1690269988727, "options": [{"text": "Delta Lake", "id": "23941798"}, {"text": "Iceberg", "id": "23941799"}, {"text": "Hudi", "id": "23941800"}, {"text": "Hive", "id": "23941801"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 10, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rgcu/what_data_lakehouse_table_format_does_your_team/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/152rgcu/what_data_lakehouse_table_format_does_your_team/", "subreddit_subscribers": 116499, "created_utc": 1689665188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c8yil9sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unleashing the power of Data: Choosing the right Storage System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": true, "name": "t3_152rbb9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IIv1_fPx7mpWttOq-Jz014OPcljRrJWfbtz0MaJy0OY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689664709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "waruithemystery.hashnode.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://waruithemystery.hashnode.dev/unleashing-the-power-of-data-choosing-the-right-storage-system", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?auto=webp&amp;s=76f5feabe1088e5a7e933f706d45b03c187041a4", "width": 1200, "height": 840}, "resolutions": [{"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04e6f81d17d408d5974273992d6d90d263e8df1c", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bdad375d47b17d15ac4f0aaef826d4ed177f7506", "width": 216, "height": 151}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec45ff075400efbd48e383d3f4181f961972ee60", "width": 320, "height": 224}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4cd3a4b29aa434f12207cc6e12d887b97fe385ef", "width": 640, "height": 448}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=099ac6fd14571e30d1b1e578f8e77d563ed48493", "width": 960, "height": 672}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39e11829a7eaae13f171f3fd5685dfe26fab5322", "width": 1080, "height": 756}], "variants": {}, "id": "VAuaOqHlidZveGyq3PdjODh479ysn4eoBTpoDQbWSDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "152rbb9", "is_robot_indexable": true, "report_reasons": null, "author": "RemarkableAttempt311", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rbb9/unleashing_the_power_of_data_choosing_the_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://waruithemystery.hashnode.dev/unleashing-the-power-of-data-choosing-the-right-storage-system", "subreddit_subscribers": 116499, "created_utc": 1689664709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any additional advice, tips, or personal experiences you can share would be immensely helpful in my career journey. I am eager to grow professionally and enhance my skills in these exciting fields. ", "author_fullname": "t2_ckp9vdid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Securing Data Engineering, Data Science, or Data Analysis Jobs as a Fresh Graduate Based in Asia, Preferably with Overseas Opportunities and Dollar-Based Compensation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152qsh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689663007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any additional advice, tips, or personal experiences you can share would be immensely helpful in my career journey. I am eager to grow professionally and enhance my skills in these exciting fields. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152qsh4", "is_robot_indexable": true, "report_reasons": null, "author": "Informal-Actuary8833", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152qsh4/seeking_advice_on_securing_data_engineering_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152qsh4/seeking_advice_on_securing_data_engineering_data/", "subreddit_subscribers": 116499, "created_utc": 1689663007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I browsed through the community posts and understood that [neetcode.io](https://neetcode.io) is by far the best and the most recommended platform for practising Python for DE interviews.\n\nI work as a Data Engineer at a small startup right now, but never in my life I have done LeetCode or even touched DSA, hence requesting for help here.\n\nIn the [neetcode.io](https://neetcode.io) platform, in the practice section, if we sort by group, the questions are grouped by topic so that you can tackle them accordingly.\n\nBased on your interview experience, can you please help me prioritise the topics? I am guessing many of these topics are for SDE interviews and not all might be relevant to DE interviews, and even if they are relevant, some must be more important than others.\n\nThe topics are:\n\n1. Arrays and Hashing\n2. Two Pointers\n3. Sliding Window\n4. Stack\n5. Binary Search\n6. Linked List\n7. Trees\n8. Tries\n9. Heap / Priority Queue\n10. Backtracking\n11. Graphs\n12. Advanced Graphs\n13. 1-D dynamic programming\n14. 2-D dynamic programming\n15. Greedy\n16. Intervals\n17. Math &amp; Geometry\n18. Bit Manipulation\n\nThe reasons I have to prioritise/filter this is because I have limited time left in the interview prep hence want the important things 1st, and also because I am not specifically targeting MAANG.\n\n&amp;#x200B;\n\nThank you for the help!!", "author_fullname": "t2_cu6910tv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview preparation help - Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152ny8o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689653788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I browsed through the community posts and understood that &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; is by far the best and the most recommended platform for practising Python for DE interviews.&lt;/p&gt;\n\n&lt;p&gt;I work as a Data Engineer at a small startup right now, but never in my life I have done LeetCode or even touched DSA, hence requesting for help here.&lt;/p&gt;\n\n&lt;p&gt;In the &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; platform, in the practice section, if we sort by group, the questions are grouped by topic so that you can tackle them accordingly.&lt;/p&gt;\n\n&lt;p&gt;Based on your interview experience, can you please help me prioritise the topics? I am guessing many of these topics are for SDE interviews and not all might be relevant to DE interviews, and even if they are relevant, some must be more important than others.&lt;/p&gt;\n\n&lt;p&gt;The topics are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Arrays and Hashing&lt;/li&gt;\n&lt;li&gt;Two Pointers&lt;/li&gt;\n&lt;li&gt;Sliding Window&lt;/li&gt;\n&lt;li&gt;Stack&lt;/li&gt;\n&lt;li&gt;Binary Search&lt;/li&gt;\n&lt;li&gt;Linked List&lt;/li&gt;\n&lt;li&gt;Trees&lt;/li&gt;\n&lt;li&gt;Tries&lt;/li&gt;\n&lt;li&gt;Heap / Priority Queue&lt;/li&gt;\n&lt;li&gt;Backtracking&lt;/li&gt;\n&lt;li&gt;Graphs&lt;/li&gt;\n&lt;li&gt;Advanced Graphs&lt;/li&gt;\n&lt;li&gt;1-D dynamic programming&lt;/li&gt;\n&lt;li&gt;2-D dynamic programming&lt;/li&gt;\n&lt;li&gt;Greedy&lt;/li&gt;\n&lt;li&gt;Intervals&lt;/li&gt;\n&lt;li&gt;Math &amp;amp; Geometry&lt;/li&gt;\n&lt;li&gt;Bit Manipulation&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The reasons I have to prioritise/filter this is because I have limited time left in the interview prep hence want the important things 1st, and also because I am not specifically targeting MAANG.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for the help!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152ny8o", "is_robot_indexable": true, "report_reasons": null, "author": "table_data", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152ny8o/interview_preparation_help_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152ny8o/interview_preparation_help_python/", "subreddit_subscribers": 116499, "created_utc": 1689653788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious about how well the open source self-hosted version works, and how it compares feature-wise to the cloud version. Thanks!", "author_fullname": "t2_brgtw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have experience self-hosting Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152lvk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689647841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious about how well the open source self-hosted version works, and how it compares feature-wise to the cloud version. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152lvk5", "is_robot_indexable": true, "report_reasons": null, "author": "kdamica", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152lvk5/does_anyone_have_experience_selfhosting_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152lvk5/does_anyone_have_experience_selfhosting_airbyte/", "subreddit_subscribers": 116499, "created_utc": 1689647841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:\n\n* bucket\n   * tbl\\_1\n      * data1.csv\n      * data2.csv\n   * tbl\\_2\n      * data1.csv\n      * data2.csv\n\nI'm successfully creating a streaming live table for both tbl\\_1 and tbl\\_2 by invoking autoloader, using the `@dlt.table` decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. \n\nThe problem I'm facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I'm only able to query the data if and only if it was loaded in the previous run of the dlt workflow.", "author_fullname": "t2_789pafin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding how Delta Live Tables (DLT) and Unity Catalog work in tandem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152k8kp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689643337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;bucket\n\n&lt;ul&gt;\n&lt;li&gt;tbl_1\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;tbl_2\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m successfully creating a streaming live table for both tbl_1 and tbl_2 by invoking autoloader, using the &lt;code&gt;@dlt.table&lt;/code&gt; decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. &lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I&amp;#39;m only able to query the data if and only if it was loaded in the previous run of the dlt workflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152k8kp", "is_robot_indexable": true, "report_reasons": null, "author": "_nudist_buddhist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "subreddit_subscribers": 116499, "created_utc": 1689643337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work as an R&amp;D Test  Engineer in the Microelectronics industry and I'm looking for a title of  some type of Software/Data engineering position to search for.\n\nA little bit of background -- my current role is to process all of our data taken from our test equipment while characterizing our integrated  circuits during on-wafer probe testing. I manipulate all of our test  data into usable format where I then plot the information according to internal/external customers wants and needs.\n\nFrom here, I normalize all of our test data taken from the lab and import everything through a data pipeline via the libraries and packages below. Next, I try to find a correlation between the process control monitors (PCM) and our test data taken from the lab. Process control monitors are random data points on the wafer that gives us information on wafer oxidation thickness, capacitance values, leakage values and so on that are distributed to us from the manufacturer. I'll use different statistical methods such as Bi-Serial Point Methods, Linear Regression and the use of histograms for example. If I find something of high correlation between the PCM data our test data, I'll dive deeper and analyze it. The whole point of this is to predict wafer yield based on a PCM data range and lab collected test data.\n\nLastly, we use machine learning models to predict our next lot's yield based off the high correlation PCM data/test data. I am new to building machine learning models and machine learning as a whole, but I've enjoyed this process so much I'm thinking about getting a Masters in either Machine Learning, Applied Data Science or something along those lines.\n\n**The libraries and packages I use are:** Python, NumPy, Pandas, Matplotlib, Pytorch, Keras, SciPy, Scikit learn and not an exhaustive list.\n\nI may be looking for a new job soon if I am switched into another role in the company that I don't want to do, which I wont get into here.\n\nAnyway, if I wanted to dive deeper into this type of role or job, what job title should search for?\n\nThanks all", "author_fullname": "t2_1ra6klf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152k2qc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689642897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work as an R&amp;amp;D Test  Engineer in the Microelectronics industry and I&amp;#39;m looking for a title of  some type of Software/Data engineering position to search for.&lt;/p&gt;\n\n&lt;p&gt;A little bit of background -- my current role is to process all of our data taken from our test equipment while characterizing our integrated  circuits during on-wafer probe testing. I manipulate all of our test  data into usable format where I then plot the information according to internal/external customers wants and needs.&lt;/p&gt;\n\n&lt;p&gt;From here, I normalize all of our test data taken from the lab and import everything through a data pipeline via the libraries and packages below. Next, I try to find a correlation between the process control monitors (PCM) and our test data taken from the lab. Process control monitors are random data points on the wafer that gives us information on wafer oxidation thickness, capacitance values, leakage values and so on that are distributed to us from the manufacturer. I&amp;#39;ll use different statistical methods such as Bi-Serial Point Methods, Linear Regression and the use of histograms for example. If I find something of high correlation between the PCM data our test data, I&amp;#39;ll dive deeper and analyze it. The whole point of this is to predict wafer yield based on a PCM data range and lab collected test data.&lt;/p&gt;\n\n&lt;p&gt;Lastly, we use machine learning models to predict our next lot&amp;#39;s yield based off the high correlation PCM data/test data. I am new to building machine learning models and machine learning as a whole, but I&amp;#39;ve enjoyed this process so much I&amp;#39;m thinking about getting a Masters in either Machine Learning, Applied Data Science or something along those lines.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The libraries and packages I use are:&lt;/strong&gt; Python, NumPy, Pandas, Matplotlib, Pytorch, Keras, SciPy, Scikit learn and not an exhaustive list.&lt;/p&gt;\n\n&lt;p&gt;I may be looking for a new job soon if I am switched into another role in the company that I don&amp;#39;t want to do, which I wont get into here.&lt;/p&gt;\n\n&lt;p&gt;Anyway, if I wanted to dive deeper into this type of role or job, what job title should search for?&lt;/p&gt;\n\n&lt;p&gt;Thanks all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152k2qc", "is_robot_indexable": true, "report_reasons": null, "author": "Upgrayyedd43", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152k2qc/job_title/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152k2qc/job_title/", "subreddit_subscribers": 116499, "created_utc": 1689642897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking of building such a tool that can\n\n\\- Aggregate all pipeline status on one page\n\n\\- Manage notifications for different systems\n\n\\- Unify incident reports\n\nI did some research only to find a 3 yo post. [https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline\\_monitoring\\_tool/](https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/)\n\nI'm wondering if there's existing tools doing this / if not, anyone has the need?", "author_fullname": "t2_6mmm3ywiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unified pipeline monitoring tool / all-in-one pipeline status page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152cldb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689624752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking of building such a tool that can&lt;/p&gt;\n\n&lt;p&gt;- Aggregate all pipeline status on one page&lt;/p&gt;\n\n&lt;p&gt;- Manage notifications for different systems&lt;/p&gt;\n\n&lt;p&gt;- Unify incident reports&lt;/p&gt;\n\n&lt;p&gt;I did some research only to find a 3 yo post. &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/\"&gt;https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if there&amp;#39;s existing tools doing this / if not, anyone has the need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152cldb", "is_robot_indexable": true, "report_reasons": null, "author": "WEI3M", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "subreddit_subscribers": 116499, "created_utc": 1689624752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9uiwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you really need exactly-once delivery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15270yt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nwqg-bA9yKtkh-5nBchWxMPm0l24EuljbLUBOPM3qYc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689612063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "streamingdata.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?auto=webp&amp;s=04d6977076f8d968368d6533d4d93bcc4e03f4d3", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=febf87d18ab938c89253d5e7d0697e337bf0e88e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c37da59f1936c995870386de473bad9a4a0c1260", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a059a8e1f66d01ae2eb0b0a1b4572e8187739f1a", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e139e12aa841bac14920bb64d92f70324e0d70d0", "width": 640, "height": 333}], "variants": {}, "id": "TL5zSeeNMw6fBGF0Ca693DL1GL7baDPqZ8ZyarYmuos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15270yt", "is_robot_indexable": true, "report_reasons": null, "author": "sap1enz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15270yt/do_you_really_need_exactlyonce_delivery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "subreddit_subscribers": 116499, "created_utc": 1689612063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a [retrieval-augmented generation](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html) use case (a.k.a. chat with your data).\n\n&amp;#x200B;\n\nMy current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like [https://www.chaindesk.ai/](https://www.chaindesk.ai/) but they feel a bit too limiting for my use case.", "author_fullname": "t2_2s6nwgck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move semi-structured data to LLMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1526j16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689610913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a &lt;a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html\"&gt;retrieval-augmented generation&lt;/a&gt; use case (a.k.a. chat with your data).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like &lt;a href=\"https://www.chaindesk.ai/\"&gt;https://www.chaindesk.ai/&lt;/a&gt; but they feel a bit too limiting for my use case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1526j16", "is_robot_indexable": true, "report_reasons": null, "author": "shrifbot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "subreddit_subscribers": 116499, "created_utc": 1689610913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse - event data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1525pib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689609082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1525pib", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525pib/lakehouse_event_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1525pib/lakehouse_event_data/", "subreddit_subscribers": 116499, "created_utc": 1689609082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to help my wife switch her domains. she is currently a FTE at infosys with \\~6 years experience in the IT Services domain. She spent 5 years at IBM before joining Infy in same project.\n\nShe has extensive onsite experience where she worked with IBM Australia with Westpac back.\n\nAs expected, she has stagnated massively and will become completely disconnected with tech if she continues in these companies. One rather seamless switch that we feel she can pursue is moving to Snowflake platform and pursuing a career in either dev or as an analyst.\n\nShe has been following tuts from multiple resources and aiming a certification as well, but lack of enough hands-on experience is making her nervous and preventing her from focussing on studies.\n\nGiven the current market situation, job opportunities are not easy either.\n\nHow can she explore internal switch within Infy to pursue Snowflake? Otherwise, how can she overall pursue this switch? We are f9 with her taking up contract positions as well as long as she gets to work on Snowflake.", "author_fullname": "t2_11mmk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "snowflake employment help for my wife", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1520p8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689597208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to help my wife switch her domains. she is currently a FTE at infosys with ~6 years experience in the IT Services domain. She spent 5 years at IBM before joining Infy in same project.&lt;/p&gt;\n\n&lt;p&gt;She has extensive onsite experience where she worked with IBM Australia with Westpac back.&lt;/p&gt;\n\n&lt;p&gt;As expected, she has stagnated massively and will become completely disconnected with tech if she continues in these companies. One rather seamless switch that we feel she can pursue is moving to Snowflake platform and pursuing a career in either dev or as an analyst.&lt;/p&gt;\n\n&lt;p&gt;She has been following tuts from multiple resources and aiming a certification as well, but lack of enough hands-on experience is making her nervous and preventing her from focussing on studies.&lt;/p&gt;\n\n&lt;p&gt;Given the current market situation, job opportunities are not easy either.&lt;/p&gt;\n\n&lt;p&gt;How can she explore internal switch within Infy to pursue Snowflake? Otherwise, how can she overall pursue this switch? We are f9 with her taking up contract positions as well as long as she gets to work on Snowflake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1520p8f", "is_robot_indexable": true, "report_reasons": null, "author": "Pbd1194", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1520p8f/snowflake_employment_help_for_my_wife/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1520p8f/snowflake_employment_help_for_my_wife/", "subreddit_subscribers": 116499, "created_utc": 1689597208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello, everyone!\n\nI am currently working on a project to build an ETL (Extract, Transform, Load) pipeline, and I would greatly appreciate some advice and guidance from the Reddit community.\n\nHere's a brief overview of the project: I am tasked with downloading data from an AWS S3 bucket, performing transformations using Pyspark, and loading the transformed data into a Postgres database. This is my first project of this nature, and I need to schedule this task to run automatically on a weekly basis.\n\nOne specific challenge I am facing is the need to compare the last six months of data in the S3 bucket with the data already present in the Postgres database. If any changes are detected in the S3 data, I need to overwrite the corresponding data in the Postgres database. The amount of data can range between 15-20 GB.\n\nI am currently using Pyspark for data transformations, but I would appreciate any recommendations or best practices on efficiently comparing and updating the data between S3 and Postgres.\n\nAdditionally, I am in the process of selecting a suitable tool for scheduling and managing ETL tasks. I have set up Airflow, but I am uncertain whether it is the best fit for this project. I would love to hear your thoughts and experiences with scheduling ETL tasks, particularly for a scenario like mine.\n\nThank you in advance for any advice, suggestions, or insights you can provide. I am eager to learn from your expertise and make this ETL pipeline project a success!", "author_fullname": "t2_fjuwxuxxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on Building an ETL Pipeline with AWS S3, Postgres, and Pyspark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151yksz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689591190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, everyone!&lt;/p&gt;\n\n&lt;p&gt;I am currently working on a project to build an ETL (Extract, Transform, Load) pipeline, and I would greatly appreciate some advice and guidance from the Reddit community.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a brief overview of the project: I am tasked with downloading data from an AWS S3 bucket, performing transformations using Pyspark, and loading the transformed data into a Postgres database. This is my first project of this nature, and I need to schedule this task to run automatically on a weekly basis.&lt;/p&gt;\n\n&lt;p&gt;One specific challenge I am facing is the need to compare the last six months of data in the S3 bucket with the data already present in the Postgres database. If any changes are detected in the S3 data, I need to overwrite the corresponding data in the Postgres database. The amount of data can range between 15-20 GB.&lt;/p&gt;\n\n&lt;p&gt;I am currently using Pyspark for data transformations, but I would appreciate any recommendations or best practices on efficiently comparing and updating the data between S3 and Postgres.&lt;/p&gt;\n\n&lt;p&gt;Additionally, I am in the process of selecting a suitable tool for scheduling and managing ETL tasks. I have set up Airflow, but I am uncertain whether it is the best fit for this project. I would love to hear your thoughts and experiences with scheduling ETL tasks, particularly for a scenario like mine.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any advice, suggestions, or insights you can provide. I am eager to learn from your expertise and make this ETL pipeline project a success!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151yksz", "is_robot_indexable": true, "report_reasons": null, "author": "Data_is_fuel", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151yksz/advice_on_building_an_etl_pipeline_with_aws_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151yksz/advice_on_building_an_etl_pipeline_with_aws_s3/", "subreddit_subscribers": 116499, "created_utc": 1689591190.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}