{"kind": "Listing", "data": {"after": "t3_152xzcv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a big tech company as a new grad and my title is technically data engineer, however much of my work is building distributed Python applications for ML and data replication, spark, Java, devops pipelines and infrastructure automation (ansible). If I write sql, it\u2019s always within a Python application and is nothing more than an insert, table creation or simple select query. With my experience, would I be more suited to go into software engineer roles moving forward? Scared of applying to companies that use modern data stack or no-code tools and I am stuck having to re-learn SQL or failing an interview.\n\nEdit: I\u2019d consider myself average at SQL, I\u2019ve passed all-SQL interviews, just worried about my skills atrophying as it\u2019s not something I really enjoy to use and my role doesn\u2019t require it", "author_fullname": "t2_7szv7c66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am a new grad \u201cdata engineer\u201d who barely writes SQL, how will my career be impacted?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152own3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689657321.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689656717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a big tech company as a new grad and my title is technically data engineer, however much of my work is building distributed Python applications for ML and data replication, spark, Java, devops pipelines and infrastructure automation (ansible). If I write sql, it\u2019s always within a Python application and is nothing more than an insert, table creation or simple select query. With my experience, would I be more suited to go into software engineer roles moving forward? Scared of applying to companies that use modern data stack or no-code tools and I am stuck having to re-learn SQL or failing an interview.&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019d consider myself average at SQL, I\u2019ve passed all-SQL interviews, just worried about my skills atrophying as it\u2019s not something I really enjoy to use and my role doesn\u2019t require it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152own3", "is_robot_indexable": true, "report_reasons": null, "author": "aacreans", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152own3/i_am_a_new_grad_data_engineer_who_barely_writes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152own3/i_am_a_new_grad_data_engineer_who_barely_writes/", "subreddit_subscribers": 116575, "created_utc": 1689656717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to data engineering, and I like to learn by trying/building. I am very unclear what's the best way to go about it?\n\nMy ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?", "author_fullname": "t2_17d42esw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best \"free\" set-up to learn or try to build a data pipeline on my own?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152c49r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689623684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to data engineering, and I like to learn by trying/building. I am very unclear what&amp;#39;s the best way to go about it?&lt;/p&gt;\n\n&lt;p&gt;My ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152c49r", "is_robot_indexable": true, "report_reasons": null, "author": "Guyserbun007", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "subreddit_subscribers": 116575, "created_utc": 1689623684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vu1osuil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free copy of \"Fundamentals of Data Engineering\" to learn DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_152yp2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GJI0r0i8VjTz63FENoduduO-aG2eafmRRKm-m4dFnog.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689687366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "go.redpanda.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://go.redpanda.com/fundamentals-of-data-engineering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?auto=webp&amp;s=6f9d8b67339ba2e24729a4a01e4af69d6901708f", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=236e8977b4b29caf518afabda6cb27e5578688e7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=67afdf69c3c0cbf2a5888fd982265c8c751faf88", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5fecab72d37c8cfac0c5625ef320265d80e8a454", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f977129c4dd4d0d928d0ef1fd8faac749207bddf", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8cb4b8b9e83333f6fb4cf1e964fc483caf512f4f", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/8AB7VBllU8HKwvPmxMwhhPGsRfEjojCWkNhg-sOfEyA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=62b640989f071b0f21f1905b5666d573f4193741", "width": 1080, "height": 565}], "variants": {}, "id": "DvdgYgQFkuNvhWsi5MycPv45U50YDo5lni76VGlxImw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152yp2h", "is_robot_indexable": true, "report_reasons": null, "author": "TemporaryPoorFrench", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/152yp2h/free_copy_of_fundamentals_of_data_engineering_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://go.redpanda.com/fundamentals-of-data-engineering", "subreddit_subscribers": 116575, "created_utc": 1689687366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I study 15 hours a day 7 days a week trying to make my dream a reality. ETL, ELT, coding, learning Python, SQL, reading entire chapters of data engineering books and outlining them on paper and then on the computer to make sure it sticks... Then there are people here asking and basically bragging about having a data engineer position where they do literally nothing. No actual data engineering, maybe some light leg work or job responsibilities, and some minor SQL. \n\n\nWhat I want to know is how. How are people getting these? Where do I get one?", "author_fullname": "t2_vnan4h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are people getting into data engineering with basically no responsibilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152w0h7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689680210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I study 15 hours a day 7 days a week trying to make my dream a reality. ETL, ELT, coding, learning Python, SQL, reading entire chapters of data engineering books and outlining them on paper and then on the computer to make sure it sticks... Then there are people here asking and basically bragging about having a data engineer position where they do literally nothing. No actual data engineering, maybe some light leg work or job responsibilities, and some minor SQL. &lt;/p&gt;\n\n&lt;p&gt;What I want to know is how. How are people getting these? Where do I get one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152w0h7", "is_robot_indexable": true, "report_reasons": null, "author": "Analyst2163", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152w0h7/how_are_people_getting_into_data_engineering_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152w0h7/how_are_people_getting_into_data_engineering_with/", "subreddit_subscribers": 116575, "created_utc": 1689680210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?", "author_fullname": "t2_c532a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What steps to take after first role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1524trd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689607060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1524trd", "is_robot_indexable": true, "report_reasons": null, "author": "gators939", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "subreddit_subscribers": 116575, "created_utc": 1689607060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4t6cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM based pipelines with PostgresML and dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_1525yyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z3TI0arYlw4RRR3jUUbPUO2vA2egarxlpp1dP09FXtE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689609669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "postgresml.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?auto=webp&amp;s=0b690342c0b9264e580cd8629721f878d18ff954", "width": 784, "height": 519}, "resolutions": [{"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf6a365fbb7793932f29fbb28fa434d479b46d55", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0effd2b3a0537c8131fd28109ff37439457f1ddc", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d160cb4efab6957e3d11789882fe0b658cafe87e", "width": 320, "height": 211}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e154f104eedac0bc7c9e36c987df586978c19eb0", "width": 640, "height": 423}], "variants": {}, "id": "dxDnyB5RtYkyN-bX3C7E2eUqvQzE9_-FZU6xkZ1aDRQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1525yyl", "is_robot_indexable": true, "report_reasons": null, "author": "something_cleverer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525yyl/llm_based_pipelines_with_postgresml_and_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "subreddit_subscribers": 116575, "created_utc": 1689609669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Two years ago I transitioned from Systems Analyst (app dev) to Data Engineer.  I am the only Data Engineer in our company.  When I transitioned, not only did I continue maintaining all of my legacy projects, but I have since taken over all cloud app development in Azure, designed and maintained our API Management Gateways for third-party devs and vendors (multiple environments, dozens of API products), created numerous backend APIs, implemented most file/data exchange processes between our company and third-parties, created numerous ETL processes which includes many replication jobs from third-parties apps, etc.  I did much of this as a level 1 DE (I am now level 2).  I am trying to understand how much of this is actual Data Engineering and how much of it is something else (Cloud App Development?).  I also am curious what level I should be.\n\nAdditional context:  5+ years with the company.", "author_fullname": "t2_4d6r2kn6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is my role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152z2bq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689689718.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689688281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Two years ago I transitioned from Systems Analyst (app dev) to Data Engineer.  I am the only Data Engineer in our company.  When I transitioned, not only did I continue maintaining all of my legacy projects, but I have since taken over all cloud app development in Azure, designed and maintained our API Management Gateways for third-party devs and vendors (multiple environments, dozens of API products), created numerous backend APIs, implemented most file/data exchange processes between our company and third-parties, created numerous ETL processes which includes many replication jobs from third-parties apps, etc.  I did much of this as a level 1 DE (I am now level 2).  I am trying to understand how much of this is actual Data Engineering and how much of it is something else (Cloud App Development?).  I also am curious what level I should be.&lt;/p&gt;\n\n&lt;p&gt;Additional context:  5+ years with the company.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152z2bq", "is_robot_indexable": true, "report_reasons": null, "author": "1_0-0_1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152z2bq/what_is_my_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152z2bq/what_is_my_role/", "subreddit_subscribers": 116575, "created_utc": 1689688281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was hired as a DS at a scale-up company, and have implemented all data engineering pipelines using the following stack: Prefect + pandas, with .parquet files on azure datalake as final storage.\n\nI am running into some performance issues, and would possibly want to separate the orchestration and compute., using some warehouse option for the compute. Additionally, the final storage should probably also be a warehouse and not a datalake, as we are hiring analysts that would probably expect some SQL-queryable storage.\n\nI am basically looking into options for warehouses that can do the whole ELT process. Would something like SnowFlake be a good option, or is it overkill for small sizes of data?   \nDoes it handle extract/normalization of fairly complex json files, or should I use some other tool for the extract part?\n\n&amp;#x200B;", "author_fullname": "t2_lixpgvfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for warehouse options to replace pandas ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152vv4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689679785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was hired as a DS at a scale-up company, and have implemented all data engineering pipelines using the following stack: Prefect + pandas, with .parquet files on azure datalake as final storage.&lt;/p&gt;\n\n&lt;p&gt;I am running into some performance issues, and would possibly want to separate the orchestration and compute., using some warehouse option for the compute. Additionally, the final storage should probably also be a warehouse and not a datalake, as we are hiring analysts that would probably expect some SQL-queryable storage.&lt;/p&gt;\n\n&lt;p&gt;I am basically looking into options for warehouses that can do the whole ELT process. Would something like SnowFlake be a good option, or is it overkill for small sizes of data?&lt;br/&gt;\nDoes it handle extract/normalization of fairly complex json files, or should I use some other tool for the extract part?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152vv4s", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping-Nail-250", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152vv4s/looking_for_warehouse_options_to_replace_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152vv4s/looking_for_warehouse_options_to_replace_pandas/", "subreddit_subscribers": 116575, "created_utc": 1689679785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nI'm exploring the transition into a data role as the next phase of my career. Uncovering data engineering concepts and architectures make my juices flow again after a few years of stagnation in my current infrastructure solution architect role. Data science and analysis isn't my bag, I'm focused on the engineering track.\n\nMy background: I've worked in public and private cloud (primarily Azure infrastructure and micro-services) and data management (primarily protection and disaster recovery) for c. 13 years, the last 5 at a senior architect level. \n\nI've seen a few posts on 'transitioning' roles and currently looking through the wiki to understand skillsets but would loveto hear from those who have experienced a similar transition from cloud solution architect into a data role. \n\n I'm working my way through DP-203 and I envisage the most difficult aspects will include coding. However, that's something I'll just have to work on.\n\nDid you work from a data engineering starting point up to data architect? Did you face any significant hurdles or were there any skills that you found invaluable in your journey?", "author_fullname": "t2_a0k3gzpb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition from cloud architect into data role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152rnc1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689665871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m exploring the transition into a data role as the next phase of my career. Uncovering data engineering concepts and architectures make my juices flow again after a few years of stagnation in my current infrastructure solution architect role. Data science and analysis isn&amp;#39;t my bag, I&amp;#39;m focused on the engineering track.&lt;/p&gt;\n\n&lt;p&gt;My background: I&amp;#39;ve worked in public and private cloud (primarily Azure infrastructure and micro-services) and data management (primarily protection and disaster recovery) for c. 13 years, the last 5 at a senior architect level. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a few posts on &amp;#39;transitioning&amp;#39; roles and currently looking through the wiki to understand skillsets but would loveto hear from those who have experienced a similar transition from cloud solution architect into a data role. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working my way through DP-203 and I envisage the most difficult aspects will include coding. However, that&amp;#39;s something I&amp;#39;ll just have to work on.&lt;/p&gt;\n\n&lt;p&gt;Did you work from a data engineering starting point up to data architect? Did you face any significant hurdles or were there any skills that you found invaluable in your journey?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152rnc1", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Figure88", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rnc1/transition_from_cloud_architect_into_data_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152rnc1/transition_from_cloud_architect_into_data_role/", "subreddit_subscribers": 116575, "created_utc": 1689665871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I browsed through the community posts and understood that [neetcode.io](https://neetcode.io) is by far the best and the most recommended platform for practising Python for DE interviews.\n\nI work as a Data Engineer at a small startup right now, but never in my life I have done LeetCode or even touched DSA, hence requesting for help here.\n\nIn the [neetcode.io](https://neetcode.io) platform, in the practice section, if we sort by group, the questions are grouped by topic so that you can tackle them accordingly.\n\nBased on your interview experience, can you please help me prioritise the topics? I am guessing many of these topics are for SDE interviews and not all might be relevant to DE interviews, and even if they are relevant, some must be more important than others.\n\nThe topics are:\n\n1. Arrays and Hashing\n2. Two Pointers\n3. Sliding Window\n4. Stack\n5. Binary Search\n6. Linked List\n7. Trees\n8. Tries\n9. Heap / Priority Queue\n10. Backtracking\n11. Graphs\n12. Advanced Graphs\n13. 1-D dynamic programming\n14. 2-D dynamic programming\n15. Greedy\n16. Intervals\n17. Math &amp; Geometry\n18. Bit Manipulation\n\nThe reasons I have to prioritise/filter this is because I have limited time left in the interview prep hence want the important things 1st, and also because I am not specifically targeting MAANG.\n\n&amp;#x200B;\n\nThank you for the help!!", "author_fullname": "t2_cu6910tv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview preparation help - Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152ny8o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689653788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I browsed through the community posts and understood that &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; is by far the best and the most recommended platform for practising Python for DE interviews.&lt;/p&gt;\n\n&lt;p&gt;I work as a Data Engineer at a small startup right now, but never in my life I have done LeetCode or even touched DSA, hence requesting for help here.&lt;/p&gt;\n\n&lt;p&gt;In the &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; platform, in the practice section, if we sort by group, the questions are grouped by topic so that you can tackle them accordingly.&lt;/p&gt;\n\n&lt;p&gt;Based on your interview experience, can you please help me prioritise the topics? I am guessing many of these topics are for SDE interviews and not all might be relevant to DE interviews, and even if they are relevant, some must be more important than others.&lt;/p&gt;\n\n&lt;p&gt;The topics are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Arrays and Hashing&lt;/li&gt;\n&lt;li&gt;Two Pointers&lt;/li&gt;\n&lt;li&gt;Sliding Window&lt;/li&gt;\n&lt;li&gt;Stack&lt;/li&gt;\n&lt;li&gt;Binary Search&lt;/li&gt;\n&lt;li&gt;Linked List&lt;/li&gt;\n&lt;li&gt;Trees&lt;/li&gt;\n&lt;li&gt;Tries&lt;/li&gt;\n&lt;li&gt;Heap / Priority Queue&lt;/li&gt;\n&lt;li&gt;Backtracking&lt;/li&gt;\n&lt;li&gt;Graphs&lt;/li&gt;\n&lt;li&gt;Advanced Graphs&lt;/li&gt;\n&lt;li&gt;1-D dynamic programming&lt;/li&gt;\n&lt;li&gt;2-D dynamic programming&lt;/li&gt;\n&lt;li&gt;Greedy&lt;/li&gt;\n&lt;li&gt;Intervals&lt;/li&gt;\n&lt;li&gt;Math &amp;amp; Geometry&lt;/li&gt;\n&lt;li&gt;Bit Manipulation&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The reasons I have to prioritise/filter this is because I have limited time left in the interview prep hence want the important things 1st, and also because I am not specifically targeting MAANG.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for the help!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152ny8o", "is_robot_indexable": true, "report_reasons": null, "author": "table_data", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152ny8o/interview_preparation_help_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152ny8o/interview_preparation_help_python/", "subreddit_subscribers": 116575, "created_utc": 1689653788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I need some output regarding this situation.  \nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post \"submit\", as soon as that happens, the job needs to be submitted!  \nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can't really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?  \nLove to know your thoughts!  \nThanks", "author_fullname": "t2_xqvyn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink Batch Job needs to run based on a trigger", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152m3hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689648465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I need some output regarding this situation.&lt;br/&gt;\nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post &amp;quot;submit&amp;quot;, as soon as that happens, the job needs to be submitted!&lt;br/&gt;\nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can&amp;#39;t really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?&lt;br/&gt;\nLove to know your thoughts!&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152m3hr", "is_robot_indexable": true, "report_reasons": null, "author": "Salekeen01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "subreddit_subscribers": 116575, "created_utc": 1689648465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:\n\n* bucket\n   * tbl\\_1\n      * data1.csv\n      * data2.csv\n   * tbl\\_2\n      * data1.csv\n      * data2.csv\n\nI'm successfully creating a streaming live table for both tbl\\_1 and tbl\\_2 by invoking autoloader, using the `@dlt.table` decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. \n\nThe problem I'm facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I'm only able to query the data if and only if it was loaded in the previous run of the dlt workflow.", "author_fullname": "t2_789pafin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding how Delta Live Tables (DLT) and Unity Catalog work in tandem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152k8kp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689643337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;bucket\n\n&lt;ul&gt;\n&lt;li&gt;tbl_1\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;tbl_2\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m successfully creating a streaming live table for both tbl_1 and tbl_2 by invoking autoloader, using the &lt;code&gt;@dlt.table&lt;/code&gt; decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. &lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I&amp;#39;m only able to query the data if and only if it was loaded in the previous run of the dlt workflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152k8kp", "is_robot_indexable": true, "report_reasons": null, "author": "_nudist_buddhist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "subreddit_subscribers": 116575, "created_utc": 1689643337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_aqxyws3e5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Need help on how to improve to get interviews or past the screening round", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"tx98gqnq8qcb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 126, "x": 108, "u": "https://preview.redd.it/tx98gqnq8qcb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3785f6592231a629d7465e6bdb3229d9d9a32011"}, {"y": 252, "x": 216, "u": "https://preview.redd.it/tx98gqnq8qcb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=006df62f119fa80de2accbad163d396b244c982c"}, {"y": 373, "x": 320, "u": "https://preview.redd.it/tx98gqnq8qcb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=150cd841e12555fd67713a7fa8e899efeb3c8e6f"}, {"y": 746, "x": 640, "u": "https://preview.redd.it/tx98gqnq8qcb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5a04ec7bcc8b171abc12d75552b393243c7463c"}], "s": {"y": 866, "x": 742, "u": "https://preview.redd.it/tx98gqnq8qcb1.png?width=742&amp;format=png&amp;auto=webp&amp;s=5ebc66fbb1b5732f937d1cd6d0d7c4f902317c06"}, "id": "tx98gqnq8qcb1"}, "q6dkvrnq8qcb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 129, "x": 108, "u": "https://preview.redd.it/q6dkvrnq8qcb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e3a8216244e146073a2efddf01861d81b501086"}, {"y": 258, "x": 216, "u": "https://preview.redd.it/q6dkvrnq8qcb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6beb33be13cf5a48b4bc57321e84c3b25577d753"}, {"y": 382, "x": 320, "u": "https://preview.redd.it/q6dkvrnq8qcb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=997b8206981c5e256f96391e6b5f143345cb7359"}, {"y": 764, "x": 640, "u": "https://preview.redd.it/q6dkvrnq8qcb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=188c1bf16a85c0c30fc437f80ebd8c097001cbab"}], "s": {"y": 878, "x": 735, "u": "https://preview.redd.it/q6dkvrnq8qcb1.png?width=735&amp;format=png&amp;auto=webp&amp;s=cfc485af37a048dd891ac7a7d8d7c4596da9da0d"}, "id": "q6dkvrnq8qcb1"}}, "name": "t3_152zcn7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Page 1/2", "media_id": "tx98gqnq8qcb1", "id": 303251320}, {"caption": "Page 2/2", "media_id": "q6dkvrnq8qcb1", "id": 303251321}]}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/yEsT9b0gHklu_z1HU-d_U_6cMvSTVCmDERCsacgdZQ0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689688966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/152zcn7", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152zcn7", "is_robot_indexable": true, "report_reasons": null, "author": "berbeer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152zcn7/need_help_on_how_to_improve_to_get_interviews_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/152zcn7", "subreddit_subscribers": 116575, "created_utc": 1689688966.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, I'd like to share my current situation to understand better where to go.\n\nI started in data as a ETL developer since 2011, I did projects using DataStream (old Cognos), PowerCenter, SSIS, Talend, SAS and even VBA up to 2016 when I joined a data visualization tool company as consultant mainly focused to create conceptual DB models and reports/dashboards with this tool. However since 2018 composed by 2 periods (2016-2021 and from 2022- up-to-date)   most of my projects were related to upgrade servers to newer software versions, configuration etc. There were a couple projects here and there that were related to predictive analytics with python and/or R, NoSQL, Hadoop, Query performance, data ingestion, but summing all of this it is no more than 10% of my time.\n\nWithin 2021 I left this job for a ecommerce company which I had to work with python, Big Query, Teradata, Presto etc. But unfortunately I had to leave it to immigrate which was a bigger dream. That's why I re-joined the previously mentioned company.\n\nI feel that I have the requirements, I never stopped to study, I'm pretty good in query performance, data modeling, user specification, also know python, Scala, AWS, data bricks. a bunch of databases (SQL Server, Oracle, Teradata, MySQL, Big Query, Redshift, Snowflake, PostgreSQL) and I also know a little docker due to home projects, yet I've applied for almost 50 openings and didn't got any replies/interviews even diposed to earn a little less than I'm currently making if necessary. Sometimes I fell that the extended period working for the data viz company kinda put a stamp on me saying that I'm not capable of doing a DE job.\n\nMy question is, is it possible to go to a DE path?", "author_fullname": "t2_8c1ywuv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From data specific consultant to DE path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152y27j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689685752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I&amp;#39;d like to share my current situation to understand better where to go.&lt;/p&gt;\n\n&lt;p&gt;I started in data as a ETL developer since 2011, I did projects using DataStream (old Cognos), PowerCenter, SSIS, Talend, SAS and even VBA up to 2016 when I joined a data visualization tool company as consultant mainly focused to create conceptual DB models and reports/dashboards with this tool. However since 2018 composed by 2 periods (2016-2021 and from 2022- up-to-date)   most of my projects were related to upgrade servers to newer software versions, configuration etc. There were a couple projects here and there that were related to predictive analytics with python and/or R, NoSQL, Hadoop, Query performance, data ingestion, but summing all of this it is no more than 10% of my time.&lt;/p&gt;\n\n&lt;p&gt;Within 2021 I left this job for a ecommerce company which I had to work with python, Big Query, Teradata, Presto etc. But unfortunately I had to leave it to immigrate which was a bigger dream. That&amp;#39;s why I re-joined the previously mentioned company.&lt;/p&gt;\n\n&lt;p&gt;I feel that I have the requirements, I never stopped to study, I&amp;#39;m pretty good in query performance, data modeling, user specification, also know python, Scala, AWS, data bricks. a bunch of databases (SQL Server, Oracle, Teradata, MySQL, Big Query, Redshift, Snowflake, PostgreSQL) and I also know a little docker due to home projects, yet I&amp;#39;ve applied for almost 50 openings and didn&amp;#39;t got any replies/interviews even diposed to earn a little less than I&amp;#39;m currently making if necessary. Sometimes I fell that the extended period working for the data viz company kinda put a stamp on me saying that I&amp;#39;m not capable of doing a DE job.&lt;/p&gt;\n\n&lt;p&gt;My question is, is it possible to go to a DE path?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152y27j", "is_robot_indexable": true, "report_reasons": null, "author": "jokerxbr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152y27j/from_data_specific_consultant_to_de_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152y27j/from_data_specific_consultant_to_de_path/", "subreddit_subscribers": 116575, "created_utc": 1689685752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working for less than a year in a small IT services company as a data analyst. I'm the only one working in the data field, so I'm totally autonomous.  My job is pretty straightforward and basic: I create dashboards on Power Bi using data from the company's activities, such as accounting or human resources. The data is stored in SQL server databases on local servers.\n\nHere's my workflow, I create sql views in order to extract and process as much of the upstream data as possible directly in sql server and then import it into power bi. Thanks to a data gateway I've been able to automate the updating of the data on the dashboards that are put online. There is no real complexity or intelligence in this process and looking at this reddit every day I wondered if my practice was correct and optimal in my case or if I could optimise it with ETLs or tools/services like Databricks dbt ect.\n\nSorry for my poor English or if what I'm writing doesn't make much sense, I'm still a data science student with poor knowledge in data engineering.", "author_fullname": "t2_txt0cja7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a student data analyst in apprenticeship, what can I do to improve the data exploitation process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152xs6i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689685051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working for less than a year in a small IT services company as a data analyst. I&amp;#39;m the only one working in the data field, so I&amp;#39;m totally autonomous.  My job is pretty straightforward and basic: I create dashboards on Power Bi using data from the company&amp;#39;s activities, such as accounting or human resources. The data is stored in SQL server databases on local servers.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my workflow, I create sql views in order to extract and process as much of the upstream data as possible directly in sql server and then import it into power bi. Thanks to a data gateway I&amp;#39;ve been able to automate the updating of the data on the dashboards that are put online. There is no real complexity or intelligence in this process and looking at this reddit every day I wondered if my practice was correct and optimal in my case or if I could optimise it with ETLs or tools/services like Databricks dbt ect.&lt;/p&gt;\n\n&lt;p&gt;Sorry for my poor English or if what I&amp;#39;m writing doesn&amp;#39;t make much sense, I&amp;#39;m still a data science student with poor knowledge in data engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152xs6i", "is_robot_indexable": true, "report_reasons": null, "author": "Zuzukxd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152xs6i/as_a_student_data_analyst_in_apprenticeship_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152xs6i/as_a_student_data_analyst_in_apprenticeship_what/", "subreddit_subscribers": 116575, "created_utc": 1689685051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Max Kremer outlines real-time data streaming with Debezium and Postgres. Gone through the process before? What has your experience been?\n\n[https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/](https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/)\n\n&amp;#x200B;", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time data streaming with Debezium and Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152ws1a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689682327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Max Kremer outlines real-time data streaming with Debezium and Postgres. Gone through the process before? What has your experience been?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/\"&gt;https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?auto=webp&amp;s=c5f5a655d6864f84f08160aa3ecc6a483e366b29", "width": 2254, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77f04efc85875721aab74a0dbed87aab2166568f", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6660b3bca381afe6691fd6377052115955289b27", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15461ccea7f16f0c86fe0838ac84029482fac910", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e98a3a8fc7d6d3e1d17432c50f2e3090f4edc6e1", "width": 640, "height": 425}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=13795e652ab765a44ab68d9a18848a95426810a4", "width": 960, "height": 638}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5da9553f31250276789472e811efd60331226597", "width": 1080, "height": 718}], "variants": {}, "id": "yOcCqb_01Tcein84ljsq1UI3XyPdtH-HzgATv4P1fwg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152ws1a", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152ws1a/realtime_data_streaming_with_debezium_and_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152ws1a/realtime_data_streaming_with_debezium_and_postgres/", "subreddit_subscribers": 116575, "created_utc": 1689682327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c8yil9sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unleashing the power of Data: Choosing the right Storage System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_152rbb9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IIv1_fPx7mpWttOq-Jz014OPcljRrJWfbtz0MaJy0OY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689664709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "waruithemystery.hashnode.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://waruithemystery.hashnode.dev/unleashing-the-power-of-data-choosing-the-right-storage-system", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?auto=webp&amp;s=76f5feabe1088e5a7e933f706d45b03c187041a4", "width": 1200, "height": 840}, "resolutions": [{"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04e6f81d17d408d5974273992d6d90d263e8df1c", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bdad375d47b17d15ac4f0aaef826d4ed177f7506", "width": 216, "height": 151}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec45ff075400efbd48e383d3f4181f961972ee60", "width": 320, "height": 224}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4cd3a4b29aa434f12207cc6e12d887b97fe385ef", "width": 640, "height": 448}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=099ac6fd14571e30d1b1e578f8e77d563ed48493", "width": 960, "height": 672}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39e11829a7eaae13f171f3fd5685dfe26fab5322", "width": 1080, "height": 756}], "variants": {}, "id": "VAuaOqHlidZveGyq3PdjODh479ysn4eoBTpoDQbWSDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "152rbb9", "is_robot_indexable": true, "report_reasons": null, "author": "RemarkableAttempt311", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rbb9/unleashing_the_power_of_data_choosing_the_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://waruithemystery.hashnode.dev/unleashing-the-power-of-data-choosing-the-right-storage-system", "subreddit_subscribers": 116575, "created_utc": 1689664709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious about how well the open source self-hosted version works, and how it compares feature-wise to the cloud version. Thanks!", "author_fullname": "t2_brgtw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have experience self-hosting Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152lvk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689647841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious about how well the open source self-hosted version works, and how it compares feature-wise to the cloud version. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152lvk5", "is_robot_indexable": true, "report_reasons": null, "author": "kdamica", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152lvk5/does_anyone_have_experience_selfhosting_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152lvk5/does_anyone_have_experience_selfhosting_airbyte/", "subreddit_subscribers": 116575, "created_utc": 1689647841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work as an R&amp;D Test  Engineer in the Microelectronics industry and I'm looking for a title of  some type of Software/Data engineering position to search for.\n\nA little bit of background -- my current role is to process all of our data taken from our test equipment while characterizing our integrated  circuits during on-wafer probe testing. I manipulate all of our test  data into usable format where I then plot the information according to internal/external customers wants and needs.\n\nFrom here, I normalize all of our test data taken from the lab and import everything through a data pipeline via the libraries and packages below. Next, I try to find a correlation between the process control monitors (PCM) and our test data taken from the lab. Process control monitors are random data points on the wafer that gives us information on wafer oxidation thickness, capacitance values, leakage values and so on that are distributed to us from the manufacturer. I'll use different statistical methods such as Bi-Serial Point Methods, Linear Regression and the use of histograms for example. If I find something of high correlation between the PCM data our test data, I'll dive deeper and analyze it. The whole point of this is to predict wafer yield based on a PCM data range and lab collected test data.\n\nLastly, we use machine learning models to predict our next lot's yield based off the high correlation PCM data/test data. I am new to building machine learning models and machine learning as a whole, but I've enjoyed this process so much I'm thinking about getting a Masters in either Machine Learning, Applied Data Science or something along those lines.\n\n**The libraries and packages I use are:** Python, NumPy, Pandas, Matplotlib, Pytorch, Keras, SciPy, Scikit learn and not an exhaustive list.\n\nI may be looking for a new job soon if I am switched into another role in the company that I don't want to do, which I wont get into here.\n\nAnyway, if I wanted to dive deeper into this type of role or job, what job title should search for?\n\nThanks all", "author_fullname": "t2_1ra6klf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152k2qc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689642897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work as an R&amp;amp;D Test  Engineer in the Microelectronics industry and I&amp;#39;m looking for a title of  some type of Software/Data engineering position to search for.&lt;/p&gt;\n\n&lt;p&gt;A little bit of background -- my current role is to process all of our data taken from our test equipment while characterizing our integrated  circuits during on-wafer probe testing. I manipulate all of our test  data into usable format where I then plot the information according to internal/external customers wants and needs.&lt;/p&gt;\n\n&lt;p&gt;From here, I normalize all of our test data taken from the lab and import everything through a data pipeline via the libraries and packages below. Next, I try to find a correlation between the process control monitors (PCM) and our test data taken from the lab. Process control monitors are random data points on the wafer that gives us information on wafer oxidation thickness, capacitance values, leakage values and so on that are distributed to us from the manufacturer. I&amp;#39;ll use different statistical methods such as Bi-Serial Point Methods, Linear Regression and the use of histograms for example. If I find something of high correlation between the PCM data our test data, I&amp;#39;ll dive deeper and analyze it. The whole point of this is to predict wafer yield based on a PCM data range and lab collected test data.&lt;/p&gt;\n\n&lt;p&gt;Lastly, we use machine learning models to predict our next lot&amp;#39;s yield based off the high correlation PCM data/test data. I am new to building machine learning models and machine learning as a whole, but I&amp;#39;ve enjoyed this process so much I&amp;#39;m thinking about getting a Masters in either Machine Learning, Applied Data Science or something along those lines.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The libraries and packages I use are:&lt;/strong&gt; Python, NumPy, Pandas, Matplotlib, Pytorch, Keras, SciPy, Scikit learn and not an exhaustive list.&lt;/p&gt;\n\n&lt;p&gt;I may be looking for a new job soon if I am switched into another role in the company that I don&amp;#39;t want to do, which I wont get into here.&lt;/p&gt;\n\n&lt;p&gt;Anyway, if I wanted to dive deeper into this type of role or job, what job title should search for?&lt;/p&gt;\n\n&lt;p&gt;Thanks all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152k2qc", "is_robot_indexable": true, "report_reasons": null, "author": "Upgrayyedd43", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152k2qc/job_title/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152k2qc/job_title/", "subreddit_subscribers": 116575, "created_utc": 1689642897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking of building such a tool that can\n\n\\- Aggregate all pipeline status on one page\n\n\\- Manage notifications for different systems\n\n\\- Unify incident reports\n\nI did some research only to find a 3 yo post. [https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline\\_monitoring\\_tool/](https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/)\n\nI'm wondering if there's existing tools doing this / if not, anyone has the need?", "author_fullname": "t2_6mmm3ywiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unified pipeline monitoring tool / all-in-one pipeline status page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152cldb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689624752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking of building such a tool that can&lt;/p&gt;\n\n&lt;p&gt;- Aggregate all pipeline status on one page&lt;/p&gt;\n\n&lt;p&gt;- Manage notifications for different systems&lt;/p&gt;\n\n&lt;p&gt;- Unify incident reports&lt;/p&gt;\n\n&lt;p&gt;I did some research only to find a 3 yo post. &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/\"&gt;https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if there&amp;#39;s existing tools doing this / if not, anyone has the need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152cldb", "is_robot_indexable": true, "report_reasons": null, "author": "WEI3M", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "subreddit_subscribers": 116575, "created_utc": 1689624752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9uiwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you really need exactly-once delivery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15270yt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nwqg-bA9yKtkh-5nBchWxMPm0l24EuljbLUBOPM3qYc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689612063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "streamingdata.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?auto=webp&amp;s=04d6977076f8d968368d6533d4d93bcc4e03f4d3", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=febf87d18ab938c89253d5e7d0697e337bf0e88e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c37da59f1936c995870386de473bad9a4a0c1260", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a059a8e1f66d01ae2eb0b0a1b4572e8187739f1a", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e139e12aa841bac14920bb64d92f70324e0d70d0", "width": 640, "height": 333}], "variants": {}, "id": "TL5zSeeNMw6fBGF0Ca693DL1GL7baDPqZ8ZyarYmuos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15270yt", "is_robot_indexable": true, "report_reasons": null, "author": "sap1enz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15270yt/do_you_really_need_exactlyonce_delivery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "subreddit_subscribers": 116575, "created_utc": 1689612063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a [retrieval-augmented generation](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html) use case (a.k.a. chat with your data).\n\n&amp;#x200B;\n\nMy current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like [https://www.chaindesk.ai/](https://www.chaindesk.ai/) but they feel a bit too limiting for my use case.", "author_fullname": "t2_2s6nwgck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move semi-structured data to LLMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1526j16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689610913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a &lt;a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html\"&gt;retrieval-augmented generation&lt;/a&gt; use case (a.k.a. chat with your data).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like &lt;a href=\"https://www.chaindesk.ai/\"&gt;https://www.chaindesk.ai/&lt;/a&gt; but they feel a bit too limiting for my use case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1526j16", "is_robot_indexable": true, "report_reasons": null, "author": "shrifbot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "subreddit_subscribers": 116575, "created_utc": 1689610913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse - event data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1525pib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689609082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1525pib", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525pib/lakehouse_event_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1525pib/lakehouse_event_data/", "subreddit_subscribers": 116575, "created_utc": 1689609082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I am really sorry if this is the wrong thread to ask. Is there a chance to work on US from EU? I see your salaries and they are just 2-5 times bigger that same positions in EU. If it\u2019s possible, what are chances to get the job for DE with 2 years of experience? Or these opportunities only for senior positions?\n\nThank you a lot for your help colleagues.", "author_fullname": "t2_b1ud1vk1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working from EU on US", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152y6r5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689686076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I am really sorry if this is the wrong thread to ask. Is there a chance to work on US from EU? I see your salaries and they are just 2-5 times bigger that same positions in EU. If it\u2019s possible, what are chances to get the job for DE with 2 years of experience? Or these opportunities only for senior positions?&lt;/p&gt;\n\n&lt;p&gt;Thank you a lot for your help colleagues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152y6r5", "is_robot_indexable": true, "report_reasons": null, "author": "AdClean1116", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152y6r5/working_from_eu_on_us/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152y6r5/working_from_eu_on_us/", "subreddit_subscribers": 116575, "created_utc": 1689686076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are working on setting up our databricks environment and are struggling with the pattern to implement the medallion architecture. \n\nWe currently have: catalog.schema.table as project.medallion\\_layer.table and are wondering if this is the way to go? \n\nWe have our environments split into two workspaces for dev and prod, I don't know if it makes sense to have bronze, silver, gold in each workspace? But also want to give different types of users levels of control. \n\nLittle lost and databricks doesn't seem to actually have any documentation on medallion implementation.", "author_fullname": "t2_81ywblydd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to actually implement medallion layers in databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152xzcv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689685542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are working on setting up our databricks environment and are struggling with the pattern to implement the medallion architecture. &lt;/p&gt;\n\n&lt;p&gt;We currently have: catalog.schema.table as project.medallion_layer.table and are wondering if this is the way to go? &lt;/p&gt;\n\n&lt;p&gt;We have our environments split into two workspaces for dev and prod, I don&amp;#39;t know if it makes sense to have bronze, silver, gold in each workspace? But also want to give different types of users levels of control. &lt;/p&gt;\n\n&lt;p&gt;Little lost and databricks doesn&amp;#39;t seem to actually have any documentation on medallion implementation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152xzcv", "is_robot_indexable": true, "report_reasons": null, "author": "DataDoyle", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152xzcv/how_to_actually_implement_medallion_layers_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152xzcv/how_to_actually_implement_medallion_layers_in/", "subreddit_subscribers": 116575, "created_utc": 1689685542.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}