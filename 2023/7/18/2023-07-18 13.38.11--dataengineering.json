{"kind": "Listing", "data": {"after": "t3_152d4j2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a big tech company as a new grad and my title is technically data engineer, however much of my work is building distributed Python applications for ML and data replication, spark, Java, devops pipelines and infrastructure automation (ansible). If I write sql, it\u2019s always within a Python application and is nothing more than an insert, table creation or simple select query. With my experience, would I be more suited to go into software engineer roles moving forward? Scared of applying to companies that use modern data stack or no-code tools and I am stuck having to re-learn SQL or failing an interview.\n\nEdit: I\u2019d consider myself average at SQL, I\u2019ve passed all-SQL interviews, just worried about my skills atrophying as it\u2019s not something I really enjoy to use and my role doesn\u2019t require it", "author_fullname": "t2_7szv7c66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am a new grad \u201cdata engineer\u201d who barely writes SQL, how will my career be impacted?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152own3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689657321.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689656717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a big tech company as a new grad and my title is technically data engineer, however much of my work is building distributed Python applications for ML and data replication, spark, Java, devops pipelines and infrastructure automation (ansible). If I write sql, it\u2019s always within a Python application and is nothing more than an insert, table creation or simple select query. With my experience, would I be more suited to go into software engineer roles moving forward? Scared of applying to companies that use modern data stack or no-code tools and I am stuck having to re-learn SQL or failing an interview.&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019d consider myself average at SQL, I\u2019ve passed all-SQL interviews, just worried about my skills atrophying as it\u2019s not something I really enjoy to use and my role doesn\u2019t require it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152own3", "is_robot_indexable": true, "report_reasons": null, "author": "aacreans", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152own3/i_am_a_new_grad_data_engineer_who_barely_writes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152own3/i_am_a_new_grad_data_engineer_who_barely_writes/", "subreddit_subscribers": 116551, "created_utc": 1689656717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to data engineering, and I like to learn by trying/building. I am very unclear what's the best way to go about it?\n\nMy ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?", "author_fullname": "t2_17d42esw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best \"free\" set-up to learn or try to build a data pipeline on my own?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152c49r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689623684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to data engineering, and I like to learn by trying/building. I am very unclear what&amp;#39;s the best way to go about it?&lt;/p&gt;\n\n&lt;p&gt;My ultimate goal is to be able to build my own website with a data pipeline in the backend and front end with data analytics visualization etc. Should I go directly with free cloud resources (like AWS), or should I try to manage a local data pipeline such as postgresql, and once I hit the bottleneck, I migrate to better scaling solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152c49r", "is_robot_indexable": true, "report_reasons": null, "author": "Guyserbun007", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152c49r/whats_the_best_free_setup_to_learn_or_try_to/", "subreddit_subscribers": 116551, "created_utc": 1689623684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?", "author_fullname": "t2_c532a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What steps to take after first role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1524trd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689607060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally got a role as a Senior Data Engineer after having a background of SQL and taking about 6 months to learn Python. I\u2019ve been here almost a year and my days are spent building pipelines using Pandas. My team though is an analytics team and I am the only data engineer on it, so I\u2019m kind of just learning on my own and doing the same tasks repeatedly. While I have plenty more to learn about Python, I am starting to wonder what other steps I should be taking to move into the next salary bracket. I\u2019m around 120k now and don\u2019t think I have the skill set to move into the 180+ range yet at all, but my team isn\u2019t giving me a ton in terms of project variety so I\u2019m not sure what would be the most effective tool/language/software to spend time learning on my own time. I like my current company but even when they ask me what my goals are/what I want to be doing I\u2019m not sure exactly what to tell them. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1524trd", "is_robot_indexable": true, "report_reasons": null, "author": "gators939", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1524trd/what_steps_to_take_after_first_role/", "subreddit_subscribers": 116551, "created_utc": 1689607060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would like to find some questions practicing for DE interview. I mostly use leetcode to practice DSA, and leetcode have multiple tags like 'array', 'binary tree' when I want to practice specific topics.\n\nHowever, there seems no similar tag for SQL problems on leetcode. I believe SQL have various type of questions, and I want to practice specific topics (join, aggregation, window function...etc) not wondering around and look at all kinds of problems.\n\nIs there any website that may have specific topics to practice SQL questions?  \nOr more specifically, SQL practicing websites for DE interview?  \n\n\nThanks a lot!", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there SQL questions practice website with specific topics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15226ql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689600967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to find some questions practicing for DE interview. I mostly use leetcode to practice DSA, and leetcode have multiple tags like &amp;#39;array&amp;#39;, &amp;#39;binary tree&amp;#39; when I want to practice specific topics.&lt;/p&gt;\n\n&lt;p&gt;However, there seems no similar tag for SQL problems on leetcode. I believe SQL have various type of questions, and I want to practice specific topics (join, aggregation, window function...etc) not wondering around and look at all kinds of problems.&lt;/p&gt;\n\n&lt;p&gt;Is there any website that may have specific topics to practice SQL questions?&lt;br/&gt;\nOr more specifically, SQL practicing websites for DE interview?  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15226ql", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15226ql/is_there_sql_questions_practice_website_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15226ql/is_there_sql_questions_practice_website_with/", "subreddit_subscribers": 116551, "created_utc": 1689600967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4t6cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM based pipelines with PostgresML and dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_1525yyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z3TI0arYlw4RRR3jUUbPUO2vA2egarxlpp1dP09FXtE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689609669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "postgresml.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?auto=webp&amp;s=0b690342c0b9264e580cd8629721f878d18ff954", "width": 784, "height": 519}, "resolutions": [{"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf6a365fbb7793932f29fbb28fa434d479b46d55", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0effd2b3a0537c8131fd28109ff37439457f1ddc", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d160cb4efab6957e3d11789882fe0b658cafe87e", "width": 320, "height": 211}, {"url": "https://external-preview.redd.it/Vamle0jyoCqbpucDv6rCTJz2Q_30l_0Gm1ZtE0ziDxI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e154f104eedac0bc7c9e36c987df586978c19eb0", "width": 640, "height": 423}], "variants": {}, "id": "dxDnyB5RtYkyN-bX3C7E2eUqvQzE9_-FZU6xkZ1aDRQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1525yyl", "is_robot_indexable": true, "report_reasons": null, "author": "something_cleverer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525yyl/llm_based_pipelines_with_postgresml_and_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://postgresml.org/blog/llm-based-pipelines-with-postgresml-and-dbt", "subreddit_subscribers": 116551, "created_utc": 1689609669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I study 15 hours a day 7 days a week trying to make my dream a reality. ETL, ELT, coding, learning Python, SQL, reading entire chapters of data engineering books and outlining them on paper and then on the computer to make sure it sticks... Then there are people here asking and basically bragging about having a data engineer position where they do literally nothing. No actual data engineering, maybe some light leg work or job responsibilities, and some minor SQL. \n\n\nWhat I want to know is how. How are people getting these? Where do I get one?", "author_fullname": "t2_vnan4h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are people getting into data engineering with basically no responsibilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152w0h7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689680210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I study 15 hours a day 7 days a week trying to make my dream a reality. ETL, ELT, coding, learning Python, SQL, reading entire chapters of data engineering books and outlining them on paper and then on the computer to make sure it sticks... Then there are people here asking and basically bragging about having a data engineer position where they do literally nothing. No actual data engineering, maybe some light leg work or job responsibilities, and some minor SQL. &lt;/p&gt;\n\n&lt;p&gt;What I want to know is how. How are people getting these? Where do I get one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152w0h7", "is_robot_indexable": true, "report_reasons": null, "author": "Analyst2163", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152w0h7/how_are_people_getting_into_data_engineering_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152w0h7/how_are_people_getting_into_data_engineering_with/", "subreddit_subscribers": 116551, "created_utc": 1689680210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nI'm exploring the transition into a data role as the next phase of my career. Uncovering data engineering concepts and architectures make my juices flow again after a few years of stagnation in my current infrastructure solution architect role. Data science and analysis isn't my bag, I'm focused on the engineering track.\n\nMy background: I've worked in public and private cloud (primarily Azure infrastructure and micro-services) and data management (primarily protection and disaster recovery) for c. 13 years, the last 5 at a senior architect level. \n\nI've seen a few posts on 'transitioning' roles and currently looking through the wiki to understand skillsets but would loveto hear from those who have experienced a similar transition from cloud solution architect into a data role. \n\n I'm working my way through DP-203 and I envisage the most difficult aspects will include coding. However, that's something I'll just have to work on.\n\nDid you work from a data engineering starting point up to data architect? Did you face any significant hurdles or were there any skills that you found invaluable in your journey?", "author_fullname": "t2_a0k3gzpb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition from cloud architect into data role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152rnc1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689665871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m exploring the transition into a data role as the next phase of my career. Uncovering data engineering concepts and architectures make my juices flow again after a few years of stagnation in my current infrastructure solution architect role. Data science and analysis isn&amp;#39;t my bag, I&amp;#39;m focused on the engineering track.&lt;/p&gt;\n\n&lt;p&gt;My background: I&amp;#39;ve worked in public and private cloud (primarily Azure infrastructure and micro-services) and data management (primarily protection and disaster recovery) for c. 13 years, the last 5 at a senior architect level. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a few posts on &amp;#39;transitioning&amp;#39; roles and currently looking through the wiki to understand skillsets but would loveto hear from those who have experienced a similar transition from cloud solution architect into a data role. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working my way through DP-203 and I envisage the most difficult aspects will include coding. However, that&amp;#39;s something I&amp;#39;ll just have to work on.&lt;/p&gt;\n\n&lt;p&gt;Did you work from a data engineering starting point up to data architect? Did you face any significant hurdles or were there any skills that you found invaluable in your journey?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152rnc1", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Figure88", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rnc1/transition_from_cloud_architect_into_data_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152rnc1/transition_from_cloud_architect_into_data_role/", "subreddit_subscribers": 116551, "created_utc": 1689665871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I need some output regarding this situation.  \nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post \"submit\", as soon as that happens, the job needs to be submitted!  \nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can't really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?  \nLove to know your thoughts!  \nThanks", "author_fullname": "t2_xqvyn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink Batch Job needs to run based on a trigger", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152m3hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689648465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I need some output regarding this situation.&lt;br/&gt;\nI have a flink batch job that needs to run based on a trigger. By trigger I meant suppose there is a FASTAPI endpoint exposed for clients to post &amp;quot;submit&amp;quot;, as soon as that happens, the job needs to be submitted!&lt;br/&gt;\nWe are using Flink-Kubernetes-Operator and its on Session Cluster mode. I can&amp;#39;t really use cron, because the its aperiodic as you can see. What will be the flink way to achieve this? Has anyone solved this kind of use cases? If so how?&lt;br/&gt;\nLove to know your thoughts!&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152m3hr", "is_robot_indexable": true, "report_reasons": null, "author": "Salekeen01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152m3hr/flink_batch_job_needs_to_run_based_on_a_trigger/", "subreddit_subscribers": 116551, "created_utc": 1689648465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:\n\n* bucket\n   * tbl\\_1\n      * data1.csv\n      * data2.csv\n   * tbl\\_2\n      * data1.csv\n      * data2.csv\n\nI'm successfully creating a streaming live table for both tbl\\_1 and tbl\\_2 by invoking autoloader, using the `@dlt.table` decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. \n\nThe problem I'm facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I'm only able to query the data if and only if it was loaded in the previous run of the dlt workflow.", "author_fullname": "t2_789pafin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding how Delta Live Tables (DLT) and Unity Catalog work in tandem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152k8kp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689643337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of trialing DLT on AWS and have a pipeline setup to pull data from an s3 bucket. The source bucket is setup such that top level folders will effectively be the landing zone for incoming data. Each folder is named according to its source table, and is used to name the streaming live tables within DLT. something like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;bucket\n\n&lt;ul&gt;\n&lt;li&gt;tbl_1\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;tbl_2\n\n&lt;ul&gt;\n&lt;li&gt;data1.csv&lt;/li&gt;\n&lt;li&gt;data2.csv&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m successfully creating a streaming live table for both tbl_1 and tbl_2 by invoking autoloader, using the &lt;code&gt;@dlt.table&lt;/code&gt; decorators, and everything loads as needed and is accessible thru the unity catalog when executed within a delta live tables workflow. &lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m facing is that in testing, deleting all of the source data under a table, running the pipeline will de-register the table previously created from the unity catalog, and it will be un-queryable - the folder for the bucket i setup for unity catalog still holds the data, but it is no longer available to be queried or even seen in the data browser from within databricks. Am I doing something wrong or not understand how this should be working? It seems I&amp;#39;m only able to query the data if and only if it was loaded in the previous run of the dlt workflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152k8kp", "is_robot_indexable": true, "report_reasons": null, "author": "_nudist_buddhist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152k8kp/understanding_how_delta_live_tables_dlt_and_unity/", "subreddit_subscribers": 116551, "created_utc": 1689643337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working for less than a year in a small IT services company as a data analyst. I'm the only one working in the data field, so I'm totally autonomous.  My job is pretty straightforward and basic: I create dashboards on Power Bi using data from the company's activities, such as accounting or human resources. The data is stored in SQL server databases on local servers.\n\nHere's my workflow, I create sql views in order to extract and process as much of the upstream data as possible directly in sql server and then import it into power bi. Thanks to a data gateway I've been able to automate the updating of the data on the dashboards that are put online. There is no real complexity or intelligence in this process and looking at this reddit every day I wondered if my practice was correct and optimal in my case or if I could optimise it with ETLs or tools/services like Databricks dbt ect.\n\nSorry for my poor English or if what I'm writing doesn't make much sense, I'm still a data science student with poor knowledge in data engineering.", "author_fullname": "t2_txt0cja7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a student data analyst in apprenticeship, what can I do to improve the data exploitation process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152xs6i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689685051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working for less than a year in a small IT services company as a data analyst. I&amp;#39;m the only one working in the data field, so I&amp;#39;m totally autonomous.  My job is pretty straightforward and basic: I create dashboards on Power Bi using data from the company&amp;#39;s activities, such as accounting or human resources. The data is stored in SQL server databases on local servers.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my workflow, I create sql views in order to extract and process as much of the upstream data as possible directly in sql server and then import it into power bi. Thanks to a data gateway I&amp;#39;ve been able to automate the updating of the data on the dashboards that are put online. There is no real complexity or intelligence in this process and looking at this reddit every day I wondered if my practice was correct and optimal in my case or if I could optimise it with ETLs or tools/services like Databricks dbt ect.&lt;/p&gt;\n\n&lt;p&gt;Sorry for my poor English or if what I&amp;#39;m writing doesn&amp;#39;t make much sense, I&amp;#39;m still a data science student with poor knowledge in data engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152xs6i", "is_robot_indexable": true, "report_reasons": null, "author": "Zuzukxd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152xs6i/as_a_student_data_analyst_in_apprenticeship_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152xs6i/as_a_student_data_analyst_in_apprenticeship_what/", "subreddit_subscribers": 116551, "created_utc": 1689685051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Max Kremer outlines real-time data streaming with Debezium and Postgres. Gone through the process before? What has your experience been?\n\n[https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/](https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/)\n\n&amp;#x200B;", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time data streaming with Debezium and Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_152ws1a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689682327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Max Kremer outlines real-time data streaming with Debezium and Postgres. Gone through the process before? What has your experience been?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/\"&gt;https://lassoo.io/blog/2023/07/17/postgres-real-time-data-streaming-debezium/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?auto=webp&amp;s=c5f5a655d6864f84f08160aa3ecc6a483e366b29", "width": 2254, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77f04efc85875721aab74a0dbed87aab2166568f", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6660b3bca381afe6691fd6377052115955289b27", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15461ccea7f16f0c86fe0838ac84029482fac910", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e98a3a8fc7d6d3e1d17432c50f2e3090f4edc6e1", "width": 640, "height": 425}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=13795e652ab765a44ab68d9a18848a95426810a4", "width": 960, "height": 638}, {"url": "https://external-preview.redd.it/xUo1q_1Kso26VozzUkD9eTjWSB2wSW1WmwRlfRS9czc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5da9553f31250276789472e811efd60331226597", "width": 1080, "height": 718}], "variants": {}, "id": "yOcCqb_01Tcein84ljsq1UI3XyPdtH-HzgATv4P1fwg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152ws1a", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152ws1a/realtime_data_streaming_with_debezium_and_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152ws1a/realtime_data_streaming_with_debezium_and_postgres/", "subreddit_subscribers": 116551, "created_utc": 1689682327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c8yil9sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unleashing the power of Data: Choosing the right Storage System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_152rbb9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IIv1_fPx7mpWttOq-Jz014OPcljRrJWfbtz0MaJy0OY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689664709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "waruithemystery.hashnode.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://waruithemystery.hashnode.dev/unleashing-the-power-of-data-choosing-the-right-storage-system", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?auto=webp&amp;s=76f5feabe1088e5a7e933f706d45b03c187041a4", "width": 1200, "height": 840}, "resolutions": [{"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04e6f81d17d408d5974273992d6d90d263e8df1c", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bdad375d47b17d15ac4f0aaef826d4ed177f7506", "width": 216, "height": 151}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec45ff075400efbd48e383d3f4181f961972ee60", "width": 320, "height": 224}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4cd3a4b29aa434f12207cc6e12d887b97fe385ef", "width": 640, "height": 448}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=099ac6fd14571e30d1b1e578f8e77d563ed48493", "width": 960, "height": 672}, {"url": "https://external-preview.redd.it/04_CA6EFhW3XZTRWjoLRFNF7MAEFZHjUMJ7BK2B-33c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39e11829a7eaae13f171f3fd5685dfe26fab5322", "width": 1080, "height": 756}], "variants": {}, "id": "VAuaOqHlidZveGyq3PdjODh479ysn4eoBTpoDQbWSDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "152rbb9", "is_robot_indexable": true, "report_reasons": null, "author": "RemarkableAttempt311", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rbb9/unleashing_the_power_of_data_choosing_the_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://waruithemystery.hashnode.dev/unleashing-the-power-of-data-choosing-the-right-storage-system", "subreddit_subscribers": 116551, "created_utc": 1689664709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I browsed through the community posts and understood that [neetcode.io](https://neetcode.io) is by far the best and the most recommended platform for practising Python for DE interviews.\n\nI work as a Data Engineer at a small startup right now, but never in my life I have done LeetCode or even touched DSA, hence requesting for help here.\n\nIn the [neetcode.io](https://neetcode.io) platform, in the practice section, if we sort by group, the questions are grouped by topic so that you can tackle them accordingly.\n\nBased on your interview experience, can you please help me prioritise the topics? I am guessing many of these topics are for SDE interviews and not all might be relevant to DE interviews, and even if they are relevant, some must be more important than others.\n\nThe topics are:\n\n1. Arrays and Hashing\n2. Two Pointers\n3. Sliding Window\n4. Stack\n5. Binary Search\n6. Linked List\n7. Trees\n8. Tries\n9. Heap / Priority Queue\n10. Backtracking\n11. Graphs\n12. Advanced Graphs\n13. 1-D dynamic programming\n14. 2-D dynamic programming\n15. Greedy\n16. Intervals\n17. Math &amp; Geometry\n18. Bit Manipulation\n\nThe reasons I have to prioritise/filter this is because I have limited time left in the interview prep hence want the important things 1st, and also because I am not specifically targeting MAANG.\n\n&amp;#x200B;\n\nThank you for the help!!", "author_fullname": "t2_cu6910tv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview preparation help - Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152ny8o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689653788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I browsed through the community posts and understood that &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; is by far the best and the most recommended platform for practising Python for DE interviews.&lt;/p&gt;\n\n&lt;p&gt;I work as a Data Engineer at a small startup right now, but never in my life I have done LeetCode or even touched DSA, hence requesting for help here.&lt;/p&gt;\n\n&lt;p&gt;In the &lt;a href=\"https://neetcode.io\"&gt;neetcode.io&lt;/a&gt; platform, in the practice section, if we sort by group, the questions are grouped by topic so that you can tackle them accordingly.&lt;/p&gt;\n\n&lt;p&gt;Based on your interview experience, can you please help me prioritise the topics? I am guessing many of these topics are for SDE interviews and not all might be relevant to DE interviews, and even if they are relevant, some must be more important than others.&lt;/p&gt;\n\n&lt;p&gt;The topics are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Arrays and Hashing&lt;/li&gt;\n&lt;li&gt;Two Pointers&lt;/li&gt;\n&lt;li&gt;Sliding Window&lt;/li&gt;\n&lt;li&gt;Stack&lt;/li&gt;\n&lt;li&gt;Binary Search&lt;/li&gt;\n&lt;li&gt;Linked List&lt;/li&gt;\n&lt;li&gt;Trees&lt;/li&gt;\n&lt;li&gt;Tries&lt;/li&gt;\n&lt;li&gt;Heap / Priority Queue&lt;/li&gt;\n&lt;li&gt;Backtracking&lt;/li&gt;\n&lt;li&gt;Graphs&lt;/li&gt;\n&lt;li&gt;Advanced Graphs&lt;/li&gt;\n&lt;li&gt;1-D dynamic programming&lt;/li&gt;\n&lt;li&gt;2-D dynamic programming&lt;/li&gt;\n&lt;li&gt;Greedy&lt;/li&gt;\n&lt;li&gt;Intervals&lt;/li&gt;\n&lt;li&gt;Math &amp;amp; Geometry&lt;/li&gt;\n&lt;li&gt;Bit Manipulation&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The reasons I have to prioritise/filter this is because I have limited time left in the interview prep hence want the important things 1st, and also because I am not specifically targeting MAANG.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for the help!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "152ny8o", "is_robot_indexable": true, "report_reasons": null, "author": "table_data", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152ny8o/interview_preparation_help_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152ny8o/interview_preparation_help_python/", "subreddit_subscribers": 116551, "created_utc": 1689653788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious about how well the open source self-hosted version works, and how it compares feature-wise to the cloud version. Thanks!", "author_fullname": "t2_brgtw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have experience self-hosting Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152lvk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689647841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious about how well the open source self-hosted version works, and how it compares feature-wise to the cloud version. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152lvk5", "is_robot_indexable": true, "report_reasons": null, "author": "kdamica", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152lvk5/does_anyone_have_experience_selfhosting_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152lvk5/does_anyone_have_experience_selfhosting_airbyte/", "subreddit_subscribers": 116551, "created_utc": 1689647841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work as an R&amp;D Test  Engineer in the Microelectronics industry and I'm looking for a title of  some type of Software/Data engineering position to search for.\n\nA little bit of background -- my current role is to process all of our data taken from our test equipment while characterizing our integrated  circuits during on-wafer probe testing. I manipulate all of our test  data into usable format where I then plot the information according to internal/external customers wants and needs.\n\nFrom here, I normalize all of our test data taken from the lab and import everything through a data pipeline via the libraries and packages below. Next, I try to find a correlation between the process control monitors (PCM) and our test data taken from the lab. Process control monitors are random data points on the wafer that gives us information on wafer oxidation thickness, capacitance values, leakage values and so on that are distributed to us from the manufacturer. I'll use different statistical methods such as Bi-Serial Point Methods, Linear Regression and the use of histograms for example. If I find something of high correlation between the PCM data our test data, I'll dive deeper and analyze it. The whole point of this is to predict wafer yield based on a PCM data range and lab collected test data.\n\nLastly, we use machine learning models to predict our next lot's yield based off the high correlation PCM data/test data. I am new to building machine learning models and machine learning as a whole, but I've enjoyed this process so much I'm thinking about getting a Masters in either Machine Learning, Applied Data Science or something along those lines.\n\n**The libraries and packages I use are:** Python, NumPy, Pandas, Matplotlib, Pytorch, Keras, SciPy, Scikit learn and not an exhaustive list.\n\nI may be looking for a new job soon if I am switched into another role in the company that I don't want to do, which I wont get into here.\n\nAnyway, if I wanted to dive deeper into this type of role or job, what job title should search for?\n\nThanks all", "author_fullname": "t2_1ra6klf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152k2qc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689642897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work as an R&amp;amp;D Test  Engineer in the Microelectronics industry and I&amp;#39;m looking for a title of  some type of Software/Data engineering position to search for.&lt;/p&gt;\n\n&lt;p&gt;A little bit of background -- my current role is to process all of our data taken from our test equipment while characterizing our integrated  circuits during on-wafer probe testing. I manipulate all of our test  data into usable format where I then plot the information according to internal/external customers wants and needs.&lt;/p&gt;\n\n&lt;p&gt;From here, I normalize all of our test data taken from the lab and import everything through a data pipeline via the libraries and packages below. Next, I try to find a correlation between the process control monitors (PCM) and our test data taken from the lab. Process control monitors are random data points on the wafer that gives us information on wafer oxidation thickness, capacitance values, leakage values and so on that are distributed to us from the manufacturer. I&amp;#39;ll use different statistical methods such as Bi-Serial Point Methods, Linear Regression and the use of histograms for example. If I find something of high correlation between the PCM data our test data, I&amp;#39;ll dive deeper and analyze it. The whole point of this is to predict wafer yield based on a PCM data range and lab collected test data.&lt;/p&gt;\n\n&lt;p&gt;Lastly, we use machine learning models to predict our next lot&amp;#39;s yield based off the high correlation PCM data/test data. I am new to building machine learning models and machine learning as a whole, but I&amp;#39;ve enjoyed this process so much I&amp;#39;m thinking about getting a Masters in either Machine Learning, Applied Data Science or something along those lines.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The libraries and packages I use are:&lt;/strong&gt; Python, NumPy, Pandas, Matplotlib, Pytorch, Keras, SciPy, Scikit learn and not an exhaustive list.&lt;/p&gt;\n\n&lt;p&gt;I may be looking for a new job soon if I am switched into another role in the company that I don&amp;#39;t want to do, which I wont get into here.&lt;/p&gt;\n\n&lt;p&gt;Anyway, if I wanted to dive deeper into this type of role or job, what job title should search for?&lt;/p&gt;\n\n&lt;p&gt;Thanks all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152k2qc", "is_robot_indexable": true, "report_reasons": null, "author": "Upgrayyedd43", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152k2qc/job_title/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152k2qc/job_title/", "subreddit_subscribers": 116551, "created_utc": 1689642897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking of building such a tool that can\n\n\\- Aggregate all pipeline status on one page\n\n\\- Manage notifications for different systems\n\n\\- Unify incident reports\n\nI did some research only to find a 3 yo post. [https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline\\_monitoring\\_tool/](https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/)\n\nI'm wondering if there's existing tools doing this / if not, anyone has the need?", "author_fullname": "t2_6mmm3ywiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unified pipeline monitoring tool / all-in-one pipeline status page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152cldb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689624752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking of building such a tool that can&lt;/p&gt;\n\n&lt;p&gt;- Aggregate all pipeline status on one page&lt;/p&gt;\n\n&lt;p&gt;- Manage notifications for different systems&lt;/p&gt;\n\n&lt;p&gt;- Unify incident reports&lt;/p&gt;\n\n&lt;p&gt;I did some research only to find a 3 yo post. &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/\"&gt;https://www.reddit.com/r/dataengineering/comments/jkzxfy/pipeline_monitoring_tool/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if there&amp;#39;s existing tools doing this / if not, anyone has the need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152cldb", "is_robot_indexable": true, "report_reasons": null, "author": "WEI3M", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152cldb/unified_pipeline_monitoring_tool_allinone/", "subreddit_subscribers": 116551, "created_utc": 1689624752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9uiwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you really need exactly-once delivery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15270yt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nwqg-bA9yKtkh-5nBchWxMPm0l24EuljbLUBOPM3qYc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689612063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "streamingdata.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?auto=webp&amp;s=04d6977076f8d968368d6533d4d93bcc4e03f4d3", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=febf87d18ab938c89253d5e7d0697e337bf0e88e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c37da59f1936c995870386de473bad9a4a0c1260", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a059a8e1f66d01ae2eb0b0a1b4572e8187739f1a", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e139e12aa841bac14920bb64d92f70324e0d70d0", "width": 640, "height": 333}], "variants": {}, "id": "TL5zSeeNMw6fBGF0Ca693DL1GL7baDPqZ8ZyarYmuos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15270yt", "is_robot_indexable": true, "report_reasons": null, "author": "sap1enz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15270yt/do_you_really_need_exactlyonce_delivery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://streamingdata.substack.com/p/do-you-really-need-exactly-once-delivery", "subreddit_subscribers": 116551, "created_utc": 1689612063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a [retrieval-augmented generation](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html) use case (a.k.a. chat with your data).\n\n&amp;#x200B;\n\nMy current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like [https://www.chaindesk.ai/](https://www.chaindesk.ai/) but they feel a bit too limiting for my use case.", "author_fullname": "t2_2s6nwgck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move semi-structured data to LLMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1526j16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689610913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tinkering with setting up a data pipeline to make a bunch of semi-structured sources in my org (documentation website, github issues, slack messages, \u2026) useful in a &lt;a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html\"&gt;retrieval-augmented generation&lt;/a&gt; use case (a.k.a. chat with your data).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My current approach of gluing together python clients for APIs of various services (openai for embeddings, pinecone for the vector db) feels kind of clunky, are there \u201cproper\u201d ways of handling that? I\u2019ve looked into e2e solutions like &lt;a href=\"https://www.chaindesk.ai/\"&gt;https://www.chaindesk.ai/&lt;/a&gt; but they feel a bit too limiting for my use case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1526j16", "is_robot_indexable": true, "report_reasons": null, "author": "shrifbot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1526j16/how_to_move_semistructured_data_to_llms/", "subreddit_subscribers": 116551, "created_utc": 1689610913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse - event data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1525pib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689609082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is event data supposed to be handled in the lakehouse architecture? It is not efficient to save lots of small events into the object storage so maybe I save them into some relational database first and then create a parquet dump or something like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1525pib", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1525pib/lakehouse_event_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1525pib/lakehouse_event_data/", "subreddit_subscribers": 116551, "created_utc": 1689609082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/152rgcu)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data lakehouse table format does your team plan to use by the end of 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152rgcu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689665188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/152rgcu\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "152rgcu", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1690269988727, "options": [{"text": "Delta Lake", "id": "23941798"}, {"text": "Iceberg", "id": "23941799"}, {"text": "Hudi", "id": "23941800"}, {"text": "Hive", "id": "23941801"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 67, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152rgcu/what_data_lakehouse_table_format_does_your_team/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/152rgcu/what_data_lakehouse_table_format_does_your_team/", "subreddit_subscribers": 116551, "created_utc": 1689665188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bjg5ils96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not able to import bacpac files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1527uzc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Dh76q4CwJ1SwBvLTA5RKMdR6EwYsGVSToIYMeI51cbg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689613964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/6uixe56s5kcb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?auto=webp&amp;s=8f45aeb19cdac07b77aab83bcad493c06602fcca", "width": 1170, "height": 1507}, "resolutions": [{"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c7fddd296c024f9cc353830f149646145fd6506", "width": 108, "height": 139}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2fca7e3564f79bfe9d184d9e02734adfe7391b2", "width": 216, "height": 278}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99e838e6735aed7f783edd82c6d3475bbcb88e66", "width": 320, "height": 412}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0a7d0ed4822daaa7f6e3904d371d9da830fed104", "width": 640, "height": 824}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=70fd648c800e959184a369600afc9df1c58b8d70", "width": 960, "height": 1236}, {"url": "https://preview.redd.it/6uixe56s5kcb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77ff354d6f918e3477f9db4463a754a9d09dbf22", "width": 1080, "height": 1391}], "variants": {}, "id": "BITAYyr-5eJpEGr2vz0o2pzOZo9Rhxgw06bDn2nRxFc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1527uzc", "is_robot_indexable": true, "report_reasons": null, "author": "Ecstatic-Cat-5830", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1527uzc/not_able_to_import_bacpac_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/6uixe56s5kcb1.jpg", "subreddit_subscribers": 116551, "created_utc": 1689613964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a bachelor\u2019s degree in aerospace engineering and I\u2019ve been working as a Data Engineer for 2 years.\n\nI\u2019m interested in pursuing a master\u2019s degree in AI or data science, but I don\u2019t want to quit my job or relocate. I\u2019ve been looking at some online programs that offer part-time options, but I\u2019m not sure if they are worth the time and money.\n\nWhat are the pros and cons of doing a part-time online master\u2019s degree in AI or data science?\n\nHow will it affect my career prospects and salary potential?\n\nIs a full time program valued more?\n\nI would appreciate any advice or insights from people who have done or are doing a part-time online master\u2019s degree in AI or data science. Thanks!", "author_fullname": "t2_8d81fo99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Considering doing a part time online masters in Data Science or AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1525dkl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689608331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bachelor\u2019s degree in aerospace engineering and I\u2019ve been working as a Data Engineer for 2 years.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m interested in pursuing a master\u2019s degree in AI or data science, but I don\u2019t want to quit my job or relocate. I\u2019ve been looking at some online programs that offer part-time options, but I\u2019m not sure if they are worth the time and money.&lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of doing a part-time online master\u2019s degree in AI or data science?&lt;/p&gt;\n\n&lt;p&gt;How will it affect my career prospects and salary potential?&lt;/p&gt;\n\n&lt;p&gt;Is a full time program valued more?&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any advice or insights from people who have done or are doing a part-time online master\u2019s degree in AI or data science. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1525dkl", "is_robot_indexable": true, "report_reasons": null, "author": "LaidbackLuke77", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1525dkl/considering_doing_a_part_time_online_masters_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1525dkl/considering_doing_a_part_time_online_masters_in/", "subreddit_subscribers": 116551, "created_utc": 1689608331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear all members,\n\nIt is with heavy heart I'm writing this to anyone who could be of any help. I wrote a few days ago on this platform for some guidance and everyone was super helpful.  \nI think my company would start cost cutting, and I really need to earn some money and since it's my beginning of my career I have to make sure to have a plan B.  \n\n\nNow I request you everyone if anyone could help me learn Web Scraping or something else through which I can start earning part-time and also want to learn other data engineering stuff so that even if something goes wrong, I could be well equipped to get another job.  \n\n\nOr maybe I'm probably overthinking all this.", "author_fullname": "t2_3k9gevl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn web scraping as a side hustle.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1523rjk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689604686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all members,&lt;/p&gt;\n\n&lt;p&gt;It is with heavy heart I&amp;#39;m writing this to anyone who could be of any help. I wrote a few days ago on this platform for some guidance and everyone was super helpful.&lt;br/&gt;\nI think my company would start cost cutting, and I really need to earn some money and since it&amp;#39;s my beginning of my career I have to make sure to have a plan B.  &lt;/p&gt;\n\n&lt;p&gt;Now I request you everyone if anyone could help me learn Web Scraping or something else through which I can start earning part-time and also want to learn other data engineering stuff so that even if something goes wrong, I could be well equipped to get another job.  &lt;/p&gt;\n\n&lt;p&gt;Or maybe I&amp;#39;m probably overthinking all this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1523rjk", "is_robot_indexable": true, "report_reasons": null, "author": "Pillstyr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1523rjk/learn_web_scraping_as_a_side_hustle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1523rjk/learn_web_scraping_as_a_side_hustle/", "subreddit_subscribers": 116551, "created_utc": 1689604686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any additional advice, tips, or personal experiences you can share would be immensely helpful in my career journey. I am eager to grow professionally and enhance my skills in these exciting fields. ", "author_fullname": "t2_ckp9vdid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Securing Data Engineering, Data Science, or Data Analysis Jobs as a Fresh Graduate Based in Asia, Preferably with Overseas Opportunities and Dollar-Based Compensation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152qsh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689663007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any additional advice, tips, or personal experiences you can share would be immensely helpful in my career journey. I am eager to grow professionally and enhance my skills in these exciting fields. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "152qsh4", "is_robot_indexable": true, "report_reasons": null, "author": "Informal-Actuary8833", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152qsh4/seeking_advice_on_securing_data_engineering_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152qsh4/seeking_advice_on_securing_data_engineering_data/", "subreddit_subscribers": 116551, "created_utc": 1689663007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm one of the co-founders of Vertis.\n\nIn my previous role as a data engineer, I saw the daily challenges our analytics teams were facing in orchestrating, deploying and monitoring SQL pipelines.\n\nMost existing tools have a steep learning curve and often require ongoing engineering support. That's why we built Vertis. Our solution allows you to orchestrate SQL pipelines in a simple, intuitive way - all without any extra configuration, no special syntax to learn, and no infrastructure to manage.\n\nVertis offers an all-in-one platform, with features such as:\n\nGitHub Integration, logging and alerting, interactive dependency graph, and more!\n\nYou can learn more about Vertis and request early access here: [https://www.vertis.app](https://www.vertis.app/)\n\nWe're excited to share Vertis with you today, and we would appreciate your thoughts and feedback. I'll be here to answer any questions you might have.", "author_fullname": "t2_33shg0e8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The simplest way to orchestrate SQL data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_152d4j2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689625944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m one of the co-founders of Vertis.&lt;/p&gt;\n\n&lt;p&gt;In my previous role as a data engineer, I saw the daily challenges our analytics teams were facing in orchestrating, deploying and monitoring SQL pipelines.&lt;/p&gt;\n\n&lt;p&gt;Most existing tools have a steep learning curve and often require ongoing engineering support. That&amp;#39;s why we built Vertis. Our solution allows you to orchestrate SQL pipelines in a simple, intuitive way - all without any extra configuration, no special syntax to learn, and no infrastructure to manage.&lt;/p&gt;\n\n&lt;p&gt;Vertis offers an all-in-one platform, with features such as:&lt;/p&gt;\n\n&lt;p&gt;GitHub Integration, logging and alerting, interactive dependency graph, and more!&lt;/p&gt;\n\n&lt;p&gt;You can learn more about Vertis and request early access here: &lt;a href=\"https://www.vertis.app/\"&gt;https://www.vertis.app&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re excited to share Vertis with you today, and we would appreciate your thoughts and feedback. I&amp;#39;ll be here to answer any questions you might have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "152d4j2", "is_robot_indexable": true, "report_reasons": null, "author": "WildShallot", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/152d4j2/the_simplest_way_to_orchestrate_sql_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/152d4j2/the_simplest_way_to_orchestrate_sql_data_pipelines/", "subreddit_subscribers": 116551, "created_utc": 1689625944.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}