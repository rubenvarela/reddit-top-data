{"kind": "Listing", "data": {"after": "t3_155wros", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I mean I'm paid well, and do work that the company finds valuable. I just put so much time, effort, and sacrifice into getting my degrees and qualifications that it just feels kind of hollow that the only way in which they prepared me to get this job was to show my employer that I'm smart. Literally a high school drop out could probably pick up SQL in a few days, enough corporate background in another few days that they'd be able to do my job in a week.\n\nI've had one or two opportunities to actually do something a little deeper than SQL dashboards and management always quashes it. They want descriptive results quickly, they don't want to wait for a full analysis. They've begun using the descriptive metrics in a predictive way, and I told then multiple times that you need to build models to actually predict things with data. They don't want to hear it. Management tells me to visualize x, y, and z, fine I can do that. But then they start asking me what a \"good\" x, y, and z look like - well I can't do that without actually evaluating them somehow. After a few months I kinda just gave up and told them what they wanted to hear. Sooner or later they're gonna find out using these arbitrary metrics to predict things is about as helpful as throwing darts at a map.\n\nThe sad part is I've lost so many of my skills, too. I was struggling to fit a linear regression model in R and evaluate it the other day, just due to the fact I haven't done that in like 5 years. It makes me worry about what's going to happen if I need to find another job. Even if I don't, even if I can work this job till I retire I just wish I was doing something that I actually needed my DS background to do.\n\nEDIT:\n\nthanks everyone who's commented. I noticed some recurring themes here, which were helpful. First off is looking for a new job - yes, that's always an option, and it will always be an option no matter how much of a job I get is a dream job. But, I think I've got a few more options before jumping ship, and before throwing away the knowledge of the product and domain out the window, I think they're worth a shot. Plus, like you all said, if this is the case with most \"DS\" jobs then I risk ending up in the same boat.\n\nAlmost every time I proposed an actual DS solution, it was shot down. That got me thinking, that like a lot of you said, it's better to ask forgiveness than permission. I think I've identified a problem I could bring some ML tools to bear on, and I think I can demonstrate that it's gonna be miles ahead of the descriptive metric based analysis we're doing now. Because they don't know I'm working on it, I won't have management up my ass requesting I simplify it to get it out sooner. I can take as long as I want on it, show off the final, finished product and make a strong case for doing more of this type of stuff. Downplay the amount of time I spent on it (because most of that time will be brushing up on DS skills). The culture here is open minded enough that this should go over well. Of course the challenge will be to explain why this is so much better without making it look like the descriptive metrics are dog shit (which, to be fair, they work reasonably well for now, but at some point they're gonna stop working)", "author_fullname": "t2_abi7jpkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My \"Data Scientist\" position is really just a glorified SQL monkey and I'm losing my DS skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1550t9y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 518, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 518, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689964558.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689881666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mean I&amp;#39;m paid well, and do work that the company finds valuable. I just put so much time, effort, and sacrifice into getting my degrees and qualifications that it just feels kind of hollow that the only way in which they prepared me to get this job was to show my employer that I&amp;#39;m smart. Literally a high school drop out could probably pick up SQL in a few days, enough corporate background in another few days that they&amp;#39;d be able to do my job in a week.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had one or two opportunities to actually do something a little deeper than SQL dashboards and management always quashes it. They want descriptive results quickly, they don&amp;#39;t want to wait for a full analysis. They&amp;#39;ve begun using the descriptive metrics in a predictive way, and I told then multiple times that you need to build models to actually predict things with data. They don&amp;#39;t want to hear it. Management tells me to visualize x, y, and z, fine I can do that. But then they start asking me what a &amp;quot;good&amp;quot; x, y, and z look like - well I can&amp;#39;t do that without actually evaluating them somehow. After a few months I kinda just gave up and told them what they wanted to hear. Sooner or later they&amp;#39;re gonna find out using these arbitrary metrics to predict things is about as helpful as throwing darts at a map.&lt;/p&gt;\n\n&lt;p&gt;The sad part is I&amp;#39;ve lost so many of my skills, too. I was struggling to fit a linear regression model in R and evaluate it the other day, just due to the fact I haven&amp;#39;t done that in like 5 years. It makes me worry about what&amp;#39;s going to happen if I need to find another job. Even if I don&amp;#39;t, even if I can work this job till I retire I just wish I was doing something that I actually needed my DS background to do.&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;thanks everyone who&amp;#39;s commented. I noticed some recurring themes here, which were helpful. First off is looking for a new job - yes, that&amp;#39;s always an option, and it will always be an option no matter how much of a job I get is a dream job. But, I think I&amp;#39;ve got a few more options before jumping ship, and before throwing away the knowledge of the product and domain out the window, I think they&amp;#39;re worth a shot. Plus, like you all said, if this is the case with most &amp;quot;DS&amp;quot; jobs then I risk ending up in the same boat.&lt;/p&gt;\n\n&lt;p&gt;Almost every time I proposed an actual DS solution, it was shot down. That got me thinking, that like a lot of you said, it&amp;#39;s better to ask forgiveness than permission. I think I&amp;#39;ve identified a problem I could bring some ML tools to bear on, and I think I can demonstrate that it&amp;#39;s gonna be miles ahead of the descriptive metric based analysis we&amp;#39;re doing now. Because they don&amp;#39;t know I&amp;#39;m working on it, I won&amp;#39;t have management up my ass requesting I simplify it to get it out sooner. I can take as long as I want on it, show off the final, finished product and make a strong case for doing more of this type of stuff. Downplay the amount of time I spent on it (because most of that time will be brushing up on DS skills). The culture here is open minded enough that this should go over well. Of course the challenge will be to explain why this is so much better without making it look like the descriptive metrics are dog shit (which, to be fair, they work reasonably well for now, but at some point they&amp;#39;re gonna stop working)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1550t9y", "is_robot_indexable": true, "report_reasons": null, "author": "sn_uv_tv_f", "discussion_type": null, "num_comments": 120, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1550t9y/my_data_scientist_position_is_really_just_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1550t9y/my_data_scientist_position_is_really_just_a/", "subreddit_subscribers": 955810, "created_utc": 1689881666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have a boss that apparently used to do technical work once but it was a long time ago. He now constantly has completely unrealistic expectations of what data science can do. Whenever I propose a realistic project, he is not interested as it doesn't \"move the needle\" and is not \"revolutionary\".  He always wants \"technical excellence\" and \"thought leadership\", yet hires inexperienced people and doesn't pay them much.\n\nSo he over-promises on my behalf constantly. For example, I have experience in causal inference. So he would say wow let's find the cause of all mortgage defaults! Causal inference is more vague then that, takes a long, long time, often leads to no concrete results. If I tell him that, then he says \"it's useless\". He also thinks of projects such as \"everything needs to happen in real-time, data from all sources is integrated, external with internal\" etc etc. Just complete lack of pragmatism and no clue about timelines. He is also super unhappy if I correct him.\n\nHe is also into AI doom, how it will lead to human extinction and so on. \n\nI am a people pleaser and find it difficult to set boundaries. I often agree to look into things that I already know are impossible. Any tips on dealing with this?", "author_fullname": "t2_ekbfo234c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with a boss that has inflated, unrealistic expectations of data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155crtu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689912083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a boss that apparently used to do technical work once but it was a long time ago. He now constantly has completely unrealistic expectations of what data science can do. Whenever I propose a realistic project, he is not interested as it doesn&amp;#39;t &amp;quot;move the needle&amp;quot; and is not &amp;quot;revolutionary&amp;quot;.  He always wants &amp;quot;technical excellence&amp;quot; and &amp;quot;thought leadership&amp;quot;, yet hires inexperienced people and doesn&amp;#39;t pay them much.&lt;/p&gt;\n\n&lt;p&gt;So he over-promises on my behalf constantly. For example, I have experience in causal inference. So he would say wow let&amp;#39;s find the cause of all mortgage defaults! Causal inference is more vague then that, takes a long, long time, often leads to no concrete results. If I tell him that, then he says &amp;quot;it&amp;#39;s useless&amp;quot;. He also thinks of projects such as &amp;quot;everything needs to happen in real-time, data from all sources is integrated, external with internal&amp;quot; etc etc. Just complete lack of pragmatism and no clue about timelines. He is also super unhappy if I correct him.&lt;/p&gt;\n\n&lt;p&gt;He is also into AI doom, how it will lead to human extinction and so on. &lt;/p&gt;\n\n&lt;p&gt;I am a people pleaser and find it difficult to set boundaries. I often agree to look into things that I already know are impossible. Any tips on dealing with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155crtu", "is_robot_indexable": true, "report_reasons": null, "author": "Ashamed-Tie6059", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155crtu/how_do_you_deal_with_a_boss_that_has_inflated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155crtu/how_do_you_deal_with_a_boss_that_has_inflated/", "subreddit_subscribers": 955810, "created_utc": 1689912083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_13ikgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "asking a friend who is a data engineer how can i automate some of my reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_155pvxf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jf6im0xoZnuCUkO1TgEr-7Zh1JX1I8SRh_06i1XVMpg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689950361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/m2762utuxbdb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/m2762utuxbdb1.png?auto=webp&amp;s=8e5a2379b22a7de445b7cf5018c7235075dec9e0", "width": 918, "height": 500}, "resolutions": [{"url": "https://preview.redd.it/m2762utuxbdb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d90346f4bc9d21893a0c30bda14120bbb184b86", "width": 108, "height": 58}, {"url": "https://preview.redd.it/m2762utuxbdb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=78fd9d2ce6ba3702cf9d68ef56eb1e0ececb9ff8", "width": 216, "height": 117}, {"url": "https://preview.redd.it/m2762utuxbdb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e26556a963a07fd57c3a948446c02c9fdb899a0", "width": 320, "height": 174}, {"url": "https://preview.redd.it/m2762utuxbdb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7fac981c5a835e4b8e6a7570f8aa3d24413cc36c", "width": 640, "height": 348}], "variants": {}, "id": "n5_YEgLHPlnnNWi53pPE9SFegvgFxZbKqJU0zRk9Mro"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "155pvxf", "is_robot_indexable": true, "report_reasons": null, "author": "Amr-Ahmed", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155pvxf/asking_a_friend_who_is_a_data_engineer_how_can_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/m2762utuxbdb1.png", "subreddit_subscribers": 955810, "created_utc": 1689950361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is just a rant I guess. I\u2019ve been looking at quite a lot of job openings for Data Scientist positions, for some reasons they all appear to be so different. Here are the three main types I\u2019ve seen:\n\n**1. The ML researcher**\nDescription: \n- Develop some magical AI that solves all our business problems using all sorts of buzzwords we hear in the news\n- Develop LLMs that has nothing to do with the business\n- There are cavern walls in Africa with cravings by Neanderthals containing cleaner data than the database\n\nRequirements: \n- 2 PhDs\n- Published 7 first author papers in top journals\n- Won 5 Kaggle competitions simultaneously with one model\n\n**2. The ML engineer**\nDescription: \n- Literally everything from data eng to MLOps to cloud infra, except actual data science\n- \u201cEnd-to-end ML pipeline\u201d\n- If you use a for loop with pandas data frame, they will bring you to the back alley and shoot you in the head\n\nRequirements: \n- Solve hard leetcode question blindfolded with one arm behind your back\n- Need to know 17 ways to accomplish the exact same thing using AWS/GCP\n- Need to know 5 different databases we don\u2019t even use\n\n**3. The mislabelled data analyst**\nDescription: \n- Nothing but making dashboards\n- Use statistics but not too much that it gives our execs imposter syndrome\n- ML, but it\u2019s logistic regression on Excel\n\nRequirements: \n- Tableau etc\n- Telepathic ability to magically make business people understand basic statistics concepts \n- Willing to be called incompetent by exec when your analysis shows the source of all business problems stemmed from poor management by said exec\n\nI\u2019m sure I\u2019ve missed out some others, and I\u2019ve also seen roles that expects you to do all three. How do people even find jobs when the entire job landscape is so confusing?", "author_fullname": "t2_2kh4l8ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are DS job descriptions so\u2026diverse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155jr9n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689934309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is just a rant I guess. I\u2019ve been looking at quite a lot of job openings for Data Scientist positions, for some reasons they all appear to be so different. Here are the three main types I\u2019ve seen:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1. The ML researcher&lt;/strong&gt;\nDescription: \n- Develop some magical AI that solves all our business problems using all sorts of buzzwords we hear in the news\n- Develop LLMs that has nothing to do with the business\n- There are cavern walls in Africa with cravings by Neanderthals containing cleaner data than the database&lt;/p&gt;\n\n&lt;p&gt;Requirements: \n- 2 PhDs\n- Published 7 first author papers in top journals\n- Won 5 Kaggle competitions simultaneously with one model&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2. The ML engineer&lt;/strong&gt;\nDescription: \n- Literally everything from data eng to MLOps to cloud infra, except actual data science\n- \u201cEnd-to-end ML pipeline\u201d\n- If you use a for loop with pandas data frame, they will bring you to the back alley and shoot you in the head&lt;/p&gt;\n\n&lt;p&gt;Requirements: \n- Solve hard leetcode question blindfolded with one arm behind your back\n- Need to know 17 ways to accomplish the exact same thing using AWS/GCP\n- Need to know 5 different databases we don\u2019t even use&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;3. The mislabelled data analyst&lt;/strong&gt;\nDescription: \n- Nothing but making dashboards\n- Use statistics but not too much that it gives our execs imposter syndrome\n- ML, but it\u2019s logistic regression on Excel&lt;/p&gt;\n\n&lt;p&gt;Requirements: \n- Tableau etc\n- Telepathic ability to magically make business people understand basic statistics concepts \n- Willing to be called incompetent by exec when your analysis shows the source of all business problems stemmed from poor management by said exec&lt;/p&gt;\n\n&lt;p&gt;I\u2019m sure I\u2019ve missed out some others, and I\u2019ve also seen roles that expects you to do all three. How do people even find jobs when the entire job landscape is so confusing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155jr9n", "is_robot_indexable": true, "report_reasons": null, "author": "supper_ham", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155jr9n/why_are_ds_job_descriptions_sodiverse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155jr9n/why_are_ds_job_descriptions_sodiverse/", "subreddit_subscribers": 955810, "created_utc": 1689934309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A lot of posts and people talking about being laid off or unemployed anywhere from 2 months to 8 months. I have been unemployed for 30 days after being laid off as senior data analyst. I was a powerhouse on my previous team. Using crazy advanced SQL, pumping out Tableau dashboards weekly, Even going so far as to do exploratory data analysis with Python, piping data from databases into BigQuery. I was a little bit of everything. Data analysts, data scientist, data engineer. \n\n\n\nI cannot find anything. Literally nothing. I have connected with recruiters, analysts, managers, data scientists on LinkedIn. I use AI to help me write compelling and friendly introductions to people asking if they have anything in their department or within their company available. I am tapping the hell out of every single aspect, every nook and cranny. Applying for every single position I possibly can. I have cleaned up my resume at least a dozen times now to make it as expert and professional looking as possible. Followed all the tips from ex-Googlers about putting percentages, dollar amounts, impact of every single bullet point.... Nothing. Literally nothing. I got one interview coming up next week for a regular business analyst role That isn't even focused in analytics, not a data analyst, not data scientist, not data engineer, just a generic analyst. That was the best I could get, and that's not even guaranteed to get me the job.  \n\n\n**To be clear, the issue is not that I am not good at what I do. I study and practice python SQL analytics data science crap 40 hours a week**. \n\n\nSome people don't realize how bad this job market is, and how much worse it's going to get once AI starts being expanded. I'm not saying that AI is going to replace all people and wipe out everyone's jobs, like I'm not into that whole doom and gloom kind of thing. But I don't see the job market getting any better in the USA. There is no way. Employers are hell-bent on cutting costs and maximizing profits, and when infinite profitability is the goal, it will never end. It'll just keep going and going and going and going and going and going and going infinitely to the Sun, then the next universe over.", "author_fullname": "t2_vnan4h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The job market is extremely bad right now. When is it going to get better?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155s4st", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689955539.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689955310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A lot of posts and people talking about being laid off or unemployed anywhere from 2 months to 8 months. I have been unemployed for 30 days after being laid off as senior data analyst. I was a powerhouse on my previous team. Using crazy advanced SQL, pumping out Tableau dashboards weekly, Even going so far as to do exploratory data analysis with Python, piping data from databases into BigQuery. I was a little bit of everything. Data analysts, data scientist, data engineer. &lt;/p&gt;\n\n&lt;p&gt;I cannot find anything. Literally nothing. I have connected with recruiters, analysts, managers, data scientists on LinkedIn. I use AI to help me write compelling and friendly introductions to people asking if they have anything in their department or within their company available. I am tapping the hell out of every single aspect, every nook and cranny. Applying for every single position I possibly can. I have cleaned up my resume at least a dozen times now to make it as expert and professional looking as possible. Followed all the tips from ex-Googlers about putting percentages, dollar amounts, impact of every single bullet point.... Nothing. Literally nothing. I got one interview coming up next week for a regular business analyst role That isn&amp;#39;t even focused in analytics, not a data analyst, not data scientist, not data engineer, just a generic analyst. That was the best I could get, and that&amp;#39;s not even guaranteed to get me the job.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;To be clear, the issue is not that I am not good at what I do. I study and practice python SQL analytics data science crap 40 hours a week&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;Some people don&amp;#39;t realize how bad this job market is, and how much worse it&amp;#39;s going to get once AI starts being expanded. I&amp;#39;m not saying that AI is going to replace all people and wipe out everyone&amp;#39;s jobs, like I&amp;#39;m not into that whole doom and gloom kind of thing. But I don&amp;#39;t see the job market getting any better in the USA. There is no way. Employers are hell-bent on cutting costs and maximizing profits, and when infinite profitability is the goal, it will never end. It&amp;#39;ll just keep going and going and going and going and going and going and going infinitely to the Sun, then the next universe over.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155s4st", "is_robot_indexable": true, "report_reasons": null, "author": "Analyst2163", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155s4st/the_job_market_is_extremely_bad_right_now_when_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155s4st/the_job_market_is_extremely_bad_right_now_when_is/", "subreddit_subscribers": 955810, "created_utc": 1689955310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got fired today from a data entry position at a biotech research company for performance issues after 2 months into the job. My company was very fast paced and my manager caught signs of me being slow since I started working there and was constantly signaling me out in personal teams meetings. I have ADHD so it's a lot harder for me to learn as quickly as other people, especially if it's within a few months. I was making some data entry mistakes as someone new would commit, but was not within the margin of error that they wanted me to work within. Because of this, I now feel insecure about pursuing data science.\n\nI'm doing excellent in my masters program and I have a 4.0 but this experience has me distraught tbh.", "author_fullname": "t2_2avd4wfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got fired from a data entry position 2 months in and I'm having second thoughts about whether or not to continue a career pathway in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1555p8t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689892830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got fired today from a data entry position at a biotech research company for performance issues after 2 months into the job. My company was very fast paced and my manager caught signs of me being slow since I started working there and was constantly signaling me out in personal teams meetings. I have ADHD so it&amp;#39;s a lot harder for me to learn as quickly as other people, especially if it&amp;#39;s within a few months. I was making some data entry mistakes as someone new would commit, but was not within the margin of error that they wanted me to work within. Because of this, I now feel insecure about pursuing data science.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m doing excellent in my masters program and I have a 4.0 but this experience has me distraught tbh.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1555p8t", "is_robot_indexable": true, "report_reasons": null, "author": "Javilism", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1555p8t/i_got_fired_from_a_data_entry_position_2_months/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1555p8t/i_got_fired_from_a_data_entry_position_2_months/", "subreddit_subscribers": 955810, "created_utc": 1689892830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m wondering how common take home data science projects are when your interviewing and should you always do them? \n\nI\u2019ve gotten three different 1 week long take home projects (out of the 5 companies I\u2019ve interviewed at so far). The projects all require data cleaning and fitting a model. One project had several messy data files with no column descriptions at all. \n\nAnother company sent me a 90 minute assessment before even talking to me (have no communication with an actual person). So it seems like they sent this assessment to tons of people. It also covered probability, coding and personal questions. I know statistics well but didn\u2019t realize I would need to have refreshed on some formulas). \n\nI\u2019m swamped with projects that may not even lead to jobs. Is this normal?", "author_fullname": "t2_bkxkz9yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take home assessments during Interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1557wv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689901660.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689898259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m wondering how common take home data science projects are when your interviewing and should you always do them? &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve gotten three different 1 week long take home projects (out of the 5 companies I\u2019ve interviewed at so far). The projects all require data cleaning and fitting a model. One project had several messy data files with no column descriptions at all. &lt;/p&gt;\n\n&lt;p&gt;Another company sent me a 90 minute assessment before even talking to me (have no communication with an actual person). So it seems like they sent this assessment to tons of people. It also covered probability, coding and personal questions. I know statistics well but didn\u2019t realize I would need to have refreshed on some formulas). &lt;/p&gt;\n\n&lt;p&gt;I\u2019m swamped with projects that may not even lead to jobs. Is this normal?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1557wv5", "is_robot_indexable": true, "report_reasons": null, "author": "Responsible_South640", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1557wv5/take_home_assessments_during_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1557wv5/take_home_assessments_during_interviews/", "subreddit_subscribers": 955810, "created_utc": 1689898259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_17e0bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone a Data Scientist in the Mining industry? What insights or industry-specifics tips can you give us!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155nzgg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689945904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155nzgg", "is_robot_indexable": true, "report_reasons": null, "author": "ayeitsdeano", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155nzgg/is_anyone_a_data_scientist_in_the_mining_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155nzgg/is_anyone_a_data_scientist_in_the_mining_industry/", "subreddit_subscribers": 955810, "created_utc": 1689945904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Same as what seems to be the rest of this subreddit, I've been laid off a couple of months ago and the rejection emails and ghosting are getting to my head - I know, me and all the other unfortunate souls.\n\nI like to think my CV is pretty good, but of course, there's always room for improvement. Sure, the CV may not be the cause at all, it's the job market being flooded atm with thousands of people with millennia of data science experience, data science not being the core of most businesses' operations,  global warming, whatever. I'm sure there are still people out there getting hired as Data Scientists every single day and I think I'm ready to get off the \"bad job market\" copium.\n\nPlease rip my CV apart like you're the CTO of a tech startup who is behind on his 2021 Audi A5 instalments and a recruiter sent you this CV for the Data Science position you want filled by a senior-level dude but you'll only pay him a low-mid data science salary as long as they're down for hybrid on-site 4.5 days/week (AND PIZZA FRIDAYS!). Also, 350 people applied for this job of yours in the first 8 hours of you posting it on LinkedIn.\n\nSeriously though, I'll take all the tough love I can get - format, content, ATS readability, bs detector. Thanks\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/f131kurr2ddb1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=0d51b6b04ec424641671a9e1b3a0165873b686ca", "author_fullname": "t2_ewtjr5j3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rip my 2 y.o.e. Data Scientist CV apart", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"f131kurr2ddb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 151, "x": 108, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=858ac1eef7ae53cf9d72efb4ee950b50c30c912e"}, {"y": 303, "x": 216, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=63be016b98e164e6324c266610e034803ea42f4a"}, {"y": 449, "x": 320, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=91fa78d4645067a0256716c6e53a42b47eb6fa35"}, {"y": 899, "x": 640, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a69955ced14e1bba4e5a693e2fb2da47efd63a1c"}, {"y": 1348, "x": 960, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b2ccaed55f14fc907365e0e1b1dffb1447fb91ab"}, {"y": 1517, "x": 1080, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bbaed0a4339b531289883cd3d293633cadad208f"}], "s": {"y": 2262, "x": 1610, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=0d51b6b04ec424641671a9e1b3a0165873b686ca"}, "id": "f131kurr2ddb1"}}, "name": "t3_155vz86", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YlxZ_BYm70NKGd3OZbyoBUFRDlosB8mUoga4qjI1L-c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689964028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Same as what seems to be the rest of this subreddit, I&amp;#39;ve been laid off a couple of months ago and the rejection emails and ghosting are getting to my head - I know, me and all the other unfortunate souls.&lt;/p&gt;\n\n&lt;p&gt;I like to think my CV is pretty good, but of course, there&amp;#39;s always room for improvement. Sure, the CV may not be the cause at all, it&amp;#39;s the job market being flooded atm with thousands of people with millennia of data science experience, data science not being the core of most businesses&amp;#39; operations,  global warming, whatever. I&amp;#39;m sure there are still people out there getting hired as Data Scientists every single day and I think I&amp;#39;m ready to get off the &amp;quot;bad job market&amp;quot; copium.&lt;/p&gt;\n\n&lt;p&gt;Please rip my CV apart like you&amp;#39;re the CTO of a tech startup who is behind on his 2021 Audi A5 instalments and a recruiter sent you this CV for the Data Science position you want filled by a senior-level dude but you&amp;#39;ll only pay him a low-mid data science salary as long as they&amp;#39;re down for hybrid on-site 4.5 days/week (AND PIZZA FRIDAYS!). Also, 350 people applied for this job of yours in the first 8 hours of you posting it on LinkedIn.&lt;/p&gt;\n\n&lt;p&gt;Seriously though, I&amp;#39;ll take all the tough love I can get - format, content, ATS readability, bs detector. Thanks&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/f131kurr2ddb1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d51b6b04ec424641671a9e1b3a0165873b686ca\"&gt;https://preview.redd.it/f131kurr2ddb1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d51b6b04ec424641671a9e1b3a0165873b686ca&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155vz86", "is_robot_indexable": true, "report_reasons": null, "author": "iulianghg", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155vz86/rip_my_2_yoe_data_scientist_cv_apart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155vz86/rip_my_2_yoe_data_scientist_cv_apart/", "subreddit_subscribers": 955810, "created_utc": 1689964028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Guys, I have started learning Data Science on my own. I bought 3 courses on Udemy and am going through the lessons in order.\n\nI have a Bachelor's degree in Mechanical Engineering, but I realized late that I have a heart for Data Science, because in the future I want to work with artificial intelligence, develop new software based on AI. Maybe even create my own SaaS.\n\nMy strategy is as follows:\n1. Take all 3 courses\n2. Start creating simple projects and upload them to GitHub\n3. Gradually build a portfolio\n4. Search for a job\n\nIMPORTANT: Guys, how realistic is it for a self-taught Data Science student to find a job. I am very afraid that I will have to go to university again. Is it possible to learn everything myself or will the job necessarily require a diploma?\n\nMoreover, I appeal to experienced Data Scientists, guys advise me how best to develop in this field. Imagine if you were asked the question \"How would you start your way if you had to start all over again?...\".\n\nThat's all for now, I'd be honored for everyone's response. Any opinion is valuable to me, I respect each of you very much. You've done well.", "author_fullname": "t2_eiqw1xpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guys, I\u2019m completely beginner in Data Science. I need to hear opinion from experienced Data Scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155swu8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689957029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys, I have started learning Data Science on my own. I bought 3 courses on Udemy and am going through the lessons in order.&lt;/p&gt;\n\n&lt;p&gt;I have a Bachelor&amp;#39;s degree in Mechanical Engineering, but I realized late that I have a heart for Data Science, because in the future I want to work with artificial intelligence, develop new software based on AI. Maybe even create my own SaaS.&lt;/p&gt;\n\n&lt;p&gt;My strategy is as follows:\n1. Take all 3 courses\n2. Start creating simple projects and upload them to GitHub\n3. Gradually build a portfolio\n4. Search for a job&lt;/p&gt;\n\n&lt;p&gt;IMPORTANT: Guys, how realistic is it for a self-taught Data Science student to find a job. I am very afraid that I will have to go to university again. Is it possible to learn everything myself or will the job necessarily require a diploma?&lt;/p&gt;\n\n&lt;p&gt;Moreover, I appeal to experienced Data Scientists, guys advise me how best to develop in this field. Imagine if you were asked the question &amp;quot;How would you start your way if you had to start all over again?...&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s all for now, I&amp;#39;d be honored for everyone&amp;#39;s response. Any opinion is valuable to me, I respect each of you very much. You&amp;#39;ve done well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155swu8", "is_robot_indexable": true, "report_reasons": null, "author": "Brave_Cup9196", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155swu8/guys_im_completely_beginner_in_data_science_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155swu8/guys_im_completely_beginner_in_data_science_i/", "subreddit_subscribers": 955810, "created_utc": 1689957029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just started a new position at a company so far they have been creating the dashboard from scratch with react. They are looking to create custom charts, tables, and graphs for the sales teams and managers. Was wondering if it is better to use an external tool to develop these?", "author_fullname": "t2_130676", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it better to create an internal tool for data analysis or use an external tool such as power bi or tableau?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155rgon", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689953836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just started a new position at a company so far they have been creating the dashboard from scratch with react. They are looking to create custom charts, tables, and graphs for the sales teams and managers. Was wondering if it is better to use an external tool to develop these?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155rgon", "is_robot_indexable": true, "report_reasons": null, "author": "A_GOLD_FISH", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155rgon/is_it_better_to_create_an_internal_tool_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155rgon/is_it_better_to_create_an_internal_tool_for_data/", "subreddit_subscribers": 955810, "created_utc": 1689953836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am going to begin an internship for a small company who don't have a data science department. We are the first ones to be working on their data. (They are not paying us)\n\n They are going to provide us with the data of students and basically we have to analyze it, it's basically an list of potential candidates who are willing to go for foreign education. I have no idea where to begin.\n\nNow I know the basics of data science and I have worked on datasets like iris which consists of basic things like flower size and etc. That was completely in python and just had to visualize and analyze the data?\n\nHow should I be preparing for this? It has to be done in excel.", "author_fullname": "t2_fl0rx7lx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to analyze student data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155o4xm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689946883.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689946267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am going to begin an internship for a small company who don&amp;#39;t have a data science department. We are the first ones to be working on their data. (They are not paying us)&lt;/p&gt;\n\n&lt;p&gt;They are going to provide us with the data of students and basically we have to analyze it, it&amp;#39;s basically an list of potential candidates who are willing to go for foreign education. I have no idea where to begin.&lt;/p&gt;\n\n&lt;p&gt;Now I know the basics of data science and I have worked on datasets like iris which consists of basic things like flower size and etc. That was completely in python and just had to visualize and analyze the data?&lt;/p&gt;\n\n&lt;p&gt;How should I be preparing for this? It has to be done in excel.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155o4xm", "is_robot_indexable": true, "report_reasons": null, "author": "stupidlyaccurate", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155o4xm/how_to_analyze_student_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155o4xm/how_to_analyze_student_data/", "subreddit_subscribers": 955810, "created_utc": 1689946267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2lz97iux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some help with accumulation curve", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_155bezu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3MoeX-3Fk0aqD7YVMsUt73EiH8s1xfGsQC3x-GCCryY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689908112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ng4lc1jdg8db1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?auto=webp&amp;s=8df10f15995798dbdcc2d62367c20e21ed1449c6", "width": 1000, "height": 751}, "resolutions": [{"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=64b4286954e782c8ca762ccc813c56d03a50fd97", "width": 108, "height": 81}, {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e47a571e57dfeba96472f8bf67284ad6d0398a8d", "width": 216, "height": 162}, {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=64c81ff4d612ffa4e356c2a28aefc543e934a39e", "width": 320, "height": 240}, {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b992a98645dbd855e1830798add9c91d3b6b3950", "width": 640, "height": 480}, {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=321f2bd15c69c0be52ea98a69011d3fbf235403b", "width": 960, "height": 720}], "variants": {}, "id": "wI2Gr6DzUMdhM9C3K31oI7SrS20yiL87WglYD-jkjV8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "155bezu", "is_robot_indexable": true, "report_reasons": null, "author": "artanos44", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155bezu/need_some_help_with_accumulation_curve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ng4lc1jdg8db1.png", "subreddit_subscribers": 955810, "created_utc": 1689908112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just landed an analytics engineer role (coming from a nursing background)\n\nLooking to get into DS, specifically with machine learning for healthcare.\n\nI have a masters in health informatics however want to continue academics (VA benefits + tuition reimbursement).\n\nAny programs worth looking into? \nI was looking at OMSA and UT Austin DS, UiUC CS.\n\nI applied to MCIT online upenn, however feel it may not be worth the price tag.\n\nTIA", "author_fullname": "t2_m8a5u0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Grad school programs worthwhile for DS and AI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1556f12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689894581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just landed an analytics engineer role (coming from a nursing background)&lt;/p&gt;\n\n&lt;p&gt;Looking to get into DS, specifically with machine learning for healthcare.&lt;/p&gt;\n\n&lt;p&gt;I have a masters in health informatics however want to continue academics (VA benefits + tuition reimbursement).&lt;/p&gt;\n\n&lt;p&gt;Any programs worth looking into? \nI was looking at OMSA and UT Austin DS, UiUC CS.&lt;/p&gt;\n\n&lt;p&gt;I applied to MCIT online upenn, however feel it may not be worth the price tag.&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1556f12", "is_robot_indexable": true, "report_reasons": null, "author": "AwkWORD47", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1556f12/grad_school_programs_worthwhile_for_ds_and_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1556f12/grad_school_programs_worthwhile_for_ds_and_ai/", "subreddit_subscribers": 955810, "created_utc": 1689894581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, hope you all are doing great. I just completed Machine Learning Specialization on Coursera by Andrew Ng and was looking for some advise on what I should do next. Would love to hear input from you guys.\n\nI'm self studying Machine Learning full-time, while I'm also getting a bachelors degree in Computer Science from an online virtual university. It's been 3+ months since I've stepped into Machine Learning and so far I've been developing deep intuition and foundational concepts of Machine Learning . Since I'm really passionate about mathematics, I'm very much focused on understanding the mathematics behind everything.\n\nBy completing this specialization I've developed good foundational concepts of the following:\n\n\u2022 Supervised Machine Learning  \n\u2022 Linear regression  \n\u2022 Logistic regression  \n\u2022 Gradient Descent / Adam Optimizer  \n\u2022 Neural networks  \n\u2022 Bias, variance trade-offs  \n\u2022 Decision trees   \n\u2022 Unsupervised Learning  \n\u2022 Clustering  \n\u2022 Anomaly detection   \n\u2022 Recommenders  \n\u2022 Collaborative filtering  \n\u2022 Content-based filtering  \n\u2022 Reinforcement learning\n\nIn this course I got some exposure to libraries like Tensorflow, numpy, matplotlib, pandas as well.\n\nI've realized that there is so much to learn only about ML models that I can spend so much time only learning these models, but as much as I want to do that, my goal is to get a job or internship or projects that I can start earning from as soon as possible. And with that I can continue on learning and getting deeper into ML and AI. With all that I've learnt so far, Supervised / Unsupevised Learning and Neural Networks seemed to me a good path that I can take to land myself a job because of the high demand. I really wanted to dive deeper into reinforcement learning but it seems that it will make it difficult for me to land a job.\n\nThis course was very much focused on intuition building and the mathematics, but I think that now I need to develop skills and focus much on the development side of things. To get myself familiar and comfortable with the libraries and whatever that is important for development so that I can comfortably apply these models in real life.\n\nShould I get more high-level overview of AI to understand what are other topics apart from ML that I can dive in or should I pick some topic in ML and dive deep into it. I personally am very interested to dive deeper into Neural Networks and Deep Learning.\n\nWould love to get advise from you guys on what I should consider next or any material that you can suggest. Thankyou!", "author_fullname": "t2_hcgjj0xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need career advise on what should I do next in ML :(", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1550giy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689880872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, hope you all are doing great. I just completed Machine Learning Specialization on Coursera by Andrew Ng and was looking for some advise on what I should do next. Would love to hear input from you guys.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m self studying Machine Learning full-time, while I&amp;#39;m also getting a bachelors degree in Computer Science from an online virtual university. It&amp;#39;s been 3+ months since I&amp;#39;ve stepped into Machine Learning and so far I&amp;#39;ve been developing deep intuition and foundational concepts of Machine Learning . Since I&amp;#39;m really passionate about mathematics, I&amp;#39;m very much focused on understanding the mathematics behind everything.&lt;/p&gt;\n\n&lt;p&gt;By completing this specialization I&amp;#39;ve developed good foundational concepts of the following:&lt;/p&gt;\n\n&lt;p&gt;\u2022 Supervised Machine Learning&lt;br/&gt;\n\u2022 Linear regression&lt;br/&gt;\n\u2022 Logistic regression&lt;br/&gt;\n\u2022 Gradient Descent / Adam Optimizer&lt;br/&gt;\n\u2022 Neural networks&lt;br/&gt;\n\u2022 Bias, variance trade-offs&lt;br/&gt;\n\u2022 Decision trees&lt;br/&gt;\n\u2022 Unsupervised Learning&lt;br/&gt;\n\u2022 Clustering&lt;br/&gt;\n\u2022 Anomaly detection&lt;br/&gt;\n\u2022 Recommenders&lt;br/&gt;\n\u2022 Collaborative filtering&lt;br/&gt;\n\u2022 Content-based filtering&lt;br/&gt;\n\u2022 Reinforcement learning&lt;/p&gt;\n\n&lt;p&gt;In this course I got some exposure to libraries like Tensorflow, numpy, matplotlib, pandas as well.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve realized that there is so much to learn only about ML models that I can spend so much time only learning these models, but as much as I want to do that, my goal is to get a job or internship or projects that I can start earning from as soon as possible. And with that I can continue on learning and getting deeper into ML and AI. With all that I&amp;#39;ve learnt so far, Supervised / Unsupevised Learning and Neural Networks seemed to me a good path that I can take to land myself a job because of the high demand. I really wanted to dive deeper into reinforcement learning but it seems that it will make it difficult for me to land a job.&lt;/p&gt;\n\n&lt;p&gt;This course was very much focused on intuition building and the mathematics, but I think that now I need to develop skills and focus much on the development side of things. To get myself familiar and comfortable with the libraries and whatever that is important for development so that I can comfortably apply these models in real life.&lt;/p&gt;\n\n&lt;p&gt;Should I get more high-level overview of AI to understand what are other topics apart from ML that I can dive in or should I pick some topic in ML and dive deep into it. I personally am very interested to dive deeper into Neural Networks and Deep Learning.&lt;/p&gt;\n\n&lt;p&gt;Would love to get advise from you guys on what I should consider next or any material that you can suggest. Thankyou!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1550giy", "is_robot_indexable": true, "report_reasons": null, "author": "Total-Opposite-8396", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1550giy/need_career_advise_on_what_should_i_do_next_in_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1550giy/need_career_advise_on_what_should_i_do_next_in_ml/", "subreddit_subscribers": 955810, "created_utc": 1689880872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://pypi.org/project/plotagain/](https://pypi.org/project/plotagain/)\n\nThe tool provides a simple contextmanager which automatically saves data used to make matplotlib plots and automatically generates a script to reproduce the plots at a later stage.\n\nExample usage:\n\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from plotagain import SavePlotContext\n    \n    x_data = np.linspace(0, 2 * np.pi, 1000)\n    y_data = np.sin(x_data)\n    with SavePlotContext(\"./data-save-dir\", locals(), overwrite=True) as spc:\n        spc.plot(x_data, y_data, c='k', label='sin')\n        spc.plot(x_data, np.cos(x_data), c='b', label='cos')\n        spc.xlabel('xaxis')\n        spc.ylabel('yaxis')\n        spc.title('Title')\n        spc.legend()\n        spc.savefig('plot.pdf')\n        spc.show()\n\nWhen run, the plot is generated as though you'd used plt instead of spc. The SmartPlotContext stores all data involved, infers variable names where possible and autogenerates the below directory structure:\n\n    data-save-dir/\n      make_plot.py\n      unnamed_arg.pkl\n      x_data.pkl\n      y_data.pkl\n\nWhere the contents of make\\_plot.py is\n\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from plotagain import load_pickle\n    \n    x_data = load_pickle('x_data.pkl')\n    y_data = load_pickle('y_data.pkl')\n    unnamed_arg = load_pickle('unnamed_arg.pkl')\n    \n    plt.plot(x_data, y_data, c='k', label='sin')\n    plt.plot(x_data, unnamed_arg, c='b', label='cos')\n    plt.xlabel('xaxis')\n    plt.ylabel('yaxis')\n    plt.title('Title')\n    plt.legend()\n    plt.savefig('plot.pdf')\n    plt.show()\n\nAll plt functions are automatically supported. The project is brand new so let me know if you find any bugs or have any ideas for new features!", "author_fullname": "t2_fvnwt14ww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Created a useful tool for matplotlib which automatically stores data used to make plots and auto-generates a script to recreate the plot for later fine-tuning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15507p6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689880334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://pypi.org/project/plotagain/\"&gt;https://pypi.org/project/plotagain/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The tool provides a simple contextmanager which automatically saves data used to make matplotlib plots and automatically generates a script to reproduce the plots at a later stage.&lt;/p&gt;\n\n&lt;p&gt;Example usage:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import numpy as np\nimport matplotlib.pyplot as plt\nfrom plotagain import SavePlotContext\n\nx_data = np.linspace(0, 2 * np.pi, 1000)\ny_data = np.sin(x_data)\nwith SavePlotContext(&amp;quot;./data-save-dir&amp;quot;, locals(), overwrite=True) as spc:\n    spc.plot(x_data, y_data, c=&amp;#39;k&amp;#39;, label=&amp;#39;sin&amp;#39;)\n    spc.plot(x_data, np.cos(x_data), c=&amp;#39;b&amp;#39;, label=&amp;#39;cos&amp;#39;)\n    spc.xlabel(&amp;#39;xaxis&amp;#39;)\n    spc.ylabel(&amp;#39;yaxis&amp;#39;)\n    spc.title(&amp;#39;Title&amp;#39;)\n    spc.legend()\n    spc.savefig(&amp;#39;plot.pdf&amp;#39;)\n    spc.show()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When run, the plot is generated as though you&amp;#39;d used plt instead of spc. The SmartPlotContext stores all data involved, infers variable names where possible and autogenerates the below directory structure:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;data-save-dir/\n  make_plot.py\n  unnamed_arg.pkl\n  x_data.pkl\n  y_data.pkl\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Where the contents of make_plot.py is&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import numpy as np\nimport matplotlib.pyplot as plt\nfrom plotagain import load_pickle\n\nx_data = load_pickle(&amp;#39;x_data.pkl&amp;#39;)\ny_data = load_pickle(&amp;#39;y_data.pkl&amp;#39;)\nunnamed_arg = load_pickle(&amp;#39;unnamed_arg.pkl&amp;#39;)\n\nplt.plot(x_data, y_data, c=&amp;#39;k&amp;#39;, label=&amp;#39;sin&amp;#39;)\nplt.plot(x_data, unnamed_arg, c=&amp;#39;b&amp;#39;, label=&amp;#39;cos&amp;#39;)\nplt.xlabel(&amp;#39;xaxis&amp;#39;)\nplt.ylabel(&amp;#39;yaxis&amp;#39;)\nplt.title(&amp;#39;Title&amp;#39;)\nplt.legend()\nplt.savefig(&amp;#39;plot.pdf&amp;#39;)\nplt.show()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;All plt functions are automatically supported. The project is brand new so let me know if you find any bugs or have any ideas for new features!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;s=27b6869059bde930b8fa91e163c4a5b593a62755", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=967712caa32aa48e894a0097548ea87ec67be18c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a3c7948dff53aae03712fb7d592fa1bbddccbb4", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15507p6", "is_robot_indexable": true, "report_reasons": null, "author": "BarnacleVegetable728", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15507p6/created_a_useful_tool_for_matplotlib_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15507p6/created_a_useful_tool_for_matplotlib_which/", "subreddit_subscribers": 955810, "created_utc": 1689880334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\u2026these phantom job posts are an incredible waste of time", "author_fullname": "t2_oy2eh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone build a chrome extension that shows % probability that an indeed/LI job posting is real?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_155vgms", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689962810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\u2026these phantom job posts are an incredible waste of time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155vgms", "is_robot_indexable": true, "report_reasons": null, "author": "morseky", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155vgms/can_someone_build_a_chrome_extension_that_shows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155vgms/can_someone_build_a_chrome_extension_that_shows/", "subreddit_subscribers": 955810, "created_utc": 1689962810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ahkaodsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a Google Sheets formula that lets you do data analysis in Sheets using GPT-4", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_155q2bn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/gncwydpnybdb1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/gncwydpnybdb1/DASH_96.mp4", "dash_url": "https://v.redd.it/gncwydpnybdb1/DASHPlaylist.mpd?a=1692560298%2CYjc3MDYwMWJlYzAwNDRmMDIzYTE5Zjg0MDUzN2ViNDU0NzY5MDI2ZTZiMTU3MDU1ZDY0ODc1Y2Q5OTUyNDM4OQ%3D%3D&amp;v=1&amp;f=sd", "duration": 45, "hls_url": "https://v.redd.it/gncwydpnybdb1/HLSPlaylist.m3u8?a=1692560298%2CZTQxZTUzYzc2ODU1Nzc2NmI5ZTRkNTY5MGMzMzJiOThlZmYwNzFkOTQ4ZjBiYTc5NjQ3OWQ4ZjRkNDc1MDJmZg%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GiIkU2SstRZiOPl1HqCHRkBK-sA7LGOVkGvEUZbGhYs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689950750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/gncwydpnybdb1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?format=pjpg&amp;auto=webp&amp;s=b158ae91ffef5013422c17c37ff263bb8d13b55c", "width": 3840, "height": 2160}, "resolutions": [{"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=faf43c42436bcdf48bc279ae3a2bb8b085c885a5", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=18fafee16f61c811e4d0f95f3dde59f2b1601a7d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=626d8a2ef1e63d3f5c39105e376166af3f65a433", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=12051331f9fe9ea9834775e36a7314eb37eb70ab", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4434ef3faf0560aabe713597dad7b9aa22640c90", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a665c71e3bf4993e89f99aa8650955b2725b36c8", "width": 1080, "height": 607}], "variants": {}, "id": "y-XNZov1Dq9ICv2SudihmZ7Jdg_KL1ge6fAQjbeQDeo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "155q2bn", "is_robot_indexable": true, "report_reasons": null, "author": "sheetsguru", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155q2bn/i_made_a_google_sheets_formula_that_lets_you_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/gncwydpnybdb1", "subreddit_subscribers": 955810, "created_utc": 1689950750.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/gncwydpnybdb1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/gncwydpnybdb1/DASH_96.mp4", "dash_url": "https://v.redd.it/gncwydpnybdb1/DASHPlaylist.mpd?a=1692560298%2CYjc3MDYwMWJlYzAwNDRmMDIzYTE5Zjg0MDUzN2ViNDU0NzY5MDI2ZTZiMTU3MDU1ZDY0ODc1Y2Q5OTUyNDM4OQ%3D%3D&amp;v=1&amp;f=sd", "duration": 45, "hls_url": "https://v.redd.it/gncwydpnybdb1/HLSPlaylist.m3u8?a=1692560298%2CZTQxZTUzYzc2ODU1Nzc2NmI5ZTRkNTY5MGMzMzJiOThlZmYwNzFkOTQ4ZjBiYTc5NjQ3OWQ4ZjRkNDc1MDJmZg%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As I'm building IT architecture for a startup, I've learned a lot about managing large databases. I want to share my insights and discoveries to perhaps help someone who might be facing similar challenges. In this article I reveal the critical aspects of database management and some practical tips to navigate common obstacles.\n\n&amp;#x200B;\n\n# How to manage large databases\n\nManaging databases can pose a fair share of challenges, primarily due to the size and intricacy of the data involved. Companies frequently grapple with how to effectively handle and manage the impact of data growth, especially when the database management systems struggle to keep pace.\n\nProblems sometimes stem from disregarded issues during the initial stages of the process. This could be because the prevailing technology was presumed to inherently manage these complexities. Hence, the secret lies in having a robust plan for handling large, intricate databases, particularly when significant data growth is expected, whether predictably or otherwise.\n\n# Data Size is Significant\n\nThe size of a database is pivotal as it impacts both performance and management approaches. The way data is processed and stored influences how the database is managed, and this holds true for data both in transit and at rest. For many large firms, data is priceless, and an increase in data could drastically alter their procedures. Therefore, planning ahead for data growth in a database is vital.\n\nIn my work with databases, I've witnessed customers struggle with performance issues and managing considerable data growth. Questions often arise, such as whether to normalize or denormalize the tables.\n\n# The Art of Normalizing Tables\n\nTable normalization is beneficial as it safeguards data integrity, curtails redundancy, and organizes data more efficiently for management, analysis, and extraction. However, normalized tables can come with performance penalties and potentially slow down queries due to the need for multiple joins when retrieving data.\n\nConversely, denormalized tables optimize retrieval primarily through indexing or using the primary key, allowing data to be stored in a buffer for faster access than performing multiple disk seeks. But they compromise data integrity and can lead to rapid database growth.\n\n# Understanding Database Complexity\n\nPerformance penalties can often arise with large and complex databases. In these scenarios, it is often more effective to manage and process these complex calculations using backend programming languages, rather than utilizing the database directly.\n\n# Selecting the Right Database Engine\n\nThe performance of a database server hinges on the data structure used and how it interacts with the queries made and the data retrieved from the table. The specific engine\u2019s data structure and the queries you apply to retrieve targeted data directly impact your database server\u2019s performance.\n\nWhen dealing with a multitude of databases, using the right engine in combination with your queries and the data you need to store and retrieve can yield excellent performance. However, this necessitates a comprehensive analysis of your needs to establish the right database environment.\n\n# Right Tools for Large Databases\n\nManaging a large database can be challenging without a robust platform to support the process. Even with skilled database engineers, there\u2019s always a risk of human error with the database server in use. Any misstep in altering configuration parameters or variables could lead to significant changes, potentially reducing the server\u2019s performance.\n\n# Some tips for working with databases:\n\n&amp;#x200B;\n\n* Pick the right data types for your columns. It saves space and makes queries run faster.\n* Use normalization rules to keep data tidy and avoid repeats.\n* Regularly maintain your database. Think about tasks like rebuilding indexes and updating stats.\n* Add indexes to columns you query a lot to speed things up, but don't go overboard.\n* Write neat database queries with the right joins and filters. Keep an eye on how they perform.\n* Keep a regular backup of your database for safety. Don't forget to check the backups are okay.\n* Use good security to keep your database safe from unauthorized access.\n* Use tools to keep tabs on how your database is performing. Spot and fix bottlenecks early.\n* Build your database to grow. It'll make adding more data easier down the line.\n* Keep track of your database layout, settings, and data flow. It helps when you need to solve problems.\n\n&amp;#x200B;\n\nTo conclude, managing large databases in 2023 necessitates not only understanding the fundamental concepts but also the use of the right tools and strategies. Through careful planning and strategic execution, you can surmount the complexities of large database management, ensuring optimal performance and robust data integrity.\n\n&amp;#x200B;\n\nI share more articles like this in my blog. If you want to check it out, visit: [https://ainsys.com/blog/2023/07/13/databases/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=data\\_science&amp;utm\\_content=databases&amp;utm\\_term=BigData](https://ainsys.com/blog/2023/07/13/databases/?utm_source=linkedin&amp;utm_medium=social&amp;utm_campaign=data_science&amp;utm_content=databases&amp;utm_term=BigData)", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to manage large databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155pmgh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689949763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As I&amp;#39;m building IT architecture for a startup, I&amp;#39;ve learned a lot about managing large databases. I want to share my insights and discoveries to perhaps help someone who might be facing similar challenges. In this article I reveal the critical aspects of database management and some practical tips to navigate common obstacles.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;How to manage large databases&lt;/h1&gt;\n\n&lt;p&gt;Managing databases can pose a fair share of challenges, primarily due to the size and intricacy of the data involved. Companies frequently grapple with how to effectively handle and manage the impact of data growth, especially when the database management systems struggle to keep pace.&lt;/p&gt;\n\n&lt;p&gt;Problems sometimes stem from disregarded issues during the initial stages of the process. This could be because the prevailing technology was presumed to inherently manage these complexities. Hence, the secret lies in having a robust plan for handling large, intricate databases, particularly when significant data growth is expected, whether predictably or otherwise.&lt;/p&gt;\n\n&lt;h1&gt;Data Size is Significant&lt;/h1&gt;\n\n&lt;p&gt;The size of a database is pivotal as it impacts both performance and management approaches. The way data is processed and stored influences how the database is managed, and this holds true for data both in transit and at rest. For many large firms, data is priceless, and an increase in data could drastically alter their procedures. Therefore, planning ahead for data growth in a database is vital.&lt;/p&gt;\n\n&lt;p&gt;In my work with databases, I&amp;#39;ve witnessed customers struggle with performance issues and managing considerable data growth. Questions often arise, such as whether to normalize or denormalize the tables.&lt;/p&gt;\n\n&lt;h1&gt;The Art of Normalizing Tables&lt;/h1&gt;\n\n&lt;p&gt;Table normalization is beneficial as it safeguards data integrity, curtails redundancy, and organizes data more efficiently for management, analysis, and extraction. However, normalized tables can come with performance penalties and potentially slow down queries due to the need for multiple joins when retrieving data.&lt;/p&gt;\n\n&lt;p&gt;Conversely, denormalized tables optimize retrieval primarily through indexing or using the primary key, allowing data to be stored in a buffer for faster access than performing multiple disk seeks. But they compromise data integrity and can lead to rapid database growth.&lt;/p&gt;\n\n&lt;h1&gt;Understanding Database Complexity&lt;/h1&gt;\n\n&lt;p&gt;Performance penalties can often arise with large and complex databases. In these scenarios, it is often more effective to manage and process these complex calculations using backend programming languages, rather than utilizing the database directly.&lt;/p&gt;\n\n&lt;h1&gt;Selecting the Right Database Engine&lt;/h1&gt;\n\n&lt;p&gt;The performance of a database server hinges on the data structure used and how it interacts with the queries made and the data retrieved from the table. The specific engine\u2019s data structure and the queries you apply to retrieve targeted data directly impact your database server\u2019s performance.&lt;/p&gt;\n\n&lt;p&gt;When dealing with a multitude of databases, using the right engine in combination with your queries and the data you need to store and retrieve can yield excellent performance. However, this necessitates a comprehensive analysis of your needs to establish the right database environment.&lt;/p&gt;\n\n&lt;h1&gt;Right Tools for Large Databases&lt;/h1&gt;\n\n&lt;p&gt;Managing a large database can be challenging without a robust platform to support the process. Even with skilled database engineers, there\u2019s always a risk of human error with the database server in use. Any misstep in altering configuration parameters or variables could lead to significant changes, potentially reducing the server\u2019s performance.&lt;/p&gt;\n\n&lt;h1&gt;Some tips for working with databases:&lt;/h1&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Pick the right data types for your columns. It saves space and makes queries run faster.&lt;/li&gt;\n&lt;li&gt;Use normalization rules to keep data tidy and avoid repeats.&lt;/li&gt;\n&lt;li&gt;Regularly maintain your database. Think about tasks like rebuilding indexes and updating stats.&lt;/li&gt;\n&lt;li&gt;Add indexes to columns you query a lot to speed things up, but don&amp;#39;t go overboard.&lt;/li&gt;\n&lt;li&gt;Write neat database queries with the right joins and filters. Keep an eye on how they perform.&lt;/li&gt;\n&lt;li&gt;Keep a regular backup of your database for safety. Don&amp;#39;t forget to check the backups are okay.&lt;/li&gt;\n&lt;li&gt;Use good security to keep your database safe from unauthorized access.&lt;/li&gt;\n&lt;li&gt;Use tools to keep tabs on how your database is performing. Spot and fix bottlenecks early.&lt;/li&gt;\n&lt;li&gt;Build your database to grow. It&amp;#39;ll make adding more data easier down the line.&lt;/li&gt;\n&lt;li&gt;Keep track of your database layout, settings, and data flow. It helps when you need to solve problems.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To conclude, managing large databases in 2023 necessitates not only understanding the fundamental concepts but also the use of the right tools and strategies. Through careful planning and strategic execution, you can surmount the complexities of large database management, ensuring optimal performance and robust data integrity.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I share more articles like this in my blog. If you want to check it out, visit: &lt;a href=\"https://ainsys.com/blog/2023/07/13/databases/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_science&amp;amp;utm_content=databases&amp;amp;utm_term=BigData\"&gt;https://ainsys.com/blog/2023/07/13/databases/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_science&amp;amp;utm_content=databases&amp;amp;utm_term=BigData&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;s=8a29f85fd320507a70ec9694b971f494352d2655", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155pmgh", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155pmgh/how_to_manage_large_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155pmgh/how_to_manage_large_databases/", "subreddit_subscribers": 955810, "created_utc": 1689949763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nhttps://i.redd.it/z3fp8o9ol9db1.gif", "author_fullname": "t2_h3a1v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] Nested Bayesian Sampling is Awesome!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 130, "top_awarded_type": null, "hide_score": false, "media_metadata": {"z3fp8o9ol9db1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 100, "x": 108, "u": "https://preview.redd.it/z3fp8o9ol9db1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=91c590454c04b75dba540612c2fe4a94dd3a3ffd"}, {"y": 201, "x": 216, "u": "https://preview.redd.it/z3fp8o9ol9db1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=95e303124668869bcc2c928cd81a98c84f8b1fe0"}, {"y": 299, "x": 320, "u": "https://preview.redd.it/z3fp8o9ol9db1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=4aec1b0b986238ed968fb63e58385cee45226000"}], "s": {"y": 374, "gif": "https://i.redd.it/z3fp8o9ol9db1.gif", "mp4": "https://preview.redd.it/z3fp8o9ol9db1.gif?format=mp4&amp;s=15dd6912835c511e30d68b164559cd2e3c46672a", "x": 400}, "id": "z3fp8o9ol9db1"}}, "name": "t3_155fy0l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/V25PemQFdpjWNlHKHsDPR0eOTRa6Lqr7Iu7-glM31Hg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689922014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/z3fp8o9ol9db1.gif\"&gt;https://i.redd.it/z3fp8o9ol9db1.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155fy0l", "is_robot_indexable": true, "report_reasons": null, "author": "pmocz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155fy0l/oc_nested_bayesian_sampling_is_awesome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155fy0l/oc_nested_bayesian_sampling_is_awesome/", "subreddit_subscribers": 955810, "created_utc": 1689922014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I have a friend who is a city planner. One day, he was tasked with reassessing the location suitability of thousands of gas stations in the city, needing to find the positions of the k-nearest gas stations to each one.\n\nHow can we find the nearest k stations with little time? This is a practical application scenario of the k-nearest neighbors problem.\n\nAs such, he came to me for help, hoping I could provide a high-performance solution.\n\nSo I write down this article and which will guide you on efficiently solving the [k-nearest neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) problem using NumPy. By comparing it with a Python iterative solution, we will demonstrate the powerful performance of NumPy.\n\nIn this article, we will delve into utilizing advanced NumPy features, such as broadcasting, fancy indexing, and sorting, to implement a high-performance k-nearest neighbors algorithm.\n\nAfter reading this article, you will able to:\n\n* Understand the k-nearest neighbors problem and its practical application scenarios\n* Learn how to use the NumPy library to solve the k-nearest neighbors problem\n* Understand in-depth how features such as NumPy broadcasting, fancy indexing, and sorting play a role in the algorithm\n* Compare the performance of NumPy with a Python iterative solution, exploring why NumPy is superior\n\nLet\u2019s delve into the high-performance world of NumPy together, exploring how we can solve the k-nearest neighbors problem more quickly and effectively using only NumPy.\n\nFor more details:\n\n[https://towardsdatascience.com/efficient-k-nearest-neighbors-k-nn-solutions-with-numpy-58cbac2a0971](https://towardsdatascience.com/efficient-k-nearest-neighbors-k-nn-solutions-with-numpy-58cbac2a0971)", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Efficient k-Nearest Neighbors (k-NN) Solutions with NumPy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15595e6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689901591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a friend who is a city planner. One day, he was tasked with reassessing the location suitability of thousands of gas stations in the city, needing to find the positions of the k-nearest gas stations to each one.&lt;/p&gt;\n\n&lt;p&gt;How can we find the nearest k stations with little time? This is a practical application scenario of the k-nearest neighbors problem.&lt;/p&gt;\n\n&lt;p&gt;As such, he came to me for help, hoping I could provide a high-performance solution.&lt;/p&gt;\n\n&lt;p&gt;So I write down this article and which will guide you on efficiently solving the &lt;a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\"&gt;k-nearest neighbors&lt;/a&gt; problem using NumPy. By comparing it with a Python iterative solution, we will demonstrate the powerful performance of NumPy.&lt;/p&gt;\n\n&lt;p&gt;In this article, we will delve into utilizing advanced NumPy features, such as broadcasting, fancy indexing, and sorting, to implement a high-performance k-nearest neighbors algorithm.&lt;/p&gt;\n\n&lt;p&gt;After reading this article, you will able to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Understand the k-nearest neighbors problem and its practical application scenarios&lt;/li&gt;\n&lt;li&gt;Learn how to use the NumPy library to solve the k-nearest neighbors problem&lt;/li&gt;\n&lt;li&gt;Understand in-depth how features such as NumPy broadcasting, fancy indexing, and sorting play a role in the algorithm&lt;/li&gt;\n&lt;li&gt;Compare the performance of NumPy with a Python iterative solution, exploring why NumPy is superior&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Let\u2019s delve into the high-performance world of NumPy together, exploring how we can solve the k-nearest neighbors problem more quickly and effectively using only NumPy.&lt;/p&gt;\n\n&lt;p&gt;For more details:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://towardsdatascience.com/efficient-k-nearest-neighbors-k-nn-solutions-with-numpy-58cbac2a0971\"&gt;https://towardsdatascience.com/efficient-k-nearest-neighbors-k-nn-solutions-with-numpy-58cbac2a0971&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15595e6", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15595e6/efficient_knearest_neighbors_knn_solutions_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15595e6/efficient_knearest_neighbors_knn_solutions_with/", "subreddit_subscribers": 955810, "created_utc": 1689901591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I am currently preparing to participate in the online master's programs at UT Austin and CU Boulder.\n\nBecause of the TOEFL score, there is no application requirement for GT, and I applied for UT Austin but was rejected. I plan to apply to Austin again this time, but in case I fail again, I found CU Boulder while looking for other online master's programs.\n\nIs there anyone who is taking MSCS or MSDS courses at CU Boulder? I am currently taking courses for admission on Coursera, and I plan to pay CU to take classes after completing the courses on Coursera.\n\nWhat I'm curious about is the following.\n\n1. After completing the Coursera course, do the formal classes taken at CU Boulder have only an additional test compared to the Coursera course? So, if I get high scores on the quizzes and assignments I take on Coursera courses, will there be any advantages to switching to CU Boulder courses?\n2. How satisfied are you with the CU Boulder master's program? I would like to know why you chose CU Boulder rather than GT or UT Austin.\n\nI would appreciate it if you could answer anything if you know anything.", "author_fullname": "t2_c0qbo6uf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you know about CU Boulder's Online Master's Program?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1551uh8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689883999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am currently preparing to participate in the online master&amp;#39;s programs at UT Austin and CU Boulder.&lt;/p&gt;\n\n&lt;p&gt;Because of the TOEFL score, there is no application requirement for GT, and I applied for UT Austin but was rejected. I plan to apply to Austin again this time, but in case I fail again, I found CU Boulder while looking for other online master&amp;#39;s programs.&lt;/p&gt;\n\n&lt;p&gt;Is there anyone who is taking MSCS or MSDS courses at CU Boulder? I am currently taking courses for admission on Coursera, and I plan to pay CU to take classes after completing the courses on Coursera.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m curious about is the following.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;After completing the Coursera course, do the formal classes taken at CU Boulder have only an additional test compared to the Coursera course? So, if I get high scores on the quizzes and assignments I take on Coursera courses, will there be any advantages to switching to CU Boulder courses?&lt;/li&gt;\n&lt;li&gt;How satisfied are you with the CU Boulder master&amp;#39;s program? I would like to know why you chose CU Boulder rather than GT or UT Austin.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I would appreciate it if you could answer anything if you know anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1551uh8", "is_robot_indexable": true, "report_reasons": null, "author": "benchpresss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1551uh8/do_you_know_about_cu_boulders_online_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1551uh8/do_you_know_about_cu_boulders_online_masters/", "subreddit_subscribers": 955810, "created_utc": 1689883999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So basically I'm going to get a major degree in data science, it's basically computing statistics and data engineering combined. \n\n\nMy question is... Is this field already oversaturated in your country or it's only oversaturated with online- courses people? \n\nBecause really, I'm from a bachelor in economics and I could simply pursue a finance major, but I like statistics and I would love working in an international company/ organisation. \n\nI know that probably my market is not the same as yours, but in my country data science is just born, so data about it are basically non existent. \n\nSo, I don't know? Please give me your knowledge?", "author_fullname": "t2_9f9o8ytt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science major", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_155wx0i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689966151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically I&amp;#39;m going to get a major degree in data science, it&amp;#39;s basically computing statistics and data engineering combined. &lt;/p&gt;\n\n&lt;p&gt;My question is... Is this field already oversaturated in your country or it&amp;#39;s only oversaturated with online- courses people? &lt;/p&gt;\n\n&lt;p&gt;Because really, I&amp;#39;m from a bachelor in economics and I could simply pursue a finance major, but I like statistics and I would love working in an international company/ organisation. &lt;/p&gt;\n\n&lt;p&gt;I know that probably my market is not the same as yours, but in my country data science is just born, so data about it are basically non existent. &lt;/p&gt;\n\n&lt;p&gt;So, I don&amp;#39;t know? Please give me your knowledge?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155wx0i", "is_robot_indexable": true, "report_reasons": null, "author": "Urom99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155wx0i/data_science_major/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155wx0i/data_science_major/", "subreddit_subscribers": 955810, "created_utc": 1689966151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all!\n\nOver the past few weeks, my colleagues and I have built a new feature in our JupyterLab plugin that allows you to converse with a chatbot contextualized with the code snippets in your notebooks. Notebooks can get large and complex quickly, so having a personal coding assistant as a partner at work, helping you find relevant information and answering your questions can be very helpful.\n\nhttps://i.redd.it/369gz1w04ddb1.gif\n\nThe technology draws background context from the snippets in your notebooks to help augment the responses from the AI. This means you can empower the chatbot with all the code you have written within JupyterLab notebooks.\n\nWith each response, the AI links you to relevant files and suggests follow-up questions based on the context of your conversation.\n\nWe base all of our engineering on community feedback, so feel free to reach out via [Discord](https://discord.gg/5AN7rVXEES) or our [support survey](https://getpieces.typeform.com/jupyterlab) with any questions or comments and we will be glad to help.\n\nIf you\u2019re interested, here\u2019s how to get started! It\u2019s just 3 easy steps and usually takes new users about 4 minutes.\n\n1. [Install Pieces OS](https://docs.pieces.app/installation-getting-started/what-am-i-installing): This is the background service that runs locally on your machine and connects Pieces applications and plugins.\n2. [Install the Pieces JupyterLab Extension](https://docs.pieces.app/extensions-plugins/jupyterlab#steps-to-install): This is the connective software that brings the power of Pieces straight to JupyterLab.\n3. In JupyterLab, open the Pieces plugin by selecting the \u201cP\u201d logo within the right side-bar. Then, switch from snippet view ( {} ) to the AI by clicking the little robot. ( \ud83e\udd16)\n\nWe\u2019re so enthusiastic about this new creation and love the feedback we have already received. Keep it coming! (There\u2019s also much more to this update than just the chatbot, you can find the full list of changes here!) After trying it out, what do you think?\n\n\\- Mason &amp; the Pieces for Developers Team &lt;3", "author_fullname": "t2_dc3rnec6l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Embedded GPT Assistant Contextualized by JupyterLab Notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "media_metadata": {"369gz1w04ddb1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/369gz1w04ddb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=849b0a609d485a0f194c4b620a21e7ec665190bb"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/369gz1w04ddb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=9af1c9428f038f42370dde653da0c1cc06a5e2ce"}, {"y": 179, "x": 320, "u": "https://preview.redd.it/369gz1w04ddb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=62a4f48cac0187b411e68ddf32fe3d4c23a6f566"}, {"y": 359, "x": 640, "u": "https://preview.redd.it/369gz1w04ddb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=4df4f5dfcf8594851e59f01f1a1824a49fe1a2e4"}], "s": {"y": 511, "gif": "https://i.redd.it/369gz1w04ddb1.gif", "mp4": "https://preview.redd.it/369gz1w04ddb1.gif?format=mp4&amp;s=338ed3b6de7cdd8178df88fc3cd7c699622c016c", "x": 909}, "id": "369gz1w04ddb1"}}, "name": "t3_155wrrd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tAgBKu_2OjvrfnT7Mt8JvpRA07Q1yJsXYel_oIwwHns.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689965843.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!&lt;/p&gt;\n\n&lt;p&gt;Over the past few weeks, my colleagues and I have built a new feature in our JupyterLab plugin that allows you to converse with a chatbot contextualized with the code snippets in your notebooks. Notebooks can get large and complex quickly, so having a personal coding assistant as a partner at work, helping you find relevant information and answering your questions can be very helpful.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/369gz1w04ddb1.gif\"&gt;https://i.redd.it/369gz1w04ddb1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The technology draws background context from the snippets in your notebooks to help augment the responses from the AI. This means you can empower the chatbot with all the code you have written within JupyterLab notebooks.&lt;/p&gt;\n\n&lt;p&gt;With each response, the AI links you to relevant files and suggests follow-up questions based on the context of your conversation.&lt;/p&gt;\n\n&lt;p&gt;We base all of our engineering on community feedback, so feel free to reach out via &lt;a href=\"https://discord.gg/5AN7rVXEES\"&gt;Discord&lt;/a&gt; or our &lt;a href=\"https://getpieces.typeform.com/jupyterlab\"&gt;support survey&lt;/a&gt; with any questions or comments and we will be glad to help.&lt;/p&gt;\n\n&lt;p&gt;If you\u2019re interested, here\u2019s how to get started! It\u2019s just 3 easy steps and usually takes new users about 4 minutes.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://docs.pieces.app/installation-getting-started/what-am-i-installing\"&gt;Install Pieces OS&lt;/a&gt;: This is the background service that runs locally on your machine and connects Pieces applications and plugins.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://docs.pieces.app/extensions-plugins/jupyterlab#steps-to-install\"&gt;Install the Pieces JupyterLab Extension&lt;/a&gt;: This is the connective software that brings the power of Pieces straight to JupyterLab.&lt;/li&gt;\n&lt;li&gt;In JupyterLab, open the Pieces plugin by selecting the \u201cP\u201d logo within the right side-bar. Then, switch from snippet view ( {} ) to the AI by clicking the little robot. ( \ud83e\udd16)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We\u2019re so enthusiastic about this new creation and love the feedback we have already received. Keep it coming! (There\u2019s also much more to this update than just the chatbot, you can find the full list of changes here!) After trying it out, what do you think?&lt;/p&gt;\n\n&lt;p&gt;- Mason &amp;amp; the Pieces for Developers Team &amp;lt;3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155wrrd", "is_robot_indexable": true, "report_reasons": null, "author": "masnwilliams", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155wrrd/an_embedded_gpt_assistant_contextualized_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155wrrd/an_embedded_gpt_assistant_contextualized_by/", "subreddit_subscribers": 955810, "created_utc": 1689965843.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think dimensionality reduction is a great way to start a task and always a great way to visualize for customers etc. I like PCA  for its interpretability, but it of course has other drawbacks. Other techniques like t-sne gives great results. But what did it actually do? How are different parts of the reduced space different in its mapping? How tight are actually a clusters? When there are many dimensions being reduced this gets really tricky.\n\nHow do you solve this? How do makes sense of dimension reducing techniques more capable than PCA? I haven't seen a lot out there and would love to see what powerful tools are out there.\n\nPlaying around on my own I did this:\n\n[https://github.com/erikbergh/interpretable\\_dim\\_reduction](https://github.com/erikbergh/interpretable_dim_reduction)\n\nWhat is out there that achieves something similar? Papers are of course interesting. But mainly something already implemented in a python package would be the best.", "author_fullname": "t2_11xlzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interpret dimensionality reduction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_155wros", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689965838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think dimensionality reduction is a great way to start a task and always a great way to visualize for customers etc. I like PCA  for its interpretability, but it of course has other drawbacks. Other techniques like t-sne gives great results. But what did it actually do? How are different parts of the reduced space different in its mapping? How tight are actually a clusters? When there are many dimensions being reduced this gets really tricky.&lt;/p&gt;\n\n&lt;p&gt;How do you solve this? How do makes sense of dimension reducing techniques more capable than PCA? I haven&amp;#39;t seen a lot out there and would love to see what powerful tools are out there.&lt;/p&gt;\n\n&lt;p&gt;Playing around on my own I did this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/erikbergh/interpretable_dim_reduction\"&gt;https://github.com/erikbergh/interpretable_dim_reduction&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What is out there that achieves something similar? Papers are of course interesting. But mainly something already implemented in a python package would be the best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?auto=webp&amp;s=454271268771ae63c20b2ebcd8d9df05115ac2ea", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78cb5d537754a0da97cb7e42171fd221440404c2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c05470ee11a42ee79a800dc6d525adc4fb9ed2cf", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=035fb57eaca8b064ade2c0eb72e052f56b9312a1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=954aed5f3c90c98961d602422c07cd9ad5b2f199", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a1c0c64557ad05f9217c89960ae0d4ed5645d27", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49befd0ee223ddf80db0ca24baf2d4b7a4d117af", "width": 1080, "height": 540}], "variants": {}, "id": "34EwOPgk44FKNkZzHlVGaXgo3yjjhhc402Mc4rN1Wrc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155wros", "is_robot_indexable": true, "report_reasons": null, "author": "tvaap", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155wros/interpret_dimensionality_reduction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155wros/interpret_dimensionality_reduction/", "subreddit_subscribers": 955810, "created_utc": 1689965838.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}