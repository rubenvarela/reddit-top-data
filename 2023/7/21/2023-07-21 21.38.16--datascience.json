{"kind": "Listing", "data": {"after": "t3_155wl9n", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_13ikgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "asking a friend who is a data engineer how can i automate some of my reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_155pvxf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 123, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 123, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jf6im0xoZnuCUkO1TgEr-7Zh1JX1I8SRh_06i1XVMpg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689950361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/m2762utuxbdb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/m2762utuxbdb1.png?auto=webp&amp;s=8e5a2379b22a7de445b7cf5018c7235075dec9e0", "width": 918, "height": 500}, "resolutions": [{"url": "https://preview.redd.it/m2762utuxbdb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d90346f4bc9d21893a0c30bda14120bbb184b86", "width": 108, "height": 58}, {"url": "https://preview.redd.it/m2762utuxbdb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=78fd9d2ce6ba3702cf9d68ef56eb1e0ececb9ff8", "width": 216, "height": 117}, {"url": "https://preview.redd.it/m2762utuxbdb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e26556a963a07fd57c3a948446c02c9fdb899a0", "width": 320, "height": 174}, {"url": "https://preview.redd.it/m2762utuxbdb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7fac981c5a835e4b8e6a7570f8aa3d24413cc36c", "width": 640, "height": 348}], "variants": {}, "id": "n5_YEgLHPlnnNWi53pPE9SFegvgFxZbKqJU0zRk9Mro"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "155pvxf", "is_robot_indexable": true, "report_reasons": null, "author": "Amr-Ahmed", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155pvxf/asking_a_friend_who_is_a_data_engineer_how_can_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/m2762utuxbdb1.png", "subreddit_subscribers": 955923, "created_utc": 1689950361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have a boss that apparently used to do technical work once but it was a long time ago. He now constantly has completely unrealistic expectations of what data science can do. Whenever I propose a realistic project, he is not interested as it doesn't \"move the needle\" and is not \"revolutionary\".  He always wants \"technical excellence\" and \"thought leadership\", yet hires inexperienced people and doesn't pay them much.\n\nSo he over-promises on my behalf constantly. For example, I have experience in causal inference. So he would say wow let's find the cause of all mortgage defaults! Causal inference is more vague then that, takes a long, long time, often leads to no concrete results. If I tell him that, then he says \"it's useless\". He also thinks of projects such as \"everything needs to happen in real-time, data from all sources is integrated, external with internal\" etc etc. Just complete lack of pragmatism and no clue about timelines. He is also super unhappy if I correct him.\n\nHe is also into AI doom, how it will lead to human extinction and so on. \n\nI am a people pleaser and find it difficult to set boundaries. I often agree to look into things that I already know are impossible. Any tips on dealing with this?", "author_fullname": "t2_ekbfo234c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with a boss that has inflated, unrealistic expectations of data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155crtu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 91, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 91, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689912083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a boss that apparently used to do technical work once but it was a long time ago. He now constantly has completely unrealistic expectations of what data science can do. Whenever I propose a realistic project, he is not interested as it doesn&amp;#39;t &amp;quot;move the needle&amp;quot; and is not &amp;quot;revolutionary&amp;quot;.  He always wants &amp;quot;technical excellence&amp;quot; and &amp;quot;thought leadership&amp;quot;, yet hires inexperienced people and doesn&amp;#39;t pay them much.&lt;/p&gt;\n\n&lt;p&gt;So he over-promises on my behalf constantly. For example, I have experience in causal inference. So he would say wow let&amp;#39;s find the cause of all mortgage defaults! Causal inference is more vague then that, takes a long, long time, often leads to no concrete results. If I tell him that, then he says &amp;quot;it&amp;#39;s useless&amp;quot;. He also thinks of projects such as &amp;quot;everything needs to happen in real-time, data from all sources is integrated, external with internal&amp;quot; etc etc. Just complete lack of pragmatism and no clue about timelines. He is also super unhappy if I correct him.&lt;/p&gt;\n\n&lt;p&gt;He is also into AI doom, how it will lead to human extinction and so on. &lt;/p&gt;\n\n&lt;p&gt;I am a people pleaser and find it difficult to set boundaries. I often agree to look into things that I already know are impossible. Any tips on dealing with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155crtu", "is_robot_indexable": true, "report_reasons": null, "author": "Ashamed-Tie6059", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155crtu/how_do_you_deal_with_a_boss_that_has_inflated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155crtu/how_do_you_deal_with_a_boss_that_has_inflated/", "subreddit_subscribers": 955923, "created_utc": 1689912083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is just a rant I guess. I\u2019ve been looking at quite a lot of job openings for Data Scientist positions, for some reasons they all appear to be so different. Here are the three main types I\u2019ve seen:\n\n**1. The ML researcher**\nDescription: \n- Develop some magical AI that solves all our business problems using all sorts of buzzwords we hear in the news\n- Develop LLMs that has nothing to do with the business\n- There are cavern walls in Africa with cravings by Neanderthals containing cleaner data than the database\n\nRequirements: \n- 2 PhDs\n- Published 7 first author papers in top journals\n- Won 5 Kaggle competitions simultaneously with one model\n\n**2. The ML engineer**\nDescription: \n- Literally everything from data eng to MLOps to cloud infra, except actual data science\n- \u201cEnd-to-end ML pipeline\u201d\n- If you use a for loop with pandas data frame, they will bring you to the back alley and shoot you in the head\n\nRequirements: \n- Solve hard leetcode question blindfolded with one arm behind your back\n- Need to know 17 ways to accomplish the exact same thing using AWS/GCP\n- Need to know 5 different databases we don\u2019t even use\n\n**3. The mislabelled data analyst**\nDescription: \n- Nothing but making dashboards\n- Use statistics but not too much that it gives our execs imposter syndrome\n- ML, but it\u2019s logistic regression on Excel\n\nRequirements: \n- Tableau etc\n- Telepathic ability to magically make business people understand basic statistics concepts \n- Willing to be called incompetent by exec when your analysis shows the source of all business problems stemmed from poor management by said exec\n\nI\u2019m sure I\u2019ve missed out some others, and I\u2019ve also seen roles that expects you to do all three. How do people even find jobs when the entire job landscape is so confusing?", "author_fullname": "t2_2kh4l8ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are DS job descriptions so\u2026diverse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155jr9n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689934309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is just a rant I guess. I\u2019ve been looking at quite a lot of job openings for Data Scientist positions, for some reasons they all appear to be so different. Here are the three main types I\u2019ve seen:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1. The ML researcher&lt;/strong&gt;\nDescription: \n- Develop some magical AI that solves all our business problems using all sorts of buzzwords we hear in the news\n- Develop LLMs that has nothing to do with the business\n- There are cavern walls in Africa with cravings by Neanderthals containing cleaner data than the database&lt;/p&gt;\n\n&lt;p&gt;Requirements: \n- 2 PhDs\n- Published 7 first author papers in top journals\n- Won 5 Kaggle competitions simultaneously with one model&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2. The ML engineer&lt;/strong&gt;\nDescription: \n- Literally everything from data eng to MLOps to cloud infra, except actual data science\n- \u201cEnd-to-end ML pipeline\u201d\n- If you use a for loop with pandas data frame, they will bring you to the back alley and shoot you in the head&lt;/p&gt;\n\n&lt;p&gt;Requirements: \n- Solve hard leetcode question blindfolded with one arm behind your back\n- Need to know 17 ways to accomplish the exact same thing using AWS/GCP\n- Need to know 5 different databases we don\u2019t even use&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;3. The mislabelled data analyst&lt;/strong&gt;\nDescription: \n- Nothing but making dashboards\n- Use statistics but not too much that it gives our execs imposter syndrome\n- ML, but it\u2019s logistic regression on Excel&lt;/p&gt;\n\n&lt;p&gt;Requirements: \n- Tableau etc\n- Telepathic ability to magically make business people understand basic statistics concepts \n- Willing to be called incompetent by exec when your analysis shows the source of all business problems stemmed from poor management by said exec&lt;/p&gt;\n\n&lt;p&gt;I\u2019m sure I\u2019ve missed out some others, and I\u2019ve also seen roles that expects you to do all three. How do people even find jobs when the entire job landscape is so confusing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155jr9n", "is_robot_indexable": true, "report_reasons": null, "author": "supper_ham", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155jr9n/why_are_ds_job_descriptions_sodiverse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155jr9n/why_are_ds_job_descriptions_sodiverse/", "subreddit_subscribers": 955923, "created_utc": 1689934309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got fired today from a data entry position at a biotech research company for performance issues after 2 months into the job. My company was very fast paced and my manager caught signs of me being slow since I started working there and was constantly signaling me out in personal teams meetings. I have ADHD so it's a lot harder for me to learn as quickly as other people, especially if it's within a few months. I was making some data entry mistakes as someone new would commit, but was not within the margin of error that they wanted me to work within. Because of this, I now feel insecure about pursuing data science.\n\nI'm doing excellent in my masters program and I have a 4.0 but this experience has me distraught tbh.", "author_fullname": "t2_2avd4wfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got fired from a data entry position 2 months in and I'm having second thoughts about whether or not to continue a career pathway in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1555p8t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689892830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got fired today from a data entry position at a biotech research company for performance issues after 2 months into the job. My company was very fast paced and my manager caught signs of me being slow since I started working there and was constantly signaling me out in personal teams meetings. I have ADHD so it&amp;#39;s a lot harder for me to learn as quickly as other people, especially if it&amp;#39;s within a few months. I was making some data entry mistakes as someone new would commit, but was not within the margin of error that they wanted me to work within. Because of this, I now feel insecure about pursuing data science.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m doing excellent in my masters program and I have a 4.0 but this experience has me distraught tbh.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1555p8t", "is_robot_indexable": true, "report_reasons": null, "author": "Javilism", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1555p8t/i_got_fired_from_a_data_entry_position_2_months/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1555p8t/i_got_fired_from_a_data_entry_position_2_months/", "subreddit_subscribers": 955923, "created_utc": 1689892830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Same as what seems to be the rest of this subreddit, I've been laid off a couple of months ago and the rejection emails and ghosting are getting to my head - I know, me and all the other unfortunate souls.\n\nI like to think my CV is pretty good, but of course, there's always room for improvement. Sure, the CV may not be the cause at all, it's the job market being flooded atm with thousands of people with millennia of data science experience, data science not being the core of most businesses' operations,  global warming, whatever. I'm sure there are still people out there getting hired as Data Scientists every single day and I think I'm ready to get off the \"bad job market\" copium.\n\nPlease rip my CV apart like you're the CTO of a tech startup who is behind on his 2021 Audi A5 instalments and a recruiter sent you this CV for the Data Science position you want filled by a senior-level dude but you'll only pay him a low-mid data science salary as long as they're down for hybrid on-site 4.5 days/week (AND PIZZA FRIDAYS!). Also, 350 people applied for this job of yours in the first 8 hours of you posting it on LinkedIn.\n\nSeriously though, I'll take all the tough love I can get - format, content, ATS readability, bs detector. Thanks\n\nEDIT: a lot of you Americans seem to dislike the Interests section. Although reading the first few comments made me feel a bit defensive about this, [u/AtleticoDeMadriz](https://www.reddit.com/user/AtleticoDeMadriz/) explained it well:\n\n&gt;none of your interests are special enough to warrant taking up space on your CV. You need to consider the effect each word has on your CV\n\nI will probably end up deleting the section as even if the hiring manager and I happen to have common interests, it probably wouldn't put me in the interview pile by itself.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/f131kurr2ddb1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=0d51b6b04ec424641671a9e1b3a0165873b686ca", "author_fullname": "t2_ewtjr5j3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rip my 2 y.o.e. Data Scientist CV apart", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"f131kurr2ddb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 151, "x": 108, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=858ac1eef7ae53cf9d72efb4ee950b50c30c912e"}, {"y": 303, "x": 216, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=63be016b98e164e6324c266610e034803ea42f4a"}, {"y": 449, "x": 320, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=91fa78d4645067a0256716c6e53a42b47eb6fa35"}, {"y": 899, "x": 640, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a69955ced14e1bba4e5a693e2fb2da47efd63a1c"}, {"y": 1348, "x": 960, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b2ccaed55f14fc907365e0e1b1dffb1447fb91ab"}, {"y": 1517, "x": 1080, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bbaed0a4339b531289883cd3d293633cadad208f"}], "s": {"y": 2262, "x": 1610, "u": "https://preview.redd.it/f131kurr2ddb1.png?width=1610&amp;format=png&amp;auto=webp&amp;s=0d51b6b04ec424641671a9e1b3a0165873b686ca"}, "id": "f131kurr2ddb1"}}, "name": "t3_155vz86", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YlxZ_BYm70NKGd3OZbyoBUFRDlosB8mUoga4qjI1L-c.jpg", "edited": 1689972048.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689964028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Same as what seems to be the rest of this subreddit, I&amp;#39;ve been laid off a couple of months ago and the rejection emails and ghosting are getting to my head - I know, me and all the other unfortunate souls.&lt;/p&gt;\n\n&lt;p&gt;I like to think my CV is pretty good, but of course, there&amp;#39;s always room for improvement. Sure, the CV may not be the cause at all, it&amp;#39;s the job market being flooded atm with thousands of people with millennia of data science experience, data science not being the core of most businesses&amp;#39; operations,  global warming, whatever. I&amp;#39;m sure there are still people out there getting hired as Data Scientists every single day and I think I&amp;#39;m ready to get off the &amp;quot;bad job market&amp;quot; copium.&lt;/p&gt;\n\n&lt;p&gt;Please rip my CV apart like you&amp;#39;re the CTO of a tech startup who is behind on his 2021 Audi A5 instalments and a recruiter sent you this CV for the Data Science position you want filled by a senior-level dude but you&amp;#39;ll only pay him a low-mid data science salary as long as they&amp;#39;re down for hybrid on-site 4.5 days/week (AND PIZZA FRIDAYS!). Also, 350 people applied for this job of yours in the first 8 hours of you posting it on LinkedIn.&lt;/p&gt;\n\n&lt;p&gt;Seriously though, I&amp;#39;ll take all the tough love I can get - format, content, ATS readability, bs detector. Thanks&lt;/p&gt;\n\n&lt;p&gt;EDIT: a lot of you Americans seem to dislike the Interests section. Although reading the first few comments made me feel a bit defensive about this, &lt;a href=\"https://www.reddit.com/user/AtleticoDeMadriz/\"&gt;u/AtleticoDeMadriz&lt;/a&gt; explained it well:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;none of your interests are special enough to warrant taking up space on your CV. You need to consider the effect each word has on your CV&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I will probably end up deleting the section as even if the hiring manager and I happen to have common interests, it probably wouldn&amp;#39;t put me in the interview pile by itself.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/f131kurr2ddb1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d51b6b04ec424641671a9e1b3a0165873b686ca\"&gt;https://preview.redd.it/f131kurr2ddb1.png?width=1610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d51b6b04ec424641671a9e1b3a0165873b686ca&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155vz86", "is_robot_indexable": true, "report_reasons": null, "author": "iulianghg", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155vz86/rip_my_2_yoe_data_scientist_cv_apart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155vz86/rip_my_2_yoe_data_scientist_cv_apart/", "subreddit_subscribers": 955923, "created_utc": 1689964028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m wondering how common take home data science projects are when your interviewing and should you always do them? \n\nI\u2019ve gotten three different 1 week long take home projects (out of the 5 companies I\u2019ve interviewed at so far). The projects all require data cleaning and fitting a model. One project had several messy data files with no column descriptions at all. \n\nAnother company sent me a 90 minute assessment before even talking to me (have no communication with an actual person). So it seems like they sent this assessment to tons of people. It also covered probability, coding and personal questions. I know statistics well but didn\u2019t realize I would need to have refreshed on some formulas). \n\nI\u2019m swamped with projects that may not even lead to jobs. Is this normal?", "author_fullname": "t2_bkxkz9yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take home assessments during Interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1557wv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689901660.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689898259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m wondering how common take home data science projects are when your interviewing and should you always do them? &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve gotten three different 1 week long take home projects (out of the 5 companies I\u2019ve interviewed at so far). The projects all require data cleaning and fitting a model. One project had several messy data files with no column descriptions at all. &lt;/p&gt;\n\n&lt;p&gt;Another company sent me a 90 minute assessment before even talking to me (have no communication with an actual person). So it seems like they sent this assessment to tons of people. It also covered probability, coding and personal questions. I know statistics well but didn\u2019t realize I would need to have refreshed on some formulas). &lt;/p&gt;\n\n&lt;p&gt;I\u2019m swamped with projects that may not even lead to jobs. Is this normal?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1557wv5", "is_robot_indexable": true, "report_reasons": null, "author": "Responsible_South640", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1557wv5/take_home_assessments_during_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1557wv5/take_home_assessments_during_interviews/", "subreddit_subscribers": 955923, "created_utc": 1689898259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im graduating in December from my undergrad, but I feel like all the projects I've done are pretty fairly boring and very cookie cutter. Because I don't go to a top school with great gpa, I want to make up for it by having something that the interviewer might think it's worthwhile to pick my brain on it. \n\nThe problem isn't that I can't find what to do, but I'm not sure how much of my projects should be \"inspired\" from the sample projects (like the ones here: https://github.com/firmai/financial-machine-learning). \n\nFor example, I want to make a project where I can scrape the financial data from ground up, ETL, and develop a ~~stock price~~ predictive model using LSTM. Im sure this could be useful in self learning, but it would it look identical to 500 other applicants who are basically doing something similar. Holding everything constant, if I were a hiring manager, I would hire the student who went to a nicer school. \n\nSo I guess my question is how can I outshine the competition? Is my only option to be realistic and work at less prestigious companies for a couple of years and work my way up, or is there something I can do right now?", "author_fullname": "t2_a0cov6p4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's an ML project that will really impress a hiring manager?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155wopr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689966748.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689965653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im graduating in December from my undergrad, but I feel like all the projects I&amp;#39;ve done are pretty fairly boring and very cookie cutter. Because I don&amp;#39;t go to a top school with great gpa, I want to make up for it by having something that the interviewer might think it&amp;#39;s worthwhile to pick my brain on it. &lt;/p&gt;\n\n&lt;p&gt;The problem isn&amp;#39;t that I can&amp;#39;t find what to do, but I&amp;#39;m not sure how much of my projects should be &amp;quot;inspired&amp;quot; from the sample projects (like the ones here: &lt;a href=\"https://github.com/firmai/financial-machine-learning\"&gt;https://github.com/firmai/financial-machine-learning&lt;/a&gt;). &lt;/p&gt;\n\n&lt;p&gt;For example, I want to make a project where I can scrape the financial data from ground up, ETL, and develop a &lt;del&gt;stock price&lt;/del&gt; predictive model using LSTM. Im sure this could be useful in self learning, but it would it look identical to 500 other applicants who are basically doing something similar. Holding everything constant, if I were a hiring manager, I would hire the student who went to a nicer school. &lt;/p&gt;\n\n&lt;p&gt;So I guess my question is how can I outshine the competition? Is my only option to be realistic and work at less prestigious companies for a couple of years and work my way up, or is there something I can do right now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0S9zym0hVNVlUspOZ9nRkI-BYThTOQEt2kYFMxazSZI.jpg?auto=webp&amp;s=c31f76da77d44608379e1b951072601c158aacad", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/0S9zym0hVNVlUspOZ9nRkI-BYThTOQEt2kYFMxazSZI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0d05551c870511f45d867e7488e8cecf55fa9c2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/0S9zym0hVNVlUspOZ9nRkI-BYThTOQEt2kYFMxazSZI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be3ff10c2c0ee166b0345cfb9ca1622af13dc639", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/0S9zym0hVNVlUspOZ9nRkI-BYThTOQEt2kYFMxazSZI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0f426ca2a08f1d845be1a7d05150a87bd982c801", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/0S9zym0hVNVlUspOZ9nRkI-BYThTOQEt2kYFMxazSZI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f36755817c361f52f880e90433e801763dca9a50", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/0S9zym0hVNVlUspOZ9nRkI-BYThTOQEt2kYFMxazSZI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=36dbf56eae558ec880fb66bc94898de7a73b51a0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/0S9zym0hVNVlUspOZ9nRkI-BYThTOQEt2kYFMxazSZI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ee423b77f0e7f20383a7870746ca44aa05062054", "width": 1080, "height": 540}], "variants": {}, "id": "_jPKGeHe58rPplBkiptBj56cbKh5LmlA_dxUhKSYGMA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155wopr", "is_robot_indexable": true, "report_reasons": null, "author": "KenseiNoodle", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155wopr/whats_an_ml_project_that_will_really_impress_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155wopr/whats_an_ml_project_that_will_really_impress_a/", "subreddit_subscribers": 955923, "created_utc": 1689965653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Guys, I have started learning Data Science on my own. I bought 3 courses on Udemy and am going through the lessons in order.\n\nI have a Bachelor's degree in Mechanical Engineering, but I realized late that I have a heart for Data Science, because in the future I want to work with artificial intelligence, develop new software based on AI. Maybe even create my own SaaS.\n\nMy strategy is as follows:\n1. Take all 3 courses\n2. Start creating simple projects and upload them to GitHub\n3. Gradually build a portfolio\n4. Search for a job\n\nIMPORTANT: Guys, how realistic is it for a self-taught Data Science student to find a job. I am very afraid that I will have to go to university again. Is it possible to learn everything myself or will the job necessarily require a diploma?\n\nMoreover, I appeal to experienced Data Scientists, guys advise me how best to develop in this field. Imagine if you were asked the question \"How would you start your way if you had to start all over again?...\".\n\nThat's all for now, I'd be honored for everyone's response. Any opinion is valuable to me, I respect each of you very much. You've done well.", "author_fullname": "t2_eiqw1xpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guys, I\u2019m completely beginner in Data Science. I need to hear opinion from experienced Data Scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155swu8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689957029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys, I have started learning Data Science on my own. I bought 3 courses on Udemy and am going through the lessons in order.&lt;/p&gt;\n\n&lt;p&gt;I have a Bachelor&amp;#39;s degree in Mechanical Engineering, but I realized late that I have a heart for Data Science, because in the future I want to work with artificial intelligence, develop new software based on AI. Maybe even create my own SaaS.&lt;/p&gt;\n\n&lt;p&gt;My strategy is as follows:\n1. Take all 3 courses\n2. Start creating simple projects and upload them to GitHub\n3. Gradually build a portfolio\n4. Search for a job&lt;/p&gt;\n\n&lt;p&gt;IMPORTANT: Guys, how realistic is it for a self-taught Data Science student to find a job. I am very afraid that I will have to go to university again. Is it possible to learn everything myself or will the job necessarily require a diploma?&lt;/p&gt;\n\n&lt;p&gt;Moreover, I appeal to experienced Data Scientists, guys advise me how best to develop in this field. Imagine if you were asked the question &amp;quot;How would you start your way if you had to start all over again?...&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s all for now, I&amp;#39;d be honored for everyone&amp;#39;s response. Any opinion is valuable to me, I respect each of you very much. You&amp;#39;ve done well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155swu8", "is_robot_indexable": true, "report_reasons": null, "author": "Brave_Cup9196", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155swu8/guys_im_completely_beginner_in_data_science_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155swu8/guys_im_completely_beginner_in_data_science_i/", "subreddit_subscribers": 955923, "created_utc": 1689957029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ahkaodsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a Google Sheets formula that lets you do data analysis in Sheets using GPT-4", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_155q2bn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/gncwydpnybdb1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/gncwydpnybdb1/DASH_96.mp4", "dash_url": "https://v.redd.it/gncwydpnybdb1/DASHPlaylist.mpd?a=1692567496%2CNzA2MmFmM2M5OTlhMDI0N2E1Yjg4NDA2MWMzZjEzMDZhNmI1ZWZlNDdjMzI3NTAxYjFiMzU4MmQ1NTIwZmRkZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 45, "hls_url": "https://v.redd.it/gncwydpnybdb1/HLSPlaylist.m3u8?a=1692567496%2CMWJmYWY3ZDY0ZDNjOWU1ZmE2ZWEyZmU1ZjNkYTZhOTk5MmY5MGQ4NDhiZWU2NDA4YjkwZTY0ZWVmMjNlZTZlMA%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GiIkU2SstRZiOPl1HqCHRkBK-sA7LGOVkGvEUZbGhYs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689950750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/gncwydpnybdb1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?format=pjpg&amp;auto=webp&amp;s=b158ae91ffef5013422c17c37ff263bb8d13b55c", "width": 3840, "height": 2160}, "resolutions": [{"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=faf43c42436bcdf48bc279ae3a2bb8b085c885a5", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=18fafee16f61c811e4d0f95f3dde59f2b1601a7d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=626d8a2ef1e63d3f5c39105e376166af3f65a433", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=12051331f9fe9ea9834775e36a7314eb37eb70ab", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4434ef3faf0560aabe713597dad7b9aa22640c90", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/4O_twz22eDxyhV8NNJVGG_moJLwT6YO1a0z2CdTxeQo.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a665c71e3bf4993e89f99aa8650955b2725b36c8", "width": 1080, "height": 607}], "variants": {}, "id": "y-XNZov1Dq9ICv2SudihmZ7Jdg_KL1ge6fAQjbeQDeo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "155q2bn", "is_robot_indexable": true, "report_reasons": null, "author": "sheetsguru", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155q2bn/i_made_a_google_sheets_formula_that_lets_you_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/gncwydpnybdb1", "subreddit_subscribers": 955923, "created_utc": 1689950750.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/gncwydpnybdb1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/gncwydpnybdb1/DASH_96.mp4", "dash_url": "https://v.redd.it/gncwydpnybdb1/DASHPlaylist.mpd?a=1692567496%2CNzA2MmFmM2M5OTlhMDI0N2E1Yjg4NDA2MWMzZjEzMDZhNmI1ZWZlNDdjMzI3NTAxYjFiMzU4MmQ1NTIwZmRkZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 45, "hls_url": "https://v.redd.it/gncwydpnybdb1/HLSPlaylist.m3u8?a=1692567496%2CMWJmYWY3ZDY0ZDNjOWU1ZmE2ZWEyZmU1ZjNkYTZhOTk5MmY5MGQ4NDhiZWU2NDA4YjkwZTY0ZWVmMjNlZTZlMA%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_17e0bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone a Data Scientist in the Mining industry? What insights or industry-specifics tips can you give us!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155nzgg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689945904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155nzgg", "is_robot_indexable": true, "report_reasons": null, "author": "ayeitsdeano", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155nzgg/is_anyone_a_data_scientist_in_the_mining_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155nzgg/is_anyone_a_data_scientist_in_the_mining_industry/", "subreddit_subscribers": 955923, "created_utc": 1689945904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So basically I'm going to get a major degree in data science, it's basically computing statistics and data engineering combined. \n\n\nMy question is... Is this field already oversaturated in your country or it's only oversaturated with online- courses people? \n\nBecause really, I'm from a bachelor in economics and I could simply pursue a finance major, but I like statistics and I would love working in an international company/ organisation. \n\nI know that probably my market is not the same as yours, but in my country data science is just born, so data about it are basically non existent. \n\nSo, I don't know? Please give me your knowledge?", "author_fullname": "t2_9f9o8ytt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science major", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155wx0i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689966151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically I&amp;#39;m going to get a major degree in data science, it&amp;#39;s basically computing statistics and data engineering combined. &lt;/p&gt;\n\n&lt;p&gt;My question is... Is this field already oversaturated in your country or it&amp;#39;s only oversaturated with online- courses people? &lt;/p&gt;\n\n&lt;p&gt;Because really, I&amp;#39;m from a bachelor in economics and I could simply pursue a finance major, but I like statistics and I would love working in an international company/ organisation. &lt;/p&gt;\n\n&lt;p&gt;I know that probably my market is not the same as yours, but in my country data science is just born, so data about it are basically non existent. &lt;/p&gt;\n\n&lt;p&gt;So, I don&amp;#39;t know? Please give me your knowledge?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155wx0i", "is_robot_indexable": true, "report_reasons": null, "author": "Urom99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155wx0i/data_science_major/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155wx0i/data_science_major/", "subreddit_subscribers": 955923, "created_utc": 1689966151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just started a new position at a company so far they have been creating the dashboard from scratch with react. They are looking to create custom charts, tables, and graphs for the sales teams and managers. Was wondering if it is better to use an external tool to develop these?", "author_fullname": "t2_130676", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it better to create an internal tool for data analysis or use an external tool such as power bi or tableau?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155rgon", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689953836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just started a new position at a company so far they have been creating the dashboard from scratch with react. They are looking to create custom charts, tables, and graphs for the sales teams and managers. Was wondering if it is better to use an external tool to develop these?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155rgon", "is_robot_indexable": true, "report_reasons": null, "author": "A_GOLD_FISH", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155rgon/is_it_better_to_create_an_internal_tool_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155rgon/is_it_better_to_create_an_internal_tool_for_data/", "subreddit_subscribers": 955923, "created_utc": 1689953836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am going to begin an internship for a small company who don't have a data science department. We are the first ones to be working on their data. (They are not paying us)\n\n They are going to provide us with the data of students and basically we have to analyze it, it's basically an list of potential candidates who are willing to go for foreign education. I have no idea where to begin.\n\nNow I know the basics of data science and I have worked on datasets like iris which consists of basic things like flower size and etc. That was completely in python and just had to visualize and analyze the data?\n\nHow should I be preparing for this? It has to be done in excel.", "author_fullname": "t2_fl0rx7lx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to analyze student data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155o4xm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689946883.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689946267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am going to begin an internship for a small company who don&amp;#39;t have a data science department. We are the first ones to be working on their data. (They are not paying us)&lt;/p&gt;\n\n&lt;p&gt;They are going to provide us with the data of students and basically we have to analyze it, it&amp;#39;s basically an list of potential candidates who are willing to go for foreign education. I have no idea where to begin.&lt;/p&gt;\n\n&lt;p&gt;Now I know the basics of data science and I have worked on datasets like iris which consists of basic things like flower size and etc. That was completely in python and just had to visualize and analyze the data?&lt;/p&gt;\n\n&lt;p&gt;How should I be preparing for this? It has to be done in excel.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155o4xm", "is_robot_indexable": true, "report_reasons": null, "author": "stupidlyaccurate", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155o4xm/how_to_analyze_student_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155o4xm/how_to_analyze_student_data/", "subreddit_subscribers": 955923, "created_utc": 1689946267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2lz97iux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some help with accumulation curve", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_155bezu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3MoeX-3Fk0aqD7YVMsUt73EiH8s1xfGsQC3x-GCCryY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689908112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ng4lc1jdg8db1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?auto=webp&amp;s=8df10f15995798dbdcc2d62367c20e21ed1449c6", "width": 1000, "height": 751}, "resolutions": [{"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=64b4286954e782c8ca762ccc813c56d03a50fd97", "width": 108, "height": 81}, {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e47a571e57dfeba96472f8bf67284ad6d0398a8d", "width": 216, "height": 162}, {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=64c81ff4d612ffa4e356c2a28aefc543e934a39e", "width": 320, "height": 240}, {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b992a98645dbd855e1830798add9c91d3b6b3950", "width": 640, "height": 480}, {"url": "https://preview.redd.it/ng4lc1jdg8db1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=321f2bd15c69c0be52ea98a69011d3fbf235403b", "width": 960, "height": 720}], "variants": {}, "id": "wI2Gr6DzUMdhM9C3K31oI7SrS20yiL87WglYD-jkjV8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "155bezu", "is_robot_indexable": true, "report_reasons": null, "author": "artanos44", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155bezu/need_some_help_with_accumulation_curve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ng4lc1jdg8db1.png", "subreddit_subscribers": 955923, "created_utc": 1689908112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Would you hire someone with more Probability and Statistics under their belt or someone with more computational experience? Asking bc I\u2019m worried I\u2019m not cut out for DS as an applied stats major. I code slow and never got to data structures. \n\nAlso do you guys use SAS and R a lot?", "author_fullname": "t2_rwtwk2fa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mathematician vs Computer Scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155wmm1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689965520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would you hire someone with more Probability and Statistics under their belt or someone with more computational experience? Asking bc I\u2019m worried I\u2019m not cut out for DS as an applied stats major. I code slow and never got to data structures. &lt;/p&gt;\n\n&lt;p&gt;Also do you guys use SAS and R a lot?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155wmm1", "is_robot_indexable": true, "report_reasons": null, "author": "Bruhhhhhhhhhhhhs", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155wmm1/mathematician_vs_computer_scientists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155wmm1/mathematician_vs_computer_scientists/", "subreddit_subscribers": 955923, "created_utc": 1689965520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As I'm building IT architecture for a startup, I've learned a lot about managing large databases. I want to share my insights and discoveries to perhaps help someone who might be facing similar challenges. In this article I reveal the critical aspects of database management and some practical tips to navigate common obstacles.\n\n&amp;#x200B;\n\n# How to manage large databases\n\nManaging databases can pose a fair share of challenges, primarily due to the size and intricacy of the data involved. Companies frequently grapple with how to effectively handle and manage the impact of data growth, especially when the database management systems struggle to keep pace.\n\nProblems sometimes stem from disregarded issues during the initial stages of the process. This could be because the prevailing technology was presumed to inherently manage these complexities. Hence, the secret lies in having a robust plan for handling large, intricate databases, particularly when significant data growth is expected, whether predictably or otherwise.\n\n# Data Size is Significant\n\nThe size of a database is pivotal as it impacts both performance and management approaches. The way data is processed and stored influences how the database is managed, and this holds true for data both in transit and at rest. For many large firms, data is priceless, and an increase in data could drastically alter their procedures. Therefore, planning ahead for data growth in a database is vital.\n\nIn my work with databases, I've witnessed customers struggle with performance issues and managing considerable data growth. Questions often arise, such as whether to normalize or denormalize the tables.\n\n# The Art of Normalizing Tables\n\nTable normalization is beneficial as it safeguards data integrity, curtails redundancy, and organizes data more efficiently for management, analysis, and extraction. However, normalized tables can come with performance penalties and potentially slow down queries due to the need for multiple joins when retrieving data.\n\nConversely, denormalized tables optimize retrieval primarily through indexing or using the primary key, allowing data to be stored in a buffer for faster access than performing multiple disk seeks. But they compromise data integrity and can lead to rapid database growth.\n\n# Understanding Database Complexity\n\nPerformance penalties can often arise with large and complex databases. In these scenarios, it is often more effective to manage and process these complex calculations using backend programming languages, rather than utilizing the database directly.\n\n# Selecting the Right Database Engine\n\nThe performance of a database server hinges on the data structure used and how it interacts with the queries made and the data retrieved from the table. The specific engine\u2019s data structure and the queries you apply to retrieve targeted data directly impact your database server\u2019s performance.\n\nWhen dealing with a multitude of databases, using the right engine in combination with your queries and the data you need to store and retrieve can yield excellent performance. However, this necessitates a comprehensive analysis of your needs to establish the right database environment.\n\n# Right Tools for Large Databases\n\nManaging a large database can be challenging without a robust platform to support the process. Even with skilled database engineers, there\u2019s always a risk of human error with the database server in use. Any misstep in altering configuration parameters or variables could lead to significant changes, potentially reducing the server\u2019s performance.\n\n# Some tips for working with databases:\n\n&amp;#x200B;\n\n* Pick the right data types for your columns. It saves space and makes queries run faster.\n* Use normalization rules to keep data tidy and avoid repeats.\n* Regularly maintain your database. Think about tasks like rebuilding indexes and updating stats.\n* Add indexes to columns you query a lot to speed things up, but don't go overboard.\n* Write neat database queries with the right joins and filters. Keep an eye on how they perform.\n* Keep a regular backup of your database for safety. Don't forget to check the backups are okay.\n* Use good security to keep your database safe from unauthorized access.\n* Use tools to keep tabs on how your database is performing. Spot and fix bottlenecks early.\n* Build your database to grow. It'll make adding more data easier down the line.\n* Keep track of your database layout, settings, and data flow. It helps when you need to solve problems.\n\n&amp;#x200B;\n\nTo conclude, managing large databases in 2023 necessitates not only understanding the fundamental concepts but also the use of the right tools and strategies. Through careful planning and strategic execution, you can surmount the complexities of large database management, ensuring optimal performance and robust data integrity.\n\n&amp;#x200B;\n\nI share more articles like this in my blog. If you want to check it out, visit: [https://ainsys.com/blog/2023/07/13/databases/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=data\\_science&amp;utm\\_content=databases&amp;utm\\_term=BigData](https://ainsys.com/blog/2023/07/13/databases/?utm_source=linkedin&amp;utm_medium=social&amp;utm_campaign=data_science&amp;utm_content=databases&amp;utm_term=BigData)", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to manage large databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155pmgh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689949763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As I&amp;#39;m building IT architecture for a startup, I&amp;#39;ve learned a lot about managing large databases. I want to share my insights and discoveries to perhaps help someone who might be facing similar challenges. In this article I reveal the critical aspects of database management and some practical tips to navigate common obstacles.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;How to manage large databases&lt;/h1&gt;\n\n&lt;p&gt;Managing databases can pose a fair share of challenges, primarily due to the size and intricacy of the data involved. Companies frequently grapple with how to effectively handle and manage the impact of data growth, especially when the database management systems struggle to keep pace.&lt;/p&gt;\n\n&lt;p&gt;Problems sometimes stem from disregarded issues during the initial stages of the process. This could be because the prevailing technology was presumed to inherently manage these complexities. Hence, the secret lies in having a robust plan for handling large, intricate databases, particularly when significant data growth is expected, whether predictably or otherwise.&lt;/p&gt;\n\n&lt;h1&gt;Data Size is Significant&lt;/h1&gt;\n\n&lt;p&gt;The size of a database is pivotal as it impacts both performance and management approaches. The way data is processed and stored influences how the database is managed, and this holds true for data both in transit and at rest. For many large firms, data is priceless, and an increase in data could drastically alter their procedures. Therefore, planning ahead for data growth in a database is vital.&lt;/p&gt;\n\n&lt;p&gt;In my work with databases, I&amp;#39;ve witnessed customers struggle with performance issues and managing considerable data growth. Questions often arise, such as whether to normalize or denormalize the tables.&lt;/p&gt;\n\n&lt;h1&gt;The Art of Normalizing Tables&lt;/h1&gt;\n\n&lt;p&gt;Table normalization is beneficial as it safeguards data integrity, curtails redundancy, and organizes data more efficiently for management, analysis, and extraction. However, normalized tables can come with performance penalties and potentially slow down queries due to the need for multiple joins when retrieving data.&lt;/p&gt;\n\n&lt;p&gt;Conversely, denormalized tables optimize retrieval primarily through indexing or using the primary key, allowing data to be stored in a buffer for faster access than performing multiple disk seeks. But they compromise data integrity and can lead to rapid database growth.&lt;/p&gt;\n\n&lt;h1&gt;Understanding Database Complexity&lt;/h1&gt;\n\n&lt;p&gt;Performance penalties can often arise with large and complex databases. In these scenarios, it is often more effective to manage and process these complex calculations using backend programming languages, rather than utilizing the database directly.&lt;/p&gt;\n\n&lt;h1&gt;Selecting the Right Database Engine&lt;/h1&gt;\n\n&lt;p&gt;The performance of a database server hinges on the data structure used and how it interacts with the queries made and the data retrieved from the table. The specific engine\u2019s data structure and the queries you apply to retrieve targeted data directly impact your database server\u2019s performance.&lt;/p&gt;\n\n&lt;p&gt;When dealing with a multitude of databases, using the right engine in combination with your queries and the data you need to store and retrieve can yield excellent performance. However, this necessitates a comprehensive analysis of your needs to establish the right database environment.&lt;/p&gt;\n\n&lt;h1&gt;Right Tools for Large Databases&lt;/h1&gt;\n\n&lt;p&gt;Managing a large database can be challenging without a robust platform to support the process. Even with skilled database engineers, there\u2019s always a risk of human error with the database server in use. Any misstep in altering configuration parameters or variables could lead to significant changes, potentially reducing the server\u2019s performance.&lt;/p&gt;\n\n&lt;h1&gt;Some tips for working with databases:&lt;/h1&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Pick the right data types for your columns. It saves space and makes queries run faster.&lt;/li&gt;\n&lt;li&gt;Use normalization rules to keep data tidy and avoid repeats.&lt;/li&gt;\n&lt;li&gt;Regularly maintain your database. Think about tasks like rebuilding indexes and updating stats.&lt;/li&gt;\n&lt;li&gt;Add indexes to columns you query a lot to speed things up, but don&amp;#39;t go overboard.&lt;/li&gt;\n&lt;li&gt;Write neat database queries with the right joins and filters. Keep an eye on how they perform.&lt;/li&gt;\n&lt;li&gt;Keep a regular backup of your database for safety. Don&amp;#39;t forget to check the backups are okay.&lt;/li&gt;\n&lt;li&gt;Use good security to keep your database safe from unauthorized access.&lt;/li&gt;\n&lt;li&gt;Use tools to keep tabs on how your database is performing. Spot and fix bottlenecks early.&lt;/li&gt;\n&lt;li&gt;Build your database to grow. It&amp;#39;ll make adding more data easier down the line.&lt;/li&gt;\n&lt;li&gt;Keep track of your database layout, settings, and data flow. It helps when you need to solve problems.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To conclude, managing large databases in 2023 necessitates not only understanding the fundamental concepts but also the use of the right tools and strategies. Through careful planning and strategic execution, you can surmount the complexities of large database management, ensuring optimal performance and robust data integrity.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I share more articles like this in my blog. If you want to check it out, visit: &lt;a href=\"https://ainsys.com/blog/2023/07/13/databases/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_science&amp;amp;utm_content=databases&amp;amp;utm_term=BigData\"&gt;https://ainsys.com/blog/2023/07/13/databases/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_science&amp;amp;utm_content=databases&amp;amp;utm_term=BigData&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;s=8a29f85fd320507a70ec9694b971f494352d2655", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155pmgh", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155pmgh/how_to_manage_large_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155pmgh/how_to_manage_large_databases/", "subreddit_subscribers": 955923, "created_utc": 1689949763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nhttps://i.redd.it/z3fp8o9ol9db1.gif", "author_fullname": "t2_h3a1v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] Nested Bayesian Sampling is Awesome!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 130, "top_awarded_type": null, "hide_score": false, "media_metadata": {"z3fp8o9ol9db1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 100, "x": 108, "u": "https://preview.redd.it/z3fp8o9ol9db1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=91c590454c04b75dba540612c2fe4a94dd3a3ffd"}, {"y": 201, "x": 216, "u": "https://preview.redd.it/z3fp8o9ol9db1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=95e303124668869bcc2c928cd81a98c84f8b1fe0"}, {"y": 299, "x": 320, "u": "https://preview.redd.it/z3fp8o9ol9db1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=4aec1b0b986238ed968fb63e58385cee45226000"}], "s": {"y": 374, "gif": "https://i.redd.it/z3fp8o9ol9db1.gif", "mp4": "https://preview.redd.it/z3fp8o9ol9db1.gif?format=mp4&amp;s=15dd6912835c511e30d68b164559cd2e3c46672a", "x": 400}, "id": "z3fp8o9ol9db1"}}, "name": "t3_155fy0l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/V25PemQFdpjWNlHKHsDPR0eOTRa6Lqr7Iu7-glM31Hg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689922014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/z3fp8o9ol9db1.gif\"&gt;https://i.redd.it/z3fp8o9ol9db1.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155fy0l", "is_robot_indexable": true, "report_reasons": null, "author": "pmocz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155fy0l/oc_nested_bayesian_sampling_is_awesome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155fy0l/oc_nested_bayesian_sampling_is_awesome/", "subreddit_subscribers": 955923, "created_utc": 1689922014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I have a friend who is a city planner. One day, he was tasked with reassessing the location suitability of thousands of gas stations in the city, needing to find the positions of the k-nearest gas stations to each one.\n\nHow can we find the nearest k stations with little time? This is a practical application scenario of the k-nearest neighbors problem.\n\nAs such, he came to me for help, hoping I could provide a high-performance solution.\n\nSo I write down this article and which will guide you on efficiently solving the [k-nearest neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) problem using NumPy. By comparing it with a Python iterative solution, we will demonstrate the powerful performance of NumPy.\n\nIn this article, we will delve into utilizing advanced NumPy features, such as broadcasting, fancy indexing, and sorting, to implement a high-performance k-nearest neighbors algorithm.\n\nAfter reading this article, you will able to:\n\n* Understand the k-nearest neighbors problem and its practical application scenarios\n* Learn how to use the NumPy library to solve the k-nearest neighbors problem\n* Understand in-depth how features such as NumPy broadcasting, fancy indexing, and sorting play a role in the algorithm\n* Compare the performance of NumPy with a Python iterative solution, exploring why NumPy is superior\n\nLet\u2019s delve into the high-performance world of NumPy together, exploring how we can solve the k-nearest neighbors problem more quickly and effectively using only NumPy.\n\nFor more details:\n\n[https://towardsdatascience.com/efficient-k-nearest-neighbors-k-nn-solutions-with-numpy-58cbac2a0971](https://towardsdatascience.com/efficient-k-nearest-neighbors-k-nn-solutions-with-numpy-58cbac2a0971)", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Efficient k-Nearest Neighbors (k-NN) Solutions with NumPy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15595e6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689901591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a friend who is a city planner. One day, he was tasked with reassessing the location suitability of thousands of gas stations in the city, needing to find the positions of the k-nearest gas stations to each one.&lt;/p&gt;\n\n&lt;p&gt;How can we find the nearest k stations with little time? This is a practical application scenario of the k-nearest neighbors problem.&lt;/p&gt;\n\n&lt;p&gt;As such, he came to me for help, hoping I could provide a high-performance solution.&lt;/p&gt;\n\n&lt;p&gt;So I write down this article and which will guide you on efficiently solving the &lt;a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\"&gt;k-nearest neighbors&lt;/a&gt; problem using NumPy. By comparing it with a Python iterative solution, we will demonstrate the powerful performance of NumPy.&lt;/p&gt;\n\n&lt;p&gt;In this article, we will delve into utilizing advanced NumPy features, such as broadcasting, fancy indexing, and sorting, to implement a high-performance k-nearest neighbors algorithm.&lt;/p&gt;\n\n&lt;p&gt;After reading this article, you will able to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Understand the k-nearest neighbors problem and its practical application scenarios&lt;/li&gt;\n&lt;li&gt;Learn how to use the NumPy library to solve the k-nearest neighbors problem&lt;/li&gt;\n&lt;li&gt;Understand in-depth how features such as NumPy broadcasting, fancy indexing, and sorting play a role in the algorithm&lt;/li&gt;\n&lt;li&gt;Compare the performance of NumPy with a Python iterative solution, exploring why NumPy is superior&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Let\u2019s delve into the high-performance world of NumPy together, exploring how we can solve the k-nearest neighbors problem more quickly and effectively using only NumPy.&lt;/p&gt;\n\n&lt;p&gt;For more details:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://towardsdatascience.com/efficient-k-nearest-neighbors-k-nn-solutions-with-numpy-58cbac2a0971\"&gt;https://towardsdatascience.com/efficient-k-nearest-neighbors-k-nn-solutions-with-numpy-58cbac2a0971&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15595e6", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15595e6/efficient_knearest_neighbors_knn_solutions_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15595e6/efficient_knearest_neighbors_knn_solutions_with/", "subreddit_subscribers": 955923, "created_utc": 1689901591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just landed an analytics engineer role (coming from a nursing background)\n\nLooking to get into DS, specifically with machine learning for healthcare.\n\nI have a masters in health informatics however want to continue academics (VA benefits + tuition reimbursement).\n\nAny programs worth looking into? \nI was looking at OMSA and UT Austin DS, UiUC CS.\n\nI applied to MCIT online upenn, however feel it may not be worth the price tag.\n\nTIA", "author_fullname": "t2_m8a5u0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Grad school programs worthwhile for DS and AI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1556f12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689894581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just landed an analytics engineer role (coming from a nursing background)&lt;/p&gt;\n\n&lt;p&gt;Looking to get into DS, specifically with machine learning for healthcare.&lt;/p&gt;\n\n&lt;p&gt;I have a masters in health informatics however want to continue academics (VA benefits + tuition reimbursement).&lt;/p&gt;\n\n&lt;p&gt;Any programs worth looking into? \nI was looking at OMSA and UT Austin DS, UiUC CS.&lt;/p&gt;\n\n&lt;p&gt;I applied to MCIT online upenn, however feel it may not be worth the price tag.&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1556f12", "is_robot_indexable": true, "report_reasons": null, "author": "AwkWORD47", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1556f12/grad_school_programs_worthwhile_for_ds_and_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1556f12/grad_school_programs_worthwhile_for_ds_and_ai/", "subreddit_subscribers": 955923, "created_utc": 1689894581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am building a product that will assist customers in their marketing/content delivery efforts. \n\nWe are collecting data on their content delivery and want to have a place on our platform where they can view analytics on this data. I really like the way Tableau looks, but the pricing does not work for us. \n\nWhat are the most popular free or open source options for adding analytics views to your website like this?", "author_fullname": "t2_bhbxzo8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best analytics dash to embed on site", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_155z3l0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689971071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building a product that will assist customers in their marketing/content delivery efforts. &lt;/p&gt;\n\n&lt;p&gt;We are collecting data on their content delivery and want to have a place on our platform where they can view analytics on this data. I really like the way Tableau looks, but the pricing does not work for us. &lt;/p&gt;\n\n&lt;p&gt;What are the most popular free or open source options for adding analytics views to your website like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155z3l0", "is_robot_indexable": true, "report_reasons": null, "author": "Poet_Plastic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155z3l0/best_analytics_dash_to_embed_on_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155z3l0/best_analytics_dash_to_embed_on_site/", "subreddit_subscribers": 955923, "created_utc": 1689971071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, newbie here. I think I'm going to pursue a master's degree in data science. So, meanwhile, if you guys can share with me some good resources to learn a bit about it on my own, that would be awesome. Please and thanks.", "author_fullname": "t2_5jq2s558", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for newbie", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_155z17j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689970918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, newbie here. I think I&amp;#39;m going to pursue a master&amp;#39;s degree in data science. So, meanwhile, if you guys can share with me some good resources to learn a bit about it on my own, that would be awesome. Please and thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155z17j", "is_robot_indexable": true, "report_reasons": null, "author": "darkk_paradise", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155z17j/resources_for_newbie/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155z17j/resources_for_newbie/", "subreddit_subscribers": 955923, "created_utc": 1689970918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a former data engineer turned Product Manager but I still love querying data and doing analyses for my product decisions. I\u2019ve tried using ChatGPT to try remembering SQL syntax but it\u2019s never organized in these playground environments that I\u2019ve seen. I\u2019m constantly losing information, rerunning the same prompts, and can\u2019t write notes to myself. \n\nThis had me thinking about the many people who probably use ChatGPT to prepare for SQL interviews - I\u2019ve seen it a lot online. If I was prepping for an interview, I would want to stay organized and also write notes to myself on important areas to focus on. Right now, the ChatGPT playground environments just wouldn\u2019t cut it form. \n\nAI workbooks (free to use) could be a very good option for this. Here\u2019s some of the benefits I see: \n\n1. **Structured Querying:** Unlike playground environments, workbooks are a structured environment where I can organize my queries. I can easily revise and fine-tune prompts. Also the ChatGPT cells remember context from previous cells so I don\u2019t need to keep mentioning the dataset schema. \n2. **Annotations**: I love the idea of jotting down important insights, and tips in the workbook itself. AI Workbooks offers markdown support so I can have headings, outlines, and even attach images/GIFs. \n3. **Collaboration**: The workbook is easy to share with others - people who might have an interview coming can start with my workbook to get started and I can learn from other people\u2019s workbooks vice-versa. \n\nI\u2019m really excited about this product because it\u2019s free for personal use and has a lot of potential to change the way we work with ChatGPT. Curious what you all think!  \n\nLink to SQL Interview AI Workbook: [https://lastmileai.dev/workbooks/clkc3biiz004jphsrjddy8j7e](https://lastmileai.dev/workbooks/clkc3biiz004jphsrjddy8j7e) ", "author_fullname": "t2_w9l6pbm5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Level up SQL Interview Prep with AI Workbooks \u2013 ChatGPT + Annotations + Collaboration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_155ypfq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689970200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a former data engineer turned Product Manager but I still love querying data and doing analyses for my product decisions. I\u2019ve tried using ChatGPT to try remembering SQL syntax but it\u2019s never organized in these playground environments that I\u2019ve seen. I\u2019m constantly losing information, rerunning the same prompts, and can\u2019t write notes to myself. &lt;/p&gt;\n\n&lt;p&gt;This had me thinking about the many people who probably use ChatGPT to prepare for SQL interviews - I\u2019ve seen it a lot online. If I was prepping for an interview, I would want to stay organized and also write notes to myself on important areas to focus on. Right now, the ChatGPT playground environments just wouldn\u2019t cut it form. &lt;/p&gt;\n\n&lt;p&gt;AI workbooks (free to use) could be a very good option for this. Here\u2019s some of the benefits I see: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Structured Querying:&lt;/strong&gt; Unlike playground environments, workbooks are a structured environment where I can organize my queries. I can easily revise and fine-tune prompts. Also the ChatGPT cells remember context from previous cells so I don\u2019t need to keep mentioning the dataset schema. &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Annotations&lt;/strong&gt;: I love the idea of jotting down important insights, and tips in the workbook itself. AI Workbooks offers markdown support so I can have headings, outlines, and even attach images/GIFs. &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Collaboration&lt;/strong&gt;: The workbook is easy to share with others - people who might have an interview coming can start with my workbook to get started and I can learn from other people\u2019s workbooks vice-versa. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I\u2019m really excited about this product because it\u2019s free for personal use and has a lot of potential to change the way we work with ChatGPT. Curious what you all think!  &lt;/p&gt;\n\n&lt;p&gt;Link to SQL Interview AI Workbook: &lt;a href=\"https://lastmileai.dev/workbooks/clkc3biiz004jphsrjddy8j7e\"&gt;https://lastmileai.dev/workbooks/clkc3biiz004jphsrjddy8j7e&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/piLadtiGEDINDfK49VcqP5XyrmtrA-URcb8tZg2_uNo.jpg?auto=webp&amp;s=fab480b05538207da1a289d6e4f8412854bb63a7", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/piLadtiGEDINDfK49VcqP5XyrmtrA-URcb8tZg2_uNo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=576f31c87853d5847d2996a5b26aa167a42fe724", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/piLadtiGEDINDfK49VcqP5XyrmtrA-URcb8tZg2_uNo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ca410d49a02688a2e97537b25ba7dc16af7c1273", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/piLadtiGEDINDfK49VcqP5XyrmtrA-URcb8tZg2_uNo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a751c9bd4a3248e89ac2e21fb2baf7b2dfc4eb35", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/piLadtiGEDINDfK49VcqP5XyrmtrA-URcb8tZg2_uNo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec58051b649763fcd9954873f95a3b05505f008f", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/piLadtiGEDINDfK49VcqP5XyrmtrA-URcb8tZg2_uNo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=89e3c463a199d1f8ba1f19e94565951648a4cf76", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/piLadtiGEDINDfK49VcqP5XyrmtrA-URcb8tZg2_uNo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=58bdcfe7b5920da80be332a5ed8a5ebaef915a5b", "width": 1080, "height": 564}], "variants": {}, "id": "_oASEv_aXior2cYNDK_zDoapFp0xA1aKtqa80e80mh0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155ypfq", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableSky2801", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155ypfq/level_up_sql_interview_prep_with_ai_workbooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155ypfq/level_up_sql_interview_prep_with_ai_workbooks/", "subreddit_subscribers": 955923, "created_utc": 1689970200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all!\n\nOver the past few weeks, my colleagues and I have built a new feature in our JupyterLab plugin that allows you to converse with a chatbot contextualized with the code snippets in your notebooks. Notebooks can get large and complex quickly, so having a personal coding assistant as a partner at work, helping you find relevant information and answering your questions can be very helpful.\n\nhttps://i.redd.it/369gz1w04ddb1.gif\n\nThe technology draws background context from the snippets in your notebooks to help augment the responses from the AI. This means you can empower the chatbot with all the code you have written within JupyterLab notebooks.\n\nWith each response, the AI links you to relevant files and suggests follow-up questions based on the context of your conversation.\n\nWe base all of our engineering on community feedback, so feel free to reach out via [Discord](https://discord.gg/5AN7rVXEES) or our [support survey](https://getpieces.typeform.com/jupyterlab) with any questions or comments and we will be glad to help.\n\nIf you\u2019re interested, here\u2019s how to get started! It\u2019s just 3 easy steps and usually takes new users about 4 minutes.\n\n1. [Install Pieces OS](https://docs.pieces.app/installation-getting-started/what-am-i-installing): This is the background service that runs locally on your machine and connects Pieces applications and plugins.\n2. [Install the Pieces JupyterLab Extension](https://docs.pieces.app/extensions-plugins/jupyterlab#steps-to-install): This is the connective software that brings the power of Pieces straight to JupyterLab.\n3. In JupyterLab, open the Pieces plugin by selecting the \u201cP\u201d logo within the right side-bar. Then, switch from snippet view ( {} ) to the AI by clicking the little robot. ( \ud83e\udd16)\n\nWe\u2019re so enthusiastic about this new creation and love the feedback we have already received. Keep it coming! (There\u2019s also much more to this update than just the chatbot, you can find the full list of changes here!) After trying it out, what do you think?\n\n\\- Mason &amp; the Pieces for Developers Team &lt;3", "author_fullname": "t2_dc3rnec6l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Embedded GPT Assistant Contextualized by JupyterLab Notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"369gz1w04ddb1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/369gz1w04ddb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=849b0a609d485a0f194c4b620a21e7ec665190bb"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/369gz1w04ddb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=9af1c9428f038f42370dde653da0c1cc06a5e2ce"}, {"y": 179, "x": 320, "u": "https://preview.redd.it/369gz1w04ddb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=62a4f48cac0187b411e68ddf32fe3d4c23a6f566"}, {"y": 359, "x": 640, "u": "https://preview.redd.it/369gz1w04ddb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=4df4f5dfcf8594851e59f01f1a1824a49fe1a2e4"}], "s": {"y": 511, "gif": "https://i.redd.it/369gz1w04ddb1.gif", "mp4": "https://preview.redd.it/369gz1w04ddb1.gif?format=mp4&amp;s=338ed3b6de7cdd8178df88fc3cd7c699622c016c", "x": 909}, "id": "369gz1w04ddb1"}}, "name": "t3_155wrrd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tAgBKu_2OjvrfnT7Mt8JvpRA07Q1yJsXYel_oIwwHns.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689965843.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!&lt;/p&gt;\n\n&lt;p&gt;Over the past few weeks, my colleagues and I have built a new feature in our JupyterLab plugin that allows you to converse with a chatbot contextualized with the code snippets in your notebooks. Notebooks can get large and complex quickly, so having a personal coding assistant as a partner at work, helping you find relevant information and answering your questions can be very helpful.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/369gz1w04ddb1.gif\"&gt;https://i.redd.it/369gz1w04ddb1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The technology draws background context from the snippets in your notebooks to help augment the responses from the AI. This means you can empower the chatbot with all the code you have written within JupyterLab notebooks.&lt;/p&gt;\n\n&lt;p&gt;With each response, the AI links you to relevant files and suggests follow-up questions based on the context of your conversation.&lt;/p&gt;\n\n&lt;p&gt;We base all of our engineering on community feedback, so feel free to reach out via &lt;a href=\"https://discord.gg/5AN7rVXEES\"&gt;Discord&lt;/a&gt; or our &lt;a href=\"https://getpieces.typeform.com/jupyterlab\"&gt;support survey&lt;/a&gt; with any questions or comments and we will be glad to help.&lt;/p&gt;\n\n&lt;p&gt;If you\u2019re interested, here\u2019s how to get started! It\u2019s just 3 easy steps and usually takes new users about 4 minutes.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://docs.pieces.app/installation-getting-started/what-am-i-installing\"&gt;Install Pieces OS&lt;/a&gt;: This is the background service that runs locally on your machine and connects Pieces applications and plugins.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://docs.pieces.app/extensions-plugins/jupyterlab#steps-to-install\"&gt;Install the Pieces JupyterLab Extension&lt;/a&gt;: This is the connective software that brings the power of Pieces straight to JupyterLab.&lt;/li&gt;\n&lt;li&gt;In JupyterLab, open the Pieces plugin by selecting the \u201cP\u201d logo within the right side-bar. Then, switch from snippet view ( {} ) to the AI by clicking the little robot. ( \ud83e\udd16)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We\u2019re so enthusiastic about this new creation and love the feedback we have already received. Keep it coming! (There\u2019s also much more to this update than just the chatbot, you can find the full list of changes here!) After trying it out, what do you think?&lt;/p&gt;\n\n&lt;p&gt;- Mason &amp;amp; the Pieces for Developers Team &amp;lt;3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155wrrd", "is_robot_indexable": true, "report_reasons": null, "author": "masnwilliams", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155wrrd/an_embedded_gpt_assistant_contextualized_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155wrrd/an_embedded_gpt_assistant_contextualized_by/", "subreddit_subscribers": 955923, "created_utc": 1689965843.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think dimensionality reduction is a great way to start a task and always a great way to visualize for customers etc. I like PCA  for its interpretability, but it of course has other drawbacks. Other techniques like t-sne gives great results. But what did it actually do? How are different parts of the reduced space different in its mapping? How tight are actually a clusters? When there are many dimensions being reduced this gets really tricky.\n\nHow do you solve this? How do makes sense of dimension reducing techniques more capable than PCA? I haven't seen a lot out there and would love to see what powerful tools are out there.\n\nPlaying around on my own I did this:\n\n[https://github.com/erikbergh/interpretable\\_dim\\_reduction](https://github.com/erikbergh/interpretable_dim_reduction)\n\nWhat is out there that achieves something similar? Papers are of course interesting. But mainly something already implemented in a python package would be the best.", "author_fullname": "t2_11xlzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interpret dimensionality reduction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155wros", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689965838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think dimensionality reduction is a great way to start a task and always a great way to visualize for customers etc. I like PCA  for its interpretability, but it of course has other drawbacks. Other techniques like t-sne gives great results. But what did it actually do? How are different parts of the reduced space different in its mapping? How tight are actually a clusters? When there are many dimensions being reduced this gets really tricky.&lt;/p&gt;\n\n&lt;p&gt;How do you solve this? How do makes sense of dimension reducing techniques more capable than PCA? I haven&amp;#39;t seen a lot out there and would love to see what powerful tools are out there.&lt;/p&gt;\n\n&lt;p&gt;Playing around on my own I did this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/erikbergh/interpretable_dim_reduction\"&gt;https://github.com/erikbergh/interpretable_dim_reduction&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What is out there that achieves something similar? Papers are of course interesting. But mainly something already implemented in a python package would be the best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?auto=webp&amp;s=454271268771ae63c20b2ebcd8d9df05115ac2ea", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78cb5d537754a0da97cb7e42171fd221440404c2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c05470ee11a42ee79a800dc6d525adc4fb9ed2cf", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=035fb57eaca8b064ade2c0eb72e052f56b9312a1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=954aed5f3c90c98961d602422c07cd9ad5b2f199", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a1c0c64557ad05f9217c89960ae0d4ed5645d27", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4Z3tsXekDxb-CvhpdsLjGhDfqNSYRXBcYyGYKSeyAhc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49befd0ee223ddf80db0ca24baf2d4b7a4d117af", "width": 1080, "height": 540}], "variants": {}, "id": "34EwOPgk44FKNkZzHlVGaXgo3yjjhhc402Mc4rN1Wrc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155wros", "is_robot_indexable": true, "report_reasons": null, "author": "tvaap", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155wros/interpret_dimensionality_reduction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155wros/interpret_dimensionality_reduction/", "subreddit_subscribers": 955923, "created_utc": 1689965838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My dataset is now at 5000 records which is determined to be not enough to build a model yet. Target is binary (default or not default)\n\nHowever, I want to find the cuts in variables that are highly predictive to create filter rules in our business underwriting process. For example, if variable A &gt; 0 &amp; variable B &lt; 10 &amp; variable C is null then default rate is 80% and we can reject customers up front.\n\nI thought of using decision trees to find those cuts and combination of variables. But do you have another ideas?", "author_fullname": "t2_6hyqu90j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Find a combination of variables cut that is predictive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155wl9n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689965440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My dataset is now at 5000 records which is determined to be not enough to build a model yet. Target is binary (default or not default)&lt;/p&gt;\n\n&lt;p&gt;However, I want to find the cuts in variables that are highly predictive to create filter rules in our business underwriting process. For example, if variable A &amp;gt; 0 &amp;amp; variable B &amp;lt; 10 &amp;amp; variable C is null then default rate is 80% and we can reject customers up front.&lt;/p&gt;\n\n&lt;p&gt;I thought of using decision trees to find those cuts and combination of variables. But do you have another ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "155wl9n", "is_robot_indexable": true, "report_reasons": null, "author": "maipham264", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/155wl9n/find_a_combination_of_variables_cut_that_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/155wl9n/find_a_combination_of_variables_cut_that_is/", "subreddit_subscribers": 955923, "created_utc": 1689965440.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}