{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Seeking advice, please delete if against the rules.\n\nI want to share a bit of context first, please bare with me.\n\nI've always been frustrated with various bookmark managers and have tried many over the years. I have three main issues:\n\n* Content going offline: I want my bookmark manager to keep a copy of the content since link rot is common. Whether it's a webpage, YouTube video, or tweet thread, I believe I should have the right to keep a copy of what I can access online, regardless of the terms of service.\n\n* Difficulty in retrieval and organization: Adding tags or using specific structures, I ain't got time for that. We went to the moon, computers should be able to automatically extract information like keywords, author name, likes count, etc. And I want to be able to do full text search similar to how searching in Gmail works.\n\n* Discoverability: When I come across something interesting to read, I often can't stop to read it immediately. I want to bookmark it and receive a weekly reminder (like a mailing list) with a mix of unread content and previously checked bookmarks. This way, I can revisit old hidden gems and remove outdated content.\n\nTo address these issues, I set a goal to build a solution that fulfills my requirements. I have a basic, ugly but working prototype that I'm using successfully for my needs. Now, I'm wondering if this problem is unique to me. If I were to make it public, would you use such a tool? If yes, what features would you like to see implemented?\n(If I decide to go forward with this, being able to download a copy of your bookmarks is a non negotiable feature for me)", "author_fullname": "t2_3zmriqy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback: data hoarding as a service", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155hls7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689929220.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689927295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seeking advice, please delete if against the rules.&lt;/p&gt;\n\n&lt;p&gt;I want to share a bit of context first, please bare with me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve always been frustrated with various bookmark managers and have tried many over the years. I have three main issues:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Content going offline: I want my bookmark manager to keep a copy of the content since link rot is common. Whether it&amp;#39;s a webpage, YouTube video, or tweet thread, I believe I should have the right to keep a copy of what I can access online, regardless of the terms of service.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Difficulty in retrieval and organization: Adding tags or using specific structures, I ain&amp;#39;t got time for that. We went to the moon, computers should be able to automatically extract information like keywords, author name, likes count, etc. And I want to be able to do full text search similar to how searching in Gmail works.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Discoverability: When I come across something interesting to read, I often can&amp;#39;t stop to read it immediately. I want to bookmark it and receive a weekly reminder (like a mailing list) with a mix of unread content and previously checked bookmarks. This way, I can revisit old hidden gems and remove outdated content.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To address these issues, I set a goal to build a solution that fulfills my requirements. I have a basic, ugly but working prototype that I&amp;#39;m using successfully for my needs. Now, I&amp;#39;m wondering if this problem is unique to me. If I were to make it public, would you use such a tool? If yes, what features would you like to see implemented?\n(If I decide to go forward with this, being able to download a copy of your bookmarks is a non negotiable feature for me)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155hls7", "is_robot_indexable": true, "report_reasons": null, "author": "goodkernel", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155hls7/looking_for_feedback_data_hoarding_as_a_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155hls7/looking_for_feedback_data_hoarding_as_a_service/", "subreddit_subscribers": 693535, "created_utc": 1689927295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently cloned my hard drive on laptop to a new one using Macrium Reflect, was around 500 GB of data. How reliable can I expect it to be? Like if I now replace the hard disk and use the new one, can I expect it to function exactly like it did before, or are errors common?\n\nI ask because I heard elsewhere that Macrium Reflect cloning works most of the time, but without specifics what can go wrong.", "author_fullname": "t2_pr4df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about using Macrium Reflect to clone hard drive.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155koim", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689937142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently cloned my hard drive on laptop to a new one using Macrium Reflect, was around 500 GB of data. How reliable can I expect it to be? Like if I now replace the hard disk and use the new one, can I expect it to function exactly like it did before, or are errors common?&lt;/p&gt;\n\n&lt;p&gt;I ask because I heard elsewhere that Macrium Reflect cloning works most of the time, but without specifics what can go wrong.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155koim", "is_robot_indexable": true, "report_reasons": null, "author": "Dron22", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155koim/question_about_using_macrium_reflect_to_clone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155koim/question_about_using_macrium_reflect_to_clone/", "subreddit_subscribers": 693535, "created_utc": 1689937142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So basically I have 4x3TB drives and 1x12TB drive, all setup in FreeNAS, no mirroring, just one pool (I know I know, I'm trying to fix it), and the pool is nearly full, which is around 20TB.\n\nI just ordered 2 12TB drives, and am planning on switching to UnRaid, as I need more flexibility. My issue though is that I believe I cannot just swap the drives into unraid and it will be happy, and I do not want to lose this data. My plan currently is to just throw the new 12TB drives into my PC, transfer the data from my NAS into those two drives, then setup the existing drives in UnRaid (wiping them), transfer the data from the 12TB drives on my PC into unraid once it's setup, then finally wipe the 12TB drives on my pc, and load them into unraid, with one of them as parity.\n\nI am pretty certain this will work, but I am looking at around a week of continuous data transfer based on my current speeds from a HDD -&gt; NAS(HDD) and vice versa. There are also probably other concerns doing it this way I am unaware of.\n\nAny suggestions on a better way to go about this? Thanks!!!", "author_fullname": "t2_10qx1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I Move 20TB of Data AND Change OS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155pzww", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689950601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So basically I have 4x3TB drives and 1x12TB drive, all setup in FreeNAS, no mirroring, just one pool (I know I know, I&amp;#39;m trying to fix it), and the pool is nearly full, which is around 20TB.&lt;/p&gt;\n\n&lt;p&gt;I just ordered 2 12TB drives, and am planning on switching to UnRaid, as I need more flexibility. My issue though is that I believe I cannot just swap the drives into unraid and it will be happy, and I do not want to lose this data. My plan currently is to just throw the new 12TB drives into my PC, transfer the data from my NAS into those two drives, then setup the existing drives in UnRaid (wiping them), transfer the data from the 12TB drives on my PC into unraid once it&amp;#39;s setup, then finally wipe the 12TB drives on my pc, and load them into unraid, with one of them as parity.&lt;/p&gt;\n\n&lt;p&gt;I am pretty certain this will work, but I am looking at around a week of continuous data transfer based on my current speeds from a HDD -&amp;gt; NAS(HDD) and vice versa. There are also probably other concerns doing it this way I am unaware of.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions on a better way to go about this? Thanks!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155pzww", "is_robot_indexable": true, "report_reasons": null, "author": "artistbuddy", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155pzww/how_do_i_move_20tb_of_data_and_change_os/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155pzww/how_do_i_move_20tb_of_data_and_change_os/", "subreddit_subscribers": 693535, "created_utc": 1689950601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know of any good 2D/3D file visualizers for Windows?\n\nI\u2019m revamping my file system, and I\u2019d love something that visualizes file organization in 2D or 3D space. Preferably something customizable. \n\nWinDirStat does it at a completely functional level, but I was hoping for something a little slicker that would allow me to arrange and organize my collections of files in a \u201croom\u201d of some sort, rather than a directory tree. Something of a virtual bookshelf or virtual library, but for my entire filing system. The organization would simply visualize the existing dir structure, not add its own.\n\nAnyone know of anything similar?", "author_fullname": "t2_zxdz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Virtual file visualizer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155quin", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689952476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know of any good 2D/3D file visualizers for Windows?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m revamping my file system, and I\u2019d love something that visualizes file organization in 2D or 3D space. Preferably something customizable. &lt;/p&gt;\n\n&lt;p&gt;WinDirStat does it at a completely functional level, but I was hoping for something a little slicker that would allow me to arrange and organize my collections of files in a \u201croom\u201d of some sort, rather than a directory tree. Something of a virtual bookshelf or virtual library, but for my entire filing system. The organization would simply visualize the existing dir structure, not add its own.&lt;/p&gt;\n\n&lt;p&gt;Anyone know of anything similar?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155quin", "is_robot_indexable": true, "report_reasons": null, "author": "CCMadman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155quin/virtual_file_visualizer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155quin/virtual_file_visualizer/", "subreddit_subscribers": 693535, "created_utc": 1689952476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have a simple Linux i5 pc build with 6 hdds. I\u2019d like to upgrade to something more made for a server rack, with ECC ram, able to run high quality 4k and the ability to install many more hdds. Any guides or advice would be massively appreciated, I know a good amount about pc building and parts but almost nothing about the server rack components or what I\u2019d need, thank you!", "author_fullname": "t2_7djm3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Plex server suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155q8rx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689951152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have a simple Linux i5 pc build with 6 hdds. I\u2019d like to upgrade to something more made for a server rack, with ECC ram, able to run high quality 4k and the ability to install many more hdds. Any guides or advice would be massively appreciated, I know a good amount about pc building and parts but almost nothing about the server rack components or what I\u2019d need, thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155q8rx", "is_robot_indexable": true, "report_reasons": null, "author": "Darkstranger111", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155q8rx/plex_server_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155q8rx/plex_server_suggestions/", "subreddit_subscribers": 693535, "created_utc": 1689951152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm sure this question or a slight variation on it has been asked a bunch of times... I don't see any recent posts on it tho so here goes.\n\nI'm making a documentary that currently represents about 25TB of data, most of it is the 6k red raw files for interviews.\n\nMy current backup system:\n\n2 x OWC 28TB Gemini drives. 1 of them is the active media drive and the other is the backup drive that is auto backed up every hour using Arq.\n\n1 x OWC 30TB drive that is kept in another location. This one is brought to the edit and backed up to via Arq about twice a month.\n\nThat's it!! So far... We have spent a lot of money on this show and I want to be sure that we don't lose the footage.\n\nWe have 3 more intvs and tons of new archival to add in the coming months so will prob add 5-6 more TBs of data, making the entire show about 30TBs total.\n\nMy ISP is very meh on site and so I don't think cloud is an option for 25TBs.\n\nI've been looking at synology and qnap but I am not 100% certain of what they are capable of and what might be best for me.\n\nShould I just buy another OWC drive, back up to it and send it to a 3rd location?\n\nI'm an editor, not a storage/NAS person, but I've been tasked with this responsibility solely... Can r/datahoarders help me not fail?!\n\nThx!", "author_fullname": "t2_fxk5z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with Documentary Data Management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155mmy0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689942502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sure this question or a slight variation on it has been asked a bunch of times... I don&amp;#39;t see any recent posts on it tho so here goes.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m making a documentary that currently represents about 25TB of data, most of it is the 6k red raw files for interviews.&lt;/p&gt;\n\n&lt;p&gt;My current backup system:&lt;/p&gt;\n\n&lt;p&gt;2 x OWC 28TB Gemini drives. 1 of them is the active media drive and the other is the backup drive that is auto backed up every hour using Arq.&lt;/p&gt;\n\n&lt;p&gt;1 x OWC 30TB drive that is kept in another location. This one is brought to the edit and backed up to via Arq about twice a month.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s it!! So far... We have spent a lot of money on this show and I want to be sure that we don&amp;#39;t lose the footage.&lt;/p&gt;\n\n&lt;p&gt;We have 3 more intvs and tons of new archival to add in the coming months so will prob add 5-6 more TBs of data, making the entire show about 30TBs total.&lt;/p&gt;\n\n&lt;p&gt;My ISP is very meh on site and so I don&amp;#39;t think cloud is an option for 25TBs.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking at synology and qnap but I am not 100% certain of what they are capable of and what might be best for me.&lt;/p&gt;\n\n&lt;p&gt;Should I just buy another OWC drive, back up to it and send it to a 3rd location?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an editor, not a storage/NAS person, but I&amp;#39;ve been tasked with this responsibility solely... Can &lt;a href=\"/r/datahoarders\"&gt;r/datahoarders&lt;/a&gt; help me not fail?!&lt;/p&gt;\n\n&lt;p&gt;Thx!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155mmy0", "is_robot_indexable": true, "report_reasons": null, "author": "esboardnewb", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155mmy0/help_with_documentary_data_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155mmy0/help_with_documentary_data_management/", "subreddit_subscribers": 693535, "created_utc": 1689942502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, not sure if this is the correct place to post this but I recently purchased a new Seagate Exos hard drive on Newegg with a 5 yr warranty in May 2023. When I checked the serial on the Seagate website, it says that it expires in 2027 (4 years from purchase date). No worries, I contacted Seagate through their support chat system and they told me that they would update the warranty within 24-48 hrs. \n\nI checked the warranty website 48 hrs later and it wasn\u2019t updated. No worries, I understand that sometimes support tickets get lost. I chat again and again they tell me wait 24-48 hrs. I wait 48 hrs and it still doesn\u2019t update. I am now on my 4th time chatting with their support team and got the same thing. I\u2019ll wait and see if it goes through this time but posting here to ask for advice on how to better navigate this. \n\nI know sometimes there is resistance from Seagate updating warranties to start when a drive is purchased because of OEM drives but whenever I chat with their support team they never bring this up. They always say \u2018yes we will update the warranty to reflect your purchase date\u2019. \n\nObviously I am frustrated. Any advice?", "author_fullname": "t2_edxvl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Problems Updating Seagate Warranty", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155dnfu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689914722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, not sure if this is the correct place to post this but I recently purchased a new Seagate Exos hard drive on Newegg with a 5 yr warranty in May 2023. When I checked the serial on the Seagate website, it says that it expires in 2027 (4 years from purchase date). No worries, I contacted Seagate through their support chat system and they told me that they would update the warranty within 24-48 hrs. &lt;/p&gt;\n\n&lt;p&gt;I checked the warranty website 48 hrs later and it wasn\u2019t updated. No worries, I understand that sometimes support tickets get lost. I chat again and again they tell me wait 24-48 hrs. I wait 48 hrs and it still doesn\u2019t update. I am now on my 4th time chatting with their support team and got the same thing. I\u2019ll wait and see if it goes through this time but posting here to ask for advice on how to better navigate this. &lt;/p&gt;\n\n&lt;p&gt;I know sometimes there is resistance from Seagate updating warranties to start when a drive is purchased because of OEM drives but whenever I chat with their support team they never bring this up. They always say \u2018yes we will update the warranty to reflect your purchase date\u2019. &lt;/p&gt;\n\n&lt;p&gt;Obviously I am frustrated. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155dnfu", "is_robot_indexable": true, "report_reasons": null, "author": "linjsph", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155dnfu/problems_updating_seagate_warranty/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155dnfu/problems_updating_seagate_warranty/", "subreddit_subscribers": 693535, "created_utc": 1689914722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Google says 3-5 years but that seems very low. Assuming you have a hard drive strictly to backup family photos and only use it a few times a year and it\u2019s safely kept in a drawer shouldn\u2019t it last much longer?", "author_fullname": "t2_v6avn3hy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long will external hard drive last?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155a5bt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689904424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Google says 3-5 years but that seems very low. Assuming you have a hard drive strictly to backup family photos and only use it a few times a year and it\u2019s safely kept in a drawer shouldn\u2019t it last much longer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155a5bt", "is_robot_indexable": true, "report_reasons": null, "author": "mike4674", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155a5bt/how_long_will_external_hard_drive_last/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155a5bt/how_long_will_external_hard_drive_last/", "subreddit_subscribers": 693535, "created_utc": 1689904424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I watched a review of the D4-300 and the guy showed that there is a fifth sata connector inside the enclosure. I guess Terramaster uses the same board for the D4-300 and D5-300.\n\nDoes anyone know if that fifth sata slot is usable or is it disabled in the firmware?", "author_fullname": "t2_3b8v43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terramaster D4-300 fifth drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1552g68", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689885329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I watched a review of the D4-300 and the guy showed that there is a fifth sata connector inside the enclosure. I guess Terramaster uses the same board for the D4-300 and D5-300.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know if that fifth sata slot is usable or is it disabled in the firmware?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1552g68", "is_robot_indexable": true, "report_reasons": null, "author": "Lokkjeh", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1552g68/terramaster_d4300_fifth_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1552g68/terramaster_d4300_fifth_drive/", "subreddit_subscribers": 693535, "created_utc": 1689885329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Basically I've finally had the dreaded email from google and have 65TB of \"media\" that I need to download within the next 60 days. I'm (obviously) not a fan of spending loads of money in one go, so I was wondering if I could just copy everything over onto newly purchased HDDs and then later down the line have them in a NAS without first having to format them or anything?", "author_fullname": "t2_46i0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When setting up a NAS/Plex Server - can I first get the HDDs and fill them before getting Synology/DIY NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_155s5e6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689955344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically I&amp;#39;ve finally had the dreaded email from google and have 65TB of &amp;quot;media&amp;quot; that I need to download within the next 60 days. I&amp;#39;m (obviously) not a fan of spending loads of money in one go, so I was wondering if I could just copy everything over onto newly purchased HDDs and then later down the line have them in a NAS without first having to format them or anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155s5e6", "is_robot_indexable": true, "report_reasons": null, "author": "VadimH", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155s5e6/when_setting_up_a_nasplex_server_can_i_first_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155s5e6/when_setting_up_a_nasplex_server_can_i_first_get/", "subreddit_subscribers": 693535, "created_utc": 1689955344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am using PhantomBuster to scrape 5-9k IG profile URLs per day. There is no problem there so far.\n\nHowever, I then want to scrape the info of those profiles (IG id, name, email, etc.) but PhantomBuster does not recommend scrapping more than 10 profiles per day this way. **This is too slow for me.**\n\nAre there any tools that allow me to scrape the info of a list of IG URLs I provide? Which can do so at a higher pace than PhantomBuster?", "author_fullname": "t2_pad7opa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Scrape More Than 10 Instagram Profiles per Day?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155oqr1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689947720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using PhantomBuster to scrape 5-9k IG profile URLs per day. There is no problem there so far.&lt;/p&gt;\n\n&lt;p&gt;However, I then want to scrape the info of those profiles (IG id, name, email, etc.) but PhantomBuster does not recommend scrapping more than 10 profiles per day this way. &lt;strong&gt;This is too slow for me.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Are there any tools that allow me to scrape the info of a list of IG URLs I provide? Which can do so at a higher pace than PhantomBuster?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155oqr1", "is_robot_indexable": true, "report_reasons": null, "author": "yunnospllrait", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155oqr1/how_to_scrape_more_than_10_instagram_profiles_per/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155oqr1/how_to_scrape_more_than_10_instagram_profiles_per/", "subreddit_subscribers": 693535, "created_utc": 1689947720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI have a folder with thousands of files with names that names can sometimes look alike or have different extensions, like:\n\n\\- filename.txt  \n\\- filename.pdf  \n\\- file-name.txt\n\nThe three files above are the same file **but the checksum and file size are all different**.\n\nIs there a way to check and display all files with very similar names and I will check manually and delete the ones I don't want?\n\nI would love something like Czkawka where it checks for similar images, displays them and then, I can delete the similar ones or check them one by one...\n\nThank you!", "author_fullname": "t2_vc7clehs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to check very similar file names on Windows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155in2y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689931050.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689930726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a folder with thousands of files with names that names can sometimes look alike or have different extensions, like:&lt;/p&gt;\n\n&lt;p&gt;- filename.txt&lt;br/&gt;\n- filename.pdf&lt;br/&gt;\n- file-name.txt&lt;/p&gt;\n\n&lt;p&gt;The three files above are the same file &lt;strong&gt;but the checksum and file size are all different&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to check and display all files with very similar names and I will check manually and delete the ones I don&amp;#39;t want?&lt;/p&gt;\n\n&lt;p&gt;I would love something like Czkawka where it checks for similar images, displays them and then, I can delete the similar ones or check them one by one...&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155in2y", "is_robot_indexable": true, "report_reasons": null, "author": "Feeling_Usual1541", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155in2y/how_to_check_very_similar_file_names_on_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155in2y/how_to_check_very_similar_file_names_on_windows/", "subreddit_subscribers": 693535, "created_utc": 1689930726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im looking for a cheap / free solution to auto Sync between a remote Windows Machine, an attached External HDD, to TrueNAS and Cloud.\n\nThe Cloud isn't set yet (the current one is only syncing with proprietary Software).   \n End goal here is on demand Sync with a click of a Button.\n\nThe Windows machine isn't managed by me, so I only want read-only from my TrueNAS server.\n\nEnd user isn\u2019t Tech Savvy and the machine isn't always on, so the Backup, should be executable by a 1 click solution.   \nAt least between the Cloud and the External HDD.   \nMirroring to my TrueNAS can be done manually by me.\n\nWhat Software / Cloud Provider do you recommend?\n\nSnapshots would be great, but are optional. (As I sync manually, the chance of ransomware encryption is basically non existent)  \nThe Files are mostly Pictures / Videos but very badly Sorted, meaning very rudimentary Folder Structure.", "author_fullname": "t2_37a4qz81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync between Windows, External HDD, TrueNas and Cloud (500GB - 1TB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155431x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689889014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im looking for a cheap / free solution to auto Sync between a remote Windows Machine, an attached External HDD, to TrueNAS and Cloud.&lt;/p&gt;\n\n&lt;p&gt;The Cloud isn&amp;#39;t set yet (the current one is only syncing with proprietary Software).&lt;br/&gt;\n End goal here is on demand Sync with a click of a Button.&lt;/p&gt;\n\n&lt;p&gt;The Windows machine isn&amp;#39;t managed by me, so I only want read-only from my TrueNAS server.&lt;/p&gt;\n\n&lt;p&gt;End user isn\u2019t Tech Savvy and the machine isn&amp;#39;t always on, so the Backup, should be executable by a 1 click solution.&lt;br/&gt;\nAt least between the Cloud and the External HDD.&lt;br/&gt;\nMirroring to my TrueNAS can be done manually by me.&lt;/p&gt;\n\n&lt;p&gt;What Software / Cloud Provider do you recommend?&lt;/p&gt;\n\n&lt;p&gt;Snapshots would be great, but are optional. (As I sync manually, the chance of ransomware encryption is basically non existent)&lt;br/&gt;\nThe Files are mostly Pictures / Videos but very badly Sorted, meaning very rudimentary Folder Structure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155431x", "is_robot_indexable": true, "report_reasons": null, "author": "offron1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155431x/sync_between_windows_external_hdd_truenas_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155431x/sync_between_windows_external_hdd_truenas_and/", "subreddit_subscribers": 693535, "created_utc": 1689889014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I see a lot of comments for backup software saying \"just use rsync!\" but from what I can tell, rsync only syncs files from one place to another, and doesn't act as a backup in situations like user deleting or modifying file by accident, original file corruption, ransomware, etc.  Does anyone have a software they really like that has some sort of version history / restore point feature, so that if a file has a problem and it gets synced before you notice it, you can get a previous version?  \n\nI'm using windows on my main server and OMV on my diy NAS, but I can run linux in a VM if necessary.  Bonus point for a free software solution, but I'm open to paying a one-time fee for something great.  Not interested in anything subscription / cloud based.\n\nThanks for any help!", "author_fullname": "t2_11hqze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite backup software with version history / restore points?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1552rg0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689886001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see a lot of comments for backup software saying &amp;quot;just use rsync!&amp;quot; but from what I can tell, rsync only syncs files from one place to another, and doesn&amp;#39;t act as a backup in situations like user deleting or modifying file by accident, original file corruption, ransomware, etc.  Does anyone have a software they really like that has some sort of version history / restore point feature, so that if a file has a problem and it gets synced before you notice it, you can get a previous version?  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using windows on my main server and OMV on my diy NAS, but I can run linux in a VM if necessary.  Bonus point for a free software solution, but I&amp;#39;m open to paying a one-time fee for something great.  Not interested in anything subscription / cloud based.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1552rg0", "is_robot_indexable": true, "report_reasons": null, "author": "Illeazar", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1552rg0/favorite_backup_software_with_version_history/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1552rg0/favorite_backup_software_with_version_history/", "subreddit_subscribers": 693535, "created_utc": 1689886001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For those that backup your family photos, do you enable encryption? I ran into a sync issue with Cloudsync on my Snyology and it hosed my entire bucket. Encryption was on from the synology side during this process. I'm going to delete the bucket and start over. Just curious what the consensus is?", "author_fullname": "t2_bru5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backblaze Photo backup B2 question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_155tfrp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689958238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those that backup your family photos, do you enable encryption? I ran into a sync issue with Cloudsync on my Snyology and it hosed my entire bucket. Encryption was on from the synology side during this process. I&amp;#39;m going to delete the bucket and start over. Just curious what the consensus is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155tfrp", "is_robot_indexable": true, "report_reasons": null, "author": "Stryker412", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155tfrp/backblaze_photo_backup_b2_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155tfrp/backblaze_photo_backup_b2_question/", "subreddit_subscribers": 693535, "created_utc": 1689958238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI'm trying to back up picturea/videos from my trip, about 60-120gb, 2k files from my phone.\n\nMy process\n- from my camera sd card, move all to phone, and overnight backing up some portion to Google drive. \n\nProblem is I often get it randomly stopped, or files are not all uploaded, for example 78 out of 100, and then I need tod delete all and do it all over again as if I i have duplicates? \n\nThanks", "author_fullname": "t2_10tx5blw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why backing up to Google drive is such a pain, what am I doing wrong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155pzgm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689950574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to back up picturea/videos from my trip, about 60-120gb, 2k files from my phone.&lt;/p&gt;\n\n&lt;p&gt;My process\n- from my camera sd card, move all to phone, and overnight backing up some portion to Google drive. &lt;/p&gt;\n\n&lt;p&gt;Problem is I often get it randomly stopped, or files are not all uploaded, for example 78 out of 100, and then I need tod delete all and do it all over again as if I i have duplicates? &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155pzgm", "is_robot_indexable": true, "report_reasons": null, "author": "-i3arty-", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155pzgm/why_backing_up_to_google_drive_is_such_a_pain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155pzgm/why_backing_up_to_google_drive_is_such_a_pain/", "subreddit_subscribers": 693535, "created_utc": 1689950574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nso i know there are ton of tools that do sync but the thing is that i want to know is there a software that can compare 2 folders (folder1, folder2) and rename folder2 files from folder1 if there size is same. Not Copy. i tried FreeFileSync and Syncovery. no luck. i changed over like 20,000 files from folder1 which have about 100 sub folders.\n\n ", "author_fullname": "t2_dsr3fft40", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any software suggestion for syncing 2 folders.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155o8d6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689946494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so i know there are ton of tools that do sync but the thing is that i want to know is there a software that can compare 2 folders (folder1, folder2) and rename folder2 files from folder1 if there size is same. Not Copy. i tried FreeFileSync and Syncovery. no luck. i changed over like 20,000 files from folder1 which have about 100 sub folders.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155o8d6", "is_robot_indexable": true, "report_reasons": null, "author": "RealThug0005", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155o8d6/any_software_suggestion_for_syncing_2_folders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155o8d6/any_software_suggestion_for_syncing_2_folders/", "subreddit_subscribers": 693535, "created_utc": 1689946494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This PSID is required to reset SED to use in NAS, but I am certain it's not print on the white label. Also tried all the number on the label, nothing works. Thanks!", "author_fullname": "t2_mjwm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For WD shucked HDD, where I can find SED PSID", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155iaj4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689929614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This PSID is required to reset SED to use in NAS, but I am certain it&amp;#39;s not print on the white label. Also tried all the number on the label, nothing works. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155iaj4", "is_robot_indexable": true, "report_reasons": null, "author": "st0n39", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155iaj4/for_wd_shucked_hdd_where_i_can_find_sed_psid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155iaj4/for_wd_shucked_hdd_where_i_can_find_sed_psid/", "subreddit_subscribers": 693535, "created_utc": 1689929614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've had great luck with Exos drives. But I was wondering how the WD in title compares to the X18 Exos platform in terms of reliability and longevity", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos X18 18TB (ST18000NM000J) or WD Ultrastar DC HC550 18TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15594fl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689901519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had great luck with Exos drives. But I was wondering how the WD in title compares to the X18 Exos platform in terms of reliability and longevity&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15594fl", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15594fl/seagate_exos_x18_18tb_st18000nm000j_or_wd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15594fl/seagate_exos_x18_18tb_st18000nm000j_or_wd/", "subreddit_subscribers": 693535, "created_utc": 1689901519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_p81pzhxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "22TB WD Elements Desktop External Hard Drive, USB 3.0\u00c2 WDBWLG0220HBK-NESN $229 Shipped (Amazon)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 51, "top_awarded_type": null, "hide_score": false, "name": "t3_1551hdj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.39, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FtKV1dsx%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FtKV1dsx&amp;image=https%3A%2F%2Fi.imgur.com%2FcARd4rc.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"262\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "height": 262}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "imgur.com", "oembed": {"provider_url": "http://imgur.com", "description": "Discover the magic of the internet at Imgur, a community powered entertainment destination. Lift your spirits with funny jokes, trending memes, entertaining gifs, inspiring stories, viral videos, and so much more from users.", "title": "22TB WD Elements Desktop External Hard Drive, USB 3.0 WDBWLG0220HBK-NESN $229 Shipped", "url": "https://imgur.com/a/tKV1dsx", "type": "rich", "thumbnail_width": 600, "height": 262, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FtKV1dsx%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FtKV1dsx&amp;image=https%3A%2F%2Fi.imgur.com%2FcARd4rc.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"262\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Imgur", "thumbnail_url": "https://i.imgur.com/cARd4rc.jpg?fb", "thumbnail_height": 315}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FtKV1dsx%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FtKV1dsx&amp;image=https%3A%2F%2Fi.imgur.com%2FcARd4rc.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"262\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1551hdj", "height": 262}, "link_flair_text": "Sale", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/N1Bu4M9DCDiS0rrRkQ33f0X6PhW3A3gNtrn2gJvkbWM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689883201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://imgur.com/a/tKV1dsx", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-lXLiTPgVLbTTI_zz8KwcHuABL3Mm9EX4kfvog0YrYI.jpg?auto=webp&amp;s=8fe105ae122099bba23d49ed48c87ea005100f12", "width": 1860, "height": 689}, "resolutions": [{"url": "https://external-preview.redd.it/-lXLiTPgVLbTTI_zz8KwcHuABL3Mm9EX4kfvog0YrYI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c13cfc122faccb614995824e35120b4fada54403", "width": 108, "height": 40}, {"url": "https://external-preview.redd.it/-lXLiTPgVLbTTI_zz8KwcHuABL3Mm9EX4kfvog0YrYI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e96f9356c404cd31e31dde21216de9e10424aa36", "width": 216, "height": 80}, {"url": "https://external-preview.redd.it/-lXLiTPgVLbTTI_zz8KwcHuABL3Mm9EX4kfvog0YrYI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=00350ef331b2e091f658778b89e33dd371cd03a3", "width": 320, "height": 118}, {"url": "https://external-preview.redd.it/-lXLiTPgVLbTTI_zz8KwcHuABL3Mm9EX4kfvog0YrYI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=366297e631cd7bef74ef4e88ea1230bdbb223ed4", "width": 640, "height": 237}, {"url": "https://external-preview.redd.it/-lXLiTPgVLbTTI_zz8KwcHuABL3Mm9EX4kfvog0YrYI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=028dc8a711b95c437bcb893af81ff0d7045c4012", "width": 960, "height": 355}, {"url": "https://external-preview.redd.it/-lXLiTPgVLbTTI_zz8KwcHuABL3Mm9EX4kfvog0YrYI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b698d41f66d5c9935fdcdd715d4b88fd423f4e17", "width": 1080, "height": 400}], "variants": {}, "id": "q5dVbN1YpvyULySG7S1gLxsUso-RdpekWljmuaKtK5Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1551hdj", "is_robot_indexable": true, "report_reasons": null, "author": "JohnNelson2022", "discussion_type": null, "num_comments": 15, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1551hdj/22tb_wd_elements_desktop_external_hard_drive_usb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imgur.com/a/tKV1dsx", "subreddit_subscribers": 693535, "created_utc": 1689883201.0, "num_crossposts": 0, "media": {"type": "imgur.com", "oembed": {"provider_url": "http://imgur.com", "description": "Discover the magic of the internet at Imgur, a community powered entertainment destination. Lift your spirits with funny jokes, trending memes, entertaining gifs, inspiring stories, viral videos, and so much more from users.", "title": "22TB WD Elements Desktop External Hard Drive, USB 3.0 WDBWLG0220HBK-NESN $229 Shipped", "url": "https://imgur.com/a/tKV1dsx", "type": "rich", "thumbnail_width": 600, "height": 262, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FtKV1dsx%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FtKV1dsx&amp;image=https%3A%2F%2Fi.imgur.com%2FcARd4rc.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"262\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Imgur", "thumbnail_url": "https://i.imgur.com/cARd4rc.jpg?fb", "thumbnail_height": 315}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "38M autistic, overloaded serial stressor\nOver-thinker extraordinaire. Also posting to Synology to cover my basis. Also admitting I have two accounts so I apologise for the doubling up of questions recently. \n\nSince I fully lack confidence in myself and my actions, and filled with the help you all have given me in this subreddit, as well as various helpful videos and wormholes from SpaceRex and Linus, I am still thoroughly convinced in 38 years on this planet, that any thing I touch inevitably turns to shit, so to avoid me setting it up wrong, my brand new DS1821+ with 8/22TB hard drives inside, is now in the safe hands of my trusted tech guys to set it up the way I want (hopefully properly and correctly) \n\nI trust them with every fibre of my being, they have brought my ancient 21.5 inch iMac 2010 back from the jaws of death more times than I can count and keep my current 2015 chugging along.\n\nEven though I felt the worst I have ever felt giving it to them, I had to constantly reassure myself that, these are the same people you have given your computers to, and they fixed them, and have them back good as new.\n\nHopefully they are able to set it up correctly but my question is to try and ascertain a time frame, as to how long this might take, formatting, checking the disks, configuring the unit correctly etc, basically wondering when I might get it back?\n\nThey said they want to test the disks, to make sure they are working alright, even though the onboard wizard does that already, and I asked them to go for SHR 2, (we were talking about FreeNas and TrueNas) but I took all the advice on here and went with SHR (which unless I am mistaken is only available through the onboard Synology wizard) I also know the unit maxes out at 108TB, now I know out of 8/22TB drives I am not going to exactly get all that space (176TB) so I requested SHR 2 (sacrificing two drives) but I don\u2019t know how much useable space I\u2019ll have left.\n\nAny helpful comments would be very much appreciated", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The tech boys have it now, may good have mercy on my soul", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_155cqfg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689911992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;38M autistic, overloaded serial stressor\nOver-thinker extraordinaire. Also posting to Synology to cover my basis. Also admitting I have two accounts so I apologise for the doubling up of questions recently. &lt;/p&gt;\n\n&lt;p&gt;Since I fully lack confidence in myself and my actions, and filled with the help you all have given me in this subreddit, as well as various helpful videos and wormholes from SpaceRex and Linus, I am still thoroughly convinced in 38 years on this planet, that any thing I touch inevitably turns to shit, so to avoid me setting it up wrong, my brand new DS1821+ with 8/22TB hard drives inside, is now in the safe hands of my trusted tech guys to set it up the way I want (hopefully properly and correctly) &lt;/p&gt;\n\n&lt;p&gt;I trust them with every fibre of my being, they have brought my ancient 21.5 inch iMac 2010 back from the jaws of death more times than I can count and keep my current 2015 chugging along.&lt;/p&gt;\n\n&lt;p&gt;Even though I felt the worst I have ever felt giving it to them, I had to constantly reassure myself that, these are the same people you have given your computers to, and they fixed them, and have them back good as new.&lt;/p&gt;\n\n&lt;p&gt;Hopefully they are able to set it up correctly but my question is to try and ascertain a time frame, as to how long this might take, formatting, checking the disks, configuring the unit correctly etc, basically wondering when I might get it back?&lt;/p&gt;\n\n&lt;p&gt;They said they want to test the disks, to make sure they are working alright, even though the onboard wizard does that already, and I asked them to go for SHR 2, (we were talking about FreeNas and TrueNas) but I took all the advice on here and went with SHR (which unless I am mistaken is only available through the onboard Synology wizard) I also know the unit maxes out at 108TB, now I know out of 8/22TB drives I am not going to exactly get all that space (176TB) so I requested SHR 2 (sacrificing two drives) but I don\u2019t know how much useable space I\u2019ll have left.&lt;/p&gt;\n\n&lt;p&gt;Any helpful comments would be very much appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "155cqfg", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/155cqfg/the_tech_boys_have_it_now_may_good_have_mercy_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/155cqfg/the_tech_boys_have_it_now_may_good_have_mercy_on/", "subreddit_subscribers": 693535, "created_utc": 1689911992.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}