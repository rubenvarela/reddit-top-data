{"kind": "Listing", "data": {"after": "t3_14ybp45", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At work we\u2019re building a lil\u2019 pipeline. Nothing fancy, just reads data from a few API\u2019s, normalizes them and sticks em in a table in our DB. \n\nWe\u2019re trying out airflow for this, and we\u2019ve been putting all of the actual code into DAGs in airflow. So, all python.\n\nI saw another post that mentioned how airflow is mostly a \u201cjob scheduler\u201d, which made me second-guess keeping all of our code in airflow DAGs. So I\u2019m wondering: do y\u2019all use airflow primarily as a scheduler for jobs that are owned by other services, or do you also rely on it to run business logic?\n\nIf that\u2019s too vague, here\u2019s a specific example:\nIdeally, I\u2019d have all of my data pulling/normalizing code in rust. We already have a nicely setup rust environment, and that\u2019s how I would handle our pipeline if it was just gonna be rust scripts and a bunch of cron jobs. \nBut since airflow has so many easy integrations, we decided just to let airflow (and thusly python DAGs) handle all of the data pulling and normalization. \n\nIs the \u201ccorrect\u201d way to use airflow:\n1) having airflow trigger rust scripts?\n2) having airflow handle everything from within airflow?", "author_fullname": "t2_8k5ls63w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is airflow better for triggering jobs in a data pipeline, or actually running the jobs itself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y3s4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689203208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At work we\u2019re building a lil\u2019 pipeline. Nothing fancy, just reads data from a few API\u2019s, normalizes them and sticks em in a table in our DB. &lt;/p&gt;\n\n&lt;p&gt;We\u2019re trying out airflow for this, and we\u2019ve been putting all of the actual code into DAGs in airflow. So, all python.&lt;/p&gt;\n\n&lt;p&gt;I saw another post that mentioned how airflow is mostly a \u201cjob scheduler\u201d, which made me second-guess keeping all of our code in airflow DAGs. So I\u2019m wondering: do y\u2019all use airflow primarily as a scheduler for jobs that are owned by other services, or do you also rely on it to run business logic?&lt;/p&gt;\n\n&lt;p&gt;If that\u2019s too vague, here\u2019s a specific example:\nIdeally, I\u2019d have all of my data pulling/normalizing code in rust. We already have a nicely setup rust environment, and that\u2019s how I would handle our pipeline if it was just gonna be rust scripts and a bunch of cron jobs. \nBut since airflow has so many easy integrations, we decided just to let airflow (and thusly python DAGs) handle all of the data pulling and normalization. &lt;/p&gt;\n\n&lt;p&gt;Is the \u201ccorrect\u201d way to use airflow:\n1) having airflow trigger rust scripts?\n2) having airflow handle everything from within airflow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14y3s4r", "is_robot_indexable": true, "report_reasons": null, "author": "chamomile-crumbs", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y3s4r/is_airflow_better_for_triggering_jobs_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y3s4r/is_airflow_better_for_triggering_jobs_in_a_data/", "subreddit_subscribers": 115544, "created_utc": 1689203208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work in a healthcare company. We use SSIS and SSMS (SQL) for most of our data needs. On the rare occasion, we also use C#, Python, and Powershell. Is this stack good enough to start job hunting or would it be better to pick up some software-specific skills? I thought about learning GCP or AWS but am not sure the likelihood of getting hired with only self-study on those topics. I've been at my current company for 8 years (intern -&gt; data analyst -&gt; database engineer) and it's a good environment / fully remote, but the money just isn't there. I'm currently making $75k/80k a year depending on bonus and yearly raises are 2%. ", "author_fullname": "t2_1b2ivfkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to further career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xwkrp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689186554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work in a healthcare company. We use SSIS and SSMS (SQL) for most of our data needs. On the rare occasion, we also use C#, Python, and Powershell. Is this stack good enough to start job hunting or would it be better to pick up some software-specific skills? I thought about learning GCP or AWS but am not sure the likelihood of getting hired with only self-study on those topics. I&amp;#39;ve been at my current company for 8 years (intern -&amp;gt; data analyst -&amp;gt; database engineer) and it&amp;#39;s a good environment / fully remote, but the money just isn&amp;#39;t there. I&amp;#39;m currently making $75k/80k a year depending on bonus and yearly raises are 2%. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xwkrp", "is_robot_indexable": true, "report_reasons": null, "author": "WhelminglyMediocre", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xwkrp/how_to_further_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xwkrp/how_to_further_career/", "subreddit_subscribers": 115544, "created_utc": 1689186554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team is looking at writing a simple framework/platform based on Cloud that'd allow various users to define batch based pipelines. Currently focusing on AWS, there are multiple modules which setup a set of services, dynamic infrastructure, orchestration, roles, notifications for the users as part of the platform. \n\nAs part of orchestration, I started looking at Dagster and one of the thing I immediately realized is that the actual data processing and orchestration is intertwined and deliberately kept together in most of the examples I saw and also a forte of Dagster as I understand compared to the traditional orhestration/workflow frameworks where they are loosely coupled and a DAG is defined.   \n\n\nWhen I look at any orchestrator, the main things I look for is that - orchestration, meaning given a set of tasks, it should be able to execute, report on, track, kill at will, rollback, fanout, do reporting and maintain metadata for it. Combining this with the actual data being processed as part of the actions/tasks is a great thing for small scale pipelines but quickly becomes a scaling/deployment problem if I want to make it available as a service (not looking for Dagster cloud yet) where users can submit many such jobs.   \n\n\nI understand and yet to explore the constructs such as Assets, Operators that allow me integrate with external services (in my case the cloud services which I'd integrate with a good wrapper over common AWS managed services and compute) but before I proceed wanted to check if I am not setting myself on a wrong path just because its supports but is indeed an antipattern.   \n\n\nWhy separate actual compute from orchestration ?   \n\\- I want to fully exploit and use existing AWS services where given a script (say the script/python code utilizing say polars,pandas, duckdb etc), I have a freedom to pack and run it as a docker image on ECS, Fargate, or lamda   \n\\- For a very big workloads, which don't fit into services such as AWS Glue/Redshift for ELT/ETL purpose, be able to spawn an appliance say through spot and get it executed in EC2 and so on..  \n\n\n.. and still use Dagster as a pure orchestrator where it can have a shim layer written that not only launches but tracks these jobs very well, helps with retries, rollbacks etc.", "author_fullname": "t2_qg4yidm6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster - Separating compute and orchestration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xodd2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team is looking at writing a simple framework/platform based on Cloud that&amp;#39;d allow various users to define batch based pipelines. Currently focusing on AWS, there are multiple modules which setup a set of services, dynamic infrastructure, orchestration, roles, notifications for the users as part of the platform. &lt;/p&gt;\n\n&lt;p&gt;As part of orchestration, I started looking at Dagster and one of the thing I immediately realized is that the actual data processing and orchestration is intertwined and deliberately kept together in most of the examples I saw and also a forte of Dagster as I understand compared to the traditional orhestration/workflow frameworks where they are loosely coupled and a DAG is defined.   &lt;/p&gt;\n\n&lt;p&gt;When I look at any orchestrator, the main things I look for is that - orchestration, meaning given a set of tasks, it should be able to execute, report on, track, kill at will, rollback, fanout, do reporting and maintain metadata for it. Combining this with the actual data being processed as part of the actions/tasks is a great thing for small scale pipelines but quickly becomes a scaling/deployment problem if I want to make it available as a service (not looking for Dagster cloud yet) where users can submit many such jobs.   &lt;/p&gt;\n\n&lt;p&gt;I understand and yet to explore the constructs such as Assets, Operators that allow me integrate with external services (in my case the cloud services which I&amp;#39;d integrate with a good wrapper over common AWS managed services and compute) but before I proceed wanted to check if I am not setting myself on a wrong path just because its supports but is indeed an antipattern.   &lt;/p&gt;\n\n&lt;p&gt;Why separate actual compute from orchestration ?&lt;br/&gt;\n- I want to fully exploit and use existing AWS services where given a script (say the script/python code utilizing say polars,pandas, duckdb etc), I have a freedom to pack and run it as a docker image on ECS, Fargate, or lamda&lt;br/&gt;\n- For a very big workloads, which don&amp;#39;t fit into services such as AWS Glue/Redshift for ELT/ETL purpose, be able to spawn an appliance say through spot and get it executed in EC2 and so on..  &lt;/p&gt;\n\n&lt;p&gt;.. and still use Dagster as a pure orchestrator where it can have a shim layer written that not only launches but tracks these jobs very well, helps with retries, rollbacks etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xodd2", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Cartoonist7071", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xodd2/dagster_separating_compute_and_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xodd2/dagster_separating_compute_and_orchestration/", "subreddit_subscribers": 115544, "created_utc": 1689167886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks,\n\nFor the past 2 years I've been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, ddl generation, self deployment, schema evolution... basically, as you build better and better pipelines you will want more and more.\n\nThe value proposition is to automate the tedious work you do, so you can focus on better things.\n\nSo dlt is a library where in the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading.\n\nIn its most complex form, you can do almost anything you can want, from memory management, multithreading, extraction DAGs, etc.\n\nThe library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community.\n\nFeedback is very welcome and so are requests for features or destinations.\n\nThe library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.[https://dlthub.com/](https://dlthub.com/)  \n\n\nI know lots of you are jaded and fed up with toy technologies - this is not a toy tech, it's purpose made for productivity and sanity.\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python library for automating data normalisation, schema creation and loading to db", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yfh6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689238840.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689238647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks,&lt;/p&gt;\n\n&lt;p&gt;For the past 2 years I&amp;#39;ve been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, ddl generation, self deployment, schema evolution... basically, as you build better and better pipelines you will want more and more.&lt;/p&gt;\n\n&lt;p&gt;The value proposition is to automate the tedious work you do, so you can focus on better things.&lt;/p&gt;\n\n&lt;p&gt;So dlt is a library where in the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading.&lt;/p&gt;\n\n&lt;p&gt;In its most complex form, you can do almost anything you can want, from memory management, multithreading, extraction DAGs, etc.&lt;/p&gt;\n\n&lt;p&gt;The library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community.&lt;/p&gt;\n\n&lt;p&gt;Feedback is very welcome and so are requests for features or destinations.&lt;/p&gt;\n\n&lt;p&gt;The library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.&lt;a href=\"https://dlthub.com/\"&gt;https://dlthub.com/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I know lots of you are jaded and fed up with toy technologies - this is not a toy tech, it&amp;#39;s purpose made for productivity and sanity.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?auto=webp&amp;s=cb39faa311105e22445462cdf83958c4587fedc2", "width": 1200, "height": 898}, "resolutions": [{"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2950fb9a02e9cdd0b136f3013b72924854fdca3f", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f0af0e48140a561a1f7b733a96875956b6389de", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25c5e30c984451ee6ea10cd4e1067e85319086d3", "width": 320, "height": 239}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=784ffdd500b6cb71463c17b9d348b620c417e6b2", "width": 640, "height": 478}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a966fccda316bcff3aef7e4ae872efc79cabbc1", "width": 960, "height": 718}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec5a6d47433e6864a169a05e9319caa70258c58d", "width": 1080, "height": 808}], "variants": {}, "id": "cUuEsBHL5TMhrkQNJ9leYxFMOF6VgvTJ_EKHwExrn8Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14yfh6p", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "subreddit_subscribers": 115544, "created_utc": 1689238647.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m frustrated at my attempts, as they seem to be going in circles, but I\u2019m just looking for better alternatives for what I\u2019m doing. \n\nI work in data migration, and at first it was fine, but now it\u2019s not scaling very well. I need to map non-normalized values to those my company has a set of standards for and so far my attempts just create tons of manual work. \n\nCurrently, I\u2019ve been building \u201cmaps\u201d of key/value pairs and coercing the values manually by removing formatting and things so I\u2019m only comparing lower case letters (and numbers if needed). By now some of maps are 100\u2019s off values in length or longer. A good example is a person\u2019s race, these values are user generated and we only allow a handful of things before we treat it differently. But there are a lot of different ways to denote a lot of different races\u2026 that\u2019s just one example obviously. \n\nI\u2019ve tried the `fuzzywuzzy` package which is partially reliable (only on Levenshtein distance). We don\u2019t have the budget for open ai either. \n\nCan anyone give me some ideas?\n\nThank you in advance!", "author_fullname": "t2_5am908px", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help mapping data in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y4yf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689206215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m frustrated at my attempts, as they seem to be going in circles, but I\u2019m just looking for better alternatives for what I\u2019m doing. &lt;/p&gt;\n\n&lt;p&gt;I work in data migration, and at first it was fine, but now it\u2019s not scaling very well. I need to map non-normalized values to those my company has a set of standards for and so far my attempts just create tons of manual work. &lt;/p&gt;\n\n&lt;p&gt;Currently, I\u2019ve been building \u201cmaps\u201d of key/value pairs and coercing the values manually by removing formatting and things so I\u2019m only comparing lower case letters (and numbers if needed). By now some of maps are 100\u2019s off values in length or longer. A good example is a person\u2019s race, these values are user generated and we only allow a handful of things before we treat it differently. But there are a lot of different ways to denote a lot of different races\u2026 that\u2019s just one example obviously. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried the &lt;code&gt;fuzzywuzzy&lt;/code&gt; package which is partially reliable (only on Levenshtein distance). We don\u2019t have the budget for open ai either. &lt;/p&gt;\n\n&lt;p&gt;Can anyone give me some ideas?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14y4yf7", "is_robot_indexable": true, "report_reasons": null, "author": "iambatmanman", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y4yf7/need_help_mapping_data_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y4yf7/need_help_mapping_data_in_python/", "subreddit_subscribers": 115544, "created_utc": 1689206215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm actually going to make this, so I want to make sure I don't leave out any great jokes. What should the office look like? What struggles should I include? What would make you laugh? ", "author_fullname": "t2_68z0an9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If there was a nature documentary about the \"datus engineerius\" and it's life inside of the corporate habitat, what kinds of things would for sure be pointed out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xoc20", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m actually going to make this, so I want to make sure I don&amp;#39;t leave out any great jokes. What should the office look like? What struggles should I include? What would make you laugh? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xoc20", "is_robot_indexable": true, "report_reasons": null, "author": "3spelledout", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xoc20/if_there_was_a_nature_documentary_about_the_datus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xoc20/if_there_was_a_nature_documentary_about_the_datus/", "subreddit_subscribers": 115544, "created_utc": 1689167792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've all no doubt seen the [\"St. Albnas\"](https://www.reddit.com/r/dataengineering/comments/14442pi/we_have_great_datasets/) meme by now. Data quality is hard \ud83e\udd26\ud83c\udffb\u200d\u2642\ufe0f.\n\nTo have some fun with this, the company I work for (Tinybird) is sponsoring a little \"hackathon\". Clean the data and avoid false positives to get some swag. No winners and losers, just participation prizes! (yay millennials!)\n\nMake sure to read the rules, and have some fun with it!\n\n[https://github.com/tinybirdco/st-albnas-hackathon](https://github.com/tinybirdco/st-albnas-hackathon)", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"St. Albnas\" Hackathon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xvfx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689183944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve all no doubt seen the &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14442pi/we_have_great_datasets/\"&gt;&amp;quot;St. Albnas&amp;quot;&lt;/a&gt; meme by now. Data quality is hard \ud83e\udd26\ud83c\udffb\u200d\u2642\ufe0f.&lt;/p&gt;\n\n&lt;p&gt;To have some fun with this, the company I work for (Tinybird) is sponsoring a little &amp;quot;hackathon&amp;quot;. Clean the data and avoid false positives to get some swag. No winners and losers, just participation prizes! (yay millennials!)&lt;/p&gt;\n\n&lt;p&gt;Make sure to read the rules, and have some fun with it!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/tinybirdco/st-albnas-hackathon\"&gt;https://github.com/tinybirdco/st-albnas-hackathon&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?auto=webp&amp;s=f0d96abead2cba1a7dcb3cd17af9aeee18d3b110", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=56cd9107ee58fa7c1de7d83a217464eb6edc661c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a032c60f128a58abe914c1be58fc4d197968b554", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cc621d87bd3645dd13b28c63cadc443dd7d9d708", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=880b60a66eaac91ceece4a1cd7fa73876c86604a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ffe2d888799e8c31a0af57a09bd1e70eb66d696", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3286eb4f4f474031681a6e19b9d2db3c9f2de5c", "width": 1080, "height": 540}], "variants": {}, "id": "GZPGBRybU-NIi8L9efQJzEa2WaNuknEOOl2vPCBbOfw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14xvfx1", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xvfx1/st_albnas_hackathon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xvfx1/st_albnas_hackathon/", "subreddit_subscribers": 115544, "created_utc": 1689183944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI was DS in Google and laid off 4 months ago and I couldn't find any DS position since then (Im living in Switzerland). And I find a great start up but they hiring data engineering position. I would really want to try it since I really like the culture of the company and I did a lot of pipelining in my DS role in Google. But I don't know how Data Eng case study interviews would be. I have no experience on that side and I can't find questions online, maybe i don't know how to search. Is there anyone can help me with mock interview for entry level positions? ", "author_fullname": "t2_78n8udb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to transition from DS to Data Eng, anyone wants to help with mock interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xtaru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689179129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I was DS in Google and laid off 4 months ago and I couldn&amp;#39;t find any DS position since then (Im living in Switzerland). And I find a great start up but they hiring data engineering position. I would really want to try it since I really like the culture of the company and I did a lot of pipelining in my DS role in Google. But I don&amp;#39;t know how Data Eng case study interviews would be. I have no experience on that side and I can&amp;#39;t find questions online, maybe i don&amp;#39;t know how to search. Is there anyone can help me with mock interview for entry level positions? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14xtaru", "is_robot_indexable": true, "report_reasons": null, "author": "hatidzhek", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xtaru/want_to_transition_from_ds_to_data_eng_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xtaru/want_to_transition_from_ds_to_data_eng_anyone/", "subreddit_subscribers": 115544, "created_utc": 1689179129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Those that work at amazon as data engineer, can you please tell me how your interview process was, how you prepped, what type of questions you were asked?", "author_fullname": "t2_3wpqg210", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "internal transfer to data engineer role at amazon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xzu9d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689194051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Those that work at amazon as data engineer, can you please tell me how your interview process was, how you prepped, what type of questions you were asked?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14xzu9d", "is_robot_indexable": true, "report_reasons": null, "author": "no_catchy_username", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xzu9d/internal_transfer_to_data_engineer_role_at_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xzu9d/internal_transfer_to_data_engineer_role_at_amazon/", "subreddit_subscribers": 115544, "created_utc": 1689194051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone else feel like they burn out people a lot faster at the Bay Area companies? Maybe it is the culture?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Burnout", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yaltn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689223473.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689222451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone else feel like they burn out people a lot faster at the Bay Area companies? Maybe it is the culture?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yaltn", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yaltn/burnout/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yaltn/burnout/", "subreddit_subscribers": 115544, "created_utc": 1689222451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi team,\n\nI have ubuntu box where we run our python scripts of off.\n\nOne of my python scripts uses aws cli to extract data from....\n\nwhen i execute python script manually it will run.\n\nwhen i add this python script to run on crontab it starts...but doesnt go past 'aws cli command' executed almost at the very begining of python script.\n\nthe python script with aws CLI:\n\n \n\nsubprocess.run(\\[\"aws\", \"s3\", \"cp\", \"link\\_to\\_aws\\_stage\", \"download\\_to\\_path, \"--recursive\",\"--profile\",\"ABC\"\\])\n\n&amp;#x200B;\n\n**Question:**\n\nhow to workaround that?\n\nhow can i set which ubuntu users can access CLI ?\n\ndo you have any better idea\n\nthanks!\n\n&amp;#x200B;", "author_fullname": "t2_do9wxbfu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help with aws cli", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xqpch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689173421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi team,&lt;/p&gt;\n\n&lt;p&gt;I have ubuntu box where we run our python scripts of off.&lt;/p&gt;\n\n&lt;p&gt;One of my python scripts uses aws cli to extract data from....&lt;/p&gt;\n\n&lt;p&gt;when i execute python script manually it will run.&lt;/p&gt;\n\n&lt;p&gt;when i add this python script to run on crontab it starts...but doesnt go past &amp;#39;aws cli command&amp;#39; executed almost at the very begining of python script.&lt;/p&gt;\n\n&lt;p&gt;the python script with aws CLI:&lt;/p&gt;\n\n&lt;p&gt;subprocess.run([&amp;quot;aws&amp;quot;, &amp;quot;s3&amp;quot;, &amp;quot;cp&amp;quot;, &amp;quot;link_to_aws_stage&amp;quot;, &amp;quot;download_to_path, &amp;quot;--recursive&amp;quot;,&amp;quot;--profile&amp;quot;,&amp;quot;ABC&amp;quot;])&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;how to workaround that?&lt;/p&gt;\n\n&lt;p&gt;how can i set which ubuntu users can access CLI ?&lt;/p&gt;\n\n&lt;p&gt;do you have any better idea&lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xqpch", "is_robot_indexable": true, "report_reasons": null, "author": "87keicam", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xqpch/help_with_aws_cli/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xqpch/help_with_aws_cli/", "subreddit_subscribers": 115544, "created_utc": 1689173421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI have been a lurker forever in this sub and today i have decided to know your opinions in some points regarding the implementation of functional programming in Data Engineering (DE).\n\nAfter reading around this paradigm (most articles i have found converge to [Maxime Beauchemin article](https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a)), there are two points that makes my head scratch a bit:\n\n&amp;#x200B;\n\n* **Dimensional snapshots**:  The fact that this can create a lot of redundancy in dimensional tables, this really does not sound like a problem to me. I actually like the fact that with this approach avoids upserts and SCD's by just re-processing the data in a given time period. What i would like to understand is, for those who already implemented dimension snapshots, if the redundancy on the tables took a toll on the visualization tools performance big enough for you to get back to SCDs or something hybrid.\n* **Late arriving facts**: this is the point that really makes me avoid functional programming. Knowing that to we have to center our focus based on the event reception or processing time and not on the event time, it means in my opinion that the dimension partition scheme should be based on the event processing time too. However, the analysts surely do their work based on the event time which it will not benefit from the partition pruning. That could make any query based on the event time be way more costly.\n\nTake in note that i have been working more recently with BigQuery, in which the storage capacity is not a problem and you can partition a table with one column only (aside from clustering). Even in platforms that allows tables with multiple partitions i still think the second point potential costs and performance can be heavily affected.\n\nTake in account these two points, you think functional programming still can be something worth to implement in DE context?\n\nI hope my doubts were clear enough for you to share your take. Best regards!\n\n&amp;#x200B;", "author_fullname": "t2_4errm1ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Funtional Programming in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xq53v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689172144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have been a lurker forever in this sub and today i have decided to know your opinions in some points regarding the implementation of functional programming in Data Engineering (DE).&lt;/p&gt;\n\n&lt;p&gt;After reading around this paradigm (most articles i have found converge to &lt;a href=\"https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a\"&gt;Maxime Beauchemin article&lt;/a&gt;), there are two points that makes my head scratch a bit:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Dimensional snapshots&lt;/strong&gt;:  The fact that this can create a lot of redundancy in dimensional tables, this really does not sound like a problem to me. I actually like the fact that with this approach avoids upserts and SCD&amp;#39;s by just re-processing the data in a given time period. What i would like to understand is, for those who already implemented dimension snapshots, if the redundancy on the tables took a toll on the visualization tools performance big enough for you to get back to SCDs or something hybrid.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Late arriving facts&lt;/strong&gt;: this is the point that really makes me avoid functional programming. Knowing that to we have to center our focus based on the event reception or processing time and not on the event time, it means in my opinion that the dimension partition scheme should be based on the event processing time too. However, the analysts surely do their work based on the event time which it will not benefit from the partition pruning. That could make any query based on the event time be way more costly.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Take in note that i have been working more recently with BigQuery, in which the storage capacity is not a problem and you can partition a table with one column only (aside from clustering). Even in platforms that allows tables with multiple partitions i still think the second point potential costs and performance can be heavily affected.&lt;/p&gt;\n\n&lt;p&gt;Take in account these two points, you think functional programming still can be something worth to implement in DE context?&lt;/p&gt;\n\n&lt;p&gt;I hope my doubts were clear enough for you to share your take. Best regards!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?auto=webp&amp;s=cf073d9e898ab6b6aac9cbd3d617eb1a8d77093f", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e6ca8361de7a95cb6c47013c1938266c06cf1bff", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fae9102fa6d32f067e38cc3b24cc65481bb6ed33", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3efad0c05c8737f8d5c4ac99e42e7579dd97057", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4e73a5bddad916ba74ea62469de010438a9a993", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1fada96526d687a1d1efd7a1d8d1e5d7d033d9c8", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd93c47a0b2c95deabadee9d4fe6e3cc05529c5e", "width": 1080, "height": 720}], "variants": {}, "id": "QnHDt9HlR913WRkisNYJkFlw9Lr3Bt7UcxRxAQAkPdY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xq53v", "is_robot_indexable": true, "report_reasons": null, "author": "lou1uol", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xq53v/funtional_programming_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xq53v/funtional_programming_in_data_engineering/", "subreddit_subscribers": 115544, "created_utc": 1689172144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GPT-4 + Streaming Data = Real-Time Generative AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14yanye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1okdH9K6hwzgqGmTotLtnPtRaaesYAmSFdpWdtEXBYI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689222640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confluent.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confluent.io/blog/chatgpt-and-streaming-data-for-real-time-generative-ai/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?auto=webp&amp;s=b3d69b2b1fe2e737d3cd99f3c114278d4c50a82e", "width": 748, "height": 748}, "resolutions": [{"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=57d65fa68561d4f6f912018b5ae267ab3c0f9e0f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8086b50841c4d24f99750485eb329e3f56d35bff", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cbff01b67c1d4013ec32d347a00d51b1b2a85038", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/oEnqHgfPz1seuOwtaksrZRrTIotbSasFA9o5OxdvEUo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7dbd0345f9d81ac9c34b1f2983c6b68c40eed63", "width": 640, "height": 640}], "variants": {}, "id": "UkEnmWaASEGNKtlwlJXUEo3JbKitP8i5PMlm8kh0bPE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14yanye", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yanye/gpt4_streaming_data_realtime_generative_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confluent.io/blog/chatgpt-and-streaming-data-for-real-time-generative-ai/", "subreddit_subscribers": 115544, "created_utc": 1689222640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is how it is done:\n\nApache Doris preserves multiple replicas of hot data and the metadata in its backend nodes, and cold data in object storage with only one copy.\n\nhttps://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=116202b543f7ad10392348ddb036a5e125c49081\n\nFull post about [hot-cold data separation](https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High availability of data without consuming too much storage space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"n5t2a43epibb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e93b5fcaf295957400ac50c724629865333f96e"}, {"y": 175, "x": 216, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d3c3d93f39247aba6281cf8abaf9705596906f8"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c900bec99726a420282e06f3c9511c60d807c49"}, {"y": 520, "x": 640, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=46886e8b513861fb5c44f981484edac60289ad1d"}, {"y": 780, "x": 960, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d547c8b465733f08671882765b3a471b95d4ea7"}, {"y": 878, "x": 1080, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2e00bd44ba6a0107a00507b4afb50b27dfd768a6"}], "s": {"y": 1041, "x": 1280, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=116202b543f7ad10392348ddb036a5e125c49081"}, "id": "n5t2a43epibb1"}}, "name": "t3_14xlmy3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cA-TRKk2RQNysgWZvGrT-7xphAfBnKQJyJcIU1Q-Mrg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1689160617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is how it is done:&lt;/p&gt;\n\n&lt;p&gt;Apache Doris preserves multiple replicas of hot data and the metadata in its backend nodes, and cold data in object storage with only one copy.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=116202b543f7ad10392348ddb036a5e125c49081\"&gt;https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=116202b543f7ad10392348ddb036a5e125c49081&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Full post about &lt;a href=\"https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf\"&gt;hot-cold data separation&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?auto=webp&amp;s=9bb433a2d2af7659bbd2aaefc86e6440fb099982", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cebf42d866ba39ad8401ec16025d2e683cb5ec5", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0db6f5ac30249427128f2acbef98d324f22c2d1b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34cbad55217597ab7e3e1f50abad3c5bc069e0d7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5bc2ca5a2ba66071e1827faae996f0dc6f6e329c", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f46f655bcbbc72ddca3942cdffe318e8677b8735", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8874a5ffe10ae71db18d29c8e4b5f59d830878fe", "width": 1080, "height": 720}], "variants": {}, "id": "XHYrsxQam1UsYnZQ-ImG7NyQc780qMXf4eXuq9sAgzc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14xlmy3", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xlmy3/high_availability_of_data_without_consuming_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xlmy3/high_availability_of_data_without_consuming_too/", "subreddit_subscribers": 115544, "created_utc": 1689160617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am based in France and I'm looking to hear news and presentations from other data practitioners (data engineering mostly). I can't find any meet-ups. Do you guys know some ? Preferably in person events, but since I'm not finding anything, online will do too. Thanks !! ", "author_fullname": "t2_8kenyeuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering meetups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yejyj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689235429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am based in France and I&amp;#39;m looking to hear news and presentations from other data practitioners (data engineering mostly). I can&amp;#39;t find any meet-ups. Do you guys know some ? Preferably in person events, but since I&amp;#39;m not finding anything, online will do too. Thanks !! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yejyj", "is_robot_indexable": true, "report_reasons": null, "author": "btenami", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14yejyj/data_engineering_meetups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yejyj/data_engineering_meetups/", "subreddit_subscribers": 115544, "created_utc": 1689235429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI wanted to share here a project I'm really excited about. \n\nRecap is mainly the work of [Chris](https://twitter.com/criccomini) but I had the privilege to be involved in some design and implementation parts. Enough with the intro stuff though, let's talk about the project.\n\nRecap is a Python library that provides a single schema for... \n\n*  IDLs (Proto, JSON schema, Avro)\n*  Databases (Snowflake, PG) \n* Schema registries (CFLT schema registry, Hive metastore) \n\n Read and convert all these schemas in one format.\n\nRecap is still a baby as Chris says but I feel there's enough functionality at this point to reach out to the community and get some feedback. \n\nThe goal is to be able to access, reason and transform between all the different formats and metadata stores that are typically found in a decently mature data infrastructure. \n\nThere's still work to be done but most of the components needed are there. \n\nTake a look and I'd love to hear your thoughts and feedback.\n\nThe main Recap page: [https://recap.build](https://recap.build)\n\nThe type system spec: [https://recap.build/spec/0.1.1](https://recap.build/spec/0.1.1)\n\nThe Github Repo: [https://github.com/recap-build/recap](https://github.com/recap-build/recap)\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_fb1s1pke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recap: A python library for describing database tables and serialization formats with minimal type coercion.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y8op7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689216832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I wanted to share here a project I&amp;#39;m really excited about. &lt;/p&gt;\n\n&lt;p&gt;Recap is mainly the work of &lt;a href=\"https://twitter.com/criccomini\"&gt;Chris&lt;/a&gt; but I had the privilege to be involved in some design and implementation parts. Enough with the intro stuff though, let&amp;#39;s talk about the project.&lt;/p&gt;\n\n&lt;p&gt;Recap is a Python library that provides a single schema for... &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt; IDLs (Proto, JSON schema, Avro)&lt;/li&gt;\n&lt;li&gt; Databases (Snowflake, PG) &lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Schema registries (CFLT schema registry, Hive metastore) &lt;/p&gt;\n\n&lt;p&gt;Read and convert all these schemas in one format.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Recap is still a baby as Chris says but I feel there&amp;#39;s enough functionality at this point to reach out to the community and get some feedback. &lt;/p&gt;\n\n&lt;p&gt;The goal is to be able to access, reason and transform between all the different formats and metadata stores that are typically found in a decently mature data infrastructure. &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s still work to be done but most of the components needed are there. &lt;/p&gt;\n\n&lt;p&gt;Take a look and I&amp;#39;d love to hear your thoughts and feedback.&lt;/p&gt;\n\n&lt;p&gt;The main Recap page: &lt;a href=\"https://recap.build\"&gt;https://recap.build&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The type system spec: &lt;a href=\"https://recap.build/spec/0.1.1\"&gt;https://recap.build/spec/0.1.1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The Github Repo: &lt;a href=\"https://github.com/recap-build/recap\"&gt;https://github.com/recap-build/recap&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14y8op7", "is_robot_indexable": true, "report_reasons": null, "author": "cpardl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y8op7/recap_a_python_library_for_describing_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y8op7/recap_a_python_library_for_describing_database/", "subreddit_subscribers": 115544, "created_utc": 1689216832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working in a role that allows me to do various data analyst related tasks with Alteryx, python, and some SQL, but if I were to make the pivot to data engineering, what role should I realistically look for that would allow me to prepare for a data engineering role? Due to being in grad school and working full time, I don\u2019t have much time to do side projects, and I won\u2019t have much time to myself till graduation. I would like to transition to data engineering, but I would like to get the proper preliminary experience before even attempting to apply for roles. Any advice would be greatly appreciated. Thank you \n\nAdditional info:\nHave experience using SQL, Python, and Alteryx\nCurrently in grad school and working full, so I do not have much time to do side projects (learn Apache and AWS)\nHave some experience in using data automation pipelines via alteryx \nHave a project portfolio and GitHub", "author_fullname": "t2_5e8sloz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is my starting point?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y4xqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689206162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working in a role that allows me to do various data analyst related tasks with Alteryx, python, and some SQL, but if I were to make the pivot to data engineering, what role should I realistically look for that would allow me to prepare for a data engineering role? Due to being in grad school and working full time, I don\u2019t have much time to do side projects, and I won\u2019t have much time to myself till graduation. I would like to transition to data engineering, but I would like to get the proper preliminary experience before even attempting to apply for roles. Any advice would be greatly appreciated. Thank you &lt;/p&gt;\n\n&lt;p&gt;Additional info:\nHave experience using SQL, Python, and Alteryx\nCurrently in grad school and working full, so I do not have much time to do side projects (learn Apache and AWS)\nHave some experience in using data automation pipelines via alteryx \nHave a project portfolio and GitHub&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14y4xqk", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableCharity7222", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y4xqk/what_is_my_starting_point/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y4xqk/what_is_my_starting_point/", "subreddit_subscribers": 115544, "created_utc": 1689206162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To keep it short I have no idea what title would be most suitable.\nI do dashboard design,build dashboard(js,css,html),I clean data and have to come up with new plans on how the data we have I can automate, I currently make no api calls (I do connect to databases but it\u2019s a system where I do not need to make api calls )or build databases YET. I do see myself in the future doing this and full stack SWE devolvement. I have no idea what the appropriate title for me would be.", "author_fullname": "t2_ilnryf6f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What am I?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y3akl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689202049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To keep it short I have no idea what title would be most suitable.\nI do dashboard design,build dashboard(js,css,html),I clean data and have to come up with new plans on how the data we have I can automate, I currently make no api calls (I do connect to databases but it\u2019s a system where I do not need to make api calls )or build databases YET. I do see myself in the future doing this and full stack SWE devolvement. I have no idea what the appropriate title for me would be.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14y3akl", "is_robot_indexable": true, "report_reasons": null, "author": "dany65ns", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y3akl/what_am_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y3akl/what_am_i/", "subreddit_subscribers": 115544, "created_utc": 1689202049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not sure how many people are developing with Kafka on here, but given ingestion of streaming data is fairly typical of most data engineer's these days, I wanted to share the below.\n\nWebinar will focus on practical implementations for enforcing data security when it comes to developing with Kafka.\n\nJoin for free: [https://app.livestorm.co/conduktor/kafka-security-masterclass](https://app.livestorm.co/conduktor/kafka-security-masterclass?type=detailed)", "author_fullname": "t2_ve0spvbx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone developing with Kafka? Learn how to enforce good data security practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y0nys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689195926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure how many people are developing with Kafka on here, but given ingestion of streaming data is fairly typical of most data engineer&amp;#39;s these days, I wanted to share the below.&lt;/p&gt;\n\n&lt;p&gt;Webinar will focus on practical implementations for enforcing data security when it comes to developing with Kafka.&lt;/p&gt;\n\n&lt;p&gt;Join for free: &lt;a href=\"https://app.livestorm.co/conduktor/kafka-security-masterclass?type=detailed\"&gt;https://app.livestorm.co/conduktor/kafka-security-masterclass&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?auto=webp&amp;s=9912334549612e265a9d73776ee4149b7b4af7d9", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de6b53cde12f5087ac77b80269c1a84277d944d5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4d8b1c2ce80807aa67bc482a92d7c4de762cb09f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b240618b737818eebc64b388105842ee01f3dd13", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ee6411df102d4e9376d9ea5588adfa0c0adb12c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7f68c1526aba47094b0927bdc5b18785ef3f9e90", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4f3b539a84d2813a879391fad13ecf1c028de2d1", "width": 1080, "height": 567}], "variants": {}, "id": "jUGrVCmjEfNzTvZDYL4juwiDIDDBlELq7IEfe92tEcU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14y0nys", "is_robot_indexable": true, "report_reasons": null, "author": "data-stash", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y0nys/anyone_developing_with_kafka_learn_how_to_enforce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y0nys/anyone_developing_with_kafka_learn_how_to_enforce/", "subreddit_subscribers": 115544, "created_utc": 1689195926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For those who have been in the field, what do you think about the security career wise compared to other SWE roles? I\u2019m not talking about salary necessarily, but more so supply/demand, mobility, potentially constant need of upskilling, etc.", "author_fullname": "t2_3co48377", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Security in the marketplace compared to BE/FE SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xxn76", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689188964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those who have been in the field, what do you think about the security career wise compared to other SWE roles? I\u2019m not talking about salary necessarily, but more so supply/demand, mobility, potentially constant need of upskilling, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xxn76", "is_robot_indexable": true, "report_reasons": null, "author": "Angriestanteater", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xxn76/security_in_the_marketplace_compared_to_befe_swe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xxn76/security_in_the_marketplace_compared_to_befe_swe/", "subreddit_subscribers": 115544, "created_utc": 1689188964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some background on myself. I recently transitioned into data engineering after 5 years as a data analyst and have been working at a startup since the beginning of the year on a contract basis. I'm practically the sole data engineer so I'm building end-to-end pipelines and I get to work with Python, SQL, DBT, Fivetran, Airflow, Postgres, MongoDB, Elasticsearch. I also do some Devops stuff - DigitalOcean is our main cloud service, but I also work with GCP and Azure (albeit at a surface level). I love the tech stack, but at the same time I'm worried I'm developing bad habits as an engineer since I'm working mostly independently and there's no proper CI/CD, at least for now. There's also no guarantee I'm gonna have a job in around 6 months since there's only a certain amount of money that's been reserved to fund my position, though there are efforts to get more funding.\n\nI recently received a job offer at a FinTech company where the core tech stack is DBT, SQL, Snowflake, and Airflow. Certain things that concern me:\n\n* Python seems to be a small part of the role. In my interview, they mentioned that Python would mostly be used to write up Airflow jobs. The job description also emphasizes more on SQL for deploying analytics code.\n* GCP, AWS or Azure not listed on job description. The team has devops engineers so I imagine they'll be the ones handling cloud infrastructure.\n* I've seen multiple job titles for the role, mainly \"Data Engineer\" and \"Analytics Engineer\". I asked them about this and they said that data and analytics engineers are one and the same to them, and they had put up the role under multiple titles to attract as many applicants as possible.\n\nSome positives I see for the role:\n\n* It's in a bigger proper engineering team, with a scrum master, other DevOps engineers, QA, etc. and CI/CD pipelines in place.\n* I got along well with the hiring manager, who really seems to know his stuff.\n* The team is rapidly expanding, which to me seems like a good sign.\n\nI've been applying to jobs for a couple months now, and I frequently see GCP/AWS/Azure experience as a requirement. Python is easily the most enjoyable part of my job, and I want to be viewed more as programmer or a SWE-focused DE in the long term rather than an analytics engineer or a SQL developer (no hate against these types of roles, they're just not what I'm looking for).\n\nAny advice would be greatly appreciated!\n\nEdit: Revised bullet point on cloud services", "author_fullname": "t2_3bhqq33p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take this job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xqg8d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689177749.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689172853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some background on myself. I recently transitioned into data engineering after 5 years as a data analyst and have been working at a startup since the beginning of the year on a contract basis. I&amp;#39;m practically the sole data engineer so I&amp;#39;m building end-to-end pipelines and I get to work with Python, SQL, DBT, Fivetran, Airflow, Postgres, MongoDB, Elasticsearch. I also do some Devops stuff - DigitalOcean is our main cloud service, but I also work with GCP and Azure (albeit at a surface level). I love the tech stack, but at the same time I&amp;#39;m worried I&amp;#39;m developing bad habits as an engineer since I&amp;#39;m working mostly independently and there&amp;#39;s no proper CI/CD, at least for now. There&amp;#39;s also no guarantee I&amp;#39;m gonna have a job in around 6 months since there&amp;#39;s only a certain amount of money that&amp;#39;s been reserved to fund my position, though there are efforts to get more funding.&lt;/p&gt;\n\n&lt;p&gt;I recently received a job offer at a FinTech company where the core tech stack is DBT, SQL, Snowflake, and Airflow. Certain things that concern me:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python seems to be a small part of the role. In my interview, they mentioned that Python would mostly be used to write up Airflow jobs. The job description also emphasizes more on SQL for deploying analytics code.&lt;/li&gt;\n&lt;li&gt;GCP, AWS or Azure not listed on job description. The team has devops engineers so I imagine they&amp;#39;ll be the ones handling cloud infrastructure.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve seen multiple job titles for the role, mainly &amp;quot;Data Engineer&amp;quot; and &amp;quot;Analytics Engineer&amp;quot;. I asked them about this and they said that data and analytics engineers are one and the same to them, and they had put up the role under multiple titles to attract as many applicants as possible.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Some positives I see for the role:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s in a bigger proper engineering team, with a scrum master, other DevOps engineers, QA, etc. and CI/CD pipelines in place.&lt;/li&gt;\n&lt;li&gt;I got along well with the hiring manager, who really seems to know his stuff.&lt;/li&gt;\n&lt;li&gt;The team is rapidly expanding, which to me seems like a good sign.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve been applying to jobs for a couple months now, and I frequently see GCP/AWS/Azure experience as a requirement. Python is easily the most enjoyable part of my job, and I want to be viewed more as programmer or a SWE-focused DE in the long term rather than an analytics engineer or a SQL developer (no hate against these types of roles, they&amp;#39;re just not what I&amp;#39;m looking for).&lt;/p&gt;\n\n&lt;p&gt;Any advice would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: Revised bullet point on cloud services&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xqg8d", "is_robot_indexable": true, "report_reasons": null, "author": "timbaktubear", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xqg8d/should_i_take_this_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xqg8d/should_i_take_this_job/", "subreddit_subscribers": 115544, "created_utc": 1689172853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Nomenclature is something I don't see brought very often in this subreddit. What naming conventions do you use when it comes to naming tables/jobs/individual pipelines and such, if any?", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What naming conventions do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xncko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689165260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Nomenclature is something I don&amp;#39;t see brought very often in this subreddit. What naming conventions do you use when it comes to naming tables/jobs/individual pipelines and such, if any?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xncko", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xncko/what_naming_conventions_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xncko/what_naming_conventions_do_you_use/", "subreddit_subscribers": 115544, "created_utc": 1689165260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\nAnalysts in my team is working hard to serve other teams instead of helping me. We want to build/ buy some self-serve tool to reduce outside requests. \nWe are looking for some tool similar to jinja template, that the outsiders will be able to select their fields, dimensions and filters and this will render the template with the relevant fields. \nWe try looker, but it was very difficult to so PoP and it is our most common cases.\nCan you help us and suggest self-serve tools?", "author_fullname": "t2_s43j01w7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-serve tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ycbuu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689227896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nAnalysts in my team is working hard to serve other teams instead of helping me. We want to build/ buy some self-serve tool to reduce outside requests. \nWe are looking for some tool similar to jinja template, that the outsiders will be able to select their fields, dimensions and filters and this will render the template with the relevant fields. \nWe try looker, but it was very difficult to so PoP and it is our most common cases.\nCan you help us and suggest self-serve tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ycbuu", "is_robot_indexable": true, "report_reasons": null, "author": "gal_12345", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ycbuu/selfserve_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ycbuu/selfserve_tool/", "subreddit_subscribers": 115544, "created_utc": 1689227896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. I am a newbie to data engineering and not very familiar with this.\n\n&amp;#x200B;\n\nOur group has a requirement where we have a large number of data timed tasks, but they have some dependencies, most of them are written in go code and run in lambda.\n\n&amp;#x200B;\n\nSo I started looking for task scheduling solutions. I found a lot of scheduling tools/systems written in Python. And they all combined runtime code  and scheduling configuration together, like  dagster and prefect, but I probably wanted a language independent pure scheduling system.\n\n&amp;#x200B;\n\nAt the same time, I also observed a lot of projects using config file to define pipeline, why not use relational database to store pipeline directly, if a lot of config file exist, I think it's hard to manage.\n\n&amp;#x200B;\n\nThe closest to what I need is benthos, but I find it a bit unmanageable to define using yaml, I would like to write something like  benthos to trigger task and use relational database to define pipeline.\n\n&amp;#x200B;\n\nIs there any suggestion to me? thank you!", "author_fullname": "t2_gg35o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pure orchestration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yc2wd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689227076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. I am a newbie to data engineering and not very familiar with this.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Our group has a requirement where we have a large number of data timed tasks, but they have some dependencies, most of them are written in go code and run in lambda.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I started looking for task scheduling solutions. I found a lot of scheduling tools/systems written in Python. And they all combined runtime code  and scheduling configuration together, like  dagster and prefect, but I probably wanted a language independent pure scheduling system.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;At the same time, I also observed a lot of projects using config file to define pipeline, why not use relational database to store pipeline directly, if a lot of config file exist, I think it&amp;#39;s hard to manage.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The closest to what I need is benthos, but I find it a bit unmanageable to define using yaml, I would like to write something like  benthos to trigger task and use relational database to define pipeline.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there any suggestion to me? thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14yc2wd", "is_robot_indexable": true, "report_reasons": null, "author": "nlimpid", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yc2wd/pure_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yc2wd/pure_orchestration/", "subreddit_subscribers": 115544, "created_utc": 1689227076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there good learning resources or online courses? I assume pyspark is more popular than scala spark.", "author_fullname": "t2_ufzthkpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to learn/prepare spark coding interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ybp45", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689225852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there good learning resources or online courses? I assume pyspark is more popular than scala spark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14ybp45", "is_robot_indexable": true, "report_reasons": null, "author": "Itchy-Jello4053", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ybp45/what_is_the_best_way_to_learnprepare_spark_coding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ybp45/what_is_the_best_way_to_learnprepare_spark_coding/", "subreddit_subscribers": 115544, "created_utc": 1689225852.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}