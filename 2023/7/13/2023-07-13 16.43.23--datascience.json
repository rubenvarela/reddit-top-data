{"kind": "Listing", "data": {"after": "t3_14yo22y", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've got nothing to do at the moment. With all of my major projects I'm waiting for someone else's input. Usually, there's small progress, then I'm excited to get working. Then something else comes up, and there's another wait of 2-4 weeks for one thing or another. \n\nI tried padding my schedule with useful stuff like ad-hoc analyses, strategising, prep work for infrastructure changes, and networking. Infrastructure work is limited due to low data maturity and heavy silos, though. There's also a limit to how much networking one can do.\n\nI've run out of meaningful things to do. This has been going on for 6 months and I'm starting to feel burned out. So, I also don't have the energy to learn anymore, maybe because I'm exhausted, maybe because it's lonely and currently void of any practical application. \n\nI talked with my boss who is sympathetic but he can only offer me more filler work at the moment. I know it's a first world problem but I'm really losing my motivation. Would you have any advice on what to do? \n\nThanks in advance.", "author_fullname": "t2_4j7ujk5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nothing to do", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xvd0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 80, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 80, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689183983.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689183754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got nothing to do at the moment. With all of my major projects I&amp;#39;m waiting for someone else&amp;#39;s input. Usually, there&amp;#39;s small progress, then I&amp;#39;m excited to get working. Then something else comes up, and there&amp;#39;s another wait of 2-4 weeks for one thing or another. &lt;/p&gt;\n\n&lt;p&gt;I tried padding my schedule with useful stuff like ad-hoc analyses, strategising, prep work for infrastructure changes, and networking. Infrastructure work is limited due to low data maturity and heavy silos, though. There&amp;#39;s also a limit to how much networking one can do.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve run out of meaningful things to do. This has been going on for 6 months and I&amp;#39;m starting to feel burned out. So, I also don&amp;#39;t have the energy to learn anymore, maybe because I&amp;#39;m exhausted, maybe because it&amp;#39;s lonely and currently void of any practical application. &lt;/p&gt;\n\n&lt;p&gt;I talked with my boss who is sympathetic but he can only offer me more filler work at the moment. I know it&amp;#39;s a first world problem but I&amp;#39;m really losing my motivation. Would you have any advice on what to do? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xvd0b", "is_robot_indexable": true, "report_reasons": null, "author": "norfkens2", "discussion_type": null, "num_comments": 86, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xvd0b/nothing_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xvd0b/nothing_to_do/", "subreddit_subscribers": 947234, "created_utc": 1689183754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Whenever I've scrolled through Linkdin, I'm seeing heinous ratios like 60-200 applicants: 1 opening. I mean I just started my DataCamp tracks last September! Am I looking in the wrong places or am I just fucked? ", "author_fullname": "t2_icfhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data science oversaturated now? | Job Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xzcdi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 78, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 78, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689192905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whenever I&amp;#39;ve scrolled through Linkdin, I&amp;#39;m seeing heinous ratios like 60-200 applicants: 1 opening. I mean I just started my DataCamp tracks last September! Am I looking in the wrong places or am I just fucked? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xzcdi", "is_robot_indexable": true, "report_reasons": null, "author": "Genedide", "discussion_type": null, "num_comments": 156, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xzcdi/is_data_science_oversaturated_now_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xzcdi/is_data_science_oversaturated_now_job_market/", "subreddit_subscribers": 947234, "created_utc": 1689192905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\nI'm currently exploring various certifications in the field of data science and machine learning, and I wanted to gather insights from the community, especially from data science experts and hiring managers.\n\nSpecifically, I'm interested in hearing your opinions and experiences regarding the value of certifications offered by AWS, Azure, Google Cloud, and Databricks.\n\nThese certifications include:\n\nAWS Certified Machine Learning - Specialty\n\nMicrosoft Certified: Azure Data Scientist Associate\n\nGoogle Cloud Certified - Machine Learning and Data science\n\nDatabricks - Data science certification \n\nWhat is the general demand and trend in the job market for professionals holding these certifications?\n\nDo you see an increasing demand for individuals with these certifications?\n\nHave you personally witnessed any significant career benefits or advantages from earning these certifications, either in terms of job opportunities, salary, or professional growth?\n\nPlease feel free to share any additional thoughts, tips, or recommendations related to these certifications or any others that you believe are valuable in the data science and machine learning domains.\n\nI'd love to know:\n\nHow valuable do you perceive these certifications to be in terms of career development and advancement within the data science and machine learning fields?\n\nAre these certifications highly regarded by hiring managers when considering candidates for data science and machine learning positions?\n\nYour insights will be greatly appreciated, and they will help me and others in the community make informed decisions regarding certifications and their potential impact on our careers.\n\nThank you in advance for your valuable contributions!", "author_fullname": "t2_60jo8coj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Valuable are AWS, Azure, Google Cloud, and Databricks Certifications for Data Science Careers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yi1ia", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689248110.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689247042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently exploring various certifications in the field of data science and machine learning, and I wanted to gather insights from the community, especially from data science experts and hiring managers.&lt;/p&gt;\n\n&lt;p&gt;Specifically, I&amp;#39;m interested in hearing your opinions and experiences regarding the value of certifications offered by AWS, Azure, Google Cloud, and Databricks.&lt;/p&gt;\n\n&lt;p&gt;These certifications include:&lt;/p&gt;\n\n&lt;p&gt;AWS Certified Machine Learning - Specialty&lt;/p&gt;\n\n&lt;p&gt;Microsoft Certified: Azure Data Scientist Associate&lt;/p&gt;\n\n&lt;p&gt;Google Cloud Certified - Machine Learning and Data science&lt;/p&gt;\n\n&lt;p&gt;Databricks - Data science certification &lt;/p&gt;\n\n&lt;p&gt;What is the general demand and trend in the job market for professionals holding these certifications?&lt;/p&gt;\n\n&lt;p&gt;Do you see an increasing demand for individuals with these certifications?&lt;/p&gt;\n\n&lt;p&gt;Have you personally witnessed any significant career benefits or advantages from earning these certifications, either in terms of job opportunities, salary, or professional growth?&lt;/p&gt;\n\n&lt;p&gt;Please feel free to share any additional thoughts, tips, or recommendations related to these certifications or any others that you believe are valuable in the data science and machine learning domains.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to know:&lt;/p&gt;\n\n&lt;p&gt;How valuable do you perceive these certifications to be in terms of career development and advancement within the data science and machine learning fields?&lt;/p&gt;\n\n&lt;p&gt;Are these certifications highly regarded by hiring managers when considering candidates for data science and machine learning positions?&lt;/p&gt;\n\n&lt;p&gt;Your insights will be greatly appreciated, and they will help me and others in the community make informed decisions regarding certifications and their potential impact on our careers.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your valuable contributions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yi1ia", "is_robot_indexable": true, "report_reasons": null, "author": "petburiraja", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yi1ia/how_valuable_are_aws_azure_google_cloud_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yi1ia/how_valuable_are_aws_azure_google_cloud_and/", "subreddit_subscribers": 947234, "created_utc": 1689247042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone here work somewhere that traditionally doesn't have a robust technical recruitment pipeline?\n\nAn example, and my goal, is nightclubs. A lot operate on paper and calculators and would greatly benefit from an on-site data scientist/engineer to create insightful dashboards, attendance/revenue forecasts, and just overall lending a helping hand bringing the club backend to modern standards.\n\nI just want some perspective from those who work in a non-traditional role and how you got your foot in the door.\n\nThanks", "author_fullname": "t2_p3oo7xu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting started in non-traditional roles (e.g. nightclubs)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xva5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689183582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone here work somewhere that traditionally doesn&amp;#39;t have a robust technical recruitment pipeline?&lt;/p&gt;\n\n&lt;p&gt;An example, and my goal, is nightclubs. A lot operate on paper and calculators and would greatly benefit from an on-site data scientist/engineer to create insightful dashboards, attendance/revenue forecasts, and just overall lending a helping hand bringing the club backend to modern standards.&lt;/p&gt;\n\n&lt;p&gt;I just want some perspective from those who work in a non-traditional role and how you got your foot in the door.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xva5f", "is_robot_indexable": true, "report_reasons": null, "author": "knavishly_vibrant38", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xva5f/getting_started_in_nontraditional_roles_eg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xva5f/getting_started_in_nontraditional_roles_eg/", "subreddit_subscribers": 947234, "created_utc": 1689183582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How often  have you actually come across over qualified candidates for a data science position ? \n\nHow have the results been when you interview them and they tick all the boxes?", "author_fullname": "t2_mloui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Over qualified candidates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y5os5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689208299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How often  have you actually come across over qualified candidates for a data science position ? &lt;/p&gt;\n\n&lt;p&gt;How have the results been when you interview them and they tick all the boxes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14y5os5", "is_robot_indexable": true, "report_reasons": null, "author": "Asshaisin", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14y5os5/over_qualified_candidates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14y5os5/over_qualified_candidates/", "subreddit_subscribers": 947234, "created_utc": 1689208299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I developed a movie recommendation system using Next.js and FastAPI, but I encountered serverless function size limitations when attempting to host it on Vercel, even after experimenting with smaller models. What can I do at this point?  It would be perfect if there were a free hosting option available. ", "author_fullname": "t2_k9zi1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I deploy my hobby project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yepoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689235977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I developed a movie recommendation system using Next.js and FastAPI, but I encountered serverless function size limitations when attempting to host it on Vercel, even after experimenting with smaller models. What can I do at this point?  It would be perfect if there were a free hosting option available. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yepoc", "is_robot_indexable": true, "report_reasons": null, "author": "bahoho", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yepoc/where_can_i_deploy_my_hobby_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yepoc/where_can_i_deploy_my_hobby_project/", "subreddit_subscribers": 947234, "created_utc": 1689235977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it possible to work as a data scientist in the political field? If yes, what would be an example job?", "author_fullname": "t2_8jxi3akg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With a political science background into data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yaqwr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689222906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to work as a data scientist in the political field? If yes, what would be an example job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yaqwr", "is_robot_indexable": true, "report_reasons": null, "author": "Revenge_is_Coming", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yaqwr/with_a_political_science_background_into_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yaqwr/with_a_political_science_background_into_data/", "subreddit_subscribers": 947234, "created_utc": 1689222906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey so I'm an intern right now, and I'm tasked with creating a model that takes in the initial order conditions (multitouch attribution, amount ordered, product, etc on first order) and predicts the LTV after 3,6,9, and 12 months. \n\nI used a decision tree and created 3 different models to predict the LTV of a month 0 customer and its of satisfactory accuracy, but I now realize I will probably need to make 4 different model for every customer cohort (when they bought), meaning I will have to make a whole lot of models.\n\nThis is very doable, the models run pretty fast, and I have around 150,000 pieces of training data, but the way I am doing it feels incredibly sloppy and suboptimal (I pretty much know it is, I just don't know an easy workaround). Any help is much appreciated for an internet in need!", "author_fullname": "t2_bmx0x96q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to creating 20 different models to predict customer Life Time Value at different points?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xzc3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689192887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey so I&amp;#39;m an intern right now, and I&amp;#39;m tasked with creating a model that takes in the initial order conditions (multitouch attribution, amount ordered, product, etc on first order) and predicts the LTV after 3,6,9, and 12 months. &lt;/p&gt;\n\n&lt;p&gt;I used a decision tree and created 3 different models to predict the LTV of a month 0 customer and its of satisfactory accuracy, but I now realize I will probably need to make 4 different model for every customer cohort (when they bought), meaning I will have to make a whole lot of models.&lt;/p&gt;\n\n&lt;p&gt;This is very doable, the models run pretty fast, and I have around 150,000 pieces of training data, but the way I am doing it feels incredibly sloppy and suboptimal (I pretty much know it is, I just don&amp;#39;t know an easy workaround). Any help is much appreciated for an internet in need!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xzc3e", "is_robot_indexable": true, "report_reasons": null, "author": "Opening-Education-88", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xzc3e/alternatives_to_creating_20_different_models_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xzc3e/alternatives_to_creating_20_different_models_to/", "subreddit_subscribers": 947234, "created_utc": 1689192887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_hccf1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vanna: Generate SQL using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14xyfav", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nCyaezNTdbXzV4H6TWK_PfbGvl_DvDoGkQHevRALOjU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689190776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/vanna-ai/vanna-py", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?auto=webp&amp;s=100f4708f96b90c6da0a2aedd316991f9de1e09e", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d372eac8bc09b5feecc623570ee0e3f256240b0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a8c93deaaa59d7ef4dc4f93e8e59bff028a79f8d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6c49ff83eb4de1b0cad42dfe0332d9c3416b1f5c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb08a3cbabdbb538e54e3f7b7a11a87293c1fe53", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d8d205fb460116096df1fd9f8f3b2697a5b802c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b0fd54791bf15922a3a1bebd000b5051d7790d03", "width": 1080, "height": 607}], "variants": {}, "id": "YkvUIM_b4CNQSWNtpeCdkahtxdm_7oPRMTgo11_lAIM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xyfav", "is_robot_indexable": true, "report_reasons": null, "author": "gogolang", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xyfav/vanna_generate_sql_using_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/vanna-ai/vanna-py", "subreddit_subscribers": 947234, "created_utc": 1689190776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Was up my people any armature/aspiring data scientist want to show each other work and talk about our work and see what we can we improve on, talk analytics, and compare our code?", "author_fullname": "t2_s63nck7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any aspiring DS want to show each other GitHub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y46d5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689204170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was up my people any armature/aspiring data scientist want to show each other work and talk about our work and see what we can we improve on, talk analytics, and compare our code?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14y46d5", "is_robot_indexable": true, "report_reasons": null, "author": "Papadude08", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14y46d5/any_aspiring_ds_want_to_show_each_other_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14y46d5/any_aspiring_ds_want_to_show_each_other_github/", "subreddit_subscribers": 947234, "created_utc": 1689204170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is there any way to read towards datascience blogs for free? I have tried mozilla extensions....but they don't work.....and also used temp mail to create new account.....but all in vein.", "author_fullname": "t2_av8t9hbl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Towards datascience blog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ylfk5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689256215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any way to read towards datascience blogs for free? I have tried mozilla extensions....but they don&amp;#39;t work.....and also used temp mail to create new account.....but all in vein.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ylfk5", "is_robot_indexable": true, "report_reasons": null, "author": "No_Understanding1485", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ylfk5/towards_datascience_blog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ylfk5/towards_datascience_blog/", "subreddit_subscribers": 947234, "created_utc": 1689256215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Did a search on LinkedIn the other day for job title of data scientist in my area, Atlanta metropolitan area. Came up with almost no results. Thought hey, that's weird, maybe if I go remote that'll help. Same result, on a wider scale. Actual job title of data scientists is completely disappearing. There are barely any jobs left with that job title that I can find currently. Statistical programmer seems to come up a lot, operations research, research analyst, machine learning engineer, things like that. But those jobs are not data scientist jobs. In fact, those often have A very different skill set and completely different scale of responsibilities, for example statistical programmer not only do they want some of the data science skill set, they want a lot of programming, extremely heavy programming, and they make it sound like you're going to be doing 70 plus hours a week of just insanely intense programming and analytics work", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "All the \"data scientist\" jobs are disappearing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ym97z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689258225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did a search on LinkedIn the other day for job title of data scientist in my area, Atlanta metropolitan area. Came up with almost no results. Thought hey, that&amp;#39;s weird, maybe if I go remote that&amp;#39;ll help. Same result, on a wider scale. Actual job title of data scientists is completely disappearing. There are barely any jobs left with that job title that I can find currently. Statistical programmer seems to come up a lot, operations research, research analyst, machine learning engineer, things like that. But those jobs are not data scientist jobs. In fact, those often have A very different skill set and completely different scale of responsibilities, for example statistical programmer not only do they want some of the data science skill set, they want a lot of programming, extremely heavy programming, and they make it sound like you&amp;#39;re going to be doing 70 plus hours a week of just insanely intense programming and analytics work&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ym97z", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ym97z/all_the_data_scientist_jobs_are_disappearing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ym97z/all_the_data_scientist_jobs_are_disappearing/", "subreddit_subscribers": 947234, "created_utc": 1689258225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been trying to teach myself various aspects of DS but coming to the horrifying realization I need to actually start a project. \n\nI followed a \"kdnuggets\" guide to getting some info for a YouTube channel and I managed to get it done for a friend's channel, although the data is useless, and the process is SO complicated with so many steps that in the end, my eyes were just glazed over and I was just copy pasting code then dealing with errors. So obviously I didn't really learn anything, and I don't have any useful data to do a project with; I had hoped I mightve been able to use this data to do some analysis with. \n\nCan anyone suggest any good resources to actually learn this process, as well as maybe some suggestions for where I can get actual useful data?", "author_fullname": "t2_asgejs9xc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A good guide to learning to scrape data with APIs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ylzry", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689257589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been trying to teach myself various aspects of DS but coming to the horrifying realization I need to actually start a project. &lt;/p&gt;\n\n&lt;p&gt;I followed a &amp;quot;kdnuggets&amp;quot; guide to getting some info for a YouTube channel and I managed to get it done for a friend&amp;#39;s channel, although the data is useless, and the process is SO complicated with so many steps that in the end, my eyes were just glazed over and I was just copy pasting code then dealing with errors. So obviously I didn&amp;#39;t really learn anything, and I don&amp;#39;t have any useful data to do a project with; I had hoped I mightve been able to use this data to do some analysis with. &lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest any good resources to actually learn this process, as well as maybe some suggestions for where I can get actual useful data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ylzry", "is_robot_indexable": true, "report_reasons": null, "author": "Embarrassed_Sky_yes", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ylzry/a_good_guide_to_learning_to_scrape_data_with_apis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ylzry/a_good_guide_to_learning_to_scrape_data_with_apis/", "subreddit_subscribers": 947234, "created_utc": 1689257589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/14yfb81)", "author_fullname": "t2_2kh4l8ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientists, do you still train models locally for work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yfb81", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689238061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14yfb81\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "14yfb81", "is_robot_indexable": true, "report_reasons": null, "author": "supper_ham", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1689497261993, "options": [{"text": "Local machine", "id": "23870804"}, {"text": "Cloud", "id": "23870805"}, {"text": "Company servers", "id": "23870806"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 236, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yfb81/data_scientists_do_you_still_train_models_locally/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/14yfb81/data_scientists_do_you_still_train_models_locally/", "subreddit_subscribers": 947234, "created_utc": 1689238061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_h7ibth00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best speech to text apis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yl8ez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689255721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yl8ez", "is_robot_indexable": true, "report_reasons": null, "author": "pg860", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yl8ez/what_are_the_best_speech_to_text_apis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yl8ez/what_are_the_best_speech_to_text_apis/", "subreddit_subscribers": 947234, "created_utc": 1689255721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Whether hiring manager or candidate, which of the following methods do you prefer as means to vet technical experience and potential?\n\nEach of these have a flaw, but I want to get a gauge of what other methods exist for vetting candidates.\n\nRecently, my team have found that a couple of the candidates have been cheating during their technical phone screening using ChatGPT/friend to answer questions. However, when we invited them onsite and asked them the same questions, their response was vastly different and incorrect. What's sad is most of the cheaters that our recruiters vetted were ironically coming from top nearby firms (MANGA), and I cannot believe how they managed to work at those firms if they cannot answer data related questions. This includes a candidate who failed to do a simple aggregate function in SQL (e.g. getting the average number of customers that used the app in a given month).\n\nOur operation is in the SF Bay Area, and we've been receiving around 500 applications per week. Given the competition, the recruiters have been vetting based on years of experience, immediate past company experience and keyword matching. \n\nGiven this scenario, how would you vet candidates effectively given the sheer volume of candidates?\n\n[View Poll](https://www.reddit.com/poll/14xw6ql)", "author_fullname": "t2_48648", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preferred Technical Interview Method", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xw6ql", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689185635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whether hiring manager or candidate, which of the following methods do you prefer as means to vet technical experience and potential?&lt;/p&gt;\n\n&lt;p&gt;Each of these have a flaw, but I want to get a gauge of what other methods exist for vetting candidates.&lt;/p&gt;\n\n&lt;p&gt;Recently, my team have found that a couple of the candidates have been cheating during their technical phone screening using ChatGPT/friend to answer questions. However, when we invited them onsite and asked them the same questions, their response was vastly different and incorrect. What&amp;#39;s sad is most of the cheaters that our recruiters vetted were ironically coming from top nearby firms (MANGA), and I cannot believe how they managed to work at those firms if they cannot answer data related questions. This includes a candidate who failed to do a simple aggregate function in SQL (e.g. getting the average number of customers that used the app in a given month).&lt;/p&gt;\n\n&lt;p&gt;Our operation is in the SF Bay Area, and we&amp;#39;ve been receiving around 500 applications per week. Given the competition, the recruiters have been vetting based on years of experience, immediate past company experience and keyword matching. &lt;/p&gt;\n\n&lt;p&gt;Given this scenario, how would you vet candidates effectively given the sheer volume of candidates?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14xw6ql\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "14xw6ql", "is_robot_indexable": true, "report_reasons": null, "author": "forbiscuit", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1689531235365, "options": [{"text": "Timed Take Home Coding Test (e.g. 1-3 hour HackerRank puzzle)", "id": "23862078"}, {"text": "Live Whiteboard/Screensharing Interview", "id": "23862079"}, {"text": "Open Book Take Home Assignments", "id": "23862080"}, {"text": "Technical Phone Screening (Q&amp;A format)", "id": "23862081"}, {"text": "Other", "id": "23862082"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 199, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xw6ql/preferred_technical_interview_method/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/14xw6ql/preferred_technical_interview_method/", "subreddit_subscribers": 947234, "created_utc": 1689185635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Background info: graduated with a marketing major and Econ minor in 2021, no coding experience whatsoever \n\nI figured the first place I should start is with getting some coding certifications but which ones do it get? Are there any good \u201cbase\u201d ones to get a start? Are there differences in which certifications to get? Just all around somewhat confused about how to get this ball rolling and would appreciate any advice/help.", "author_fullname": "t2_4291wa9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I know I want to work in data science, but where do I start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yjmxk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689251601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background info: graduated with a marketing major and Econ minor in 2021, no coding experience whatsoever &lt;/p&gt;\n\n&lt;p&gt;I figured the first place I should start is with getting some coding certifications but which ones do it get? Are there any good \u201cbase\u201d ones to get a start? Are there differences in which certifications to get? Just all around somewhat confused about how to get this ball rolling and would appreciate any advice/help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yjmxk", "is_robot_indexable": true, "report_reasons": null, "author": "EddieSpaghetti2950", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yjmxk/i_know_i_want_to_work_in_data_science_but_where/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yjmxk/i_know_i_want_to_work_in_data_science_but_where/", "subreddit_subscribers": 947234, "created_utc": 1689251601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a data analyst and haven't worked on DCJ (Digital Customer Journey) before. In my project I was assigned to handle DCJ and generate a flow and insights out of it.\n\nWith out talking about the Client or the industry this is an overview of how my data looks like.  \n\n\\--&gt; Large table with billions of records and comes down to millions if I filter for few customers and their interaction points with the website. (Data is very rough....)\n\n\\--&gt; Has the timestamp at which they went into each page and not so accurate page name.\n\n\\--&gt; Immediate previous page info is also available but not reliable.\n\n&amp;#x200B;\n\nMy problem is that I need to get the flow of the journey and insights for certain group of customers who left the company in the recent past.\n\nIf i check on the flow of a single customer. His/Her visit to common pages are so many (which is not useful). Eliminating the common pages makes the flow disturbed.\n\nCreating a generalized flow seems to be impossible.\n\nCurrently making experiments with parallel categories and Sankey diagram (very complex and client cannot understand)\n\n&amp;#x200B;\n\nHelp: I need suggestions on how to approach this project. I am totally stuck. \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_q60xrlzp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insight generation for Digital customer journey!!! Totally stuck", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yjmmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689251574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst and haven&amp;#39;t worked on DCJ (Digital Customer Journey) before. In my project I was assigned to handle DCJ and generate a flow and insights out of it.&lt;/p&gt;\n\n&lt;p&gt;With out talking about the Client or the industry this is an overview of how my data looks like.  &lt;/p&gt;\n\n&lt;p&gt;--&amp;gt; Large table with billions of records and comes down to millions if I filter for few customers and their interaction points with the website. (Data is very rough....)&lt;/p&gt;\n\n&lt;p&gt;--&amp;gt; Has the timestamp at which they went into each page and not so accurate page name.&lt;/p&gt;\n\n&lt;p&gt;--&amp;gt; Immediate previous page info is also available but not reliable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My problem is that I need to get the flow of the journey and insights for certain group of customers who left the company in the recent past.&lt;/p&gt;\n\n&lt;p&gt;If i check on the flow of a single customer. His/Her visit to common pages are so many (which is not useful). Eliminating the common pages makes the flow disturbed.&lt;/p&gt;\n\n&lt;p&gt;Creating a generalized flow seems to be impossible.&lt;/p&gt;\n\n&lt;p&gt;Currently making experiments with parallel categories and Sankey diagram (very complex and client cannot understand)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Help: I need suggestions on how to approach this project. I am totally stuck. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yjmmc", "is_robot_indexable": true, "report_reasons": null, "author": "hungry_man13", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yjmmc/insight_generation_for_digital_customer_journey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yjmmc/insight_generation_for_digital_customer_journey/", "subreddit_subscribers": 947234, "created_utc": 1689251574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone ! I\u2019m a master student and I\u2019m currently looking for participants for my psychology research, (18-25 yrs old wanted and living in UK). It\u2019s a 5-10 mins survey about social media and self-esteem.  It would be wonderful if any of you participated. Thank you! https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV_56aKJ4ajKHvSIbc", "author_fullname": "t2_dgps546ru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for participants", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yib1o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689247833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone ! I\u2019m a master student and I\u2019m currently looking for participants for my psychology research, (18-25 yrs old wanted and living in UK). It\u2019s a 5-10 mins survey about social media and self-esteem.  It would be wonderful if any of you participated. Thank you! &lt;a href=\"https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV_56aKJ4ajKHvSIbc\"&gt;https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV_56aKJ4ajKHvSIbc&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yib1o", "is_robot_indexable": true, "report_reasons": null, "author": "Anissa-rf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yib1o/looking_for_participants/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yib1o/looking_for_participants/", "subreddit_subscribers": 947234, "created_utc": 1689247833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built a python library for automating data normalisation, schema creation and loading to db. WDYT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ygl6x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_uamr9xer", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks,\n\nFor the past 2 years I've been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, ddl generation, self deployment, schema evolution... basically, as you build better and better pipelines you will want more and more.\n\nThe value proposition is to automate the tedious work you do, so you can focus on better things.\n\nSo dlt is a library where in the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading.\n\nIn its most complex form, you can do almost anything you can want, from memory management, multithreading, extraction DAGs, etc.\n\nThe library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community.\n\nFeedback is very welcome and so are requests for features or destinations.\n\nThe library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.[https://dlthub.com/](https://dlthub.com/)  \n\n\nI know lots of you are jaded and fed up with toy technologies - this is not a toy tech, it's purpose made for productivity and sanity.\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python library for automating data normalisation, schema creation and loading to db", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yfh6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689238840.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689238647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks,&lt;/p&gt;\n\n&lt;p&gt;For the past 2 years I&amp;#39;ve been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, ddl generation, self deployment, schema evolution... basically, as you build better and better pipelines you will want more and more.&lt;/p&gt;\n\n&lt;p&gt;The value proposition is to automate the tedious work you do, so you can focus on better things.&lt;/p&gt;\n\n&lt;p&gt;So dlt is a library where in the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading.&lt;/p&gt;\n\n&lt;p&gt;In its most complex form, you can do almost anything you can want, from memory management, multithreading, extraction DAGs, etc.&lt;/p&gt;\n\n&lt;p&gt;The library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community.&lt;/p&gt;\n\n&lt;p&gt;Feedback is very welcome and so are requests for features or destinations.&lt;/p&gt;\n\n&lt;p&gt;The library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.&lt;a href=\"https://dlthub.com/\"&gt;https://dlthub.com/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I know lots of you are jaded and fed up with toy technologies - this is not a toy tech, it&amp;#39;s purpose made for productivity and sanity.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?auto=webp&amp;s=cb39faa311105e22445462cdf83958c4587fedc2", "width": 1200, "height": 898}, "resolutions": [{"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2950fb9a02e9cdd0b136f3013b72924854fdca3f", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f0af0e48140a561a1f7b733a96875956b6389de", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25c5e30c984451ee6ea10cd4e1067e85319086d3", "width": 320, "height": 239}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=784ffdd500b6cb71463c17b9d348b620c417e6b2", "width": 640, "height": 478}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a966fccda316bcff3aef7e4ae872efc79cabbc1", "width": 960, "height": 718}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec5a6d47433e6864a169a05e9319caa70258c58d", "width": 1080, "height": 808}], "variants": {}, "id": "cUuEsBHL5TMhrkQNJ9leYxFMOF6VgvTJ_EKHwExrn8Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14yfh6p", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "subreddit_subscribers": 115594, "created_utc": 1689238647.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1689242433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?auto=webp&amp;s=cb39faa311105e22445462cdf83958c4587fedc2", "width": 1200, "height": 898}, "resolutions": [{"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2950fb9a02e9cdd0b136f3013b72924854fdca3f", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f0af0e48140a561a1f7b733a96875956b6389de", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25c5e30c984451ee6ea10cd4e1067e85319086d3", "width": 320, "height": 239}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=784ffdd500b6cb71463c17b9d348b620c417e6b2", "width": 640, "height": 478}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a966fccda316bcff3aef7e4ae872efc79cabbc1", "width": 960, "height": 718}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec5a6d47433e6864a169a05e9319caa70258c58d", "width": 1080, "height": 808}], "variants": {}, "id": "cUuEsBHL5TMhrkQNJ9leYxFMOF6VgvTJ_EKHwExrn8Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ygl6x", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14yfh6p", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ygl6x/i_built_a_python_library_for_automating_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "subreddit_subscribers": 947234, "created_utc": 1689242433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been out of school for 2 years and have been trying to get a job the entire time in the US. No matter how many resumes I send out, no one is even seeing me for an interview. I didn't do too badly in college (over 3.0 GPA) and am getting really frustrated with no one giving me any attention. I have also been doing coding projects online so my computer programming skills don't dull. Is there any way I can make myself more marketable?", "author_fullname": "t2_omkcn0p6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xyu3i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689191744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been out of school for 2 years and have been trying to get a job the entire time in the US. No matter how many resumes I send out, no one is even seeing me for an interview. I didn&amp;#39;t do too badly in college (over 3.0 GPA) and am getting really frustrated with no one giving me any attention. I have also been doing coding projects online so my computer programming skills don&amp;#39;t dull. Is there any way I can make myself more marketable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xyu3i", "is_robot_indexable": true, "report_reasons": null, "author": "GainAffectionate7196", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xyu3i/job_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xyu3i/job_help/", "subreddit_subscribers": 947234, "created_utc": 1689191744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Greetings, everyone! I am working on a project, and I need to clean data on a excel sheet. I was wondering if someone knew of a service (or you yourself could help) that can clean data. The data from the spread sheet has +60000 rows and I need 3-5 specific columns. The columns I am looking for are Name, Location, Date. However, the column Name sometime has Location and Date included in that single entry. In addition, the entries for Name are sometimes abbreviated as well as for Location and Date. I believe the data cleaning is advanced. ", "author_fullname": "t2_6npgrd5e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone who anyone who can clean data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xvrol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689184707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings, everyone! I am working on a project, and I need to clean data on a excel sheet. I was wondering if someone knew of a service (or you yourself could help) that can clean data. The data from the spread sheet has +60000 rows and I need 3-5 specific columns. The columns I am looking for are Name, Location, Date. However, the column Name sometime has Location and Date included in that single entry. In addition, the entries for Name are sometimes abbreviated as well as for Location and Date. I believe the data cleaning is advanced. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xvrol", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished_Ad_5697", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xvrol/does_anyone_who_anyone_who_can_clean_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xvrol/does_anyone_who_anyone_who_can_clean_data/", "subreddit_subscribers": 947234, "created_utc": 1689184707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "People in this field has their own repo over GitHub or other platforms.\nBut it is also easy to download someone else's work and upload to a new repo and call it out as my own.\nHow can recruiter know about such fake repos and filter out people who are showing off.", "author_fullname": "t2_9dgp42l3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you identify genuine repos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14yoheq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689263542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;People in this field has their own repo over GitHub or other platforms.\nBut it is also easy to download someone else&amp;#39;s work and upload to a new repo and call it out as my own.\nHow can recruiter know about such fake repos and filter out people who are showing off.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yoheq", "is_robot_indexable": true, "report_reasons": null, "author": "Miserable-Ad-4849", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yoheq/how_do_you_identify_genuine_repos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yoheq/how_do_you_identify_genuine_repos/", "subreddit_subscribers": 947234, "created_utc": 1689263542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you have some kind of iterative feedback loop that helps you update your approach to a given analysis/model?\n\nDo your stakeholders hold you accountable in some way that helps you grow your expertise in certain methods?", "author_fullname": "t2_apemm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you know the methods you're using are appropriate in your work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14yodfe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689263287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have some kind of iterative feedback loop that helps you update your approach to a given analysis/model?&lt;/p&gt;\n\n&lt;p&gt;Do your stakeholders hold you accountable in some way that helps you grow your expertise in certain methods?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yodfe", "is_robot_indexable": true, "report_reasons": null, "author": "WhosaWhatsa", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yodfe/how_do_you_know_the_methods_youre_using_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yodfe/how_do_you_know_the_methods_youre_using_are/", "subreddit_subscribers": 947234, "created_utc": 1689263287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!  \n\n\nThank you in advance for your help. I am analyzing some behavioral data, where a subject can be in one of 4 locations. I plan to analyze a difference score; however, I'm only concerned about the difference between 2 locations (location 1 and 4). My first thought was to simply create a score based on \"time in location 1\" - \"time in location 4\". Yet, the subjects can spend varying amounts of time in 1 of the other two locations. Would this suggest some form of normalization or standardization might be beneficial? I know typically it's done when the two values run on different scales, so I'm not 100% sure this situation requires it. Thank you again!", "author_fullname": "t2_3r5mfjkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I standardize/normalize this difference score?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14yo22y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689262531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!  &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help. I am analyzing some behavioral data, where a subject can be in one of 4 locations. I plan to analyze a difference score; however, I&amp;#39;m only concerned about the difference between 2 locations (location 1 and 4). My first thought was to simply create a score based on &amp;quot;time in location 1&amp;quot; - &amp;quot;time in location 4&amp;quot;. Yet, the subjects can spend varying amounts of time in 1 of the other two locations. Would this suggest some form of normalization or standardization might be beneficial? I know typically it&amp;#39;s done when the two values run on different scales, so I&amp;#39;m not 100% sure this situation requires it. Thank you again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yo22y", "is_robot_indexable": true, "report_reasons": null, "author": "Sir_Nerdly", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yo22y/should_i_standardizenormalize_this_difference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yo22y/should_i_standardizenormalize_this_difference/", "subreddit_subscribers": 947234, "created_utc": 1689262531.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}