{"kind": "Listing", "data": {"after": "t3_14y0nys", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got into a data engineering role, it's my first job as a DE. And i am feeling absolutely lost, i don't understand what's happening, everything is everywhere, my team mates are very busy so no one properly explains what's happening and some structural change is happening in the whole section of DE teams. And I feel absolutely overwhelmed.\nHow do you tackle this?", "author_fullname": "t2_vn1meuc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal to feel completely lost during initial months of your data engineering job ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xhi13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 106, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 106, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689147891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got into a data engineering role, it&amp;#39;s my first job as a DE. And i am feeling absolutely lost, i don&amp;#39;t understand what&amp;#39;s happening, everything is everywhere, my team mates are very busy so no one properly explains what&amp;#39;s happening and some structural change is happening in the whole section of DE teams. And I feel absolutely overwhelmed.\nHow do you tackle this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xhi13", "is_robot_indexable": true, "report_reasons": null, "author": "jojobaoil68", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xhi13/is_it_normal_to_feel_completely_lost_during/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xhi13/is_it_normal_to_feel_completely_lost_during/", "subreddit_subscribers": 115477, "created_utc": 1689147891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone - for context I'm a DE with \\~3 YoE that I spent working in a small startup where I was, *for the most part*, the sole DE.  \nI was responsible for not only implementing an end-to-end data pipeline that handles data from ingestion to analytics dashboards but also built the websockets and APIs needed to interact with different parts of the pipeline - which I really liked.\n\nAround a month ago I got the opportunity to join a big company as a DE, both the job listing and the interview had big emphasis on experience with end-to-end data pipelines and good SWE practices.\n\nI figured this would be a great opportunity to work with more experienced engineers on a project with significantly more data than what I'm used to.\n\nThe data stack is: Airflow - dbt (core) - AWS S3 (data lake) - AWS Redshift (dw) - Quicksight.\n\nMost of the tasks I pick up involve building dbt models, solving merge conflicts, configuring Airflow DAGs or sometimes assisting the analytics team.\n\nThe good thing is that the company has a great data culture and big emphasis on CI/CD and good SWE practices - they also insist on having DEs handle the building of dbt models and query optimization which is a good thing imo.\n\nMy major concern however is that the role doesn't feel as technically challenging as I was hoping for it to be, so do you guys think this is a good position to progress my career long term *from a technical standpoint* or should I keep an eye on other opportunities ?", "author_fullname": "t2_pna4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joined a new company as a DE for a big project and I'm feeling a bit underwhelmed - Would like to hear a second opinion.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xkfjd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689157100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone - for context I&amp;#39;m a DE with ~3 YoE that I spent working in a small startup where I was, &lt;em&gt;for the most part&lt;/em&gt;, the sole DE.&lt;br/&gt;\nI was responsible for not only implementing an end-to-end data pipeline that handles data from ingestion to analytics dashboards but also built the websockets and APIs needed to interact with different parts of the pipeline - which I really liked.&lt;/p&gt;\n\n&lt;p&gt;Around a month ago I got the opportunity to join a big company as a DE, both the job listing and the interview had big emphasis on experience with end-to-end data pipelines and good SWE practices.&lt;/p&gt;\n\n&lt;p&gt;I figured this would be a great opportunity to work with more experienced engineers on a project with significantly more data than what I&amp;#39;m used to.&lt;/p&gt;\n\n&lt;p&gt;The data stack is: Airflow - dbt (core) - AWS S3 (data lake) - AWS Redshift (dw) - Quicksight.&lt;/p&gt;\n\n&lt;p&gt;Most of the tasks I pick up involve building dbt models, solving merge conflicts, configuring Airflow DAGs or sometimes assisting the analytics team.&lt;/p&gt;\n\n&lt;p&gt;The good thing is that the company has a great data culture and big emphasis on CI/CD and good SWE practices - they also insist on having DEs handle the building of dbt models and query optimization which is a good thing imo.&lt;/p&gt;\n\n&lt;p&gt;My major concern however is that the role doesn&amp;#39;t feel as technically challenging as I was hoping for it to be, so do you guys think this is a good position to progress my career long term &lt;em&gt;from a technical standpoint&lt;/em&gt; or should I keep an eye on other opportunities ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xkfjd", "is_robot_indexable": true, "report_reasons": null, "author": "King_TN", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xkfjd/joined_a_new_company_as_a_de_for_a_big_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xkfjd/joined_a_new_company_as_a_de_for_a_big_project/", "subreddit_subscribers": 115477, "created_utc": 1689157100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At work we\u2019re building a lil\u2019 pipeline. Nothing fancy, just reads data from a few API\u2019s, normalizes them and sticks em in a table in our DB. \n\nWe\u2019re trying out airflow for this, and we\u2019ve been putting all of the actual code into DAGs in airflow. So, all python.\n\nI saw another post that mentioned how airflow is mostly a \u201cjob scheduler\u201d, which made me second-guess keeping all of our code in airflow DAGs. So I\u2019m wondering: do y\u2019all use airflow primarily as a scheduler for jobs that are owned by other services, or do you also rely on it to run business logic?\n\nIf that\u2019s too vague, here\u2019s a specific example:\nIdeally, I\u2019d have all of my data pulling/normalizing code in rust. We already have a nicely setup rust environment, and that\u2019s how I would handle our pipeline if it was just gonna be rust scripts and a bunch of cron jobs. \nBut since airflow has so many easy integrations, we decided just to let airflow (and thusly python DAGs) handle all of the data pulling and normalization. \n\nIs the \u201ccorrect\u201d way to use airflow:\n1) having airflow trigger rust scripts?\n2) having airflow handle everything from within airflow?", "author_fullname": "t2_8k5ls63w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is airflow better for triggering jobs in a data pipeline, or actually running the jobs itself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y3s4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689203208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At work we\u2019re building a lil\u2019 pipeline. Nothing fancy, just reads data from a few API\u2019s, normalizes them and sticks em in a table in our DB. &lt;/p&gt;\n\n&lt;p&gt;We\u2019re trying out airflow for this, and we\u2019ve been putting all of the actual code into DAGs in airflow. So, all python.&lt;/p&gt;\n\n&lt;p&gt;I saw another post that mentioned how airflow is mostly a \u201cjob scheduler\u201d, which made me second-guess keeping all of our code in airflow DAGs. So I\u2019m wondering: do y\u2019all use airflow primarily as a scheduler for jobs that are owned by other services, or do you also rely on it to run business logic?&lt;/p&gt;\n\n&lt;p&gt;If that\u2019s too vague, here\u2019s a specific example:\nIdeally, I\u2019d have all of my data pulling/normalizing code in rust. We already have a nicely setup rust environment, and that\u2019s how I would handle our pipeline if it was just gonna be rust scripts and a bunch of cron jobs. \nBut since airflow has so many easy integrations, we decided just to let airflow (and thusly python DAGs) handle all of the data pulling and normalization. &lt;/p&gt;\n\n&lt;p&gt;Is the \u201ccorrect\u201d way to use airflow:\n1) having airflow trigger rust scripts?\n2) having airflow handle everything from within airflow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14y3s4r", "is_robot_indexable": true, "report_reasons": null, "author": "chamomile-crumbs", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y3s4r/is_airflow_better_for_triggering_jobs_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y3s4r/is_airflow_better_for_triggering_jobs_in_a_data/", "subreddit_subscribers": 115477, "created_utc": 1689203208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team is looking at writing a simple framework/platform based on Cloud that'd allow various users to define batch based pipelines. Currently focusing on AWS, there are multiple modules which setup a set of services, dynamic infrastructure, orchestration, roles, notifications for the users as part of the platform. \n\nAs part of orchestration, I started looking at Dagster and one of the thing I immediately realized is that the actual data processing and orchestration is intertwined and deliberately kept together in most of the examples I saw and also a forte of Dagster as I understand compared to the traditional orhestration/workflow frameworks where they are loosely coupled and a DAG is defined.   \n\n\nWhen I look at any orchestrator, the main things I look for is that - orchestration, meaning given a set of tasks, it should be able to execute, report on, track, kill at will, rollback, fanout, do reporting and maintain metadata for it. Combining this with the actual data being processed as part of the actions/tasks is a great thing for small scale pipelines but quickly becomes a scaling/deployment problem if I want to make it available as a service (not looking for Dagster cloud yet) where users can submit many such jobs.   \n\n\nI understand and yet to explore the constructs such as Assets, Operators that allow me integrate with external services (in my case the cloud services which I'd integrate with a good wrapper over common AWS managed services and compute) but before I proceed wanted to check if I am not setting myself on a wrong path just because its supports but is indeed an antipattern.   \n\n\nWhy separate actual compute from orchestration ?   \n\\- I want to fully exploit and use existing AWS services where given a script (say the script/python code utilizing say polars,pandas, duckdb etc), I have a freedom to pack and run it as a docker image on ECS, Fargate, or lamda   \n\\- For a very big workloads, which don't fit into services such as AWS Glue/Redshift for ELT/ETL purpose, be able to spawn an appliance say through spot and get it executed in EC2 and so on..  \n\n\n.. and still use Dagster as a pure orchestrator where it can have a shim layer written that not only launches but tracks these jobs very well, helps with retries, rollbacks etc.", "author_fullname": "t2_qg4yidm6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster - Separating compute and orchestration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xodd2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team is looking at writing a simple framework/platform based on Cloud that&amp;#39;d allow various users to define batch based pipelines. Currently focusing on AWS, there are multiple modules which setup a set of services, dynamic infrastructure, orchestration, roles, notifications for the users as part of the platform. &lt;/p&gt;\n\n&lt;p&gt;As part of orchestration, I started looking at Dagster and one of the thing I immediately realized is that the actual data processing and orchestration is intertwined and deliberately kept together in most of the examples I saw and also a forte of Dagster as I understand compared to the traditional orhestration/workflow frameworks where they are loosely coupled and a DAG is defined.   &lt;/p&gt;\n\n&lt;p&gt;When I look at any orchestrator, the main things I look for is that - orchestration, meaning given a set of tasks, it should be able to execute, report on, track, kill at will, rollback, fanout, do reporting and maintain metadata for it. Combining this with the actual data being processed as part of the actions/tasks is a great thing for small scale pipelines but quickly becomes a scaling/deployment problem if I want to make it available as a service (not looking for Dagster cloud yet) where users can submit many such jobs.   &lt;/p&gt;\n\n&lt;p&gt;I understand and yet to explore the constructs such as Assets, Operators that allow me integrate with external services (in my case the cloud services which I&amp;#39;d integrate with a good wrapper over common AWS managed services and compute) but before I proceed wanted to check if I am not setting myself on a wrong path just because its supports but is indeed an antipattern.   &lt;/p&gt;\n\n&lt;p&gt;Why separate actual compute from orchestration ?&lt;br/&gt;\n- I want to fully exploit and use existing AWS services where given a script (say the script/python code utilizing say polars,pandas, duckdb etc), I have a freedom to pack and run it as a docker image on ECS, Fargate, or lamda&lt;br/&gt;\n- For a very big workloads, which don&amp;#39;t fit into services such as AWS Glue/Redshift for ELT/ETL purpose, be able to spawn an appliance say through spot and get it executed in EC2 and so on..  &lt;/p&gt;\n\n&lt;p&gt;.. and still use Dagster as a pure orchestrator where it can have a shim layer written that not only launches but tracks these jobs very well, helps with retries, rollbacks etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xodd2", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Cartoonist7071", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xodd2/dagster_separating_compute_and_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xodd2/dagster_separating_compute_and_orchestration/", "subreddit_subscribers": 115477, "created_utc": 1689167886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work in a healthcare company. We use SSIS and SSMS (SQL) for most of our data needs. On the rare occasion, we also use C#, Python, and Powershell. Is this stack good enough to start job hunting or would it be better to pick up some software-specific skills? I thought about learning GCP or AWS but am not sure the likelihood of getting hired with only self-study on those topics. I've been at my current company for 8 years (intern -&gt; data analyst -&gt; database engineer) and it's a good environment / fully remote, but the money just isn't there. I'm currently making $75k/80k a year depending on bonus and yearly raises are 2%. ", "author_fullname": "t2_1b2ivfkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to further career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xwkrp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689186554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work in a healthcare company. We use SSIS and SSMS (SQL) for most of our data needs. On the rare occasion, we also use C#, Python, and Powershell. Is this stack good enough to start job hunting or would it be better to pick up some software-specific skills? I thought about learning GCP or AWS but am not sure the likelihood of getting hired with only self-study on those topics. I&amp;#39;ve been at my current company for 8 years (intern -&amp;gt; data analyst -&amp;gt; database engineer) and it&amp;#39;s a good environment / fully remote, but the money just isn&amp;#39;t there. I&amp;#39;m currently making $75k/80k a year depending on bonus and yearly raises are 2%. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xwkrp", "is_robot_indexable": true, "report_reasons": null, "author": "WhelminglyMediocre", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xwkrp/how_to_further_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xwkrp/how_to_further_career/", "subreddit_subscribers": 115477, "created_utc": 1689186554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm actually going to make this, so I want to make sure I don't leave out any great jokes. What should the office look like? What struggles should I include? What would make you laugh? ", "author_fullname": "t2_68z0an9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If there was a nature documentary about the \"datus engineerius\" and it's life inside of the corporate habitat, what kinds of things would for sure be pointed out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xoc20", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m actually going to make this, so I want to make sure I don&amp;#39;t leave out any great jokes. What should the office look like? What struggles should I include? What would make you laugh? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xoc20", "is_robot_indexable": true, "report_reasons": null, "author": "3spelledout", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xoc20/if_there_was_a_nature_documentary_about_the_datus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xoc20/if_there_was_a_nature_documentary_about_the_datus/", "subreddit_subscribers": 115477, "created_utc": 1689167792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've all no doubt seen the [\"St. Albnas\"](https://www.reddit.com/r/dataengineering/comments/14442pi/we_have_great_datasets/) meme by now. Data quality is hard \ud83e\udd26\ud83c\udffb\u200d\u2642\ufe0f.\n\nTo have some fun with this, the company I work for (Tinybird) is sponsoring a little \"hackathon\". Clean the data and avoid false positives to get some swag. No winners and losers, just participation prizes! (yay millennials!)\n\nMake sure to read the rules, and have some fun with it!\n\n[https://github.com/tinybirdco/st-albnas-hackathon](https://github.com/tinybirdco/st-albnas-hackathon)", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"St. Albnas\" Hackathon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xvfx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689183944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve all no doubt seen the &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14442pi/we_have_great_datasets/\"&gt;&amp;quot;St. Albnas&amp;quot;&lt;/a&gt; meme by now. Data quality is hard \ud83e\udd26\ud83c\udffb\u200d\u2642\ufe0f.&lt;/p&gt;\n\n&lt;p&gt;To have some fun with this, the company I work for (Tinybird) is sponsoring a little &amp;quot;hackathon&amp;quot;. Clean the data and avoid false positives to get some swag. No winners and losers, just participation prizes! (yay millennials!)&lt;/p&gt;\n\n&lt;p&gt;Make sure to read the rules, and have some fun with it!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/tinybirdco/st-albnas-hackathon\"&gt;https://github.com/tinybirdco/st-albnas-hackathon&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?auto=webp&amp;s=f0d96abead2cba1a7dcb3cd17af9aeee18d3b110", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=56cd9107ee58fa7c1de7d83a217464eb6edc661c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a032c60f128a58abe914c1be58fc4d197968b554", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cc621d87bd3645dd13b28c63cadc443dd7d9d708", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=880b60a66eaac91ceece4a1cd7fa73876c86604a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ffe2d888799e8c31a0af57a09bd1e70eb66d696", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3286eb4f4f474031681a6e19b9d2db3c9f2de5c", "width": 1080, "height": 540}], "variants": {}, "id": "GZPGBRybU-NIi8L9efQJzEa2WaNuknEOOl2vPCBbOfw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14xvfx1", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xvfx1/st_albnas_hackathon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xvfx1/st_albnas_hackathon/", "subreddit_subscribers": 115477, "created_utc": 1689183944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m frustrated at my attempts, as they seem to be going in circles, but I\u2019m just looking for better alternatives for what I\u2019m doing. \n\nI work in data migration, and at first it was fine, but now it\u2019s not scaling very well. I need to map non-normalized values to those my company has a set of standards for and so far my attempts just create tons of manual work. \n\nCurrently, I\u2019ve been building \u201cmaps\u201d of key/value pairs and coercing the values manually by removing formatting and things so I\u2019m only comparing lower case letters (and numbers if needed). By now some of maps are 100\u2019s off values in length or longer. A good example is a person\u2019s race, these values are user generated and we only allow a handful of things before we treat it differently. But there are a lot of different ways to denote a lot of different races\u2026 that\u2019s just one example obviously. \n\nI\u2019ve tried the `fuzzywuzzy` package which is partially reliable (only on Levenshtein distance). We don\u2019t have the budget for open ai either. \n\nCan anyone give me some ideas?\n\nThank you in advance!", "author_fullname": "t2_5am908px", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help mapping data in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y4yf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689206215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m frustrated at my attempts, as they seem to be going in circles, but I\u2019m just looking for better alternatives for what I\u2019m doing. &lt;/p&gt;\n\n&lt;p&gt;I work in data migration, and at first it was fine, but now it\u2019s not scaling very well. I need to map non-normalized values to those my company has a set of standards for and so far my attempts just create tons of manual work. &lt;/p&gt;\n\n&lt;p&gt;Currently, I\u2019ve been building \u201cmaps\u201d of key/value pairs and coercing the values manually by removing formatting and things so I\u2019m only comparing lower case letters (and numbers if needed). By now some of maps are 100\u2019s off values in length or longer. A good example is a person\u2019s race, these values are user generated and we only allow a handful of things before we treat it differently. But there are a lot of different ways to denote a lot of different races\u2026 that\u2019s just one example obviously. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried the &lt;code&gt;fuzzywuzzy&lt;/code&gt; package which is partially reliable (only on Levenshtein distance). We don\u2019t have the budget for open ai either. &lt;/p&gt;\n\n&lt;p&gt;Can anyone give me some ideas?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14y4yf7", "is_robot_indexable": true, "report_reasons": null, "author": "iambatmanman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y4yf7/need_help_mapping_data_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y4yf7/need_help_mapping_data_in_python/", "subreddit_subscribers": 115477, "created_utc": 1689206215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI was DS in Google and laid off 4 months ago and I couldn't find any DS position since then (Im living in Switzerland). And I find a great start up but they hiring data engineering position. I would really want to try it since I really like the culture of the company and I did a lot of pipelining in my DS role in Google. But I don't know how Data Eng case study interviews would be. I have no experience on that side and I can't find questions online, maybe i don't know how to search. Is there anyone can help me with mock interview for entry level positions? ", "author_fullname": "t2_78n8udb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to transition from DS to Data Eng, anyone wants to help with mock interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xtaru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689179129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I was DS in Google and laid off 4 months ago and I couldn&amp;#39;t find any DS position since then (Im living in Switzerland). And I find a great start up but they hiring data engineering position. I would really want to try it since I really like the culture of the company and I did a lot of pipelining in my DS role in Google. But I don&amp;#39;t know how Data Eng case study interviews would be. I have no experience on that side and I can&amp;#39;t find questions online, maybe i don&amp;#39;t know how to search. Is there anyone can help me with mock interview for entry level positions? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14xtaru", "is_robot_indexable": true, "report_reasons": null, "author": "hatidzhek", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xtaru/want_to_transition_from_ds_to_data_eng_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xtaru/want_to_transition_from_ds_to_data_eng_anyone/", "subreddit_subscribers": 115477, "created_utc": 1689179129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any easy way to calculate the minimum number of workers, drivers and memory needed in databricks? A website that does the calculation if any?", "author_fullname": "t2_aqp7hdzb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any websites to calculate Databricks drivers and workers required?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xgcwi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689144002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any easy way to calculate the minimum number of workers, drivers and memory needed in databricks? A website that does the calculation if any?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xgcwi", "is_robot_indexable": true, "report_reasons": null, "author": "johnyjohnyespappa", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xgcwi/any_websites_to_calculate_databricks_drivers_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xgcwi/any_websites_to_calculate_databricks_drivers_and/", "subreddit_subscribers": 115477, "created_utc": 1689144002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Those that work at amazon as data engineer, can you please tell me how your interview process was, how you prepped, what type of questions you were asked?", "author_fullname": "t2_3wpqg210", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "internal transfer to data engineer role at amazon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xzu9d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689194051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Those that work at amazon as data engineer, can you please tell me how your interview process was, how you prepped, what type of questions you were asked?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14xzu9d", "is_robot_indexable": true, "report_reasons": null, "author": "no_catchy_username", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xzu9d/internal_transfer_to_data_engineer_role_at_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xzu9d/internal_transfer_to_data_engineer_role_at_amazon/", "subreddit_subscribers": 115477, "created_utc": 1689194051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi team,\n\nI have ubuntu box where we run our python scripts of off.\n\nOne of my python scripts uses aws cli to extract data from....\n\nwhen i execute python script manually it will run.\n\nwhen i add this python script to run on crontab it starts...but doesnt go past 'aws cli command' executed almost at the very begining of python script.\n\nthe python script with aws CLI:\n\n \n\nsubprocess.run(\\[\"aws\", \"s3\", \"cp\", \"link\\_to\\_aws\\_stage\", \"download\\_to\\_path, \"--recursive\",\"--profile\",\"ABC\"\\])\n\n&amp;#x200B;\n\n**Question:**\n\nhow to workaround that?\n\nhow can i set which ubuntu users can access CLI ?\n\ndo you have any better idea\n\nthanks!\n\n&amp;#x200B;", "author_fullname": "t2_do9wxbfu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help with aws cli", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xqpch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689173421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi team,&lt;/p&gt;\n\n&lt;p&gt;I have ubuntu box where we run our python scripts of off.&lt;/p&gt;\n\n&lt;p&gt;One of my python scripts uses aws cli to extract data from....&lt;/p&gt;\n\n&lt;p&gt;when i execute python script manually it will run.&lt;/p&gt;\n\n&lt;p&gt;when i add this python script to run on crontab it starts...but doesnt go past &amp;#39;aws cli command&amp;#39; executed almost at the very begining of python script.&lt;/p&gt;\n\n&lt;p&gt;the python script with aws CLI:&lt;/p&gt;\n\n&lt;p&gt;subprocess.run([&amp;quot;aws&amp;quot;, &amp;quot;s3&amp;quot;, &amp;quot;cp&amp;quot;, &amp;quot;link_to_aws_stage&amp;quot;, &amp;quot;download_to_path, &amp;quot;--recursive&amp;quot;,&amp;quot;--profile&amp;quot;,&amp;quot;ABC&amp;quot;])&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;how to workaround that?&lt;/p&gt;\n\n&lt;p&gt;how can i set which ubuntu users can access CLI ?&lt;/p&gt;\n\n&lt;p&gt;do you have any better idea&lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xqpch", "is_robot_indexable": true, "report_reasons": null, "author": "87keicam", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xqpch/help_with_aws_cli/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xqpch/help_with_aws_cli/", "subreddit_subscribers": 115477, "created_utc": 1689173421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI have been a lurker forever in this sub and today i have decided to know your opinions in some points regarding the implementation of functional programming in Data Engineering (DE).\n\nAfter reading around this paradigm (most articles i have found converge to [Maxime Beauchemin article](https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a)), there are two points that makes my head scratch a bit:\n\n&amp;#x200B;\n\n* **Dimensional snapshots**:  The fact that this can create a lot of redundancy in dimensional tables, this really does not sound like a problem to me. I actually like the fact that with this approach avoids upserts and SCD's by just re-processing the data in a given time period. What i would like to understand is, for those who already implemented dimension snapshots, if the redundancy on the tables took a toll on the visualization tools performance big enough for you to get back to SCDs or something hybrid.\n* **Late arriving facts**: this is the point that really makes me avoid functional programming. Knowing that to we have to center our focus based on the event reception or processing time and not on the event time, it means in my opinion that the dimension partition scheme should be based on the event processing time too. However, the analysts surely do their work based on the event time which it will not benefit from the partition pruning. That could make any query based on the event time be way more costly.\n\nTake in note that i have been working more recently with BigQuery, in which the storage capacity is not a problem and you can partition a table with one column only (aside from clustering). Even in platforms that allows tables with multiple partitions i still think the second point potential costs and performance can be heavily affected.\n\nTake in account these two points, you think functional programming still can be something worth to implement in DE context?\n\nI hope my doubts were clear enough for you to share your take. Best regards!\n\n&amp;#x200B;", "author_fullname": "t2_4errm1ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Funtional Programming in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xq53v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689172144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have been a lurker forever in this sub and today i have decided to know your opinions in some points regarding the implementation of functional programming in Data Engineering (DE).&lt;/p&gt;\n\n&lt;p&gt;After reading around this paradigm (most articles i have found converge to &lt;a href=\"https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a\"&gt;Maxime Beauchemin article&lt;/a&gt;), there are two points that makes my head scratch a bit:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Dimensional snapshots&lt;/strong&gt;:  The fact that this can create a lot of redundancy in dimensional tables, this really does not sound like a problem to me. I actually like the fact that with this approach avoids upserts and SCD&amp;#39;s by just re-processing the data in a given time period. What i would like to understand is, for those who already implemented dimension snapshots, if the redundancy on the tables took a toll on the visualization tools performance big enough for you to get back to SCDs or something hybrid.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Late arriving facts&lt;/strong&gt;: this is the point that really makes me avoid functional programming. Knowing that to we have to center our focus based on the event reception or processing time and not on the event time, it means in my opinion that the dimension partition scheme should be based on the event processing time too. However, the analysts surely do their work based on the event time which it will not benefit from the partition pruning. That could make any query based on the event time be way more costly.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Take in note that i have been working more recently with BigQuery, in which the storage capacity is not a problem and you can partition a table with one column only (aside from clustering). Even in platforms that allows tables with multiple partitions i still think the second point potential costs and performance can be heavily affected.&lt;/p&gt;\n\n&lt;p&gt;Take in account these two points, you think functional programming still can be something worth to implement in DE context?&lt;/p&gt;\n\n&lt;p&gt;I hope my doubts were clear enough for you to share your take. Best regards!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?auto=webp&amp;s=cf073d9e898ab6b6aac9cbd3d617eb1a8d77093f", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e6ca8361de7a95cb6c47013c1938266c06cf1bff", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fae9102fa6d32f067e38cc3b24cc65481bb6ed33", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3efad0c05c8737f8d5c4ac99e42e7579dd97057", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4e73a5bddad916ba74ea62469de010438a9a993", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1fada96526d687a1d1efd7a1d8d1e5d7d033d9c8", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd93c47a0b2c95deabadee9d4fe6e3cc05529c5e", "width": 1080, "height": 720}], "variants": {}, "id": "QnHDt9HlR913WRkisNYJkFlw9Lr3Bt7UcxRxAQAkPdY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xq53v", "is_robot_indexable": true, "report_reasons": null, "author": "lou1uol", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xq53v/funtional_programming_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xq53v/funtional_programming_in_data_engineering/", "subreddit_subscribers": 115477, "created_utc": 1689172144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is how it is done:\n\nApache Doris preserves multiple replicas of hot data and the metadata in its backend nodes, and cold data in object storage with only one copy.\n\nhttps://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=116202b543f7ad10392348ddb036a5e125c49081\n\nFull post about [hot-cold data separation](https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High availability of data without consuming too much storage space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"n5t2a43epibb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e93b5fcaf295957400ac50c724629865333f96e"}, {"y": 175, "x": 216, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d3c3d93f39247aba6281cf8abaf9705596906f8"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c900bec99726a420282e06f3c9511c60d807c49"}, {"y": 520, "x": 640, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=46886e8b513861fb5c44f981484edac60289ad1d"}, {"y": 780, "x": 960, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d547c8b465733f08671882765b3a471b95d4ea7"}, {"y": 878, "x": 1080, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2e00bd44ba6a0107a00507b4afb50b27dfd768a6"}], "s": {"y": 1041, "x": 1280, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=116202b543f7ad10392348ddb036a5e125c49081"}, "id": "n5t2a43epibb1"}}, "name": "t3_14xlmy3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cA-TRKk2RQNysgWZvGrT-7xphAfBnKQJyJcIU1Q-Mrg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1689160617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is how it is done:&lt;/p&gt;\n\n&lt;p&gt;Apache Doris preserves multiple replicas of hot data and the metadata in its backend nodes, and cold data in object storage with only one copy.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=116202b543f7ad10392348ddb036a5e125c49081\"&gt;https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=116202b543f7ad10392348ddb036a5e125c49081&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Full post about &lt;a href=\"https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf\"&gt;hot-cold data separation&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?auto=webp&amp;s=9bb433a2d2af7659bbd2aaefc86e6440fb099982", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cebf42d866ba39ad8401ec16025d2e683cb5ec5", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0db6f5ac30249427128f2acbef98d324f22c2d1b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34cbad55217597ab7e3e1f50abad3c5bc069e0d7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5bc2ca5a2ba66071e1827faae996f0dc6f6e329c", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f46f655bcbbc72ddca3942cdffe318e8677b8735", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8874a5ffe10ae71db18d29c8e4b5f59d830878fe", "width": 1080, "height": 720}], "variants": {}, "id": "XHYrsxQam1UsYnZQ-ImG7NyQc780qMXf4eXuq9sAgzc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14xlmy3", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xlmy3/high_availability_of_data_without_consuming_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xlmy3/high_availability_of_data_without_consuming_too/", "subreddit_subscribers": 115477, "created_utc": 1689160617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Follow up post: [Previous post](https://www.reddit.com/r/dataengineering/comments/14o8h6h/data_engineer_looking_to_study_mechanical/?utm_source=share&amp;utm_medium=web2x&amp;context=3)\n\nHello, So as you know from last time, I was working on a GKE project, where I deployed a docker image that retrieves data from ADH and inserts it into BigQuery, Thank you everyone for your recommendation and your advices, I finally managed to finish the project, I scheduled, everything works perfectly!! My question is: how can I further improve the project by automating the deployment process? I was thinking of terraform and ansible, but I'm here once again to ask about your opinion, and if you have any advice!! \n\nEdit: I used Makefile but I think it's a bit clumsy \n\nTL;DR I want to automate the deployment process of pushing an image to artifact registry on google + apply workload cronjobs using ansible/terraform, Any advices? :D", "author_fullname": "t2_5u3c1gj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automate GKE deployment process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xj1mi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689152860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Follow up post: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14o8h6h/data_engineer_looking_to_study_mechanical/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;Previous post&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hello, So as you know from last time, I was working on a GKE project, where I deployed a docker image that retrieves data from ADH and inserts it into BigQuery, Thank you everyone for your recommendation and your advices, I finally managed to finish the project, I scheduled, everything works perfectly!! My question is: how can I further improve the project by automating the deployment process? I was thinking of terraform and ansible, but I&amp;#39;m here once again to ask about your opinion, and if you have any advice!! &lt;/p&gt;\n\n&lt;p&gt;Edit: I used Makefile but I think it&amp;#39;s a bit clumsy &lt;/p&gt;\n\n&lt;p&gt;TL;DR I want to automate the deployment process of pushing an image to artifact registry on google + apply workload cronjobs using ansible/terraform, Any advices? :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xj1mi", "is_robot_indexable": true, "report_reasons": null, "author": "iGodFather302", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xj1mi/automate_gke_deployment_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xj1mi/automate_gke_deployment_process/", "subreddit_subscribers": 115477, "created_utc": 1689152860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To keep it short I have no idea what title would be most suitable.\nI do dashboard design,build dashboard(js,css,html),I clean data and have to come up with new plans on how the data we have I can automate, I currently make no api calls (I do connect to databases but it\u2019s a system where I do not need to make api calls )or build databases YET. I do see myself in the future doing this and full stack SWE devolvement. I have no idea what the appropriate title for me would be.", "author_fullname": "t2_ilnryf6f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What am I?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y3akl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689202049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To keep it short I have no idea what title would be most suitable.\nI do dashboard design,build dashboard(js,css,html),I clean data and have to come up with new plans on how the data we have I can automate, I currently make no api calls (I do connect to databases but it\u2019s a system where I do not need to make api calls )or build databases YET. I do see myself in the future doing this and full stack SWE devolvement. I have no idea what the appropriate title for me would be.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14y3akl", "is_robot_indexable": true, "report_reasons": null, "author": "dany65ns", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y3akl/what_am_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y3akl/what_am_i/", "subreddit_subscribers": 115477, "created_utc": 1689202049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some background on myself. I recently transitioned into data engineering after 5 years as a data analyst and have been working at a startup since the beginning of the year on a contract basis. I'm practically the sole data engineer so I'm building end-to-end pipelines and I get to work with Python, SQL, DBT, Fivetran, Airflow, Postgres, MongoDB, Elasticsearch. I also do some Devops stuff - DigitalOcean is our main cloud service, but I also work with GCP and Azure (albeit at a surface level). I love the tech stack, but at the same time I'm worried I'm developing bad habits as an engineer since I'm working mostly independently and there's no proper CI/CD, at least for now. There's also no guarantee I'm gonna have a job in around 6 months since there's only a certain amount of money that's been reserved to fund my position, though there are efforts to get more funding.\n\nI recently received a job offer at a FinTech company where the core tech stack is DBT, SQL, Snowflake, and Airflow. Certain things that concern me:\n\n* Python seems to be a small part of the role. In my interview, they mentioned that Python would mostly be used to write up Airflow jobs. The job description also emphasizes more on SQL for deploying analytics code.\n* GCP, AWS or Azure not listed on job description. The team has devops engineers so I imagine they'll be the ones handling cloud infrastructure.\n* I've seen multiple job titles for the role, mainly \"Data Engineer\" and \"Analytics Engineer\". I asked them about this and they said that data and analytics engineers are one and the same to them, and they had put up the role under multiple titles to attract as many applicants as possible.\n\nSome positives I see for the role:\n\n* It's in a bigger proper engineering team, with a scrum master, other DevOps engineers, QA, etc. and CI/CD pipelines in place.\n* I got along well with the hiring manager, who really seems to know his stuff.\n* The team is rapidly expanding, which to me seems like a good sign.\n\nI've been applying to jobs for a couple months now, and I frequently see GCP/AWS/Azure experience as a requirement. Python is easily the most enjoyable part of my job, and I want to be viewed more as programmer or a SWE-focused DE in the long term rather than an analytics engineer or a SQL developer (no hate against these types of roles, they're just not what I'm looking for).\n\nAny advice would be greatly appreciated!\n\nEdit: Revised bullet point on cloud services", "author_fullname": "t2_3bhqq33p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take this job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xqg8d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689177749.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689172853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some background on myself. I recently transitioned into data engineering after 5 years as a data analyst and have been working at a startup since the beginning of the year on a contract basis. I&amp;#39;m practically the sole data engineer so I&amp;#39;m building end-to-end pipelines and I get to work with Python, SQL, DBT, Fivetran, Airflow, Postgres, MongoDB, Elasticsearch. I also do some Devops stuff - DigitalOcean is our main cloud service, but I also work with GCP and Azure (albeit at a surface level). I love the tech stack, but at the same time I&amp;#39;m worried I&amp;#39;m developing bad habits as an engineer since I&amp;#39;m working mostly independently and there&amp;#39;s no proper CI/CD, at least for now. There&amp;#39;s also no guarantee I&amp;#39;m gonna have a job in around 6 months since there&amp;#39;s only a certain amount of money that&amp;#39;s been reserved to fund my position, though there are efforts to get more funding.&lt;/p&gt;\n\n&lt;p&gt;I recently received a job offer at a FinTech company where the core tech stack is DBT, SQL, Snowflake, and Airflow. Certain things that concern me:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python seems to be a small part of the role. In my interview, they mentioned that Python would mostly be used to write up Airflow jobs. The job description also emphasizes more on SQL for deploying analytics code.&lt;/li&gt;\n&lt;li&gt;GCP, AWS or Azure not listed on job description. The team has devops engineers so I imagine they&amp;#39;ll be the ones handling cloud infrastructure.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve seen multiple job titles for the role, mainly &amp;quot;Data Engineer&amp;quot; and &amp;quot;Analytics Engineer&amp;quot;. I asked them about this and they said that data and analytics engineers are one and the same to them, and they had put up the role under multiple titles to attract as many applicants as possible.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Some positives I see for the role:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s in a bigger proper engineering team, with a scrum master, other DevOps engineers, QA, etc. and CI/CD pipelines in place.&lt;/li&gt;\n&lt;li&gt;I got along well with the hiring manager, who really seems to know his stuff.&lt;/li&gt;\n&lt;li&gt;The team is rapidly expanding, which to me seems like a good sign.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve been applying to jobs for a couple months now, and I frequently see GCP/AWS/Azure experience as a requirement. Python is easily the most enjoyable part of my job, and I want to be viewed more as programmer or a SWE-focused DE in the long term rather than an analytics engineer or a SQL developer (no hate against these types of roles, they&amp;#39;re just not what I&amp;#39;m looking for).&lt;/p&gt;\n\n&lt;p&gt;Any advice would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: Revised bullet point on cloud services&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xqg8d", "is_robot_indexable": true, "report_reasons": null, "author": "timbaktubear", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xqg8d/should_i_take_this_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xqg8d/should_i_take_this_job/", "subreddit_subscribers": 115477, "created_utc": 1689172853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Nomenclature is something I don't see brought very often in this subreddit. What naming conventions do you use when it comes to naming tables/jobs/individual pipelines and such, if any?", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What naming conventions do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xncko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689165260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Nomenclature is something I don&amp;#39;t see brought very often in this subreddit. What naming conventions do you use when it comes to naming tables/jobs/individual pipelines and such, if any?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xncko", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xncko/what_naming_conventions_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xncko/what_naming_conventions_do_you_use/", "subreddit_subscribers": 115477, "created_utc": 1689165260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\nI have platform basing on Kafka. A lot of events go through various topics. I am writting streaming app to process events in real time(join on streams are possible). I consider Kafka Streams and Flink as a streaming technologies. My first thought was to use Kafka Streams but I heard that there is some problem with inner Kafka topics during join operations. Could uou gove me some advice what would u use?", "author_fullname": "t2_omva4fi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink or Kafka Streams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xhrhj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689148809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nI have platform basing on Kafka. A lot of events go through various topics. I am writting streaming app to process events in real time(join on streams are possible). I consider Kafka Streams and Flink as a streaming technologies. My first thought was to use Kafka Streams but I heard that there is some problem with inner Kafka topics during join operations. Could uou gove me some advice what would u use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xhrhj", "is_robot_indexable": true, "report_reasons": null, "author": "BigDataMax", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xhrhj/flink_or_kafka_streams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xhrhj/flink_or_kafka_streams/", "subreddit_subscribers": 115477, "created_utc": 1689148809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!  \n\n\nI am currently doing two things :   \n\\- Religiously auditing the Coursera course playlist (DP-203) -- For the exam  \n\\- Trying to work through the book - \"Fundamentals of Data Engineering\" -- For the industry\n\nAre there any other resources that are really helpful in acing the certification exam?\n\nWould doing the Azure 900 - Azure Fundamentals course would help me with this course? (I have no previous exposure to any of the cloud computing services)?\n\nAlso, is anyone else currently preparing for this certification? I think this course might get a little overwhelming as move further in the course. Hence it'd be nice to have a study buddy. Please don't be shy to reach out if you've begun the course.", "author_fullname": "t2_k6fzzm72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on Microsoft Azure Data Engineer Associate Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xfm81", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689141588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!  &lt;/p&gt;\n\n&lt;p&gt;I am currently doing two things :&lt;br/&gt;\n- Religiously auditing the Coursera course playlist (DP-203) -- For the exam&lt;br/&gt;\n- Trying to work through the book - &amp;quot;Fundamentals of Data Engineering&amp;quot; -- For the industry&lt;/p&gt;\n\n&lt;p&gt;Are there any other resources that are really helpful in acing the certification exam?&lt;/p&gt;\n\n&lt;p&gt;Would doing the Azure 900 - Azure Fundamentals course would help me with this course? (I have no previous exposure to any of the cloud computing services)?&lt;/p&gt;\n\n&lt;p&gt;Also, is anyone else currently preparing for this certification? I think this course might get a little overwhelming as move further in the course. Hence it&amp;#39;d be nice to have a study buddy. Please don&amp;#39;t be shy to reach out if you&amp;#39;ve begun the course.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xfm81", "is_robot_indexable": true, "report_reasons": null, "author": "VastDragonfruit847", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xfm81/advice_on_microsoft_azure_data_engineer_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xfm81/advice_on_microsoft_azure_data_engineer_associate/", "subreddit_subscribers": 115477, "created_utc": 1689141588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI wanted to share here a project I'm really excited about. \n\nRecap is mainly the work of [Chris](https://twitter.com/criccomini) but I had the privilege to be involved in some design and implementation parts. Enough with the intro stuff though, let's talk about the project.\n\nRecap is a Python library that provides a single schema for... \n\n*  IDLs (Proto, JSON schema, Avro)\n*  Databases (Snowflake, PG) \n* Schema registries (CFLT schema registry, Hive metastore) \n\n Read and convert all these schemas in one format.\n\nRecap is still a baby as Chris says but I feel there's enough functionality at this point to reach out to the community and get some feedback. \n\nThe goal is to be able to access, reason and transform between all the different formats and metadata stores that are typically found in a decently mature data infrastructure. \n\nThere's still work to be done but most of the components needed are there. \n\nTake a look and I'd love to hear your thoughts and feedback.\n\nThe main Recap page: [https://recap.build](https://recap.build)\n\nThe type system spec: [https://recap.build/spec/0.1.1](https://recap.build/spec/0.1.1)\n\nThe Github Repo: [https://github.com/recap-build/recap](https://github.com/recap-build/recap)\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_fb1s1pke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recap: A python library for describing database tables and serialization formats with minimal type coercion.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14y8op7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689216832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I wanted to share here a project I&amp;#39;m really excited about. &lt;/p&gt;\n\n&lt;p&gt;Recap is mainly the work of &lt;a href=\"https://twitter.com/criccomini\"&gt;Chris&lt;/a&gt; but I had the privilege to be involved in some design and implementation parts. Enough with the intro stuff though, let&amp;#39;s talk about the project.&lt;/p&gt;\n\n&lt;p&gt;Recap is a Python library that provides a single schema for... &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt; IDLs (Proto, JSON schema, Avro)&lt;/li&gt;\n&lt;li&gt; Databases (Snowflake, PG) &lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Schema registries (CFLT schema registry, Hive metastore) &lt;/p&gt;\n\n&lt;p&gt;Read and convert all these schemas in one format.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Recap is still a baby as Chris says but I feel there&amp;#39;s enough functionality at this point to reach out to the community and get some feedback. &lt;/p&gt;\n\n&lt;p&gt;The goal is to be able to access, reason and transform between all the different formats and metadata stores that are typically found in a decently mature data infrastructure. &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s still work to be done but most of the components needed are there. &lt;/p&gt;\n\n&lt;p&gt;Take a look and I&amp;#39;d love to hear your thoughts and feedback.&lt;/p&gt;\n\n&lt;p&gt;The main Recap page: &lt;a href=\"https://recap.build\"&gt;https://recap.build&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The type system spec: &lt;a href=\"https://recap.build/spec/0.1.1\"&gt;https://recap.build/spec/0.1.1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The Github Repo: &lt;a href=\"https://github.com/recap-build/recap\"&gt;https://github.com/recap-build/recap&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "14y8op7", "is_robot_indexable": true, "report_reasons": null, "author": "cpardl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y8op7/recap_a_python_library_for_describing_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y8op7/recap_a_python_library_for_describing_database/", "subreddit_subscribers": 115477, "created_utc": 1689216832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Big Data Streaming and Real-time Analytics: [https://mytechbasket.com/play\\_quiz.php?paper\\_id=48](https://mytechbasket.com/play_quiz.php?paper_id=48)\n\nBig Data Visualization and Exploration: [https://mytechbasket.com/play\\_quiz.php?paper\\_id=49](https://mytechbasket.com/play_quiz.php?paper_id=49)", "author_fullname": "t2_2t8oxbzn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing 100 Bigdata Objective Type Questions on Bigdata Streaming, Real-time Analytics, Visualization and Exploration in form of 2 Exams (50 Objective Questions each)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14y7uzp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689214512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Big Data Streaming and Real-time Analytics: &lt;a href=\"https://mytechbasket.com/play_quiz.php?paper_id=48\"&gt;https://mytechbasket.com/play_quiz.php?paper_id=48&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Big Data Visualization and Exploration: &lt;a href=\"https://mytechbasket.com/play_quiz.php?paper_id=49\"&gt;https://mytechbasket.com/play_quiz.php?paper_id=49&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14y7uzp", "is_robot_indexable": true, "report_reasons": null, "author": "nkptcs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y7uzp/sharing_100_bigdata_objective_type_questions_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y7uzp/sharing_100_bigdata_objective_type_questions_on/", "subreddit_subscribers": 115477, "created_utc": 1689214512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working in a role that allows me to do various data analyst related tasks with Alteryx, python, and some SQL, but if I were to make the pivot to data engineering, what role should I realistically look for that would allow me to prepare for a data engineering role? Due to being in grad school and working full time, I don\u2019t have much time to do side projects, and I won\u2019t have much time to myself till graduation. I would like to transition to data engineering, but I would like to get the proper preliminary experience before even attempting to apply for roles. Any advice would be greatly appreciated. Thank you \n\nAdditional info:\nHave experience using SQL, Python, and Alteryx\nCurrently in grad school and working full, so I do not have much time to do side projects (learn Apache and AWS)\nHave some experience in using data automation pipelines via alteryx \nHave a project portfolio and GitHub", "author_fullname": "t2_5e8sloz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is my starting point?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y4xqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689206162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working in a role that allows me to do various data analyst related tasks with Alteryx, python, and some SQL, but if I were to make the pivot to data engineering, what role should I realistically look for that would allow me to prepare for a data engineering role? Due to being in grad school and working full time, I don\u2019t have much time to do side projects, and I won\u2019t have much time to myself till graduation. I would like to transition to data engineering, but I would like to get the proper preliminary experience before even attempting to apply for roles. Any advice would be greatly appreciated. Thank you &lt;/p&gt;\n\n&lt;p&gt;Additional info:\nHave experience using SQL, Python, and Alteryx\nCurrently in grad school and working full, so I do not have much time to do side projects (learn Apache and AWS)\nHave some experience in using data automation pipelines via alteryx \nHave a project portfolio and GitHub&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14y4xqk", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableCharity7222", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y4xqk/what_is_my_starting_point/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y4xqk/what_is_my_starting_point/", "subreddit_subscribers": 115477, "created_utc": 1689206162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Very nice theoretical article about what to look at when building data quality enterprise strategy", "author_fullname": "t2_2bhtmk4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strategies for Data Quality With Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_14y3v9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PSRFvYuC5VldfwX8vc9R9NPEiLK75-AzRE3uVIUm2Ao.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689203420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mlopshowto.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Very nice theoretical article about what to look at when building data quality enterprise strategy&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://mlopshowto.com/strategies-for-data-quality-with-apache-spark-4688632f149a", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nMSubvoXBEM4Q3zV8lderMnLWHRtWPA2h66djNfX2wI.jpg?auto=webp&amp;s=bcca22aa493d62175ad9841daab980c1aca6993d", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/nMSubvoXBEM4Q3zV8lderMnLWHRtWPA2h66djNfX2wI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=570486308eeb18903e46a0171885459251f05836", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/nMSubvoXBEM4Q3zV8lderMnLWHRtWPA2h66djNfX2wI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5590216e7cd6961870f222a8c27810f996811d36", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/nMSubvoXBEM4Q3zV8lderMnLWHRtWPA2h66djNfX2wI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d84042a0f81b21b1752817414c746fb25eefecc9", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/nMSubvoXBEM4Q3zV8lderMnLWHRtWPA2h66djNfX2wI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=00b0077231d918d0176a9e0ea77ecd072286b898", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/nMSubvoXBEM4Q3zV8lderMnLWHRtWPA2h66djNfX2wI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cc79c930b56ac1371d31225ef070915ac960bd14", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/nMSubvoXBEM4Q3zV8lderMnLWHRtWPA2h66djNfX2wI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2c5f1c2c423ff764566cf5c00a0ba938b9894de5", "width": 1080, "height": 720}], "variants": {}, "id": "n_lR7unkdgTgqheQ_Nk7m2xvE3N0cY7GiDhrsjiLtLI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14y3v9u", "is_robot_indexable": true, "report_reasons": null, "author": "nf_x", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y3v9u/strategies_for_data_quality_with_apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://mlopshowto.com/strategies-for-data-quality-with-apache-spark-4688632f149a", "subreddit_subscribers": 115477, "created_utc": 1689203420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not sure how many people are developing with Kafka on here, but given ingestion of streaming data is fairly typical of most data engineer's these days, I wanted to share the below.\n\nWebinar will focus on practical implementations for enforcing data security when it comes to developing with Kafka.\n\nJoin for free: [https://app.livestorm.co/conduktor/kafka-security-masterclass](https://app.livestorm.co/conduktor/kafka-security-masterclass?type=detailed)", "author_fullname": "t2_ve0spvbx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone developing with Kafka? Learn how to enforce good data security practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y0nys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689195926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure how many people are developing with Kafka on here, but given ingestion of streaming data is fairly typical of most data engineer&amp;#39;s these days, I wanted to share the below.&lt;/p&gt;\n\n&lt;p&gt;Webinar will focus on practical implementations for enforcing data security when it comes to developing with Kafka.&lt;/p&gt;\n\n&lt;p&gt;Join for free: &lt;a href=\"https://app.livestorm.co/conduktor/kafka-security-masterclass?type=detailed\"&gt;https://app.livestorm.co/conduktor/kafka-security-masterclass&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?auto=webp&amp;s=9912334549612e265a9d73776ee4149b7b4af7d9", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de6b53cde12f5087ac77b80269c1a84277d944d5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4d8b1c2ce80807aa67bc482a92d7c4de762cb09f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b240618b737818eebc64b388105842ee01f3dd13", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ee6411df102d4e9376d9ea5588adfa0c0adb12c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7f68c1526aba47094b0927bdc5b18785ef3f9e90", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/gdX9UrF8lx2KGqZ9Xm47u_FRRLB4LDjP1isEAi9kgoc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4f3b539a84d2813a879391fad13ecf1c028de2d1", "width": 1080, "height": 567}], "variants": {}, "id": "jUGrVCmjEfNzTvZDYL4juwiDIDDBlELq7IEfe92tEcU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14y0nys", "is_robot_indexable": true, "report_reasons": null, "author": "data-stash", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14y0nys/anyone_developing_with_kafka_learn_how_to_enforce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14y0nys/anyone_developing_with_kafka_learn_how_to_enforce/", "subreddit_subscribers": 115477, "created_utc": 1689195926.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}