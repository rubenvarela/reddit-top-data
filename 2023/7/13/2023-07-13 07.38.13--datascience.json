{"kind": "Listing", "data": {"after": "t3_14xt4s1", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Asking for a friend", "author_fullname": "t2_7qvort5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone here ever lied/stretched the truth on their CV and had it work out in the end?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xj6h1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 167, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 167, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689153278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Asking for a friend&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xj6h1", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial_Space9001", "discussion_type": null, "num_comments": 152, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xj6h1/has_anyone_here_ever_liedstretched_the_truth_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xj6h1/has_anyone_here_ever_liedstretched_the_truth_on/", "subreddit_subscribers": 946897, "created_utc": 1689153278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've got nothing to do at the moment. With all of my major projects I'm waiting for someone else's input. Usually, there's small progress, then I'm excited to get working. Then something else comes up, and there's another wait of 2-4 weeks for one thing or another. \n\nI tried padding my schedule with useful stuff like ad-hoc analyses, strategising, prep work for infrastructure changes, and networking. Infrastructure work is limited due to low data maturity and heavy silos, though. There's also a limit to how much networking one can do.\n\nI've run out of meaningful things to do. This has been going on for 6 months and I'm starting to feel burned out. So, I also don't have the energy to learn anymore, maybe because I'm exhausted, maybe because it's lonely and currently void of any practical application. \n\nI talked with my boss who is sympathetic but he can only offer me more filler work at the moment. I know it's a first world problem but I'm really losing my motivation. Would you have any advice on what to do? \n\nThanks in advance.", "author_fullname": "t2_4j7ujk5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nothing to do", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xvd0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689183983.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689183754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got nothing to do at the moment. With all of my major projects I&amp;#39;m waiting for someone else&amp;#39;s input. Usually, there&amp;#39;s small progress, then I&amp;#39;m excited to get working. Then something else comes up, and there&amp;#39;s another wait of 2-4 weeks for one thing or another. &lt;/p&gt;\n\n&lt;p&gt;I tried padding my schedule with useful stuff like ad-hoc analyses, strategising, prep work for infrastructure changes, and networking. Infrastructure work is limited due to low data maturity and heavy silos, though. There&amp;#39;s also a limit to how much networking one can do.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve run out of meaningful things to do. This has been going on for 6 months and I&amp;#39;m starting to feel burned out. So, I also don&amp;#39;t have the energy to learn anymore, maybe because I&amp;#39;m exhausted, maybe because it&amp;#39;s lonely and currently void of any practical application. &lt;/p&gt;\n\n&lt;p&gt;I talked with my boss who is sympathetic but he can only offer me more filler work at the moment. I know it&amp;#39;s a first world problem but I&amp;#39;m really losing my motivation. Would you have any advice on what to do? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xvd0b", "is_robot_indexable": true, "report_reasons": null, "author": "norfkens2", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xvd0b/nothing_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xvd0b/nothing_to_do/", "subreddit_subscribers": 946897, "created_utc": 1689183754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone here work somewhere that traditionally doesn't have a robust technical recruitment pipeline?\n\nAn example, and my goal, is nightclubs. A lot operate on paper and calculators and would greatly benefit from an on-site data scientist/engineer to create insightful dashboards, attendance/revenue forecasts, and just overall lending a helping hand bringing the club backend to modern standards.\n\nI just want some perspective from those who work in a non-traditional role and how you got your foot in the door.\n\nThanks", "author_fullname": "t2_p3oo7xu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting started in non-traditional roles (e.g. nightclubs)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xva5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689183582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone here work somewhere that traditionally doesn&amp;#39;t have a robust technical recruitment pipeline?&lt;/p&gt;\n\n&lt;p&gt;An example, and my goal, is nightclubs. A lot operate on paper and calculators and would greatly benefit from an on-site data scientist/engineer to create insightful dashboards, attendance/revenue forecasts, and just overall lending a helping hand bringing the club backend to modern standards.&lt;/p&gt;\n\n&lt;p&gt;I just want some perspective from those who work in a non-traditional role and how you got your foot in the door.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xva5f", "is_robot_indexable": true, "report_reasons": null, "author": "knavishly_vibrant38", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xva5f/getting_started_in_nontraditional_roles_eg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xva5f/getting_started_in_nontraditional_roles_eg/", "subreddit_subscribers": 946897, "created_utc": 1689183582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Whenever I've scrolled through Linkdin, I'm seeing heinous ratios like 60-200 applicants: 1 opening. I mean I just started my DataCamp tracks last September! Am I looking in the wrong places or am I just fucked? ", "author_fullname": "t2_icfhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data science oversaturated now? | Job Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xzcdi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689192905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whenever I&amp;#39;ve scrolled through Linkdin, I&amp;#39;m seeing heinous ratios like 60-200 applicants: 1 opening. I mean I just started my DataCamp tracks last September! Am I looking in the wrong places or am I just fucked? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xzcdi", "is_robot_indexable": true, "report_reasons": null, "author": "Genedide", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xzcdi/is_data_science_oversaturated_now_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xzcdi/is_data_science_oversaturated_now_job_market/", "subreddit_subscribers": 946897, "created_utc": 1689192905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How often  have you actually come across over qualified candidates for a data science position ? \n\nHow have the results been when you interview them and they tick all the boxes?", "author_fullname": "t2_mloui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Over qualified candidates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y5os5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689208299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How often  have you actually come across over qualified candidates for a data science position ? &lt;/p&gt;\n\n&lt;p&gt;How have the results been when you interview them and they tick all the boxes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14y5os5", "is_robot_indexable": true, "report_reasons": null, "author": "Asshaisin", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14y5os5/over_qualified_candidates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14y5os5/over_qualified_candidates/", "subreddit_subscribers": 946897, "created_utc": 1689208299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_hccf1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vanna: Generate SQL using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14xyfav", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nCyaezNTdbXzV4H6TWK_PfbGvl_DvDoGkQHevRALOjU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689190776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/vanna-ai/vanna-py", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?auto=webp&amp;s=100f4708f96b90c6da0a2aedd316991f9de1e09e", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d372eac8bc09b5feecc623570ee0e3f256240b0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a8c93deaaa59d7ef4dc4f93e8e59bff028a79f8d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6c49ff83eb4de1b0cad42dfe0332d9c3416b1f5c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb08a3cbabdbb538e54e3f7b7a11a87293c1fe53", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d8d205fb460116096df1fd9f8f3b2697a5b802c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b0fd54791bf15922a3a1bebd000b5051d7790d03", "width": 1080, "height": 607}], "variants": {}, "id": "YkvUIM_b4CNQSWNtpeCdkahtxdm_7oPRMTgo11_lAIM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xyfav", "is_robot_indexable": true, "report_reasons": null, "author": "gogolang", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xyfav/vanna_generate_sql_using_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/vanna-ai/vanna-py", "subreddit_subscribers": 946897, "created_utc": 1689190776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey so I'm an intern right now, and I'm tasked with creating a model that takes in the initial order conditions (multitouch attribution, amount ordered, product, etc on first order) and predicts the LTV after 3,6,9, and 12 months. \n\nI used a decision tree and created 3 different models to predict the LTV of a month 0 customer and its of satisfactory accuracy, but I now realize I will probably need to make 4 different model for every customer cohort (when they bought), meaning I will have to make a whole lot of models.\n\nThis is very doable, the models run pretty fast, and I have around 150,000 pieces of training data, but the way I am doing it feels incredibly sloppy and suboptimal (I pretty much know it is, I just don't know an easy workaround). Any help is much appreciated for an internet in need!", "author_fullname": "t2_bmx0x96q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to creating 20 different models to predict customer Life Time Value at different points?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xzc3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689192887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey so I&amp;#39;m an intern right now, and I&amp;#39;m tasked with creating a model that takes in the initial order conditions (multitouch attribution, amount ordered, product, etc on first order) and predicts the LTV after 3,6,9, and 12 months. &lt;/p&gt;\n\n&lt;p&gt;I used a decision tree and created 3 different models to predict the LTV of a month 0 customer and its of satisfactory accuracy, but I now realize I will probably need to make 4 different model for every customer cohort (when they bought), meaning I will have to make a whole lot of models.&lt;/p&gt;\n\n&lt;p&gt;This is very doable, the models run pretty fast, and I have around 150,000 pieces of training data, but the way I am doing it feels incredibly sloppy and suboptimal (I pretty much know it is, I just don&amp;#39;t know an easy workaround). Any help is much appreciated for an internet in need!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xzc3e", "is_robot_indexable": true, "report_reasons": null, "author": "Opening-Education-88", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xzc3e/alternatives_to_creating_20_different_models_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xzc3e/alternatives_to_creating_20_different_models_to/", "subreddit_subscribers": 946897, "created_utc": 1689192887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it possible to work as a data scientist in the political field? If yes, what would be an example job?", "author_fullname": "t2_8jxi3akg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With a political science background into data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yaqwr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689222906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to work as a data scientist in the political field? If yes, what would be an example job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yaqwr", "is_robot_indexable": true, "report_reasons": null, "author": "Revenge_is_Coming", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yaqwr/with_a_political_science_background_into_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yaqwr/with_a_political_science_background_into_data/", "subreddit_subscribers": 946897, "created_utc": 1689222906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Was up my people any armature/aspiring data scientist want to show each other work and talk about our work and see what we can we improve on, talk analytics, and compare our code?", "author_fullname": "t2_s63nck7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any aspiring DS want to show each other GitHub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y46d5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689204170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was up my people any armature/aspiring data scientist want to show each other work and talk about our work and see what we can we improve on, talk analytics, and compare our code?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14y46d5", "is_robot_indexable": true, "report_reasons": null, "author": "Papadude08", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14y46d5/any_aspiring_ds_want_to_show_each_other_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14y46d5/any_aspiring_ds_want_to_show_each_other_github/", "subreddit_subscribers": 946897, "created_utc": 1689204170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Whether hiring manager or candidate, which of the following methods do you prefer as means to vet technical experience and potential?\n\nEach of these have a flaw, but I want to get a gauge of what other methods exist for vetting candidates.\n\nRecently, my team have found that a couple of the candidates have been cheating during their technical phone screening using ChatGPT/friend to answer questions. However, when we invited them onsite and asked them the same questions, their response was vastly different and incorrect. What's sad is most of the cheaters that our recruiters vetted were ironically coming from top nearby firms (MANGA), and I cannot believe how they managed to work at those firms if they cannot answer data related questions. This includes a candidate who failed to do a simple aggregate function in SQL (e.g. getting the average number of customers that used the app in a given month).\n\nOur operation is in the SF Bay Area, and we've been receiving around 500 applications per week. Given the competition, the recruiters have been vetting based on years of experience, immediate past company experience and keyword matching. \n\nGiven this scenario, how would you vet candidates effectively given the sheer volume of candidates?\n\n[View Poll](https://www.reddit.com/poll/14xw6ql)", "author_fullname": "t2_48648", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preferred Technical Interview Method", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xw6ql", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689185635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whether hiring manager or candidate, which of the following methods do you prefer as means to vet technical experience and potential?&lt;/p&gt;\n\n&lt;p&gt;Each of these have a flaw, but I want to get a gauge of what other methods exist for vetting candidates.&lt;/p&gt;\n\n&lt;p&gt;Recently, my team have found that a couple of the candidates have been cheating during their technical phone screening using ChatGPT/friend to answer questions. However, when we invited them onsite and asked them the same questions, their response was vastly different and incorrect. What&amp;#39;s sad is most of the cheaters that our recruiters vetted were ironically coming from top nearby firms (MANGA), and I cannot believe how they managed to work at those firms if they cannot answer data related questions. This includes a candidate who failed to do a simple aggregate function in SQL (e.g. getting the average number of customers that used the app in a given month).&lt;/p&gt;\n\n&lt;p&gt;Our operation is in the SF Bay Area, and we&amp;#39;ve been receiving around 500 applications per week. Given the competition, the recruiters have been vetting based on years of experience, immediate past company experience and keyword matching. &lt;/p&gt;\n\n&lt;p&gt;Given this scenario, how would you vet candidates effectively given the sheer volume of candidates?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14xw6ql\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "14xw6ql", "is_robot_indexable": true, "report_reasons": null, "author": "forbiscuit", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1689531235365, "options": [{"text": "Timed Take Home Coding Test (e.g. 1-3 hour HackerRank puzzle)", "id": "23862078"}, {"text": "Live Whiteboard/Screensharing Interview", "id": "23862079"}, {"text": "Open Book Take Home Assignments", "id": "23862080"}, {"text": "Technical Phone Screening (Q&amp;A format)", "id": "23862081"}, {"text": "Other", "id": "23862082"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 164, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xw6ql/preferred_technical_interview_method/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/14xw6ql/preferred_technical_interview_method/", "subreddit_subscribers": 946897, "created_utc": 1689185635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hot-Cold Data Separation: What, Why, and How?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_14xltsk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cA-TRKk2RQNysgWZvGrT-7xphAfBnKQJyJcIU1Q-Mrg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689161147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.devgenius.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?auto=webp&amp;s=9bb433a2d2af7659bbd2aaefc86e6440fb099982", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cebf42d866ba39ad8401ec16025d2e683cb5ec5", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0db6f5ac30249427128f2acbef98d324f22c2d1b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34cbad55217597ab7e3e1f50abad3c5bc069e0d7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5bc2ca5a2ba66071e1827faae996f0dc6f6e329c", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f46f655bcbbc72ddca3942cdffe318e8677b8735", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8874a5ffe10ae71db18d29c8e4b5f59d830878fe", "width": 1080, "height": 720}], "variants": {}, "id": "XHYrsxQam1UsYnZQ-ImG7NyQc780qMXf4eXuq9sAgzc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xltsk", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xltsk/hotcold_data_separation_what_why_and_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf", "subreddit_subscribers": 946897, "created_utc": 1689161147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I have an important presentation in 24 hours. I really want to create a map visualisation of the data but I'm wondering the easiest/most efficient way to do it quickly?\n\nI've already cleaned the data and tried doing it in Tableau but am having trouble figuring it out quickly.\n\nMy data is the location (city), types of incidents, and number of incidents.\n\nIs this realistic to achieve in a short time frame? I'm intermediate at excel but beginner in Tableau. I don't have access to powerBI. Any other free tool you recommend I'd be happy to use.\n\nThanks!", "author_fullname": "t2_uos6k2i4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create a map visualisation of dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xok3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689168358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have an important presentation in 24 hours. I really want to create a map visualisation of the data but I&amp;#39;m wondering the easiest/most efficient way to do it quickly?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve already cleaned the data and tried doing it in Tableau but am having trouble figuring it out quickly.&lt;/p&gt;\n\n&lt;p&gt;My data is the location (city), types of incidents, and number of incidents.&lt;/p&gt;\n\n&lt;p&gt;Is this realistic to achieve in a short time frame? I&amp;#39;m intermediate at excel but beginner in Tableau. I don&amp;#39;t have access to powerBI. Any other free tool you recommend I&amp;#39;d be happy to use.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xok3v", "is_robot_indexable": true, "report_reasons": null, "author": "Greenblueberry349", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xok3v/how_to_create_a_map_visualisation_of_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xok3v/how_to_create_a_map_visualisation_of_dataset/", "subreddit_subscribers": 946897, "created_utc": 1689168358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As an application developer, I have a data package that I obtained legally from my application, to whom can I sell it?", "author_fullname": "t2_ez3ai744", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xkq2d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689157983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As an application developer, I have a data package that I obtained legally from my application, to whom can I sell it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xkq2d", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Asparagus-225", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xkq2d/data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xkq2d/data/", "subreddit_subscribers": 946897, "created_utc": 1689157983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is there anyone in this group taking part in the data science course by MIT and is it worth it?", "author_fullname": "t2_ncdd386r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science course inquiry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xjecc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689153937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there anyone in this group taking part in the data science course by MIT and is it worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xjecc", "is_robot_indexable": true, "report_reasons": null, "author": "TapLongjumping1703", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xjecc/data_science_course_inquiry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xjecc/data_science_course_inquiry/", "subreddit_subscribers": 946897, "created_utc": 1689153937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How to stand out in a data science home assignment?\n\nI received a task where I need to create a churn prediction model. It's for a position that involves both data science and machine learning engineering, although the task seems to have a stronger focus on modeling.\n\nThey mentioned that I should present my modeling strategy but didn't provide many details on how I should structure my code.\n\nThey asked me to explain my modeling strategy, how the model works, and how to interpret the model's output.\n\nI thought of the following strategy:\n- Perform exploratory analysis, including correlation analysis, identifying potential feature engineering opportunities, checking for missing data and noise. In the end, I can summarize the results and insights from the analysis.\n- Next, create two baselines: a heuristic baseline that relies on a user behavior feature using a simple \"if\" condition, and another baseline using a decision tree. \n- Perform feature engineering and use XGBoost. I chose the decision tree as one of the baselines to explain the workings of both models in a simpler way, as I'm using XGBoost in this step.\n- Optimize parameters using Optuna.\n- Compare the baselines with XGBoost and evaluate the metrics. I will try to explain whether it's better to focus on recall or precision and discuss the pros and cons of each.\n- Interpret the model. This is where I'm a bit uncertain. I plan to use SHAP values or feature importance to gain insights. I welcome any suggestions.\n- Refactor the code. In this part, I intend to organize everything into a well-structured Python project, using a pipeline with DVC, and if possible, include unit tests. I really want to have clean code since my background is more in software engineering than data science.\n- Finally, I will prepare the presentation. I will try to explain my decisions, assumptions, the results of the analysis, and provide an explanation of the model, among other things.\n\nThey gave me one week to complete the assignment, and it's been tiring.\n\nWhat would you do differently?", "author_fullname": "t2_lax5ak3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to stand out in data science home assignments?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y9x43", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689220397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How to stand out in a data science home assignment?&lt;/p&gt;\n\n&lt;p&gt;I received a task where I need to create a churn prediction model. It&amp;#39;s for a position that involves both data science and machine learning engineering, although the task seems to have a stronger focus on modeling.&lt;/p&gt;\n\n&lt;p&gt;They mentioned that I should present my modeling strategy but didn&amp;#39;t provide many details on how I should structure my code.&lt;/p&gt;\n\n&lt;p&gt;They asked me to explain my modeling strategy, how the model works, and how to interpret the model&amp;#39;s output.&lt;/p&gt;\n\n&lt;p&gt;I thought of the following strategy:\n- Perform exploratory analysis, including correlation analysis, identifying potential feature engineering opportunities, checking for missing data and noise. In the end, I can summarize the results and insights from the analysis.\n- Next, create two baselines: a heuristic baseline that relies on a user behavior feature using a simple &amp;quot;if&amp;quot; condition, and another baseline using a decision tree. \n- Perform feature engineering and use XGBoost. I chose the decision tree as one of the baselines to explain the workings of both models in a simpler way, as I&amp;#39;m using XGBoost in this step.\n- Optimize parameters using Optuna.\n- Compare the baselines with XGBoost and evaluate the metrics. I will try to explain whether it&amp;#39;s better to focus on recall or precision and discuss the pros and cons of each.\n- Interpret the model. This is where I&amp;#39;m a bit uncertain. I plan to use SHAP values or feature importance to gain insights. I welcome any suggestions.\n- Refactor the code. In this part, I intend to organize everything into a well-structured Python project, using a pipeline with DVC, and if possible, include unit tests. I really want to have clean code since my background is more in software engineering than data science.\n- Finally, I will prepare the presentation. I will try to explain my decisions, assumptions, the results of the analysis, and provide an explanation of the model, among other things.&lt;/p&gt;\n\n&lt;p&gt;They gave me one week to complete the assignment, and it&amp;#39;s been tiring.&lt;/p&gt;\n\n&lt;p&gt;What would you do differently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14y9x43", "is_robot_indexable": true, "report_reasons": null, "author": "Waste_Necessary654", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14y9x43/how_to_stand_out_in_data_science_home_assignments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14y9x43/how_to_stand_out_in_data_science_home_assignments/", "subreddit_subscribers": 946897, "created_utc": 1689220397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is there an aggregated data source I can use to access social media content where I can filter and sort based on the number of likes or comments that indicate popularity/engagement?", "author_fullname": "t2_17d42esw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aggregated data source, API, or Python libraries for social media content", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y0yrv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689196619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there an aggregated data source I can use to access social media content where I can filter and sort based on the number of likes or comments that indicate popularity/engagement?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14y0yrv", "is_robot_indexable": true, "report_reasons": null, "author": "Guyserbun007", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14y0yrv/aggregated_data_source_api_or_python_libraries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14y0yrv/aggregated_data_source_api_or_python_libraries/", "subreddit_subscribers": 946897, "created_utc": 1689196619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been out of school for 2 years and have been trying to get a job the entire time in the US. No matter how many resumes I send out, no one is even seeing me for an interview. I didn't do too badly in college (over 3.0 GPA) and am getting really frustrated with no one giving me any attention. I have also been doing coding projects online so my computer programming skills don't dull. Is there any way I can make myself more marketable?", "author_fullname": "t2_omkcn0p6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xyu3i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689191744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been out of school for 2 years and have been trying to get a job the entire time in the US. No matter how many resumes I send out, no one is even seeing me for an interview. I didn&amp;#39;t do too badly in college (over 3.0 GPA) and am getting really frustrated with no one giving me any attention. I have also been doing coding projects online so my computer programming skills don&amp;#39;t dull. Is there any way I can make myself more marketable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xyu3i", "is_robot_indexable": true, "report_reasons": null, "author": "GainAffectionate7196", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xyu3i/job_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xyu3i/job_help/", "subreddit_subscribers": 946897, "created_utc": 1689191744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nI'm working on my MS in Data Science right now and we had a lecture on clustering yesterday. I really enjoyed it and saw the applications of it, so I wanted to do a personal project to throw on my resume. \n\nLet's saw I do a K-Means cluster. I remove all of the categorical data, normalize everything remaining, get my clusters and add the corresponding cluster to each row of data.\n\nI know that analysts/scientists will do analysis on those clusters specifically, but what if I were to re-add the categorical data afterwards? For example, if I removed the \"gender\" column to do my K-Means, would it be problematic if I added it back in after? \n\nMy idea is to use that data and make a dashboard that allows the user to filter by cluster. Evidently, the dashboard needs categorical data to gain valuable insight from the clusters. \n\nI'm not sure if that is problematic or not? Am I going to somehow create a false narrative if I add in the removed categorical variables after the K-Means has been run? ", "author_fullname": "t2_1x7s010", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Re-Adding Categorical Data After K-Means Clustering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xy6p4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689190218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on my MS in Data Science right now and we had a lecture on clustering yesterday. I really enjoyed it and saw the applications of it, so I wanted to do a personal project to throw on my resume. &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s saw I do a K-Means cluster. I remove all of the categorical data, normalize everything remaining, get my clusters and add the corresponding cluster to each row of data.&lt;/p&gt;\n\n&lt;p&gt;I know that analysts/scientists will do analysis on those clusters specifically, but what if I were to re-add the categorical data afterwards? For example, if I removed the &amp;quot;gender&amp;quot; column to do my K-Means, would it be problematic if I added it back in after? &lt;/p&gt;\n\n&lt;p&gt;My idea is to use that data and make a dashboard that allows the user to filter by cluster. Evidently, the dashboard needs categorical data to gain valuable insight from the clusters. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if that is problematic or not? Am I going to somehow create a false narrative if I add in the removed categorical variables after the K-Means has been run? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xy6p4", "is_robot_indexable": true, "report_reasons": null, "author": "HercHuntsdirty", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xy6p4/readding_categorical_data_after_kmeans_clustering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xy6p4/readding_categorical_data_after_kmeans_clustering/", "subreddit_subscribers": 946897, "created_utc": 1689190218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am moving from a Data Scientist role into a Tech Lead role. Even though I worked de facto as a tech lead in the organization, it was my first promotion into a senior role. \n\nMy manager (who I highly appreciate) also told me that the change would come with changing my salary. We talked about it in general. How much (%) raise would be fair, given that I earn slightly more than the average salary in my area?\n\nThanks", "author_fullname": "t2_4udseb4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a distinction between \"tech lead\" and \"team leader\" roles in your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xy32c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689189980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am moving from a Data Scientist role into a Tech Lead role. Even though I worked de facto as a tech lead in the organization, it was my first promotion into a senior role. &lt;/p&gt;\n\n&lt;p&gt;My manager (who I highly appreciate) also told me that the change would come with changing my salary. We talked about it in general. How much (%) raise would be fair, given that I earn slightly more than the average salary in my area?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xy32c", "is_robot_indexable": true, "report_reasons": null, "author": "David202023", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xy32c/is_there_a_distinction_between_tech_lead_and_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xy32c/is_there_a_distinction_between_tech_lead_and_team/", "subreddit_subscribers": 946897, "created_utc": 1689189980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nData scientist/python developer/cloud engineer here. I am working on the math side of an app, and was wondering if someone has ever worked on linear relationships within scattered 2-d data.\n\nI have attached an example image in the link below, but I wanted to basically group together data points that are &lt;x Euclidian distance apart, and segment to segment is less than a certain degree of angle. I am familiar with clustering (looked into DBSCAN, hierarchical, etc) but because the data is fairly distributed, I am having a hard time getting distinct clusters of any shape out of it. \n\nAnyone with experience with doing something like this that can point me towards some resources, my internet searches aren't yielding much.\n\nOpen to an example in pretty much any language.\n\nhttps://imgur.com/a/2G1M07E", "author_fullname": "t2_bq6l0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Like clustering, but linear paths through scattered data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xxy1q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689189660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Data scientist/python developer/cloud engineer here. I am working on the math side of an app, and was wondering if someone has ever worked on linear relationships within scattered 2-d data.&lt;/p&gt;\n\n&lt;p&gt;I have attached an example image in the link below, but I wanted to basically group together data points that are &amp;lt;x Euclidian distance apart, and segment to segment is less than a certain degree of angle. I am familiar with clustering (looked into DBSCAN, hierarchical, etc) but because the data is fairly distributed, I am having a hard time getting distinct clusters of any shape out of it. &lt;/p&gt;\n\n&lt;p&gt;Anyone with experience with doing something like this that can point me towards some resources, my internet searches aren&amp;#39;t yielding much.&lt;/p&gt;\n\n&lt;p&gt;Open to an example in pretty much any language.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/2G1M07E\"&gt;https://imgur.com/a/2G1M07E&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HjU-SkGylr94Yh5Z14KSxVUM3Qyw04ZuxZgPXu_Kd_s.jpg?auto=webp&amp;s=780675fb3b3cc5b78d12d64fe258eeebddf5e049", "width": 480, "height": 372}, "resolutions": [{"url": "https://external-preview.redd.it/HjU-SkGylr94Yh5Z14KSxVUM3Qyw04ZuxZgPXu_Kd_s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4f993ef2532388dd34252ec84e50adeee997d467", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/HjU-SkGylr94Yh5Z14KSxVUM3Qyw04ZuxZgPXu_Kd_s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=775278490dd1acb782bbb20301c48dc8dd3ca058", "width": 216, "height": 167}, {"url": "https://external-preview.redd.it/HjU-SkGylr94Yh5Z14KSxVUM3Qyw04ZuxZgPXu_Kd_s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2c4a5c1f2759feb8dc4192213d3eb3fa0f84d6fe", "width": 320, "height": 248}], "variants": {}, "id": "vfNU3TdrEW-RtJvOMqDyi0PC8c6LE3vGwpUJkGhcUKo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xxy1q", "is_robot_indexable": true, "report_reasons": null, "author": "laXfever34", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xxy1q/like_clustering_but_linear_paths_through/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xxy1q/like_clustering_but_linear_paths_through/", "subreddit_subscribers": 946897, "created_utc": 1689189660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm interested in learning a bit more about formal data science methods. Curious about the proper way to approach forecasting (let's say, incoming work orders).\n\nI built a super simple model to just brainstorm a starting point. I basically used the model to produce \"data\" and am trying to use that data to reverse engineer the model.\n\nWeeks 1-12 are 1000 work orders a week, weeks 17-36 are 2000, and weeks 41-52 are 1000 (ignoring potential week 53 for simplicity). From 12-17 orders ramp up at 200/week and 36-41 ramp down by 200/week. That's the seasonality I built.\n\nI then built 130 weeks (2.5 years) of \"data\" by taking the first week = 1000, and every week I looked up the seasonal value, compounded by 1.0009 per week from the starting point (5% annual growth). That's my data set I'm trying to reverse engineer the model from.\n\nThe new data scientist who started with my company is teaching me python and we built a model together, that basically took a linear trend, and then calculated seasonality based on the deviation from the linear trend.\n\nThe problem is, the trend in the beginning model doesn't change, it's a 1.05\\^(1/52) weekly compound growth. However, the trend in the output model changes dramatically based on how many weeks are in the dataset. If it's a multiple of 52, it's fine, but at 64 weeks for instance it underestimates the trend (extra data at low seasonality) and at 88 weeks it overestimates the trend (extra data at high seasonal points).\n\nI'm not even sure a linear trend is appropriate given the expected compounding growth.\n\nWhat's the standard approach for building a simple forecast model based on this type of seasonality and compounding growth?", "author_fullname": "t2_o8c07y7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic Forecasting - trend vs seasonality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xxs56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689189281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in learning a bit more about formal data science methods. Curious about the proper way to approach forecasting (let&amp;#39;s say, incoming work orders).&lt;/p&gt;\n\n&lt;p&gt;I built a super simple model to just brainstorm a starting point. I basically used the model to produce &amp;quot;data&amp;quot; and am trying to use that data to reverse engineer the model.&lt;/p&gt;\n\n&lt;p&gt;Weeks 1-12 are 1000 work orders a week, weeks 17-36 are 2000, and weeks 41-52 are 1000 (ignoring potential week 53 for simplicity). From 12-17 orders ramp up at 200/week and 36-41 ramp down by 200/week. That&amp;#39;s the seasonality I built.&lt;/p&gt;\n\n&lt;p&gt;I then built 130 weeks (2.5 years) of &amp;quot;data&amp;quot; by taking the first week = 1000, and every week I looked up the seasonal value, compounded by 1.0009 per week from the starting point (5% annual growth). That&amp;#39;s my data set I&amp;#39;m trying to reverse engineer the model from.&lt;/p&gt;\n\n&lt;p&gt;The new data scientist who started with my company is teaching me python and we built a model together, that basically took a linear trend, and then calculated seasonality based on the deviation from the linear trend.&lt;/p&gt;\n\n&lt;p&gt;The problem is, the trend in the beginning model doesn&amp;#39;t change, it&amp;#39;s a 1.05^(1/52) weekly compound growth. However, the trend in the output model changes dramatically based on how many weeks are in the dataset. If it&amp;#39;s a multiple of 52, it&amp;#39;s fine, but at 64 weeks for instance it underestimates the trend (extra data at low seasonality) and at 88 weeks it overestimates the trend (extra data at high seasonal points).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not even sure a linear trend is appropriate given the expected compounding growth.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the standard approach for building a simple forecast model based on this type of seasonality and compounding growth?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xxs56", "is_robot_indexable": true, "report_reasons": null, "author": "Mission-Wall-3311", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xxs56/basic_forecasting_trend_vs_seasonality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xxs56/basic_forecasting_trend_vs_seasonality/", "subreddit_subscribers": 946897, "created_utc": 1689189281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As an American FinTech company, we're looking for an Investigations Analyst to join us in making the crypto space safer.\n\nWe use the challenge program to evaluate applicants, and if you find the task intriguing, we're likely to be a good fit.\n\nTo participate, submit a pull request to the [challenge repo](https://go.inca.digital/investigation-challenge?11). To make sure your submission doesn't get lost, you can also email your PR link along with your resume and the link to this challenge to [challenge-submission@blockshop.org](mailto:challenge-submission@blockshop.org).\n\nYou can also find more about the opportunity [here](https://inca.digital/careers/#roles--data-analyst-investigations-and-research).\n\nMore about [Inca Digital](https://inca.digital/).", "author_fullname": "t2_udca2loi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Challenge announcement: generate a comprehensive report that assesses the degree of decentralization in the crypto asset project.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xx6ww", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689200658.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689187959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As an American FinTech company, we&amp;#39;re looking for an Investigations Analyst to join us in making the crypto space safer.&lt;/p&gt;\n\n&lt;p&gt;We use the challenge program to evaluate applicants, and if you find the task intriguing, we&amp;#39;re likely to be a good fit.&lt;/p&gt;\n\n&lt;p&gt;To participate, submit a pull request to the &lt;a href=\"https://go.inca.digital/investigation-challenge?11\"&gt;challenge repo&lt;/a&gt;. To make sure your submission doesn&amp;#39;t get lost, you can also email your PR link along with your resume and the link to this challenge to [&lt;a href=\"mailto:challenge-submission@blockshop.org\"&gt;challenge-submission@blockshop.org&lt;/a&gt;](mailto:&lt;a href=\"mailto:challenge-submission@blockshop.org\"&gt;challenge-submission@blockshop.org&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;You can also find more about the opportunity &lt;a href=\"https://inca.digital/careers/#roles--data-analyst-investigations-and-research\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;More about &lt;a href=\"https://inca.digital/\"&gt;Inca Digital&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JgTgOc6O3vcBWkJOm-DGPYbKp2FMGX0bK-BFwGjm0OQ.jpg?auto=webp&amp;s=29e6c98b082ae21d39fc67515135fea9259e7e60", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JgTgOc6O3vcBWkJOm-DGPYbKp2FMGX0bK-BFwGjm0OQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c548ae572afa12b67fbf2e2d83aede4cf1ae7016", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JgTgOc6O3vcBWkJOm-DGPYbKp2FMGX0bK-BFwGjm0OQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=62efad2016864c398862b22a8fe43de13b43ecba", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JgTgOc6O3vcBWkJOm-DGPYbKp2FMGX0bK-BFwGjm0OQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7a9fe471347a7150dbde3f7fbf9a758766d95d1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JgTgOc6O3vcBWkJOm-DGPYbKp2FMGX0bK-BFwGjm0OQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8998f0fd3657fbb7852f28ec0c6b84d436bd221e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JgTgOc6O3vcBWkJOm-DGPYbKp2FMGX0bK-BFwGjm0OQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=531cf2747a0c872bbafa606f9418a4a360573d08", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JgTgOc6O3vcBWkJOm-DGPYbKp2FMGX0bK-BFwGjm0OQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=52ebbdc63410849b987908c7b6c4929cedcaf756", "width": 1080, "height": 540}], "variants": {}, "id": "jyZ6WfA-YqIdv509-QIu3I2Op3UgzQQwMlK0vgSRFzw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xx6ww", "is_robot_indexable": true, "report_reasons": null, "author": "IncaDigital_Inc", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xx6ww/challenge_announcement_generate_a_comprehensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xx6ww/challenge_announcement_generate_a_comprehensive/", "subreddit_subscribers": 946897, "created_utc": 1689187959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Howdy, I'm Tommy, and... I'm kinda mess about which are the most important metrics ( CPC, CTR, ROI, etc... ) for a healthy b2b Google Ads campaign.", "author_fullname": "t2_9x9k2l3qk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "B2B - GOOGLE ADS METRIC TIPS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xvxak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689185029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy, I&amp;#39;m Tommy, and... I&amp;#39;m kinda mess about which are the most important metrics ( CPC, CTR, ROI, etc... ) for a healthy b2b Google Ads campaign.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xvxak", "is_robot_indexable": true, "report_reasons": null, "author": "fcktommy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xvxak/b2b_google_ads_metric_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xvxak/b2b_google_ads_metric_tips/", "subreddit_subscribers": 946897, "created_utc": 1689185029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We are are offering a free compute trial on our managed Kubernetes machine learning platform. We appreciate any input we can receive. Academic users are given preference and half of the free compute is dedicated for them. Please let us know if you're interested!", "author_fullname": "t2_rrbvcyw7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Compute Trial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xud92", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689181496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are are offering a free compute trial on our managed Kubernetes machine learning platform. We appreciate any input we can receive. Academic users are given preference and half of the free compute is dedicated for them. Please let us know if you&amp;#39;re interested!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xud92", "is_robot_indexable": true, "report_reasons": null, "author": "robert67976", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xud92/free_compute_trial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xud92/free_compute_trial/", "subreddit_subscribers": 946897, "created_utc": 1689181496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working as a data scientist on a fairly average-low salary. I am 30 y/o, still fairly new to the industry after a career change but really enjoying it. I see a lot of roles ask for a master's as minimum. Unfortunately I don't have one those \ud83d\ude14 . Do people here generally feel like it's necessary to get a master's? I'm considering doing a cheap and quick masters , e.g. https://www.opit.com/courses/computer-science-master/ \n\n\nWould really appreciate any advice, for instance whether a master's from a new online only organisation will be respected in the sector?\n\nThanks!", "author_fullname": "t2_dcu0a8ch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xt4s1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689178774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working as a data scientist on a fairly average-low salary. I am 30 y/o, still fairly new to the industry after a career change but really enjoying it. I see a lot of roles ask for a master&amp;#39;s as minimum. Unfortunately I don&amp;#39;t have one those \ud83d\ude14 . Do people here generally feel like it&amp;#39;s necessary to get a master&amp;#39;s? I&amp;#39;m considering doing a cheap and quick masters , e.g. &lt;a href=\"https://www.opit.com/courses/computer-science-master/\"&gt;https://www.opit.com/courses/computer-science-master/&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Would really appreciate any advice, for instance whether a master&amp;#39;s from a new online only organisation will be respected in the sector?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xt4s1", "is_robot_indexable": true, "report_reasons": null, "author": "bigslimjim91", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xt4s1/masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xt4s1/masters/", "subreddit_subscribers": 946897, "created_utc": 1689178774.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}