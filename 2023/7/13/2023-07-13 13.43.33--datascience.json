{"kind": "Listing", "data": {"after": "t3_14yfp3c", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've got nothing to do at the moment. With all of my major projects I'm waiting for someone else's input. Usually, there's small progress, then I'm excited to get working. Then something else comes up, and there's another wait of 2-4 weeks for one thing or another. \n\nI tried padding my schedule with useful stuff like ad-hoc analyses, strategising, prep work for infrastructure changes, and networking. Infrastructure work is limited due to low data maturity and heavy silos, though. There's also a limit to how much networking one can do.\n\nI've run out of meaningful things to do. This has been going on for 6 months and I'm starting to feel burned out. So, I also don't have the energy to learn anymore, maybe because I'm exhausted, maybe because it's lonely and currently void of any practical application. \n\nI talked with my boss who is sympathetic but he can only offer me more filler work at the moment. I know it's a first world problem but I'm really losing my motivation. Would you have any advice on what to do? \n\nThanks in advance.", "author_fullname": "t2_4j7ujk5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nothing to do", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xvd0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689183983.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689183754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got nothing to do at the moment. With all of my major projects I&amp;#39;m waiting for someone else&amp;#39;s input. Usually, there&amp;#39;s small progress, then I&amp;#39;m excited to get working. Then something else comes up, and there&amp;#39;s another wait of 2-4 weeks for one thing or another. &lt;/p&gt;\n\n&lt;p&gt;I tried padding my schedule with useful stuff like ad-hoc analyses, strategising, prep work for infrastructure changes, and networking. Infrastructure work is limited due to low data maturity and heavy silos, though. There&amp;#39;s also a limit to how much networking one can do.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve run out of meaningful things to do. This has been going on for 6 months and I&amp;#39;m starting to feel burned out. So, I also don&amp;#39;t have the energy to learn anymore, maybe because I&amp;#39;m exhausted, maybe because it&amp;#39;s lonely and currently void of any practical application. &lt;/p&gt;\n\n&lt;p&gt;I talked with my boss who is sympathetic but he can only offer me more filler work at the moment. I know it&amp;#39;s a first world problem but I&amp;#39;m really losing my motivation. Would you have any advice on what to do? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xvd0b", "is_robot_indexable": true, "report_reasons": null, "author": "norfkens2", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xvd0b/nothing_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xvd0b/nothing_to_do/", "subreddit_subscribers": 947115, "created_utc": 1689183754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Whenever I've scrolled through Linkdin, I'm seeing heinous ratios like 60-200 applicants: 1 opening. I mean I just started my DataCamp tracks last September! Am I looking in the wrong places or am I just fucked? ", "author_fullname": "t2_icfhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data science oversaturated now? | Job Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xzcdi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689192905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whenever I&amp;#39;ve scrolled through Linkdin, I&amp;#39;m seeing heinous ratios like 60-200 applicants: 1 opening. I mean I just started my DataCamp tracks last September! Am I looking in the wrong places or am I just fucked? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xzcdi", "is_robot_indexable": true, "report_reasons": null, "author": "Genedide", "discussion_type": null, "num_comments": 127, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xzcdi/is_data_science_oversaturated_now_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xzcdi/is_data_science_oversaturated_now_job_market/", "subreddit_subscribers": 947115, "created_utc": 1689192905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone here work somewhere that traditionally doesn't have a robust technical recruitment pipeline?\n\nAn example, and my goal, is nightclubs. A lot operate on paper and calculators and would greatly benefit from an on-site data scientist/engineer to create insightful dashboards, attendance/revenue forecasts, and just overall lending a helping hand bringing the club backend to modern standards.\n\nI just want some perspective from those who work in a non-traditional role and how you got your foot in the door.\n\nThanks", "author_fullname": "t2_p3oo7xu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting started in non-traditional roles (e.g. nightclubs)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xva5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689183582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone here work somewhere that traditionally doesn&amp;#39;t have a robust technical recruitment pipeline?&lt;/p&gt;\n\n&lt;p&gt;An example, and my goal, is nightclubs. A lot operate on paper and calculators and would greatly benefit from an on-site data scientist/engineer to create insightful dashboards, attendance/revenue forecasts, and just overall lending a helping hand bringing the club backend to modern standards.&lt;/p&gt;\n\n&lt;p&gt;I just want some perspective from those who work in a non-traditional role and how you got your foot in the door.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xva5f", "is_robot_indexable": true, "report_reasons": null, "author": "knavishly_vibrant38", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xva5f/getting_started_in_nontraditional_roles_eg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xva5f/getting_started_in_nontraditional_roles_eg/", "subreddit_subscribers": 947115, "created_utc": 1689183582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How often  have you actually come across over qualified candidates for a data science position ? \n\nHow have the results been when you interview them and they tick all the boxes?", "author_fullname": "t2_mloui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Over qualified candidates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y5os5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689208299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How often  have you actually come across over qualified candidates for a data science position ? &lt;/p&gt;\n\n&lt;p&gt;How have the results been when you interview them and they tick all the boxes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14y5os5", "is_robot_indexable": true, "report_reasons": null, "author": "Asshaisin", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14y5os5/over_qualified_candidates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14y5os5/over_qualified_candidates/", "subreddit_subscribers": 947115, "created_utc": 1689208299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I developed a movie recommendation system using Next.js and FastAPI, but I encountered serverless function size limitations when attempting to host it on Vercel, even after experimenting with smaller models. What can I do at this point?  It would be perfect if there were a free hosting option available. ", "author_fullname": "t2_k9zi1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I deploy my hobby project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yepoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689235977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I developed a movie recommendation system using Next.js and FastAPI, but I encountered serverless function size limitations when attempting to host it on Vercel, even after experimenting with smaller models. What can I do at this point?  It would be perfect if there were a free hosting option available. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yepoc", "is_robot_indexable": true, "report_reasons": null, "author": "bahoho", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yepoc/where_can_i_deploy_my_hobby_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yepoc/where_can_i_deploy_my_hobby_project/", "subreddit_subscribers": 947115, "created_utc": 1689235977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\nI'm currently exploring various certifications in the field of data science and machine learning, and I wanted to gather insights from the community, especially from data science experts and hiring managers.\n\nSpecifically, I'm interested in hearing your opinions and experiences regarding the value of certifications offered by AWS, Azure, Google Cloud, and Databricks.\n\nThese certifications include:\n\nAWS Certified Machine Learning - Specialty\n\nMicrosoft Certified: Azure Data Scientist Associate\n\nGoogle Cloud Certified - Machine Learning and Data science\n\nDatabricks - Data science certification \n\nWhat is the general demand and trend in the job market for professionals holding these certifications?\n\nDo you see an increasing demand for individuals with these certifications?\n\nHave you personally witnessed any significant career benefits or advantages from earning these certifications, either in terms of job opportunities, salary, or professional growth?\n\nPlease feel free to share any additional thoughts, tips, or recommendations related to these certifications or any others that you believe are valuable in the data science and machine learning domains.\n\nI'd love to know:\n\nHow valuable do you perceive these certifications to be in terms of career development and advancement within the data science and machine learning fields?\n\nAre these certifications highly regarded by hiring managers when considering candidates for data science and machine learning positions?\n\nYour insights will be greatly appreciated, and they will help me and others in the community make informed decisions regarding certifications and their potential impact on our careers.\n\nThank you in advance for your valuable contributions!", "author_fullname": "t2_60jo8coj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Valuable are AWS, Azure, Google Cloud, and Databricks Certifications for Data Science Careers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yi1ia", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689248110.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689247042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently exploring various certifications in the field of data science and machine learning, and I wanted to gather insights from the community, especially from data science experts and hiring managers.&lt;/p&gt;\n\n&lt;p&gt;Specifically, I&amp;#39;m interested in hearing your opinions and experiences regarding the value of certifications offered by AWS, Azure, Google Cloud, and Databricks.&lt;/p&gt;\n\n&lt;p&gt;These certifications include:&lt;/p&gt;\n\n&lt;p&gt;AWS Certified Machine Learning - Specialty&lt;/p&gt;\n\n&lt;p&gt;Microsoft Certified: Azure Data Scientist Associate&lt;/p&gt;\n\n&lt;p&gt;Google Cloud Certified - Machine Learning and Data science&lt;/p&gt;\n\n&lt;p&gt;Databricks - Data science certification &lt;/p&gt;\n\n&lt;p&gt;What is the general demand and trend in the job market for professionals holding these certifications?&lt;/p&gt;\n\n&lt;p&gt;Do you see an increasing demand for individuals with these certifications?&lt;/p&gt;\n\n&lt;p&gt;Have you personally witnessed any significant career benefits or advantages from earning these certifications, either in terms of job opportunities, salary, or professional growth?&lt;/p&gt;\n\n&lt;p&gt;Please feel free to share any additional thoughts, tips, or recommendations related to these certifications or any others that you believe are valuable in the data science and machine learning domains.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to know:&lt;/p&gt;\n\n&lt;p&gt;How valuable do you perceive these certifications to be in terms of career development and advancement within the data science and machine learning fields?&lt;/p&gt;\n\n&lt;p&gt;Are these certifications highly regarded by hiring managers when considering candidates for data science and machine learning positions?&lt;/p&gt;\n\n&lt;p&gt;Your insights will be greatly appreciated, and they will help me and others in the community make informed decisions regarding certifications and their potential impact on our careers.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your valuable contributions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yi1ia", "is_robot_indexable": true, "report_reasons": null, "author": "petburiraja", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yi1ia/how_valuable_are_aws_azure_google_cloud_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yi1ia/how_valuable_are_aws_azure_google_cloud_and/", "subreddit_subscribers": 947115, "created_utc": 1689247042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey so I'm an intern right now, and I'm tasked with creating a model that takes in the initial order conditions (multitouch attribution, amount ordered, product, etc on first order) and predicts the LTV after 3,6,9, and 12 months. \n\nI used a decision tree and created 3 different models to predict the LTV of a month 0 customer and its of satisfactory accuracy, but I now realize I will probably need to make 4 different model for every customer cohort (when they bought), meaning I will have to make a whole lot of models.\n\nThis is very doable, the models run pretty fast, and I have around 150,000 pieces of training data, but the way I am doing it feels incredibly sloppy and suboptimal (I pretty much know it is, I just don't know an easy workaround). Any help is much appreciated for an internet in need!", "author_fullname": "t2_bmx0x96q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to creating 20 different models to predict customer Life Time Value at different points?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xzc3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689192887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey so I&amp;#39;m an intern right now, and I&amp;#39;m tasked with creating a model that takes in the initial order conditions (multitouch attribution, amount ordered, product, etc on first order) and predicts the LTV after 3,6,9, and 12 months. &lt;/p&gt;\n\n&lt;p&gt;I used a decision tree and created 3 different models to predict the LTV of a month 0 customer and its of satisfactory accuracy, but I now realize I will probably need to make 4 different model for every customer cohort (when they bought), meaning I will have to make a whole lot of models.&lt;/p&gt;\n\n&lt;p&gt;This is very doable, the models run pretty fast, and I have around 150,000 pieces of training data, but the way I am doing it feels incredibly sloppy and suboptimal (I pretty much know it is, I just don&amp;#39;t know an easy workaround). Any help is much appreciated for an internet in need!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xzc3e", "is_robot_indexable": true, "report_reasons": null, "author": "Opening-Education-88", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xzc3e/alternatives_to_creating_20_different_models_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xzc3e/alternatives_to_creating_20_different_models_to/", "subreddit_subscribers": 947115, "created_utc": 1689192887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_hccf1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vanna: Generate SQL using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14xyfav", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nCyaezNTdbXzV4H6TWK_PfbGvl_DvDoGkQHevRALOjU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689190776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/vanna-ai/vanna-py", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?auto=webp&amp;s=100f4708f96b90c6da0a2aedd316991f9de1e09e", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d372eac8bc09b5feecc623570ee0e3f256240b0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a8c93deaaa59d7ef4dc4f93e8e59bff028a79f8d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6c49ff83eb4de1b0cad42dfe0332d9c3416b1f5c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb08a3cbabdbb538e54e3f7b7a11a87293c1fe53", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d8d205fb460116096df1fd9f8f3b2697a5b802c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/YbSdxPBtgTyPbB6GGCWcl9thzHp-lUDPVdmJx6j7CBc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b0fd54791bf15922a3a1bebd000b5051d7790d03", "width": 1080, "height": 607}], "variants": {}, "id": "YkvUIM_b4CNQSWNtpeCdkahtxdm_7oPRMTgo11_lAIM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xyfav", "is_robot_indexable": true, "report_reasons": null, "author": "gogolang", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xyfav/vanna_generate_sql_using_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/vanna-ai/vanna-py", "subreddit_subscribers": 947115, "created_utc": 1689190776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it possible to work as a data scientist in the political field? If yes, what would be an example job?", "author_fullname": "t2_8jxi3akg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With a political science background into data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yaqwr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689222906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to work as a data scientist in the political field? If yes, what would be an example job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yaqwr", "is_robot_indexable": true, "report_reasons": null, "author": "Revenge_is_Coming", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yaqwr/with_a_political_science_background_into_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yaqwr/with_a_political_science_background_into_data/", "subreddit_subscribers": 947115, "created_utc": 1689222906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Was up my people any armature/aspiring data scientist want to show each other work and talk about our work and see what we can we improve on, talk analytics, and compare our code?", "author_fullname": "t2_s63nck7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any aspiring DS want to show each other GitHub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14y46d5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689204170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was up my people any armature/aspiring data scientist want to show each other work and talk about our work and see what we can we improve on, talk analytics, and compare our code?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14y46d5", "is_robot_indexable": true, "report_reasons": null, "author": "Papadude08", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14y46d5/any_aspiring_ds_want_to_show_each_other_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14y46d5/any_aspiring_ds_want_to_show_each_other_github/", "subreddit_subscribers": 947115, "created_utc": 1689204170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/14yfb81)", "author_fullname": "t2_2kh4l8ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientists, do you still train models locally for work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yfb81", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689238061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14yfb81\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "14yfb81", "is_robot_indexable": true, "report_reasons": null, "author": "supper_ham", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1689497261993, "options": [{"text": "Local machine", "id": "23870804"}, {"text": "Cloud", "id": "23870805"}, {"text": "Company servers", "id": "23870806"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 138, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yfb81/data_scientists_do_you_still_train_models_locally/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/14yfb81/data_scientists_do_you_still_train_models_locally/", "subreddit_subscribers": 947115, "created_utc": 1689238061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Whether hiring manager or candidate, which of the following methods do you prefer as means to vet technical experience and potential?\n\nEach of these have a flaw, but I want to get a gauge of what other methods exist for vetting candidates.\n\nRecently, my team have found that a couple of the candidates have been cheating during their technical phone screening using ChatGPT/friend to answer questions. However, when we invited them onsite and asked them the same questions, their response was vastly different and incorrect. What's sad is most of the cheaters that our recruiters vetted were ironically coming from top nearby firms (MANGA), and I cannot believe how they managed to work at those firms if they cannot answer data related questions. This includes a candidate who failed to do a simple aggregate function in SQL (e.g. getting the average number of customers that used the app in a given month).\n\nOur operation is in the SF Bay Area, and we've been receiving around 500 applications per week. Given the competition, the recruiters have been vetting based on years of experience, immediate past company experience and keyword matching. \n\nGiven this scenario, how would you vet candidates effectively given the sheer volume of candidates?\n\n[View Poll](https://www.reddit.com/poll/14xw6ql)", "author_fullname": "t2_48648", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preferred Technical Interview Method", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xw6ql", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689185635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whether hiring manager or candidate, which of the following methods do you prefer as means to vet technical experience and potential?&lt;/p&gt;\n\n&lt;p&gt;Each of these have a flaw, but I want to get a gauge of what other methods exist for vetting candidates.&lt;/p&gt;\n\n&lt;p&gt;Recently, my team have found that a couple of the candidates have been cheating during their technical phone screening using ChatGPT/friend to answer questions. However, when we invited them onsite and asked them the same questions, their response was vastly different and incorrect. What&amp;#39;s sad is most of the cheaters that our recruiters vetted were ironically coming from top nearby firms (MANGA), and I cannot believe how they managed to work at those firms if they cannot answer data related questions. This includes a candidate who failed to do a simple aggregate function in SQL (e.g. getting the average number of customers that used the app in a given month).&lt;/p&gt;\n\n&lt;p&gt;Our operation is in the SF Bay Area, and we&amp;#39;ve been receiving around 500 applications per week. Given the competition, the recruiters have been vetting based on years of experience, immediate past company experience and keyword matching. &lt;/p&gt;\n\n&lt;p&gt;Given this scenario, how would you vet candidates effectively given the sheer volume of candidates?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14xw6ql\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "14xw6ql", "is_robot_indexable": true, "report_reasons": null, "author": "forbiscuit", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1689531235365, "options": [{"text": "Timed Take Home Coding Test (e.g. 1-3 hour HackerRank puzzle)", "id": "23862078"}, {"text": "Live Whiteboard/Screensharing Interview", "id": "23862079"}, {"text": "Open Book Take Home Assignments", "id": "23862080"}, {"text": "Technical Phone Screening (Q&amp;A format)", "id": "23862081"}, {"text": "Other", "id": "23862082"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 191, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xw6ql/preferred_technical_interview_method/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/14xw6ql/preferred_technical_interview_method/", "subreddit_subscribers": 947115, "created_utc": 1689185635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built a python library for automating data normalisation, schema creation and loading to db. WDYT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ygl6x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_uamr9xer", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks,\n\nFor the past 2 years I've been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, ddl generation, self deployment, schema evolution... basically, as you build better and better pipelines you will want more and more.\n\nThe value proposition is to automate the tedious work you do, so you can focus on better things.\n\nSo dlt is a library where in the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading.\n\nIn its most complex form, you can do almost anything you can want, from memory management, multithreading, extraction DAGs, etc.\n\nThe library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community.\n\nFeedback is very welcome and so are requests for features or destinations.\n\nThe library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.[https://dlthub.com/](https://dlthub.com/)  \n\n\nI know lots of you are jaded and fed up with toy technologies - this is not a toy tech, it's purpose made for productivity and sanity.\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python library for automating data normalisation, schema creation and loading to db", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yfh6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689238840.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689238647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks,&lt;/p&gt;\n\n&lt;p&gt;For the past 2 years I&amp;#39;ve been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, ddl generation, self deployment, schema evolution... basically, as you build better and better pipelines you will want more and more.&lt;/p&gt;\n\n&lt;p&gt;The value proposition is to automate the tedious work you do, so you can focus on better things.&lt;/p&gt;\n\n&lt;p&gt;So dlt is a library where in the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading.&lt;/p&gt;\n\n&lt;p&gt;In its most complex form, you can do almost anything you can want, from memory management, multithreading, extraction DAGs, etc.&lt;/p&gt;\n\n&lt;p&gt;The library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community.&lt;/p&gt;\n\n&lt;p&gt;Feedback is very welcome and so are requests for features or destinations.&lt;/p&gt;\n\n&lt;p&gt;The library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.&lt;a href=\"https://dlthub.com/\"&gt;https://dlthub.com/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I know lots of you are jaded and fed up with toy technologies - this is not a toy tech, it&amp;#39;s purpose made for productivity and sanity.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?auto=webp&amp;s=cb39faa311105e22445462cdf83958c4587fedc2", "width": 1200, "height": 898}, "resolutions": [{"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2950fb9a02e9cdd0b136f3013b72924854fdca3f", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f0af0e48140a561a1f7b733a96875956b6389de", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25c5e30c984451ee6ea10cd4e1067e85319086d3", "width": 320, "height": 239}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=784ffdd500b6cb71463c17b9d348b620c417e6b2", "width": 640, "height": 478}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a966fccda316bcff3aef7e4ae872efc79cabbc1", "width": 960, "height": 718}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec5a6d47433e6864a169a05e9319caa70258c58d", "width": 1080, "height": 808}], "variants": {}, "id": "cUuEsBHL5TMhrkQNJ9leYxFMOF6VgvTJ_EKHwExrn8Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14yfh6p", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "subreddit_subscribers": 115558, "created_utc": 1689238647.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1689242433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?auto=webp&amp;s=cb39faa311105e22445462cdf83958c4587fedc2", "width": 1200, "height": 898}, "resolutions": [{"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2950fb9a02e9cdd0b136f3013b72924854fdca3f", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f0af0e48140a561a1f7b733a96875956b6389de", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25c5e30c984451ee6ea10cd4e1067e85319086d3", "width": 320, "height": 239}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=784ffdd500b6cb71463c17b9d348b620c417e6b2", "width": 640, "height": 478}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a966fccda316bcff3aef7e4ae872efc79cabbc1", "width": 960, "height": 718}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec5a6d47433e6864a169a05e9319caa70258c58d", "width": 1080, "height": 808}], "variants": {}, "id": "cUuEsBHL5TMhrkQNJ9leYxFMOF6VgvTJ_EKHwExrn8Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ygl6x", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14yfh6p", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ygl6x/i_built_a_python_library_for_automating_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "subreddit_subscribers": 947115, "created_utc": 1689242433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been out of school for 2 years and have been trying to get a job the entire time in the US. No matter how many resumes I send out, no one is even seeing me for an interview. I didn't do too badly in college (over 3.0 GPA) and am getting really frustrated with no one giving me any attention. I have also been doing coding projects online so my computer programming skills don't dull. Is there any way I can make myself more marketable?", "author_fullname": "t2_omkcn0p6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xyu3i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689191744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been out of school for 2 years and have been trying to get a job the entire time in the US. No matter how many resumes I send out, no one is even seeing me for an interview. I didn&amp;#39;t do too badly in college (over 3.0 GPA) and am getting really frustrated with no one giving me any attention. I have also been doing coding projects online so my computer programming skills don&amp;#39;t dull. Is there any way I can make myself more marketable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xyu3i", "is_robot_indexable": true, "report_reasons": null, "author": "GainAffectionate7196", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xyu3i/job_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xyu3i/job_help/", "subreddit_subscribers": 947115, "created_utc": 1689191744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I have an important presentation in 24 hours. I really want to create a map visualisation of the data but I'm wondering the easiest/most efficient way to do it quickly?\n\nI've already cleaned the data and tried doing it in Tableau but am having trouble figuring it out quickly.\n\nMy data is the location (city), types of incidents, and number of incidents.\n\nIs this realistic to achieve in a short time frame? I'm intermediate at excel but beginner in Tableau. I don't have access to powerBI. Any other free tool you recommend I'd be happy to use.\n\nThanks!", "author_fullname": "t2_uos6k2i4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create a map visualisation of dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xok3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689168358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have an important presentation in 24 hours. I really want to create a map visualisation of the data but I&amp;#39;m wondering the easiest/most efficient way to do it quickly?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve already cleaned the data and tried doing it in Tableau but am having trouble figuring it out quickly.&lt;/p&gt;\n\n&lt;p&gt;My data is the location (city), types of incidents, and number of incidents.&lt;/p&gt;\n\n&lt;p&gt;Is this realistic to achieve in a short time frame? I&amp;#39;m intermediate at excel but beginner in Tableau. I don&amp;#39;t have access to powerBI. Any other free tool you recommend I&amp;#39;d be happy to use.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14xok3v", "is_robot_indexable": true, "report_reasons": null, "author": "Greenblueberry349", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14xok3v/how_to_create_a_map_visualisation_of_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14xok3v/how_to_create_a_map_visualisation_of_dataset/", "subreddit_subscribers": 947115, "created_utc": 1689168358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am learning Data Sciencea and I am relatively new.\n\nI am looking for resources like books, articles or courses etc.\nHere are the list of topics which I need resources for:\n\n1. Statistics and Probability\n2. Mathematics and theory related to Algorithms\n3. Linear Algebra (For Deep Learning)\n4. Natural Language Processing\n5. Computer Vision\n6. Any other topic which I missed and your would love to share \ud83d\ude09\n\nFeel free to suggest any book with any level of Mathematics (means your can share beginner, intermediate or advanced level resources).", "author_fullname": "t2_atde1af1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for Resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14yk7qn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689253175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning Data Sciencea and I am relatively new.&lt;/p&gt;\n\n&lt;p&gt;I am looking for resources like books, articles or courses etc.\nHere are the list of topics which I need resources for:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Statistics and Probability&lt;/li&gt;\n&lt;li&gt;Mathematics and theory related to Algorithms&lt;/li&gt;\n&lt;li&gt;Linear Algebra (For Deep Learning)&lt;/li&gt;\n&lt;li&gt;Natural Language Processing&lt;/li&gt;\n&lt;li&gt;Computer Vision&lt;/li&gt;\n&lt;li&gt;Any other topic which I missed and your would love to share \ud83d\ude09&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Feel free to suggest any book with any level of Mathematics (means your can share beginner, intermediate or advanced level resources).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yk7qn", "is_robot_indexable": true, "report_reasons": null, "author": "Ethan045627", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yk7qn/suggestions_for_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yk7qn/suggestions_for_resources/", "subreddit_subscribers": 947115, "created_utc": 1689253175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vg5ezy1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "hiring managers, data science is more than this, right?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_14yk493", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1RjI_g2Caf4ZQrTRXZUxhcKhYC3xJDTRLjewt9mtYAg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689252910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtube.com/shorts/EA-mo9zhtq0?feature=share", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cHMTnlNraeh9Ed_DSPTderp1U_Jv75eezYA9RzQF3Ts.jpg?auto=webp&amp;s=21c3a5433e01ebaa408eebd6970457ebf5aa2684", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/cHMTnlNraeh9Ed_DSPTderp1U_Jv75eezYA9RzQF3Ts.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d3e328b98ec6f1c98d3913ec3d6f72b4038fe4ed", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/cHMTnlNraeh9Ed_DSPTderp1U_Jv75eezYA9RzQF3Ts.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=35a4f03d6e601d52965ea560e25ec8132885c0d7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/cHMTnlNraeh9Ed_DSPTderp1U_Jv75eezYA9RzQF3Ts.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=194cb65e2deaf7cc5fc9d5f697bac8f60fcbaa1a", "width": 320, "height": 240}], "variants": {}, "id": "U0t_DgSDIhmoXEIyoZ6E3kv1UTvJnfBNXBpeDGRR_RI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yk493", "is_robot_indexable": true, "report_reasons": null, "author": "sassyalfred", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yk493/hiring_managers_data_science_is_more_than_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtube.com/shorts/EA-mo9zhtq0?feature=share", "subreddit_subscribers": 947115, "created_utc": 1689252910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, i want to webscrape a subreddit. Is it still free? (API). Do you know some kind of instruction for python. Thank you", "author_fullname": "t2_2qpf5pg9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit webscraping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14yjz2b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689252516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, i want to webscrape a subreddit. Is it still free? (API). Do you know some kind of instruction for python. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yjz2b", "is_robot_indexable": true, "report_reasons": null, "author": "DoctorPhysics08", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yjz2b/reddit_webscraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yjz2b/reddit_webscraping/", "subreddit_subscribers": 947115, "created_utc": 1689252516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Background info: graduated with a marketing major and Econ minor in 2021, no coding experience whatsoever \n\nI figured the first place I should start is with getting some coding certifications but which ones do it get? Are there any good \u201cbase\u201d ones to get a start? Are there differences in which certifications to get? Just all around somewhat confused about how to get this ball rolling and would appreciate any advice/help.", "author_fullname": "t2_4291wa9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I know I want to work in data science, but where do I start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14yjmxk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689251601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background info: graduated with a marketing major and Econ minor in 2021, no coding experience whatsoever &lt;/p&gt;\n\n&lt;p&gt;I figured the first place I should start is with getting some coding certifications but which ones do it get? Are there any good \u201cbase\u201d ones to get a start? Are there differences in which certifications to get? Just all around somewhat confused about how to get this ball rolling and would appreciate any advice/help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yjmxk", "is_robot_indexable": true, "report_reasons": null, "author": "EddieSpaghetti2950", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yjmxk/i_know_i_want_to_work_in_data_science_but_where/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yjmxk/i_know_i_want_to_work_in_data_science_but_where/", "subreddit_subscribers": 947115, "created_utc": 1689251601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a data analyst and haven't worked on DCJ (Digital Customer Journey) before. In my project I was assigned to handle DCJ and generate a flow and insights out of it.\n\nWith out talking about the Client or the industry this is an overview of how my data looks like.  \n\n\\--&gt; Large table with billions of records and comes down to millions if I filter for few customers and their interaction points with the website. (Data is very rough....)\n\n\\--&gt; Has the timestamp at which they went into each page and not so accurate page name.\n\n\\--&gt; Immediate previous page info is also available but not reliable.\n\n&amp;#x200B;\n\nMy problem is that I need to get the flow of the journey and insights for certain group of customers who left the company in the recent past.\n\nIf i check on the flow of a single customer. His/Her visit to common pages are so many (which is not useful). Eliminating the common pages makes the flow disturbed.\n\nCreating a generalized flow seems to be impossible.\n\nCurrently making experiments with parallel categories and Sankey diagram (very complex and client cannot understand)\n\n&amp;#x200B;\n\nHelp: I need suggestions on how to approach this project. I am totally stuck. \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_q60xrlzp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insight generation for Digital customer journey!!! Totally stuck", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14yjmmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689251574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst and haven&amp;#39;t worked on DCJ (Digital Customer Journey) before. In my project I was assigned to handle DCJ and generate a flow and insights out of it.&lt;/p&gt;\n\n&lt;p&gt;With out talking about the Client or the industry this is an overview of how my data looks like.  &lt;/p&gt;\n\n&lt;p&gt;--&amp;gt; Large table with billions of records and comes down to millions if I filter for few customers and their interaction points with the website. (Data is very rough....)&lt;/p&gt;\n\n&lt;p&gt;--&amp;gt; Has the timestamp at which they went into each page and not so accurate page name.&lt;/p&gt;\n\n&lt;p&gt;--&amp;gt; Immediate previous page info is also available but not reliable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My problem is that I need to get the flow of the journey and insights for certain group of customers who left the company in the recent past.&lt;/p&gt;\n\n&lt;p&gt;If i check on the flow of a single customer. His/Her visit to common pages are so many (which is not useful). Eliminating the common pages makes the flow disturbed.&lt;/p&gt;\n\n&lt;p&gt;Creating a generalized flow seems to be impossible.&lt;/p&gt;\n\n&lt;p&gt;Currently making experiments with parallel categories and Sankey diagram (very complex and client cannot understand)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Help: I need suggestions on how to approach this project. I am totally stuck. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yjmmc", "is_robot_indexable": true, "report_reasons": null, "author": "hungry_man13", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yjmmc/insight_generation_for_digital_customer_journey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yjmmc/insight_generation_for_digital_customer_journey/", "subreddit_subscribers": 947115, "created_utc": 1689251574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Any idea about Public Administration needs in the data science field?\n\nAt the moment I am planning to develop a system that interacts with an LLM to interrogate some APIs in order to give the citizen some pieces of information, but I am scared of the memory requests.", "author_fullname": "t2_25ovihzo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Projects for Public Administration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14yjgmg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689251107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any idea about Public Administration needs in the data science field?&lt;/p&gt;\n\n&lt;p&gt;At the moment I am planning to develop a system that interacts with an LLM to interrogate some APIs in order to give the citizen some pieces of information, but I am scared of the memory requests.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yjgmg", "is_robot_indexable": true, "report_reasons": null, "author": "lahaine93", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yjgmg/data_science_projects_for_public_administration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yjgmg/data_science_projects_for_public_administration/", "subreddit_subscribers": 947115, "created_utc": 1689251107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2i29jtun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coming off the ICOs PETS guide, has anyone used/explored any services using PETs to work with data? This podcast was intriguing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_14yic7h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BT_r6i91l5w?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Privacy by Design: The Future of Homomorphic Encryption &amp;amp; Secure Data Analytics\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Privacy by Design: The Future of Homomorphic Encryption &amp; Secure Data Analytics", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BT_r6i91l5w?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Privacy by Design: The Future of Homomorphic Encryption &amp;amp; Secure Data Analytics\"&gt;&lt;/iframe&gt;", "author_name": "Hacker Valley Media", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/BT_r6i91l5w/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@HackerValleyMedia"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BT_r6i91l5w?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Privacy by Design: The Future of Homomorphic Encryption &amp;amp; Secure Data Analytics\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/14yic7h", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Q5Sgh8vjsOCwsRypHHkTCyJ4x8A2LOMgL4Z8ULcwkkE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689247910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/BT_r6i91l5w", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HvmoiW9j__O2g8xZcx0WeHa1wDW5aSDY4sYwym2YwhE.jpg?auto=webp&amp;s=edfa6981db562ea23e156689a7d9ba2b4152d0bd", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/HvmoiW9j__O2g8xZcx0WeHa1wDW5aSDY4sYwym2YwhE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=11d862c985f29577e96f2370a50974b0f0605ea7", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/HvmoiW9j__O2g8xZcx0WeHa1wDW5aSDY4sYwym2YwhE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9213876dc8b3e033ab53cdb21879d45a9594264", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/HvmoiW9j__O2g8xZcx0WeHa1wDW5aSDY4sYwym2YwhE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d6f0a69ceb572758f4c98e68300caaeb79b134c", "width": 320, "height": 240}], "variants": {}, "id": "15yokn1dtAdjs7mihI6c8G6R_AZFbu7jxd9mzya1COM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yic7h", "is_robot_indexable": true, "report_reasons": null, "author": "thebiztechguy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yic7h/coming_off_the_icos_pets_guide_has_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/BT_r6i91l5w", "subreddit_subscribers": 947115, "created_utc": 1689247910.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Privacy by Design: The Future of Homomorphic Encryption &amp; Secure Data Analytics", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/BT_r6i91l5w?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Privacy by Design: The Future of Homomorphic Encryption &amp;amp; Secure Data Analytics\"&gt;&lt;/iframe&gt;", "author_name": "Hacker Valley Media", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/BT_r6i91l5w/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@HackerValleyMedia"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone ! I\u2019m a master student and I\u2019m currently looking for participants for my psychology research, (18-25 yrs old wanted and living in UK). It\u2019s a 5-10 mins survey about social media and self-esteem.  It would be wonderful if any of you participated. Thank you! https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV_56aKJ4ajKHvSIbc", "author_fullname": "t2_dgps546ru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for participants", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yib1o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689247833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone ! I\u2019m a master student and I\u2019m currently looking for participants for my psychology research, (18-25 yrs old wanted and living in UK). It\u2019s a 5-10 mins survey about social media and self-esteem.  It would be wonderful if any of you participated. Thank you! &lt;a href=\"https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV_56aKJ4ajKHvSIbc\"&gt;https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV_56aKJ4ajKHvSIbc&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yib1o", "is_robot_indexable": true, "report_reasons": null, "author": "Anissa-rf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yib1o/looking_for_participants/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yib1o/looking_for_participants/", "subreddit_subscribers": 947115, "created_utc": 1689247833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a17h5nfoh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlocking the Power of Data Analytics: A Guide for UK Businesses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yi3fy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1689247209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "uk.sganalytics.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://uk.sganalytics.com/blog/unlocking-the-power-of-data-analytics/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yi3fy", "is_robot_indexable": true, "report_reasons": null, "author": "Pratikshahh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yi3fy/unlocking_the_power_of_data_analytics_a_guide_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://uk.sganalytics.com/blog/unlocking-the-power-of-data-analytics/", "subreddit_subscribers": 947115, "created_utc": 1689247209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/xj29w82h6pbb1.jpg?width=2800&amp;format=pjpg&amp;auto=webp&amp;s=507fecaa336906c9bae079634d400e3c239b9f3d\n\nYou can find it interesting. In this guide from OpenCV.ai team (the consulting arm of OpenCV), you will dissect the intricate process of object position prediction in 3D space, discussing the mechanics of rotation, translation, and scale, focusing on metrics for evaluating these predictions.\n\nhttps://preview.redd.it/brv4sjzi6pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=e3689b27eed7666e91f6089fba72ed5bd74119ef\n\nIn the vast world of **3D object pose estimation**, one group of tasks demands a distinct spotlight. This is where we delve into predicting the position of rigid objects in 3D, which comes down to 6DoF (Degrees of Freedom) estimation. In this guide, we will dissect the intricate process of object position prediction in 3D space, discussing the mechanics of rotation, translation, and scale, focusing on metrics for evaluating these predictions.\n\nhttps://preview.redd.it/4knpqfnk6pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=c04b956f02f88bf5079243d96fba509224515bde\n\n**The 6DoF estimation task** encompasses predicting an object's position in 3D space (X, Y, Z coordinates), along with its rotation around these axes, called yaw, pitch, and roll.\n\nThough various approaches exist to predict these, measuring their effectiveness is no simple task. Quality metrics in 2D space tasks have reached a certain level of consensus, but in 3D, things are a bit more complicated.\n\n**Before we start reviewing metrics, let\u2019s look closer at this task.**\u200d\n\n### Task overview\n\n**3D pose estimation** begins with an **RGB** (and sometimes RGBD) image that features the target object. The aim is to predict the object's **6D position**, representing the rigid transformation from the object's coordinate system to the camera's coordinate system.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/d21rvmew6pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=9980005033f3c35c365c0f4213beec6a8cdc5709\n\nA complete 6D pose **consists of two elements** \\- the 3D rotation (3x3 matrix R) of the object and the 3D translation (3x1 vector t). For calculation convenience, they can both be padded to 4x4 matrices.\n\n### Rotation\n\nRotation involves a rotation matrix (R), which essentially breaks down into three 2D rotation matrices. The rotation matrix is defined by the yaw, pitch, and roll angles:\n\n[where \u03b1, \u03b2, and \u03b3 are yaw, pitch, and roll angles, respectively.\u200d](https://preview.redd.it/awmv6jo07pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=638579eacc6d43738dfe7341dba931e67ede32ff)\n\n### Translation\n\nIn the translation matrix, we take into account the distances in the x, y, and z coordinates (\ud835\udc97x, \ud835\udc97y, \ud835\udc97z).\u00a0Translation transformation matrix T in the 3D space is a 4D matrix with the following structure:\n\n&amp;#x200B;\n\n[where \ud835\udc97x, \ud835\udc97y, \ud835\udc97z are the translation distances in x, y, and z.](https://preview.redd.it/8e0nfma77pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=adc8cc8c0f75dad86dcdf8c039d35c28622e9813)\n\nIn other terms, the translation is a vector (t), which, when added to the original position, shifts the entire model in 3D space\u200d\n\n### Metrics\n\nEvaluation of these transformations is usually done via two groups of metrics: those measuring the whole transformation matrix and those measuring R, T, and S matrices separately. We will overview the 2 most common metrics - one from each group.\n\nThe most common overall metric is the average distance (**ADD**) or **ADD(s)** for symmetric objects. Here, the goal is to measure the distance between the Ground Truth (GT) 3D point cloud and the predicted 3D point cloud resulting from the transformation.\n\nAs a first step, predicted and GT 3D point clouds, are calculated from a base model using predicted and GT transformation matrices. Then the distance is measured for each point, and the mean distance is calculated. **The** **mean distance is calculated for each object.**\n\n&amp;#x200B;\n\nhttps://preview.redd.it/3fpkl95d7pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=e57d5ca9ad42e1c4655b7d7afe3ab3eca5d7b134\n\nAs a second step, the threshold of mean distance is picked. Then the percentage of objects with the mean distance below this threshold is calculated. This number is called ADD accuracy. ADD(s) is the same metric for symmetric objects.\n\n\u200d\n\n### R, T, and S\n\nHowever, in certain cases, evaluating rotation, translation, and scale separately can provide deeper insights into the error sources.\u00a0\n\nThe **translation error** is typically measured as the distance between the predicted and GT vectors.\u00a0\n\nThe **scale error** is calculated by dividing the GT scale by the predicted scale.\n\nCalculating the **rotation error**, on the other hand, is more challenging. Rotation matrices belong to the [**3D rotation group**](https://en.wikipedia.org/wiki/3D_rotation_group), often denoted SO(3). Therefore the difference between two rotation matrices, Rgt and Rpred, can be calculated by the metric of distance in SO(3).\u00a0\n\nThere are several approaches to defining a distance function or metric in a 3D rotation group. You can take a closer look at them in this [**paper**](https://www.cs.cmu.edu/~cga/dynopt/readings/Rmetric.pdf) in section 3. Some of them are based on quaternions, and some use the direct comparison of matrices, or for example, deviation from identity matrix. We will overview the most representable and intuitive method here.\n\n**This method calculates the solid angle between Rgt** **and Rpred** **matrices:**\n\n&amp;#x200B;\n\nhttps://preview.redd.it/acuy0gbg7pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=266805768e39067e3404c4e0a83f5885ea2a6e76\n\nFrom this equation angle of rotation can be easily calculated:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/anxijvoj7pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=b950ddc33228358f51607fc7388a7e87bc8d4c0a\n\nAs a result, we get a solid angle, which would represent the overall error angle in 3D space. The advantage of this metric is that it gives a spatial visual representation of the error.\n\n\u200d\n\n### Conclusion\n\nEvaluation is one of the critical processes in Deep Learning, and the right choice of evaluation metrics is crucial. Only with reliable and interpretable metrics can we not only make the right decisions but also explain them to our colleagues or customers.\n\n\u200d", "author_fullname": "t2_ny4qnnnz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Object position in 3D space - 6Dof (Degrees of Freedom) metrics overview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 99, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3fpkl95d7pbb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/3fpkl95d7pbb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2975ff8cdd7a969904213efafc8535e069ff54ab"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/3fpkl95d7pbb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e24bb0030ed0a21ae65da7e1211775629f3baf53"}, {"y": 106, "x": 320, "u": "https://preview.redd.it/3fpkl95d7pbb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef45daef7df2f9404043717bd58f3fe76f5002e9"}, {"y": 212, "x": 640, "u": "https://preview.redd.it/3fpkl95d7pbb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c8670ba7d86f23f5e0624f931000d19cccc267b6"}, {"y": 319, "x": 960, "u": "https://preview.redd.it/3fpkl95d7pbb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7fcda22a03f4de125b8fd017038c352c5e05f9ee"}, {"y": 359, "x": 1080, "u": "https://preview.redd.it/3fpkl95d7pbb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=45c297c37bcde0b989d51382e9fe4ab48284d8bf"}], "s": {"y": 832, "x": 2500, "u": "https://preview.redd.it/3fpkl95d7pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=e57d5ca9ad42e1c4655b7d7afe3ab3eca5d7b134"}, "id": "3fpkl95d7pbb1"}, "xj29w82h6pbb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/xj29w82h6pbb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=92a2a2f420b0682fd6a8ac404172c4266dc6b0a2"}, {"y": 153, "x": 216, "u": "https://preview.redd.it/xj29w82h6pbb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fc120d73920484c132016d7012d01416f5e61114"}, {"y": 226, "x": 320, "u": "https://preview.redd.it/xj29w82h6pbb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f0c19639c133de21d83b931099636489e4fa87a"}, {"y": 453, "x": 640, "u": "https://preview.redd.it/xj29w82h6pbb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ed82d0a3e9cffc241bed32ea92491f60f14ac79"}, {"y": 680, "x": 960, "u": "https://preview.redd.it/xj29w82h6pbb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=955c78932451d8dc7fdf29d08e20d27e04870446"}, {"y": 765, "x": 1080, "u": "https://preview.redd.it/xj29w82h6pbb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bbbe928f6256e29c4a8583fee43ef3aaed6563e1"}], "s": {"y": 1984, "x": 2800, "u": "https://preview.redd.it/xj29w82h6pbb1.jpg?width=2800&amp;format=pjpg&amp;auto=webp&amp;s=507fecaa336906c9bae079634d400e3c239b9f3d"}, "id": "xj29w82h6pbb1"}, "8e0nfma77pbb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/8e0nfma77pbb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a3473d5605011c9db494e544cf41911a33467c8c"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/8e0nfma77pbb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=88ebba2268b12e25c218158b37eddda1cb1572fc"}, {"y": 106, "x": 320, "u": "https://preview.redd.it/8e0nfma77pbb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=94f90148adb6d7032e223ed0d8afdcc0b413e661"}, {"y": 212, "x": 640, "u": "https://preview.redd.it/8e0nfma77pbb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bdd7e47757911c9fe9aa178aa54995472a13ad5b"}, {"y": 319, "x": 960, "u": "https://preview.redd.it/8e0nfma77pbb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=361e12d05986bf3327873807051d05dc66898513"}, {"y": 359, "x": 1080, "u": "https://preview.redd.it/8e0nfma77pbb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1081b097f20d393e67b5bdfca2164c3e95b068ab"}], "s": {"y": 832, "x": 2500, "u": "https://preview.redd.it/8e0nfma77pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=adc8cc8c0f75dad86dcdf8c039d35c28622e9813"}, "id": "8e0nfma77pbb1"}, "anxijvoj7pbb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/anxijvoj7pbb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e194848c6accdbec4ae281db4f2becd1ac902398"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/anxijvoj7pbb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=982e6dee78abeca73dccf88730a0ca6ba176da13"}, {"y": 106, "x": 320, "u": "https://preview.redd.it/anxijvoj7pbb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4c928d8a6beecfe7e1baf17b9a8681e770265201"}, {"y": 212, "x": 640, "u": "https://preview.redd.it/anxijvoj7pbb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ef1dabf02a7d1c2c59e9280fc8e46e05891e294b"}, {"y": 319, "x": 960, "u": "https://preview.redd.it/anxijvoj7pbb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=98b1b9e5dc3694d00648f4d5ecf11acefc28be2f"}, {"y": 359, "x": 1080, "u": "https://preview.redd.it/anxijvoj7pbb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=482b94e7ba7602bdad0766b9e1f061530f62c826"}], "s": {"y": 832, "x": 2500, "u": "https://preview.redd.it/anxijvoj7pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=b950ddc33228358f51607fc7388a7e87bc8d4c0a"}, "id": "anxijvoj7pbb1"}, "awmv6jo07pbb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/awmv6jo07pbb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8f037ee8bb258590b5b9a440b9dae4fcb62c7cb7"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/awmv6jo07pbb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c3bb4219f4d47b34f964287f6342ee888c65b8c"}, {"y": 106, "x": 320, "u": "https://preview.redd.it/awmv6jo07pbb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ccd91a387d3091b5c8ac54b2dab5cf5c501912f6"}, {"y": 212, "x": 640, "u": "https://preview.redd.it/awmv6jo07pbb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=035909c378d694c572f2781ebfcd84602cbbdb83"}, {"y": 319, "x": 960, "u": "https://preview.redd.it/awmv6jo07pbb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8d83753df5b0670fcaa18d097c058cbbe0d01b0e"}, {"y": 359, "x": 1080, "u": "https://preview.redd.it/awmv6jo07pbb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87646af791d8555ce30dd2b31c38874885135404"}], "s": {"y": 832, "x": 2500, "u": "https://preview.redd.it/awmv6jo07pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=638579eacc6d43738dfe7341dba931e67ede32ff"}, "id": "awmv6jo07pbb1"}, "4knpqfnk6pbb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/4knpqfnk6pbb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c5da963bc09aa6f028a411587ce1fb83563cce9f"}, {"y": 100, "x": 216, "u": "https://preview.redd.it/4knpqfnk6pbb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9bfd697f800c49df8fbdec9f0cd4d2f19b3fb4b7"}, {"y": 148, "x": 320, "u": "https://preview.redd.it/4knpqfnk6pbb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d6b618251da3902ae06042686743a97e66b4d0c5"}, {"y": 297, "x": 640, "u": "https://preview.redd.it/4knpqfnk6pbb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb0499a14a7390395943cf4fa084eaba6c0e4df6"}, {"y": 446, "x": 960, "u": "https://preview.redd.it/4knpqfnk6pbb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=781bf655e29023c10c1f2f20088b6e70407ac3f1"}, {"y": 502, "x": 1080, "u": "https://preview.redd.it/4knpqfnk6pbb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=55bb2543503e3ec88dcd95b8272efa3647ad3077"}], "s": {"y": 1164, "x": 2500, "u": "https://preview.redd.it/4knpqfnk6pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=c04b956f02f88bf5079243d96fba509224515bde"}, "id": "4knpqfnk6pbb1"}, "brv4sjzi6pbb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/brv4sjzi6pbb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=87c498ec51d96efd8ef439946d0f6d490e439478"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/brv4sjzi6pbb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=94e93779b035423bb51cd13badfdc404d69ae1ab"}, {"y": 106, "x": 320, "u": "https://preview.redd.it/brv4sjzi6pbb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1ce66b3c7e6e98c3c6187d286aea58bd2cd810bc"}, {"y": 212, "x": 640, "u": "https://preview.redd.it/brv4sjzi6pbb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3fbf89a723e5b5c9eb055cbae93a3ec76e21922f"}, {"y": 319, "x": 960, "u": "https://preview.redd.it/brv4sjzi6pbb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f89bd037d7f7e60a4ef8b77c3f5f0bdfdea3e61d"}, {"y": 359, "x": 1080, "u": "https://preview.redd.it/brv4sjzi6pbb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed0151b3f794d3cbcd86bfd3194a2b51467ce4e2"}], "s": {"y": 832, "x": 2500, "u": "https://preview.redd.it/brv4sjzi6pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=e3689b27eed7666e91f6089fba72ed5bd74119ef"}, "id": "brv4sjzi6pbb1"}, "d21rvmew6pbb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/d21rvmew6pbb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04b045040bdbf08ef5b01f6acb6543a5a8748eea"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/d21rvmew6pbb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=75f1b357ad4636633a2801fae83408d50ffd6650"}, {"y": 106, "x": 320, "u": "https://preview.redd.it/d21rvmew6pbb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=43bdbf6a8821b58e68f93ba3a33981d256854c99"}, {"y": 212, "x": 640, "u": "https://preview.redd.it/d21rvmew6pbb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0cbf50b4a71de06ad31dfde3f95ff13cf4350194"}, {"y": 319, "x": 960, "u": "https://preview.redd.it/d21rvmew6pbb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7941b5759ca690aeb1548e8c51545f308068a81a"}, {"y": 359, "x": 1080, "u": "https://preview.redd.it/d21rvmew6pbb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=14a9ef31da217e53595012edbee45834373ea73e"}], "s": {"y": 832, "x": 2500, "u": "https://preview.redd.it/d21rvmew6pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=9980005033f3c35c365c0f4213beec6a8cdc5709"}, "id": "d21rvmew6pbb1"}, "acuy0gbg7pbb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/acuy0gbg7pbb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5173dd4e494dbb740c42033955294e12ee45b58"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/acuy0gbg7pbb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=797618623e7e11df8731ecd333bb075f6e78cf93"}, {"y": 106, "x": 320, "u": "https://preview.redd.it/acuy0gbg7pbb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e696c16aa9837bd925967ad41e191f0aa63630a"}, {"y": 212, "x": 640, "u": "https://preview.redd.it/acuy0gbg7pbb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e356cc9dd3a899044401c97f638fac0ee3950582"}, {"y": 319, "x": 960, "u": "https://preview.redd.it/acuy0gbg7pbb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a7d6126c2053fa51df764fd52f89b629237004d2"}, {"y": 359, "x": 1080, "u": "https://preview.redd.it/acuy0gbg7pbb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=654cbc97dfb710d874052ec901d352685d347d01"}], "s": {"y": 832, "x": 2500, "u": "https://preview.redd.it/acuy0gbg7pbb1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s=266805768e39067e3404c4e0a83f5885ea2a6e76"}, "id": "acuy0gbg7pbb1"}}, "name": "t3_14yfp3c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TXhogetkFrFmjPRmj0Cx_eG50fAboJEiJN83nnDH9r0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689239388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xj29w82h6pbb1.jpg?width=2800&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=507fecaa336906c9bae079634d400e3c239b9f3d\"&gt;https://preview.redd.it/xj29w82h6pbb1.jpg?width=2800&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=507fecaa336906c9bae079634d400e3c239b9f3d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You can find it interesting. In this guide from OpenCV.ai team (the consulting arm of OpenCV), you will dissect the intricate process of object position prediction in 3D space, discussing the mechanics of rotation, translation, and scale, focusing on metrics for evaluating these predictions.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/brv4sjzi6pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e3689b27eed7666e91f6089fba72ed5bd74119ef\"&gt;https://preview.redd.it/brv4sjzi6pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e3689b27eed7666e91f6089fba72ed5bd74119ef&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In the vast world of &lt;strong&gt;3D object pose estimation&lt;/strong&gt;, one group of tasks demands a distinct spotlight. This is where we delve into predicting the position of rigid objects in 3D, which comes down to 6DoF (Degrees of Freedom) estimation. In this guide, we will dissect the intricate process of object position prediction in 3D space, discussing the mechanics of rotation, translation, and scale, focusing on metrics for evaluating these predictions.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4knpqfnk6pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c04b956f02f88bf5079243d96fba509224515bde\"&gt;https://preview.redd.it/4knpqfnk6pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c04b956f02f88bf5079243d96fba509224515bde&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The 6DoF estimation task&lt;/strong&gt; encompasses predicting an object&amp;#39;s position in 3D space (X, Y, Z coordinates), along with its rotation around these axes, called yaw, pitch, and roll.&lt;/p&gt;\n\n&lt;p&gt;Though various approaches exist to predict these, measuring their effectiveness is no simple task. Quality metrics in 2D space tasks have reached a certain level of consensus, but in 3D, things are a bit more complicated.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Before we start reviewing metrics, let\u2019s look closer at this task.&lt;/strong&gt;\u200d&lt;/p&gt;\n\n&lt;h3&gt;Task overview&lt;/h3&gt;\n\n&lt;p&gt;&lt;strong&gt;3D pose estimation&lt;/strong&gt; begins with an &lt;strong&gt;RGB&lt;/strong&gt; (and sometimes RGBD) image that features the target object. The aim is to predict the object&amp;#39;s &lt;strong&gt;6D position&lt;/strong&gt;, representing the rigid transformation from the object&amp;#39;s coordinate system to the camera&amp;#39;s coordinate system.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/d21rvmew6pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9980005033f3c35c365c0f4213beec6a8cdc5709\"&gt;https://preview.redd.it/d21rvmew6pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9980005033f3c35c365c0f4213beec6a8cdc5709&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A complete 6D pose &lt;strong&gt;consists of two elements&lt;/strong&gt; - the 3D rotation (3x3 matrix R) of the object and the 3D translation (3x1 vector t). For calculation convenience, they can both be padded to 4x4 matrices.&lt;/p&gt;\n\n&lt;h3&gt;Rotation&lt;/h3&gt;\n\n&lt;p&gt;Rotation involves a rotation matrix (R), which essentially breaks down into three 2D rotation matrices. The rotation matrix is defined by the yaw, pitch, and roll angles:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/awmv6jo07pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=638579eacc6d43738dfe7341dba931e67ede32ff\"&gt;where \u03b1, \u03b2, and \u03b3 are yaw, pitch, and roll angles, respectively.\u200d&lt;/a&gt;&lt;/p&gt;\n\n&lt;h3&gt;Translation&lt;/h3&gt;\n\n&lt;p&gt;In the translation matrix, we take into account the distances in the x, y, and z coordinates (\ud835\udc97x, \ud835\udc97y, \ud835\udc97z).\u00a0Translation transformation matrix T in the 3D space is a 4D matrix with the following structure:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8e0nfma77pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=adc8cc8c0f75dad86dcdf8c039d35c28622e9813\"&gt;where \ud835\udc97x, \ud835\udc97y, \ud835\udc97z are the translation distances in x, y, and z.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In other terms, the translation is a vector (t), which, when added to the original position, shifts the entire model in 3D space\u200d&lt;/p&gt;\n\n&lt;h3&gt;Metrics&lt;/h3&gt;\n\n&lt;p&gt;Evaluation of these transformations is usually done via two groups of metrics: those measuring the whole transformation matrix and those measuring R, T, and S matrices separately. We will overview the 2 most common metrics - one from each group.&lt;/p&gt;\n\n&lt;p&gt;The most common overall metric is the average distance (&lt;strong&gt;ADD&lt;/strong&gt;) or &lt;strong&gt;ADD(s)&lt;/strong&gt; for symmetric objects. Here, the goal is to measure the distance between the Ground Truth (GT) 3D point cloud and the predicted 3D point cloud resulting from the transformation.&lt;/p&gt;\n\n&lt;p&gt;As a first step, predicted and GT 3D point clouds, are calculated from a base model using predicted and GT transformation matrices. Then the distance is measured for each point, and the mean distance is calculated. &lt;strong&gt;The&lt;/strong&gt; &lt;strong&gt;mean distance is calculated for each object.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3fpkl95d7pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e57d5ca9ad42e1c4655b7d7afe3ab3eca5d7b134\"&gt;https://preview.redd.it/3fpkl95d7pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e57d5ca9ad42e1c4655b7d7afe3ab3eca5d7b134&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As a second step, the threshold of mean distance is picked. Then the percentage of objects with the mean distance below this threshold is calculated. This number is called ADD accuracy. ADD(s) is the same metric for symmetric objects.&lt;/p&gt;\n\n&lt;p&gt;\u200d&lt;/p&gt;\n\n&lt;h3&gt;R, T, and S&lt;/h3&gt;\n\n&lt;p&gt;However, in certain cases, evaluating rotation, translation, and scale separately can provide deeper insights into the error sources.\u00a0&lt;/p&gt;\n\n&lt;p&gt;The &lt;strong&gt;translation error&lt;/strong&gt; is typically measured as the distance between the predicted and GT vectors.\u00a0&lt;/p&gt;\n\n&lt;p&gt;The &lt;strong&gt;scale error&lt;/strong&gt; is calculated by dividing the GT scale by the predicted scale.&lt;/p&gt;\n\n&lt;p&gt;Calculating the &lt;strong&gt;rotation error&lt;/strong&gt;, on the other hand, is more challenging. Rotation matrices belong to the &lt;a href=\"https://en.wikipedia.org/wiki/3D_rotation_group\"&gt;&lt;strong&gt;3D rotation group&lt;/strong&gt;&lt;/a&gt;, often denoted SO(3). Therefore the difference between two rotation matrices, Rgt and Rpred, can be calculated by the metric of distance in SO(3).\u00a0&lt;/p&gt;\n\n&lt;p&gt;There are several approaches to defining a distance function or metric in a 3D rotation group. You can take a closer look at them in this &lt;a href=\"https://www.cs.cmu.edu/%7Ecga/dynopt/readings/Rmetric.pdf\"&gt;&lt;strong&gt;paper&lt;/strong&gt;&lt;/a&gt; in section 3. Some of them are based on quaternions, and some use the direct comparison of matrices, or for example, deviation from identity matrix. We will overview the most representable and intuitive method here.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;This method calculates the solid angle between Rgt&lt;/strong&gt; &lt;strong&gt;and Rpred&lt;/strong&gt; &lt;strong&gt;matrices:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/acuy0gbg7pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=266805768e39067e3404c4e0a83f5885ea2a6e76\"&gt;https://preview.redd.it/acuy0gbg7pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=266805768e39067e3404c4e0a83f5885ea2a6e76&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;From this equation angle of rotation can be easily calculated:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/anxijvoj7pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b950ddc33228358f51607fc7388a7e87bc8d4c0a\"&gt;https://preview.redd.it/anxijvoj7pbb1.jpg?width=2500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b950ddc33228358f51607fc7388a7e87bc8d4c0a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As a result, we get a solid angle, which would represent the overall error angle in 3D space. The advantage of this metric is that it gives a spatial visual representation of the error.&lt;/p&gt;\n\n&lt;p&gt;\u200d&lt;/p&gt;\n\n&lt;h3&gt;Conclusion&lt;/h3&gt;\n\n&lt;p&gt;Evaluation is one of the critical processes in Deep Learning, and the right choice of evaluation metrics is crucial. Only with reliable and interpretable metrics can we not only make the right decisions but also explain them to our colleagues or customers.&lt;/p&gt;\n\n&lt;p&gt;\u200d&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14yfp3c", "is_robot_indexable": true, "report_reasons": null, "author": "No-Independence5880", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14yfp3c/object_position_in_3d_space_6dof_degrees_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14yfp3c/object_position_in_3d_space_6dof_degrees_of/", "subreddit_subscribers": 947115, "created_utc": 1689239388.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}