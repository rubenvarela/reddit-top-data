{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I do have experience in the specific field I'm going to be doing data science in. However, in DS per se, I don't even have a year experience. It's a big company for which I always dreamed of working, so I'm as happy as I am terrified.\n\nCan field knowledge carry me through the job? \n\nI can't even tell what differs a senior data scientist from a junior.\n\nPlease, I need advice on what to expect (and what is going to be expected of me).", "author_fullname": "t2_uhmjjac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got hired to a senior level position. I have 7 months experience and I'm terrified.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14u4pbd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 111, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 111, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688823938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I do have experience in the specific field I&amp;#39;m going to be doing data science in. However, in DS per se, I don&amp;#39;t even have a year experience. It&amp;#39;s a big company for which I always dreamed of working, so I&amp;#39;m as happy as I am terrified.&lt;/p&gt;\n\n&lt;p&gt;Can field knowledge carry me through the job? &lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t even tell what differs a senior data scientist from a junior.&lt;/p&gt;\n\n&lt;p&gt;Please, I need advice on what to expect (and what is going to be expected of me).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14u4pbd", "is_robot_indexable": true, "report_reasons": null, "author": "bekkai", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14u4pbd/just_got_hired_to_a_senior_level_position_i_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14u4pbd/just_got_hired_to_a_senior_level_position_i_have/", "subreddit_subscribers": 942407, "created_utc": 1688823938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The authors of An Introduction to Statistical Learning w/ Applications in R (ISLR) have just released a Python edition of the book. Both R and Python versions of the book are freely available [https://www.statlearning.com/](https://www.statlearning.com/) . ", "author_fullname": "t2_52x58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Introduction to Statistical Learning (ISL) w/ Python is Now Available!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ucbvf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688842786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The authors of An Introduction to Statistical Learning w/ Applications in R (ISLR) have just released a Python edition of the book. Both R and Python versions of the book are freely available &lt;a href=\"https://www.statlearning.com/\"&gt;https://www.statlearning.com/&lt;/a&gt; . &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ucbvf", "is_robot_indexable": true, "report_reasons": null, "author": "conorc123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ucbvf/an_introduction_to_statistical_learning_isl_w/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ucbvf/an_introduction_to_statistical_learning_isl_w/", "subreddit_subscribers": 942407, "created_utc": 1688842786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in a position where a company would like to hire me to do a whole swath of data projects: from dashboards, to building out databases, to predictive modelling. \n\nSo I wanted to know what y'all would charge per hour to do your current duties. I attempted to Google this, but the answers were inconclusive/far too varied.\n\nI'm estimating like $165 per hour in a major US city.", "author_fullname": "t2_769lgtz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you charge per hour?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tn0bd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688772378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in a position where a company would like to hire me to do a whole swath of data projects: from dashboards, to building out databases, to predictive modelling. &lt;/p&gt;\n\n&lt;p&gt;So I wanted to know what y&amp;#39;all would charge per hour to do your current duties. I attempted to Google this, but the answers were inconclusive/far too varied.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m estimating like $165 per hour in a major US city.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tn0bd", "is_robot_indexable": true, "report_reasons": null, "author": "FisterAct", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tn0bd/what_would_you_charge_per_hour/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tn0bd/what_would_you_charge_per_hour/", "subreddit_subscribers": 942407, "created_utc": 1688772378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working building a classification model. I have built a model and baselined it with pycaret and the results looked promising given the limited  7 months of data. Around 0.7 MCC and auc 0.92-94. \n\nI started building an actual model and the results were ok on cross-validation in general for model performance. However as I move into model backtesting the situation changes the model performs slightly better than random probability. MCC and Kappa 0.2 and auc of 0.6.\n\nI have exactly 7 months of data and I\u2019m following an expanding window back testing methodology with 2 months window of prediction due to how data is loaded.\nHowever my only issue is that given as I introduce more data the models are not developing any better. So i am not sure if its a longitudinal data.\n\n\nI have around 20,000 rows of data in training, and 70/30 class imbalance to the positive class. Most method\u2019s addressing still wouldn\u2019t lift the model up. I did try many methods and im not sure why nothing is pulling this up.\n\n\nI am trying to figure out what to do because i am not sure why. \n\nMy only explanations could be\n\n1) lack of data due to how temporal data seems to be important to my model but i dont have enough longevity\n\n2) i am expecting too much of my model to predict 2 months in advance\n \n3) economic reasons are making the models very turbulent, i work with  interests and investments and with rate hicks predicting customer behavior is hard\n\n4) the labeling of my target is not good, the labeling was built on loose rules around the database that if a sale was done or not but we don\u2019t really know for sure what happend. \n\n\nI would really appreciate insights.\n\nI checked for data leakage and everything and i really dont know what to do. I followed all the steps about stratification but still no luck.", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backtesting vs cross validation model results (I really need help)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tuk3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688793710.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688793173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working building a classification model. I have built a model and baselined it with pycaret and the results looked promising given the limited  7 months of data. Around 0.7 MCC and auc 0.92-94. &lt;/p&gt;\n\n&lt;p&gt;I started building an actual model and the results were ok on cross-validation in general for model performance. However as I move into model backtesting the situation changes the model performs slightly better than random probability. MCC and Kappa 0.2 and auc of 0.6.&lt;/p&gt;\n\n&lt;p&gt;I have exactly 7 months of data and I\u2019m following an expanding window back testing methodology with 2 months window of prediction due to how data is loaded.\nHowever my only issue is that given as I introduce more data the models are not developing any better. So i am not sure if its a longitudinal data.&lt;/p&gt;\n\n&lt;p&gt;I have around 20,000 rows of data in training, and 70/30 class imbalance to the positive class. Most method\u2019s addressing still wouldn\u2019t lift the model up. I did try many methods and im not sure why nothing is pulling this up.&lt;/p&gt;\n\n&lt;p&gt;I am trying to figure out what to do because i am not sure why. &lt;/p&gt;\n\n&lt;p&gt;My only explanations could be&lt;/p&gt;\n\n&lt;p&gt;1) lack of data due to how temporal data seems to be important to my model but i dont have enough longevity&lt;/p&gt;\n\n&lt;p&gt;2) i am expecting too much of my model to predict 2 months in advance&lt;/p&gt;\n\n&lt;p&gt;3) economic reasons are making the models very turbulent, i work with  interests and investments and with rate hicks predicting customer behavior is hard&lt;/p&gt;\n\n&lt;p&gt;4) the labeling of my target is not good, the labeling was built on loose rules around the database that if a sale was done or not but we don\u2019t really know for sure what happend. &lt;/p&gt;\n\n&lt;p&gt;I would really appreciate insights.&lt;/p&gt;\n\n&lt;p&gt;I checked for data leakage and everything and i really dont know what to do. I followed all the steps about stratification but still no luck.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tuk3v", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tuk3v/backtesting_vs_cross_validation_model_results_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tuk3v/backtesting_vs_cross_validation_model_results_i/", "subreddit_subscribers": 942407, "created_utc": 1688793173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Heeellooo there. Hope you're doing well.\n\nHere's my problem: I was asked to do revenue forecasting for all of our shops. Was great, 7% of MAPE over 3months. I use a \"fake\" sarimax with Fourier terms to predict seasonality (we have yearly seasonality)\n\nThen, upper management asked to do it at the each shop level. Here comes the trap : from time to time, shops must refund buyers to the extent that for that day, the data is negative. Sometimes, huuuugely negative. Of course, it kills the training. They absolutely don't mind if I'm not able to predict the negative value, in a way they want a \"smoothed\" prediction of revenu. \n\nI have some ideas but I would like to open my chakra with you :p\n\nHow would you address that ? I take every int! Let's brainstorm down there :D\n\nThks for your help, have a great weekend.", "author_fullname": "t2_bl8dhx5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series forecasting issue : negative value peak", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14txgmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688802192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heeellooo there. Hope you&amp;#39;re doing well.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my problem: I was asked to do revenue forecasting for all of our shops. Was great, 7% of MAPE over 3months. I use a &amp;quot;fake&amp;quot; sarimax with Fourier terms to predict seasonality (we have yearly seasonality)&lt;/p&gt;\n\n&lt;p&gt;Then, upper management asked to do it at the each shop level. Here comes the trap : from time to time, shops must refund buyers to the extent that for that day, the data is negative. Sometimes, huuuugely negative. Of course, it kills the training. They absolutely don&amp;#39;t mind if I&amp;#39;m not able to predict the negative value, in a way they want a &amp;quot;smoothed&amp;quot; prediction of revenu. &lt;/p&gt;\n\n&lt;p&gt;I have some ideas but I would like to open my chakra with you :p&lt;/p&gt;\n\n&lt;p&gt;How would you address that ? I take every int! Let&amp;#39;s brainstorm down there :D&lt;/p&gt;\n\n&lt;p&gt;Thks for your help, have a great weekend.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14txgmc", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal-Yak5547", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14txgmc/time_series_forecasting_issue_negative_value_peak/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14txgmc/time_series_forecasting_issue_negative_value_peak/", "subreddit_subscribers": 942407, "created_utc": 1688802192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Long story short, I worked as a data scientist in a really good organization but politics and health issues led me to quit my job by the end of March this year. I took around 2 months to recover and started my job search (note: I know that the market is really bad) last month. I have had interviews with no success at all. The interviewers ask me all sorts of questions spannning areas like data structures, basic and advanced data science, mathematics behind ML algorithms (which I am quite comfortable with), cloud platforms, SQL and databases, my work experience, generative AI (:O). Let's just say I've been rejected by companies for the following reasons.\n\n1. Company A - no experience in MLOps (but I answered their questions on statistics, ML, deep learning)\n2. Company B - less than a year experience in SQL (I worked primarily on neural networks for 7+ years, solving problems in computer vision and NLP. I did not use SQL at all).\n3. Company C - Could not reverse a linked list.\n4. Company D - No professional experience in design of experiements and A/B Testing. \n5. Company E- I have no clue !!\n\nI am just sick and tired of the interview process. It's taking a toll on my physical, mental and financial health. However, I want to be positive in these difficult times and not lose hope. \n\nTaking action is the best thing to do rather than sitting in a corner and crying about how depressing my life is. My questions are\n\n1. How do I take advantage of my unemployment and build a better portfolio/profile?\n2. What key areas in data science/ML should I focus on? The amount of time and investment required to study a single topic thoroughly is HUGE and there are tons of topics to cover. \n3. Is generative AI worth looking at? \\[I know how transformers, GANs and VAEs  work but I have no idea about the latest developments in generative AI like prompt engineering (whatever that means), Langchain, stable diffusion etc\\]. I think very few companies may actually use generative AI for their work. I could be wrong. I'm building my SQL skills and reviewing statistical inference for now. \n\n&amp;#x200B;", "author_fullname": "t2_7aj1qm5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I take advantage of my unemployment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ttowy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688790630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I worked as a data scientist in a really good organization but politics and health issues led me to quit my job by the end of March this year. I took around 2 months to recover and started my job search (note: I know that the market is really bad) last month. I have had interviews with no success at all. The interviewers ask me all sorts of questions spannning areas like data structures, basic and advanced data science, mathematics behind ML algorithms (which I am quite comfortable with), cloud platforms, SQL and databases, my work experience, generative AI (:O). Let&amp;#39;s just say I&amp;#39;ve been rejected by companies for the following reasons.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Company A - no experience in MLOps (but I answered their questions on statistics, ML, deep learning)&lt;/li&gt;\n&lt;li&gt;Company B - less than a year experience in SQL (I worked primarily on neural networks for 7+ years, solving problems in computer vision and NLP. I did not use SQL at all).&lt;/li&gt;\n&lt;li&gt;Company C - Could not reverse a linked list.&lt;/li&gt;\n&lt;li&gt;Company D - No professional experience in design of experiements and A/B Testing. &lt;/li&gt;\n&lt;li&gt;Company E- I have no clue !!&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am just sick and tired of the interview process. It&amp;#39;s taking a toll on my physical, mental and financial health. However, I want to be positive in these difficult times and not lose hope. &lt;/p&gt;\n\n&lt;p&gt;Taking action is the best thing to do rather than sitting in a corner and crying about how depressing my life is. My questions are&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How do I take advantage of my unemployment and build a better portfolio/profile?&lt;/li&gt;\n&lt;li&gt;What key areas in data science/ML should I focus on? The amount of time and investment required to study a single topic thoroughly is HUGE and there are tons of topics to cover. &lt;/li&gt;\n&lt;li&gt;Is generative AI worth looking at? [I know how transformers, GANs and VAEs  work but I have no idea about the latest developments in generative AI like prompt engineering (whatever that means), Langchain, stable diffusion etc]. I think very few companies may actually use generative AI for their work. I could be wrong. I&amp;#39;m building my SQL skills and reviewing statistical inference for now. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ttowy", "is_robot_indexable": true, "report_reasons": null, "author": "madhav1113", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ttowy/how_do_i_take_advantage_of_my_unemployment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ttowy/how_do_i_take_advantage_of_my_unemployment/", "subreddit_subscribers": 942407, "created_utc": 1688790630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to see if I can improve the performance of a basic ML model (RF and XGBoost) by training it on a tabular dataset that was synthetically extended by a GAN (CTGAN to be precise). \n\nThe notion of synthetically extending a dataset to improve machine learning performance has had some real success, mainly in computer vision application. E.g. in this paper ([https://arxiv.org/pdf/1803.01229.pdf](https://arxiv.org/pdf/1803.01229.pdf)), sensitivity increases from 78.6% to 85.7% and specificity from 88.4% to 92.4%. Applications to tabular data, though, are hard to find, and I am struggling with the intuition on why synthetic data would significantly improve ML performance.\n\nI did come across the following blogpost from synthetic data company mostly AI ([https://mostly.ai/blog/boost-machine-learning-accuracy-with-synthetic-data](https://mostly.ai/blog/boost-machine-learning-accuracy-with-synthetic-data)) where AUC increases from 91.9% to 92.8% by running an XGboost model on a synthetic set of size 1000k instead of a real set of size 10k. According to the author, the claimed improvement (which isnt too high) is due to:  \n*\"The performance of machine learning models can be in fact improved by training on synthetic data in place of the real data. This is possible as the synthetic data helps these models to learn and understand patterns by 1) providing significantly more samples than otherwise available in the original data, and by 2) providing specifically more samples of any minority classes that would otherwise remain under-represented.\"*\n\nThe AUC improvement I mentioned was on a relatively balanced dataset, so mainly the authors point 1) is of interest here. I don't know if the claim that the model 'learns to understand patterns better' is a valid one. For me, the synthetic data just adds some extra randomness to the dataset and thereby prevents overfitting. I thus see the use of synthetic data mainly as a form of regularization. Then again, the improvements in the computer vision paper are quite significant so maybe there is more going on there but I can't quite grasp what that is. In a way it sounds like alchemy, creating something out of nothing. \n\nDoes anyone have a good take on the intuition behind synthetic data and why it will or won't work?", "author_fullname": "t2_c33rcjc6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synthetically extending dataset to improve ML performance: alchemy or science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tzh6p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688808702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to see if I can improve the performance of a basic ML model (RF and XGBoost) by training it on a tabular dataset that was synthetically extended by a GAN (CTGAN to be precise). &lt;/p&gt;\n\n&lt;p&gt;The notion of synthetically extending a dataset to improve machine learning performance has had some real success, mainly in computer vision application. E.g. in this paper (&lt;a href=\"https://arxiv.org/pdf/1803.01229.pdf\"&gt;https://arxiv.org/pdf/1803.01229.pdf&lt;/a&gt;), sensitivity increases from 78.6% to 85.7% and specificity from 88.4% to 92.4%. Applications to tabular data, though, are hard to find, and I am struggling with the intuition on why synthetic data would significantly improve ML performance.&lt;/p&gt;\n\n&lt;p&gt;I did come across the following blogpost from synthetic data company mostly AI (&lt;a href=\"https://mostly.ai/blog/boost-machine-learning-accuracy-with-synthetic-data\"&gt;https://mostly.ai/blog/boost-machine-learning-accuracy-with-synthetic-data&lt;/a&gt;) where AUC increases from 91.9% to 92.8% by running an XGboost model on a synthetic set of size 1000k instead of a real set of size 10k. According to the author, the claimed improvement (which isnt too high) is due to:&lt;br/&gt;\n&lt;em&gt;&amp;quot;The performance of machine learning models can be in fact improved by training on synthetic data in place of the real data. This is possible as the synthetic data helps these models to learn and understand patterns by 1) providing significantly more samples than otherwise available in the original data, and by 2) providing specifically more samples of any minority classes that would otherwise remain under-represented.&amp;quot;&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;The AUC improvement I mentioned was on a relatively balanced dataset, so mainly the authors point 1) is of interest here. I don&amp;#39;t know if the claim that the model &amp;#39;learns to understand patterns better&amp;#39; is a valid one. For me, the synthetic data just adds some extra randomness to the dataset and thereby prevents overfitting. I thus see the use of synthetic data mainly as a form of regularization. Then again, the improvements in the computer vision paper are quite significant so maybe there is more going on there but I can&amp;#39;t quite grasp what that is. In a way it sounds like alchemy, creating something out of nothing. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have a good take on the intuition behind synthetic data and why it will or won&amp;#39;t work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tzh6p", "is_robot_indexable": true, "report_reasons": null, "author": "ProfDrGisoise", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tzh6p/synthetically_extending_dataset_to_improve_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tzh6p/synthetically_extending_dataset_to_improve_ml/", "subreddit_subscribers": 942407, "created_utc": 1688808702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Okay I'm interning for a PhD student and I'm in charge of putting the model into production (in theory). What I've gathered so far online is that the simple ways to do it is just spun up a docker container of TF Serving with the shared\\_model and serve it through a FastAPI RESTAPI app, which seems doable. What if I want to update (remove/replace) the models? I need a way to replace the container of the old model with a newer one without having to take the system down for maintenance. I know that this is achievable through K8s but it seems too complex for what I need, basically I need a load balancer/reverse proxy of some kinda that enables me to maintain multiple instances of the TF Serving container (instances of it) and also enable me to do rolling updates so that I can achieve zero down time of the model.  \n\n\nI know this sounds more like a question Infrastructure/Ops than DS/ML but I wonder what's the simplest way ML engineers or DSs can do this because eventually my internship will end and my supervisor will need to maintain everything on his own and he's purely a scientist/ML engineer/DS.", "author_fullname": "t2_raq6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serving ML models with TF Serving and FastAPI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14twnyy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688799738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay I&amp;#39;m interning for a PhD student and I&amp;#39;m in charge of putting the model into production (in theory). What I&amp;#39;ve gathered so far online is that the simple ways to do it is just spun up a docker container of TF Serving with the shared_model and serve it through a FastAPI RESTAPI app, which seems doable. What if I want to update (remove/replace) the models? I need a way to replace the container of the old model with a newer one without having to take the system down for maintenance. I know that this is achievable through K8s but it seems too complex for what I need, basically I need a load balancer/reverse proxy of some kinda that enables me to maintain multiple instances of the TF Serving container (instances of it) and also enable me to do rolling updates so that I can achieve zero down time of the model.  &lt;/p&gt;\n\n&lt;p&gt;I know this sounds more like a question Infrastructure/Ops than DS/ML but I wonder what&amp;#39;s the simplest way ML engineers or DSs can do this because eventually my internship will end and my supervisor will need to maintain everything on his own and he&amp;#39;s purely a scientist/ML engineer/DS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14twnyy", "is_robot_indexable": true, "report_reasons": null, "author": "Theboyscampus", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14twnyy/serving_ml_models_with_tf_serving_and_fastapi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14twnyy/serving_ml_models_with_tf_serving_and_fastapi/", "subreddit_subscribers": 942407, "created_utc": 1688799738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What kind of raises or incentives, if any, are you seeing from your companies? \n\nI am just trying to gauge expectations.", "author_fullname": "t2_lz0by2qo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of raises or incentives have you been seeing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tqww3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688782736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What kind of raises or incentives, if any, are you seeing from your companies? &lt;/p&gt;\n\n&lt;p&gt;I am just trying to gauge expectations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tqww3", "is_robot_indexable": true, "report_reasons": null, "author": "Firm-Engineer-9909", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tqww3/what_kind_of_raises_or_incentives_have_you_been/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tqww3/what_kind_of_raises_or_incentives_have_you_been/", "subreddit_subscribers": 942407, "created_utc": 1688782736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I love exploring the Dask library and am thrilled with its superpower computing capabilities \n\nAnyone else like it too?\n\nIf so share your fun tips and tricks please X", "author_fullname": "t2_ueb4qpts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips and tricks optimising Dask (fun question and accurate/serious answers only please)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14ugf1x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688852815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I love exploring the Dask library and am thrilled with its superpower computing capabilities &lt;/p&gt;\n\n&lt;p&gt;Anyone else like it too?&lt;/p&gt;\n\n&lt;p&gt;If so share your fun tips and tricks please X&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ugf1x", "is_robot_indexable": true, "report_reasons": null, "author": "snoo_snoozin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ugf1x/tips_and_tricks_optimising_dask_fun_question_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ugf1x/tips_and_tricks_optimising_dask_fun_question_and/", "subreddit_subscribers": 942407, "created_utc": 1688852815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We cannot use promo mix models because of wrong interpretation coming up from the model output. We are getting very high unusual roi hence not an option.", "author_fullname": "t2_d9yrvn3t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could anyone propose a proven methodology for predicting drug samples to be given to physicians in US . We have historical patient population, prescription brand writing data available with us...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14txj1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688802406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We cannot use promo mix models because of wrong interpretation coming up from the model output. We are getting very high unusual roi hence not an option.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14txj1f", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable_Emu2124", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14txj1f/could_anyone_propose_a_proven_methodology_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14txj1f/could_anyone_propose_a_proven_methodology_for/", "subreddit_subscribers": 942407, "created_utc": 1688802406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "After around two years of stopping my career in data science (PhD in Physics and postdoc) I am now looking to return. What are some online courses or books you would recommend to put me up to speed and rust me out in python and model building? While I look for a job, I'm thinking of doing some courses that could help me out in that regard. Bonus points if they are free/cheap!", "author_fullname": "t2_9fzhcwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting back into data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ts0yj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688785845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After around two years of stopping my career in data science (PhD in Physics and postdoc) I am now looking to return. What are some online courses or books you would recommend to put me up to speed and rust me out in python and model building? While I look for a job, I&amp;#39;m thinking of doing some courses that could help me out in that regard. Bonus points if they are free/cheap!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ts0yj", "is_robot_indexable": true, "report_reasons": null, "author": "tasclew", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ts0yj/getting_back_into_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ts0yj/getting_back_into_data_science/", "subreddit_subscribers": 942407, "created_utc": 1688785845.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}