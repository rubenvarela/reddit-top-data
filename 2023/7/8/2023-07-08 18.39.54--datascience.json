{"kind": "Listing", "data": {"after": null, "dist": 16, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I do have experience in the specific field I'm going to be doing data science in. However, in DS per se, I don't even have a year experience. It's a big company for which I always dreamed of working, so I'm as happy as I am terrified.\n\nCan field knowledge carry me through the job? \n\nI can't even tell what differs a senior data scientist from a junior.\n\nPlease, I need advice on what to expect (and what is going to be expected of me).", "author_fullname": "t2_uhmjjac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got hired to a senior level position. I have 7 months experience and I'm terrified.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14u4pbd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688823938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I do have experience in the specific field I&amp;#39;m going to be doing data science in. However, in DS per se, I don&amp;#39;t even have a year experience. It&amp;#39;s a big company for which I always dreamed of working, so I&amp;#39;m as happy as I am terrified.&lt;/p&gt;\n\n&lt;p&gt;Can field knowledge carry me through the job? &lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t even tell what differs a senior data scientist from a junior.&lt;/p&gt;\n\n&lt;p&gt;Please, I need advice on what to expect (and what is going to be expected of me).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14u4pbd", "is_robot_indexable": true, "report_reasons": null, "author": "bekkai", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14u4pbd/just_got_hired_to_a_senior_level_position_i_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14u4pbd/just_got_hired_to_a_senior_level_position_i_have/", "subreddit_subscribers": 942230, "created_utc": 1688823938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in a position where a company would like to hire me to do a whole swath of data projects: from dashboards, to building out databases, to predictive modelling. \n\nSo I wanted to know what y'all would charge per hour to do your current duties. I attempted to Google this, but the answers were inconclusive/far too varied.\n\nI'm estimating like $165 per hour in a major US city.", "author_fullname": "t2_769lgtz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you charge per hour?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tn0bd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688772378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in a position where a company would like to hire me to do a whole swath of data projects: from dashboards, to building out databases, to predictive modelling. &lt;/p&gt;\n\n&lt;p&gt;So I wanted to know what y&amp;#39;all would charge per hour to do your current duties. I attempted to Google this, but the answers were inconclusive/far too varied.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m estimating like $165 per hour in a major US city.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tn0bd", "is_robot_indexable": true, "report_reasons": null, "author": "FisterAct", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tn0bd/what_would_you_charge_per_hour/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tn0bd/what_would_you_charge_per_hour/", "subreddit_subscribers": 942230, "created_utc": 1688772378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working building a classification model. I have built a model and baselined it with pycaret and the results looked promising given the limited  7 months of data. Around 0.7 MCC and auc 0.92-94. \n\nI started building an actual model and the results were ok on cross-validation in general for model performance. However as I move into model backtesting the situation changes the model performs slightly better than random probability. MCC and Kappa 0.2 and auc of 0.6.\n\nI have exactly 7 months of data and I\u2019m following an expanding window back testing methodology with 2 months window of prediction due to how data is loaded.\nHowever my only issue is that given as I introduce more data the models are not developing any better. So i am not sure if its a longitudinal data.\n\n\nI have around 20,000 rows of data in training, and 70/30 class imbalance to the positive class. Most method\u2019s addressing still wouldn\u2019t lift the model up. I did try many methods and im not sure why nothing is pulling this up.\n\n\nI am trying to figure out what to do because i am not sure why. \n\nMy only explanations could be\n\n1) lack of data due to how temporal data seems to be important to my model but i dont have enough longevity\n\n2) i am expecting too much of my model to predict 2 months in advance\n \n3) economic reasons are making the models very turbulent, i work with  interests and investments and with rate hicks predicting customer behavior is hard\n\n4) the labeling of my target is not good, the labeling was built on loose rules around the database that if a sale was done or not but we don\u2019t really know for sure what happend. \n\n\nI would really appreciate insights.\n\nI checked for data leakage and everything and i really dont know what to do. I followed all the steps about stratification but still no luck.", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backtesting vs cross validation model results (I really need help)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tuk3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688793710.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688793173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working building a classification model. I have built a model and baselined it with pycaret and the results looked promising given the limited  7 months of data. Around 0.7 MCC and auc 0.92-94. &lt;/p&gt;\n\n&lt;p&gt;I started building an actual model and the results were ok on cross-validation in general for model performance. However as I move into model backtesting the situation changes the model performs slightly better than random probability. MCC and Kappa 0.2 and auc of 0.6.&lt;/p&gt;\n\n&lt;p&gt;I have exactly 7 months of data and I\u2019m following an expanding window back testing methodology with 2 months window of prediction due to how data is loaded.\nHowever my only issue is that given as I introduce more data the models are not developing any better. So i am not sure if its a longitudinal data.&lt;/p&gt;\n\n&lt;p&gt;I have around 20,000 rows of data in training, and 70/30 class imbalance to the positive class. Most method\u2019s addressing still wouldn\u2019t lift the model up. I did try many methods and im not sure why nothing is pulling this up.&lt;/p&gt;\n\n&lt;p&gt;I am trying to figure out what to do because i am not sure why. &lt;/p&gt;\n\n&lt;p&gt;My only explanations could be&lt;/p&gt;\n\n&lt;p&gt;1) lack of data due to how temporal data seems to be important to my model but i dont have enough longevity&lt;/p&gt;\n\n&lt;p&gt;2) i am expecting too much of my model to predict 2 months in advance&lt;/p&gt;\n\n&lt;p&gt;3) economic reasons are making the models very turbulent, i work with  interests and investments and with rate hicks predicting customer behavior is hard&lt;/p&gt;\n\n&lt;p&gt;4) the labeling of my target is not good, the labeling was built on loose rules around the database that if a sale was done or not but we don\u2019t really know for sure what happend. &lt;/p&gt;\n\n&lt;p&gt;I would really appreciate insights.&lt;/p&gt;\n\n&lt;p&gt;I checked for data leakage and everything and i really dont know what to do. I followed all the steps about stratification but still no luck.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tuk3v", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tuk3v/backtesting_vs_cross_validation_model_results_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tuk3v/backtesting_vs_cross_validation_model_results_i/", "subreddit_subscribers": 942230, "created_utc": 1688793173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If you made this choice once, what did you chose and why? Do you regret it?", "author_fullname": "t2_nw83t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PhD or Industry with a MSc?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tgrbr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688757925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you made this choice once, what did you chose and why? Do you regret it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tgrbr", "is_robot_indexable": true, "report_reasons": null, "author": "chacalgamer", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tgrbr/phd_or_industry_with_a_msc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tgrbr/phd_or_industry_with_a_msc/", "subreddit_subscribers": 942230, "created_utc": 1688757925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Heeellooo there. Hope you're doing well.\n\nHere's my problem: I was asked to do revenue forecasting for all of our shops. Was great, 7% of MAPE over 3months. I use a \"fake\" sarimax with Fourier terms to predict seasonality (we have yearly seasonality)\n\nThen, upper management asked to do it at the each shop level. Here comes the trap : from time to time, shops must refund buyers to the extent that for that day, the data is negative. Sometimes, huuuugely negative. Of course, it kills the training. They absolutely don't mind if I'm not able to predict the negative value, in a way they want a \"smoothed\" prediction of revenu. \n\nI have some ideas but I would like to open my chakra with you :p\n\nHow would you address that ? I take every int! Let's brainstorm down there :D\n\nThks for your help, have a great weekend.", "author_fullname": "t2_bl8dhx5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series forecasting issue : negative value peak", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14txgmc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688802192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heeellooo there. Hope you&amp;#39;re doing well.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my problem: I was asked to do revenue forecasting for all of our shops. Was great, 7% of MAPE over 3months. I use a &amp;quot;fake&amp;quot; sarimax with Fourier terms to predict seasonality (we have yearly seasonality)&lt;/p&gt;\n\n&lt;p&gt;Then, upper management asked to do it at the each shop level. Here comes the trap : from time to time, shops must refund buyers to the extent that for that day, the data is negative. Sometimes, huuuugely negative. Of course, it kills the training. They absolutely don&amp;#39;t mind if I&amp;#39;m not able to predict the negative value, in a way they want a &amp;quot;smoothed&amp;quot; prediction of revenu. &lt;/p&gt;\n\n&lt;p&gt;I have some ideas but I would like to open my chakra with you :p&lt;/p&gt;\n\n&lt;p&gt;How would you address that ? I take every int! Let&amp;#39;s brainstorm down there :D&lt;/p&gt;\n\n&lt;p&gt;Thks for your help, have a great weekend.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14txgmc", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal-Yak5547", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14txgmc/time_series_forecasting_issue_negative_value_peak/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14txgmc/time_series_forecasting_issue_negative_value_peak/", "subreddit_subscribers": 942230, "created_utc": 1688802192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Long story short, I worked as a data scientist in a really good organization but politics and health issues led me to quit my job by the end of March this year. I took around 2 months to recover and started my job search (note: I know that the market is really bad) last month. I have had interviews with no success at all. The interviewers ask me all sorts of questions spannning areas like data structures, basic and advanced data science, mathematics behind ML algorithms (which I am quite comfortable with), cloud platforms, SQL and databases, my work experience, generative AI (:O). Let's just say I've been rejected by companies for the following reasons.\n\n1. Company A - no experience in MLOps (but I answered their questions on statistics, ML, deep learning)\n2. Company B - less than a year experience in SQL (I worked primarily on neural networks for 7+ years, solving problems in computer vision and NLP. I did not use SQL at all).\n3. Company C - Could not reverse a linked list.\n4. Company D - No professional experience in design of experiements and A/B Testing. \n5. Company E- I have no clue !!\n\nI am just sick and tired of the interview process. It's taking a toll on my physical, mental and financial health. However, I want to be positive in these difficult times and not lose hope. \n\nTaking action is the best thing to do rather than sitting in a corner and crying about how depressing my life is. My questions are\n\n1. How do I take advantage of my unemployment and build a better portfolio/profile?\n2. What key areas in data science/ML should I focus on? The amount of time and investment required to study a single topic thoroughly is HUGE and there are tons of topics to cover. \n3. Is generative AI worth looking at? \\[I know how transformers, GANs and VAEs  work but I have no idea about the latest developments in generative AI like prompt engineering (whatever that means), Langchain, stable diffusion etc\\]. I think very few companies may actually use generative AI for their work. I could be wrong. I'm building my SQL skills and reviewing statistical inference for now. \n\n&amp;#x200B;", "author_fullname": "t2_7aj1qm5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I take advantage of my unemployment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ttowy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688790630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I worked as a data scientist in a really good organization but politics and health issues led me to quit my job by the end of March this year. I took around 2 months to recover and started my job search (note: I know that the market is really bad) last month. I have had interviews with no success at all. The interviewers ask me all sorts of questions spannning areas like data structures, basic and advanced data science, mathematics behind ML algorithms (which I am quite comfortable with), cloud platforms, SQL and databases, my work experience, generative AI (:O). Let&amp;#39;s just say I&amp;#39;ve been rejected by companies for the following reasons.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Company A - no experience in MLOps (but I answered their questions on statistics, ML, deep learning)&lt;/li&gt;\n&lt;li&gt;Company B - less than a year experience in SQL (I worked primarily on neural networks for 7+ years, solving problems in computer vision and NLP. I did not use SQL at all).&lt;/li&gt;\n&lt;li&gt;Company C - Could not reverse a linked list.&lt;/li&gt;\n&lt;li&gt;Company D - No professional experience in design of experiements and A/B Testing. &lt;/li&gt;\n&lt;li&gt;Company E- I have no clue !!&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am just sick and tired of the interview process. It&amp;#39;s taking a toll on my physical, mental and financial health. However, I want to be positive in these difficult times and not lose hope. &lt;/p&gt;\n\n&lt;p&gt;Taking action is the best thing to do rather than sitting in a corner and crying about how depressing my life is. My questions are&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How do I take advantage of my unemployment and build a better portfolio/profile?&lt;/li&gt;\n&lt;li&gt;What key areas in data science/ML should I focus on? The amount of time and investment required to study a single topic thoroughly is HUGE and there are tons of topics to cover. &lt;/li&gt;\n&lt;li&gt;Is generative AI worth looking at? [I know how transformers, GANs and VAEs  work but I have no idea about the latest developments in generative AI like prompt engineering (whatever that means), Langchain, stable diffusion etc]. I think very few companies may actually use generative AI for their work. I could be wrong. I&amp;#39;m building my SQL skills and reviewing statistical inference for now. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ttowy", "is_robot_indexable": true, "report_reasons": null, "author": "madhav1113", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ttowy/how_do_i_take_advantage_of_my_unemployment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ttowy/how_do_i_take_advantage_of_my_unemployment/", "subreddit_subscribers": 942230, "created_utc": 1688790630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What kind of raises or incentives, if any, are you seeing from your companies? \n\nI am just trying to gauge expectations.", "author_fullname": "t2_lz0by2qo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of raises or incentives have you been seeing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tqww3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688782736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What kind of raises or incentives, if any, are you seeing from your companies? &lt;/p&gt;\n\n&lt;p&gt;I am just trying to gauge expectations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tqww3", "is_robot_indexable": true, "report_reasons": null, "author": "Firm-Engineer-9909", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tqww3/what_kind_of_raises_or_incentives_have_you_been/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tqww3/what_kind_of_raises_or_incentives_have_you_been/", "subreddit_subscribers": 942230, "created_utc": 1688782736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to see if I can improve the performance of a basic ML model (RF and XGBoost) by training it on a tabular dataset that was synthetically extended by a GAN (CTGAN to be precise). \n\nThe notion of synthetically extending a dataset to improve machine learning performance has had some real success, mainly in computer vision application. E.g. in this paper ([https://arxiv.org/pdf/1803.01229.pdf](https://arxiv.org/pdf/1803.01229.pdf)), sensitivity increases from 78.6% to 85.7% and specificity from 88.4% to 92.4%. Applications to tabular data, though, are hard to find, and I am struggling with the intuition on why synthetic data would significantly improve ML performance.\n\nI did come across the following blogpost from synthetic data company mostly AI ([https://mostly.ai/blog/boost-machine-learning-accuracy-with-synthetic-data](https://mostly.ai/blog/boost-machine-learning-accuracy-with-synthetic-data)) where AUC increases from 91.9% to 92.8% by running an XGboost model on a synthetic set of size 1000k instead of a real set of size 10k. According to the author, the claimed improvement (which isnt too high) is due to:  \n*\"The performance of machine learning models can be in fact improved by training on synthetic data in place of the real data. This is possible as the synthetic data helps these models to learn and understand patterns by 1) providing significantly more samples than otherwise available in the original data, and by 2) providing specifically more samples of any minority classes that would otherwise remain under-represented.\"*\n\nThe AUC improvement I mentioned was on a relatively balanced dataset, so mainly the authors point 1) is of interest here. I don't know if the claim that the model 'learns to understand patterns better' is a valid one. For me, the synthetic data just adds some extra randomness to the dataset and thereby prevents overfitting. I thus see the use of synthetic data mainly as a form of regularization. Then again, the improvements in the computer vision paper are quite significant so maybe there is more going on there but I can't quite grasp what that is. In a way it sounds like alchemy, creating something out of nothing. \n\nDoes anyone have a good take on the intuition behind synthetic data and why it will or won't work?", "author_fullname": "t2_c33rcjc6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synthetically extending dataset to improve ML performance: alchemy or science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tzh6p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688808702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to see if I can improve the performance of a basic ML model (RF and XGBoost) by training it on a tabular dataset that was synthetically extended by a GAN (CTGAN to be precise). &lt;/p&gt;\n\n&lt;p&gt;The notion of synthetically extending a dataset to improve machine learning performance has had some real success, mainly in computer vision application. E.g. in this paper (&lt;a href=\"https://arxiv.org/pdf/1803.01229.pdf\"&gt;https://arxiv.org/pdf/1803.01229.pdf&lt;/a&gt;), sensitivity increases from 78.6% to 85.7% and specificity from 88.4% to 92.4%. Applications to tabular data, though, are hard to find, and I am struggling with the intuition on why synthetic data would significantly improve ML performance.&lt;/p&gt;\n\n&lt;p&gt;I did come across the following blogpost from synthetic data company mostly AI (&lt;a href=\"https://mostly.ai/blog/boost-machine-learning-accuracy-with-synthetic-data\"&gt;https://mostly.ai/blog/boost-machine-learning-accuracy-with-synthetic-data&lt;/a&gt;) where AUC increases from 91.9% to 92.8% by running an XGboost model on a synthetic set of size 1000k instead of a real set of size 10k. According to the author, the claimed improvement (which isnt too high) is due to:&lt;br/&gt;\n&lt;em&gt;&amp;quot;The performance of machine learning models can be in fact improved by training on synthetic data in place of the real data. This is possible as the synthetic data helps these models to learn and understand patterns by 1) providing significantly more samples than otherwise available in the original data, and by 2) providing specifically more samples of any minority classes that would otherwise remain under-represented.&amp;quot;&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;The AUC improvement I mentioned was on a relatively balanced dataset, so mainly the authors point 1) is of interest here. I don&amp;#39;t know if the claim that the model &amp;#39;learns to understand patterns better&amp;#39; is a valid one. For me, the synthetic data just adds some extra randomness to the dataset and thereby prevents overfitting. I thus see the use of synthetic data mainly as a form of regularization. Then again, the improvements in the computer vision paper are quite significant so maybe there is more going on there but I can&amp;#39;t quite grasp what that is. In a way it sounds like alchemy, creating something out of nothing. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have a good take on the intuition behind synthetic data and why it will or won&amp;#39;t work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tzh6p", "is_robot_indexable": true, "report_reasons": null, "author": "ProfDrGisoise", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tzh6p/synthetically_extending_dataset_to_improve_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tzh6p/synthetically_extending_dataset_to_improve_ml/", "subreddit_subscribers": 942230, "created_utc": 1688808702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Okay I'm interning for a PhD student and I'm in charge of putting the model into production (in theory). What I've gathered so far online is that the simple ways to do it is just spun up a docker container of TF Serving with the shared\\_model and serve it through a FastAPI RESTAPI app, which seems doable. What if I want to update (remove/replace) the models? I need a way to replace the container of the old model with a newer one without having to take the system down for maintenance. I know that this is achievable through K8s but it seems too complex for what I need, basically I need a load balancer/reverse proxy of some kinda that enables me to maintain multiple instances of the TF Serving container (instances of it) and also enable me to do rolling updates so that I can achieve zero down time of the model.  \n\n\nI know this sounds more like a question Infrastructure/Ops than DS/ML but I wonder what's the simplest way ML engineers or DSs can do this because eventually my internship will end and my supervisor will need to maintain everything on his own and he's purely a scientist/ML engineer/DS.", "author_fullname": "t2_raq6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serving ML models with TF Serving and FastAPI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14twnyy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688799738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay I&amp;#39;m interning for a PhD student and I&amp;#39;m in charge of putting the model into production (in theory). What I&amp;#39;ve gathered so far online is that the simple ways to do it is just spun up a docker container of TF Serving with the shared_model and serve it through a FastAPI RESTAPI app, which seems doable. What if I want to update (remove/replace) the models? I need a way to replace the container of the old model with a newer one without having to take the system down for maintenance. I know that this is achievable through K8s but it seems too complex for what I need, basically I need a load balancer/reverse proxy of some kinda that enables me to maintain multiple instances of the TF Serving container (instances of it) and also enable me to do rolling updates so that I can achieve zero down time of the model.  &lt;/p&gt;\n\n&lt;p&gt;I know this sounds more like a question Infrastructure/Ops than DS/ML but I wonder what&amp;#39;s the simplest way ML engineers or DSs can do this because eventually my internship will end and my supervisor will need to maintain everything on his own and he&amp;#39;s purely a scientist/ML engineer/DS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14twnyy", "is_robot_indexable": true, "report_reasons": null, "author": "Theboyscampus", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14twnyy/serving_ml_models_with_tf_serving_and_fastapi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14twnyy/serving_ml_models_with_tf_serving_and_fastapi/", "subreddit_subscribers": 942230, "created_utc": 1688799738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI'm using the book \"Advanced Analytics with PySpark\" to learn Spark. I'm trying to read multiple files using  spark.read.csv(\"block\\_\\*.csv\"), but it's taking a very long time and it doesn't finish.\n\nThe thing is that even with a simple dataframe, when I use the method .show() it also takes some time to run.\n\nI'm running it locally btw, with 8GB RAM, a 256GB SSD, and an i7 processor.\n\nDoes anyone know how can I resolve this issue or why this is happening?\n\nThanks in advance! ", "author_fullname": "t2_6f2do8cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark taking forever", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tjwcl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688765019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using the book &amp;quot;Advanced Analytics with PySpark&amp;quot; to learn Spark. I&amp;#39;m trying to read multiple files using  spark.read.csv(&amp;quot;block_*.csv&amp;quot;), but it&amp;#39;s taking a very long time and it doesn&amp;#39;t finish.&lt;/p&gt;\n\n&lt;p&gt;The thing is that even with a simple dataframe, when I use the method .show() it also takes some time to run.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m running it locally btw, with 8GB RAM, a 256GB SSD, and an i7 processor.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know how can I resolve this issue or why this is happening?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tjwcl", "is_robot_indexable": true, "report_reasons": null, "author": "nirvana5b", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tjwcl/pyspark_taking_forever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14tjwcl/pyspark_taking_forever/", "subreddit_subscribers": 942230, "created_utc": 1688765019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We cannot use promo mix models because of wrong interpretation coming up from the model output. We are getting very high unusual roi hence not an option.", "author_fullname": "t2_d9yrvn3t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could anyone propose a proven methodology for predicting drug samples to be given to physicians in US . We have historical patient population, prescription brand writing data available with us...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14txj1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688802406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We cannot use promo mix models because of wrong interpretation coming up from the model output. We are getting very high unusual roi hence not an option.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14txj1f", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable_Emu2124", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14txj1f/could_anyone_propose_a_proven_methodology_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14txj1f/could_anyone_propose_a_proven_methodology_for/", "subreddit_subscribers": 942230, "created_utc": 1688802406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "After around two years of stopping my career in data science (PhD in Physics and postdoc) I am now looking to return. What are some online courses or books you would recommend to put me up to speed and rust me out in python and model building? While I look for a job, I'm thinking of doing some courses that could help me out in that regard. Bonus points if they are free/cheap!", "author_fullname": "t2_9fzhcwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting back into data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ts0yj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688785845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After around two years of stopping my career in data science (PhD in Physics and postdoc) I am now looking to return. What are some online courses or books you would recommend to put me up to speed and rust me out in python and model building? While I look for a job, I&amp;#39;m thinking of doing some courses that could help me out in that regard. Bonus points if they are free/cheap!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ts0yj", "is_robot_indexable": true, "report_reasons": null, "author": "tasclew", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ts0yj/getting_back_into_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ts0yj/getting_back_into_data_science/", "subreddit_subscribers": 942230, "created_utc": 1688785845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking web traffic or marketing analytics fake data for fun projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tj6o7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_dmawn6hx", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "analytics", "selftext": "Title. Looking for some web traffic or website metrics and data to use for analytics. Click rate, conversion, how long they stayed on the website, address information, etc. Completely fictitious information. Searched on taggo and didn't really have great success but wanted to know if anyone had any of this data that they have used in the past for a fun project", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking web traffic or marketing analytics fake data for fun projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/analytics", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tj689", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688763383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.analytics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. Looking for some web traffic or website metrics and data to use for analytics. Click rate, conversion, how long they stayed on the website, address information, etc. Completely fictitious information. Searched on taggo and didn&amp;#39;t really have great success but wanted to know if anyone had any of this data that they have used in the past for a fun project&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f48f7eba-c677-11e9-b8c9-0e4f41e428f2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rhz9", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14tj689", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/analytics/comments/14tj689/seeking_web_traffic_or_marketing_analytics_fake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/analytics/comments/14tj689/seeking_web_traffic_or_marketing_analytics_fake/", "subreddit_subscribers": 136579, "created_utc": 1688763383.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1688763413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.analytics", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/analytics/comments/14tj689/seeking_web_traffic_or_marketing_analytics_fake/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tj6o7", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14tj689", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tj6o7/seeking_web_traffic_or_marketing_analytics_fake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/analytics/comments/14tj689/seeking_web_traffic_or_marketing_analytics_fake/", "subreddit_subscribers": 942230, "created_utc": 1688763413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Discussion] Looking for an Open-Source Speech to Text model (english) that captures filler words, pauses and also records timestamps for each word.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tg680", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_ekhcbstnv", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "Looking for an Open-Source Speech to Text model (english) that captures filler words, pauses and also records timestamps for each word. \n\nThe model should capture the text verbatim, without much processing. The text should include the false starts to a sentence, misspoken words, incorrect pronunciation or word form etc.\n\nThe transcript is being captured to ascertain the speaking ability of the speaker hence all this information is required.\n\nExample Transcription of Audio:  \n\n\n    Yes. One of the most important things I have is my piano because um I like playing\n    the piano. I got it from my parents to my er twelve birthday, so I have it for about\n    nine years, and the reason why it is so important for me is that I can go into\n    another world when I\u2019m playing piano. I can forget what\u2019s around me and what ...\n    I can forget my problems and this is sometimes quite good for a few minutes. Or I\n    can play to relax or just, yes to ... to relax and to think of something completely\n    different.\n\nI believe the OpenAI Whisper has support for recording timestamps. I don't want to rely on paid API service for the Speech to Text Transcription.", "author_fullname": "t2_ekhcbstnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Discussion] Looking for an Open-Source Speech to Text model (english) that captures filler words, pauses and also records timestamps for each word.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "one", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tbr3d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "cd34ef9a-6abd-11ea-a7ea-0ec6041e93a9", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688746621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for an Open-Source Speech to Text model (english) that captures filler words, pauses and also records timestamps for each word. &lt;/p&gt;\n\n&lt;p&gt;The model should capture the text verbatim, without much processing. The text should include the false starts to a sentence, misspoken words, incorrect pronunciation or word form etc.&lt;/p&gt;\n\n&lt;p&gt;The transcript is being captured to ascertain the speaking ability of the speaker hence all this information is required.&lt;/p&gt;\n\n&lt;p&gt;Example Transcription of Audio:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Yes. One of the most important things I have is my piano because um I like playing\nthe piano. I got it from my parents to my er twelve birthday, so I have it for about\nnine years, and the reason why it is so important for me is that I can go into\nanother world when I\u2019m playing piano. I can forget what\u2019s around me and what ...\nI can forget my problems and this is sometimes quite good for a few minutes. Or I\ncan play to relax or just, yes to ... to relax and to think of something completely\ndifferent.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I believe the OpenAI Whisper has support for recording timestamps. I don&amp;#39;t want to rely on paid API service for the Speech to Text Transcription.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "ML Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tbr3d", "is_robot_indexable": true, "report_reasons": null, "author": "awinml1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/MachineLearning/comments/14tbr3d/discussion_looking_for_an_opensource_speech_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MachineLearning/comments/14tbr3d/discussion_looking_for_an_opensource_speech_to/", "subreddit_subscribers": 2703427, "created_utc": 1688746621.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1688756628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/MachineLearning/comments/14tbr3d/discussion_looking_for_an_opensource_speech_to/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14tg680", "is_robot_indexable": true, "report_reasons": null, "author": "awinml1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14tbr3d", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14tg680/discussion_looking_for_an_opensource_speech_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MachineLearning/comments/14tbr3d/discussion_looking_for_an_opensource_speech_to/", "subreddit_subscribers": 942230, "created_utc": 1688756628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a data analyst and I am in a situation where my new boss is a software engineer. He is used to doing everything in a test environment, which of course is standard for applications. We also do the same for database creation and maintenance, however right now we don't use a test environment for adding views, we just directly create them in production. These views do not feed into any software applications other than standard data visualization/BI tools. Our test environment currently has limited data, but we could change that by feeding it production data. \n\nI haven't had any other data analyst job so I am unfamiliar with how things should work, but I am confused how QA testing a view would work or be valuable enough to justify the time. A view either runs or it doesn't, so there doesn't seem to be any testing required there. And other testing seems like it would be highly dependent on goal of the view being created. Testing the view as it is being created to ensure it is working as expected is important, but is going the extra step of creating test cases for each view and running it in a test environment necessary for a smaller organization? Is there something I am missing? And in general I am curious to hear how other folks ensure the views they create are working as expected.", "author_fullname": "t2_4dj20h9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question regarding QA testing views", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14terw2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688753464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data analyst and I am in a situation where my new boss is a software engineer. He is used to doing everything in a test environment, which of course is standard for applications. We also do the same for database creation and maintenance, however right now we don&amp;#39;t use a test environment for adding views, we just directly create them in production. These views do not feed into any software applications other than standard data visualization/BI tools. Our test environment currently has limited data, but we could change that by feeding it production data. &lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t had any other data analyst job so I am unfamiliar with how things should work, but I am confused how QA testing a view would work or be valuable enough to justify the time. A view either runs or it doesn&amp;#39;t, so there doesn&amp;#39;t seem to be any testing required there. And other testing seems like it would be highly dependent on goal of the view being created. Testing the view as it is being created to ensure it is working as expected is important, but is going the extra step of creating test cases for each view and running it in a test environment necessary for a smaller organization? Is there something I am missing? And in general I am curious to hear how other folks ensure the views they create are working as expected.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14terw2", "is_robot_indexable": true, "report_reasons": null, "author": "darkfor3st", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14terw2/question_regarding_qa_testing_views/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14terw2/question_regarding_qa_testing_views/", "subreddit_subscribers": 942230, "created_utc": 1688753464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to model historical bitcoin prices and predict odds it will go over amount X by date Y.\n\nI pulled data from yahoo but that one is once a day, where can I find intraday data from bitcoin trades?\n\n&amp;#x200B;\n\nI tried to pull it from coinbase (using Python)\n\n[https://docs.cloud.coinbase.com/exchange/reference/exchangerestapi\\_getproducttrades](https://docs.cloud.coinbase.com/exchange/reference/exchangerestapi_getproducttrades)\n\n    import http.client\n    import json\n    \n    conn = http.client.HTTPSConnection(\"api.exchange.coinbase.com\")\n    payload = ''\n    headers = {\n      'Content-Type': 'application/json'\n    }\n    conn.request(\"GET\", \"/products/:product_id/trades\", payload, headers)\n    res = conn.getresponse()\n    data = res.read()\n    print(data.decode(\"utf-8\"))\n\nand I got {\"message\":\"User-Agent header is required.\"}", "author_fullname": "t2_7tvt2nks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "get intraday data for bitcoin price", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14th0ni", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688758733.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688758515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to model historical bitcoin prices and predict odds it will go over amount X by date Y.&lt;/p&gt;\n\n&lt;p&gt;I pulled data from yahoo but that one is once a day, where can I find intraday data from bitcoin trades?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I tried to pull it from coinbase (using Python)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.cloud.coinbase.com/exchange/reference/exchangerestapi_getproducttrades\"&gt;https://docs.cloud.coinbase.com/exchange/reference/exchangerestapi_getproducttrades&lt;/a&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import http.client\nimport json\n\nconn = http.client.HTTPSConnection(&amp;quot;api.exchange.coinbase.com&amp;quot;)\npayload = &amp;#39;&amp;#39;\nheaders = {\n  &amp;#39;Content-Type&amp;#39;: &amp;#39;application/json&amp;#39;\n}\nconn.request(&amp;quot;GET&amp;quot;, &amp;quot;/products/:product_id/trades&amp;quot;, payload, headers)\nres = conn.getresponse()\ndata = res.read()\nprint(data.decode(&amp;quot;utf-8&amp;quot;))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;and I got {&amp;quot;message&amp;quot;:&amp;quot;User-Agent header is required.&amp;quot;}&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14th0ni", "is_robot_indexable": true, "report_reasons": null, "author": "Impossible-Ask4646", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14th0ni/get_intraday_data_for_bitcoin_price/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14th0ni/get_intraday_data_for_bitcoin_price/", "subreddit_subscribers": 942230, "created_utc": 1688758515.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}