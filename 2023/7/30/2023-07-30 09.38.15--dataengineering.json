{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5qg3y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This explains A LOT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15d1z98", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": "transparent", "ups": 249, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 249, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TtBWX7gmlaBDiDWxfgG18OJbBjB5srIFvlPxnvnH8OU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690662377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/m5tcvsl7ryeb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/m5tcvsl7ryeb1.png?auto=webp&amp;s=f7ae601aa0a27f91e9d4dbb019e079cc6dfc05fc", "width": 714, "height": 717}, "resolutions": [{"url": "https://preview.redd.it/m5tcvsl7ryeb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=594691c66aae8d504850af5afe34ac1a9364bc00", "width": 108, "height": 108}, {"url": "https://preview.redd.it/m5tcvsl7ryeb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=02c5d5e71550bdd5d8667f7c4c50d85e34ef2dcb", "width": 216, "height": 216}, {"url": "https://preview.redd.it/m5tcvsl7ryeb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=50587755f2fa2ceb837164df68d5e35c0eed09e6", "width": 320, "height": 321}, {"url": "https://preview.redd.it/m5tcvsl7ryeb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8b7dbbfa264d356ec434804355e70ac084b1d195", "width": 640, "height": 642}], "variants": {}, "id": "TdyoVxy6dqhqoqrQr6SxmdK9qX_66oG6Kk-m11aWZzQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Se\u00f1or Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15d1z98", "is_robot_indexable": true, "report_reasons": null, "author": "morpho4444", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15d1z98/this_explains_a_lot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/m5tcvsl7ryeb1.png", "subreddit_subscribers": 119092, "created_utc": 1690662377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I created a crash course of Polars library of Python and talked about data types in Polars, reading and writing operations, file handling, and powerful data manipulation techniques. I am leaving the link, have a great day!!\n\n[https://www.youtube.com/watch?v=aiHSMYvoqYE](https://www.youtube.com/watch?v=aiHSMYvoqYE)", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recorded a crash course on Polars library of Python (Great library for working with big data) and uploaded it on Youtube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cnwi1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690622900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I created a crash course of Polars library of Python and talked about data types in Polars, reading and writing operations, file handling, and powerful data manipulation techniques. I am leaving the link, have a great day!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=aiHSMYvoqYE\"&gt;https://www.youtube.com/watch?v=aiHSMYvoqYE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rIeX28O2XfIv3Y4U1OTyTkfRQORKzqxxw43Jw5vYzh4.jpg?auto=webp&amp;s=96140c2eb3acba0ac6beadc2b0fde8a7c5df9dc6", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/rIeX28O2XfIv3Y4U1OTyTkfRQORKzqxxw43Jw5vYzh4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f0cced515ca16fd65de90344f4505be38bae9be1", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/rIeX28O2XfIv3Y4U1OTyTkfRQORKzqxxw43Jw5vYzh4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e2ceb1cb25a99dab9a5756f465fc984003531baa", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/rIeX28O2XfIv3Y4U1OTyTkfRQORKzqxxw43Jw5vYzh4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a691db8960c92445122d69e8eea5a7bf8b600430", "width": 320, "height": 240}], "variants": {}, "id": "_rVKQNaxcPqL1qZYn-JkINnf7oHCvdPuQq4k6I3ej4A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15cnwi1", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cnwi1/i_recorded_a_crash_course_on_polars_library_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cnwi1/i_recorded_a_crash_course_on_polars_library_of/", "subreddit_subscribers": 119092, "created_utc": 1690622900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I placed into my junior Data Engineer role (current) through a rotational development program. \nI've never done a leetcode-style interview before and was wondering whether Data Engineering job interviews usually require this type of testing.", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is Leetcode for DE interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15d0a1c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690657978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I placed into my junior Data Engineer role (current) through a rotational development program. \nI&amp;#39;ve never done a leetcode-style interview before and was wondering whether Data Engineering job interviews usually require this type of testing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15d0a1c", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15d0a1c/how_important_is_leetcode_for_de_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15d0a1c/how_important_is_leetcode_for_de_interviews/", "subreddit_subscribers": 119092, "created_utc": 1690657978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At a recent meetup I saw guys punting AbInitio for all ETL and WH processes. Is this the way to go? I know it's got some nuances to the language, but it's got some simple looking connectors and components. Is it worth it? Connections I deal with are the normal SQL, XLS, Kafka, etc. I'm proficient in Python and SQL. Will it be tough to learn? And is it worth the effort?", "author_fullname": "t2_11t26p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AbInitio a yes or no?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cod1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690624550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At a recent meetup I saw guys punting AbInitio for all ETL and WH processes. Is this the way to go? I know it&amp;#39;s got some nuances to the language, but it&amp;#39;s got some simple looking connectors and components. Is it worth it? Connections I deal with are the normal SQL, XLS, Kafka, etc. I&amp;#39;m proficient in Python and SQL. Will it be tough to learn? And is it worth the effort?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15cod1t", "is_robot_indexable": true, "report_reasons": null, "author": "byeproduct", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cod1t/abinitio_a_yes_or_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cod1t/abinitio_a_yes_or_no/", "subreddit_subscribers": 119092, "created_utc": 1690624550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently grinding the easy-medium difficulty sql problems, and notice I need 2-3 attempts to pass all test cases because of some minor errors.\n\nI am wondering if the actual sql interview will expect an one-take pass from me, or will I have to write down the solution on a white board without any test cases?\n\nSuggestions about how to become sql proficient just like doing 1+1?", "author_fullname": "t2_csk6gf7q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does most of the SQL coding interview requires a one-take pass?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15d2nue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690664133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently grinding the easy-medium difficulty sql problems, and notice I need 2-3 attempts to pass all test cases because of some minor errors.&lt;/p&gt;\n\n&lt;p&gt;I am wondering if the actual sql interview will expect an one-take pass from me, or will I have to write down the solution on a white board without any test cases?&lt;/p&gt;\n\n&lt;p&gt;Suggestions about how to become sql proficient just like doing 1+1?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15d2nue", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Astronomer-471", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15d2nue/does_most_of_the_sql_coding_interview_requires_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15d2nue/does_most_of_the_sql_coding_interview_requires_a/", "subreddit_subscribers": 119092, "created_utc": 1690664133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We currently use Azure Data Factory to do transformations (data flows) but it's not fun. It's slow and expensive.\n\nGiven absolute freedom, what tools would you use?\n\nOur architecture looks like this: we gather data from many sources and push it to delta lake. Then we do some basic transformations and put data in delta lake folders. Then we do complex transformations using these folders as sources. We do joins etc, and we use some databases as sources to help us do transformations (like providing missing values). Finally, we sink to our databases where we store data that is displayed for users. I think we process like 10-100 GB of data everytime.\n\nBtw, I'm complete noob, backend engineer, never did any data engineering, just started recently.", "author_fullname": "t2_8kfdimyn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives for ADF", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cz9ep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690655400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We currently use Azure Data Factory to do transformations (data flows) but it&amp;#39;s not fun. It&amp;#39;s slow and expensive.&lt;/p&gt;\n\n&lt;p&gt;Given absolute freedom, what tools would you use?&lt;/p&gt;\n\n&lt;p&gt;Our architecture looks like this: we gather data from many sources and push it to delta lake. Then we do some basic transformations and put data in delta lake folders. Then we do complex transformations using these folders as sources. We do joins etc, and we use some databases as sources to help us do transformations (like providing missing values). Finally, we sink to our databases where we store data that is displayed for users. I think we process like 10-100 GB of data everytime.&lt;/p&gt;\n\n&lt;p&gt;Btw, I&amp;#39;m complete noob, backend engineer, never did any data engineering, just started recently.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15cz9ep", "is_robot_indexable": true, "report_reasons": null, "author": "Apprehensive-Lead794", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cz9ep/alternatives_for_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cz9ep/alternatives_for_adf/", "subreddit_subscribers": 119092, "created_utc": 1690655400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mhyr29t1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Command Cheatsheet - join our LinkedIn dbt Developer Group for more content: https://www.linkedin.com/groups/12857345/", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_15cwagm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/T9ndC7xcEgnI5PNA1a6L2FoWv3vek6NzvdY8AQe0vjw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690647697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/8vv2c73ijxeb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/8vv2c73ijxeb1.png?auto=webp&amp;s=b382988a0fc2b6d0737b1ec1f09522999216bffd", "width": 2245, "height": 1587}, "resolutions": [{"url": "https://preview.redd.it/8vv2c73ijxeb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b464b07b2aeb028934cb336397268bbbcd3c805b", "width": 108, "height": 76}, {"url": "https://preview.redd.it/8vv2c73ijxeb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e7c8d9abb76dfc05149b751d1806cfd5dfa66e6", "width": 216, "height": 152}, {"url": "https://preview.redd.it/8vv2c73ijxeb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=998ce771e4b0b3f6418943d8a7b6b0a3d074e59e", "width": 320, "height": 226}, {"url": "https://preview.redd.it/8vv2c73ijxeb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1c0c5d4be1284781fdc3b1b1f5a8fb9b5d661a7", "width": 640, "height": 452}, {"url": "https://preview.redd.it/8vv2c73ijxeb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f9dcc3a4c31b6fe9c0af43fe84b23859b5766456", "width": 960, "height": 678}, {"url": "https://preview.redd.it/8vv2c73ijxeb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28bf339f5fca623ad9cc8797e952d70be34fa27c", "width": 1080, "height": 763}], "variants": {}, "id": "cwaFeb5fLoKAAy7tLKh8x7IqVQx8x5I1In-ykIl19wU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15cwagm", "is_robot_indexable": true, "report_reasons": null, "author": "Datafluent", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cwagm/dbt_command_cheatsheet_join_our_linkedin_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/8vv2c73ijxeb1.png", "subreddit_subscribers": 119092, "created_utc": 1690647697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone use an open source warehouse for their solution? Something like clickhouse, Doris or Starrocks? Curious what your architecture is like? Do you load the data and raw and transform in the warehouse or transform in your storage and load final tables into the warehouse? Do you deploy in a container on a k8s cluster to manage compute? \n\nWas thinking about going the open source route and deploying in a docker container on a k8s cluster but wanted to get opinions?", "author_fullname": "t2_ffzuzn1vk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience with open source warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cr30l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690633590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone use an open source warehouse for their solution? Something like clickhouse, Doris or Starrocks? Curious what your architecture is like? Do you load the data and raw and transform in the warehouse or transform in your storage and load final tables into the warehouse? Do you deploy in a container on a k8s cluster to manage compute? &lt;/p&gt;\n\n&lt;p&gt;Was thinking about going the open source route and deploying in a docker container on a k8s cluster but wanted to get opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15cr30l", "is_robot_indexable": true, "report_reasons": null, "author": "Public_Fart42069", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cr30l/experience_with_open_source_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cr30l/experience_with_open_source_warehouse/", "subreddit_subscribers": 119092, "created_utc": 1690633590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will consume an API using Python, specifically the YouTube API, to get data from channels. It won't be a massive amount of data, maybe around 20 channels. \n\nSo, I want to store this data in a database, probably SQL. After storing this data, I'll need to perform a query to filter items with a specific string.\n\n  \nThen, I need to send the filtered data to a WordPress page where some data visualizations are present. I still need to familiarize myself with the implementation, but basically, I need to send the filtered data from the database to the WordPress front-end. \n\nWhat do you recommend for deploying this application? Considering that it's not a huge amount of data (neither in terms of data acquisition nor the site's expected traffic). \n\nI thought about using Heroku, but I'm also wondering if the free tier of AWS or GCP could handle it. Any advice? ", "author_fullname": "t2_5wo1rzy0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Python App to Fetch, Store, and Display Data - Need Advice for Deployment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cyq11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690654003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will consume an API using Python, specifically the YouTube API, to get data from channels. It won&amp;#39;t be a massive amount of data, maybe around 20 channels. &lt;/p&gt;\n\n&lt;p&gt;So, I want to store this data in a database, probably SQL. After storing this data, I&amp;#39;ll need to perform a query to filter items with a specific string.&lt;/p&gt;\n\n&lt;p&gt;Then, I need to send the filtered data to a WordPress page where some data visualizations are present. I still need to familiarize myself with the implementation, but basically, I need to send the filtered data from the database to the WordPress front-end. &lt;/p&gt;\n\n&lt;p&gt;What do you recommend for deploying this application? Considering that it&amp;#39;s not a huge amount of data (neither in terms of data acquisition nor the site&amp;#39;s expected traffic). &lt;/p&gt;\n\n&lt;p&gt;I thought about using Heroku, but I&amp;#39;m also wondering if the free tier of AWS or GCP could handle it. Any advice? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15cyq11", "is_robot_indexable": true, "report_reasons": null, "author": "interferemadly", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cyq11/building_a_python_app_to_fetch_store_and_display/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cyq11/building_a_python_app_to_fetch_store_and_display/", "subreddit_subscribers": 119092, "created_utc": 1690654003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI recently started as a DE at a software scale-up (4 weeks). It's a lot of work, especially since I'm still getting accustomed to the data model and data flows that the company has put together over the years. I notice that I'm often very tired at the end of the day, having done lots of ETL stuff within a context that is new to me. \n\nIn the weekends I feel like I need to rest, but I also have to urge (almost like an obligation) to learn new DE stuff. I spoke to me friends and family and they say that I already have a lot on my plate, because I'm still getting accustomed to a totally new DE stack. They say I need the weekend to process everything and clear my mind before I can start with the next week. \n\nSo how do you guys do it? Do you take some time in the weekend to learn new DE-related stuff? Or do you have the same feeling that you really need to rest and take your mind off of DE?", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take a rest or invest in learning new stuff", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15dgfsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690706214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I recently started as a DE at a software scale-up (4 weeks). It&amp;#39;s a lot of work, especially since I&amp;#39;m still getting accustomed to the data model and data flows that the company has put together over the years. I notice that I&amp;#39;m often very tired at the end of the day, having done lots of ETL stuff within a context that is new to me. &lt;/p&gt;\n\n&lt;p&gt;In the weekends I feel like I need to rest, but I also have to urge (almost like an obligation) to learn new DE stuff. I spoke to me friends and family and they say that I already have a lot on my plate, because I&amp;#39;m still getting accustomed to a totally new DE stack. They say I need the weekend to process everything and clear my mind before I can start with the next week. &lt;/p&gt;\n\n&lt;p&gt;So how do you guys do it? Do you take some time in the weekend to learn new DE-related stuff? Or do you have the same feeling that you really need to rest and take your mind off of DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15dgfsb", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15dgfsb/take_a_rest_or_invest_in_learning_new_stuff/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15dgfsb/take_a_rest_or_invest_in_learning_new_stuff/", "subreddit_subscribers": 119092, "created_utc": 1690706214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi team, I will start working on the GCP cloud digital leader certification. Do you have some good practice resources regarding this ?\n\n&amp;#x200B;\n\nI really appreciate any help you can provide. ", "author_fullname": "t2_7sxdmzpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP cloud digital leader resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15d9p3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690683561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi team, I will start working on the GCP cloud digital leader certification. Do you have some good practice resources regarding this ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I really appreciate any help you can provide. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15d9p3u", "is_robot_indexable": true, "report_reasons": null, "author": "felipeHernandez19", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15d9p3u/gcp_cloud_digital_leader_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15d9p3u/gcp_cloud_digital_leader_resources/", "subreddit_subscribers": 119092, "created_utc": 1690683561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm trying to figure out if what I'm doing is one job or several and if not, what the typical title is for the kind of work I'm doing.\n\nI work at a company of 700 as a \"Business Intelligence Analyst\" alongside a Data Engineer. We both report to the Head of Engineering. I was part of an acquisition of a company of 200 where I designed the entire architecture, created warehouse, ETL'd apps to it, created reporting for end users etc.\n\nWhat I typically DO is three-fold:\n\n- I grab raw data from a warehouse (snowflake) (Having advised on its ETL requirements), manipulate it into a model in Power BI, replicate the tables required to run reports off'f that model in SQL, and then get the data engineer to create that table in our warehouse. I do this for 3 different product lines (acquisitions) being folded into one.\n\n- In parallel I work with C-Suite and/or operations leads from research/sales/support/finance/Hr/half a dozen others. I gather their requirements for commissioned reports or upgrades to existing ones, create the reports in pbi, oversee the power bi workspaces and environments, advise on where to find data and what events are going to be needed.\n\n- Advise on the transfer of and maintain access to the legacy warehouse.\n\nOutput's 3-fold:\n\n- I consult on what the data Execs are looking at means\n\n- I create reports/dashboards for departments to use\n\n- I create semantic/processed data marts/sets and models for people to use\n\nThe above all feels like its a few different jobs strung together being done by one man. \n\nMy question is this: \n\nWhat'd be the different jobs I'm doing were they all done by a team? Alternatively, What would the title for the one man be? Preliminary research seems to suggest it's \"Data Analytics Engineer\" but I'm looking to second opinion that opinion.\n\nI ask because I'm considering a move to someplace less stressful/more profitable where the title's \"Architect\" and want to know what kind of roles I've held here for reference.\n\nThank you all in advance!", "author_fullname": "t2_7xr34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What am I doing? What is what I'm doing called?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15d8ie2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690679959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out if what I&amp;#39;m doing is one job or several and if not, what the typical title is for the kind of work I&amp;#39;m doing.&lt;/p&gt;\n\n&lt;p&gt;I work at a company of 700 as a &amp;quot;Business Intelligence Analyst&amp;quot; alongside a Data Engineer. We both report to the Head of Engineering. I was part of an acquisition of a company of 200 where I designed the entire architecture, created warehouse, ETL&amp;#39;d apps to it, created reporting for end users etc.&lt;/p&gt;\n\n&lt;p&gt;What I typically DO is three-fold:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I grab raw data from a warehouse (snowflake) (Having advised on its ETL requirements), manipulate it into a model in Power BI, replicate the tables required to run reports off&amp;#39;f that model in SQL, and then get the data engineer to create that table in our warehouse. I do this for 3 different product lines (acquisitions) being folded into one.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In parallel I work with C-Suite and/or operations leads from research/sales/support/finance/Hr/half a dozen others. I gather their requirements for commissioned reports or upgrades to existing ones, create the reports in pbi, oversee the power bi workspaces and environments, advise on where to find data and what events are going to be needed.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Advise on the transfer of and maintain access to the legacy warehouse.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Output&amp;#39;s 3-fold:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I consult on what the data Execs are looking at means&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I create reports/dashboards for departments to use&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I create semantic/processed data marts/sets and models for people to use&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The above all feels like its a few different jobs strung together being done by one man. &lt;/p&gt;\n\n&lt;p&gt;My question is this: &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;d be the different jobs I&amp;#39;m doing were they all done by a team? Alternatively, What would the title for the one man be? Preliminary research seems to suggest it&amp;#39;s &amp;quot;Data Analytics Engineer&amp;quot; but I&amp;#39;m looking to second opinion that opinion.&lt;/p&gt;\n\n&lt;p&gt;I ask because I&amp;#39;m considering a move to someplace less stressful/more profitable where the title&amp;#39;s &amp;quot;Architect&amp;quot; and want to know what kind of roles I&amp;#39;ve held here for reference.&lt;/p&gt;\n\n&lt;p&gt;Thank you all in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15d8ie2", "is_robot_indexable": true, "report_reasons": null, "author": "Acidwits", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15d8ie2/what_am_i_doing_what_is_what_im_doing_called/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15d8ie2/what_am_i_doing_what_is_what_im_doing_called/", "subreddit_subscribers": 119092, "created_utc": 1690679959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Grab Reduces Traffic Cost for Kafka Consumers on AWS to Zero", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15cnrhf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CHzxOlIdFai73jdps92QFmTBe2u_Muatxm35LWGgVVs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690622386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2023/07/grab-apache-kafka-aws-cost/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?auto=webp&amp;s=0215757ae25713ea844ebf251d8017ef21a46dcf", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8c4b47c1e2c2616fc7bbbd7ab15707f9527f3555", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=97432d70baea78d7c5fd7caa036cd57c55ca5fbb", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=212c8330116c5159534c69e1ffc2f844ecb2b1a2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=39eed804b9cfe931843414614801fc3d0abcce68", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa570a8e3701065aee193930e08baf55979373b5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=34802f7b3f0c815b784533832b12539e38a522b6", "width": 1080, "height": 567}], "variants": {}, "id": "aTjRY1Q9I9oaBT4jYUFfCvmgvYk6dxx7itnnM5s6qXs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15cnrhf", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cnrhf/grab_reduces_traffic_cost_for_kafka_consumers_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2023/07/grab-apache-kafka-aws-cost/", "subreddit_subscribers": 119092, "created_utc": 1690622386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am currently applying for data analyst / BI consultant positions. A friend of mine told me to present project in an interview is great to show your skills and engagement. \n\nThus I want to make a full project (pipeline + visualisation) but I do not have any idea. I already made a Spotify project to visualise my Spotify data. I'm looking for another challenge. \n\nAny ideas?\n\nThank you.", "author_fullname": "t2_dtr7r94xd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "End to end project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15dgai3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690705638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am currently applying for data analyst / BI consultant positions. A friend of mine told me to present project in an interview is great to show your skills and engagement. &lt;/p&gt;\n\n&lt;p&gt;Thus I want to make a full project (pipeline + visualisation) but I do not have any idea. I already made a Spotify project to visualise my Spotify data. I&amp;#39;m looking for another challenge. &lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15dgai3", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Finish673", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15dgai3/end_to_end_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15dgai3/end_to_end_project/", "subreddit_subscribers": 119092, "created_utc": 1690705638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am needing to maintain an enterprise data model for the company and don\u2019t want any table changes in prod unless it is approved by the architect. Since it is very easy to change DDLs with dbt, how would you do that? Make sure architect reviews all dbt code changes?  Plus I would like to start having ERDs through like sqldbm as our data documentation for users. Any recommendations?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dbt within enterprise data model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15d0lq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690658823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am needing to maintain an enterprise data model for the company and don\u2019t want any table changes in prod unless it is approved by the architect. Since it is very easy to change DDLs with dbt, how would you do that? Make sure architect reviews all dbt code changes?  Plus I would like to start having ERDs through like sqldbm as our data documentation for users. Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15d0lq0", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15d0lq0/dbt_within_enterprise_data_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15d0lq0/dbt_within_enterprise_data_model/", "subreddit_subscribers": 119092, "created_utc": 1690658823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've always wanted pipe syntax like R has in Python. Although you can chain pandas methods, there are a lot of cases where (to me) it feels clunky to write and read. There are a couple of existing packages, but I didn't feel like any of them really met my needs and preferences. \n\nIf anyone wants to give it a shot and provide feedback, I'd like to improve it. There are built in datasets and examples in the README.md. \n\nInstallation:\npip install PandaPlyr\n\nRepo:\nhttps://github.com/OlivierNDO/PandaPlyr", "author_fullname": "t2_ha2yf9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PandaPlyr - Pipe Syntax for Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cyzmw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690654694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve always wanted pipe syntax like R has in Python. Although you can chain pandas methods, there are a lot of cases where (to me) it feels clunky to write and read. There are a couple of existing packages, but I didn&amp;#39;t feel like any of them really met my needs and preferences. &lt;/p&gt;\n\n&lt;p&gt;If anyone wants to give it a shot and provide feedback, I&amp;#39;d like to improve it. There are built in datasets and examples in the README.md. &lt;/p&gt;\n\n&lt;p&gt;Installation:\npip install PandaPlyr&lt;/p&gt;\n\n&lt;p&gt;Repo:\n&lt;a href=\"https://github.com/OlivierNDO/PandaPlyr\"&gt;https://github.com/OlivierNDO/PandaPlyr&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9tpv1bN-Mmv-lOfGTgbTjKpfBO68IMmo2L638ity-wQ.jpg?auto=webp&amp;s=8546b7035066b53a89f1df263c536aeb3f1b1dbf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/9tpv1bN-Mmv-lOfGTgbTjKpfBO68IMmo2L638ity-wQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=915006049e3e4d5464953d0c8874c6b156c29b3a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/9tpv1bN-Mmv-lOfGTgbTjKpfBO68IMmo2L638ity-wQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d8382d76f28d3edc2094965533818c049b504c1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/9tpv1bN-Mmv-lOfGTgbTjKpfBO68IMmo2L638ity-wQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c53ab1dc0db39fe9ea9ef19eb28f1d6ce6d4ecd3", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/9tpv1bN-Mmv-lOfGTgbTjKpfBO68IMmo2L638ity-wQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7303b72c37111d45acbda20209c208fa1753e091", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/9tpv1bN-Mmv-lOfGTgbTjKpfBO68IMmo2L638ity-wQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b9d548933b5989fdce5db73a06cdb7c4a2a97168", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/9tpv1bN-Mmv-lOfGTgbTjKpfBO68IMmo2L638ity-wQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2b2741624c062f274093b51bdd8cefe2532ce516", "width": 1080, "height": 540}], "variants": {}, "id": "pvsmY3yQ7rSXzfsqeEaJIKih57SyVvjKAfSz4Ixezjk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15cyzmw", "is_robot_indexable": true, "report_reasons": null, "author": "HungryQuant", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cyzmw/pandaplyr_pipe_syntax_for_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cyzmw/pandaplyr_pipe_syntax_for_pandas/", "subreddit_subscribers": 119092, "created_utc": 1690654694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings, \n\nI am creating this post to discuss slowly changing dimensions of type two and implementation plans, strategies in Snowflake. \n\nExample: \n\nImagine one has a table that is being delivered nightly via Snowpipe (full-load) into the same table daily, and in the table there is an added column ETL-DATE which is of data type timestamp_ntz, and for this table one must implement a slowly changing dimension (type 2) to unlock historical analysis over time.\n\nWhat are some strategies that are used for this set up? I have read a bit about streams and tasks for SCD, but placing a stream on this table only categorizes items as all update since this is a full load with new ETL-DATE everyday the table is fully loaded. \n\nAny ideas, thoughts, or different documentation guides that you could help me point me to in the correct direction?\n\nThanks!", "author_fullname": "t2_7mwoeyyj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SCD Type 2 (Snowflake)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cyw1f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690654439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings, &lt;/p&gt;\n\n&lt;p&gt;I am creating this post to discuss slowly changing dimensions of type two and implementation plans, strategies in Snowflake. &lt;/p&gt;\n\n&lt;p&gt;Example: &lt;/p&gt;\n\n&lt;p&gt;Imagine one has a table that is being delivered nightly via Snowpipe (full-load) into the same table daily, and in the table there is an added column ETL-DATE which is of data type timestamp_ntz, and for this table one must implement a slowly changing dimension (type 2) to unlock historical analysis over time.&lt;/p&gt;\n\n&lt;p&gt;What are some strategies that are used for this set up? I have read a bit about streams and tasks for SCD, but placing a stream on this table only categorizes items as all update since this is a full load with new ETL-DATE everyday the table is fully loaded. &lt;/p&gt;\n\n&lt;p&gt;Any ideas, thoughts, or different documentation guides that you could help me point me to in the correct direction?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15cyw1f", "is_robot_indexable": true, "report_reasons": null, "author": "electronicentropy5", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cyw1f/scd_type_2_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cyw1f/scd_type_2_snowflake/", "subreddit_subscribers": 119092, "created_utc": 1690654439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The company im working in is an AWS shop now and most of our data sits in S3. My boss is seriously considering Microsoft Data Fabric after meeting with sales team. \n\nCan anyone give an opinion on using Shortcuts in Microsoft Data Fabric to connect to S3 in order to realise a data mesh architecture? Will it rack up massive egress costs from s3?", "author_fullname": "t2_mr7f2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft data fabric and working with AWS via shortcuts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15colib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690625352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The company im working in is an AWS shop now and most of our data sits in S3. My boss is seriously considering Microsoft Data Fabric after meeting with sales team. &lt;/p&gt;\n\n&lt;p&gt;Can anyone give an opinion on using Shortcuts in Microsoft Data Fabric to connect to S3 in order to realise a data mesh architecture? Will it rack up massive egress costs from s3?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15colib", "is_robot_indexable": true, "report_reasons": null, "author": "detaurus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15colib/microsoft_data_fabric_and_working_with_aws_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15colib/microsoft_data_fabric_and_working_with_aws_via/", "subreddit_subscribers": 119092, "created_utc": 1690625352.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. How would you define data products?\n2. If you are in a company, and you need to share data products with other departments or people outside the company, what would you care about?\n3. What approach is good to you for sharing data products?\n4. Do you think there is value for sharing data  products?\n5. Applying the mindset of thinking backwards. What is the ideal world to you about data and what are missing?\n\nFeel free to answer any question I came up with. Thank you!", "author_fullname": "t2_1vdngj8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about data products", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cxlfb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690651079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;How would you define data products?&lt;/li&gt;\n&lt;li&gt;If you are in a company, and you need to share data products with other departments or people outside the company, what would you care about?&lt;/li&gt;\n&lt;li&gt;What approach is good to you for sharing data products?&lt;/li&gt;\n&lt;li&gt;Do you think there is value for sharing data  products?&lt;/li&gt;\n&lt;li&gt;Applying the mindset of thinking backwards. What is the ideal world to you about data and what are missing?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Feel free to answer any question I came up with. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15cxlfb", "is_robot_indexable": true, "report_reasons": null, "author": "cyyeh", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cxlfb/questions_about_data_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cxlfb/questions_about_data_products/", "subreddit_subscribers": 119092, "created_utc": 1690651079.0, "num_crossposts": 1, "media": null, "is_video": false}}], "before": null}}