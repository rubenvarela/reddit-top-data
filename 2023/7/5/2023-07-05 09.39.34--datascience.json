{"kind": "Listing", "data": {"after": null, "dist": 15, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working for about half a year now as a junior machine learning engineer. I feel like I have gained more skills/experience making my own project than what I have in the industry.\n\nI want to stay relevant in the field and continue to progress my career and eventually move the ladder.\n\n&amp;#x200B;\n\nHow do you guys stay relevant, hone your skills and master your craft?", "author_fullname": "t2_16t67m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to stay relevant in the field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qmqj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688494781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working for about half a year now as a junior machine learning engineer. I feel like I have gained more skills/experience making my own project than what I have in the industry.&lt;/p&gt;\n\n&lt;p&gt;I want to stay relevant in the field and continue to progress my career and eventually move the ladder.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How do you guys stay relevant, hone your skills and master your craft?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qmqj2", "is_robot_indexable": true, "report_reasons": null, "author": "Mighty__hammer", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qmqj2/how_to_stay_relevant_in_the_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qmqj2/how_to_stay_relevant_in_the_field/", "subreddit_subscribers": 938673, "created_utc": 1688494781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently a newcomer learning data science and i was given a task in an assignment question to do multivariate analysis on the whole dataset. The data set that was given to me is i assumed to be a mock dataset of a food delivery service with multiple variables both numerical and categorical. The question doesn't specify what are the values i need to analyze, it just told me to do multivariate analysis to explore the relationships between the variables in that dataset. To put it simply, i think it tasked me to do multivariate EDA. However, i didn't realize how many possible combinations of potentially correlated variables the dataframe had with each other. Do i really need to do a highly detailed analysis on each possible correlation for each variable, specifying a detailed description of each relationship, or can i do a more broad and general analysis? I have to admit, I am getting really tired of doing this, not to mention my lack of expertise in using pandas in making the proper dataframe to present the data properly.", "author_fullname": "t2_32iq704k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I have to check for every single possible correlation between each variable while doing multivariate data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qad4a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688480945.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688462926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a newcomer learning data science and i was given a task in an assignment question to do multivariate analysis on the whole dataset. The data set that was given to me is i assumed to be a mock dataset of a food delivery service with multiple variables both numerical and categorical. The question doesn&amp;#39;t specify what are the values i need to analyze, it just told me to do multivariate analysis to explore the relationships between the variables in that dataset. To put it simply, i think it tasked me to do multivariate EDA. However, i didn&amp;#39;t realize how many possible combinations of potentially correlated variables the dataframe had with each other. Do i really need to do a highly detailed analysis on each possible correlation for each variable, specifying a detailed description of each relationship, or can i do a more broad and general analysis? I have to admit, I am getting really tired of doing this, not to mention my lack of expertise in using pandas in making the proper dataframe to present the data properly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qad4a", "is_robot_indexable": true, "report_reasons": null, "author": "mega_lova_nia", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qad4a/do_i_have_to_check_for_every_single_possible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qad4a/do_i_have_to_check_for_every_single_possible/", "subreddit_subscribers": 938673, "created_utc": 1688462926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have my Excel 2019 associate certificate (MO 200) and am working on the word certificate and the excel specialist certificate. Is being a report writer the best job to get before being a data analyst? Or is data entry better? I understand that it will take a lot of self learning to be a data analyst. I just want to know what is a good starting job to work while preparing to be a data analyst. Also is a report writer an entry level job or do I need to do data entry before being a report writer? Or are there other options that are equally as good or better?\n\nAlso I have an associates degree in comp sci.", "author_fullname": "t2_dwqc3c21a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best entry level job to lead up to being a data analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qx8td", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688526162.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688522287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have my Excel 2019 associate certificate (MO 200) and am working on the word certificate and the excel specialist certificate. Is being a report writer the best job to get before being a data analyst? Or is data entry better? I understand that it will take a lot of self learning to be a data analyst. I just want to know what is a good starting job to work while preparing to be a data analyst. Also is a report writer an entry level job or do I need to do data entry before being a report writer? Or are there other options that are equally as good or better?&lt;/p&gt;\n\n&lt;p&gt;Also I have an associates degree in comp sci.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qx8td", "is_robot_indexable": true, "report_reasons": null, "author": "Larrysc6", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qx8td/what_is_the_best_entry_level_job_to_lead_up_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qx8td/what_is_the_best_entry_level_job_to_lead_up_to/", "subreddit_subscribers": 938673, "created_utc": 1688522287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ebz9hcabk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best feature engineering book (in python)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qx9as", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688522327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qx9as", "is_robot_indexable": true, "report_reasons": null, "author": "cho_odama_rasengan", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qx9as/best_feature_engineering_book_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qx9as/best_feature_engineering_book_in_python/", "subreddit_subscribers": 938673, "created_utc": 1688522327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Not even sure they\u2019re anything more than Frobes hype driven FOMO for business leaders, but maybe a proper regression analysis might be an appropriate source for these thing\u2026\n\nI\u2019m tasked to declare a set of \u201cleading KPIs\u201d as a team leader in analytics. These are supposed to be  for a very specific initiative (technically a knee jerk reaction to not hitting anywhere close to where our company needs to be in terms of our annual goals for the year). \n\nBasically, they want more conversions...\n\nProblem, they have absolutely no idea how to get them\u2026\n\nIgnoring all the details, Ive agreed to provide them with some very rudimentary optimization algorithm that aims to improve marketing response rate. Let\u2019s leave it at that for now.\n\nThey want a leading KPI for this\u2026 A leading KPI\u2026 for an optimization algorithm (basically just multi armed bandit application to segmented prospect groups for specific ads on the topic of conversion). We\u2019re not even sure the ads will work, but that\u2019s another optimization problem. \n\nAs I think about this, I realize all of data science aims to eliminate the need for these \u201cleading KPIs\u201d and instead build solutions that either:\n\n* Identify \u201cleading KPIs\u201d for manual operations in the form of regression terms and coefficients\n* Do away with manual decision making all together and let algos go brrrr refining business operations automatically, doing away with the needs for a human interpretable \u201cleading KPI\u201d\n* Predict future values of time series processes that may or may not ignore other independent variables, more often just decomposing a process into its additive forms and extrapolating potential future value ranges and probability distributions for those  - like, model says 68% chance of rainfall between 1\u201d and 3\u201d over next 30 days kind of thing, do with this what you will\n\nThe entire concept of a \u201cleading KPI\u201d is very sale sand operations productivity oriented, right? Hold time for a call center leads customer satisfaction. How much wood a wood chuck can chick leads whatever wood chucks do with the wood. A roofer can lay 3 shingles per minute when he\u2019s rested and 1 per minute when he is exhausted, therefore a roof can be finished in X time given Y breaks. A sales team can produce 10 leads per hour if they wear suits and 100 per hour if they go to the bar with a group of potential clients.\n\nHow does this even translate to data science? At most, I can think of things like VPN bandwidth, data warehouse performance, training hardware specs, cloud budget, team size, WIP, ad hoc request load, interruption frequency, vintage of teams last contemporary technology training, workstation specs, etc. \n\nThe rest really depends on deployment and utilization - like the marketing team does or does not ignore model results, or advertising is fully automated so marketing team can\u2019t ignore the results.\n\nIt\u2019s not like the number of models in production is any indicator of company performance. Quality of models, maybe\u2026 But really its about what aspects of a work day contribute to a productive team that is not burdened by distractions and allowed to do their work in stable, repeatable, unbiased ways that operate on theories based on observable realities. \n\nThat\u2019s it. \n\nGive me more people with better training and experience, leave us alone, define problems well and allow us the agency of telling you if what you want is feasible and actually something that can realistically be done. Give us enough budget to build and deploy the solution. Give us people to support and maintain it. Then we monitor \u201clagging KPIs\u201d in the range of profit, revenue, expenses, and how variants model performance measures contribute to those.\n\n&amp;#x200B;\n\nUnless I\u2019m supposed to say MRSE or F1 are my \u201cleading KPIs?\u201d My perspective is that they are not and are completely dependent on if the model even gets deployed or may even dictate if the model is deployed. I can\u2019t just say, \u201coh, all these hypothetical models I might build will absolutely hit an MRSE of 0.0012345 and that will contribute to increased conversion rate.\u201d Or am I viewing this wrong? ", "author_fullname": "t2_w100sesa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The concept of \u201cLeading KPIs\u201d is not compatible with Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qvre5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688517661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not even sure they\u2019re anything more than Frobes hype driven FOMO for business leaders, but maybe a proper regression analysis might be an appropriate source for these thing\u2026&lt;/p&gt;\n\n&lt;p&gt;I\u2019m tasked to declare a set of \u201cleading KPIs\u201d as a team leader in analytics. These are supposed to be  for a very specific initiative (technically a knee jerk reaction to not hitting anywhere close to where our company needs to be in terms of our annual goals for the year). &lt;/p&gt;\n\n&lt;p&gt;Basically, they want more conversions...&lt;/p&gt;\n\n&lt;p&gt;Problem, they have absolutely no idea how to get them\u2026&lt;/p&gt;\n\n&lt;p&gt;Ignoring all the details, Ive agreed to provide them with some very rudimentary optimization algorithm that aims to improve marketing response rate. Let\u2019s leave it at that for now.&lt;/p&gt;\n\n&lt;p&gt;They want a leading KPI for this\u2026 A leading KPI\u2026 for an optimization algorithm (basically just multi armed bandit application to segmented prospect groups for specific ads on the topic of conversion). We\u2019re not even sure the ads will work, but that\u2019s another optimization problem. &lt;/p&gt;\n\n&lt;p&gt;As I think about this, I realize all of data science aims to eliminate the need for these \u201cleading KPIs\u201d and instead build solutions that either:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Identify \u201cleading KPIs\u201d for manual operations in the form of regression terms and coefficients&lt;/li&gt;\n&lt;li&gt;Do away with manual decision making all together and let algos go brrrr refining business operations automatically, doing away with the needs for a human interpretable \u201cleading KPI\u201d&lt;/li&gt;\n&lt;li&gt;Predict future values of time series processes that may or may not ignore other independent variables, more often just decomposing a process into its additive forms and extrapolating potential future value ranges and probability distributions for those  - like, model says 68% chance of rainfall between 1\u201d and 3\u201d over next 30 days kind of thing, do with this what you will&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The entire concept of a \u201cleading KPI\u201d is very sale sand operations productivity oriented, right? Hold time for a call center leads customer satisfaction. How much wood a wood chuck can chick leads whatever wood chucks do with the wood. A roofer can lay 3 shingles per minute when he\u2019s rested and 1 per minute when he is exhausted, therefore a roof can be finished in X time given Y breaks. A sales team can produce 10 leads per hour if they wear suits and 100 per hour if they go to the bar with a group of potential clients.&lt;/p&gt;\n\n&lt;p&gt;How does this even translate to data science? At most, I can think of things like VPN bandwidth, data warehouse performance, training hardware specs, cloud budget, team size, WIP, ad hoc request load, interruption frequency, vintage of teams last contemporary technology training, workstation specs, etc. &lt;/p&gt;\n\n&lt;p&gt;The rest really depends on deployment and utilization - like the marketing team does or does not ignore model results, or advertising is fully automated so marketing team can\u2019t ignore the results.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s not like the number of models in production is any indicator of company performance. Quality of models, maybe\u2026 But really its about what aspects of a work day contribute to a productive team that is not burdened by distractions and allowed to do their work in stable, repeatable, unbiased ways that operate on theories based on observable realities. &lt;/p&gt;\n\n&lt;p&gt;That\u2019s it. &lt;/p&gt;\n\n&lt;p&gt;Give me more people with better training and experience, leave us alone, define problems well and allow us the agency of telling you if what you want is feasible and actually something that can realistically be done. Give us enough budget to build and deploy the solution. Give us people to support and maintain it. Then we monitor \u201clagging KPIs\u201d in the range of profit, revenue, expenses, and how variants model performance measures contribute to those.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Unless I\u2019m supposed to say MRSE or F1 are my \u201cleading KPIs?\u201d My perspective is that they are not and are completely dependent on if the model even gets deployed or may even dictate if the model is deployed. I can\u2019t just say, \u201coh, all these hypothetical models I might build will absolutely hit an MRSE of 0.0012345 and that will contribute to increased conversion rate.\u201d Or am I viewing this wrong? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qvre5", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Sir-5932", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qvre5/the_concept_of_leading_kpis_is_not_compatible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qvre5/the_concept_of_leading_kpis_is_not_compatible/", "subreddit_subscribers": 938673, "created_utc": 1688517661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\nWe're hosting a free-to-enter, virtual hackathon, All Inclusive Hacks, focused on developing creative solutions to strengthen inclusivity in modern AI products. It will be hosted during mid to late August and we expect the prize pool to be in the range of **$200k to $300k.** We\u00a0currently in sponsorship talks with major tech corporations, including **Google, OpenAI, and Microsoft**. This is\u00a0**open to all** aged 13+ regardless of experience in programming!\n\n**Why Should You Join This Hackathon?**\n\nThis hackathon is a great opportunity to...\n\n1. Win cash and in-kind prizes!\n2. Meet peers with similar interests\n3. Improve one's resume for jobs, internships, and college or grad school admissions\n4. Improve one's grasp of artificial intelligence and its industry applications\n5. Learn from our workshops that will be hosted by leading figures in artificial intelligence\n\nParticipants are not expected to develop complex AI products or models! Rather, we expect simple more fundamental and abstract solutions that tackle some of the issues listed below:\u00a0\n\n\\- Language Preservation\n\n\\- Stereotype/Bias Identification\n\n\\- Disability Access\n\n\\- Ethics\n\n\\- Explainability\u00a0\n\n\\-\u00a0*A Relevant Issue of Your Choice!*\n\nSign Up Link: [https://all-inclusive-hacks.devpost.com/](https://all-inclusive-hacks.devpost.com/)", "author_fullname": "t2_dfcjm8gnk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Projected $200,000 in Prizes AI Hackathon (Free to Enter)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qwcj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688519445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re hosting a free-to-enter, virtual hackathon, All Inclusive Hacks, focused on developing creative solutions to strengthen inclusivity in modern AI products. It will be hosted during mid to late August and we expect the prize pool to be in the range of &lt;strong&gt;$200k to $300k.&lt;/strong&gt; We\u00a0currently in sponsorship talks with major tech corporations, including &lt;strong&gt;Google, OpenAI, and Microsoft&lt;/strong&gt;. This is\u00a0&lt;strong&gt;open to all&lt;/strong&gt; aged 13+ regardless of experience in programming!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why Should You Join This Hackathon?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This hackathon is a great opportunity to...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Win cash and in-kind prizes!&lt;/li&gt;\n&lt;li&gt;Meet peers with similar interests&lt;/li&gt;\n&lt;li&gt;Improve one&amp;#39;s resume for jobs, internships, and college or grad school admissions&lt;/li&gt;\n&lt;li&gt;Improve one&amp;#39;s grasp of artificial intelligence and its industry applications&lt;/li&gt;\n&lt;li&gt;Learn from our workshops that will be hosted by leading figures in artificial intelligence&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Participants are not expected to develop complex AI products or models! Rather, we expect simple more fundamental and abstract solutions that tackle some of the issues listed below:\u00a0&lt;/p&gt;\n\n&lt;p&gt;- Language Preservation&lt;/p&gt;\n\n&lt;p&gt;- Stereotype/Bias Identification&lt;/p&gt;\n\n&lt;p&gt;- Disability Access&lt;/p&gt;\n\n&lt;p&gt;- Ethics&lt;/p&gt;\n\n&lt;p&gt;- Explainability\u00a0&lt;/p&gt;\n\n&lt;p&gt;-\u00a0&lt;em&gt;A Relevant Issue of Your Choice!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Sign Up Link: &lt;a href=\"https://all-inclusive-hacks.devpost.com/\"&gt;https://all-inclusive-hacks.devpost.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?auto=webp&amp;v=enabled&amp;s=6704dfe78599a146e6a4116e366a624a91f5a53c", "width": 518, "height": 478}, "resolutions": [{"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=220d04d3513568acaa174bd86f214c0e2431bd80", "width": 108, "height": 99}, {"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=800259dad38ece532e00e0a47ab37d305b7a8c8b", "width": 216, "height": 199}, {"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a712b9286be9ecec816bc6f7780dd12ed3a3be8", "width": 320, "height": 295}], "variants": {}, "id": "aq3DlaWNARS2L2mhnH3TdUlfYvK4Gj48uHsY8cSiQxE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qwcj2", "is_robot_indexable": true, "report_reasons": null, "author": "AllInclusiveHacks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qwcj2/projected_200000_in_prizes_ai_hackathon_free_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qwcj2/projected_200000_in_prizes_ai_hackathon_free_to/", "subreddit_subscribers": 938673, "created_utc": 1688519445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks,  I have just started doing a data science course, though with the advancement of AI and people like Mo Gawdat talking about the implications of AI in especially programming related jobs, I wanted to ask people who have been working in this field how relevant do you think data science as a  career would be in the future?  ", "author_fullname": "t2_ajbk60r1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Relevance with AI.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r0qka", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688533390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,  I have just started doing a data science course, though with the advancement of AI and people like Mo Gawdat talking about the implications of AI in especially programming related jobs, I wanted to ask people who have been working in this field how relevant do you think data science as a  career would be in the future?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r0qka", "is_robot_indexable": true, "report_reasons": null, "author": "Leather_Depth1765", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r0qka/data_science_relevance_with_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r0qka/data_science_relevance_with_ai/", "subreddit_subscribers": 938673, "created_utc": 1688533390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nThis is my first time posting here and I'll try to keep it short. First some context, I have a bachelors degree in molecular biology, with an emphasis in data analytics. By emphasis in data analytics, I mean that we had a few semesters with optional courses, specialising in lab techniques or data analytics and I chose the latter. Im familiar with both R (preffered) and Python, as well as their corresponding packages used in data analysis, however not an expert by any means, parametric and non parametric statistics, data cleaning, visualisations (what plots are used for what combination of variables) and just a touch of ML.\n\nHowever, I have no knowledge of databases and how to work with them, I dont know SQL, nor am I familiar with Apache Spark, Tableau, power BI. I only know of data structures in theory.\n\nI applied for a data science master's degree in my uni, which is a 1.5 year program, of which 9 months will be spent on various data science courses and 6 months on a master's degree thesis. Financially speaking this is not a problem, education is free where Im from.\n\nNow I started to doubt myself, is this worth the time and effort? I checked some of the job listings and they require quite extensive knowledge of the things that I lack in, like Azure, SQL, creating data pipelines and so on, and i doubt my master's program will cover these things. Are they hard to learn? Where do I begin? Im not afraid of coding, but Im not a software engineer by trade, for who these things are likely second nature.", "author_fullname": "t2_6wtukv4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Required competencies for DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r0xhq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688534010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;This is my first time posting here and I&amp;#39;ll try to keep it short. First some context, I have a bachelors degree in molecular biology, with an emphasis in data analytics. By emphasis in data analytics, I mean that we had a few semesters with optional courses, specialising in lab techniques or data analytics and I chose the latter. Im familiar with both R (preffered) and Python, as well as their corresponding packages used in data analysis, however not an expert by any means, parametric and non parametric statistics, data cleaning, visualisations (what plots are used for what combination of variables) and just a touch of ML.&lt;/p&gt;\n\n&lt;p&gt;However, I have no knowledge of databases and how to work with them, I dont know SQL, nor am I familiar with Apache Spark, Tableau, power BI. I only know of data structures in theory.&lt;/p&gt;\n\n&lt;p&gt;I applied for a data science master&amp;#39;s degree in my uni, which is a 1.5 year program, of which 9 months will be spent on various data science courses and 6 months on a master&amp;#39;s degree thesis. Financially speaking this is not a problem, education is free where Im from.&lt;/p&gt;\n\n&lt;p&gt;Now I started to doubt myself, is this worth the time and effort? I checked some of the job listings and they require quite extensive knowledge of the things that I lack in, like Azure, SQL, creating data pipelines and so on, and i doubt my master&amp;#39;s program will cover these things. Are they hard to learn? Where do I begin? Im not afraid of coding, but Im not a software engineer by trade, for who these things are likely second nature.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r0xhq", "is_robot_indexable": true, "report_reasons": null, "author": "eatyourtoes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r0xhq/required_competencies_for_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r0xhq/required_competencies_for_ds/", "subreddit_subscribers": 938673, "created_utc": 1688534010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hey fellow Redditors!\n\nI recently wrote an article on the topic of smart manufacturing in process industries, with a focus on data analysis and Python programming. I would greatly appreciate your feedback and insights on the content.\n\n&amp;#x200B;\n\n[https://medium.com/@vishalvora\\_53246/revolutionizing-process-industries-unleashing-the-power-of-smart-manufacturing-with-data-analysis-e58984e1075c](https://medium.com/@vishalvora_53246/revolutionizing-process-industries-unleashing-the-power-of-smart-manufacturing-with-data-analysis-e58984e1075c)", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any one from process industry? need your feed back for medium article.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r05de", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688531473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors!&lt;/p&gt;\n\n&lt;p&gt;I recently wrote an article on the topic of smart manufacturing in process industries, with a focus on data analysis and Python programming. I would greatly appreciate your feedback and insights on the content.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@vishalvora_53246/revolutionizing-process-industries-unleashing-the-power-of-smart-manufacturing-with-data-analysis-e58984e1075c\"&gt;https://medium.com/@vishalvora_53246/revolutionizing-process-industries-unleashing-the-power-of-smart-manufacturing-with-data-analysis-e58984e1075c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_IKUBtxUD84NIe99qD0QsUBlPavzfFcfRZbBcgBLrHo.jpg?auto=webp&amp;v=enabled&amp;s=993ea05299fda76b3d4137d06a069a6d391bb94f", "width": 902, "height": 528}, "resolutions": [{"url": "https://external-preview.redd.it/_IKUBtxUD84NIe99qD0QsUBlPavzfFcfRZbBcgBLrHo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7b9a3cfd60871242d29cf56557a049fc792f50d", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/_IKUBtxUD84NIe99qD0QsUBlPavzfFcfRZbBcgBLrHo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91b9703aa22118c6148a4995d95fe308b33f74f0", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/_IKUBtxUD84NIe99qD0QsUBlPavzfFcfRZbBcgBLrHo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34561c11aa10539b990b188f444a00defa68ca48", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/_IKUBtxUD84NIe99qD0QsUBlPavzfFcfRZbBcgBLrHo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73295163460fb12a695d4ed03d2552fe2a0368eb", "width": 640, "height": 374}], "variants": {}, "id": "WY3eds72GQKf5PbUeBoQ3qkeTkdpo4XR0eRPwYM-QDA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r05de", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r05de/any_one_from_process_industry_need_your_feed_back/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r05de/any_one_from_process_industry_need_your_feed_back/", "subreddit_subscribers": 938673, "created_utc": 1688531473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am pursuing masters in data science from australia,  it will take around 2 years to complete.  Being an international student its important for me to get a job in IT once my course get completion.\n\nMy question is what will be the scope/ future of data scientist/ analyst in australian after 2 years.\n\nCurrently i am seeing less opportunity for in data science field in IT.", "author_fullname": "t2_er2xhtky3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future of data scientist in australia(fresher)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r056t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688531456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am pursuing masters in data science from australia,  it will take around 2 years to complete.  Being an international student its important for me to get a job in IT once my course get completion.&lt;/p&gt;\n\n&lt;p&gt;My question is what will be the scope/ future of data scientist/ analyst in australian after 2 years.&lt;/p&gt;\n\n&lt;p&gt;Currently i am seeing less opportunity for in data science field in IT.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r056t", "is_robot_indexable": true, "report_reasons": null, "author": "jaySharma_12", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r056t/future_of_data_scientist_in_australiafresher/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r056t/future_of_data_scientist_in_australiafresher/", "subreddit_subscribers": 938673, "created_utc": 1688531456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**This post is several related questions rolled into one.**\n\n**First and most simply, what is** [this kind of graph](https://www.sgmoratilla.com/static/e7ac56cc3e90327b21f79ab7d144d7c5/7468b/github-contributios-activity.png) **called?** This image was taken from GitHub, where the graph represents total GitHub participation over a given period. It breaks participation down into four areas of open source contribution, devoting one axis to each, and sums to 100%. Presumably this type of chart could be generalized to have any number of axes.\n\n**Second, I'm looking for the optimal way to visualize the aggregate results of a simple ablation study.** I'm an ML research engineer, and at work I've been working on an ablation study for publication. The study is investigating what happens when we feed non-text features into transformer models. We have 4 types of features, so not a huge number, but more than you could simply throw onto an x-y plane without careful consideration. I've trained many models combinatorically, one for each combination of features from none to all. I have the metrics for all of these models. What I need now is a good way to succinctly visualize these results graphically/geometrically, rather than just saying \"hey here's a table\" with like 200 kappas. I'd like the reader to walk away with a sense of how much each feature contributes to model performance, relative to a baseline of no non-text features. Ideas?\n\n**Third, I'm wondering if the graph type linked in my initial paragraph is one way to visualize my study's results.** As I worked with four different features, I was thinking I could have one axis per feature. Then I could simply group the performance of all my models by feature, take the mean performance across all models that use each feature, then just plot those means (I don't think normalization would achieve anything as all axes would already be on the same scale). The math of this proposal would look like this (assuming only 3 features for simplicity, and thus a 3-axis visualization, though the concept is the same):\n\n&amp;#x200B;\n\n||feature 1|feature 3|feature 3|performance|\n|:-|:-|:-|:-|:-|\n|model 1|\u2713|\u2713|\u2713|0.8|\n|model 2|\u2713|\u2713||0.5|\n|model 3|\u2713||\u2713|0.7|\n|model 4||\u2713|\u2713|0.6|\n|model 5|\u2713|||0.2|\n|model 6||\u2713||0.4|\n|model 7|||\u2713|0.1|\n\n&amp;#x200B;\n\n|feature|mean performance|\n|:-|:-|\n|feature 1|(0.8 + 0.5 + 0.7 + 0.2) / 4 = **0.550**|\n|feature 2|(0.8 + 0.5 + 0.6 + 0.4) / 4 = **0.575**|\n|feature 3|(0.8 + 0.7 + 0.6 + 0.3) / 4 = **0.600**|\n\nSo the numbers in the final column of the final table are what would be plotted. These would determine how \"pointy\" the polygon is in each axis.\n\nIs that math defensible, and would the resultant visualization effectively communicate the relative contributions of each feature to the performance of my model? I've been thinking about this since Friday including reading some other ablation studies for inspiration but it's the best I could come up with", "author_fullname": "t2_x66s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Name that chart type! Trying to visualize multidimensional ablation study results", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qyrb2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688532582.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688526968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;This post is several related questions rolled into one.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;First and most simply, what is&lt;/strong&gt; &lt;a href=\"https://www.sgmoratilla.com/static/e7ac56cc3e90327b21f79ab7d144d7c5/7468b/github-contributios-activity.png\"&gt;this kind of graph&lt;/a&gt; &lt;strong&gt;called?&lt;/strong&gt; This image was taken from GitHub, where the graph represents total GitHub participation over a given period. It breaks participation down into four areas of open source contribution, devoting one axis to each, and sums to 100%. Presumably this type of chart could be generalized to have any number of axes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Second, I&amp;#39;m looking for the optimal way to visualize the aggregate results of a simple ablation study.&lt;/strong&gt; I&amp;#39;m an ML research engineer, and at work I&amp;#39;ve been working on an ablation study for publication. The study is investigating what happens when we feed non-text features into transformer models. We have 4 types of features, so not a huge number, but more than you could simply throw onto an x-y plane without careful consideration. I&amp;#39;ve trained many models combinatorically, one for each combination of features from none to all. I have the metrics for all of these models. What I need now is a good way to succinctly visualize these results graphically/geometrically, rather than just saying &amp;quot;hey here&amp;#39;s a table&amp;quot; with like 200 kappas. I&amp;#39;d like the reader to walk away with a sense of how much each feature contributes to model performance, relative to a baseline of no non-text features. Ideas?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Third, I&amp;#39;m wondering if the graph type linked in my initial paragraph is one way to visualize my study&amp;#39;s results.&lt;/strong&gt; As I worked with four different features, I was thinking I could have one axis per feature. Then I could simply group the performance of all my models by feature, take the mean performance across all models that use each feature, then just plot those means (I don&amp;#39;t think normalization would achieve anything as all axes would already be on the same scale). The math of this proposal would look like this (assuming only 3 features for simplicity, and thus a 3-axis visualization, though the concept is the same):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;feature 1&lt;/th&gt;\n&lt;th align=\"left\"&gt;feature 3&lt;/th&gt;\n&lt;th align=\"left\"&gt;feature 3&lt;/th&gt;\n&lt;th align=\"left\"&gt;performance&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 1&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.8&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 2&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 3&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.7&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 4&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 5&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.4&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 7&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;feature&lt;/th&gt;\n&lt;th align=\"left\"&gt;mean performance&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;feature 1&lt;/td&gt;\n&lt;td align=\"left\"&gt;(0.8 + 0.5 + 0.7 + 0.2) / 4 = &lt;strong&gt;0.550&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;feature 2&lt;/td&gt;\n&lt;td align=\"left\"&gt;(0.8 + 0.5 + 0.6 + 0.4) / 4 = &lt;strong&gt;0.575&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;feature 3&lt;/td&gt;\n&lt;td align=\"left\"&gt;(0.8 + 0.7 + 0.6 + 0.3) / 4 = &lt;strong&gt;0.600&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;So the numbers in the final column of the final table are what would be plotted. These would determine how &amp;quot;pointy&amp;quot; the polygon is in each axis.&lt;/p&gt;\n\n&lt;p&gt;Is that math defensible, and would the resultant visualization effectively communicate the relative contributions of each feature to the performance of my model? I&amp;#39;ve been thinking about this since Friday including reading some other ablation studies for inspiration but it&amp;#39;s the best I could come up with&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?auto=webp&amp;v=enabled&amp;s=14e928f2e715587d4353a758b604481743a43175", "width": 1764, "height": 1406}, "resolutions": [{"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88c0922186107e6c7d22a501be157fb8871c34b3", "width": 108, "height": 86}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f2065ddd761ec458ad8406aa2249f120d7aa2ea", "width": 216, "height": 172}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05133b02c78a517b5bcc4e0974ec0dda69c35729", "width": 320, "height": 255}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ab3bcb43e1ce6df60b8a686b136aafb82e2352b", "width": 640, "height": 510}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6fb7079ed8a6fa565d1e98693609727d96ee4c7", "width": 960, "height": 765}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4b09260079681b565991faf0fe73f2f17d9eefe", "width": 1080, "height": 860}], "variants": {}, "id": "EZZn27rTOwtEKCC6oWZJvw6d58nuKqsBTCbE5DZvFdw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qyrb2", "is_robot_indexable": true, "report_reasons": null, "author": "synthphreak", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qyrb2/name_that_chart_type_trying_to_visualize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qyrb2/name_that_chart_type_trying_to_visualize/", "subreddit_subscribers": 938673, "created_utc": 1688526968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nHey! \nI'm currently building my data science portfolio and would love your feedback about it (Attached link). Your feedback will be immensely helpful as I strive to enhance my portfolio and increase my chances of landing a data science job. Futhermore, I'm on the hunt for my first data science or data analysis job, and I would greatly appreciate any advice or tips you may have to offer. If you have any insights or suggestions on how to secure my first job in the field, I would be incredibly grateful for your guidance.\n\nThank you in advance for your valuable input!", "author_fullname": "t2_t1grjisj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on Data Science Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qyhnl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1688526143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey! \nI&amp;#39;m currently building my data science portfolio and would love your feedback about it (Attached link). Your feedback will be immensely helpful as I strive to enhance my portfolio and increase my chances of landing a data science job. Futhermore, I&amp;#39;m on the hunt for my first data science or data analysis job, and I would greatly appreciate any advice or tips you may have to offer. If you have any insights or suggestions on how to secure my first job in the field, I would be incredibly grateful for your guidance.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your valuable input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/lpalfonsoa/Data-Analysis", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qyhnl", "is_robot_indexable": true, "report_reasons": null, "author": "Sae-nathra", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qyhnl/feedback_on_data_science_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/lpalfonsoa/Data-Analysis", "subreddit_subscribers": 938673, "created_utc": 1688526143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nFor a project I am doing I want to identify the top x topics/issues discussed in [r/changemyview](https://www.reddit.com/r/changemyview/). For example I may find the most common topics are\n\n1. Affirmative Action\n2. Gun Control\n3. etc ...\n\nI am familiar with using praw to retrieve post titles from the sub. What are some techniques to identify the topic/issue each post is addressing. For example in the post: \"CMV: The 2nd Amendment enables the police state, it does not protect our other rights.\" the topic is 2nd Amendment. Is the best way to do this to define several topics and classify each post into one of the pre defined topics? Another method I saw online is using \"Bag of Words\" or \"Term Frequency-Inverse Document Frequency\" both of these methods take into account the frequency and importance of a word. I am not familiar with these two methods but I was thinking I could find the most frequently occurring words to identify the most frequent topics as well.\n\nTLDR: How to parse [r/changemyview](https://www.reddit.com/r/changemyview/) in order to identify the most frequently occurring topics.", "author_fullname": "t2_jagpllod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to identify topics using r/changemyview post titles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qml8v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688494430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;For a project I am doing I want to identify the top x topics/issues discussed in &lt;a href=\"https://www.reddit.com/r/changemyview/\"&gt;r/changemyview&lt;/a&gt;. For example I may find the most common topics are&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Affirmative Action&lt;/li&gt;\n&lt;li&gt;Gun Control&lt;/li&gt;\n&lt;li&gt;etc ...&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am familiar with using praw to retrieve post titles from the sub. What are some techniques to identify the topic/issue each post is addressing. For example in the post: &amp;quot;CMV: The 2nd Amendment enables the police state, it does not protect our other rights.&amp;quot; the topic is 2nd Amendment. Is the best way to do this to define several topics and classify each post into one of the pre defined topics? Another method I saw online is using &amp;quot;Bag of Words&amp;quot; or &amp;quot;Term Frequency-Inverse Document Frequency&amp;quot; both of these methods take into account the frequency and importance of a word. I am not familiar with these two methods but I was thinking I could find the most frequently occurring words to identify the most frequent topics as well.&lt;/p&gt;\n\n&lt;p&gt;TLDR: How to parse &lt;a href=\"https://www.reddit.com/r/changemyview/\"&gt;r/changemyview&lt;/a&gt; in order to identify the most frequently occurring topics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qml8v", "is_robot_indexable": true, "report_reasons": null, "author": "JigglyBooii", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qml8v/how_to_identify_topics_using_rchangemyview_post/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qml8v/how_to_identify_topics_using_rchangemyview_post/", "subreddit_subscribers": 938673, "created_utc": 1688494430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys\n\nI am still kinda new to this data analytics industry but in a nutshell,\n\nI am working for a company and my personal project is auto populating some columns based on one column. I can't give you specifics since the information is confidential but basically, I am using description column to auto populate engine hours, model year and etc of farming equipment. For example, the description columns are usually like \"John Deere 2019, it has 1500 hours. it is in good condition, it also has Hydraulics and AC. Front dual. it has enclosed cap\" something like this. And I wrote almost all the codes that are needed for this on SQLite except that I faced an issue where I cannot use regex properly in the where clause (it does not produce the right results) and also  the instring function in SQLite does not support specifying a range of numbers. and it can only search for a specific substring within a string. But I found out that I could solve the issue by using PATINDEX function that I could not solve by using SQLite.\n\n&amp;#x200B;\n\nSo I decided to use SQL server instead and tried to find a way to automate uploading process. However, I also realized that I did not want to convert all the codes into SQL server form since it will take a long time.. I used Chat GPT and it converts a lot of stuff wrong. Also, SQL requires a little more manipulation in SQL import wizard than SQLite import function in terms of importing the csv data. I want users to be able to use the program easily. Right now, I have codes for SQLite since I solved the issue in a different way finally but I am not sure if making users to install SQLite and import and run the codes is the best way.\n\n&amp;#x200B;\n\nI thought about SSIS ETL process but I am not sure if this process is what I want.  What I want is make users to easily upload the csv data and get the data based on the algorithms on which I wrote the codes for the process of autopopulating the columns based on the one column. So I looked into visual basic studio 2019. and I also used chat gpt to figure this out. The chat gpt says that I could use [ASP.net](https://ASP.net) to allow users to easily upload the csv file and get the columns autopopulate on a website by using and inserting the SQL codes. However, certainly, I do not know how to do this specifically. I was able to make a webpage but there are multiple pages I need to fill out to make this work in the visual studio ASP project. The chat gpt does not help the specifications since the codes are usually kinda wrong.\n\n&amp;#x200B;\n\nDo any of the data scientists or analysts have suggestions how to go about this? Also, I am pretty sure what I am doing is kinda close to machine learning since I am building an algorithms for almost every case I can think of. Are there anyways that I can teach the machine to learn how to build different cases for itself so I don't have to input new codes for new patterns when a new case rises?", "author_fullname": "t2_cnor8yse9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Autopopulating program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qld2h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688493432.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688491580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys&lt;/p&gt;\n\n&lt;p&gt;I am still kinda new to this data analytics industry but in a nutshell,&lt;/p&gt;\n\n&lt;p&gt;I am working for a company and my personal project is auto populating some columns based on one column. I can&amp;#39;t give you specifics since the information is confidential but basically, I am using description column to auto populate engine hours, model year and etc of farming equipment. For example, the description columns are usually like &amp;quot;John Deere 2019, it has 1500 hours. it is in good condition, it also has Hydraulics and AC. Front dual. it has enclosed cap&amp;quot; something like this. And I wrote almost all the codes that are needed for this on SQLite except that I faced an issue where I cannot use regex properly in the where clause (it does not produce the right results) and also  the instring function in SQLite does not support specifying a range of numbers. and it can only search for a specific substring within a string. But I found out that I could solve the issue by using PATINDEX function that I could not solve by using SQLite.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I decided to use SQL server instead and tried to find a way to automate uploading process. However, I also realized that I did not want to convert all the codes into SQL server form since it will take a long time.. I used Chat GPT and it converts a lot of stuff wrong. Also, SQL requires a little more manipulation in SQL import wizard than SQLite import function in terms of importing the csv data. I want users to be able to use the program easily. Right now, I have codes for SQLite since I solved the issue in a different way finally but I am not sure if making users to install SQLite and import and run the codes is the best way.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I thought about SSIS ETL process but I am not sure if this process is what I want.  What I want is make users to easily upload the csv data and get the data based on the algorithms on which I wrote the codes for the process of autopopulating the columns based on the one column. So I looked into visual basic studio 2019. and I also used chat gpt to figure this out. The chat gpt says that I could use &lt;a href=\"https://ASP.net\"&gt;ASP.net&lt;/a&gt; to allow users to easily upload the csv file and get the columns autopopulate on a website by using and inserting the SQL codes. However, certainly, I do not know how to do this specifically. I was able to make a webpage but there are multiple pages I need to fill out to make this work in the visual studio ASP project. The chat gpt does not help the specifications since the codes are usually kinda wrong.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do any of the data scientists or analysts have suggestions how to go about this? Also, I am pretty sure what I am doing is kinda close to machine learning since I am building an algorithms for almost every case I can think of. Are there anyways that I can teach the machine to learn how to build different cases for itself so I don&amp;#39;t have to input new codes for new patterns when a new case rises?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tOcHqen1kUsOwwy69KXemKWBNWHsA4cbiSO3JrFVitg.jpg?auto=webp&amp;v=enabled&amp;s=a626a7e9d320fbdfe2116b03f85e52dc18fce2e3", "width": 238, "height": 238}, "resolutions": [{"url": "https://external-preview.redd.it/tOcHqen1kUsOwwy69KXemKWBNWHsA4cbiSO3JrFVitg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93819bfca99048541e71bba5f90386fdbbba7844", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/tOcHqen1kUsOwwy69KXemKWBNWHsA4cbiSO3JrFVitg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d43106cb2f5d8a9a58fe523b46fa1bafbfd024d", "width": 216, "height": 216}], "variants": {}, "id": "TtFVmEs53hWc_tUPscFPQzT0bv04t5CPuG5-SNnw3mo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qld2h", "is_robot_indexable": true, "report_reasons": null, "author": "Money_Working_9702", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qld2h/autopopulating_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qld2h/autopopulating_program/", "subreddit_subscribers": 938673, "created_utc": 1688491580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The future of the data science job market is very bright. The demand for data scientists is expected to grow much faster than the supply in the coming years. This is due to the increasing amount of data that is being generated, and the growing need for businesses to use this data to make better decisions.\n\n&amp;#x200B;\n\n[Data Science Grow field](https://preview.redd.it/qk7d1fo0c3ab1.jpg?width=405&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=38f61e3167d81bdbb235fd83436e4e716cc03674)\n\nAccording to the U.S. Bureau of Labor Statistics, the field of **data science is projected to grow by 22% from 2020 to 2030.** This is much faster than the average growth rate for all occupations, which is 8%.\n\nThe demand for data scientists is being driven by several factors, including:\n\n* The increasing amount of data that is being generated.\n* The growing complexity of data analysis.\n* The need for businesses to use data to make better decisions.\n* The increasing availability of data science education programs.\n\nThe supply of data scientists is not keeping pace with the demand. This is due to several factors, including:\n\n* The high skill requirements for data science jobs.\n* The lack of data science education programs.\n* The fact that many data scientists are employed by tech companies, which are not always willing to share their data with other businesses.\n\nAs a result of the growing demand and limited supply, data scientists are in high demand and can command high salaries. Data scientists are among the highest-paid professionals in the United States.\n\nIf you are interested in a career in data science, now is a great time to get started. The demand for data scientists is only going to grow in the coming years, and there are several educational programs available to help you learn the skills you need to succeed in this field.\n\n&amp;#x200B;\n\n[Digicrome Academy career tips](https://preview.redd.it/yzi2umupb3ab1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=575f1bdff9e31b857f8be3a95be37506eef71840)\n\n**Here are some tips for getting started in a career in data science:**\n\n* Get a strong foundation in statistics, machine learning, and programming.\n* Take advantage of the growing number of data science education programs.\n* Gain experience by working on data science projects.\n* Network with other data scientists.\n\nIf you are willing to put in the work, you can have a very successful career in data science.\n\n&amp;#x200B;\n\n[Digicrome Offers: Data Science Course](https://preview.redd.it/vuku6vggc3ab1.jpg?width=602&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=f08dd1c8378624da0fbaecc626995b6e08b4f8fe)\n\nIf you are interested in pursuing a course in Data Science, look no further than Digicrome! Digicrome offers the latest technology and updated tools in its 2023 curriculum. By enrolling in Digicrome, you can acquire the skills you need to excel in this field.\n\nOne of the key advantages of choosing Digicrome is their 100% job guarantee. After completing the course, you can bid farewell to job-related worries because Digicrome ensures that you land a job. Additionally, they provide internship opportunities to further enhance your practical knowledge.\n\nDon't wander elsewhere when you have the opportunity to soar high with Digicrome. Join hands with Digicrome and give your career the wings it deserves!\n\n\ud83d\udc68\u200d\ud83c\udf93 Are you interested to join our Data Science Course &amp; Training?  \nRegister here:-\u00a0[https://www.digicrome.com](https://www.digicrome.com/) ", "author_fullname": "t2_uu5voryv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the future of the data science job market in terms of supply and demand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vuku6vggc3ab1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/vuku6vggc3ab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52893014a5ab383466eef967438f974fb3e61b05"}, {"y": 76, "x": 216, "u": "https://preview.redd.it/vuku6vggc3ab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c15de54186afadddde07a83f45b10c4ca869fbcc"}, {"y": 112, "x": 320, "u": "https://preview.redd.it/vuku6vggc3ab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4173c3d88e00fa6f909c67f3153eca2ea466a6f"}], "s": {"y": 212, "x": 602, "u": "https://preview.redd.it/vuku6vggc3ab1.jpg?width=602&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=f08dd1c8378624da0fbaecc626995b6e08b4f8fe"}, "id": "vuku6vggc3ab1"}, "yzi2umupb3ab1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/yzi2umupb3ab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6cc38c194cf8a8b60d5e1146c4c8b4b7ec2f566b"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/yzi2umupb3ab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db2c1a73c2c5afe4d7aa5f65124375ff6a0754ce"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/yzi2umupb3ab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=093bddc937fdf88aeed3286808faa17453496060"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/yzi2umupb3ab1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66472cca57b28994da634e65d89f47159dbb9f07"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/yzi2umupb3ab1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=436c30f19903f715a0d12d39365e2e850dfa3e7b"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/yzi2umupb3ab1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=828d9492edf0e76dc46eba17a1efdbffa00c8b65"}], "s": {"y": 675, "x": 1200, "u": "https://preview.redd.it/yzi2umupb3ab1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=575f1bdff9e31b857f8be3a95be37506eef71840"}, "id": "yzi2umupb3ab1"}, "qk7d1fo0c3ab1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 33, "x": 108, "u": "https://preview.redd.it/qk7d1fo0c3ab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=451b998dfcd909dac60c47ff73c2b4fc3a1c644f"}, {"y": 66, "x": 216, "u": "https://preview.redd.it/qk7d1fo0c3ab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60c80f098385168e37a3d6f1bd79e05779c2a68e"}, {"y": 97, "x": 320, "u": "https://preview.redd.it/qk7d1fo0c3ab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3adebfc1767d8ee815b8b22e0d9fe3256ccf28d"}], "s": {"y": 124, "x": 405, "u": "https://preview.redd.it/qk7d1fo0c3ab1.jpg?width=405&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=38f61e3167d81bdbb235fd83436e4e716cc03674"}, "id": "qk7d1fo0c3ab1"}}, "name": "t3_14r2dxn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ew0-_V_Ms7z4yZO3Fk66LDyAyHSx6xmFMH7_Fm7_tHk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1688538942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The future of the data science job market is very bright. The demand for data scientists is expected to grow much faster than the supply in the coming years. This is due to the increasing amount of data that is being generated, and the growing need for businesses to use this data to make better decisions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qk7d1fo0c3ab1.jpg?width=405&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=38f61e3167d81bdbb235fd83436e4e716cc03674\"&gt;Data Science Grow field&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;According to the U.S. Bureau of Labor Statistics, the field of &lt;strong&gt;data science is projected to grow by 22% from 2020 to 2030.&lt;/strong&gt; This is much faster than the average growth rate for all occupations, which is 8%.&lt;/p&gt;\n\n&lt;p&gt;The demand for data scientists is being driven by several factors, including:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The increasing amount of data that is being generated.&lt;/li&gt;\n&lt;li&gt;The growing complexity of data analysis.&lt;/li&gt;\n&lt;li&gt;The need for businesses to use data to make better decisions.&lt;/li&gt;\n&lt;li&gt;The increasing availability of data science education programs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The supply of data scientists is not keeping pace with the demand. This is due to several factors, including:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The high skill requirements for data science jobs.&lt;/li&gt;\n&lt;li&gt;The lack of data science education programs.&lt;/li&gt;\n&lt;li&gt;The fact that many data scientists are employed by tech companies, which are not always willing to share their data with other businesses.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As a result of the growing demand and limited supply, data scientists are in high demand and can command high salaries. Data scientists are among the highest-paid professionals in the United States.&lt;/p&gt;\n\n&lt;p&gt;If you are interested in a career in data science, now is a great time to get started. The demand for data scientists is only going to grow in the coming years, and there are several educational programs available to help you learn the skills you need to succeed in this field.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yzi2umupb3ab1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=575f1bdff9e31b857f8be3a95be37506eef71840\"&gt;Digicrome Academy career tips&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here are some tips for getting started in a career in data science:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Get a strong foundation in statistics, machine learning, and programming.&lt;/li&gt;\n&lt;li&gt;Take advantage of the growing number of data science education programs.&lt;/li&gt;\n&lt;li&gt;Gain experience by working on data science projects.&lt;/li&gt;\n&lt;li&gt;Network with other data scientists.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you are willing to put in the work, you can have a very successful career in data science.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vuku6vggc3ab1.jpg?width=602&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f08dd1c8378624da0fbaecc626995b6e08b4f8fe\"&gt;Digicrome Offers: Data Science Course&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you are interested in pursuing a course in Data Science, look no further than Digicrome! Digicrome offers the latest technology and updated tools in its 2023 curriculum. By enrolling in Digicrome, you can acquire the skills you need to excel in this field.&lt;/p&gt;\n\n&lt;p&gt;One of the key advantages of choosing Digicrome is their 100% job guarantee. After completing the course, you can bid farewell to job-related worries because Digicrome ensures that you land a job. Additionally, they provide internship opportunities to further enhance your practical knowledge.&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t wander elsewhere when you have the opportunity to soar high with Digicrome. Join hands with Digicrome and give your career the wings it deserves!&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc68\u200d\ud83c\udf93 Are you interested to join our Data Science Course &amp;amp; Training?&lt;br/&gt;\nRegister here:-\u00a0&lt;a href=\"https://www.digicrome.com/\"&gt;https://www.digicrome.com&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nys9i8_YjBr0vZeCWvlfo_scoL22B9Fw3fzqf36ylj8.jpg?auto=webp&amp;v=enabled&amp;s=1f54ad93a4aee4bb1114cbfe1196f8cbfc6ddc27", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/Nys9i8_YjBr0vZeCWvlfo_scoL22B9Fw3fzqf36ylj8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f7a25968dc382af7943d543a0340ae685b533b2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Nys9i8_YjBr0vZeCWvlfo_scoL22B9Fw3fzqf36ylj8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f31e5f73d737d67f454e5cd79e346f8a1992aa9", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Nys9i8_YjBr0vZeCWvlfo_scoL22B9Fw3fzqf36ylj8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9eed228e5215730f8f216ded590ff2652d8c847a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Nys9i8_YjBr0vZeCWvlfo_scoL22B9Fw3fzqf36ylj8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5855f569f8e5f93df2fcc7a889f371d9bade5b3f", "width": 640, "height": 360}], "variants": {}, "id": "AQHzrMWoTF3y7T_77Z6aeGzmdFYwhGTDBc5IH7VsLeI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r2dxn", "is_robot_indexable": true, "report_reasons": null, "author": "DigicromeCompany", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r2dxn/what_is_the_future_of_the_data_science_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r2dxn/what_is_the_future_of_the_data_science_job_market/", "subreddit_subscribers": 938673, "created_utc": 1688538942.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}