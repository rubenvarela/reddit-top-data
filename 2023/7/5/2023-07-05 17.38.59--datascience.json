{"kind": "Listing", "data": {"after": "t3_14qld2h", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working for about half a year now as a junior machine learning engineer. I feel like I have gained more skills/experience making my own project than what I have in the industry.\n\nI want to stay relevant in the field and continue to progress my career and eventually move the ladder.\n\n&amp;#x200B;\n\nHow do you guys stay relevant, hone your skills and master your craft?", "author_fullname": "t2_16t67m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to stay relevant in the field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qmqj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 99, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 99, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688494781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working for about half a year now as a junior machine learning engineer. I feel like I have gained more skills/experience making my own project than what I have in the industry.&lt;/p&gt;\n\n&lt;p&gt;I want to stay relevant in the field and continue to progress my career and eventually move the ladder.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How do you guys stay relevant, hone your skills and master your craft?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qmqj2", "is_robot_indexable": true, "report_reasons": null, "author": "Mighty__hammer", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qmqj2/how_to_stay_relevant_in_the_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qmqj2/how_to_stay_relevant_in_the_field/", "subreddit_subscribers": 938971, "created_utc": 1688494781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_11vkze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An academic paper about nomadic data processors (1964) Link in comments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_14r7oge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688555564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kwctcycdq4ab1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kwctcycdq4ab1.png?auto=webp&amp;v=enabled&amp;s=65f0e8a8ea5f810f45112d79e97c9ec58db88e3c", "width": 546, "height": 369}, "resolutions": [{"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ad712a8a16b641596ef93210ef4447fdca9569d", "width": 108, "height": 72}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e16bf8b08436578518a18a99a48d40f687b24bd0", "width": 216, "height": 145}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9a8443eac162b12af36a700bca2d6c89ee6e8f0", "width": 320, "height": 216}], "variants": {"obfuscated": {"source": {"url": "https://preview.redd.it/kwctcycdq4ab1.png?blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=225232f7bca3f7ac2f8e92fa0c7b085691b7dd9e", "width": 546, "height": 369}, "resolutions": [{"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=15a7bc321b65fe5d8d669f489818ed353e23523c", "width": 108, "height": 72}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e9fa7b210f5433bf5d2674c01aaa30b0e21a37da", "width": 216, "height": 145}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=75997868d8dbc9c46ab17b6af7d151c86a0fdf87", "width": 320, "height": 216}]}, "nsfw": {"source": {"url": "https://preview.redd.it/kwctcycdq4ab1.png?blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=225232f7bca3f7ac2f8e92fa0c7b085691b7dd9e", "width": 546, "height": 369}, "resolutions": [{"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=15a7bc321b65fe5d8d669f489818ed353e23523c", "width": 108, "height": 72}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e9fa7b210f5433bf5d2674c01aaa30b0e21a37da", "width": 216, "height": 145}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=75997868d8dbc9c46ab17b6af7d151c86a0fdf87", "width": 320, "height": 216}]}}, "id": "eIo6mAbbv-KpjZ5RRFpgZLy1-qpeevCGyZArz66JUts"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r7oge", "is_robot_indexable": true, "report_reasons": null, "author": "subaculture", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r7oge/an_academic_paper_about_nomadic_data_processors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kwctcycdq4ab1.png", "subreddit_subscribers": 938971, "created_utc": 1688555564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ebz9hcabk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best feature engineering book (in python)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qx9as", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688522327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qx9as", "is_robot_indexable": true, "report_reasons": null, "author": "cho_odama_rasengan", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qx9as/best_feature_engineering_book_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qx9as/best_feature_engineering_book_in_python/", "subreddit_subscribers": 938971, "created_utc": 1688522327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks,  I have just started doing a data science course, though with the advancement of AI and people like Mo Gawdat talking about the implications of AI in especially programming related jobs, I wanted to ask people who have been working in this field how relevant do you think data science as a  career would be in the future?  ", "author_fullname": "t2_ajbk60r1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Relevance with AI.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r0qka", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688533390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,  I have just started doing a data science course, though with the advancement of AI and people like Mo Gawdat talking about the implications of AI in especially programming related jobs, I wanted to ask people who have been working in this field how relevant do you think data science as a  career would be in the future?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r0qka", "is_robot_indexable": true, "report_reasons": null, "author": "Leather_Depth1765", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r0qka/data_science_relevance_with_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r0qka/data_science_relevance_with_ai/", "subreddit_subscribers": 938971, "created_utc": 1688533390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\nWe're hosting a free-to-enter, virtual hackathon, All Inclusive Hacks, focused on developing creative solutions to strengthen inclusivity in modern AI products. It will be hosted during mid to late August and we expect the prize pool to be in the range of **$200k to $300k.** We\u00a0currently in sponsorship talks with major tech corporations, including **Google, OpenAI, and Microsoft**. This is\u00a0**open to all** aged 13+ regardless of experience in programming!\n\n**Why Should You Join This Hackathon?**\n\nThis hackathon is a great opportunity to...\n\n1. Win cash and in-kind prizes!\n2. Meet peers with similar interests\n3. Improve one's resume for jobs, internships, and college or grad school admissions\n4. Improve one's grasp of artificial intelligence and its industry applications\n5. Learn from our workshops that will be hosted by leading figures in artificial intelligence\n\nParticipants are not expected to develop complex AI products or models! Rather, we expect simple more fundamental and abstract solutions that tackle some of the issues listed below:\u00a0\n\n\\- Language Preservation\n\n\\- Stereotype/Bias Identification\n\n\\- Disability Access\n\n\\- Ethics\n\n\\- Explainability\u00a0\n\n\\-\u00a0*A Relevant Issue of Your Choice!*\n\nSign Up Link: [https://all-inclusive-hacks.devpost.com/](https://all-inclusive-hacks.devpost.com/)", "author_fullname": "t2_dfcjm8gnk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Projected $200,000 in Prizes AI Hackathon (Free to Enter)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qwcj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688519445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re hosting a free-to-enter, virtual hackathon, All Inclusive Hacks, focused on developing creative solutions to strengthen inclusivity in modern AI products. It will be hosted during mid to late August and we expect the prize pool to be in the range of &lt;strong&gt;$200k to $300k.&lt;/strong&gt; We\u00a0currently in sponsorship talks with major tech corporations, including &lt;strong&gt;Google, OpenAI, and Microsoft&lt;/strong&gt;. This is\u00a0&lt;strong&gt;open to all&lt;/strong&gt; aged 13+ regardless of experience in programming!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why Should You Join This Hackathon?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This hackathon is a great opportunity to...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Win cash and in-kind prizes!&lt;/li&gt;\n&lt;li&gt;Meet peers with similar interests&lt;/li&gt;\n&lt;li&gt;Improve one&amp;#39;s resume for jobs, internships, and college or grad school admissions&lt;/li&gt;\n&lt;li&gt;Improve one&amp;#39;s grasp of artificial intelligence and its industry applications&lt;/li&gt;\n&lt;li&gt;Learn from our workshops that will be hosted by leading figures in artificial intelligence&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Participants are not expected to develop complex AI products or models! Rather, we expect simple more fundamental and abstract solutions that tackle some of the issues listed below:\u00a0&lt;/p&gt;\n\n&lt;p&gt;- Language Preservation&lt;/p&gt;\n\n&lt;p&gt;- Stereotype/Bias Identification&lt;/p&gt;\n\n&lt;p&gt;- Disability Access&lt;/p&gt;\n\n&lt;p&gt;- Ethics&lt;/p&gt;\n\n&lt;p&gt;- Explainability\u00a0&lt;/p&gt;\n\n&lt;p&gt;-\u00a0&lt;em&gt;A Relevant Issue of Your Choice!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Sign Up Link: &lt;a href=\"https://all-inclusive-hacks.devpost.com/\"&gt;https://all-inclusive-hacks.devpost.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?auto=webp&amp;v=enabled&amp;s=6704dfe78599a146e6a4116e366a624a91f5a53c", "width": 518, "height": 478}, "resolutions": [{"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=220d04d3513568acaa174bd86f214c0e2431bd80", "width": 108, "height": 99}, {"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=800259dad38ece532e00e0a47ab37d305b7a8c8b", "width": 216, "height": 199}, {"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a712b9286be9ecec816bc6f7780dd12ed3a3be8", "width": 320, "height": 295}], "variants": {}, "id": "aq3DlaWNARS2L2mhnH3TdUlfYvK4Gj48uHsY8cSiQxE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qwcj2", "is_robot_indexable": true, "report_reasons": null, "author": "AllInclusiveHacks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qwcj2/projected_200000_in_prizes_ai_hackathon_free_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qwcj2/projected_200000_in_prizes_ai_hackathon_free_to/", "subreddit_subscribers": 938971, "created_utc": 1688519445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let\u2019s say you created a project for your company and you want to add it to your portfolio on github to showcase your skills for recruiters, how would you share it given that data is confidential?", "author_fullname": "t2_81zrh19oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you show data projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rf14j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688573211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say you created a project for your company and you want to add it to your portfolio on github to showcase your skills for recruiters, how would you share it given that data is confidential?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rf14j", "is_robot_indexable": true, "report_reasons": null, "author": "Careful_Engineer_700", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rf14j/how_do_you_show_data_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rf14j/how_do_you_show_data_projects/", "subreddit_subscribers": 938971, "created_utc": 1688573211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Not even sure they\u2019re anything more than Frobes hype driven FOMO for business leaders, but maybe a proper regression analysis might be an appropriate source for these thing\u2026\n\nI\u2019m tasked to declare a set of \u201cleading KPIs\u201d as a team leader in analytics. These are supposed to be  for a very specific initiative (technically a knee jerk reaction to not hitting anywhere close to where our company needs to be in terms of our annual goals for the year). \n\nBasically, they want more conversions...\n\nProblem, they have absolutely no idea how to get them\u2026\n\nIgnoring all the details, Ive agreed to provide them with some very rudimentary optimization algorithm that aims to improve marketing response rate. Let\u2019s leave it at that for now.\n\nThey want a leading KPI for this\u2026 A leading KPI\u2026 for an optimization algorithm (basically just multi armed bandit application to segmented prospect groups for specific ads on the topic of conversion). We\u2019re not even sure the ads will work, but that\u2019s another optimization problem. \n\nAs I think about this, I realize all of data science aims to eliminate the need for these \u201cleading KPIs\u201d and instead build solutions that either:\n\n* Identify \u201cleading KPIs\u201d for manual operations in the form of regression terms and coefficients\n* Do away with manual decision making all together and let algos go brrrr refining business operations automatically, doing away with the needs for a human interpretable \u201cleading KPI\u201d\n* Predict future values of time series processes that may or may not ignore other independent variables, more often just decomposing a process into its additive forms and extrapolating potential future value ranges and probability distributions for those  - like, model says 68% chance of rainfall between 1\u201d and 3\u201d over next 30 days kind of thing, do with this what you will\n\nThe entire concept of a \u201cleading KPI\u201d is very sale sand operations productivity oriented, right? Hold time for a call center leads customer satisfaction. How much wood a wood chuck can chick leads whatever wood chucks do with the wood. A roofer can lay 3 shingles per minute when he\u2019s rested and 1 per minute when he is exhausted, therefore a roof can be finished in X time given Y breaks. A sales team can produce 10 leads per hour if they wear suits and 100 per hour if they go to the bar with a group of potential clients.\n\nHow does this even translate to data science? At most, I can think of things like VPN bandwidth, data warehouse performance, training hardware specs, cloud budget, team size, WIP, ad hoc request load, interruption frequency, vintage of teams last contemporary technology training, workstation specs, etc. \n\nThe rest really depends on deployment and utilization - like the marketing team does or does not ignore model results, or advertising is fully automated so marketing team can\u2019t ignore the results.\n\nIt\u2019s not like the number of models in production is any indicator of company performance. Quality of models, maybe\u2026 But really its about what aspects of a work day contribute to a productive team that is not burdened by distractions and allowed to do their work in stable, repeatable, unbiased ways that operate on theories based on observable realities. \n\nThat\u2019s it. \n\nGive me more people with better training and experience, leave us alone, define problems well and allow us the agency of telling you if what you want is feasible and actually something that can realistically be done. Give us enough budget to build and deploy the solution. Give us people to support and maintain it. Then we monitor \u201clagging KPIs\u201d in the range of profit, revenue, expenses, and how variants model performance measures contribute to those.\n\n&amp;#x200B;\n\nUnless I\u2019m supposed to say MRSE or F1 are my \u201cleading KPIs?\u201d My perspective is that they are not and are completely dependent on if the model even gets deployed or may even dictate if the model is deployed. I can\u2019t just say, \u201coh, all these hypothetical models I might build will absolutely hit an MRSE of 0.0012345 and that will contribute to increased conversion rate.\u201d Or am I viewing this wrong? ", "author_fullname": "t2_w100sesa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The concept of \u201cLeading KPIs\u201d is not compatible with Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qvre5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688517661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not even sure they\u2019re anything more than Frobes hype driven FOMO for business leaders, but maybe a proper regression analysis might be an appropriate source for these thing\u2026&lt;/p&gt;\n\n&lt;p&gt;I\u2019m tasked to declare a set of \u201cleading KPIs\u201d as a team leader in analytics. These are supposed to be  for a very specific initiative (technically a knee jerk reaction to not hitting anywhere close to where our company needs to be in terms of our annual goals for the year). &lt;/p&gt;\n\n&lt;p&gt;Basically, they want more conversions...&lt;/p&gt;\n\n&lt;p&gt;Problem, they have absolutely no idea how to get them\u2026&lt;/p&gt;\n\n&lt;p&gt;Ignoring all the details, Ive agreed to provide them with some very rudimentary optimization algorithm that aims to improve marketing response rate. Let\u2019s leave it at that for now.&lt;/p&gt;\n\n&lt;p&gt;They want a leading KPI for this\u2026 A leading KPI\u2026 for an optimization algorithm (basically just multi armed bandit application to segmented prospect groups for specific ads on the topic of conversion). We\u2019re not even sure the ads will work, but that\u2019s another optimization problem. &lt;/p&gt;\n\n&lt;p&gt;As I think about this, I realize all of data science aims to eliminate the need for these \u201cleading KPIs\u201d and instead build solutions that either:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Identify \u201cleading KPIs\u201d for manual operations in the form of regression terms and coefficients&lt;/li&gt;\n&lt;li&gt;Do away with manual decision making all together and let algos go brrrr refining business operations automatically, doing away with the needs for a human interpretable \u201cleading KPI\u201d&lt;/li&gt;\n&lt;li&gt;Predict future values of time series processes that may or may not ignore other independent variables, more often just decomposing a process into its additive forms and extrapolating potential future value ranges and probability distributions for those  - like, model says 68% chance of rainfall between 1\u201d and 3\u201d over next 30 days kind of thing, do with this what you will&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The entire concept of a \u201cleading KPI\u201d is very sale sand operations productivity oriented, right? Hold time for a call center leads customer satisfaction. How much wood a wood chuck can chick leads whatever wood chucks do with the wood. A roofer can lay 3 shingles per minute when he\u2019s rested and 1 per minute when he is exhausted, therefore a roof can be finished in X time given Y breaks. A sales team can produce 10 leads per hour if they wear suits and 100 per hour if they go to the bar with a group of potential clients.&lt;/p&gt;\n\n&lt;p&gt;How does this even translate to data science? At most, I can think of things like VPN bandwidth, data warehouse performance, training hardware specs, cloud budget, team size, WIP, ad hoc request load, interruption frequency, vintage of teams last contemporary technology training, workstation specs, etc. &lt;/p&gt;\n\n&lt;p&gt;The rest really depends on deployment and utilization - like the marketing team does or does not ignore model results, or advertising is fully automated so marketing team can\u2019t ignore the results.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s not like the number of models in production is any indicator of company performance. Quality of models, maybe\u2026 But really its about what aspects of a work day contribute to a productive team that is not burdened by distractions and allowed to do their work in stable, repeatable, unbiased ways that operate on theories based on observable realities. &lt;/p&gt;\n\n&lt;p&gt;That\u2019s it. &lt;/p&gt;\n\n&lt;p&gt;Give me more people with better training and experience, leave us alone, define problems well and allow us the agency of telling you if what you want is feasible and actually something that can realistically be done. Give us enough budget to build and deploy the solution. Give us people to support and maintain it. Then we monitor \u201clagging KPIs\u201d in the range of profit, revenue, expenses, and how variants model performance measures contribute to those.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Unless I\u2019m supposed to say MRSE or F1 are my \u201cleading KPIs?\u201d My perspective is that they are not and are completely dependent on if the model even gets deployed or may even dictate if the model is deployed. I can\u2019t just say, \u201coh, all these hypothetical models I might build will absolutely hit an MRSE of 0.0012345 and that will contribute to increased conversion rate.\u201d Or am I viewing this wrong? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qvre5", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Sir-5932", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qvre5/the_concept_of_leading_kpis_is_not_compatible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qvre5/the_concept_of_leading_kpis_is_not_compatible/", "subreddit_subscribers": 938971, "created_utc": 1688517661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have no biology background. But I look at this task and think to myself, this could use a spectral embedding technique like Laplacian Eigen-maps. Or any other technique (we've all seen the famous examples in scikit-learn to unroll the rainbow \"swiss roll\"). Has anyone else done this, and can they comment on the success of it.", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spectral Embedding for protein (un)-folding?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14reu8w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688572828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have no biology background. But I look at this task and think to myself, this could use a spectral embedding technique like Laplacian Eigen-maps. Or any other technique (we&amp;#39;ve all seen the famous examples in scikit-learn to unroll the rainbow &amp;quot;swiss roll&amp;quot;). Has anyone else done this, and can they comment on the success of it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14reu8w", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14reu8w/spectral_embedding_for_protein_unfolding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14reu8w/spectral_embedding_for_protein_unfolding/", "subreddit_subscribers": 938971, "created_utc": 1688572828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For some background, I have a bachelor degree with a major in data science and AI, where I learn everything from math/stats fundamentals, visualisation, data structures, data wrangling, classical ML models, to deep learning stuff. I also had a pretty long internship at a company where I worked on a computer vision project.\n\nHowever from my job search and application experience, I've never heard back from any AI/ML/data science positions. Fortunately, I also applied for data engineer and software engineer roles which I thought I was less qualified for but had more success with in the end. Here's a breakdown of my 129 applications:\n\n&gt; - AI/ML engineer: 20 applied (0 interview opportunity)\n\n&gt; - Data scientist: 17 applied (0 interview opportunity)\n\n&gt; - Data analyst: 28 applied (2 interview opportunities/7%)\n\n&gt; - Data engineer: 17 applied (3 interview opportunities/18%)\n\n&gt; - Software engineer: 47 applied (6 interview opportunities/13%)\n\n&gt; - Total: 129 applied (11 interview opportunities/9%)\n\nI only applied for postings where I had at least some chance which means skipping past many DS/ML jobs which require at least a masters/PHD/&gt;3 years experience.\n\nIs the field of AI/ML/DS that bleak? I chose a data science and AI major because people told me that AI/data is going to be the future and where all the demand will be at. I was told CS/SWE is going to be oversaturated and finding a job in software engineering will be difficult.\n\nI accepted a software engineer offer in the end and can't help but feel that I would have been better off getting a CS degree in university so that I'm more competitive for SWE jobs.", "author_fullname": "t2_csdkjjuj5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there way more opportunities in software engineering than the AI/data science field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rd5us", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688569293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For some background, I have a bachelor degree with a major in data science and AI, where I learn everything from math/stats fundamentals, visualisation, data structures, data wrangling, classical ML models, to deep learning stuff. I also had a pretty long internship at a company where I worked on a computer vision project.&lt;/p&gt;\n\n&lt;p&gt;However from my job search and application experience, I&amp;#39;ve never heard back from any AI/ML/data science positions. Fortunately, I also applied for data engineer and software engineer roles which I thought I was less qualified for but had more success with in the end. Here&amp;#39;s a breakdown of my 129 applications:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;AI/ML engineer: 20 applied (0 interview opportunity)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data scientist: 17 applied (0 interview opportunity)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data analyst: 28 applied (2 interview opportunities/7%)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data engineer: 17 applied (3 interview opportunities/18%)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Software engineer: 47 applied (6 interview opportunities/13%)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Total: 129 applied (11 interview opportunities/9%)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I only applied for postings where I had at least some chance which means skipping past many DS/ML jobs which require at least a masters/PHD/&amp;gt;3 years experience.&lt;/p&gt;\n\n&lt;p&gt;Is the field of AI/ML/DS that bleak? I chose a data science and AI major because people told me that AI/data is going to be the future and where all the demand will be at. I was told CS/SWE is going to be oversaturated and finding a job in software engineering will be difficult.&lt;/p&gt;\n\n&lt;p&gt;I accepted a software engineer offer in the end and can&amp;#39;t help but feel that I would have been better off getting a CS degree in university so that I&amp;#39;m more competitive for SWE jobs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rd5us", "is_robot_indexable": true, "report_reasons": null, "author": "ballotlunch", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rd5us/are_there_way_more_opportunities_in_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rd5us/are_there_way_more_opportunities_in_software/", "subreddit_subscribers": 938971, "created_utc": 1688569293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I am building an open-source LLM evaluation toolkit to help ensures your LLM applications are performing reliably by checking their responses on aspects such as correctness, structural integrity, bias, hallucination, etc.\n\nIt can be used to:\n\n1. Validate the model's response and safeguard your users against incorrect outputs.\n2. Experiment across multiple model providers, prompt templates, and make correct choices by quantifying the model's performance.\n3. Monitor your model's performance in production and protect yourself against unwanted drifts due to model updates or changing user behaviors\n\nYou can check out the project -\u00a0[https://github.com/uptrain-ai/uptrain](https://github.com/uptrain-ai/uptrain)\u00a0and would love to hear feedback from the community", "author_fullname": "t2_sgam369p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Launching UpTrain - an open-source LLM testing tool to help check the performance of your LLM applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rbxsf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688566602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I am building an open-source LLM evaluation toolkit to help ensures your LLM applications are performing reliably by checking their responses on aspects such as correctness, structural integrity, bias, hallucination, etc.&lt;/p&gt;\n\n&lt;p&gt;It can be used to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Validate the model&amp;#39;s response and safeguard your users against incorrect outputs.&lt;/li&gt;\n&lt;li&gt;Experiment across multiple model providers, prompt templates, and make correct choices by quantifying the model&amp;#39;s performance.&lt;/li&gt;\n&lt;li&gt;Monitor your model&amp;#39;s performance in production and protect yourself against unwanted drifts due to model updates or changing user behaviors&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;You can check out the project -\u00a0&lt;a href=\"https://github.com/uptrain-ai/uptrain\"&gt;https://github.com/uptrain-ai/uptrain&lt;/a&gt;\u00a0and would love to hear feedback from the community&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qbuz0sDUpVROrXcMQUqkJOPZrgSkyniAatNZd0IVLLM.jpg?auto=webp&amp;v=enabled&amp;s=1f79be466da11e7b5111f20ae6e4015a6969b225", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qbuz0sDUpVROrXcMQUqkJOPZrgSkyniAatNZd0IVLLM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1523f8745bb87dda9c88fde8c634c84ae55cdabd", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qbuz0sDUpVROrXcMQUqkJOPZrgSkyniAatNZd0IVLLM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c45eaec965dbe79d2c6f3c29e286971c8029a302", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qbuz0sDUpVROrXcMQUqkJOPZrgSkyniAatNZd0IVLLM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=873fc4141834f66149d80b83bd9c97fea2d15196", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qbuz0sDUpVROrXcMQUqkJOPZrgSkyniAatNZd0IVLLM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9af0ae138ab80afe287775691cf77564754e0817", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qbuz0sDUpVROrXcMQUqkJOPZrgSkyniAatNZd0IVLLM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6e671ff17d1d69aa5bdc7aec22149a163b05128", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qbuz0sDUpVROrXcMQUqkJOPZrgSkyniAatNZd0IVLLM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4aa4994a3d9a92aa3130821017b0b18cbd36d474", "width": 1080, "height": 540}], "variants": {}, "id": "Ulo155l56HDRYC0dMjUyEo2J_R_g3f2qItiFCddsrbE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rbxsf", "is_robot_indexable": true, "report_reasons": null, "author": "Vegetable-Skill-9700", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rbxsf/launching_uptrain_an_opensource_llm_testing_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rbxsf/launching_uptrain_an_opensource_llm_testing_tool/", "subreddit_subscribers": 938971, "created_utc": 1688566602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have been given the chance to go back to school and looking to switch majors. I haven\u2019t been since 2017. I was looking at two different schools, the one I used to go to and one near family. The university I used to attend (university of n Texas) has both a data science and computer science degree. The university near family (university of oklahoma) has computer science but not data science (does have a masters). \n\nI feel that my personal interests would align more with data science. I love math and I\u2019m analytical. The last degree I was pursuing before dropping out was Econ w/ a finance minor. I feel that the DS curriculum at UNT has little to no math classes (outside of the DS classes). I also feel that UNT might not be as highly ranked as OU.\n\nCould I get a career in DS with a bachelor\u2019s in CS and get a minor in statistics? Or would it be best to get a DS degree at a lower ranked school?", "author_fullname": "t2_61fmbk98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going back to school and need advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ravw9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688564157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have been given the chance to go back to school and looking to switch majors. I haven\u2019t been since 2017. I was looking at two different schools, the one I used to go to and one near family. The university I used to attend (university of n Texas) has both a data science and computer science degree. The university near family (university of oklahoma) has computer science but not data science (does have a masters). &lt;/p&gt;\n\n&lt;p&gt;I feel that my personal interests would align more with data science. I love math and I\u2019m analytical. The last degree I was pursuing before dropping out was Econ w/ a finance minor. I feel that the DS curriculum at UNT has little to no math classes (outside of the DS classes). I also feel that UNT might not be as highly ranked as OU.&lt;/p&gt;\n\n&lt;p&gt;Could I get a career in DS with a bachelor\u2019s in CS and get a minor in statistics? Or would it be best to get a DS degree at a lower ranked school?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ravw9", "is_robot_indexable": true, "report_reasons": null, "author": "dameis", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ravw9/going_back_to_school_and_need_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ravw9/going_back_to_school_and_need_advice/", "subreddit_subscribers": 938971, "created_utc": 1688564157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Most of the data i'm managing is nice to sketch up in a notebook, but to actually run it in a nice production environment I'm running them as python scripts. \n\nI like .ipynbs, but they have their limits. I would rather develop locally in VS and run a .py file, but I miss the rich text output of the notepad, basically. \n\nI'm sure VS code has some solution for this. What's the best way to solve this? Thanks", "author_fullname": "t2_aefxxhc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "notebook-like experience in VS code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rd1vl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688569071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the data i&amp;#39;m managing is nice to sketch up in a notebook, but to actually run it in a nice production environment I&amp;#39;m running them as python scripts. &lt;/p&gt;\n\n&lt;p&gt;I like .ipynbs, but they have their limits. I would rather develop locally in VS and run a .py file, but I miss the rich text output of the notepad, basically. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure VS code has some solution for this. What&amp;#39;s the best way to solve this? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rd1vl", "is_robot_indexable": true, "report_reasons": null, "author": "throwawayrandomvowel", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rd1vl/notebooklike_experience_in_vs_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rd1vl/notebooklike_experience_in_vs_code/", "subreddit_subscribers": 938971, "created_utc": 1688569071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone. \n\nI have a problem that I am struggling a bit with if someone can please assist me. \n\nI want to create a dataframe where the following filtering is done. \n\nI want to look within each account number they are all unique but appear multiple times. Within each account number I want to select the row where an event occurs thus where column Target is 1. But I also want to select the 3 rows before the tagger event for each account number. \n\nThis is for python. \n\nThanks for the assistance everyone.", "author_fullname": "t2_8wx63wmz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Filtering dataframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rcbic", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688567454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. &lt;/p&gt;\n\n&lt;p&gt;I have a problem that I am struggling a bit with if someone can please assist me. &lt;/p&gt;\n\n&lt;p&gt;I want to create a dataframe where the following filtering is done. &lt;/p&gt;\n\n&lt;p&gt;I want to look within each account number they are all unique but appear multiple times. Within each account number I want to select the row where an event occurs thus where column Target is 1. But I also want to select the 3 rows before the tagger event for each account number. &lt;/p&gt;\n\n&lt;p&gt;This is for python. &lt;/p&gt;\n\n&lt;p&gt;Thanks for the assistance everyone.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rcbic", "is_robot_indexable": true, "report_reasons": null, "author": "Drspacewombat", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rcbic/filtering_dataframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rcbic/filtering_dataframe/", "subreddit_subscribers": 938971, "created_utc": 1688567454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hi all, first timer here.\n\nI am from France, and we have been working on a time series labeling tool for a few months now. We got frustrated with the lack of tools out there. We couldn't really find anything that suited us. We wanted it to go fast and be easy to use. The functionalities we wanted were :\n\n\\- Easy install, good UX\n\n\\- Fast delivery and labeling \n\n\\- A module that can go through the data and propose labeling candidates\n\n\\- A label propagator based on pattern recognition\n\n\\- A search function\n\n\\- An export file usable on any other third-party software\n\n&amp;#x200B;\n\nI am here because we are at a stage where we need some help now : \n\n\\- we need people to test the app\n\n\\- we need feedback\n\n\\- we need new ideas\n\n&amp;#x200B;\n\nIf you are interested here is the download link: [https://github.com/ezako/upalgo-labeling/releases/tag/1.7.9](https://github.com/ezako/upalgo-labeling/releases/tag/1.7.9)\n\nHere is a key for testing :  key/eyJhY2NvdW50Ijp7ImlkIjoiOTAwNTc5ZGMtYTdkNC00ZGNmLWFjYWYtMmU4ODUwNDdjY2YwIn0sInByb2R1Y3QiOnsiaWQiOiI5OTk2NzI5Ni05MzUwLTQ4NjAtOGVhYi1mOWFjNGUwMDYyYmYifSwicG9saWN5Ijp7ImlkIjoiZWE4OTM1ZmItNjczNy00ZWM0LWE3MDMtNDdkZDg1ZjZmMWVmIiwiZHVyYXRpb24iOjI0MTkyMDB9LCJ1c2VyIjpudWxsLCJsaWNlbnNlIjp7ImlkIjoiMTFiNzA0YTctY2JlZi00OTU3LTk4NDctODcxODQ5MDcyZjRmIiwiY3JlYXRlZCI6IjIwMjMtMDctMDVUMTQ6MjM6NDkuNDEzWiIsImV4cGlyeSI6IjIwMjMtMDgtMDJUMTQ6MjM6NDkuNDE1WiJ9fQ==.khCYaqdSCKJL2PpqDp34lQo5whGgKqYHPW3udUrpHbQVxAbd2tRatap7cNKis6jYBksliuB5qz-Hzljhb2hwCg== \n\nThanks 1000x.", "author_fullname": "t2_5n781fb1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series labeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rc70d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688567161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, first timer here.&lt;/p&gt;\n\n&lt;p&gt;I am from France, and we have been working on a time series labeling tool for a few months now. We got frustrated with the lack of tools out there. We couldn&amp;#39;t really find anything that suited us. We wanted it to go fast and be easy to use. The functionalities we wanted were :&lt;/p&gt;\n\n&lt;p&gt;- Easy install, good UX&lt;/p&gt;\n\n&lt;p&gt;- Fast delivery and labeling &lt;/p&gt;\n\n&lt;p&gt;- A module that can go through the data and propose labeling candidates&lt;/p&gt;\n\n&lt;p&gt;- A label propagator based on pattern recognition&lt;/p&gt;\n\n&lt;p&gt;- A search function&lt;/p&gt;\n\n&lt;p&gt;- An export file usable on any other third-party software&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am here because we are at a stage where we need some help now : &lt;/p&gt;\n\n&lt;p&gt;- we need people to test the app&lt;/p&gt;\n\n&lt;p&gt;- we need feedback&lt;/p&gt;\n\n&lt;p&gt;- we need new ideas&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you are interested here is the download link: &lt;a href=\"https://github.com/ezako/upalgo-labeling/releases/tag/1.7.9\"&gt;https://github.com/ezako/upalgo-labeling/releases/tag/1.7.9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is a key for testing :  key/eyJhY2NvdW50Ijp7ImlkIjoiOTAwNTc5ZGMtYTdkNC00ZGNmLWFjYWYtMmU4ODUwNDdjY2YwIn0sInByb2R1Y3QiOnsiaWQiOiI5OTk2NzI5Ni05MzUwLTQ4NjAtOGVhYi1mOWFjNGUwMDYyYmYifSwicG9saWN5Ijp7ImlkIjoiZWE4OTM1ZmItNjczNy00ZWM0LWE3MDMtNDdkZDg1ZjZmMWVmIiwiZHVyYXRpb24iOjI0MTkyMDB9LCJ1c2VyIjpudWxsLCJsaWNlbnNlIjp7ImlkIjoiMTFiNzA0YTctY2JlZi00OTU3LTk4NDctODcxODQ5MDcyZjRmIiwiY3JlYXRlZCI6IjIwMjMtMDctMDVUMTQ6MjM6NDkuNDEzWiIsImV4cGlyeSI6IjIwMjMtMDgtMDJUMTQ6MjM6NDkuNDE1WiJ9fQ==.khCYaqdSCKJL2PpqDp34lQo5whGgKqYHPW3udUrpHbQVxAbd2tRatap7cNKis6jYBksliuB5qz-Hzljhb2hwCg== &lt;/p&gt;\n\n&lt;p&gt;Thanks 1000x.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9Pf5IJv1vyNjC93p_OVfa65h8reMGqupMDfk_Tv9B10.jpg?auto=webp&amp;v=enabled&amp;s=7639e8d2d0ed051cf76b506f66764f8b9120297c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/9Pf5IJv1vyNjC93p_OVfa65h8reMGqupMDfk_Tv9B10.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eaf3ebf1ece67b74b1a265a1761cb2ec46e23c61", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/9Pf5IJv1vyNjC93p_OVfa65h8reMGqupMDfk_Tv9B10.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef8f209dda8f749f3241c4f6ebc8b2c367f154f5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/9Pf5IJv1vyNjC93p_OVfa65h8reMGqupMDfk_Tv9B10.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91796f51e99bbbce3a5df350b05004fc675c05d6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/9Pf5IJv1vyNjC93p_OVfa65h8reMGqupMDfk_Tv9B10.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4143fcbfcf4263caade9586049a55d82db4db03b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/9Pf5IJv1vyNjC93p_OVfa65h8reMGqupMDfk_Tv9B10.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=059be6a8bde5d66ca97dbc86ef2c644e98fc7c78", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/9Pf5IJv1vyNjC93p_OVfa65h8reMGqupMDfk_Tv9B10.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a830854fea5af2ee79992afdfd975ff10efbaf8", "width": 1080, "height": 540}], "variants": {}, "id": "K5HYfmbL5mBYXvPY8j5i3fPpNlf2ocuNxkSN4DoeH_E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rc70d", "is_robot_indexable": true, "report_reasons": null, "author": "WeddingSmall7685", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rc70d/time_series_labeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rc70d/time_series_labeling/", "subreddit_subscribers": 938971, "created_utc": 1688567161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, so I have this task that I need to solve.\n\nCan someone help me on how to get dataset from API or DB connector. Need just one example to understand. Their tutorial videos also not providing any information.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/qomm06bwj5ab1.png?width=1270&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fc0e0015f639d036ba2d1267020b6de361aa916e", "author_fullname": "t2_cim5rbri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with KNIME task.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 29, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qomm06bwj5ab1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 22, "x": 108, "u": "https://preview.redd.it/qomm06bwj5ab1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5574927049447fd066ba442643474b9e6b951ce0"}, {"y": 44, "x": 216, "u": "https://preview.redd.it/qomm06bwj5ab1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e96240d77415f240e2c944275460bf21a914470f"}, {"y": 66, "x": 320, "u": "https://preview.redd.it/qomm06bwj5ab1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2dc430d84c0abf2a59fda69374c629e8e2c2c3f5"}, {"y": 133, "x": 640, "u": "https://preview.redd.it/qomm06bwj5ab1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0277aa09c39fb38d7705bdfeae8411f72dcbfbce"}, {"y": 199, "x": 960, "u": "https://preview.redd.it/qomm06bwj5ab1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89c9ebdbc7fbc876aa9102353cd816cc3f55a8d9"}, {"y": 224, "x": 1080, "u": "https://preview.redd.it/qomm06bwj5ab1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e57d873f2dce261814575f47a088561260cea997"}], "s": {"y": 264, "x": 1270, "u": "https://preview.redd.it/qomm06bwj5ab1.png?width=1270&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fc0e0015f639d036ba2d1267020b6de361aa916e"}, "id": "qomm06bwj5ab1"}}, "name": "t3_14rbm0l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7ZrmKc2mAwiOsCnbxunPcBseQ1wc2T6Idk5eRVv4nWE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688565864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, so I have this task that I need to solve.&lt;/p&gt;\n\n&lt;p&gt;Can someone help me on how to get dataset from API or DB connector. Need just one example to understand. Their tutorial videos also not providing any information.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qomm06bwj5ab1.png?width=1270&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fc0e0015f639d036ba2d1267020b6de361aa916e\"&gt;https://preview.redd.it/qomm06bwj5ab1.png?width=1270&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fc0e0015f639d036ba2d1267020b6de361aa916e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rbm0l", "is_robot_indexable": true, "report_reasons": null, "author": "meis_xry", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rbm0l/need_help_with_knime_task/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rbm0l/need_help_with_knime_task/", "subreddit_subscribers": 938971, "created_utc": 1688565864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9de03cxq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can ChatGPT Help You Master Complex Data Science Concepts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14r9qae", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-4XEKCAEQSjr8YIh1CKX6NkEl04Fgswo1Qonz2gubWQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688561299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "albertchristopherr.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://albertchristopherr.medium.com/can-chatgpt-help-you-master-complex-data-science-concepts-da2cdf71b603", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ftkR8JK70gydHptJENB3J34v-v-AelleBULFSgTZNn8.jpg?auto=webp&amp;v=enabled&amp;s=c8a8ec6dfa106d3462763a27c2502cd31b2de728", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/ftkR8JK70gydHptJENB3J34v-v-AelleBULFSgTZNn8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d05911022b4ade2d383b8c99858aa8d5e9aa5018", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ftkR8JK70gydHptJENB3J34v-v-AelleBULFSgTZNn8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2671c6de3542c2cf984c21d9305e8005e6efc8e1", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ftkR8JK70gydHptJENB3J34v-v-AelleBULFSgTZNn8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4956f850bf477c5c26b7108f84744e14fcbcfd1c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ftkR8JK70gydHptJENB3J34v-v-AelleBULFSgTZNn8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4cef9a8caeefbeca059a4c4bb8657e2957a8aa55", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ftkR8JK70gydHptJENB3J34v-v-AelleBULFSgTZNn8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2379f7eb1e1a8fcd26011e76b0ce47d73eb37f1e", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ftkR8JK70gydHptJENB3J34v-v-AelleBULFSgTZNn8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b500a0c8e76bb88726782a3caefbfb8a356044b", "width": 1080, "height": 607}], "variants": {}, "id": "h6nqA_BoTyFuDSm5gaT5uwsCmIfi032iTJRvsXPZNho"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r9qae", "is_robot_indexable": true, "report_reasons": null, "author": "Palaksharma22", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r9qae/can_chatgpt_help_you_master_complex_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://albertchristopherr.medium.com/can-chatgpt-help-you-master-complex-data-science-concepts-da2cdf71b603", "subreddit_subscribers": 938971, "created_utc": 1688561299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just got an offer for a logistics Analyst position but I don\u2019t know what to expect if I\u2019m being completely honest.", "author_fullname": "t2_a8bfi7prl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A bit unrelated but what does a logistics Analyst actually do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r7jv9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688555172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just got an offer for a logistics Analyst position but I don\u2019t know what to expect if I\u2019m being completely honest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r7jv9", "is_robot_indexable": true, "report_reasons": null, "author": "SuspiciousAd8192", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r7jv9/a_bit_unrelated_but_what_does_a_logistics_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r7jv9/a_bit_unrelated_but_what_does_a_logistics_analyst/", "subreddit_subscribers": 938971, "created_utc": 1688555172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey!\n\nVery new to ML, working on a self found project to help with my learnings...   \n I have access to transactions, the data looks something like...    \ntransactionType, Currency, USDEquivilent, MonthlyTotal    \nI have \\~9k examples, and I am trying to highlight Anomalys using an isolation forest using sklearn   \nI have my data preprocessed and scaled, and through the model seemingly okay (and the results look reasonable)    \nHowever, when I then feed some test data into the trained model, its not working as I would expect.   \nHere is an example...     \nif I pass these 5 examples in as test data   \n\\- transactiontype1,EUR,500,&lt;2.5M   \n\\- transactiontype1,EUR,5000, 2.5M - 15M    \n\\- transactiontype1,EUR,50000,15M - 50M   \n\\- transactiontype1,EUR,500000,50M - 125M   \n\\- transactiontype1,EUR,500000,125M - 250M    \nthe result for Anomalys is...  (1 = Non anomaly, -1 = anomaly)  \n\\- 1   \n\\- 1   \n\\- 1   \n\\- -1   \n\\- -1   \nWhich seems reasonable. However, when I just feed in     \n\\- transactiontype1,EUR,500000,50M - 125M   \n\\- transactiontype1,EUR,500000,125M - 250M    \nThe result for Anomalys is...    \n\\- 1    \n\\- 1    \nWhich I don't quite understand, why would this differ just because of what I'm passing in to a trained model? ", "author_fullname": "t2_2t7rvu71", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anomaly Detection - Isolation Forest", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r73rg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688554197.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688553891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey!&lt;/p&gt;\n\n&lt;p&gt;Very new to ML, working on a self found project to help with my learnings...&lt;br/&gt;\n I have access to transactions, the data looks something like...&lt;br/&gt;\ntransactionType, Currency, USDEquivilent, MonthlyTotal&lt;br/&gt;\nI have ~9k examples, and I am trying to highlight Anomalys using an isolation forest using sklearn&lt;br/&gt;\nI have my data preprocessed and scaled, and through the model seemingly okay (and the results look reasonable)&lt;br/&gt;\nHowever, when I then feed some test data into the trained model, its not working as I would expect.&lt;br/&gt;\nHere is an example...&lt;br/&gt;\nif I pass these 5 examples in as test data&lt;br/&gt;\n- transactiontype1,EUR,500,&amp;lt;2.5M&lt;br/&gt;\n- transactiontype1,EUR,5000, 2.5M - 15M&lt;br/&gt;\n- transactiontype1,EUR,50000,15M - 50M&lt;br/&gt;\n- transactiontype1,EUR,500000,50M - 125M&lt;br/&gt;\n- transactiontype1,EUR,500000,125M - 250M&lt;br/&gt;\nthe result for Anomalys is...  (1 = Non anomaly, -1 = anomaly)&lt;br/&gt;\n- 1&lt;br/&gt;\n- 1&lt;br/&gt;\n- 1&lt;br/&gt;\n- -1&lt;br/&gt;\n- -1&lt;br/&gt;\nWhich seems reasonable. However, when I just feed in&lt;br/&gt;\n- transactiontype1,EUR,500000,50M - 125M&lt;br/&gt;\n- transactiontype1,EUR,500000,125M - 250M&lt;br/&gt;\nThe result for Anomalys is...&lt;br/&gt;\n- 1&lt;br/&gt;\n- 1&lt;br/&gt;\nWhich I don&amp;#39;t quite understand, why would this differ just because of what I&amp;#39;m passing in to a trained model? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r73rg", "is_robot_indexable": true, "report_reasons": null, "author": "CerealKiller1993", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r73rg/anomaly_detection_isolation_forest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r73rg/anomaly_detection_isolation_forest/", "subreddit_subscribers": 938971, "created_utc": 1688553891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Calling all Data Scientists! \ud83d\ude80   \nWe're thrilled to announce the launch of ***Spheron Terraform Provider***, revolutionizing the way you train your ML models on the decentralized cloud. Say goodbye to compromises on speed and performance.\n\nWith Spheron Terraform Provider, you gain *unprecedented control over your infrastructure on the Spheron platform. From deploying marketplace applications to launching instances and seamlessly linking them to domains, all at your fingertips through a simple Terraform resource block.*\n\n**Ready to dive in?** Check out our comprehensive [documentation](https://docs.spheron.network/terraform/), which covers everything you need to get started - prerequisites, installation, configuration, and usage. And don't forget to explore the Spheron Terraform Provider code on the Terraform [Registry](https://registry.terraform.io/providers/spheronFdn/spheron/latest) for a seamless infrastructure-as-code experience.\n\nUnlock the true potential of Spheron Compute in your ML workflows with the game-changing Spheron Terraform Provider. Embrace a decentralized cloud without compromise!  \nTry it out now and share your thoughts. We welcome and value all feedback to make your experience even better. Let's shape the future of the decentralized cloud together! ", "author_fullname": "t2_tdyk2ru0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Spheron Terraform Provider: Empowering Data Scientists with Decentralized Cloud!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r6pma", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688552676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Calling all Data Scientists! \ud83d\ude80&lt;br/&gt;\nWe&amp;#39;re thrilled to announce the launch of &lt;strong&gt;&lt;em&gt;Spheron Terraform Provider&lt;/em&gt;&lt;/strong&gt;, revolutionizing the way you train your ML models on the decentralized cloud. Say goodbye to compromises on speed and performance.&lt;/p&gt;\n\n&lt;p&gt;With Spheron Terraform Provider, you gain &lt;em&gt;unprecedented control over your infrastructure on the Spheron platform. From deploying marketplace applications to launching instances and seamlessly linking them to domains, all at your fingertips through a simple Terraform resource block.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Ready to dive in?&lt;/strong&gt; Check out our comprehensive &lt;a href=\"https://docs.spheron.network/terraform/\"&gt;documentation&lt;/a&gt;, which covers everything you need to get started - prerequisites, installation, configuration, and usage. And don&amp;#39;t forget to explore the Spheron Terraform Provider code on the Terraform &lt;a href=\"https://registry.terraform.io/providers/spheronFdn/spheron/latest\"&gt;Registry&lt;/a&gt; for a seamless infrastructure-as-code experience.&lt;/p&gt;\n\n&lt;p&gt;Unlock the true potential of Spheron Compute in your ML workflows with the game-changing Spheron Terraform Provider. Embrace a decentralized cloud without compromise!&lt;br/&gt;\nTry it out now and share your thoughts. We welcome and value all feedback to make your experience even better. Let&amp;#39;s shape the future of the decentralized cloud together! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NMLxfkMk9g5BnMSxfb4-Oh72d6TL-87W_JzT1D7YuUs.jpg?auto=webp&amp;v=enabled&amp;s=2ab3d3188d5717204ef2a18cdc3b2974f7a6343a", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/NMLxfkMk9g5BnMSxfb4-Oh72d6TL-87W_JzT1D7YuUs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0c81f17c03bf793db74e3cb1e85d7826310456d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/NMLxfkMk9g5BnMSxfb4-Oh72d6TL-87W_JzT1D7YuUs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3e00163fbe8295f8525a57edea7a88697b224d8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/NMLxfkMk9g5BnMSxfb4-Oh72d6TL-87W_JzT1D7YuUs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1dea41a58c42cf92e98afb22f12042d9a887ff2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/NMLxfkMk9g5BnMSxfb4-Oh72d6TL-87W_JzT1D7YuUs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a6e91597b82f4660cbd8be28a313fb7e4b9b4f4c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/NMLxfkMk9g5BnMSxfb4-Oh72d6TL-87W_JzT1D7YuUs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61c9d46e73023a834f84c26bd41e467c2ae80b49", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/NMLxfkMk9g5BnMSxfb4-Oh72d6TL-87W_JzT1D7YuUs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a68223b3c28adf0ffd5aebcd37b512194045c98", "width": 1080, "height": 567}], "variants": {}, "id": "Ym3Q3DXqVn90E6b6bpkGs4-ycOk9IH88FFsMuF5oaZc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r6pma", "is_robot_indexable": true, "report_reasons": null, "author": "TaxFlaky6026", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r6pma/introducing_spheron_terraform_provider_empowering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r6pma/introducing_spheron_terraform_provider_empowering/", "subreddit_subscribers": 938971, "created_utc": 1688552676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nThis is my first time posting here and I'll try to keep it short. First some context, I have a bachelors degree in molecular biology, with an emphasis in data analytics. By emphasis in data analytics, I mean that we had a few semesters with optional courses, specialising in lab techniques or data analytics and I chose the latter. Im familiar with both R (preffered) and Python, as well as their corresponding packages used in data analysis, however not an expert by any means, parametric and non parametric statistics, data cleaning, visualisations (what plots are used for what combination of variables) and just a touch of ML.\n\nHowever, I have no knowledge of databases and how to work with them, I dont know SQL, nor am I familiar with Apache Spark, Tableau, power BI. I only know of data structures in theory.\n\nI applied for a data science master's degree in my uni, which is a 1.5 year program, of which 9 months will be spent on various data science courses and 6 months on a master's degree thesis. Financially speaking this is not a problem, education is free where Im from.\n\nNow I started to doubt myself, is this worth the time and effort? I checked some of the job listings and they require quite extensive knowledge of the things that I lack in, like Azure, SQL, creating data pipelines and so on, and i doubt my master's program will cover these things. Are they hard to learn? Where do I begin? Im not afraid of coding, but Im not a software engineer by trade, for who these things are likely second nature.", "author_fullname": "t2_6wtukv4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Required competencies for DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r0xhq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688534010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;This is my first time posting here and I&amp;#39;ll try to keep it short. First some context, I have a bachelors degree in molecular biology, with an emphasis in data analytics. By emphasis in data analytics, I mean that we had a few semesters with optional courses, specialising in lab techniques or data analytics and I chose the latter. Im familiar with both R (preffered) and Python, as well as their corresponding packages used in data analysis, however not an expert by any means, parametric and non parametric statistics, data cleaning, visualisations (what plots are used for what combination of variables) and just a touch of ML.&lt;/p&gt;\n\n&lt;p&gt;However, I have no knowledge of databases and how to work with them, I dont know SQL, nor am I familiar with Apache Spark, Tableau, power BI. I only know of data structures in theory.&lt;/p&gt;\n\n&lt;p&gt;I applied for a data science master&amp;#39;s degree in my uni, which is a 1.5 year program, of which 9 months will be spent on various data science courses and 6 months on a master&amp;#39;s degree thesis. Financially speaking this is not a problem, education is free where Im from.&lt;/p&gt;\n\n&lt;p&gt;Now I started to doubt myself, is this worth the time and effort? I checked some of the job listings and they require quite extensive knowledge of the things that I lack in, like Azure, SQL, creating data pipelines and so on, and i doubt my master&amp;#39;s program will cover these things. Are they hard to learn? Where do I begin? Im not afraid of coding, but Im not a software engineer by trade, for who these things are likely second nature.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r0xhq", "is_robot_indexable": true, "report_reasons": null, "author": "eatyourtoes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r0xhq/required_competencies_for_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r0xhq/required_competencies_for_ds/", "subreddit_subscribers": 938971, "created_utc": 1688534010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am pursuing masters in data science from australia,  it will take around 2 years to complete.  Being an international student its important for me to get a job in IT once my course get completion.\n\nMy question is what will be the scope/ future of data scientist/ analyst in australian after 2 years.\n\nCurrently i am seeing less opportunity for in data science field in IT.", "author_fullname": "t2_er2xhtky3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future of data scientist in australia(fresher)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r056t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688531456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am pursuing masters in data science from australia,  it will take around 2 years to complete.  Being an international student its important for me to get a job in IT once my course get completion.&lt;/p&gt;\n\n&lt;p&gt;My question is what will be the scope/ future of data scientist/ analyst in australian after 2 years.&lt;/p&gt;\n\n&lt;p&gt;Currently i am seeing less opportunity for in data science field in IT.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r056t", "is_robot_indexable": true, "report_reasons": null, "author": "jaySharma_12", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r056t/future_of_data_scientist_in_australiafresher/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r056t/future_of_data_scientist_in_australiafresher/", "subreddit_subscribers": 938971, "created_utc": 1688531456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**This post is several related questions rolled into one.**\n\n**First and most simply, what is** [this kind of graph](https://www.sgmoratilla.com/static/e7ac56cc3e90327b21f79ab7d144d7c5/7468b/github-contributios-activity.png) **called?** This image was taken from GitHub, where the graph represents total GitHub participation over a given period. It breaks participation down into four areas of open source contribution, devoting one axis to each, and sums to 100%. Presumably this type of chart could be generalized to have any number of axes.\n\n**Second, I'm looking for the optimal way to visualize the aggregate results of a simple ablation study.** I'm an ML research engineer, and at work I've been working on an ablation study for publication. The study is investigating what happens when we feed non-text features into transformer models. We have 4 types of features, so not a huge number, but more than you could simply throw onto an x-y plane without careful consideration. I've trained many models combinatorically, one for each combination of features from none to all. I have the metrics for all of these models. What I need now is a good way to succinctly visualize these results graphically/geometrically, rather than just saying \"hey here's a table\" with like 200 kappas. I'd like the reader to walk away with a sense of how much each feature contributes to model performance, relative to a baseline of no non-text features. Ideas?\n\n**Third, I'm wondering if the graph type linked in my initial paragraph is one way to visualize my study's results.** As I worked with four different features, I was thinking I could have one axis per feature. Then I could simply group the performance of all my models by feature, take the mean performance across all models that use each feature, then just plot those means (I don't think normalization would achieve anything as all axes would already be on the same scale). The math of this proposal would look like this (assuming only 3 features for simplicity, and thus a 3-axis visualization, though the concept is the same):\n\n&amp;#x200B;\n\n||feature 1|feature 3|feature 3|performance|\n|:-|:-|:-|:-|:-|\n|model 1|\u2713|\u2713|\u2713|0.8|\n|model 2|\u2713|\u2713||0.5|\n|model 3|\u2713||\u2713|0.7|\n|model 4||\u2713|\u2713|0.6|\n|model 5|\u2713|||0.2|\n|model 6||\u2713||0.4|\n|model 7|||\u2713|0.1|\n\n&amp;#x200B;\n\n|feature|mean performance|\n|:-|:-|\n|feature 1|(0.8 + 0.5 + 0.7 + 0.2) / 4 = **0.550**|\n|feature 2|(0.8 + 0.5 + 0.6 + 0.4) / 4 = **0.575**|\n|feature 3|(0.8 + 0.7 + 0.6 + 0.3) / 4 = **0.600**|\n\nSo the numbers in the final column of the final table are what would be plotted. These would determine how \"pointy\" the polygon is in each axis.\n\nIs that math defensible, and would the resultant visualization effectively communicate the relative contributions of each feature to the performance of my model? I've been thinking about this since Friday including reading some other ablation studies for inspiration but it's the best I could come up with", "author_fullname": "t2_x66s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Name that chart type! Trying to visualize multidimensional ablation study results", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qyrb2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688532582.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688526968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;This post is several related questions rolled into one.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;First and most simply, what is&lt;/strong&gt; &lt;a href=\"https://www.sgmoratilla.com/static/e7ac56cc3e90327b21f79ab7d144d7c5/7468b/github-contributios-activity.png\"&gt;this kind of graph&lt;/a&gt; &lt;strong&gt;called?&lt;/strong&gt; This image was taken from GitHub, where the graph represents total GitHub participation over a given period. It breaks participation down into four areas of open source contribution, devoting one axis to each, and sums to 100%. Presumably this type of chart could be generalized to have any number of axes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Second, I&amp;#39;m looking for the optimal way to visualize the aggregate results of a simple ablation study.&lt;/strong&gt; I&amp;#39;m an ML research engineer, and at work I&amp;#39;ve been working on an ablation study for publication. The study is investigating what happens when we feed non-text features into transformer models. We have 4 types of features, so not a huge number, but more than you could simply throw onto an x-y plane without careful consideration. I&amp;#39;ve trained many models combinatorically, one for each combination of features from none to all. I have the metrics for all of these models. What I need now is a good way to succinctly visualize these results graphically/geometrically, rather than just saying &amp;quot;hey here&amp;#39;s a table&amp;quot; with like 200 kappas. I&amp;#39;d like the reader to walk away with a sense of how much each feature contributes to model performance, relative to a baseline of no non-text features. Ideas?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Third, I&amp;#39;m wondering if the graph type linked in my initial paragraph is one way to visualize my study&amp;#39;s results.&lt;/strong&gt; As I worked with four different features, I was thinking I could have one axis per feature. Then I could simply group the performance of all my models by feature, take the mean performance across all models that use each feature, then just plot those means (I don&amp;#39;t think normalization would achieve anything as all axes would already be on the same scale). The math of this proposal would look like this (assuming only 3 features for simplicity, and thus a 3-axis visualization, though the concept is the same):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;feature 1&lt;/th&gt;\n&lt;th align=\"left\"&gt;feature 3&lt;/th&gt;\n&lt;th align=\"left\"&gt;feature 3&lt;/th&gt;\n&lt;th align=\"left\"&gt;performance&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 1&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.8&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 2&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 3&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.7&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 4&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 5&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.4&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 7&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;feature&lt;/th&gt;\n&lt;th align=\"left\"&gt;mean performance&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;feature 1&lt;/td&gt;\n&lt;td align=\"left\"&gt;(0.8 + 0.5 + 0.7 + 0.2) / 4 = &lt;strong&gt;0.550&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;feature 2&lt;/td&gt;\n&lt;td align=\"left\"&gt;(0.8 + 0.5 + 0.6 + 0.4) / 4 = &lt;strong&gt;0.575&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;feature 3&lt;/td&gt;\n&lt;td align=\"left\"&gt;(0.8 + 0.7 + 0.6 + 0.3) / 4 = &lt;strong&gt;0.600&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;So the numbers in the final column of the final table are what would be plotted. These would determine how &amp;quot;pointy&amp;quot; the polygon is in each axis.&lt;/p&gt;\n\n&lt;p&gt;Is that math defensible, and would the resultant visualization effectively communicate the relative contributions of each feature to the performance of my model? I&amp;#39;ve been thinking about this since Friday including reading some other ablation studies for inspiration but it&amp;#39;s the best I could come up with&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?auto=webp&amp;v=enabled&amp;s=14e928f2e715587d4353a758b604481743a43175", "width": 1764, "height": 1406}, "resolutions": [{"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88c0922186107e6c7d22a501be157fb8871c34b3", "width": 108, "height": 86}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f2065ddd761ec458ad8406aa2249f120d7aa2ea", "width": 216, "height": 172}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05133b02c78a517b5bcc4e0974ec0dda69c35729", "width": 320, "height": 255}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ab3bcb43e1ce6df60b8a686b136aafb82e2352b", "width": 640, "height": 510}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6fb7079ed8a6fa565d1e98693609727d96ee4c7", "width": 960, "height": 765}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4b09260079681b565991faf0fe73f2f17d9eefe", "width": 1080, "height": 860}], "variants": {}, "id": "EZZn27rTOwtEKCC6oWZJvw6d58nuKqsBTCbE5DZvFdw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qyrb2", "is_robot_indexable": true, "report_reasons": null, "author": "synthphreak", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qyrb2/name_that_chart_type_trying_to_visualize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qyrb2/name_that_chart_type_trying_to_visualize/", "subreddit_subscribers": 938971, "created_utc": 1688526968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_17d73o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top 5 AI tools for fast surgical video annotation in 2023 - Supervisely", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14raf5d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/luARQ0kBg-0R_r-GFY7SpnMHguaS--wQjN1J58NtJY8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688563019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "supervisely.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://supervisely.com/blog/top-5-AI-tools-for-surgical-video-annotation/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PwWy9jSv6nlze9NqII9x4009Hj5AYwEACQaeXFImHPI.jpg?auto=webp&amp;v=enabled&amp;s=014b70d2ce1d667c0d85a5492e96d6a8299e454b", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/PwWy9jSv6nlze9NqII9x4009Hj5AYwEACQaeXFImHPI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed73fb1fc8fcf1c4386b2c152cb6d75c534f4d6e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/PwWy9jSv6nlze9NqII9x4009Hj5AYwEACQaeXFImHPI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07992f46f527996b8bd180cf6305094921a20bcd", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/PwWy9jSv6nlze9NqII9x4009Hj5AYwEACQaeXFImHPI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=214b7f6a54fb134cb43b6dfc500ab14ba63b78de", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/PwWy9jSv6nlze9NqII9x4009Hj5AYwEACQaeXFImHPI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9ed2520c23c9ba67bf0ac971b7d45dbae5d0875", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/PwWy9jSv6nlze9NqII9x4009Hj5AYwEACQaeXFImHPI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9053c6bc200945436fdc75208e13593b1355c917", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/PwWy9jSv6nlze9NqII9x4009Hj5AYwEACQaeXFImHPI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9bf18d0882f525c9009217f7da07032b354d9b5f", "width": 1080, "height": 607}], "variants": {}, "id": "jdbGpKyYC4jG97cT7CGwA0apcCoc23Dy3hb9bNRYpzg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14raf5d", "is_robot_indexable": true, "report_reasons": null, "author": "tdionis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14raf5d/top_5_ai_tools_for_fast_surgical_video_annotation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://supervisely.com/blog/top-5-AI-tools-for-surgical-video-annotation/", "subreddit_subscribers": 938971, "created_utc": 1688563019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nFor a project I am doing I want to identify the top x topics/issues discussed in [r/changemyview](https://www.reddit.com/r/changemyview/). For example I may find the most common topics are\n\n1. Affirmative Action\n2. Gun Control\n3. etc ...\n\nI am familiar with using praw to retrieve post titles from the sub. What are some techniques to identify the topic/issue each post is addressing. For example in the post: \"CMV: The 2nd Amendment enables the police state, it does not protect our other rights.\" the topic is 2nd Amendment. Is the best way to do this to define several topics and classify each post into one of the pre defined topics? Another method I saw online is using \"Bag of Words\" or \"Term Frequency-Inverse Document Frequency\" both of these methods take into account the frequency and importance of a word. I am not familiar with these two methods but I was thinking I could find the most frequently occurring words to identify the most frequent topics as well.\n\nTLDR: How to parse [r/changemyview](https://www.reddit.com/r/changemyview/) in order to identify the most frequently occurring topics.", "author_fullname": "t2_jagpllod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to identify topics using r/changemyview post titles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qml8v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688494430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;For a project I am doing I want to identify the top x topics/issues discussed in &lt;a href=\"https://www.reddit.com/r/changemyview/\"&gt;r/changemyview&lt;/a&gt;. For example I may find the most common topics are&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Affirmative Action&lt;/li&gt;\n&lt;li&gt;Gun Control&lt;/li&gt;\n&lt;li&gt;etc ...&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am familiar with using praw to retrieve post titles from the sub. What are some techniques to identify the topic/issue each post is addressing. For example in the post: &amp;quot;CMV: The 2nd Amendment enables the police state, it does not protect our other rights.&amp;quot; the topic is 2nd Amendment. Is the best way to do this to define several topics and classify each post into one of the pre defined topics? Another method I saw online is using &amp;quot;Bag of Words&amp;quot; or &amp;quot;Term Frequency-Inverse Document Frequency&amp;quot; both of these methods take into account the frequency and importance of a word. I am not familiar with these two methods but I was thinking I could find the most frequently occurring words to identify the most frequent topics as well.&lt;/p&gt;\n\n&lt;p&gt;TLDR: How to parse &lt;a href=\"https://www.reddit.com/r/changemyview/\"&gt;r/changemyview&lt;/a&gt; in order to identify the most frequently occurring topics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qml8v", "is_robot_indexable": true, "report_reasons": null, "author": "JigglyBooii", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qml8v/how_to_identify_topics_using_rchangemyview_post/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qml8v/how_to_identify_topics_using_rchangemyview_post/", "subreddit_subscribers": 938971, "created_utc": 1688494430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys\n\nI am still kinda new to this data analytics industry but in a nutshell,\n\nI am working for a company and my personal project is auto populating some columns based on one column. I can't give you specifics since the information is confidential but basically, I am using description column to auto populate engine hours, model year and etc of farming equipment. For example, the description columns are usually like \"John Deere 2019, it has 1500 hours. it is in good condition, it also has Hydraulics and AC. Front dual. it has enclosed cap\" something like this. And I wrote almost all the codes that are needed for this on SQLite except that I faced an issue where I cannot use regex properly in the where clause (it does not produce the right results) and also  the instring function in SQLite does not support specifying a range of numbers. and it can only search for a specific substring within a string. But I found out that I could solve the issue by using PATINDEX function that I could not solve by using SQLite.\n\n&amp;#x200B;\n\nSo I decided to use SQL server instead and tried to find a way to automate uploading process. However, I also realized that I did not want to convert all the codes into SQL server form since it will take a long time.. I used Chat GPT and it converts a lot of stuff wrong. Also, SQL requires a little more manipulation in SQL import wizard than SQLite import function in terms of importing the csv data. I want users to be able to use the program easily. Right now, I have codes for SQLite since I solved the issue in a different way finally but I am not sure if making users to install SQLite and import and run the codes is the best way.\n\n&amp;#x200B;\n\nI thought about SSIS ETL process but I am not sure if this process is what I want.  What I want is make users to easily upload the csv data and get the data based on the algorithms on which I wrote the codes for the process of autopopulating the columns based on the one column. So I looked into visual basic studio 2019. and I also used chat gpt to figure this out. The chat gpt says that I could use [ASP.net](https://ASP.net) to allow users to easily upload the csv file and get the columns autopopulate on a website by using and inserting the SQL codes. However, certainly, I do not know how to do this specifically. I was able to make a webpage but there are multiple pages I need to fill out to make this work in the visual studio ASP project. The chat gpt does not help the specifications since the codes are usually kinda wrong.\n\n&amp;#x200B;\n\nDo any of the data scientists or analysts have suggestions how to go about this? Also, I am pretty sure what I am doing is kinda close to machine learning since I am building an algorithms for almost every case I can think of. Are there anyways that I can teach the machine to learn how to build different cases for itself so I don't have to input new codes for new patterns when a new case rises?", "author_fullname": "t2_cnor8yse9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Autopopulating program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qld2h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688493432.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688491580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys&lt;/p&gt;\n\n&lt;p&gt;I am still kinda new to this data analytics industry but in a nutshell,&lt;/p&gt;\n\n&lt;p&gt;I am working for a company and my personal project is auto populating some columns based on one column. I can&amp;#39;t give you specifics since the information is confidential but basically, I am using description column to auto populate engine hours, model year and etc of farming equipment. For example, the description columns are usually like &amp;quot;John Deere 2019, it has 1500 hours. it is in good condition, it also has Hydraulics and AC. Front dual. it has enclosed cap&amp;quot; something like this. And I wrote almost all the codes that are needed for this on SQLite except that I faced an issue where I cannot use regex properly in the where clause (it does not produce the right results) and also  the instring function in SQLite does not support specifying a range of numbers. and it can only search for a specific substring within a string. But I found out that I could solve the issue by using PATINDEX function that I could not solve by using SQLite.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I decided to use SQL server instead and tried to find a way to automate uploading process. However, I also realized that I did not want to convert all the codes into SQL server form since it will take a long time.. I used Chat GPT and it converts a lot of stuff wrong. Also, SQL requires a little more manipulation in SQL import wizard than SQLite import function in terms of importing the csv data. I want users to be able to use the program easily. Right now, I have codes for SQLite since I solved the issue in a different way finally but I am not sure if making users to install SQLite and import and run the codes is the best way.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I thought about SSIS ETL process but I am not sure if this process is what I want.  What I want is make users to easily upload the csv data and get the data based on the algorithms on which I wrote the codes for the process of autopopulating the columns based on the one column. So I looked into visual basic studio 2019. and I also used chat gpt to figure this out. The chat gpt says that I could use &lt;a href=\"https://ASP.net\"&gt;ASP.net&lt;/a&gt; to allow users to easily upload the csv file and get the columns autopopulate on a website by using and inserting the SQL codes. However, certainly, I do not know how to do this specifically. I was able to make a webpage but there are multiple pages I need to fill out to make this work in the visual studio ASP project. The chat gpt does not help the specifications since the codes are usually kinda wrong.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do any of the data scientists or analysts have suggestions how to go about this? Also, I am pretty sure what I am doing is kinda close to machine learning since I am building an algorithms for almost every case I can think of. Are there anyways that I can teach the machine to learn how to build different cases for itself so I don&amp;#39;t have to input new codes for new patterns when a new case rises?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tOcHqen1kUsOwwy69KXemKWBNWHsA4cbiSO3JrFVitg.jpg?auto=webp&amp;v=enabled&amp;s=a626a7e9d320fbdfe2116b03f85e52dc18fce2e3", "width": 238, "height": 238}, "resolutions": [{"url": "https://external-preview.redd.it/tOcHqen1kUsOwwy69KXemKWBNWHsA4cbiSO3JrFVitg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93819bfca99048541e71bba5f90386fdbbba7844", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/tOcHqen1kUsOwwy69KXemKWBNWHsA4cbiSO3JrFVitg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d43106cb2f5d8a9a58fe523b46fa1bafbfd024d", "width": 216, "height": 216}], "variants": {}, "id": "TtFVmEs53hWc_tUPscFPQzT0bv04t5CPuG5-SNnw3mo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qld2h", "is_robot_indexable": true, "report_reasons": null, "author": "Money_Working_9702", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qld2h/autopopulating_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qld2h/autopopulating_program/", "subreddit_subscribers": 938971, "created_utc": 1688491580.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}