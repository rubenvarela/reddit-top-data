{"kind": "Listing", "data": {"after": "t3_14r6ltr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.\n\nI have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next\n\nFor anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.\n\nThe resources I used were:\n\n1. [https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/](https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/) \\- used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics\n2. [https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc](https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc) \\- a good reference guide\n3. [https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF](https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF) \\- essentially 90% of the actual exam questions pretty decent explanations  \n\n\nP.S Sorry couldn't forget to include [Spark Internals Explanation](https://www.youtube.com/watch?v=7ooZ4S7Ay6Y)! A phenomenal resource to dive deep on how Spark works under the hood", "author_fullname": "t2_ic83gko1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got certified! - Databricks certified associate developer for apache spark 3.0 in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzt8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 115, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 115, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688544365.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688530389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.&lt;/p&gt;\n\n&lt;p&gt;I have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next&lt;/p&gt;\n\n&lt;p&gt;For anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.&lt;/p&gt;\n\n&lt;p&gt;The resources I used were:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/\"&gt;https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/&lt;/a&gt; - used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc\"&gt;https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc&lt;/a&gt; - a good reference guide&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF\"&gt;https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF&lt;/a&gt; - essentially 90% of the actual exam questions pretty decent explanations&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;P.S Sorry couldn&amp;#39;t forget to include &lt;a href=\"https://www.youtube.com/watch?v=7ooZ4S7Ay6Y\"&gt;Spark Internals Explanation&lt;/a&gt;! A phenomenal resource to dive deep on how Spark works under the hood&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qzt8y", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Debate_94", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "subreddit_subscribers": 114224, "created_utc": 1688530389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I was first learning dbt I found a lot of really great resources (dbt docs, blog posts, slack threads etc.) and wanted to try to put that all together in one place for anyone else new to dbt, or anyone wanting to learn a bit more about it.   \nThe guide covers everything from \u2018what is dbt?\u2019 to advanced topics like model refactoring best practices.  \nI hope it's useful! **And if you spot anything missing, or ways to make it better, please let me know!**  \n\n\nDesktop link: [https://count.co/canvas/JpkaYdqr9oN](https://count.co/canvas/JpkaYdqr9oN)  \nMobile link: [https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914](https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914)  \n\n\nFull disclosure: I do work for [count.co](https://count.co), the canvas in which the guide was built. ", "author_fullname": "t2_1zfun4sx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I attempted to create the Ultimate Guide to dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r4v10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688547009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was first learning dbt I found a lot of really great resources (dbt docs, blog posts, slack threads etc.) and wanted to try to put that all together in one place for anyone else new to dbt, or anyone wanting to learn a bit more about it.&lt;br/&gt;\nThe guide covers everything from \u2018what is dbt?\u2019 to advanced topics like model refactoring best practices.&lt;br/&gt;\nI hope it&amp;#39;s useful! &lt;strong&gt;And if you spot anything missing, or ways to make it better, please let me know!&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Desktop link: &lt;a href=\"https://count.co/canvas/JpkaYdqr9oN\"&gt;https://count.co/canvas/JpkaYdqr9oN&lt;/a&gt;&lt;br/&gt;\nMobile link: &lt;a href=\"https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914\"&gt;https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Full disclosure: I do work for &lt;a href=\"https://count.co\"&gt;count.co&lt;/a&gt;, the canvas in which the guide was built. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?auto=webp&amp;v=enabled&amp;s=c90d7e97aa224a896783d02a2a830784cb2c0920", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bd97f02fcc00d06a42618c0358185b4bc650318", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb4ee7c5f99ac12f4224cd68ccf6e07358a570c8", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20558ea1403333413bd92f54c54785a76892a5b7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6edc187fbdad61643782e43cb3dad2664e040241", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea269da98515be9aa97a81600be483c293aee457", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3fdea5709efc2342950519678dccbfa5b6a5bc9", "width": 1080, "height": 720}], "variants": {}, "id": "2h6z0wcxfeyGYPsAUSLRq1EjtP-b9N_kgrbXZ-BV1x0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14r4v10", "is_robot_indexable": true, "report_reasons": null, "author": "tbrownlow", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r4v10/i_attempted_to_create_the_ultimate_guide_to_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r4v10/i_attempted_to_create_the_ultimate_guide_to_dbt/", "subreddit_subscribers": 114224, "created_utc": 1688547009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a Junior DE from Argentina and got contacted via LinkedIn for a DE position in a Miami based Fintech company called fivvy.\n\nThe interview went great, however at the very end the recruiter asked me to write by hand a brief description of myself and the value I would add to the company, sign it and send them a picture so they could asses my personality traits with graphology in lieu of a psychological evaluation.\n\nI am really confused, and considering pulling back from the recruiting process. But maybe it is a cultural thing and I am reading too much into it.\n\nThe role itself is very similar to what I do in my current job(AWS, ETL using glue, requirements gathering etc.) But the pay is roughly 80% more\n\n\nUpdate: thanks everyone for the insight, I rejected the request and told the company that I wasn't comfortable with a graphology evaluation, but also told them that I was still interested in the position and if they were still interested in my services I was open to other forms of psychological assessment.\n\nI just hope they don't start asking for my zodiac sign \ud83d\ude02", "author_fullname": "t2_11jrhn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common in the US to ask for a handwritten cover letter in DE(or at all)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rcq73", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688583759.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688568386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a Junior DE from Argentina and got contacted via LinkedIn for a DE position in a Miami based Fintech company called fivvy.&lt;/p&gt;\n\n&lt;p&gt;The interview went great, however at the very end the recruiter asked me to write by hand a brief description of myself and the value I would add to the company, sign it and send them a picture so they could asses my personality traits with graphology in lieu of a psychological evaluation.&lt;/p&gt;\n\n&lt;p&gt;I am really confused, and considering pulling back from the recruiting process. But maybe it is a cultural thing and I am reading too much into it.&lt;/p&gt;\n\n&lt;p&gt;The role itself is very similar to what I do in my current job(AWS, ETL using glue, requirements gathering etc.) But the pay is roughly 80% more&lt;/p&gt;\n\n&lt;p&gt;Update: thanks everyone for the insight, I rejected the request and told the company that I wasn&amp;#39;t comfortable with a graphology evaluation, but also told them that I was still interested in the position and if they were still interested in my services I was open to other forms of psychological assessment.&lt;/p&gt;\n\n&lt;p&gt;I just hope they don&amp;#39;t start asking for my zodiac sign \ud83d\ude02&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14rcq73", "is_robot_indexable": true, "report_reasons": null, "author": "IfThisThenWhat", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rcq73/is_it_common_in_the_us_to_ask_for_a_handwritten/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rcq73/is_it_common_in_the_us_to_ask_for_a_handwritten/", "subreddit_subscribers": 114224, "created_utc": 1688568386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). \n\nI get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. \n\nI have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). \n\nHow do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?", "author_fullname": "t2_pu047jjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Performance vs On-Prem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14quid6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688513977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). &lt;/p&gt;\n\n&lt;p&gt;I get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. &lt;/p&gt;\n\n&lt;p&gt;I have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). &lt;/p&gt;\n\n&lt;p&gt;How do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14quid6", "is_robot_indexable": true, "report_reasons": null, "author": "atlvernburn", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "subreddit_subscribers": 114224, "created_utc": 1688513977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7rg2eq0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg won the table format war: But not in the way you thought it might", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14rcaj9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XsYFMlNEZCDXJMqVj5ipNSy5AE0iyr_5rFyuLsdfKjQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688567397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bitsondatadev.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bitsondatadev.substack.com/p/iceberg-won-the-table-format-war", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?auto=webp&amp;v=enabled&amp;s=6b43e6782abb50094ef2d34a99021b60c20c639a", "width": 1080, "height": 1618}, "resolutions": [{"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e525d7b58e0d859466ef65335c697f07133fbe6c", "width": 108, "height": 161}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c941b71d9b3c6f5474c6bbdaa7dd20bd6aec5c2", "width": 216, "height": 323}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39f026b8f1273327c96114b4aa1a3482d371742d", "width": 320, "height": 479}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ad02b4e8ddf6f18a0a4bf17d725e4caa38d19e3", "width": 640, "height": 958}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=655ccbb038d6e012f114158f4c31150af8726079", "width": 960, "height": 1438}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b107211e8d9b291ec66e7691bf4b048f348c3d6", "width": 1080, "height": 1618}], "variants": {}, "id": "SDJCzYbCv7yEFiUYDPkYEbxyWOF93G9i_gU6hrmUfY4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rcaj9", "is_robot_indexable": true, "report_reasons": null, "author": "bitsondatadev", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rcaj9/iceberg_won_the_table_format_war_but_not_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bitsondatadev.substack.com/p/iceberg-won-the-table-format-war", "subreddit_subscribers": 114224, "created_utc": 1688567397.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently got a job after completing my Bachelors, as a trainee/junior data engineer in a Fintech , During my college times everyone was talking about SDE/backend/frontend/mobile-dev jobs and I have idea about them that a good developer can earn good with few years of experience.But Data engineering was unheard of and I knew a few things about data science and understood that these 2 are different .\n\nCan you help me by answering these 4 questions in short?\n(even yes /no answers will be appreciated)\n\n1.)Since the demand of Software developers is high and they are in demand everywhere, do data engineers have similar kind of demand in big MNCs and faang type companies.Since Data is increasing day by day and every co. I think would use them so this job profile should be hot but I haven't heard about this job till I got my current job offer.\n\n2.)I have explored frontend and backend web dev , and somewhat liked backend web dev using node js, and while practicing DSA and writing backend I started a liking towards programming, so do data engineers get to code enough ?\n\n3.) I got a basic intro to SQL in my college and then I didn't got much interested in it , so do you guys already have a interest in SQL when you choose Data engineer at first or you started enjoying it when you started working with it?\n\n4.)Can you share that salaries of software developer in your company vs your salary as a data engineer with same year of experience.Is there a huge difference or is it somewhat similar.", "author_fullname": "t2_jh44nvdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do data Engineers get paid Similar to software developers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14res9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688572706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently got a job after completing my Bachelors, as a trainee/junior data engineer in a Fintech , During my college times everyone was talking about SDE/backend/frontend/mobile-dev jobs and I have idea about them that a good developer can earn good with few years of experience.But Data engineering was unheard of and I knew a few things about data science and understood that these 2 are different .&lt;/p&gt;\n\n&lt;p&gt;Can you help me by answering these 4 questions in short?\n(even yes /no answers will be appreciated)&lt;/p&gt;\n\n&lt;p&gt;1.)Since the demand of Software developers is high and they are in demand everywhere, do data engineers have similar kind of demand in big MNCs and faang type companies.Since Data is increasing day by day and every co. I think would use them so this job profile should be hot but I haven&amp;#39;t heard about this job till I got my current job offer.&lt;/p&gt;\n\n&lt;p&gt;2.)I have explored frontend and backend web dev , and somewhat liked backend web dev using node js, and while practicing DSA and writing backend I started a liking towards programming, so do data engineers get to code enough ?&lt;/p&gt;\n\n&lt;p&gt;3.) I got a basic intro to SQL in my college and then I didn&amp;#39;t got much interested in it , so do you guys already have a interest in SQL when you choose Data engineer at first or you started enjoying it when you started working with it?&lt;/p&gt;\n\n&lt;p&gt;4.)Can you share that salaries of software developer in your company vs your salary as a data engineer with same year of experience.Is there a huge difference or is it somewhat similar.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14res9p", "is_robot_indexable": true, "report_reasons": null, "author": "micky_357000", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14res9p/do_data_engineers_get_paid_similar_to_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14res9p/do_data_engineers_get_paid_similar_to_software/", "subreddit_subscribers": 114224, "created_utc": 1688572706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. A query optimizer that is more effective than manual optimization\n2. Faster log queries with less storage space consumed\n3. 20 times higher concurrency\n4. Enhanced Data Lakehouse capabilities (more data sources supported and faster performance)\n5. A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios\n6. Efficient management of memory and CPU resources\n7. Elastic scaling of computation resources and hot-cold data separation for much lower storage costs\n8. Faster, stabler, and smarter data ingestion\n9. No more OOM errors\n10. Support for Kubernetes deployment\n\n[Release Note](https://doris.apache.org/docs/dev/releasenotes/release-2.0-beta/)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris 2.0 Beta Now Available: Faster, Stabler, and More Versatile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r8zo3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688559364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;A query optimizer that is more effective than manual optimization&lt;/li&gt;\n&lt;li&gt;Faster log queries with less storage space consumed&lt;/li&gt;\n&lt;li&gt;20 times higher concurrency&lt;/li&gt;\n&lt;li&gt;Enhanced Data Lakehouse capabilities (more data sources supported and faster performance)&lt;/li&gt;\n&lt;li&gt;A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios&lt;/li&gt;\n&lt;li&gt;Efficient management of memory and CPU resources&lt;/li&gt;\n&lt;li&gt;Elastic scaling of computation resources and hot-cold data separation for much lower storage costs&lt;/li&gt;\n&lt;li&gt;Faster, stabler, and smarter data ingestion&lt;/li&gt;\n&lt;li&gt;No more OOM errors&lt;/li&gt;\n&lt;li&gt;Support for Kubernetes deployment&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://doris.apache.org/docs/dev/releasenotes/release-2.0-beta/\"&gt;Release Note&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14r8zo3", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r8zo3/apache_doris_20_beta_now_available_faster_stabler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r8zo3/apache_doris_20_beta_now_available_faster_stabler/", "subreddit_subscribers": 114224, "created_utc": 1688559364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently migrating my new teams pipeline from databricks notebook (all in dev, no cicd, or major tests. scheduled in databricks. All spark.sql code, no pyspark at all.) to snowflake +dbt. \n\nWhile everything is going well, I want to create a local development environment everyone on my team can use easily (mostly non engineers). One of the main pain points is that 3/4 of my team has windows computers since they are analysts. \n\nBest way to do this is creating some devcontainers with VScode. And while I've already done this and it's working quite nice, I want to take it a few steps further and want to keep all the development inside VScode. For example, right now, I tests some queries in snowflake worksheets and when it works, I basically copy paste the query to vscode and change the table format to dbt (source or ref). This is a bit tedious for me and for my analysts it will be worse since they are use to get results instantly in databricks notebooks. \n\nIs there actually a better way of developing with dbt? can i possibly run a dbt model and get the query result inside vscode directly (without having to change table name)? \n\nAny other tips would be appreciated. \n\n&amp;#x200B;", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better VSCODE local dev with snowflake+dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r5j5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688549124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently migrating my new teams pipeline from databricks notebook (all in dev, no cicd, or major tests. scheduled in databricks. All spark.sql code, no pyspark at all.) to snowflake +dbt. &lt;/p&gt;\n\n&lt;p&gt;While everything is going well, I want to create a local development environment everyone on my team can use easily (mostly non engineers). One of the main pain points is that 3/4 of my team has windows computers since they are analysts. &lt;/p&gt;\n\n&lt;p&gt;Best way to do this is creating some devcontainers with VScode. And while I&amp;#39;ve already done this and it&amp;#39;s working quite nice, I want to take it a few steps further and want to keep all the development inside VScode. For example, right now, I tests some queries in snowflake worksheets and when it works, I basically copy paste the query to vscode and change the table format to dbt (source or ref). This is a bit tedious for me and for my analysts it will be worse since they are use to get results instantly in databricks notebooks. &lt;/p&gt;\n\n&lt;p&gt;Is there actually a better way of developing with dbt? can i possibly run a dbt model and get the query result inside vscode directly (without having to change table name)? &lt;/p&gt;\n\n&lt;p&gt;Any other tips would be appreciated. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r5j5q", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r5j5q/better_vscode_local_dev_with_snowflakedbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r5j5q/better_vscode_local_dev_with_snowflakedbt/", "subreddit_subscribers": 114224, "created_utc": 1688549124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I wanna read the Kimball books as I've seen them mentioned many times as being a great source of quality information about how to do things.\n\nI see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling\n\nThe Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses\n\nThe Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data\n\n\nShould I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.\n\nThanks a lot guys. Really appreciate the help you've all been", "author_fullname": "t2_p5wlf0g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Kimball to Start with", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qusqd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688514805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I wanna read the Kimball books as I&amp;#39;ve seen them mentioned many times as being a great source of quality information about how to do things.&lt;/p&gt;\n\n&lt;p&gt;I see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data&lt;/p&gt;\n\n&lt;p&gt;Should I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot guys. Really appreciate the help you&amp;#39;ve all been&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qusqd", "is_robot_indexable": true, "report_reasons": null, "author": "El_Cato_Crande", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "subreddit_subscribers": 114224, "created_utc": 1688514805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_11542k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implement AI data pipelines with Langchain, Airbyte, and Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_14rhh9l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yWcVfn-tLMgAI7K286VmrEybc86CmyhunF3lTZ9hgxY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688578305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/tutorials/implement-ai-data-pipelines-with-langchain-airbyte-and-dagster", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?auto=webp&amp;v=enabled&amp;s=1af6048fcc13938bfecab53fb0e90911c070be09", "width": 1000, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88dd319e2433f7c5a955b28528634d479371c768", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c013286161a3276a638993530a3045d0cc05b0ee", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66581eb66efeccbe1086349b85b378a8e9b5f5cd", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8363a081c698d1000e4e4fcabfacf1b1ea9e2c80", "width": 640, "height": 401}, {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7028277736d139a2066ccffb094c7efa4a56baba", "width": 960, "height": 602}], "variants": {}, "id": "6UwY4HhvOQZGtlu_FO200MjNRPVvIqZC_OnXRYlDO6Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rhh9l", "is_robot_indexable": true, "report_reasons": null, "author": "jeanlaf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rhh9l/implement_ai_data_pipelines_with_langchain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/tutorials/implement-ai-data-pipelines-with-langchain-airbyte-and-dagster", "subreddit_subscribers": 114224, "created_utc": 1688578305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I plan on starting a simple ETL pipeline using Airflow and Kafka and want your guys' opinion on what I plan to do.\n\nI am using the [random user API](https://randomuser.me/api/) to get the data, then performing a simple transformation to prepare it to be put into its respective tables. I plan to simulate spikes of user data generating using a random number generator via Airflow and then pass the data into Kafka using producer nodes. Then I can put the data into a PostgreSQL RDS instance for the data to be stored. I know I don't need to use Kafka, but I want to dabble in Kafka a little to gain some experience. On the note of experience, I know the basic jist of Kafka and Airflow, but I am by no means an expert on either of them; I want to apply the knowledge I have learned so far.\n\nHere is what the DAG would look like:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64\n\n&amp;#x200B;\n\nHere is what the data model would look like:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=655c0eb2d4f5f1034199871f479cec86029f4446\n\n&amp;#x200B;\n\nHere is my [GitHub](https://github.com/Nishal3/) if you want to see and critique my other projects.", "author_fullname": "t2_3arqiq34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Data Engineering Project with Kafka and Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 12, "top_awarded_type": null, "hide_score": false, "media_metadata": {"01epxslza6ab1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 9, "x": 108, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84e4414faacf34bab670573e90939bdf706d18e1"}, {"y": 18, "x": 216, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=638e7a75ac5361579e82a258453133cc6bb18245"}, {"y": 27, "x": 320, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f41f67c8d53ce2403756a59203cb07d28fb133b3"}, {"y": 55, "x": 640, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2c65ddfd03037ac0117eadca4ed0310c03e95e2"}, {"y": 82, "x": 960, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1f20926c6a1b3f7acf25c82333fed1b77c2be9c"}], "s": {"y": 90, "x": 1046, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64"}, "id": "01epxslza6ab1"}, "varxvs70b6ab1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80356744fcd1539a924fc938c05d34ab0098fb43"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce5190fbb4f8d074f3ec88f32897b45d352f0b36"}, {"y": 150, "x": 320, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd7b29c7290da1333ea6980cb8dad64c1b7f77db"}, {"y": 300, "x": 640, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3661598793f34af557ac951512f8c1486ec27453"}, {"y": 451, "x": 960, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1eb10957b2ddb649302821ce8e0ddad18052fbad"}, {"y": 507, "x": 1080, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2804a9739228cac3bda0cfebce10aeb95db00c47"}], "s": {"y": 564, "x": 1200, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=655c0eb2d4f5f1034199871f479cec86029f4446"}, "id": "varxvs70b6ab1"}}, "name": "t3_14rfp9v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eZcC3yPDi1xZFKdBoki8y5_BheHkwheH-I60n_qWzxI.jpg", "edited": 1688577655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688574605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I plan on starting a simple ETL pipeline using Airflow and Kafka and want your guys&amp;#39; opinion on what I plan to do.&lt;/p&gt;\n\n&lt;p&gt;I am using the &lt;a href=\"https://randomuser.me/api/\"&gt;random user API&lt;/a&gt; to get the data, then performing a simple transformation to prepare it to be put into its respective tables. I plan to simulate spikes of user data generating using a random number generator via Airflow and then pass the data into Kafka using producer nodes. Then I can put the data into a PostgreSQL RDS instance for the data to be stored. I know I don&amp;#39;t need to use Kafka, but I want to dabble in Kafka a little to gain some experience. On the note of experience, I know the basic jist of Kafka and Airflow, but I am by no means an expert on either of them; I want to apply the knowledge I have learned so far.&lt;/p&gt;\n\n&lt;p&gt;Here is what the DAG would look like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64\"&gt;https://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is what the data model would look like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=655c0eb2d4f5f1034199871f479cec86029f4446\"&gt;https://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=655c0eb2d4f5f1034199871f479cec86029f4446&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is my &lt;a href=\"https://github.com/Nishal3/\"&gt;GitHub&lt;/a&gt; if you want to see and critique my other projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rfp9v", "is_robot_indexable": true, "report_reasons": null, "author": "RepresentativePen297", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rfp9v/beginner_data_engineering_project_with_kafka_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rfp9v/beginner_data_engineering_project_with_kafka_and/", "subreddit_subscribers": 114224, "created_utc": 1688574605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Make Your Data Ingestion Simple, Fast, And Robust - 11 Advanced best practices for working with data ingestion pipelines.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_14r4zcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l9qusAuLPw7VDO87OQ_ds_wMR85zOD0Cha7Av6hEh6c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688547389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "meltano.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://meltano.com/blog/how-to-make-your-data-ingestion-simple-fast-and-robust/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?auto=webp&amp;v=enabled&amp;s=7720628d9a0212948420b874d2e71fc85101c13b", "width": 1440, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ef88de54f10d16905227ea609f981d8a2db7058", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d56d7b3a0d68c53284e6568ac0810f27fd4d07a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a253637116c25aad58aba1391cfc1fc2359b9f6", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36478f2a1f13ba7b3e80fff977e3465cd0f1f155", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26032ee0e078c185a78e5530051273f586a69b79", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cca4f827fe0072829e77e25a7c5923100f7b9fbd", "width": 1080, "height": 810}], "variants": {}, "id": "DfcrVMfetugEAM3zA9zmoKT9fQhKdRUq7Wgvmj4oU5k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14r4zcp", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r4zcp/how_to_make_your_data_ingestion_simple_fast_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://meltano.com/blog/how-to-make-your-data-ingestion-simple-fast-and-robust/", "subreddit_subscribers": 114224, "created_utc": 1688547389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone, \n\nWhat is the best resources for understanding how to build out a pipeline from scratch. I'm currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.\n\nIt had me thinking if I was to get the job I wouldn't know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.\n\nI figured I should get started now since it's always good to learn things start to finish.\n\nAny resources you could provide would be great (books, articles, other post, ect...)\n\nThanks in advance!", "author_fullname": "t2_5ejp13jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering start to finish", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzi8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688529422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone, &lt;/p&gt;\n\n&lt;p&gt;What is the best resources for understanding how to build out a pipeline from scratch. I&amp;#39;m currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.&lt;/p&gt;\n\n&lt;p&gt;It had me thinking if I was to get the job I wouldn&amp;#39;t know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.&lt;/p&gt;\n\n&lt;p&gt;I figured I should get started now since it&amp;#39;s always good to learn things start to finish.&lt;/p&gt;\n\n&lt;p&gt;Any resources you could provide would be great (books, articles, other post, ect...)&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qzi8p", "is_robot_indexable": true, "report_reasons": null, "author": "knowledgeMeUp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "subreddit_subscribers": 114224, "created_utc": 1688529422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can we streamline the process of understanding source data? Frequently, questions like \"What business process generates this data and why?\" require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.\n\nTypically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.\n\nAny advice to make this better?", "author_fullname": "t2_55thi7w8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I ensure that my data model accurately represents the data in my OLAP DB? How can I be certain that my DIM and FACT tables effectively capture the business workflow, leading to optimized and efficient queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qvo0e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688517373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can we streamline the process of understanding source data? Frequently, questions like &amp;quot;What business process generates this data and why?&amp;quot; require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.&lt;/p&gt;\n\n&lt;p&gt;Typically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.&lt;/p&gt;\n\n&lt;p&gt;Any advice to make this better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qvo0e", "is_robot_indexable": true, "report_reasons": null, "author": "faizfablillah", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "subreddit_subscribers": 114224, "created_utc": 1688517373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Data Engineers,\n\nWe recently [announced](https://www.reddit.com/r/dataengineering/comments/14dgupv/new_de_community_looking_for_mods/) that we would be opening up a new community for data engineering professionals to network and join in-person events. We had over 300+ signups on the waitlist with data engineers from over 33 countries. We've sent out emails to everyone on the waitlist - if you didn't receive an email, please check your spam folder or reach out to info@dataengineering.wiki.\n\nWe are now generally accepting members and you can [join here](https://community.dataengineering.wiki/). \ud83e\udd73\n\n&amp;#x200B;\n\n[This could be you](https://i.redd.it/7t1ig7dlf6ab1.gif)\n\nWe've had a lot of offers to help out and we've put together a few ways you can get involved in the professional community. If you're interested in any of these, please message the mod team:\n\n1. **Volunteer to speak:** we are putting together some local and virtual meetups and are looking for speakers to share something they are passionate about.\n2. **Help organize a meetup:** if you're interested in starting a local meetup in your area let us know and we can connect you with speakers and resources to help you get it started.\n3. **Join as an existing meetup:** we can create a space just for your local area which you can customize and use for free to operate your existing meetup.\n4. **Contribute to our newsletter:** we run a free monthly newsletter and are always looking for interesting ideas to share.\n5. **Share your story:** share your written story about how you got to where you are today and give advice and inspire others who might want to take the same path.\n6. **Share your feedback:** most importantly, we need your feedback to keep improving this community. If you would be willing to leave us a review that we can use externally, please let us know!\n\nAs always, we are listening to your feedback and using it to shape the community and we cannot do it without you. Thank you to everyone who has offered their time, help, and expertise to make our community great.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Professional Data Engineering Community", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7t1ig7dlf6ab1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/7t1ig7dlf6ab1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=c0824e0a9dd0c41e701f9b59130398d415814e74"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/7t1ig7dlf6ab1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=bd846bacdb14cd24a6a23be46392e1e3faace672"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/7t1ig7dlf6ab1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=ed8eb361cb9119cb29387cb047bc9befa992df4d"}], "s": {"y": 270, "gif": "https://i.redd.it/7t1ig7dlf6ab1.gif", "mp4": "https://preview.redd.it/7t1ig7dlf6ab1.gif?format=mp4&amp;v=enabled&amp;s=e337a1528c70290c68f4827092d5ebcb097201a0", "x": 480}, "id": "7t1ig7dlf6ab1"}}, "name": "t3_14rguyt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/-USL2EfsHXULEhtptOG1XKYcO-1oop69-iMrWTy__88.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688577029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;We recently &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14dgupv/new_de_community_looking_for_mods/\"&gt;announced&lt;/a&gt; that we would be opening up a new community for data engineering professionals to network and join in-person events. We had over 300+ signups on the waitlist with data engineers from over 33 countries. We&amp;#39;ve sent out emails to everyone on the waitlist - if you didn&amp;#39;t receive an email, please check your spam folder or reach out to &lt;a href=\"mailto:info@dataengineering.wiki\"&gt;info@dataengineering.wiki&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;We are now generally accepting members and you can &lt;a href=\"https://community.dataengineering.wiki/\"&gt;join here&lt;/a&gt;. \ud83e\udd73&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/7t1ig7dlf6ab1.gif\"&gt;This could be you&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve had a lot of offers to help out and we&amp;#39;ve put together a few ways you can get involved in the professional community. If you&amp;#39;re interested in any of these, please message the mod team:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Volunteer to speak:&lt;/strong&gt; we are putting together some local and virtual meetups and are looking for speakers to share something they are passionate about.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Help organize a meetup:&lt;/strong&gt; if you&amp;#39;re interested in starting a local meetup in your area let us know and we can connect you with speakers and resources to help you get it started.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Join as an existing meetup:&lt;/strong&gt; we can create a space just for your local area which you can customize and use for free to operate your existing meetup.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Contribute to our newsletter:&lt;/strong&gt; we run a free monthly newsletter and are always looking for interesting ideas to share.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Share your story:&lt;/strong&gt; share your written story about how you got to where you are today and give advice and inspire others who might want to take the same path.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Share your feedback:&lt;/strong&gt; most importantly, we need your feedback to keep improving this community. If you would be willing to leave us a review that we can use externally, please let us know!&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;As always, we are listening to your feedback and using it to shape the community and we cannot do it without you. Thank you to everyone who has offered their time, help, and expertise to make our community great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5d8a87e8-a952-11eb-9a8a-0e3979f03641", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "14rguyt", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rguyt/professional_data_engineering_community/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/14rguyt/professional_data_engineering_community/", "subreddit_subscribers": 114224, "created_utc": 1688577029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data processing becomes critical when training a robust machine learning model. We occasionally need to restructure and add new data to the datasets to increase the efficiency of the data.\n\nWe'll look at how to combine multiple datasets and merge multiple datasets with the same and different column names in this article. We'll use the `pandas` library's following functions to carry out these operations.\n\n* `pandas.concat()`\n* `pandas.merge()`\n* `pandas.DataFrame.join()`\n\nThe `concat()` function in `pandas` is a go-to option for combining the DataFrames due to its simplicity. However, if we want more control over how the data is joined and on which column in the DataFrame, the `merge()` function is a good choice. If we want to join data based on the index, we should use the `join()` method.\n\n**Here is the guide for performing the joining, merging, and combining multiple datasets using pandas\ud83d\udc47\ud83d\udc47\ud83d\udc47**\n\n[Join, Merge, and Combine Multiple Datasets Using pandas](https://geekpython.in/multiple-datasets-integration-using-pandas)", "author_fullname": "t2_pb3nzmce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Join, Merge, and Combine Multiple Datasets Using pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rfc42", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688573885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data processing becomes critical when training a robust machine learning model. We occasionally need to restructure and add new data to the datasets to increase the efficiency of the data.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ll look at how to combine multiple datasets and merge multiple datasets with the same and different column names in this article. We&amp;#39;ll use the &lt;code&gt;pandas&lt;/code&gt; library&amp;#39;s following functions to carry out these operations.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;pandas.concat()&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;pandas.merge()&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;pandas.DataFrame.join()&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The &lt;code&gt;concat()&lt;/code&gt; function in &lt;code&gt;pandas&lt;/code&gt; is a go-to option for combining the DataFrames due to its simplicity. However, if we want more control over how the data is joined and on which column in the DataFrame, the &lt;code&gt;merge()&lt;/code&gt; function is a good choice. If we want to join data based on the index, we should use the &lt;code&gt;join()&lt;/code&gt; method.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here is the guide for performing the joining, merging, and combining multiple datasets using pandas\ud83d\udc47\ud83d\udc47\ud83d\udc47&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://geekpython.in/multiple-datasets-integration-using-pandas\"&gt;Join, Merge, and Combine Multiple Datasets Using pandas&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?auto=webp&amp;v=enabled&amp;s=a86eb9301b61fa532a6d31f179f928edeac5c80f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d24a3db04a0e4fc4a34d774000d20ee3771c1662", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8028e69481dcd025a846db21a926b6b68b0a0ec6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ab601003583d9a1723acb0c83e7410f66d07c0a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25157b9375bd2ae56788ea4f0c9a96d2e8324291", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=079aa6053c57cbf1981b753528aba55790fc8cf8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7537826672a08f63baec8c917ad34c6f6e1c0b4", "width": 1080, "height": 567}], "variants": {}, "id": "gRfQV35yrH1dVxSBfhVGiluToaN_lKvBv96jgo5GOSQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rfc42", "is_robot_indexable": true, "report_reasons": null, "author": "python4geeks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rfc42/join_merge_and_combine_multiple_datasets_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rfc42/join_merge_and_combine_multiple_datasets_using/", "subreddit_subscribers": 114224, "created_utc": 1688573885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like your opinion of the Python library Dask. \n\nI made some tests with several datasets with a total of 8 GB and it performed a simple ETL process in 30 sec. \n\nI did the same process wit PySpark and it took 28 sec.  \nI also found this article talking about Spark vs Dask  \n[https://www.coiled.io/blog/moving-from-spark-to-dask](https://www.coiled.io/blog/moving-from-spark-to-dask) \n\nIs Dask that good to handle middle to big-size datasets?   \nThen why is a library not that well known? \n\n&amp;#x200B;", "author_fullname": "t2_7dy3sswp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dask for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r8spe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688558832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like your opinion of the Python library Dask. &lt;/p&gt;\n\n&lt;p&gt;I made some tests with several datasets with a total of 8 GB and it performed a simple ETL process in 30 sec. &lt;/p&gt;\n\n&lt;p&gt;I did the same process wit PySpark and it took 28 sec.&lt;br/&gt;\nI also found this article talking about Spark vs Dask&lt;br/&gt;\n&lt;a href=\"https://www.coiled.io/blog/moving-from-spark-to-dask\"&gt;https://www.coiled.io/blog/moving-from-spark-to-dask&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Is Dask that good to handle middle to big-size datasets?&lt;br/&gt;\nThen why is a library not that well known? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?auto=webp&amp;v=enabled&amp;s=985e0dac5a538651a27facacb88f439ffb706ab1", "width": 2049, "height": 1077}, "resolutions": [{"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b34463d6ffa31246495a19a91c892ec7bcc23ca7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e21104286c21d66fefead2c53a4995959da5675", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbd23e1c247e5be5adc30c6ce5cee34b97b4c220", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bcceb6db91e2355af81f4ae2f3b9e7bf02148b80", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d8fede23f3d1fd2fc38a01ec8fd06bed011bbf6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa5d248f3a623fcc480dc7d3b25f4cdf1690212b", "width": 1080, "height": 567}], "variants": {}, "id": "f7eK9VqpVNGVOYBwzqp50W4KQEUY3gbUPuEbkbhVvp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r8spe", "is_robot_indexable": true, "report_reasons": null, "author": "Asleep-Organization7", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r8spe/dask_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r8spe/dask_for_data_engineering/", "subreddit_subscribers": 114224, "created_utc": 1688558832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. \n\nThese data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?", "author_fullname": "t2_dg51ak2mn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "user identity, machine identity and now we need data identity ? what do you think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qws59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688520815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. &lt;/p&gt;\n\n&lt;p&gt;These data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qws59", "is_robot_indexable": true, "report_reasons": null, "author": "Extreme-Summer-2756", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "subreddit_subscribers": 114224, "created_utc": 1688520815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Every Major Announcement at Snowflake Summit 2023 and 1 Word Never Mentioned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": true, "name": "t3_14roylf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dReVV7G2VUQpzoOs4ibJgMNunvywct2RJX65zpfGl7E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688594696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/summit-2023", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?auto=webp&amp;v=enabled&amp;s=0352906f85b88e570a23caff7459e8ca8bb0a199", "width": 1200, "height": 681}, "resolutions": [{"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6b003ba5cc8d94470bd887537a884fff3897135", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6662a48c2d494b2178152935027a7126d71a9bb", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6c508cc66d9646c54c0776562f119623378c10e", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7651f62818d66a56e3cf767344f092785aca2621", "width": 640, "height": 363}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=849a4f468e289eaa1761c390c88c168f543e2814", "width": 960, "height": 544}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64f89276363ebd2c3537c4f7cc0ec646bb5da275", "width": 1080, "height": 612}], "variants": {}, "id": "iG_2gOkQJ7vEPRvHmIKIANcgo69jtGBrPK32a06sAtc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14roylf", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14roylf/every_major_announcement_at_snowflake_summit_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/summit-2023", "subreddit_subscribers": 114224, "created_utc": 1688594696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My organization is trying to modernize and have put an unfortunate soul (me) in charge of creating a CI/CD pipeline for our products. Our goal is to use Jenkins to communicate via Webhooks from our DevOps platform, but there's been a number of roadblocks given our IT infrastructure. I've also had some trouble communicating *why* CI/CD is important.\n\nI'm curious what others have experienced in setting up a CI/CD platform.", "author_fullname": "t2_98rrwspa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a CI/CD pipeline difficult to set up in your experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rmmkp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688589964.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688589545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My organization is trying to modernize and have put an unfortunate soul (me) in charge of creating a CI/CD pipeline for our products. Our goal is to use Jenkins to communicate via Webhooks from our DevOps platform, but there&amp;#39;s been a number of roadblocks given our IT infrastructure. I&amp;#39;ve also had some trouble communicating &lt;em&gt;why&lt;/em&gt; CI/CD is important.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious what others have experienced in setting up a CI/CD platform.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rmmkp", "is_robot_indexable": true, "report_reasons": null, "author": "what_duck", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14rmmkp/is_a_cicd_pipeline_difficult_to_set_up_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rmmkp/is_a_cicd_pipeline_difficult_to_set_up_in_your/", "subreddit_subscribers": 114224, "created_utc": 1688589545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe are starting a new team to work don data engineering/data warehouse at my current company. Over the last couple of weeks, I am doing lot of reading to identify a correct tech stack.\n\nConsiderations:\n\n1. Our DB is in the range of couple of hundred GBs, not huge in terms of TBs\n2. In the short future, we would want to get started with reporting (BI) with an eye on Data Science/ML later \n3. We're an AWS heavy shop. So naturally, our first consideration is RedShift.\n\nDuring my short research, I have heard good things about SnowFlake and Redshift seems to be underwhelming as data warehouse. But, considering our data size and cost, I'm not sure Snowflake would be a good choice for us.\n\nSo any suggestions on the techstack (building ETL pipeline, orchestration tools, data warehouse with ability or providing supportive tools to build self serving reports) would be greatly appreciated.\n\nThank you", "author_fullname": "t2_2gcm7kx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with choosing techstack for a new DE team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rildp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688580682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We are starting a new team to work don data engineering/data warehouse at my current company. Over the last couple of weeks, I am doing lot of reading to identify a correct tech stack.&lt;/p&gt;\n\n&lt;p&gt;Considerations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Our DB is in the range of couple of hundred GBs, not huge in terms of TBs&lt;/li&gt;\n&lt;li&gt;In the short future, we would want to get started with reporting (BI) with an eye on Data Science/ML later &lt;/li&gt;\n&lt;li&gt;We&amp;#39;re an AWS heavy shop. So naturally, our first consideration is RedShift.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;During my short research, I have heard good things about SnowFlake and Redshift seems to be underwhelming as data warehouse. But, considering our data size and cost, I&amp;#39;m not sure Snowflake would be a good choice for us.&lt;/p&gt;\n\n&lt;p&gt;So any suggestions on the techstack (building ETL pipeline, orchestration tools, data warehouse with ability or providing supportive tools to build self serving reports) would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rildp", "is_robot_indexable": true, "report_reasons": null, "author": "sasu1992", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rildp/help_with_choosing_techstack_for_a_new_de_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rildp/help_with_choosing_techstack_for_a_new_de_team/", "subreddit_subscribers": 114224, "created_utc": 1688580682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3ve2psi7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to ingest records from Cosmos DB using Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14rg8sp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K9HWxxNow5rZ1qHfE85vs6WW8VUI2Nepbluw3PUw1JA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688575754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "harshmatharu.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://harshmatharu.com/blog/ingest-records-from-cosmosdb-using-spark", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?auto=webp&amp;v=enabled&amp;s=1de2aca917b90b3cc72b9ff239383268a0dc0b51", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74737eb465d78c5776ace82d6198ea07b3974837", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a58e0d510f9fd695ba5af32714ed3d876300827", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcfa83755ef2e572549fcfcf59e6cad69dd4e958", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eca423e4ee6c122e76905f0c73a2367123a7005f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bac243d049140155ee5fbcb7bf090bf78b39c170", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1760d0644c4d83951578a257fb8666dce146b79", "width": 1080, "height": 540}], "variants": {}, "id": "A8iVhGJK0JkIk30sZdO6ZQLeU7OXOeoPiLa7dFQ7U0M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rg8sp", "is_robot_indexable": true, "report_reasons": null, "author": "Dramatic_Necessary_3", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rg8sp/how_to_ingest_records_from_cosmos_db_using_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://harshmatharu.com/blog/ingest-records-from-cosmosdb-using-spark", "subreddit_subscribers": 114224, "created_utc": 1688575754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm currently working on a project to demonstrate my ability to develop end-to-end data pipelines. I'm wondering if there are any skills or tools that I may have overlooked. Currently, my process involves the following components:\n\n* I utilize Airflow as the orchestrator, which retrieves data from an online API.\n* Next, I perform data transformations using Spark.\n* The transformed data is then loaded into a PostgreSQL database.\n* I create various views from this data using PostgreSQL.\n* Finally, I use Grafana to automatically generate and display dashboards based on the views. \n* All of these components are implemented using Docker containers.\n\n1) Is there anything essential to the data engineer position that I may have omitted? Could you show the logic of your typical end-to-end data pipeline and what tech-stack do you use to do it?\n\n2) What's the best practice or ideal data pipeline/tech stack?\n\n3) How is your performance (data engineers) typically measured? (e.g. By the number of pipelines done?)", "author_fullname": "t2_3vzap1d5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Showcasing Complete ETL Pipeline Skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rcg9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688567760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a project to demonstrate my ability to develop end-to-end data pipelines. I&amp;#39;m wondering if there are any skills or tools that I may have overlooked. Currently, my process involves the following components:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I utilize Airflow as the orchestrator, which retrieves data from an online API.&lt;/li&gt;\n&lt;li&gt;Next, I perform data transformations using Spark.&lt;/li&gt;\n&lt;li&gt;The transformed data is then loaded into a PostgreSQL database.&lt;/li&gt;\n&lt;li&gt;I create various views from this data using PostgreSQL.&lt;/li&gt;\n&lt;li&gt;Finally, I use Grafana to automatically generate and display dashboards based on the views. &lt;/li&gt;\n&lt;li&gt;All of these components are implemented using Docker containers.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;1) Is there anything essential to the data engineer position that I may have omitted? Could you show the logic of your typical end-to-end data pipeline and what tech-stack do you use to do it?&lt;/p&gt;\n\n&lt;p&gt;2) What&amp;#39;s the best practice or ideal data pipeline/tech stack?&lt;/p&gt;\n\n&lt;p&gt;3) How is your performance (data engineers) typically measured? (e.g. By the number of pipelines done?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rcg9h", "is_robot_indexable": true, "report_reasons": null, "author": "conlake", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rcg9h/showcasing_complete_etl_pipeline_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rcg9h/showcasing_complete_etl_pipeline_skills/", "subreddit_subscribers": 114224, "created_utc": 1688567760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, wanted a second opinion on if this idea is one of those picking up a penny in front of a steam roller things. We are limited to using lambda to make an api call to trino and step functions as the orchestrator\n\nOption 1 - Explicit \n\n    Step function Task 1(Trino Transformation 1) &gt; Task 2(TT2) &gt; Task 3(TT3) \n\nOption 2 - \"recursion\" \n\n    Trigger(send step ID) &gt; Recursive Task(output next step Id), rerun function until end state is reached. \n\nWhat kind safeguard should I put in place to prevent infinite recursion? \n\nThanks!", "author_fullname": "t2_8lbog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a bad idea? Using \"recursion\" in AWS step functions to orchestrate sequential trino steps instead of explicitly assigning every step to a task.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rbu13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688566655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688566372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, wanted a second opinion on if this idea is one of those picking up a penny in front of a steam roller things. We are limited to using lambda to make an api call to trino and step functions as the orchestrator&lt;/p&gt;\n\n&lt;p&gt;Option 1 - Explicit &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Step function Task 1(Trino Transformation 1) &amp;gt; Task 2(TT2) &amp;gt; Task 3(TT3) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Option 2 - &amp;quot;recursion&amp;quot; &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Trigger(send step ID) &amp;gt; Recursive Task(output next step Id), rerun function until end state is reached. \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;What kind safeguard should I put in place to prevent infinite recursion? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rbu13", "is_robot_indexable": true, "report_reasons": null, "author": "AUGcodon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rbu13/is_this_a_bad_idea_using_recursion_in_aws_step/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rbu13/is_this_a_bad_idea_using_recursion_in_aws_step/", "subreddit_subscribers": 114224, "created_utc": 1688566372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently stumbled on a job opportunity that uses Oracle data integrator. As someone who is 'at home' with Oracle, seemed intriguing, but then I checked market share and found Informatica has much greater market share...   \n\n\non the other hand, I am more fond of 'hands-on tools', like writing scripts by myself, not utilizing any kind of GUI.   \nWhat is the relevance and prospects of tools like ODI and/or Informatica, and even Oracle's GoldenGate vs Spark and others?  \n\n\nwhen talking about this, obviously, I am talking about big corporate clients with some regulations and needs for support, etc etc..", "author_fullname": "t2_bnm2tai1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Informatica vs. Oracle Data Integrator vs Oracle GoldenGate vs others (Spark, Python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r6ltr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688552385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently stumbled on a job opportunity that uses Oracle data integrator. As someone who is &amp;#39;at home&amp;#39; with Oracle, seemed intriguing, but then I checked market share and found Informatica has much greater market share...   &lt;/p&gt;\n\n&lt;p&gt;on the other hand, I am more fond of &amp;#39;hands-on tools&amp;#39;, like writing scripts by myself, not utilizing any kind of GUI.&lt;br/&gt;\nWhat is the relevance and prospects of tools like ODI and/or Informatica, and even Oracle&amp;#39;s GoldenGate vs Spark and others?  &lt;/p&gt;\n\n&lt;p&gt;when talking about this, obviously, I am talking about big corporate clients with some regulations and needs for support, etc etc..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r6ltr", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Cancel_7891", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r6ltr/informatica_vs_oracle_data_integrator_vs_oracle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r6ltr/informatica_vs_oracle_data_integrator_vs_oracle/", "subreddit_subscribers": 114224, "created_utc": 1688552385.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}