{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a small firm that is about thirty years behind in tech.  All of our data is in spreadsheets scattered across a vast and confusing folder tree. We are looking to use alteryx as a no-code ETL and eventually creating an azure database. I noticed most DEs use dagster or airflow. Does anybody have experience with a no code tool like Alteryx? I worry no-code equates to no flexibility", "author_fullname": "t2_4euwn6ok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody use Alteryx", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qi60z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688484263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a small firm that is about thirty years behind in tech.  All of our data is in spreadsheets scattered across a vast and confusing folder tree. We are looking to use alteryx as a no-code ETL and eventually creating an azure database. I noticed most DEs use dagster or airflow. Does anybody have experience with a no code tool like Alteryx? I worry no-code equates to no flexibility&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qi60z", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Enthusiasm-6194", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qi60z/anybody_use_alteryx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qi60z/anybody_use_alteryx/", "subreddit_subscribers": 114104, "created_utc": 1688484263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am the only DE in the team, and we want to hire a senior DE soon. My manager has asked me to interview somebody with ~20 years of experience in data engineering while I have only ~4 YOE as a data engineer. When I looked at this candidate\u2019s resume, I got overwhelmed by the expertise they claimed to have. I feel I don\u2019t have enough knowledge to accurately assess this candidate. How should I go about interviewing this candidate? What sort of questions should I ask?", "author_fullname": "t2_cbdg7n9sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should you interview somebody with vastly more experience than yourself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qslvf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688508789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the only DE in the team, and we want to hire a senior DE soon. My manager has asked me to interview somebody with ~20 years of experience in data engineering while I have only ~4 YOE as a data engineer. When I looked at this candidate\u2019s resume, I got overwhelmed by the expertise they claimed to have. I feel I don\u2019t have enough knowledge to accurately assess this candidate. How should I go about interviewing this candidate? What sort of questions should I ask?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14qslvf", "is_robot_indexable": true, "report_reasons": null, "author": "fun_coordinator", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qslvf/how_should_you_interview_somebody_with_vastly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qslvf/how_should_you_interview_somebody_with_vastly/", "subreddit_subscribers": 114104, "created_utc": 1688508789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have DE interview coming up  and I am thinking to prepare few questions based on handling ETL errors.\n\nA data pipeline should address these issues:\n\n1\u00b7 Partial loads (A scenarios where Partial processing of the files or records or any failures of ETL Jobs occurred; to clean up a few records and re-run the job)\n\n&amp;#x200B;\n\n2 \u00b7 Restart-ability (You have to re-run from a previous successful run because a downstream dependent job failed or reprocess process some data from history. for e.g. We need to run since last Monday or a random date)\n\n&amp;#x200B;\n\n3\u00b7 Re-processing the same files (A source issue where they sent multiple files; We need to pick the right records)\n\n&amp;#x200B;\n\n4 \u00b7 Catch-up loads (In case you missed executing jobs for specific runs and playing catch up; Batch Processing) .\n\nAny Answers on these would be super helpful. Thanks. \ud83d\ude4f ", "author_fullname": "t2_c4v6qwrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Interview question for handling ETL pipeline errors.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qiuds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688485836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have DE interview coming up  and I am thinking to prepare few questions based on handling ETL errors.&lt;/p&gt;\n\n&lt;p&gt;A data pipeline should address these issues:&lt;/p&gt;\n\n&lt;p&gt;1\u00b7 Partial loads (A scenarios where Partial processing of the files or records or any failures of ETL Jobs occurred; to clean up a few records and re-run the job)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2 \u00b7 Restart-ability (You have to re-run from a previous successful run because a downstream dependent job failed or reprocess process some data from history. for e.g. We need to run since last Monday or a random date)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;3\u00b7 Re-processing the same files (A source issue where they sent multiple files; We need to pick the right records)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;4 \u00b7 Catch-up loads (In case you missed executing jobs for specific runs and playing catch up; Batch Processing) .&lt;/p&gt;\n\n&lt;p&gt;Any Answers on these would be super helpful. Thanks. \ud83d\ude4f &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14qiuds", "is_robot_indexable": true, "report_reasons": null, "author": "HealthyCobbler1588", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qiuds/de_interview_question_for_handling_etl_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qiuds/de_interview_question_for_handling_etl_pipeline/", "subreddit_subscribers": 114104, "created_utc": 1688485836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Link: https://trello.com/b/Rvw8Jygt/interview-preparation\n\nI have been looking for entry level or junior data engineering roles, and have been using a Trello board to help with interview preparation.\n\nIt contains lists of common interview questions, technical questions, and behavioural questions.\n\nI\u2019ve tried tagging behavioural questions based on attribute it\u2019s measuring (e.g., conflict management) so you can filter by these.\n\nFor the technical questions, these are a combination of questions I\u2019ve been asked, or questions you could be asked if applying for a data engineering or analyst role.\n\nFor each card/question you can write potential answers in the description field.\n\nYou can obviously customise it however you like, but hopefully is useful for some of you", "author_fullname": "t2_osh2xtjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created an interview preparation Trello template with technical &amp; behavioural questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ql6jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688491177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Link: &lt;a href=\"https://trello.com/b/Rvw8Jygt/interview-preparation\"&gt;https://trello.com/b/Rvw8Jygt/interview-preparation&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have been looking for entry level or junior data engineering roles, and have been using a Trello board to help with interview preparation.&lt;/p&gt;\n\n&lt;p&gt;It contains lists of common interview questions, technical questions, and behavioural questions.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried tagging behavioural questions based on attribute it\u2019s measuring (e.g., conflict management) so you can filter by these.&lt;/p&gt;\n\n&lt;p&gt;For the technical questions, these are a combination of questions I\u2019ve been asked, or questions you could be asked if applying for a data engineering or analyst role.&lt;/p&gt;\n\n&lt;p&gt;For each card/question you can write potential answers in the description field.&lt;/p&gt;\n\n&lt;p&gt;You can obviously customise it however you like, but hopefully is useful for some of you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14ql6jc", "is_robot_indexable": true, "report_reasons": null, "author": "TheDataPanda", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ql6jc/i_created_an_interview_preparation_trello/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ql6jc/i_created_an_interview_preparation_trello/", "subreddit_subscribers": 114104, "created_utc": 1688491177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.\n\nI have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next\n\nFor anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.\n\nThe resources I used were:\n\n1. [https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/](https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/) \\- used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics\n2. [https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc](https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc) \\- a good reference guide\n3. [https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF](https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF) \\- essentially 90% of the actual exam questions pretty decent explanations", "author_fullname": "t2_ic83gko1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got certified! - Databricks certified associate developer for apache spark 3.0 in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzt8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688530907.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688530389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.&lt;/p&gt;\n\n&lt;p&gt;I have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next&lt;/p&gt;\n\n&lt;p&gt;For anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.&lt;/p&gt;\n\n&lt;p&gt;The resources I used were:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/\"&gt;https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/&lt;/a&gt; - used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc\"&gt;https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc&lt;/a&gt; - a good reference guide&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF\"&gt;https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF&lt;/a&gt; - essentially 90% of the actual exam questions pretty decent explanations&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qzt8y", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Debate_94", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "subreddit_subscribers": 114104, "created_utc": 1688530389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nLooking to get more knowledge on data warehousing and I've seen the Kimball books mentioned a couple of times and was just wondering if anyone could point me in the direction of the best one to get for a beginner please", "author_fullname": "t2_44gx5087", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kimball books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14q9f0u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688459926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Looking to get more knowledge on data warehousing and I&amp;#39;ve seen the Kimball books mentioned a couple of times and was just wondering if anyone could point me in the direction of the best one to get for a beginner please&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14q9f0u", "is_robot_indexable": true, "report_reasons": null, "author": "rogerbarario", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14q9f0u/kimball_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14q9f0u/kimball_books/", "subreddit_subscribers": 114104, "created_utc": 1688459926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit!\n\nI wanted to share an exciting new **open-source project: \"VulcanSQL\"**! If you're interested in seamlessly transitioning your operational and analytical use cases from data warehouses and databases to the edge API server, this open-source data API framework might be just what you're looking for.\n\n**VulcanSQL (**[**https://vulcansql.com/**](https://vulcansql.com/)**) offers a powerful solution for building embedded analytics and automation use cases**, and it leverages the impressive capabilities of DuckDB as a caching layer. This combination brings about cost reduction and a significant boost in performance, making it an excellent choice for those seeking to optimize their data processing architecture.\n\nBy utilizing VulcanSQL, you can move remote data computing in cloud data warehouses, such as Snowflake and BigQuery to the edge. This embedded approach ensures that your analytics and automation processes can be executed efficiently and seamlessly, even in resource-constrained environments.\n\nGitHub: [https://github.com/Canner/vulcan-sql](https://github.com/Canner/vulcan-sql)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/x5mq6yz9xx9b1.jpg?width=1898&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a99c8da42c303f7d0f070d359a15cb24f35e49f9", "author_fullname": "t2_7cnfbq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VulcanSQL: Create and Share Data APIs Fast!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"x5mq6yz9xx9b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 64, "x": 108, "u": "https://preview.redd.it/x5mq6yz9xx9b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da9eefb94173b598db82465747434804fb70026b"}, {"y": 129, "x": 216, "u": "https://preview.redd.it/x5mq6yz9xx9b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e540a10f9e4279ff4517b60eee5c51348a5c526"}, {"y": 192, "x": 320, "u": "https://preview.redd.it/x5mq6yz9xx9b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30342e5318b0d32101a960fad79bd8f17feae7df"}, {"y": 384, "x": 640, "u": "https://preview.redd.it/x5mq6yz9xx9b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4c3b82ec09bb7c172d7327af8442d4e83640aaa"}, {"y": 576, "x": 960, "u": "https://preview.redd.it/x5mq6yz9xx9b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7282efd7bf8c7bbde23c10618d8f16affe12ad91"}, {"y": 648, "x": 1080, "u": "https://preview.redd.it/x5mq6yz9xx9b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3610576ed1bb08815044e1d44e5b11e35a8bd3bf"}], "s": {"y": 1140, "x": 1898, "u": "https://preview.redd.it/x5mq6yz9xx9b1.jpg?width=1898&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a99c8da42c303f7d0f070d359a15cb24f35e49f9"}, "id": "x5mq6yz9xx9b1"}}, "name": "t3_14qdocu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vEyy2SVwfs-aj-up3xIx17_x8r3H3b2QXFF2U3-mdrw.jpg", "edited": 1688473681.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1688473066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit!&lt;/p&gt;\n\n&lt;p&gt;I wanted to share an exciting new &lt;strong&gt;open-source project: &amp;quot;VulcanSQL&amp;quot;&lt;/strong&gt;! If you&amp;#39;re interested in seamlessly transitioning your operational and analytical use cases from data warehouses and databases to the edge API server, this open-source data API framework might be just what you&amp;#39;re looking for.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;VulcanSQL (&lt;/strong&gt;&lt;a href=\"https://vulcansql.com/\"&gt;&lt;strong&gt;https://vulcansql.com/&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;) offers a powerful solution for building embedded analytics and automation use cases&lt;/strong&gt;, and it leverages the impressive capabilities of DuckDB as a caching layer. This combination brings about cost reduction and a significant boost in performance, making it an excellent choice for those seeking to optimize their data processing architecture.&lt;/p&gt;\n\n&lt;p&gt;By utilizing VulcanSQL, you can move remote data computing in cloud data warehouses, such as Snowflake and BigQuery to the edge. This embedded approach ensures that your analytics and automation processes can be executed efficiently and seamlessly, even in resource-constrained environments.&lt;/p&gt;\n\n&lt;p&gt;GitHub: &lt;a href=\"https://github.com/Canner/vulcan-sql\"&gt;https://github.com/Canner/vulcan-sql&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/x5mq6yz9xx9b1.jpg?width=1898&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a99c8da42c303f7d0f070d359a15cb24f35e49f9\"&gt;https://preview.redd.it/x5mq6yz9xx9b1.jpg?width=1898&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a99c8da42c303f7d0f070d359a15cb24f35e49f9&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?auto=webp&amp;v=enabled&amp;s=096936d3a3acc84f7c6e65b82c5465bd621d7a39", "width": 1896, "height": 972}, "resolutions": [{"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a20408a90862102c389f32e9ba6bffd4e68ed5fe", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=513c186d82cb8c624b22695b46860b25dbe71237", "width": 216, "height": 110}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9eef1ae614145cbe91ce579ed9d23062eb567b56", "width": 320, "height": 164}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f70a552fd2e1a46efc8b770028aba7ffcd3254c1", "width": 640, "height": 328}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06118b47f3a4b1fb24dc67b7b9be888c4e3efc4f", "width": 960, "height": 492}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4171ab66bac7d5d51ebe95cd80bee33ac2fb677", "width": 1080, "height": 553}], "variants": {}, "id": "7_XxcEdZcvt6ayYQHB7LhwUPC73RNr8NakKfG8vfPEY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14qdocu", "is_robot_indexable": true, "report_reasons": null, "author": "chilijung", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qdocu/vulcansql_create_and_share_data_apis_fast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qdocu/vulcansql_create_and_share_data_apis_fast/", "subreddit_subscribers": 114104, "created_utc": 1688473066.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there! I've done some data analysis based on Glassdoor job postings for the search term \"data engineer\" I looked at around 3,000 job entries from Europe, USA + Canada, South-East Asia + Oceania.\n\nHere's the analysis I conducted:\nYou can find it here: *[+100 insights - Data Engineer \ud83e\udded\ud83d\uddfa\ufe0f](https://www.kaggle.com/code/lukkardata/100-insights-data-engineer#%F0%9F%8C%9F-Introduction)*\n\nI based my research on various sources like blogs, courses, and vlogs to figure out what companies mean when they use the title \"data engineer\". The data science roles can be vague, and responsibilities tend to get mixed up. So, I'm here to gather valuable feedback.\n\n___\n\nOne area where I have the most doubts is regarding the selected technologies. I'm not sure if I've categorized them correctly or if I've chosen the right ones. You can check the tech here: *[Tech Knowledge Required](https://www.kaggle.com/code/lukkardata/100-insights-data-engineer#14.-Tech-Knowledge-Required)*\n\nHere are the specific questions I have according to tech:\n\n1. Is Databricks more of a \"cloud platform\" or a \"data integration &amp; processing platform\"?\n2. Are the *\"Tech Knowledge Required\"* categories well-defined?\n3. Are there any redundant categories?\n4. Are there any missing or unnecessary tech categories?\n5. Do you think there's anything else I should add?\n\t\nPlease point out any misspelled words or confusing phrases in my analysis. Feel free to provide any additional comments apart from the technology aspect.\n\n___\n\nLastly, I have a premium question for you. I've heard that in most companies, a \"Data Scientist\" is essentially just a \"Data Engineer\" with added responsibilities like creating regressions and data classifications. I'm curious about your insights or personal experience with this. Or does it depend on the company?\n\nThanks a lot for taking the time to read through this!\n\n___\n\nI'm a fresh Redditor, so I apologize if I violated any rule here ;)", "author_fullname": "t2_yf843", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey! I've Analyzed Thousands of Data Engineer Job Postings - Feedback Needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14q92b9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688460799.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688458714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there! I&amp;#39;ve done some data analysis based on Glassdoor job postings for the search term &amp;quot;data engineer&amp;quot; I looked at around 3,000 job entries from Europe, USA + Canada, South-East Asia + Oceania.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the analysis I conducted:\nYou can find it here: &lt;em&gt;&lt;a href=\"https://www.kaggle.com/code/lukkardata/100-insights-data-engineer#%F0%9F%8C%9F-Introduction\"&gt;+100 insights - Data Engineer \ud83e\udded\ud83d\uddfa\ufe0f&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I based my research on various sources like blogs, courses, and vlogs to figure out what companies mean when they use the title &amp;quot;data engineer&amp;quot;. The data science roles can be vague, and responsibilities tend to get mixed up. So, I&amp;#39;m here to gather valuable feedback.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;One area where I have the most doubts is regarding the selected technologies. I&amp;#39;m not sure if I&amp;#39;ve categorized them correctly or if I&amp;#39;ve chosen the right ones. You can check the tech here: &lt;em&gt;&lt;a href=\"https://www.kaggle.com/code/lukkardata/100-insights-data-engineer#14.-Tech-Knowledge-Required\"&gt;Tech Knowledge Required&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Here are the specific questions I have according to tech:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is Databricks more of a &amp;quot;cloud platform&amp;quot; or a &amp;quot;data integration &amp;amp; processing platform&amp;quot;?&lt;/li&gt;\n&lt;li&gt;Are the &lt;em&gt;&amp;quot;Tech Knowledge Required&amp;quot;&lt;/em&gt; categories well-defined?&lt;/li&gt;\n&lt;li&gt;Are there any redundant categories?&lt;/li&gt;\n&lt;li&gt;Are there any missing or unnecessary tech categories?&lt;/li&gt;\n&lt;li&gt;Do you think there&amp;#39;s anything else I should add?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Please point out any misspelled words or confusing phrases in my analysis. Feel free to provide any additional comments apart from the technology aspect.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Lastly, I have a premium question for you. I&amp;#39;ve heard that in most companies, a &amp;quot;Data Scientist&amp;quot; is essentially just a &amp;quot;Data Engineer&amp;quot; with added responsibilities like creating regressions and data classifications. I&amp;#39;m curious about your insights or personal experience with this. Or does it depend on the company?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for taking the time to read through this!&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;I&amp;#39;m a fresh Redditor, so I apologize if I violated any rule here ;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hIZn74UCUzMss02AeqYwTjjr9Q4P0f4_c6SjRwG_mWM.jpg?auto=webp&amp;v=enabled&amp;s=06fa2c14b6ccb76528c85e988a38335ee8d4e9a8", "width": 160, "height": 160}, "resolutions": [{"url": "https://external-preview.redd.it/hIZn74UCUzMss02AeqYwTjjr9Q4P0f4_c6SjRwG_mWM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55a56d0e849f51b511a0d930de53bbed87e211f7", "width": 108, "height": 108}], "variants": {}, "id": "p15coSqe7L8wApjnVlwASEYE50BcnmvRuPbSVpGUPaM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14q92b9", "is_robot_indexable": true, "report_reasons": null, "author": "Lukkar", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14q92b9/hey_ive_analyzed_thousands_of_data_engineer_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14q92b9/hey_ive_analyzed_thousands_of_data_engineer_job/", "subreddit_subscribers": 114104, "created_utc": 1688458714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Reddit,\n\nI am building a DWH for a client that has most of its data stored in Azure Cosmos containers. Each items, but not all are stored with GUIDs as IDs.\n\n&amp;#x200B;\n\nI am tasked with making a data warehouse to store historical changes, but also to enable reporting in Power BI. I have developed a theoretical pipeline inspired by Databricks Medallion Structure that loads the data into seperate SQL tables using ADF for orchestration:\n\n\\-  staging SQL tables with ID's, data in json structure and a timestamp\n\n\\- A bronze layer, which checks for changes in the data between the staging tables and present table. It will skip unchanges records, and create a new row with updated set time\\_from and time\\_to columns in order to form SCD2s.\n\n\\- A silver layer, where most of the data will be cleaned &amp; transformed, a tabular schema will be established using  statitically defined SQL queries with data types.  \n\n\\- Gold layer, where I was considering making a star schema inspired by Kimballs 3NF. This would involve making fact tables and add surrogate keys either in this layer or the prior, maybe using a mapping table, as I could imagine that the data from the source could change relatively often.\n\n&amp;#x200B;\n\nSo my issue is, how valid is this approach or a thing of the past? I come from a prior Power BI consultancy where we strictly used Kimballs architecture, but I was never taught how to establish the Fact tables. Additionally, I am unsure how to establish a fail-proof method of adding surrogate keys and handle changing dimensions in this regards. \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_8112m7hs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are Surrogate keys and building fact tables in datawarehouses a thing of the past?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qczkc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688470969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Reddit,&lt;/p&gt;\n\n&lt;p&gt;I am building a DWH for a client that has most of its data stored in Azure Cosmos containers. Each items, but not all are stored with GUIDs as IDs.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am tasked with making a data warehouse to store historical changes, but also to enable reporting in Power BI. I have developed a theoretical pipeline inspired by Databricks Medallion Structure that loads the data into seperate SQL tables using ADF for orchestration:&lt;/p&gt;\n\n&lt;p&gt;-  staging SQL tables with ID&amp;#39;s, data in json structure and a timestamp&lt;/p&gt;\n\n&lt;p&gt;- A bronze layer, which checks for changes in the data between the staging tables and present table. It will skip unchanges records, and create a new row with updated set time_from and time_to columns in order to form SCD2s.&lt;/p&gt;\n\n&lt;p&gt;- A silver layer, where most of the data will be cleaned &amp;amp; transformed, a tabular schema will be established using  statitically defined SQL queries with data types.  &lt;/p&gt;\n\n&lt;p&gt;- Gold layer, where I was considering making a star schema inspired by Kimballs 3NF. This would involve making fact tables and add surrogate keys either in this layer or the prior, maybe using a mapping table, as I could imagine that the data from the source could change relatively often.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So my issue is, how valid is this approach or a thing of the past? I come from a prior Power BI consultancy where we strictly used Kimballs architecture, but I was never taught how to establish the Fact tables. Additionally, I am unsure how to establish a fail-proof method of adding surrogate keys and handle changing dimensions in this regards. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qczkc", "is_robot_indexable": true, "report_reasons": null, "author": "Olafcitoo", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qczkc/are_surrogate_keys_and_building_fact_tables_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qczkc/are_surrogate_keys_and_building_fact_tables_in/", "subreddit_subscribers": 114104, "created_utc": 1688470969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lets assume we're talking about structured data that's been pulled into a lake.\n\nIn most cases, data has certain characteristics that you might search by (indexable columns) (\"employee id\") and/or have values that might be optimized for read (e.g., numeric values in a columnstore structure).\n\nIf all you have is just progressively cleaner layers of data that's actually just in object store (e.g., parquet files in s3) but doesn't use anything like what I described above, how is that efficient to query?\n\nMy guess is that they're using a layer that brute forces the efficiency (distributed queries), or the product has an additional part that actually lets you store the data in a more traditionally table like structure.", "author_fullname": "t2_ahf8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do Lakes Provide Adequate Query Performance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qfef7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688477719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets assume we&amp;#39;re talking about structured data that&amp;#39;s been pulled into a lake.&lt;/p&gt;\n\n&lt;p&gt;In most cases, data has certain characteristics that you might search by (indexable columns) (&amp;quot;employee id&amp;quot;) and/or have values that might be optimized for read (e.g., numeric values in a columnstore structure).&lt;/p&gt;\n\n&lt;p&gt;If all you have is just progressively cleaner layers of data that&amp;#39;s actually just in object store (e.g., parquet files in s3) but doesn&amp;#39;t use anything like what I described above, how is that efficient to query?&lt;/p&gt;\n\n&lt;p&gt;My guess is that they&amp;#39;re using a layer that brute forces the efficiency (distributed queries), or the product has an additional part that actually lets you store the data in a more traditionally table like structure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qfef7", "is_robot_indexable": true, "report_reasons": null, "author": "PencilBoy99", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qfef7/how_do_lakes_provide_adequate_query_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qfef7/how_do_lakes_provide_adequate_query_performance/", "subreddit_subscribers": 114104, "created_utc": 1688477719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in my mid 20s, single, and have a hybrid job which gives me a crap ton of free time to just sit around wasting time. I already lift, read, etc. so I've got all the good habits I could possibly want to build. However, I would like to make more money.\n\nAre there any side hustles for an early career DE that don't have a huge barrier to entry or that aren't basically gambling?\n\nI've considered web apps but frankly I'm coming up with solutions without very well documented problems. Additionally the time required to build a good functional web app could easily be over a year to ever earn that first dollar.\n\nI've considered scripts for predicting sports card values or for gaining an edge in sports betting but once again that just seems like gambling with extra steps.\n\nI'm too early in my career for consulting.\n\nThe best idea I've come up with is some sort of DE/analytics blog with an emphasis on sports or small scale IoT projects.\n\nDoes anyone have any other suggestions? Should I just be focusing my time on learning new skills to get a raise and/or a new job?\n\n&amp;#x200B;", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any side hustles as a DE with smaller barriers to entry than building a full-scale web app?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qqy5s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688504686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in my mid 20s, single, and have a hybrid job which gives me a crap ton of free time to just sit around wasting time. I already lift, read, etc. so I&amp;#39;ve got all the good habits I could possibly want to build. However, I would like to make more money.&lt;/p&gt;\n\n&lt;p&gt;Are there any side hustles for an early career DE that don&amp;#39;t have a huge barrier to entry or that aren&amp;#39;t basically gambling?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered web apps but frankly I&amp;#39;m coming up with solutions without very well documented problems. Additionally the time required to build a good functional web app could easily be over a year to ever earn that first dollar.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered scripts for predicting sports card values or for gaining an edge in sports betting but once again that just seems like gambling with extra steps.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m too early in my career for consulting.&lt;/p&gt;\n\n&lt;p&gt;The best idea I&amp;#39;ve come up with is some sort of DE/analytics blog with an emphasis on sports or small scale IoT projects.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any other suggestions? Should I just be focusing my time on learning new skills to get a raise and/or a new job?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qqy5s", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qqy5s/are_there_any_side_hustles_as_a_de_with_smaller/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qqy5s/are_there_any_side_hustles_as_a_de_with_smaller/", "subreddit_subscribers": 114104, "created_utc": 1688504686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a junior data analyst shifting towards a data engineering role. We are implementing a modern data stack with azure blob storage, azure synapse and databricks. We just have one source of data (homegrown ERP system developed in-house) using sql server. The ERP system is pretty bad in terms of data quality (poor data, lots of etl to do). What\u2019s the best way to approach data engineering? Our plan is use databricks notebooks for etl, synapse pipelines for orchestration, great expectations for validations. Our team is intermediate in Python, but looking to grow. Solution should be simple, yet scalable. Team of 5. Any suggestions/tips?", "author_fullname": "t2_56ltry44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing a modern data platform in a small team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qiyie", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688486091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a junior data analyst shifting towards a data engineering role. We are implementing a modern data stack with azure blob storage, azure synapse and databricks. We just have one source of data (homegrown ERP system developed in-house) using sql server. The ERP system is pretty bad in terms of data quality (poor data, lots of etl to do). What\u2019s the best way to approach data engineering? Our plan is use databricks notebooks for etl, synapse pipelines for orchestration, great expectations for validations. Our team is intermediate in Python, but looking to grow. Solution should be simple, yet scalable. Team of 5. Any suggestions/tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qiyie", "is_robot_indexable": true, "report_reasons": null, "author": "Specific-Passage", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qiyie/implementing_a_modern_data_platform_in_a_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qiyie/implementing_a_modern_data_platform_in_a_small/", "subreddit_subscribers": 114104, "created_utc": 1688486091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). \n\nI get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. \n\nI have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). \n\nHow do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?", "author_fullname": "t2_pu047jjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Performance vs On-Prem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14quid6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688513977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). &lt;/p&gt;\n\n&lt;p&gt;I get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. &lt;/p&gt;\n\n&lt;p&gt;I have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). &lt;/p&gt;\n\n&lt;p&gt;How do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14quid6", "is_robot_indexable": true, "report_reasons": null, "author": "atlvernburn", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "subreddit_subscribers": 114104, "created_utc": 1688513977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I wanna read the Kimball books as I've seen them mentioned many times as being a great source of quality information about how to do things.\n\nI see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling\n\nThe Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses\n\nThe Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data\n\n\nShould I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.\n\nThanks a lot guys. Really appreciate the help you've all been", "author_fullname": "t2_p5wlf0g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Kimball to Start with", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qusqd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688514805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I wanna read the Kimball books as I&amp;#39;ve seen them mentioned many times as being a great source of quality information about how to do things.&lt;/p&gt;\n\n&lt;p&gt;I see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data&lt;/p&gt;\n\n&lt;p&gt;Should I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot guys. Really appreciate the help you&amp;#39;ve all been&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qusqd", "is_robot_indexable": true, "report_reasons": null, "author": "El_Cato_Crande", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "subreddit_subscribers": 114104, "created_utc": 1688514805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\\*Hi All!\\*\n\n  \n\n\nLately, I've been immersing myself in Snowflake tool and exploring its capabilities. Along the way, I've compiled a collection of queries that I've executed and organized them on GitHub. It's a resource for anyone looking to refresh their understanding of the basic concepts.\n\n  \n\n\nHere's the link to the GitHub repository: \\[Snowflake Queries Repository\\](https://github.com/dattapadal/Snowflake_tutorial.git)\n\n  \n\n\nThanks", "author_fullname": "t2_138wofcx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake basic concepts with queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14q8rts", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688457760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;*Hi All!*&lt;/p&gt;\n\n&lt;p&gt;Lately, I&amp;#39;ve been immersing myself in Snowflake tool and exploring its capabilities. Along the way, I&amp;#39;ve compiled a collection of queries that I&amp;#39;ve executed and organized them on GitHub. It&amp;#39;s a resource for anyone looking to refresh their understanding of the basic concepts.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link to the GitHub repository: [Snowflake Queries Repository](&lt;a href=\"https://github.com/dattapadal/Snowflake_tutorial.git\"&gt;https://github.com/dattapadal/Snowflake_tutorial.git&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W6xO7n7RE-FsiAyRm0_56YyETqfsvYRbpt_Y6okUWfI.jpg?auto=webp&amp;v=enabled&amp;s=ee0b5e8c05946a835350ed8272a10fd6e84bd6fd", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/W6xO7n7RE-FsiAyRm0_56YyETqfsvYRbpt_Y6okUWfI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58c2a3e02e2d0305738b37f02e38628e7100030d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/W6xO7n7RE-FsiAyRm0_56YyETqfsvYRbpt_Y6okUWfI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae6104a3cf487c5b8dd2911570335ede54101b3a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/W6xO7n7RE-FsiAyRm0_56YyETqfsvYRbpt_Y6okUWfI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17fa74f417a0afec7c0fa2ee474689cb60c7fcf4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/W6xO7n7RE-FsiAyRm0_56YyETqfsvYRbpt_Y6okUWfI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1137f0707b0a04891814efbe90fbb47374648c9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/W6xO7n7RE-FsiAyRm0_56YyETqfsvYRbpt_Y6okUWfI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=147aaed4cca00816d4f8926d0f6c189b49ca15e2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/W6xO7n7RE-FsiAyRm0_56YyETqfsvYRbpt_Y6okUWfI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f6c08d3a0da7a93c1da9b486ef7cab338ef6e3b", "width": 1080, "height": 540}], "variants": {}, "id": "VNtyUw_auHa3mR_aUhtUyTw1gYG26LlQwNZoU08Ww2Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "14q8rts", "is_robot_indexable": true, "report_reasons": null, "author": "akashTheTraveller", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14q8rts/snowflake_basic_concepts_with_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14q8rts/snowflake_basic_concepts_with_queries/", "subreddit_subscribers": 114104, "created_utc": 1688457760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can we streamline the process of understanding source data? Frequently, questions like \"What business process generates this data and why?\" require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.\n\nTypically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.\n\nAny advice to make this better?", "author_fullname": "t2_55thi7w8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I ensure that my data model accurately represents the data in my OLAP DB? How can I be certain that my DIM and FACT tables effectively capture the business workflow, leading to optimized and efficient queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qvo0e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688517373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can we streamline the process of understanding source data? Frequently, questions like &amp;quot;What business process generates this data and why?&amp;quot; require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.&lt;/p&gt;\n\n&lt;p&gt;Typically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.&lt;/p&gt;\n\n&lt;p&gt;Any advice to make this better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qvo0e", "is_robot_indexable": true, "report_reasons": null, "author": "faizfablillah", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "subreddit_subscribers": 114104, "created_utc": 1688517373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone, \n\nWhat is the best resources for understanding how to build out a pipeline from scratch. I'm currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.\n\nIt had me thinking if I was to get the job I wouldn't know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.\n\nI figured I should get started now since it's always good to learn things start to finish.\n\nAny resources you could provide would be great (books, articles, other post, ect...)\n\nThanks in advance!", "author_fullname": "t2_5ejp13jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering start to finish", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzi8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688529422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone, &lt;/p&gt;\n\n&lt;p&gt;What is the best resources for understanding how to build out a pipeline from scratch. I&amp;#39;m currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.&lt;/p&gt;\n\n&lt;p&gt;It had me thinking if I was to get the job I wouldn&amp;#39;t know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.&lt;/p&gt;\n\n&lt;p&gt;I figured I should get started now since it&amp;#39;s always good to learn things start to finish.&lt;/p&gt;\n\n&lt;p&gt;Any resources you could provide would be great (books, articles, other post, ect...)&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qzi8p", "is_robot_indexable": true, "report_reasons": null, "author": "knowledgeMeUp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "subreddit_subscribers": 114104, "created_utc": 1688529422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. \n\nThese data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?", "author_fullname": "t2_dg51ak2mn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "user identity, machine identity and now we need data identity ? what do you think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qws59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688520815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. &lt;/p&gt;\n\n&lt;p&gt;These data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qws59", "is_robot_indexable": true, "report_reasons": null, "author": "Extreme-Summer-2756", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "subreddit_subscribers": 114104, "created_utc": 1688520815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you have any suggestions for the routine job to extract Big data from MySQL server to CSV, preprocessing (cleaning and transformation), and prepare for machine learning? Is there easy way anyone using?\n\n&amp;#x200B;", "author_fullname": "t2_85tjk7wh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big data processing for machine learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qqmzn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688503949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have any suggestions for the routine job to extract Big data from MySQL server to CSV, preprocessing (cleaning and transformation), and prepare for machine learning? Is there easy way anyone using?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qqmzn", "is_robot_indexable": true, "report_reasons": null, "author": "Jebin1999", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qqmzn/big_data_processing_for_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qqmzn/big_data_processing_for_machine_learning/", "subreddit_subscribers": 114104, "created_utc": 1688503949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! I'm looking for Data Engineering roles that look like Software Engineering positions, in other words, more \"technical\" roles in the universe of DE (Roles that don't look like Data or Business Analyst and ETL or SQL Developer positions)\n\nI want something that feels like a breed between a SWE role and a DE role. Out of all the positions I found, I came across this one and I was wondering if you guys - who have a lot more experience than me - feel like this hits the mark:\n\n\"Your work will involve creating analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other essential business performance metrics. You will also be responsible for managing the data architecture for data ingestion, pipeline setup, and data curation. Additionally, you will manipulate data at scale to ensure it is in a readily usable state, collaborating closely with various business and Spoke stakeholders.\n\nKey Responsibilities:\n\n* Create and maintain data pipeline architecture. Assemble large, complex data sets that meet functional/non-functional business requirements.\n* Build the infrastructure required for optimal data extraction, transformation, and loading using SQL and AWS 'big data' technologies.\n* Develop analytics tools leveraging the data pipeline to provide actionable insights.\n* Manage the data architecture for data ingestion, pipeline setup, and data curation, and manipulate data at scale, aligning it with business and Spoke stakeholder needs.\n\nRequired Qualifications:\n\n* Master's degree in Computer Engineering.\n* Strong expertise in building and optimizing 'big data' data pipelines, architectures, and datasets.\n* Experience in building processes supporting data transformation, data structures, metadata, dependency, and workload management.\n* Proficiency in AWS Infrastructure as Code (IaC) and Infrastructure as a Service (IaaS) services.\n* Programming skills in functional programming and object-oriented scripting languages (Mostly python, sometimes scala and Java).\n\nPreferred Qualifications:\n\n* Experience with big data tools and distributed clusters such as Hadoop, Spark, Kafka, Kinesis.\n* Familiarity with data pipeline and workflow management tools like Azkaban, Luigi, Airflow, Glue Workflow.\"\n\nThank you so much for your help!\n\n&amp;#x200B;", "author_fullname": "t2_cettm338", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this look like a solid DE role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qny43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688497710.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688497524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I&amp;#39;m looking for Data Engineering roles that look like Software Engineering positions, in other words, more &amp;quot;technical&amp;quot; roles in the universe of DE (Roles that don&amp;#39;t look like Data or Business Analyst and ETL or SQL Developer positions)&lt;/p&gt;\n\n&lt;p&gt;I want something that feels like a breed between a SWE role and a DE role. Out of all the positions I found, I came across this one and I was wondering if you guys - who have a lot more experience than me - feel like this hits the mark:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Your work will involve creating analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other essential business performance metrics. You will also be responsible for managing the data architecture for data ingestion, pipeline setup, and data curation. Additionally, you will manipulate data at scale to ensure it is in a readily usable state, collaborating closely with various business and Spoke stakeholders.&lt;/p&gt;\n\n&lt;p&gt;Key Responsibilities:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Create and maintain data pipeline architecture. Assemble large, complex data sets that meet functional/non-functional business requirements.&lt;/li&gt;\n&lt;li&gt;Build the infrastructure required for optimal data extraction, transformation, and loading using SQL and AWS &amp;#39;big data&amp;#39; technologies.&lt;/li&gt;\n&lt;li&gt;Develop analytics tools leveraging the data pipeline to provide actionable insights.&lt;/li&gt;\n&lt;li&gt;Manage the data architecture for data ingestion, pipeline setup, and data curation, and manipulate data at scale, aligning it with business and Spoke stakeholder needs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Required Qualifications:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Master&amp;#39;s degree in Computer Engineering.&lt;/li&gt;\n&lt;li&gt;Strong expertise in building and optimizing &amp;#39;big data&amp;#39; data pipelines, architectures, and datasets.&lt;/li&gt;\n&lt;li&gt;Experience in building processes supporting data transformation, data structures, metadata, dependency, and workload management.&lt;/li&gt;\n&lt;li&gt;Proficiency in AWS Infrastructure as Code (IaC) and Infrastructure as a Service (IaaS) services.&lt;/li&gt;\n&lt;li&gt;Programming skills in functional programming and object-oriented scripting languages (Mostly python, sometimes scala and Java).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Preferred Qualifications:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Experience with big data tools and distributed clusters such as Hadoop, Spark, Kafka, Kinesis.&lt;/li&gt;\n&lt;li&gt;Familiarity with data pipeline and workflow management tools like Azkaban, Luigi, Airflow, Glue Workflow.&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you so much for your help!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qny43", "is_robot_indexable": true, "report_reasons": null, "author": "PM_ME_YOUR_GIGI", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qny43/does_this_look_like_a_solid_de_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qny43/does_this_look_like_a_solid_de_role/", "subreddit_subscribers": 114104, "created_utc": 1688497524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data news #34", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14qfahg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c_vhfWQUDlhOO21mUbuHvftlROyLxhesVDI5R1Dyxrk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688477441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "patrikbraborec.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://patrikbraborec.substack.com/p/data-news-34", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VYXffSLy3WmewfP7Wjx4nzO1UZHgMhL4srT0jHW7vKA.jpg?auto=webp&amp;v=enabled&amp;s=b7f4d409b378d8d561ff709882be9c6946dc1334", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/VYXffSLy3WmewfP7Wjx4nzO1UZHgMhL4srT0jHW7vKA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4890a73a28d6612a88e7e1cd5a9fbd4b4fa3270", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/VYXffSLy3WmewfP7Wjx4nzO1UZHgMhL4srT0jHW7vKA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38c5074e4383c0d0ceadba26810db78f74351ed8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/VYXffSLy3WmewfP7Wjx4nzO1UZHgMhL4srT0jHW7vKA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f5cffba8aa04b1219f2755ba7c2799147986302", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/VYXffSLy3WmewfP7Wjx4nzO1UZHgMhL4srT0jHW7vKA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=575940f3d088e995a8c21868e1aa65c023339941", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/VYXffSLy3WmewfP7Wjx4nzO1UZHgMhL4srT0jHW7vKA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20a9af4d3ace58f5d0c164441fa6f34bae51da7c", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/VYXffSLy3WmewfP7Wjx4nzO1UZHgMhL4srT0jHW7vKA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5556f61036c62b4b6bc4e439ce32d0d52294406", "width": 1080, "height": 540}], "variants": {}, "id": "80B2Nu9up8f7xhDcO12O-ombIlywvYfJk18s8O_t1Mg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14qfahg", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qfahg/data_news_34/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://patrikbraborec.substack.com/p/data-news-34", "subreddit_subscribers": 114104, "created_utc": 1688477441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, in my work there is data we get / extract data from Postgresql, MySQL, etc with estimated schedule every 15 minutes with data we get incremental 1 day. The data that we get it's more than million. why 15 minutes, it's because we need to serve data fastly but not realtime to other transformation process. I want it stay incremental 1 day by incremental column.\n\nWe extract the data by using query in source db. Before i getting into airflow, we used pentaho / kettle for this ingestion / extraction. But, the problem when we extract data on airflow using pandas + psycopg to send it into aws S3 is getting slow and consume so much resource in cpu than im using pentaho before that more consume of memory and fast for getting data. I guess this is cause of Java Connector in pentaho that make it run faster (?) i dont know.\n\nThis is for old pipeline:\nPostgresql (Source) -&gt; Pentaho Extraction (JDBC ?) -&gt; Local System (CSV) -&gt; AWS S3 -&gt; Redshift\n\nNew Pipeline : \nPostgresql (Source) -&gt; Airflow Extraction (Pandas + psycopg) -&gt; Local System (CSV) -&gt; AWS S3 -&gt; Redshift\n\nOld Pipeline is faster, and resources consume less. When i tried full refresh on pentaho transformation it's never getting error about high memory, but when i tried airflow with pandas and psycopg it's get error high memory (memory leak).\n\nSo, i'm still want to use Airflow for this data extraction and will remove pentaho. But, i don't know what the best practice if we get data that having schedule will update every 15 minutes. Is there any Open Source tools or libraries that help this problem ? \n\nI Have tried but it's still not solving the problem:\n- Asynchronously get data using AIOPG / aiomysql but there is not really much improvement or nothing is improved by speed.\n- Apache Spark, first when i call SparkSession.builder.getOrCreate() every run schedule it's take time consuming about 30 - 60 seconds, secondly sometimes spark is fast but sometimes it's slow.\n- Airbyte, first it's good using JDBC and good when tried for full refresh. But, airbyte is not based query, because i dont want to get all the column table, and sometimes there is more than 2 incremental column so i preffered query based instead. The dbt transform in airbyte make it confuss me because is it like we get all the data with all the column first then we transform it ? so it's kinda ineffective or maybe time consuming\n\nI'm newbie in data engineer. That's why i want to know what maybe best practice for extraction data that schedule every 15 minutes with big data ? I still want to get data with incremental 1 day, fastly, less consume resource or getting no error when trying with full refresh data. (Full refresh data is not every 15 minutes but it trigger manually) \n\nWhat about your company data extraction method ? is anything wrong with my trial in async, airbyte, or spark that maybe im skipped ?\nThanks A lot", "author_fullname": "t2_8ejjs2r3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What best practices get / extract data that frequently update with a little big data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qbe2n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688466192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, in my work there is data we get / extract data from Postgresql, MySQL, etc with estimated schedule every 15 minutes with data we get incremental 1 day. The data that we get it&amp;#39;s more than million. why 15 minutes, it&amp;#39;s because we need to serve data fastly but not realtime to other transformation process. I want it stay incremental 1 day by incremental column.&lt;/p&gt;\n\n&lt;p&gt;We extract the data by using query in source db. Before i getting into airflow, we used pentaho / kettle for this ingestion / extraction. But, the problem when we extract data on airflow using pandas + psycopg to send it into aws S3 is getting slow and consume so much resource in cpu than im using pentaho before that more consume of memory and fast for getting data. I guess this is cause of Java Connector in pentaho that make it run faster (?) i dont know.&lt;/p&gt;\n\n&lt;p&gt;This is for old pipeline:\nPostgresql (Source) -&amp;gt; Pentaho Extraction (JDBC ?) -&amp;gt; Local System (CSV) -&amp;gt; AWS S3 -&amp;gt; Redshift&lt;/p&gt;\n\n&lt;p&gt;New Pipeline : \nPostgresql (Source) -&amp;gt; Airflow Extraction (Pandas + psycopg) -&amp;gt; Local System (CSV) -&amp;gt; AWS S3 -&amp;gt; Redshift&lt;/p&gt;\n\n&lt;p&gt;Old Pipeline is faster, and resources consume less. When i tried full refresh on pentaho transformation it&amp;#39;s never getting error about high memory, but when i tried airflow with pandas and psycopg it&amp;#39;s get error high memory (memory leak).&lt;/p&gt;\n\n&lt;p&gt;So, i&amp;#39;m still want to use Airflow for this data extraction and will remove pentaho. But, i don&amp;#39;t know what the best practice if we get data that having schedule will update every 15 minutes. Is there any Open Source tools or libraries that help this problem ? &lt;/p&gt;\n\n&lt;p&gt;I Have tried but it&amp;#39;s still not solving the problem:\n- Asynchronously get data using AIOPG / aiomysql but there is not really much improvement or nothing is improved by speed.\n- Apache Spark, first when i call SparkSession.builder.getOrCreate() every run schedule it&amp;#39;s take time consuming about 30 - 60 seconds, secondly sometimes spark is fast but sometimes it&amp;#39;s slow.\n- Airbyte, first it&amp;#39;s good using JDBC and good when tried for full refresh. But, airbyte is not based query, because i dont want to get all the column table, and sometimes there is more than 2 incremental column so i preffered query based instead. The dbt transform in airbyte make it confuss me because is it like we get all the data with all the column first then we transform it ? so it&amp;#39;s kinda ineffective or maybe time consuming&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m newbie in data engineer. That&amp;#39;s why i want to know what maybe best practice for extraction data that schedule every 15 minutes with big data ? I still want to get data with incremental 1 day, fastly, less consume resource or getting no error when trying with full refresh data. (Full refresh data is not every 15 minutes but it trigger manually) &lt;/p&gt;\n\n&lt;p&gt;What about your company data extraction method ? is anything wrong with my trial in async, airbyte, or spark that maybe im skipped ?\nThanks A lot&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qbe2n", "is_robot_indexable": true, "report_reasons": null, "author": "azharizz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qbe2n/what_best_practices_get_extract_data_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qbe2n/what_best_practices_get_extract_data_that/", "subreddit_subscribers": 114104, "created_utc": 1688466192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have many streams and main business objects can be found in different flavours in different datastores (data mesh kinda architecture). The problem is ensuring that data quality stays good along the way as we can have troubles finding the root cause of bad / missing data. (not published event or bad consumed event, lag?)\n\nWhat would be a good way to monitor this, I'm feeling tracing, logs &amp; supervision are very tech solutions that are great for globally ensuring that everything is working, not so great for focused data supervision (we do not have very exploitable logs so fetching other app logs and yours through 1 splunk query is not possible), they can't really help when you particularly want to check quickly the sanity around 1 business object (it requires devops, dev access, takes time). \n\nI'm thinking that building a business object timeseries (dynamodb or cassandra for instance) for storing latest footprints pushed at end of processes of said business objects (id 1, gone stream A ok at timestamp t1...), so I could easily fetch by API what happened lately on these elements accross multiple apps &amp; datastores, would it be a good way or I am actually reinventing the wheel somewhere? The idea of having such timelines would also allow real time data health checks (for some random picked ones for instance) which I believe would be very valuable. Did anybody build something similar or could cover this data quality check?  \n", "author_fullname": "t2_fcsuc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to monitor business objects through EDA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14q82kg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688455444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have many streams and main business objects can be found in different flavours in different datastores (data mesh kinda architecture). The problem is ensuring that data quality stays good along the way as we can have troubles finding the root cause of bad / missing data. (not published event or bad consumed event, lag?)&lt;/p&gt;\n\n&lt;p&gt;What would be a good way to monitor this, I&amp;#39;m feeling tracing, logs &amp;amp; supervision are very tech solutions that are great for globally ensuring that everything is working, not so great for focused data supervision (we do not have very exploitable logs so fetching other app logs and yours through 1 splunk query is not possible), they can&amp;#39;t really help when you particularly want to check quickly the sanity around 1 business object (it requires devops, dev access, takes time). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking that building a business object timeseries (dynamodb or cassandra for instance) for storing latest footprints pushed at end of processes of said business objects (id 1, gone stream A ok at timestamp t1...), so I could easily fetch by API what happened lately on these elements accross multiple apps &amp;amp; datastores, would it be a good way or I am actually reinventing the wheel somewhere? The idea of having such timelines would also allow real time data health checks (for some random picked ones for instance) which I believe would be very valuable. Did anybody build something similar or could cover this data quality check?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14q82kg", "is_robot_indexable": true, "report_reasons": null, "author": "zenbeni", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14q82kg/how_to_monitor_business_objects_through_eda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14q82kg/how_to_monitor_business_objects_through_eda/", "subreddit_subscribers": 114104, "created_utc": 1688455444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello redditors of r/dataengineer I feel like i walked in to a party I was  never invited to but here I am, asking a question.I was recently accepted to get educated as an Data engineer or a Fullstack .net developer.Now I am going to be honest, I an a geotech engineer and love tech but looking to challenge myself abit intellectually workwise but dont really know either of the occupations well enough to decide, I am not necissarly trying to combine my previous work with a new one, More of a fresh start and I wanted to know if you guys think i should choose Data engineer over Fullstack .net developer and why.", "author_fullname": "t2_7ikqjysld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer vs Fullstack as a job and why should I choose Data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14quusz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688514976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello redditors of &lt;a href=\"/r/dataengineer\"&gt;r/dataengineer&lt;/a&gt; I feel like i walked in to a party I was  never invited to but here I am, asking a question.I was recently accepted to get educated as an Data engineer or a Fullstack .net developer.Now I am going to be honest, I an a geotech engineer and love tech but looking to challenge myself abit intellectually workwise but dont really know either of the occupations well enough to decide, I am not necissarly trying to combine my previous work with a new one, More of a fresh start and I wanted to know if you guys think i should choose Data engineer over Fullstack .net developer and why.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14quusz", "is_robot_indexable": true, "report_reasons": null, "author": "InternationalTour303", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14quusz/data_engineer_vs_fullstack_as_a_job_and_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14quusz/data_engineer_vs_fullstack_as_a_job_and_why/", "subreddit_subscribers": 114104, "created_utc": 1688514976.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}