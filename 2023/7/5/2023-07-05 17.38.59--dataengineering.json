{"kind": "Listing", "data": {"after": "t3_14redmy", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.\n\nI have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next\n\nFor anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.\n\nThe resources I used were:\n\n1. [https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/](https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/) \\- used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics\n2. [https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc](https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc) \\- a good reference guide\n3. [https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF](https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF) \\- essentially 90% of the actual exam questions pretty decent explanations  \n\n\nP.S Sorry couldn't forget to include [Spark Internals Explanation](https://www.youtube.com/watch?v=7ooZ4S7Ay6Y)! A phenomenal resource to dive deep on how Spark works under the hood", "author_fullname": "t2_ic83gko1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got certified! - Databricks certified associate developer for apache spark 3.0 in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzt8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 98, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 98, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688544365.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688530389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.&lt;/p&gt;\n\n&lt;p&gt;I have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next&lt;/p&gt;\n\n&lt;p&gt;For anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.&lt;/p&gt;\n\n&lt;p&gt;The resources I used were:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/\"&gt;https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/&lt;/a&gt; - used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc\"&gt;https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc&lt;/a&gt; - a good reference guide&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF\"&gt;https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF&lt;/a&gt; - essentially 90% of the actual exam questions pretty decent explanations&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;P.S Sorry couldn&amp;#39;t forget to include &lt;a href=\"https://www.youtube.com/watch?v=7ooZ4S7Ay6Y\"&gt;Spark Internals Explanation&lt;/a&gt;! A phenomenal resource to dive deep on how Spark works under the hood&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qzt8y", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Debate_94", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "subreddit_subscribers": 114179, "created_utc": 1688530389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am the only DE in the team, and we want to hire a senior DE soon. My manager has asked me to interview somebody with ~20 years of experience in data engineering while I have only ~4 YOE as a data engineer. When I looked at this candidate\u2019s resume, I got overwhelmed by the expertise they claimed to have. I feel I don\u2019t have enough knowledge to accurately assess this candidate. How should I go about interviewing this candidate? What sort of questions should I ask?", "author_fullname": "t2_cbdg7n9sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should you interview somebody with vastly more experience than yourself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qslvf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688508789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the only DE in the team, and we want to hire a senior DE soon. My manager has asked me to interview somebody with ~20 years of experience in data engineering while I have only ~4 YOE as a data engineer. When I looked at this candidate\u2019s resume, I got overwhelmed by the expertise they claimed to have. I feel I don\u2019t have enough knowledge to accurately assess this candidate. How should I go about interviewing this candidate? What sort of questions should I ask?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14qslvf", "is_robot_indexable": true, "report_reasons": null, "author": "fun_coordinator", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qslvf/how_should_you_interview_somebody_with_vastly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qslvf/how_should_you_interview_somebody_with_vastly/", "subreddit_subscribers": 114179, "created_utc": 1688508789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I was first learning dbt I found a lot of really great resources (dbt docs, blog posts, slack threads etc.) and wanted to try to put that all together in one place for anyone else new to dbt, or anyone wanting to learn a bit more about it.   \nThe guide covers everything from \u2018what is dbt?\u2019 to advanced topics like model refactoring best practices.  \nI hope it's useful! **And if you spot anything missing, or ways to make it better, please let me know!**  \n\n\nDesktop link: [https://count.co/canvas/JpkaYdqr9oN](https://count.co/canvas/JpkaYdqr9oN)  \nMobile link: [https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914](https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914)  \n\n\nFull disclosure: I do work for [count.co](https://count.co), the canvas in which the guide was built. ", "author_fullname": "t2_1zfun4sx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I attempted to create the Ultimate Guide to dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r4v10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688547009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was first learning dbt I found a lot of really great resources (dbt docs, blog posts, slack threads etc.) and wanted to try to put that all together in one place for anyone else new to dbt, or anyone wanting to learn a bit more about it.&lt;br/&gt;\nThe guide covers everything from \u2018what is dbt?\u2019 to advanced topics like model refactoring best practices.&lt;br/&gt;\nI hope it&amp;#39;s useful! &lt;strong&gt;And if you spot anything missing, or ways to make it better, please let me know!&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Desktop link: &lt;a href=\"https://count.co/canvas/JpkaYdqr9oN\"&gt;https://count.co/canvas/JpkaYdqr9oN&lt;/a&gt;&lt;br/&gt;\nMobile link: &lt;a href=\"https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914\"&gt;https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Full disclosure: I do work for &lt;a href=\"https://count.co\"&gt;count.co&lt;/a&gt;, the canvas in which the guide was built. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?auto=webp&amp;v=enabled&amp;s=c90d7e97aa224a896783d02a2a830784cb2c0920", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bd97f02fcc00d06a42618c0358185b4bc650318", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb4ee7c5f99ac12f4224cd68ccf6e07358a570c8", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20558ea1403333413bd92f54c54785a76892a5b7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6edc187fbdad61643782e43cb3dad2664e040241", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea269da98515be9aa97a81600be483c293aee457", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3fdea5709efc2342950519678dccbfa5b6a5bc9", "width": 1080, "height": 720}], "variants": {}, "id": "2h6z0wcxfeyGYPsAUSLRq1EjtP-b9N_kgrbXZ-BV1x0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14r4v10", "is_robot_indexable": true, "report_reasons": null, "author": "tbrownlow", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r4v10/i_attempted_to_create_the_ultimate_guide_to_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r4v10/i_attempted_to_create_the_ultimate_guide_to_dbt/", "subreddit_subscribers": 114179, "created_utc": 1688547009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Link: https://trello.com/b/Rvw8Jygt/interview-preparation\n\nI have been looking for entry level or junior data engineering roles, and have been using a Trello board to help with interview preparation.\n\nIt contains lists of common interview questions, technical questions, and behavioural questions.\n\nI\u2019ve tried tagging behavioural questions based on attribute it\u2019s measuring (e.g., conflict management) so you can filter by these.\n\nFor the technical questions, these are a combination of questions I\u2019ve been asked, or questions you could be asked if applying for a data engineering or analyst role.\n\nFor each card/question you can write potential answers in the description field.\n\nYou can obviously customise it however you like, but hopefully is useful for some of you", "author_fullname": "t2_osh2xtjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created an interview preparation Trello template with technical &amp; behavioural questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ql6jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688491177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Link: &lt;a href=\"https://trello.com/b/Rvw8Jygt/interview-preparation\"&gt;https://trello.com/b/Rvw8Jygt/interview-preparation&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have been looking for entry level or junior data engineering roles, and have been using a Trello board to help with interview preparation.&lt;/p&gt;\n\n&lt;p&gt;It contains lists of common interview questions, technical questions, and behavioural questions.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried tagging behavioural questions based on attribute it\u2019s measuring (e.g., conflict management) so you can filter by these.&lt;/p&gt;\n\n&lt;p&gt;For the technical questions, these are a combination of questions I\u2019ve been asked, or questions you could be asked if applying for a data engineering or analyst role.&lt;/p&gt;\n\n&lt;p&gt;For each card/question you can write potential answers in the description field.&lt;/p&gt;\n\n&lt;p&gt;You can obviously customise it however you like, but hopefully is useful for some of you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14ql6jc", "is_robot_indexable": true, "report_reasons": null, "author": "TheDataPanda", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ql6jc/i_created_an_interview_preparation_trello/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ql6jc/i_created_an_interview_preparation_trello/", "subreddit_subscribers": 114179, "created_utc": 1688491177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). \n\nI get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. \n\nI have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). \n\nHow do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?", "author_fullname": "t2_pu047jjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Performance vs On-Prem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14quid6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688513977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). &lt;/p&gt;\n\n&lt;p&gt;I get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. &lt;/p&gt;\n\n&lt;p&gt;I have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). &lt;/p&gt;\n\n&lt;p&gt;How do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14quid6", "is_robot_indexable": true, "report_reasons": null, "author": "atlvernburn", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "subreddit_subscribers": 114179, "created_utc": 1688513977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in my mid 20s, single, and have a hybrid job which gives me a crap ton of free time to just sit around wasting time. I already lift, read, etc. so I've got all the good habits I could possibly want to build. However, I would like to make more money.\n\nAre there any side hustles for an early career DE that don't have a huge barrier to entry or that aren't basically gambling?\n\nI've considered web apps but frankly I'm coming up with solutions without very well documented problems. Additionally the time required to build a good functional web app could easily be over a year to ever earn that first dollar.\n\nI've considered scripts for predicting sports card values or for gaining an edge in sports betting but once again that just seems like gambling with extra steps.\n\nI'm too early in my career for consulting.\n\nThe best idea I've come up with is some sort of DE/analytics blog with an emphasis on sports or small scale IoT projects.\n\nDoes anyone have any other suggestions? Should I just be focusing my time on learning new skills to get a raise and/or a new job?\n\n&amp;#x200B;", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any side hustles as a DE with smaller barriers to entry than building a full-scale web app?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qqy5s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688504686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in my mid 20s, single, and have a hybrid job which gives me a crap ton of free time to just sit around wasting time. I already lift, read, etc. so I&amp;#39;ve got all the good habits I could possibly want to build. However, I would like to make more money.&lt;/p&gt;\n\n&lt;p&gt;Are there any side hustles for an early career DE that don&amp;#39;t have a huge barrier to entry or that aren&amp;#39;t basically gambling?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered web apps but frankly I&amp;#39;m coming up with solutions without very well documented problems. Additionally the time required to build a good functional web app could easily be over a year to ever earn that first dollar.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered scripts for predicting sports card values or for gaining an edge in sports betting but once again that just seems like gambling with extra steps.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m too early in my career for consulting.&lt;/p&gt;\n\n&lt;p&gt;The best idea I&amp;#39;ve come up with is some sort of DE/analytics blog with an emphasis on sports or small scale IoT projects.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any other suggestions? Should I just be focusing my time on learning new skills to get a raise and/or a new job?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qqy5s", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qqy5s/are_there_any_side_hustles_as_a_de_with_smaller/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qqy5s/are_there_any_side_hustles_as_a_de_with_smaller/", "subreddit_subscribers": 114179, "created_utc": 1688504686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. A query optimizer that is more effective than manual optimization\n2. Faster log queries with less storage space consumed\n3. 20 times higher concurrency\n4. Enhanced Data Lakehouse capabilities (more data sources supported and faster performance)\n5. A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios\n6. Efficient management of memory and CPU resources\n7. Elastic scaling of computation resources and hot-cold data separation for much lower storage costs\n8. Faster, stabler, and smarter data ingestion\n9. No more OOM errors\n10. Support for Kubernetes deployment\n\n[Release Note](https://doris.apache.org/docs/dev/releasenotes/release-2.0-beta/)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris 2.0 Beta Now Available: Faster, Stabler, and More Versatile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r8zo3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688559364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;A query optimizer that is more effective than manual optimization&lt;/li&gt;\n&lt;li&gt;Faster log queries with less storage space consumed&lt;/li&gt;\n&lt;li&gt;20 times higher concurrency&lt;/li&gt;\n&lt;li&gt;Enhanced Data Lakehouse capabilities (more data sources supported and faster performance)&lt;/li&gt;\n&lt;li&gt;A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios&lt;/li&gt;\n&lt;li&gt;Efficient management of memory and CPU resources&lt;/li&gt;\n&lt;li&gt;Elastic scaling of computation resources and hot-cold data separation for much lower storage costs&lt;/li&gt;\n&lt;li&gt;Faster, stabler, and smarter data ingestion&lt;/li&gt;\n&lt;li&gt;No more OOM errors&lt;/li&gt;\n&lt;li&gt;Support for Kubernetes deployment&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://doris.apache.org/docs/dev/releasenotes/release-2.0-beta/\"&gt;Release Note&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14r8zo3", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r8zo3/apache_doris_20_beta_now_available_faster_stabler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r8zo3/apache_doris_20_beta_now_available_faster_stabler/", "subreddit_subscribers": 114179, "created_utc": 1688559364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently migrating my new teams pipeline from databricks notebook (all in dev, no cicd, or major tests. scheduled in databricks. All spark.sql code, no pyspark at all.) to snowflake +dbt. \n\nWhile everything is going well, I want to create a local development environment everyone on my team can use easily (mostly non engineers). One of the main pain points is that 3/4 of my team has windows computers since they are analysts. \n\nBest way to do this is creating some devcontainers with VScode. And while I've already done this and it's working quite nice, I want to take it a few steps further and want to keep all the development inside VScode. For example, right now, I tests some queries in snowflake worksheets and when it works, I basically copy paste the query to vscode and change the table format to dbt (source or ref). This is a bit tedious for me and for my analysts it will be worse since they are use to get results instantly in databricks notebooks. \n\nIs there actually a better way of developing with dbt? can i possibly run a dbt model and get the query result inside vscode directly (without having to change table name)? \n\nAny other tips would be appreciated. \n\n&amp;#x200B;", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better VSCODE local dev with snowflake+dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r5j5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688549124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently migrating my new teams pipeline from databricks notebook (all in dev, no cicd, or major tests. scheduled in databricks. All spark.sql code, no pyspark at all.) to snowflake +dbt. &lt;/p&gt;\n\n&lt;p&gt;While everything is going well, I want to create a local development environment everyone on my team can use easily (mostly non engineers). One of the main pain points is that 3/4 of my team has windows computers since they are analysts. &lt;/p&gt;\n\n&lt;p&gt;Best way to do this is creating some devcontainers with VScode. And while I&amp;#39;ve already done this and it&amp;#39;s working quite nice, I want to take it a few steps further and want to keep all the development inside VScode. For example, right now, I tests some queries in snowflake worksheets and when it works, I basically copy paste the query to vscode and change the table format to dbt (source or ref). This is a bit tedious for me and for my analysts it will be worse since they are use to get results instantly in databricks notebooks. &lt;/p&gt;\n\n&lt;p&gt;Is there actually a better way of developing with dbt? can i possibly run a dbt model and get the query result inside vscode directly (without having to change table name)? &lt;/p&gt;\n\n&lt;p&gt;Any other tips would be appreciated. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r5j5q", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r5j5q/better_vscode_local_dev_with_snowflakedbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r5j5q/better_vscode_local_dev_with_snowflakedbt/", "subreddit_subscribers": 114179, "created_utc": 1688549124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I wanna read the Kimball books as I've seen them mentioned many times as being a great source of quality information about how to do things.\n\nI see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling\n\nThe Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses\n\nThe Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data\n\n\nShould I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.\n\nThanks a lot guys. Really appreciate the help you've all been", "author_fullname": "t2_p5wlf0g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Kimball to Start with", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qusqd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688514805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I wanna read the Kimball books as I&amp;#39;ve seen them mentioned many times as being a great source of quality information about how to do things.&lt;/p&gt;\n\n&lt;p&gt;I see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data&lt;/p&gt;\n\n&lt;p&gt;Should I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot guys. Really appreciate the help you&amp;#39;ve all been&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qusqd", "is_robot_indexable": true, "report_reasons": null, "author": "El_Cato_Crande", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "subreddit_subscribers": 114179, "created_utc": 1688514805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a Junior DE from Argentina and got contacted via LinkedIn for a DE position in a Miami based Fintech company called fivvy.\n\nThe interview went great, however at the very end the recruiter asked me to write by hand a brief description of myself and the value I would add to the company, sign it and send them a picture so they could asses my personality traits with graphology in lieu of a psychological evaluation.\n\nI am really confused, and considering pulling back from the recruiting process. But maybe it is a cultural thing and I am reading too much into it.\n\nThe role itself is very similar to what I do in my current job(AWS, ETL using glue, requirements gathering etc.) But the pay is roughly 80% more", "author_fullname": "t2_11jrhn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common in the US to ask for a handwritten cover letter in DE(or at all)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rcq73", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688568386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a Junior DE from Argentina and got contacted via LinkedIn for a DE position in a Miami based Fintech company called fivvy.&lt;/p&gt;\n\n&lt;p&gt;The interview went great, however at the very end the recruiter asked me to write by hand a brief description of myself and the value I would add to the company, sign it and send them a picture so they could asses my personality traits with graphology in lieu of a psychological evaluation.&lt;/p&gt;\n\n&lt;p&gt;I am really confused, and considering pulling back from the recruiting process. But maybe it is a cultural thing and I am reading too much into it.&lt;/p&gt;\n\n&lt;p&gt;The role itself is very similar to what I do in my current job(AWS, ETL using glue, requirements gathering etc.) But the pay is roughly 80% more&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14rcq73", "is_robot_indexable": true, "report_reasons": null, "author": "IfThisThenWhat", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rcq73/is_it_common_in_the_us_to_ask_for_a_handwritten/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rcq73/is_it_common_in_the_us_to_ask_for_a_handwritten/", "subreddit_subscribers": 114179, "created_utc": 1688568386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7rg2eq0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg won the table format war: But not in the way you thought it might", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14rcaj9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XsYFMlNEZCDXJMqVj5ipNSy5AE0iyr_5rFyuLsdfKjQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688567397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bitsondatadev.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bitsondatadev.substack.com/p/iceberg-won-the-table-format-war", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?auto=webp&amp;v=enabled&amp;s=6b43e6782abb50094ef2d34a99021b60c20c639a", "width": 1080, "height": 1618}, "resolutions": [{"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e525d7b58e0d859466ef65335c697f07133fbe6c", "width": 108, "height": 161}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c941b71d9b3c6f5474c6bbdaa7dd20bd6aec5c2", "width": 216, "height": 323}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39f026b8f1273327c96114b4aa1a3482d371742d", "width": 320, "height": 479}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ad02b4e8ddf6f18a0a4bf17d725e4caa38d19e3", "width": 640, "height": 958}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=655ccbb038d6e012f114158f4c31150af8726079", "width": 960, "height": 1438}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b107211e8d9b291ec66e7691bf4b048f348c3d6", "width": 1080, "height": 1618}], "variants": {}, "id": "SDJCzYbCv7yEFiUYDPkYEbxyWOF93G9i_gU6hrmUfY4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rcaj9", "is_robot_indexable": true, "report_reasons": null, "author": "bitsondatadev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rcaj9/iceberg_won_the_table_format_war_but_not_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bitsondatadev.substack.com/p/iceberg-won-the-table-format-war", "subreddit_subscribers": 114179, "created_utc": 1688567397.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can we streamline the process of understanding source data? Frequently, questions like \"What business process generates this data and why?\" require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.\n\nTypically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.\n\nAny advice to make this better?", "author_fullname": "t2_55thi7w8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I ensure that my data model accurately represents the data in my OLAP DB? How can I be certain that my DIM and FACT tables effectively capture the business workflow, leading to optimized and efficient queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qvo0e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688517373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can we streamline the process of understanding source data? Frequently, questions like &amp;quot;What business process generates this data and why?&amp;quot; require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.&lt;/p&gt;\n\n&lt;p&gt;Typically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.&lt;/p&gt;\n\n&lt;p&gt;Any advice to make this better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qvo0e", "is_robot_indexable": true, "report_reasons": null, "author": "faizfablillah", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "subreddit_subscribers": 114179, "created_utc": 1688517373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I plan on starting a simple ETL pipeline using Airflow and Kafka and want your guys' opinion on what I plan to do.\n\nI am using the [random user API](https://randomuser.me/api/) to get the data, then performing a simple transformation to prepare it to be put into its respective tables. I plan to simulate spikes of user data generating using a random number generator via Airflow and then pass the data into Kafka using producer nodes. Then I can put the data into a PostgreSQL RDS instance for the data to be stored. I know I don't need to use Kafka, but I want to dabble in Kafka a little to gain some experience. On the note of experience, I know the basic jist of Kafka and Airflow, but I am by no means an expert on either of them; I want to apply the knowledge I have learned so far.\n\nHere is what the DAG would look like:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64\n\n&amp;#x200B;\n\nHere is what the data model would look like:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=655c0eb2d4f5f1034199871f479cec86029f4446\n\n&amp;#x200B;\n\nHere is my [GitHub](https://github.com/Nishal3/) if you want to see and critique my other projects.", "author_fullname": "t2_3arqiq34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Data Engineering Project with Kafka and Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 12, "top_awarded_type": null, "hide_score": true, "media_metadata": {"01epxslza6ab1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 9, "x": 108, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84e4414faacf34bab670573e90939bdf706d18e1"}, {"y": 18, "x": 216, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=638e7a75ac5361579e82a258453133cc6bb18245"}, {"y": 27, "x": 320, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f41f67c8d53ce2403756a59203cb07d28fb133b3"}, {"y": 55, "x": 640, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2c65ddfd03037ac0117eadca4ed0310c03e95e2"}, {"y": 82, "x": 960, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1f20926c6a1b3f7acf25c82333fed1b77c2be9c"}], "s": {"y": 90, "x": 1046, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64"}, "id": "01epxslza6ab1"}, "varxvs70b6ab1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80356744fcd1539a924fc938c05d34ab0098fb43"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce5190fbb4f8d074f3ec88f32897b45d352f0b36"}, {"y": 150, "x": 320, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd7b29c7290da1333ea6980cb8dad64c1b7f77db"}, {"y": 300, "x": 640, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3661598793f34af557ac951512f8c1486ec27453"}, {"y": 451, "x": 960, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1eb10957b2ddb649302821ce8e0ddad18052fbad"}, {"y": 507, "x": 1080, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2804a9739228cac3bda0cfebce10aeb95db00c47"}], "s": {"y": 564, "x": 1200, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=655c0eb2d4f5f1034199871f479cec86029f4446"}, "id": "varxvs70b6ab1"}}, "name": "t3_14rfp9v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eZcC3yPDi1xZFKdBoki8y5_BheHkwheH-I60n_qWzxI.jpg", "edited": 1688577655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688574605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I plan on starting a simple ETL pipeline using Airflow and Kafka and want your guys&amp;#39; opinion on what I plan to do.&lt;/p&gt;\n\n&lt;p&gt;I am using the &lt;a href=\"https://randomuser.me/api/\"&gt;random user API&lt;/a&gt; to get the data, then performing a simple transformation to prepare it to be put into its respective tables. I plan to simulate spikes of user data generating using a random number generator via Airflow and then pass the data into Kafka using producer nodes. Then I can put the data into a PostgreSQL RDS instance for the data to be stored. I know I don&amp;#39;t need to use Kafka, but I want to dabble in Kafka a little to gain some experience. On the note of experience, I know the basic jist of Kafka and Airflow, but I am by no means an expert on either of them; I want to apply the knowledge I have learned so far.&lt;/p&gt;\n\n&lt;p&gt;Here is what the DAG would look like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64\"&gt;https://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is what the data model would look like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=655c0eb2d4f5f1034199871f479cec86029f4446\"&gt;https://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=655c0eb2d4f5f1034199871f479cec86029f4446&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is my &lt;a href=\"https://github.com/Nishal3/\"&gt;GitHub&lt;/a&gt; if you want to see and critique my other projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rfp9v", "is_robot_indexable": true, "report_reasons": null, "author": "RepresentativePen297", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rfp9v/beginner_data_engineering_project_with_kafka_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rfp9v/beginner_data_engineering_project_with_kafka_and/", "subreddit_subscribers": 114179, "created_utc": 1688574605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like your opinion of the Python library Dask. \n\nI made some tests with several datasets with a total of 8 GB and it performed a simple ETL process in 30 sec. \n\nI did the same process wit PySpark and it took 28 sec.  \nI also found this article talking about Spark vs Dask  \n[https://www.coiled.io/blog/moving-from-spark-to-dask](https://www.coiled.io/blog/moving-from-spark-to-dask) \n\nIs Dask that good to handle middle to big-size datasets?   \nThen why is a library not that well known? \n\n&amp;#x200B;", "author_fullname": "t2_7dy3sswp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dask for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r8spe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688558832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like your opinion of the Python library Dask. &lt;/p&gt;\n\n&lt;p&gt;I made some tests with several datasets with a total of 8 GB and it performed a simple ETL process in 30 sec. &lt;/p&gt;\n\n&lt;p&gt;I did the same process wit PySpark and it took 28 sec.&lt;br/&gt;\nI also found this article talking about Spark vs Dask&lt;br/&gt;\n&lt;a href=\"https://www.coiled.io/blog/moving-from-spark-to-dask\"&gt;https://www.coiled.io/blog/moving-from-spark-to-dask&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Is Dask that good to handle middle to big-size datasets?&lt;br/&gt;\nThen why is a library not that well known? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?auto=webp&amp;v=enabled&amp;s=985e0dac5a538651a27facacb88f439ffb706ab1", "width": 2049, "height": 1077}, "resolutions": [{"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b34463d6ffa31246495a19a91c892ec7bcc23ca7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e21104286c21d66fefead2c53a4995959da5675", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbd23e1c247e5be5adc30c6ce5cee34b97b4c220", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bcceb6db91e2355af81f4ae2f3b9e7bf02148b80", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d8fede23f3d1fd2fc38a01ec8fd06bed011bbf6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa5d248f3a623fcc480dc7d3b25f4cdf1690212b", "width": 1080, "height": 567}], "variants": {}, "id": "f7eK9VqpVNGVOYBwzqp50W4KQEUY3gbUPuEbkbhVvp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r8spe", "is_robot_indexable": true, "report_reasons": null, "author": "Asleep-Organization7", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r8spe/dask_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r8spe/dask_for_data_engineering/", "subreddit_subscribers": 114179, "created_utc": 1688558832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone, \n\nWhat is the best resources for understanding how to build out a pipeline from scratch. I'm currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.\n\nIt had me thinking if I was to get the job I wouldn't know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.\n\nI figured I should get started now since it's always good to learn things start to finish.\n\nAny resources you could provide would be great (books, articles, other post, ect...)\n\nThanks in advance!", "author_fullname": "t2_5ejp13jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering start to finish", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzi8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688529422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone, &lt;/p&gt;\n\n&lt;p&gt;What is the best resources for understanding how to build out a pipeline from scratch. I&amp;#39;m currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.&lt;/p&gt;\n\n&lt;p&gt;It had me thinking if I was to get the job I wouldn&amp;#39;t know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.&lt;/p&gt;\n\n&lt;p&gt;I figured I should get started now since it&amp;#39;s always good to learn things start to finish.&lt;/p&gt;\n\n&lt;p&gt;Any resources you could provide would be great (books, articles, other post, ect...)&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qzi8p", "is_robot_indexable": true, "report_reasons": null, "author": "knowledgeMeUp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "subreddit_subscribers": 114179, "created_utc": 1688529422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. \n\nThese data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?", "author_fullname": "t2_dg51ak2mn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "user identity, machine identity and now we need data identity ? what do you think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qws59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688520815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. &lt;/p&gt;\n\n&lt;p&gt;These data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qws59", "is_robot_indexable": true, "report_reasons": null, "author": "Extreme-Summer-2756", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "subreddit_subscribers": 114179, "created_utc": 1688520815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently got a job after completing my Bachelors, as a trainee/junior data engineer in a Fintech , During my college times everyone was talking about SDE/backend/frontend/mobile-dev jobs and I have idea about them that a good developer can earn good with few years of experience.But Data engineering was unheard of and I knew a few things about data science and understood that these 2 are different .\n\nCan you help me by answering these 4 questions in short?\n(even yes /no answers will be appreciated)\n\n1.)Since the demand of Software developers is high and they are in demand everywhere, do data engineers have similar kind of demand in big MNCs and faang type companies.Since Data is increasing day by day and every co. I think would use them so this job profile should be hot but I haven't heard about this job till I got my current job offer.\n\n2.)I have explored frontend and backend web dev , and somewhat liked backend web dev using node js, and while practicing DSA and writing backend I started a liking towards programming, so do data engineers get to code enough ?\n\n3.) I got a basic intro to SQL in my college and then I didn't got much interested in it , so do you guys already have a interest in SQL when you choose Data engineer at first or you started enjoying it when you started working with it?\n\n4.)Can you share that salaries of software developer in your company vs your salary as a data engineer with same year of experience.Is there a huge difference or is it somewhat similar.", "author_fullname": "t2_jh44nvdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do data Engineers get paid Similar to software developers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14res9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688572706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently got a job after completing my Bachelors, as a trainee/junior data engineer in a Fintech , During my college times everyone was talking about SDE/backend/frontend/mobile-dev jobs and I have idea about them that a good developer can earn good with few years of experience.But Data engineering was unheard of and I knew a few things about data science and understood that these 2 are different .&lt;/p&gt;\n\n&lt;p&gt;Can you help me by answering these 4 questions in short?\n(even yes /no answers will be appreciated)&lt;/p&gt;\n\n&lt;p&gt;1.)Since the demand of Software developers is high and they are in demand everywhere, do data engineers have similar kind of demand in big MNCs and faang type companies.Since Data is increasing day by day and every co. I think would use them so this job profile should be hot but I haven&amp;#39;t heard about this job till I got my current job offer.&lt;/p&gt;\n\n&lt;p&gt;2.)I have explored frontend and backend web dev , and somewhat liked backend web dev using node js, and while practicing DSA and writing backend I started a liking towards programming, so do data engineers get to code enough ?&lt;/p&gt;\n\n&lt;p&gt;3.) I got a basic intro to SQL in my college and then I didn&amp;#39;t got much interested in it , so do you guys already have a interest in SQL when you choose Data engineer at first or you started enjoying it when you started working with it?&lt;/p&gt;\n\n&lt;p&gt;4.)Can you share that salaries of software developer in your company vs your salary as a data engineer with same year of experience.Is there a huge difference or is it somewhat similar.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14res9p", "is_robot_indexable": true, "report_reasons": null, "author": "micky_357000", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14res9p/do_data_engineers_get_paid_similar_to_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14res9p/do_data_engineers_get_paid_similar_to_software/", "subreddit_subscribers": 114179, "created_utc": 1688572706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, wanted a second opinion on if this idea is one of those picking up a penny in front of a steam roller things. We are limited to using lambda to make an api call to trino and step functions as the orchestrator\n\nOption 1 - Explicit \n\n    Step function Task 1(Trino Transformation 1) &gt; Task 2(TT2) &gt; Task 3(TT3) \n\nOption 2 - \"recursion\" \n\n    Trigger(send step ID) &gt; Recursive Task(output next step Id), rerun function until end state is reached. \n\nWhat kind safeguard should I put in place to prevent infinite recursion? \n\nThanks!", "author_fullname": "t2_8lbog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a bad idea? Using \"recursion\" in AWS step functions to orchestrate sequential trino steps instead of explicitly assigning every step to a task.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rbu13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688566655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688566372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, wanted a second opinion on if this idea is one of those picking up a penny in front of a steam roller things. We are limited to using lambda to make an api call to trino and step functions as the orchestrator&lt;/p&gt;\n\n&lt;p&gt;Option 1 - Explicit &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Step function Task 1(Trino Transformation 1) &amp;gt; Task 2(TT2) &amp;gt; Task 3(TT3) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Option 2 - &amp;quot;recursion&amp;quot; &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Trigger(send step ID) &amp;gt; Recursive Task(output next step Id), rerun function until end state is reached. \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;What kind safeguard should I put in place to prevent infinite recursion? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rbu13", "is_robot_indexable": true, "report_reasons": null, "author": "AUGcodon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rbu13/is_this_a_bad_idea_using_recursion_in_aws_step/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rbu13/is_this_a_bad_idea_using_recursion_in_aws_step/", "subreddit_subscribers": 114179, "created_utc": 1688566372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently stumbled on a job opportunity that uses Oracle data integrator. As someone who is 'at home' with Oracle, seemed intriguing, but then I checked market share and found Informatica has much greater market share...   \n\n\non the other hand, I am more fond of 'hands-on tools', like writing scripts by myself, not utilizing any kind of GUI.   \nWhat is the relevance and prospects of tools like ODI and/or Informatica, and even Oracle's GoldenGate vs Spark and others?  \n\n\nwhen talking about this, obviously, I am talking about big corporate clients with some regulations and needs for support, etc etc..", "author_fullname": "t2_bnm2tai1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Informatica vs. Oracle Data Integrator vs Oracle GoldenGate vs others (Spark, Python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r6ltr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688552385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently stumbled on a job opportunity that uses Oracle data integrator. As someone who is &amp;#39;at home&amp;#39; with Oracle, seemed intriguing, but then I checked market share and found Informatica has much greater market share...   &lt;/p&gt;\n\n&lt;p&gt;on the other hand, I am more fond of &amp;#39;hands-on tools&amp;#39;, like writing scripts by myself, not utilizing any kind of GUI.&lt;br/&gt;\nWhat is the relevance and prospects of tools like ODI and/or Informatica, and even Oracle&amp;#39;s GoldenGate vs Spark and others?  &lt;/p&gt;\n\n&lt;p&gt;when talking about this, obviously, I am talking about big corporate clients with some regulations and needs for support, etc etc..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r6ltr", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Cancel_7891", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r6ltr/informatica_vs_oracle_data_integrator_vs_oracle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r6ltr/informatica_vs_oracle_data_integrator_vs_oracle/", "subreddit_subscribers": 114179, "created_utc": 1688552385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Make Your Data Ingestion Simple, Fast, And Robust - 11 Advanced best practices for working with data ingestion pipelines.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_14r4zcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l9qusAuLPw7VDO87OQ_ds_wMR85zOD0Cha7Av6hEh6c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688547389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "meltano.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://meltano.com/blog/how-to-make-your-data-ingestion-simple-fast-and-robust/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?auto=webp&amp;v=enabled&amp;s=7720628d9a0212948420b874d2e71fc85101c13b", "width": 1440, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ef88de54f10d16905227ea609f981d8a2db7058", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d56d7b3a0d68c53284e6568ac0810f27fd4d07a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a253637116c25aad58aba1391cfc1fc2359b9f6", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36478f2a1f13ba7b3e80fff977e3465cd0f1f155", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26032ee0e078c185a78e5530051273f586a69b79", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cca4f827fe0072829e77e25a7c5923100f7b9fbd", "width": 1080, "height": 810}], "variants": {}, "id": "DfcrVMfetugEAM3zA9zmoKT9fQhKdRUq7Wgvmj4oU5k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14r4zcp", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r4zcp/how_to_make_your_data_ingestion_simple_fast_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://meltano.com/blog/how-to-make-your-data-ingestion-simple-fast-and-robust/", "subreddit_subscribers": 114179, "created_utc": 1688547389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in Desktop Support and always had an interest in Data Analytics and Engineering. Will I need experience working as a Data Analyst or DBA to get a job in Data Engineering? Or will a portfolio of python/SQL DE related projects help land a position? \n\nI only ask since I've seen past posts that mostly transition from DA. When I look up job postings, they require years of experience but I'm not entirely sure where I can go from IT Desktop. I signed up for a Start Data Engineering email course that I'm hoping will give some guidance but I was curious if anyone started from a non-DA background.", "author_fullname": "t2_e21m22x4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from a IT Desktop Support to Data Engineering question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rghgv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688576250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in Desktop Support and always had an interest in Data Analytics and Engineering. Will I need experience working as a Data Analyst or DBA to get a job in Data Engineering? Or will a portfolio of python/SQL DE related projects help land a position? &lt;/p&gt;\n\n&lt;p&gt;I only ask since I&amp;#39;ve seen past posts that mostly transition from DA. When I look up job postings, they require years of experience but I&amp;#39;m not entirely sure where I can go from IT Desktop. I signed up for a Start Data Engineering email course that I&amp;#39;m hoping will give some guidance but I was curious if anyone started from a non-DA background.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14rghgv", "is_robot_indexable": true, "report_reasons": null, "author": "Green_Merlin6", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rghgv/transitioning_from_a_it_desktop_support_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rghgv/transitioning_from_a_it_desktop_support_to_data/", "subreddit_subscribers": 114179, "created_utc": 1688576250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3ve2psi7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to ingest records from Cosmos DB using Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_14rg8sp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K9HWxxNow5rZ1qHfE85vs6WW8VUI2Nepbluw3PUw1JA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688575754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "harshmatharu.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://harshmatharu.com/blog/ingest-records-from-cosmosdb-using-spark", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?auto=webp&amp;v=enabled&amp;s=1de2aca917b90b3cc72b9ff239383268a0dc0b51", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74737eb465d78c5776ace82d6198ea07b3974837", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a58e0d510f9fd695ba5af32714ed3d876300827", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcfa83755ef2e572549fcfcf59e6cad69dd4e958", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eca423e4ee6c122e76905f0c73a2367123a7005f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bac243d049140155ee5fbcb7bf090bf78b39c170", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1760d0644c4d83951578a257fb8666dce146b79", "width": 1080, "height": 540}], "variants": {}, "id": "A8iVhGJK0JkIk30sZdO6ZQLeU7OXOeoPiLa7dFQ7U0M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rg8sp", "is_robot_indexable": true, "report_reasons": null, "author": "Dramatic_Necessary_3", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rg8sp/how_to_ingest_records_from_cosmos_db_using_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://harshmatharu.com/blog/ingest-records-from-cosmosdb-using-spark", "subreddit_subscribers": 114179, "created_utc": 1688575754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data processing becomes critical when training a robust machine learning model. We occasionally need to restructure and add new data to the datasets to increase the efficiency of the data.\n\nWe'll look at how to combine multiple datasets and merge multiple datasets with the same and different column names in this article. We'll use the `pandas` library's following functions to carry out these operations.\n\n* `pandas.concat()`\n* `pandas.merge()`\n* `pandas.DataFrame.join()`\n\nThe `concat()` function in `pandas` is a go-to option for combining the DataFrames due to its simplicity. However, if we want more control over how the data is joined and on which column in the DataFrame, the `merge()` function is a good choice. If we want to join data based on the index, we should use the `join()` method.\n\n**Here is the guide for performing the joining, merging, and combining multiple datasets using pandas\ud83d\udc47\ud83d\udc47\ud83d\udc47**\n\n[Join, Merge, and Combine Multiple Datasets Using pandas](https://geekpython.in/multiple-datasets-integration-using-pandas)", "author_fullname": "t2_pb3nzmce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Join, Merge, and Combine Multiple Datasets Using pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rfc42", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688573885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data processing becomes critical when training a robust machine learning model. We occasionally need to restructure and add new data to the datasets to increase the efficiency of the data.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ll look at how to combine multiple datasets and merge multiple datasets with the same and different column names in this article. We&amp;#39;ll use the &lt;code&gt;pandas&lt;/code&gt; library&amp;#39;s following functions to carry out these operations.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;pandas.concat()&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;pandas.merge()&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;pandas.DataFrame.join()&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The &lt;code&gt;concat()&lt;/code&gt; function in &lt;code&gt;pandas&lt;/code&gt; is a go-to option for combining the DataFrames due to its simplicity. However, if we want more control over how the data is joined and on which column in the DataFrame, the &lt;code&gt;merge()&lt;/code&gt; function is a good choice. If we want to join data based on the index, we should use the &lt;code&gt;join()&lt;/code&gt; method.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here is the guide for performing the joining, merging, and combining multiple datasets using pandas\ud83d\udc47\ud83d\udc47\ud83d\udc47&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://geekpython.in/multiple-datasets-integration-using-pandas\"&gt;Join, Merge, and Combine Multiple Datasets Using pandas&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?auto=webp&amp;v=enabled&amp;s=a86eb9301b61fa532a6d31f179f928edeac5c80f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d24a3db04a0e4fc4a34d774000d20ee3771c1662", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8028e69481dcd025a846db21a926b6b68b0a0ec6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ab601003583d9a1723acb0c83e7410f66d07c0a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25157b9375bd2ae56788ea4f0c9a96d2e8324291", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=079aa6053c57cbf1981b753528aba55790fc8cf8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7537826672a08f63baec8c917ad34c6f6e1c0b4", "width": 1080, "height": 567}], "variants": {}, "id": "gRfQV35yrH1dVxSBfhVGiluToaN_lKvBv96jgo5GOSQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rfc42", "is_robot_indexable": true, "report_reasons": null, "author": "python4geeks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rfc42/join_merge_and_combine_multiple_datasets_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rfc42/join_merge_and_combine_multiple_datasets_using/", "subreddit_subscribers": 114179, "created_utc": 1688573885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have experience moving from the dbt Team plan to the Enterprise tier?  Just trying to understand the rough pricing difference per user and biggest benefits.\n\n&amp;#x200B;\n\nBACKGROUND: \n\nI work for a company that consists of 3 historically very decentralized business units where I have built out a data warehouse for 1 of the 3 using dbt Team with a small team of 3 people.  Trying to understand whether it makes sense to get Enterprise across all 3 to develop more consistently across as well as facilitating a 4th corporate centralized DW from data shared up from the business units.", "author_fullname": "t2_oarfc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Enterprise vs Team Plan Pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rf3ss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688573384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have experience moving from the dbt Team plan to the Enterprise tier?  Just trying to understand the rough pricing difference per user and biggest benefits.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;BACKGROUND: &lt;/p&gt;\n\n&lt;p&gt;I work for a company that consists of 3 historically very decentralized business units where I have built out a data warehouse for 1 of the 3 using dbt Team with a small team of 3 people.  Trying to understand whether it makes sense to get Enterprise across all 3 to develop more consistently across as well as facilitating a 4th corporate centralized DW from data shared up from the business units.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rf3ss", "is_robot_indexable": true, "report_reasons": null, "author": "morse__code", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rf3ss/dbt_enterprise_vs_team_plan_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rf3ss/dbt_enterprise_vs_team_plan_pricing/", "subreddit_subscribers": 114179, "created_utc": 1688573384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Object Management for AI/ML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 40, "top_awarded_type": null, "hide_score": true, "name": "t3_14redmy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/0YCqHRFf0iYhbX6oxneRn3LCneBUXrHFC-zTy7XgQM4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688571886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/object-management-for-ai-ml/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/o90jjJj9nPUvvV546dwgSBCTAFlyqtwVdpE1m6PN3rI.jpg?auto=webp&amp;v=enabled&amp;s=7f3eb49fcd6af6071327985c0611b5602e7e770d", "width": 2000, "height": 584}, "resolutions": [{"url": "https://external-preview.redd.it/o90jjJj9nPUvvV546dwgSBCTAFlyqtwVdpE1m6PN3rI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4d97aa81fceb608d18c8f496a18a43e5f5f2d29", "width": 108, "height": 31}, {"url": "https://external-preview.redd.it/o90jjJj9nPUvvV546dwgSBCTAFlyqtwVdpE1m6PN3rI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=948e0a4407108ed599ace5b55f90062407e9ff07", "width": 216, "height": 63}, {"url": "https://external-preview.redd.it/o90jjJj9nPUvvV546dwgSBCTAFlyqtwVdpE1m6PN3rI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2702d4ff96ea643aa39699075161b26e75c7e6b2", "width": 320, "height": 93}, {"url": "https://external-preview.redd.it/o90jjJj9nPUvvV546dwgSBCTAFlyqtwVdpE1m6PN3rI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12f0b37cddb13c50e8456574612ac6022704631b", "width": 640, "height": 186}, {"url": "https://external-preview.redd.it/o90jjJj9nPUvvV546dwgSBCTAFlyqtwVdpE1m6PN3rI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f386c4ce39383f942bb669bd3a8d1c849e9464c3", "width": 960, "height": 280}, {"url": "https://external-preview.redd.it/o90jjJj9nPUvvV546dwgSBCTAFlyqtwVdpE1m6PN3rI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f41775c699ca1be1c2bc381bf438bd725d07813", "width": 1080, "height": 315}], "variants": {}, "id": "GKbSloohQhvXsZeFPwXiii_nLuOQoAE5_jiZgDXDRow"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14redmy", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14redmy/object_management_for_aiml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/object-management-for-ai-ml/", "subreddit_subscribers": 114179, "created_utc": 1688571886.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}