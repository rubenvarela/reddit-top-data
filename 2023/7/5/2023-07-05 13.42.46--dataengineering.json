{"kind": "Listing", "data": {"after": "t3_14qny43", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.\n\nI have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next\n\nFor anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.\n\nThe resources I used were:\n\n1. [https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/](https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/) \\- used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics\n2. [https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc](https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc) \\- a good reference guide\n3. [https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF](https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF) \\- essentially 90% of the actual exam questions pretty decent explanations  \n\n\nP.S Sorry couldn't forget to include [Spark Internals Explanation](https://www.youtube.com/watch?v=7ooZ4S7Ay6Y)! A phenomenal resource to dive deep on how Spark works under the hood", "author_fullname": "t2_ic83gko1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got certified! - Databricks certified associate developer for apache spark 3.0 in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzt8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688544365.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688530389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.&lt;/p&gt;\n\n&lt;p&gt;I have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next&lt;/p&gt;\n\n&lt;p&gt;For anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.&lt;/p&gt;\n\n&lt;p&gt;The resources I used were:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/\"&gt;https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/&lt;/a&gt; - used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc\"&gt;https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc&lt;/a&gt; - a good reference guide&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF\"&gt;https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF&lt;/a&gt; - essentially 90% of the actual exam questions pretty decent explanations&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;P.S Sorry couldn&amp;#39;t forget to include &lt;a href=\"https://www.youtube.com/watch?v=7ooZ4S7Ay6Y\"&gt;Spark Internals Explanation&lt;/a&gt;! A phenomenal resource to dive deep on how Spark works under the hood&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qzt8y", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Debate_94", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "subreddit_subscribers": 114145, "created_utc": 1688530389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am the only DE in the team, and we want to hire a senior DE soon. My manager has asked me to interview somebody with ~20 years of experience in data engineering while I have only ~4 YOE as a data engineer. When I looked at this candidate\u2019s resume, I got overwhelmed by the expertise they claimed to have. I feel I don\u2019t have enough knowledge to accurately assess this candidate. How should I go about interviewing this candidate? What sort of questions should I ask?", "author_fullname": "t2_cbdg7n9sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should you interview somebody with vastly more experience than yourself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qslvf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688508789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the only DE in the team, and we want to hire a senior DE soon. My manager has asked me to interview somebody with ~20 years of experience in data engineering while I have only ~4 YOE as a data engineer. When I looked at this candidate\u2019s resume, I got overwhelmed by the expertise they claimed to have. I feel I don\u2019t have enough knowledge to accurately assess this candidate. How should I go about interviewing this candidate? What sort of questions should I ask?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14qslvf", "is_robot_indexable": true, "report_reasons": null, "author": "fun_coordinator", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qslvf/how_should_you_interview_somebody_with_vastly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qslvf/how_should_you_interview_somebody_with_vastly/", "subreddit_subscribers": 114145, "created_utc": 1688508789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have DE interview coming up  and I am thinking to prepare few questions based on handling ETL errors.\n\nA data pipeline should address these issues:\n\n1\u00b7 Partial loads (A scenarios where Partial processing of the files or records or any failures of ETL Jobs occurred; to clean up a few records and re-run the job)\n\n&amp;#x200B;\n\n2 \u00b7 Restart-ability (You have to re-run from a previous successful run because a downstream dependent job failed or reprocess process some data from history. for e.g. We need to run since last Monday or a random date)\n\n&amp;#x200B;\n\n3\u00b7 Re-processing the same files (A source issue where they sent multiple files; We need to pick the right records)\n\n&amp;#x200B;\n\n4 \u00b7 Catch-up loads (In case you missed executing jobs for specific runs and playing catch up; Batch Processing) .\n\nAny Answers on these would be super helpful. Thanks. \ud83d\ude4f ", "author_fullname": "t2_c4v6qwrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Interview question for handling ETL pipeline errors.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qiuds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688485836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have DE interview coming up  and I am thinking to prepare few questions based on handling ETL errors.&lt;/p&gt;\n\n&lt;p&gt;A data pipeline should address these issues:&lt;/p&gt;\n\n&lt;p&gt;1\u00b7 Partial loads (A scenarios where Partial processing of the files or records or any failures of ETL Jobs occurred; to clean up a few records and re-run the job)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2 \u00b7 Restart-ability (You have to re-run from a previous successful run because a downstream dependent job failed or reprocess process some data from history. for e.g. We need to run since last Monday or a random date)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;3\u00b7 Re-processing the same files (A source issue where they sent multiple files; We need to pick the right records)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;4 \u00b7 Catch-up loads (In case you missed executing jobs for specific runs and playing catch up; Batch Processing) .&lt;/p&gt;\n\n&lt;p&gt;Any Answers on these would be super helpful. Thanks. \ud83d\ude4f &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14qiuds", "is_robot_indexable": true, "report_reasons": null, "author": "HealthyCobbler1588", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qiuds/de_interview_question_for_handling_etl_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qiuds/de_interview_question_for_handling_etl_pipeline/", "subreddit_subscribers": 114145, "created_utc": 1688485836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a small firm that is about thirty years behind in tech.  All of our data is in spreadsheets scattered across a vast and confusing folder tree. We are looking to use alteryx as a no-code ETL and eventually creating an azure database. I noticed most DEs use dagster or airflow. Does anybody have experience with a no code tool like Alteryx? I worry no-code equates to no flexibility", "author_fullname": "t2_4euwn6ok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody use Alteryx", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qi60z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688484263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a small firm that is about thirty years behind in tech.  All of our data is in spreadsheets scattered across a vast and confusing folder tree. We are looking to use alteryx as a no-code ETL and eventually creating an azure database. I noticed most DEs use dagster or airflow. Does anybody have experience with a no code tool like Alteryx? I worry no-code equates to no flexibility&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qi60z", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Enthusiasm-6194", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qi60z/anybody_use_alteryx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qi60z/anybody_use_alteryx/", "subreddit_subscribers": 114145, "created_utc": 1688484263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Link: https://trello.com/b/Rvw8Jygt/interview-preparation\n\nI have been looking for entry level or junior data engineering roles, and have been using a Trello board to help with interview preparation.\n\nIt contains lists of common interview questions, technical questions, and behavioural questions.\n\nI\u2019ve tried tagging behavioural questions based on attribute it\u2019s measuring (e.g., conflict management) so you can filter by these.\n\nFor the technical questions, these are a combination of questions I\u2019ve been asked, or questions you could be asked if applying for a data engineering or analyst role.\n\nFor each card/question you can write potential answers in the description field.\n\nYou can obviously customise it however you like, but hopefully is useful for some of you", "author_fullname": "t2_osh2xtjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created an interview preparation Trello template with technical &amp; behavioural questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ql6jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688491177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Link: &lt;a href=\"https://trello.com/b/Rvw8Jygt/interview-preparation\"&gt;https://trello.com/b/Rvw8Jygt/interview-preparation&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have been looking for entry level or junior data engineering roles, and have been using a Trello board to help with interview preparation.&lt;/p&gt;\n\n&lt;p&gt;It contains lists of common interview questions, technical questions, and behavioural questions.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried tagging behavioural questions based on attribute it\u2019s measuring (e.g., conflict management) so you can filter by these.&lt;/p&gt;\n\n&lt;p&gt;For the technical questions, these are a combination of questions I\u2019ve been asked, or questions you could be asked if applying for a data engineering or analyst role.&lt;/p&gt;\n\n&lt;p&gt;For each card/question you can write potential answers in the description field.&lt;/p&gt;\n\n&lt;p&gt;You can obviously customise it however you like, but hopefully is useful for some of you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14ql6jc", "is_robot_indexable": true, "report_reasons": null, "author": "TheDataPanda", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ql6jc/i_created_an_interview_preparation_trello/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ql6jc/i_created_an_interview_preparation_trello/", "subreddit_subscribers": 114145, "created_utc": 1688491177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I was first learning dbt I found a lot of really great resources (dbt docs, blog posts, slack threads etc.) and wanted to try to put that all together in one place for anyone else new to dbt, or anyone wanting to learn a bit more about it.   \nThe guide covers everything from \u2018what is dbt?\u2019 to advanced topics like model refactoring best practices.  \nI hope it's useful! **And if you spot anything missing, or ways to make it better, please let me know!**  \n\n\nDesktop link: [https://count.co/canvas/JpkaYdqr9oN](https://count.co/canvas/JpkaYdqr9oN)  \nMobile link: [https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914](https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914)  \n\n\nFull disclosure: I do work for [count.co](https://count.co), the canvas in which the guide was built. ", "author_fullname": "t2_1zfun4sx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I attempted to create the Ultimate Guide to dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r4v10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688547009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was first learning dbt I found a lot of really great resources (dbt docs, blog posts, slack threads etc.) and wanted to try to put that all together in one place for anyone else new to dbt, or anyone wanting to learn a bit more about it.&lt;br/&gt;\nThe guide covers everything from \u2018what is dbt?\u2019 to advanced topics like model refactoring best practices.&lt;br/&gt;\nI hope it&amp;#39;s useful! &lt;strong&gt;And if you spot anything missing, or ways to make it better, please let me know!&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Desktop link: &lt;a href=\"https://count.co/canvas/JpkaYdqr9oN\"&gt;https://count.co/canvas/JpkaYdqr9oN&lt;/a&gt;&lt;br/&gt;\nMobile link: &lt;a href=\"https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914\"&gt;https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Full disclosure: I do work for &lt;a href=\"https://count.co\"&gt;count.co&lt;/a&gt;, the canvas in which the guide was built. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?auto=webp&amp;v=enabled&amp;s=c90d7e97aa224a896783d02a2a830784cb2c0920", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bd97f02fcc00d06a42618c0358185b4bc650318", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb4ee7c5f99ac12f4224cd68ccf6e07358a570c8", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20558ea1403333413bd92f54c54785a76892a5b7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6edc187fbdad61643782e43cb3dad2664e040241", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea269da98515be9aa97a81600be483c293aee457", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3fdea5709efc2342950519678dccbfa5b6a5bc9", "width": 1080, "height": 720}], "variants": {}, "id": "2h6z0wcxfeyGYPsAUSLRq1EjtP-b9N_kgrbXZ-BV1x0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "14r4v10", "is_robot_indexable": true, "report_reasons": null, "author": "tbrownlow", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r4v10/i_attempted_to_create_the_ultimate_guide_to_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r4v10/i_attempted_to_create_the_ultimate_guide_to_dbt/", "subreddit_subscribers": 114145, "created_utc": 1688547009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). \n\nI get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. \n\nI have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). \n\nHow do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?", "author_fullname": "t2_pu047jjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Performance vs On-Prem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14quid6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688513977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). &lt;/p&gt;\n\n&lt;p&gt;I get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. &lt;/p&gt;\n\n&lt;p&gt;I have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). &lt;/p&gt;\n\n&lt;p&gt;How do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14quid6", "is_robot_indexable": true, "report_reasons": null, "author": "atlvernburn", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "subreddit_subscribers": 114145, "created_utc": 1688513977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in my mid 20s, single, and have a hybrid job which gives me a crap ton of free time to just sit around wasting time. I already lift, read, etc. so I've got all the good habits I could possibly want to build. However, I would like to make more money.\n\nAre there any side hustles for an early career DE that don't have a huge barrier to entry or that aren't basically gambling?\n\nI've considered web apps but frankly I'm coming up with solutions without very well documented problems. Additionally the time required to build a good functional web app could easily be over a year to ever earn that first dollar.\n\nI've considered scripts for predicting sports card values or for gaining an edge in sports betting but once again that just seems like gambling with extra steps.\n\nI'm too early in my career for consulting.\n\nThe best idea I've come up with is some sort of DE/analytics blog with an emphasis on sports or small scale IoT projects.\n\nDoes anyone have any other suggestions? Should I just be focusing my time on learning new skills to get a raise and/or a new job?\n\n&amp;#x200B;", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any side hustles as a DE with smaller barriers to entry than building a full-scale web app?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qqy5s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688504686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in my mid 20s, single, and have a hybrid job which gives me a crap ton of free time to just sit around wasting time. I already lift, read, etc. so I&amp;#39;ve got all the good habits I could possibly want to build. However, I would like to make more money.&lt;/p&gt;\n\n&lt;p&gt;Are there any side hustles for an early career DE that don&amp;#39;t have a huge barrier to entry or that aren&amp;#39;t basically gambling?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered web apps but frankly I&amp;#39;m coming up with solutions without very well documented problems. Additionally the time required to build a good functional web app could easily be over a year to ever earn that first dollar.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered scripts for predicting sports card values or for gaining an edge in sports betting but once again that just seems like gambling with extra steps.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m too early in my career for consulting.&lt;/p&gt;\n\n&lt;p&gt;The best idea I&amp;#39;ve come up with is some sort of DE/analytics blog with an emphasis on sports or small scale IoT projects.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any other suggestions? Should I just be focusing my time on learning new skills to get a raise and/or a new job?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qqy5s", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qqy5s/are_there_any_side_hustles_as_a_de_with_smaller/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qqy5s/are_there_any_side_hustles_as_a_de_with_smaller/", "subreddit_subscribers": 114145, "created_utc": 1688504686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lets assume we're talking about structured data that's been pulled into a lake.\n\nIn most cases, data has certain characteristics that you might search by (indexable columns) (\"employee id\") and/or have values that might be optimized for read (e.g., numeric values in a columnstore structure).\n\nIf all you have is just progressively cleaner layers of data that's actually just in object store (e.g., parquet files in s3) but doesn't use anything like what I described above, how is that efficient to query?\n\nMy guess is that they're using a layer that brute forces the efficiency (distributed queries), or the product has an additional part that actually lets you store the data in a more traditionally table like structure.", "author_fullname": "t2_ahf8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do Lakes Provide Adequate Query Performance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qfef7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688477719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets assume we&amp;#39;re talking about structured data that&amp;#39;s been pulled into a lake.&lt;/p&gt;\n\n&lt;p&gt;In most cases, data has certain characteristics that you might search by (indexable columns) (&amp;quot;employee id&amp;quot;) and/or have values that might be optimized for read (e.g., numeric values in a columnstore structure).&lt;/p&gt;\n\n&lt;p&gt;If all you have is just progressively cleaner layers of data that&amp;#39;s actually just in object store (e.g., parquet files in s3) but doesn&amp;#39;t use anything like what I described above, how is that efficient to query?&lt;/p&gt;\n\n&lt;p&gt;My guess is that they&amp;#39;re using a layer that brute forces the efficiency (distributed queries), or the product has an additional part that actually lets you store the data in a more traditionally table like structure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qfef7", "is_robot_indexable": true, "report_reasons": null, "author": "PencilBoy99", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qfef7/how_do_lakes_provide_adequate_query_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qfef7/how_do_lakes_provide_adequate_query_performance/", "subreddit_subscribers": 114145, "created_utc": 1688477719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a junior data analyst shifting towards a data engineering role. We are implementing a modern data stack with azure blob storage, azure synapse and databricks. We just have one source of data (homegrown ERP system developed in-house) using sql server. The ERP system is pretty bad in terms of data quality (poor data, lots of etl to do). What\u2019s the best way to approach data engineering? Our plan is use databricks notebooks for etl, synapse pipelines for orchestration, great expectations for validations. Our team is intermediate in Python, but looking to grow. Solution should be simple, yet scalable. Team of 5. Any suggestions/tips?", "author_fullname": "t2_56ltry44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing a modern data platform in a small team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qiyie", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688486091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a junior data analyst shifting towards a data engineering role. We are implementing a modern data stack with azure blob storage, azure synapse and databricks. We just have one source of data (homegrown ERP system developed in-house) using sql server. The ERP system is pretty bad in terms of data quality (poor data, lots of etl to do). What\u2019s the best way to approach data engineering? Our plan is use databricks notebooks for etl, synapse pipelines for orchestration, great expectations for validations. Our team is intermediate in Python, but looking to grow. Solution should be simple, yet scalable. Team of 5. Any suggestions/tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qiyie", "is_robot_indexable": true, "report_reasons": null, "author": "Specific-Passage", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qiyie/implementing_a_modern_data_platform_in_a_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qiyie/implementing_a_modern_data_platform_in_a_small/", "subreddit_subscribers": 114145, "created_utc": 1688486091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I wanna read the Kimball books as I've seen them mentioned many times as being a great source of quality information about how to do things.\n\nI see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling\n\nThe Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses\n\nThe Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data\n\n\nShould I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.\n\nThanks a lot guys. Really appreciate the help you've all been", "author_fullname": "t2_p5wlf0g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Kimball to Start with", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qusqd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688514805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I wanna read the Kimball books as I&amp;#39;ve seen them mentioned many times as being a great source of quality information about how to do things.&lt;/p&gt;\n\n&lt;p&gt;I see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data&lt;/p&gt;\n\n&lt;p&gt;Should I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot guys. Really appreciate the help you&amp;#39;ve all been&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qusqd", "is_robot_indexable": true, "report_reasons": null, "author": "El_Cato_Crande", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "subreddit_subscribers": 114145, "created_utc": 1688514805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. A query optimizer that is more effective than manual optimization\n2. Faster log queries with less storage space consumed\n3. 20 times higher concurrency\n4. Enhanced Data Lakehouse capabilities (more data sources supported and faster performance)\n5. A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios\n6. Efficient management of memory and CPU resources\n7. Elastic scaling of computation resources and hot-cold data separation for much lower storage costs\n8. Faster, stabler, and smarter data ingestion\n9. No more OOM errors\n10. Support for Kubernetes deployment\n\n[Release Note](https://doris.apache.org/docs/dev/releasenotes/release-2.0-beta/)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris 2.0 Beta Now Available: Faster, Stabler, and More Versatile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14r8zo3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688559364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;A query optimizer that is more effective than manual optimization&lt;/li&gt;\n&lt;li&gt;Faster log queries with less storage space consumed&lt;/li&gt;\n&lt;li&gt;20 times higher concurrency&lt;/li&gt;\n&lt;li&gt;Enhanced Data Lakehouse capabilities (more data sources supported and faster performance)&lt;/li&gt;\n&lt;li&gt;A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios&lt;/li&gt;\n&lt;li&gt;Efficient management of memory and CPU resources&lt;/li&gt;\n&lt;li&gt;Elastic scaling of computation resources and hot-cold data separation for much lower storage costs&lt;/li&gt;\n&lt;li&gt;Faster, stabler, and smarter data ingestion&lt;/li&gt;\n&lt;li&gt;No more OOM errors&lt;/li&gt;\n&lt;li&gt;Support for Kubernetes deployment&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://doris.apache.org/docs/dev/releasenotes/release-2.0-beta/\"&gt;Release Note&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14r8zo3", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r8zo3/apache_doris_20_beta_now_available_faster_stabler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r8zo3/apache_doris_20_beta_now_available_faster_stabler/", "subreddit_subscribers": 114145, "created_utc": 1688559364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently migrating my new teams pipeline from databricks notebook (all in dev, no cicd, or major tests. scheduled in databricks. All spark.sql code, no pyspark at all.) to snowflake +dbt. \n\nWhile everything is going well, I want to create a local development environment everyone on my team can use easily (mostly non engineers). One of the main pain points is that 3/4 of my team has windows computers since they are analysts. \n\nBest way to do this is creating some devcontainers with VScode. And while I've already done this and it's working quite nice, I want to take it a few steps further and want to keep all the development inside VScode. For example, right now, I tests some queries in snowflake worksheets and when it works, I basically copy paste the query to vscode and change the table format to dbt (source or ref). This is a bit tedious for me and for my analysts it will be worse since they are use to get results instantly in databricks notebooks. \n\nIs there actually a better way of developing with dbt? can i possibly run a dbt model and get the query result inside vscode directly (without having to change table name)? \n\nAny other tips would be appreciated. \n\n&amp;#x200B;", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better VSCODE local dev with snowflake+dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r5j5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688549124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently migrating my new teams pipeline from databricks notebook (all in dev, no cicd, or major tests. scheduled in databricks. All spark.sql code, no pyspark at all.) to snowflake +dbt. &lt;/p&gt;\n\n&lt;p&gt;While everything is going well, I want to create a local development environment everyone on my team can use easily (mostly non engineers). One of the main pain points is that 3/4 of my team has windows computers since they are analysts. &lt;/p&gt;\n\n&lt;p&gt;Best way to do this is creating some devcontainers with VScode. And while I&amp;#39;ve already done this and it&amp;#39;s working quite nice, I want to take it a few steps further and want to keep all the development inside VScode. For example, right now, I tests some queries in snowflake worksheets and when it works, I basically copy paste the query to vscode and change the table format to dbt (source or ref). This is a bit tedious for me and for my analysts it will be worse since they are use to get results instantly in databricks notebooks. &lt;/p&gt;\n\n&lt;p&gt;Is there actually a better way of developing with dbt? can i possibly run a dbt model and get the query result inside vscode directly (without having to change table name)? &lt;/p&gt;\n\n&lt;p&gt;Any other tips would be appreciated. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r5j5q", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r5j5q/better_vscode_local_dev_with_snowflakedbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r5j5q/better_vscode_local_dev_with_snowflakedbt/", "subreddit_subscribers": 114145, "created_utc": 1688549124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can we streamline the process of understanding source data? Frequently, questions like \"What business process generates this data and why?\" require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.\n\nTypically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.\n\nAny advice to make this better?", "author_fullname": "t2_55thi7w8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I ensure that my data model accurately represents the data in my OLAP DB? How can I be certain that my DIM and FACT tables effectively capture the business workflow, leading to optimized and efficient queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qvo0e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688517373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can we streamline the process of understanding source data? Frequently, questions like &amp;quot;What business process generates this data and why?&amp;quot; require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.&lt;/p&gt;\n\n&lt;p&gt;Typically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.&lt;/p&gt;\n\n&lt;p&gt;Any advice to make this better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qvo0e", "is_robot_indexable": true, "report_reasons": null, "author": "faizfablillah", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "subreddit_subscribers": 114145, "created_utc": 1688517373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like your opinion of the Python library Dask. \n\nI made some tests with several datasets with a total of 8 GB and it performed a simple ETL process in 30 sec. \n\nI did the same process wit PySpark and it took 28 sec.  \nI also found this article talking about Spark vs Dask  \n[https://www.coiled.io/blog/moving-from-spark-to-dask](https://www.coiled.io/blog/moving-from-spark-to-dask) \n\nIs Dask that good to handle middle to big-size datasets?   \nThen why is a library not that well known? \n\n&amp;#x200B;", "author_fullname": "t2_7dy3sswp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dask for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14r8spe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688558832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like your opinion of the Python library Dask. &lt;/p&gt;\n\n&lt;p&gt;I made some tests with several datasets with a total of 8 GB and it performed a simple ETL process in 30 sec. &lt;/p&gt;\n\n&lt;p&gt;I did the same process wit PySpark and it took 28 sec.&lt;br/&gt;\nI also found this article talking about Spark vs Dask&lt;br/&gt;\n&lt;a href=\"https://www.coiled.io/blog/moving-from-spark-to-dask\"&gt;https://www.coiled.io/blog/moving-from-spark-to-dask&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Is Dask that good to handle middle to big-size datasets?&lt;br/&gt;\nThen why is a library not that well known? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?auto=webp&amp;v=enabled&amp;s=985e0dac5a538651a27facacb88f439ffb706ab1", "width": 2049, "height": 1077}, "resolutions": [{"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b34463d6ffa31246495a19a91c892ec7bcc23ca7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e21104286c21d66fefead2c53a4995959da5675", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbd23e1c247e5be5adc30c6ce5cee34b97b4c220", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bcceb6db91e2355af81f4ae2f3b9e7bf02148b80", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d8fede23f3d1fd2fc38a01ec8fd06bed011bbf6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa5d248f3a623fcc480dc7d3b25f4cdf1690212b", "width": 1080, "height": 567}], "variants": {}, "id": "f7eK9VqpVNGVOYBwzqp50W4KQEUY3gbUPuEbkbhVvp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r8spe", "is_robot_indexable": true, "report_reasons": null, "author": "Asleep-Organization7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r8spe/dask_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r8spe/dask_for_data_engineering/", "subreddit_subscribers": 114145, "created_utc": 1688558832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone, \n\nWhat is the best resources for understanding how to build out a pipeline from scratch. I'm currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.\n\nIt had me thinking if I was to get the job I wouldn't know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.\n\nI figured I should get started now since it's always good to learn things start to finish.\n\nAny resources you could provide would be great (books, articles, other post, ect...)\n\nThanks in advance!", "author_fullname": "t2_5ejp13jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering start to finish", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzi8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688529422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone, &lt;/p&gt;\n\n&lt;p&gt;What is the best resources for understanding how to build out a pipeline from scratch. I&amp;#39;m currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.&lt;/p&gt;\n\n&lt;p&gt;It had me thinking if I was to get the job I wouldn&amp;#39;t know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.&lt;/p&gt;\n\n&lt;p&gt;I figured I should get started now since it&amp;#39;s always good to learn things start to finish.&lt;/p&gt;\n\n&lt;p&gt;Any resources you could provide would be great (books, articles, other post, ect...)&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qzi8p", "is_robot_indexable": true, "report_reasons": null, "author": "knowledgeMeUp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "subreddit_subscribers": 114145, "created_utc": 1688529422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. \n\nThese data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?", "author_fullname": "t2_dg51ak2mn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "user identity, machine identity and now we need data identity ? what do you think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qws59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688520815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. &lt;/p&gt;\n\n&lt;p&gt;These data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qws59", "is_robot_indexable": true, "report_reasons": null, "author": "Extreme-Summer-2756", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "subreddit_subscribers": 114145, "created_utc": 1688520815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently stumbled on a job opportunity that uses Oracle data integrator. As someone who is 'at home' with Oracle, seemed intriguing, but then I checked market share and found Informatica has much greater market share...   \n\n\non the other hand, I am more fond of 'hands-on tools', like writing scripts by myself, not utilizing any kind of GUI.   \nWhat is the relevance and prospects of tools like ODI and/or Informatica, and even Oracle's GoldenGate vs Spark and others?  \n\n\nwhen talking about this, obviously, I am talking about big corporate clients with some regulations and needs for support, etc etc..", "author_fullname": "t2_bnm2tai1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Informatica vs. Oracle Data Integrator vs Oracle GoldenGate vs others (Spark, Python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r6ltr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688552385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently stumbled on a job opportunity that uses Oracle data integrator. As someone who is &amp;#39;at home&amp;#39; with Oracle, seemed intriguing, but then I checked market share and found Informatica has much greater market share...   &lt;/p&gt;\n\n&lt;p&gt;on the other hand, I am more fond of &amp;#39;hands-on tools&amp;#39;, like writing scripts by myself, not utilizing any kind of GUI.&lt;br/&gt;\nWhat is the relevance and prospects of tools like ODI and/or Informatica, and even Oracle&amp;#39;s GoldenGate vs Spark and others?  &lt;/p&gt;\n\n&lt;p&gt;when talking about this, obviously, I am talking about big corporate clients with some regulations and needs for support, etc etc..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r6ltr", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Cancel_7891", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r6ltr/informatica_vs_oracle_data_integrator_vs_oracle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r6ltr/informatica_vs_oracle_data_integrator_vs_oracle/", "subreddit_subscribers": 114145, "created_utc": 1688552385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hi. I am pretty new to this data field where I am learning new things every day.\n\nMy goal was to **stream Firestore data to BigQuery** so that I can use it further on for visualizations in either Google Studio or Power BI.\n\nI installed the **Straming Firestore to BigQuery extension in Firebase** and also completed the backfilling of data using the \"**npx** [u/firebaseextensions](https://www.reddit.com/u/firebaseextensions/)/fs-bq-import-collection\".\n\nHere is the issue that I am facing:\n\n* When I UPDATE the documents that have been pushed to the Firestore, they do not appear in the raw\\_changelog table in BigQuery. But when I create a new document myself or edit the same created document it shows in the raw\\_changelog as CREATE and UPDATE operation respectively. Why is that? Why the data being pushed by the app is not being recorded by the changelog?", "author_fullname": "t2_crouj2skt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling stuck with streaming Firestore data to BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r67qw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688551262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I am pretty new to this data field where I am learning new things every day.&lt;/p&gt;\n\n&lt;p&gt;My goal was to &lt;strong&gt;stream Firestore data to BigQuery&lt;/strong&gt; so that I can use it further on for visualizations in either Google Studio or Power BI.&lt;/p&gt;\n\n&lt;p&gt;I installed the &lt;strong&gt;Straming Firestore to BigQuery extension in Firebase&lt;/strong&gt; and also completed the backfilling of data using the &amp;quot;&lt;strong&gt;npx&lt;/strong&gt; &lt;a href=\"https://www.reddit.com/u/firebaseextensions/\"&gt;u/firebaseextensions&lt;/a&gt;/fs-bq-import-collection&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Here is the issue that I am facing:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;When I UPDATE the documents that have been pushed to the Firestore, they do not appear in the raw_changelog table in BigQuery. But when I create a new document myself or edit the same created document it shows in the raw_changelog as CREATE and UPDATE operation respectively. Why is that? Why the data being pushed by the app is not being recorded by the changelog?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14r67qw", "is_robot_indexable": true, "report_reasons": null, "author": "data_analyst_0103", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r67qw/feeling_stuck_with_streaming_firestore_data_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r67qw/feeling_stuck_with_streaming_firestore_data_to/", "subreddit_subscribers": 114145, "created_utc": 1688551262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Make Your Data Ingestion Simple, Fast, And Robust - 11 Advanced best practices for working with data ingestion pipelines.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_14r4zcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l9qusAuLPw7VDO87OQ_ds_wMR85zOD0Cha7Av6hEh6c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688547389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "meltano.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://meltano.com/blog/how-to-make-your-data-ingestion-simple-fast-and-robust/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?auto=webp&amp;v=enabled&amp;s=7720628d9a0212948420b874d2e71fc85101c13b", "width": 1440, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ef88de54f10d16905227ea609f981d8a2db7058", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d56d7b3a0d68c53284e6568ac0810f27fd4d07a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a253637116c25aad58aba1391cfc1fc2359b9f6", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36478f2a1f13ba7b3e80fff977e3465cd0f1f155", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26032ee0e078c185a78e5530051273f586a69b79", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/We1k4iBPvWrh3qiDXNw79BLLAdzo6Ychb8e9hdwmxmw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cca4f827fe0072829e77e25a7c5923100f7b9fbd", "width": 1080, "height": 810}], "variants": {}, "id": "DfcrVMfetugEAM3zA9zmoKT9fQhKdRUq7Wgvmj4oU5k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14r4zcp", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r4zcp/how_to_make_your_data_ingestion_simple_fast_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://meltano.com/blog/how-to-make-your-data-ingestion-simple-fast-and-robust/", "subreddit_subscribers": 114145, "created_utc": 1688547389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dx287f3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IoT Data Direct Ingestion to Kafka Using WaterStream MQTT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_14r4dc3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IJIQlzcbHJXG6hE9Qvd96k8DRWPovOdnj1j-ZA_dEzI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688545378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.shellkode.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.shellkode.com/iot-data-direct-ingestion-to-kafka-using-waterstream-mqtt-11f52c73a84e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4iV43hDCwPV_SlpQAjlkrvosEcRg_U--mmkzT528iN0.jpg?auto=webp&amp;v=enabled&amp;s=aba6406dc06ab90c983bd7e87f6592ad70982e7b", "width": 1129, "height": 750}, "resolutions": [{"url": "https://external-preview.redd.it/4iV43hDCwPV_SlpQAjlkrvosEcRg_U--mmkzT528iN0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2adbfe1a4b20254d8e6bed96feb1ef2d0d6e55fc", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/4iV43hDCwPV_SlpQAjlkrvosEcRg_U--mmkzT528iN0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70da6ead73666a13d53436fc7ea09d93df69e9b0", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/4iV43hDCwPV_SlpQAjlkrvosEcRg_U--mmkzT528iN0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d413caee36cd3f29aa6df6cb2e9b217113b7facf", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/4iV43hDCwPV_SlpQAjlkrvosEcRg_U--mmkzT528iN0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e78d165c6b33c5f75b7735a6852d0f28f8610be4", "width": 640, "height": 425}, {"url": "https://external-preview.redd.it/4iV43hDCwPV_SlpQAjlkrvosEcRg_U--mmkzT528iN0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b36240ed62e7270edb54daa50dc32753df046694", "width": 960, "height": 637}, {"url": "https://external-preview.redd.it/4iV43hDCwPV_SlpQAjlkrvosEcRg_U--mmkzT528iN0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c214a93a136097ead3829fc128749de3dccb6a8", "width": 1080, "height": 717}], "variants": {}, "id": "viHgehZtURfQeNMyf1EppRn0NhrhFXtATzkPPlNqnBI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14r4dc3", "is_robot_indexable": true, "report_reasons": null, "author": "TheSqlAdmin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r4dc3/iot_data_direct_ingestion_to_kafka_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.shellkode.com/iot-data-direct-ingestion-to-kafka-using-waterstream-mqtt-11f52c73a84e", "subreddit_subscribers": 114145, "created_utc": 1688545378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I really want to break into data analysis out of my current job. I work at a large hospital in the Emergency Department as a patient care technician. I graduated with my Mathematics degree but unfortunately never got around to applying for internships or doing any AMAZING data projects worth putting on my resume. I've heard it would be in my best interest to start on my own project. Since I work in the hospital, I thought it would be fun to make a clone of the software that we use, EPIC. \n\nI just want to start small and focus on an Emergency Department version. A tab where you can scroll and view patient names and room number, a tab for those in the waiting room, a tab that shows general data like average wait times, etc. I just don't know where to begin!\n\nWhat tools would I need? I know a fair amount of SQL and Python, but never really used anything like Tableau or PowerBI. Is there anywhere I could get mock patient data? And this might be a dumb question, Is it legal to make a clone of this software and present it to employers?\n\nAny help appreciated!", "author_fullname": "t2_oxvx2j4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for a personal project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r475p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688544801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really want to break into data analysis out of my current job. I work at a large hospital in the Emergency Department as a patient care technician. I graduated with my Mathematics degree but unfortunately never got around to applying for internships or doing any AMAZING data projects worth putting on my resume. I&amp;#39;ve heard it would be in my best interest to start on my own project. Since I work in the hospital, I thought it would be fun to make a clone of the software that we use, EPIC. &lt;/p&gt;\n\n&lt;p&gt;I just want to start small and focus on an Emergency Department version. A tab where you can scroll and view patient names and room number, a tab for those in the waiting room, a tab that shows general data like average wait times, etc. I just don&amp;#39;t know where to begin!&lt;/p&gt;\n\n&lt;p&gt;What tools would I need? I know a fair amount of SQL and Python, but never really used anything like Tableau or PowerBI. Is there anywhere I could get mock patient data? And this might be a dumb question, Is it legal to make a clone of this software and present it to employers?&lt;/p&gt;\n\n&lt;p&gt;Any help appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14r475p", "is_robot_indexable": true, "report_reasons": null, "author": "SqueezyOrangeJuice", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r475p/advice_for_a_personal_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r475p/advice_for_a_personal_project/", "subreddit_subscribers": 114145, "created_utc": 1688544801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello redditors of r/dataengineer I feel like i walked in to a party I was  never invited to but here I am, asking a question.I was recently accepted to get educated as an Data engineer or a Fullstack .net developer.Now I am going to be honest, I an a geotech engineer and love tech but looking to challenge myself abit intellectually workwise but dont really know either of the occupations well enough to decide, I am not necissarly trying to combine my previous work with a new one, More of a fresh start and I wanted to know if you guys think i should choose Data engineer over Fullstack .net developer and why.", "author_fullname": "t2_7ikqjysld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer vs Fullstack as a job and why should I choose Data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14quusz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688514976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello redditors of &lt;a href=\"/r/dataengineer\"&gt;r/dataengineer&lt;/a&gt; I feel like i walked in to a party I was  never invited to but here I am, asking a question.I was recently accepted to get educated as an Data engineer or a Fullstack .net developer.Now I am going to be honest, I an a geotech engineer and love tech but looking to challenge myself abit intellectually workwise but dont really know either of the occupations well enough to decide, I am not necissarly trying to combine my previous work with a new one, More of a fresh start and I wanted to know if you guys think i should choose Data engineer over Fullstack .net developer and why.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14quusz", "is_robot_indexable": true, "report_reasons": null, "author": "InternationalTour303", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14quusz/data_engineer_vs_fullstack_as_a_job_and_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14quusz/data_engineer_vs_fullstack_as_a_job_and_why/", "subreddit_subscribers": 114145, "created_utc": 1688514976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you have any suggestions for the routine job to extract Big data from MySQL server to CSV, preprocessing (cleaning and transformation), and prepare for machine learning? Is there easy way anyone using?\n\n&amp;#x200B;", "author_fullname": "t2_85tjk7wh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big data processing for machine learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qqmzn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688503949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have any suggestions for the routine job to extract Big data from MySQL server to CSV, preprocessing (cleaning and transformation), and prepare for machine learning? Is there easy way anyone using?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qqmzn", "is_robot_indexable": true, "report_reasons": null, "author": "Jebin1999", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qqmzn/big_data_processing_for_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qqmzn/big_data_processing_for_machine_learning/", "subreddit_subscribers": 114145, "created_utc": 1688503949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! I'm looking for Data Engineering roles that look like Software Engineering positions, in other words, more \"technical\" roles in the universe of DE (Roles that don't look like Data or Business Analyst and ETL or SQL Developer positions)\n\nI want something that feels like a breed between a SWE role and a DE role. Out of all the positions I found, I came across this one and I was wondering if you guys - who have a lot more experience than me - feel like this hits the mark:\n\n\"Your work will involve creating analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other essential business performance metrics. You will also be responsible for managing the data architecture for data ingestion, pipeline setup, and data curation. Additionally, you will manipulate data at scale to ensure it is in a readily usable state, collaborating closely with various business and Spoke stakeholders.\n\nKey Responsibilities:\n\n* Create and maintain data pipeline architecture. Assemble large, complex data sets that meet functional/non-functional business requirements.\n* Build the infrastructure required for optimal data extraction, transformation, and loading using SQL and AWS 'big data' technologies.\n* Develop analytics tools leveraging the data pipeline to provide actionable insights.\n* Manage the data architecture for data ingestion, pipeline setup, and data curation, and manipulate data at scale, aligning it with business and Spoke stakeholder needs.\n\nRequired Qualifications:\n\n* Master's degree in Computer Engineering.\n* Strong expertise in building and optimizing 'big data' data pipelines, architectures, and datasets.\n* Experience in building processes supporting data transformation, data structures, metadata, dependency, and workload management.\n* Proficiency in AWS Infrastructure as Code (IaC) and Infrastructure as a Service (IaaS) services.\n* Programming skills in functional programming and object-oriented scripting languages (Mostly python, sometimes scala and Java).\n\nPreferred Qualifications:\n\n* Experience with big data tools and distributed clusters such as Hadoop, Spark, Kafka, Kinesis.\n* Familiarity with data pipeline and workflow management tools like Azkaban, Luigi, Airflow, Glue Workflow.\"\n\nThank you so much for your help!\n\n&amp;#x200B;", "author_fullname": "t2_cettm338", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this look like a solid DE role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qny43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688497710.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688497524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I&amp;#39;m looking for Data Engineering roles that look like Software Engineering positions, in other words, more &amp;quot;technical&amp;quot; roles in the universe of DE (Roles that don&amp;#39;t look like Data or Business Analyst and ETL or SQL Developer positions)&lt;/p&gt;\n\n&lt;p&gt;I want something that feels like a breed between a SWE role and a DE role. Out of all the positions I found, I came across this one and I was wondering if you guys - who have a lot more experience than me - feel like this hits the mark:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Your work will involve creating analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other essential business performance metrics. You will also be responsible for managing the data architecture for data ingestion, pipeline setup, and data curation. Additionally, you will manipulate data at scale to ensure it is in a readily usable state, collaborating closely with various business and Spoke stakeholders.&lt;/p&gt;\n\n&lt;p&gt;Key Responsibilities:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Create and maintain data pipeline architecture. Assemble large, complex data sets that meet functional/non-functional business requirements.&lt;/li&gt;\n&lt;li&gt;Build the infrastructure required for optimal data extraction, transformation, and loading using SQL and AWS &amp;#39;big data&amp;#39; technologies.&lt;/li&gt;\n&lt;li&gt;Develop analytics tools leveraging the data pipeline to provide actionable insights.&lt;/li&gt;\n&lt;li&gt;Manage the data architecture for data ingestion, pipeline setup, and data curation, and manipulate data at scale, aligning it with business and Spoke stakeholder needs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Required Qualifications:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Master&amp;#39;s degree in Computer Engineering.&lt;/li&gt;\n&lt;li&gt;Strong expertise in building and optimizing &amp;#39;big data&amp;#39; data pipelines, architectures, and datasets.&lt;/li&gt;\n&lt;li&gt;Experience in building processes supporting data transformation, data structures, metadata, dependency, and workload management.&lt;/li&gt;\n&lt;li&gt;Proficiency in AWS Infrastructure as Code (IaC) and Infrastructure as a Service (IaaS) services.&lt;/li&gt;\n&lt;li&gt;Programming skills in functional programming and object-oriented scripting languages (Mostly python, sometimes scala and Java).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Preferred Qualifications:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Experience with big data tools and distributed clusters such as Hadoop, Spark, Kafka, Kinesis.&lt;/li&gt;\n&lt;li&gt;Familiarity with data pipeline and workflow management tools like Azkaban, Luigi, Airflow, Glue Workflow.&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you so much for your help!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qny43", "is_robot_indexable": true, "report_reasons": null, "author": "PM_ME_YOUR_GIGI", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qny43/does_this_look_like_a_solid_de_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qny43/does_this_look_like_a_solid_de_role/", "subreddit_subscribers": 114145, "created_utc": 1688497524.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}