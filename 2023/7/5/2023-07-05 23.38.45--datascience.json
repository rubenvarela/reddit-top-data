{"kind": "Listing", "data": {"after": null, "dist": 10, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_11vkze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An academic paper about nomadic data processors (1964) Link in comments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_14r7oge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 109, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 109, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688555564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kwctcycdq4ab1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kwctcycdq4ab1.png?auto=webp&amp;v=enabled&amp;s=65f0e8a8ea5f810f45112d79e97c9ec58db88e3c", "width": 546, "height": 369}, "resolutions": [{"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ad712a8a16b641596ef93210ef4447fdca9569d", "width": 108, "height": 72}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e16bf8b08436578518a18a99a48d40f687b24bd0", "width": 216, "height": 145}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9a8443eac162b12af36a700bca2d6c89ee6e8f0", "width": 320, "height": 216}], "variants": {"obfuscated": {"source": {"url": "https://preview.redd.it/kwctcycdq4ab1.png?blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=225232f7bca3f7ac2f8e92fa0c7b085691b7dd9e", "width": 546, "height": 369}, "resolutions": [{"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=15a7bc321b65fe5d8d669f489818ed353e23523c", "width": 108, "height": 72}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e9fa7b210f5433bf5d2674c01aaa30b0e21a37da", "width": 216, "height": 145}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=75997868d8dbc9c46ab17b6af7d151c86a0fdf87", "width": 320, "height": 216}]}, "nsfw": {"source": {"url": "https://preview.redd.it/kwctcycdq4ab1.png?blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=225232f7bca3f7ac2f8e92fa0c7b085691b7dd9e", "width": 546, "height": 369}, "resolutions": [{"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=15a7bc321b65fe5d8d669f489818ed353e23523c", "width": 108, "height": 72}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e9fa7b210f5433bf5d2674c01aaa30b0e21a37da", "width": 216, "height": 145}, {"url": "https://preview.redd.it/kwctcycdq4ab1.png?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=75997868d8dbc9c46ab17b6af7d151c86a0fdf87", "width": 320, "height": 216}]}}, "id": "eIo6mAbbv-KpjZ5RRFpgZLy1-qpeevCGyZArz66JUts"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r7oge", "is_robot_indexable": true, "report_reasons": null, "author": "subaculture", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r7oge/an_academic_paper_about_nomadic_data_processors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kwctcycdq4ab1.png", "subreddit_subscribers": 939208, "created_utc": 1688555564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let\u2019s say you created a project for your company and you want to add it to your portfolio on github to showcase your skills for recruiters, how would you share it given that data is confidential?", "author_fullname": "t2_81zrh19oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you show data projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rf14j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688573211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say you created a project for your company and you want to add it to your portfolio on github to showcase your skills for recruiters, how would you share it given that data is confidential?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rf14j", "is_robot_indexable": true, "report_reasons": null, "author": "Careful_Engineer_700", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rf14j/how_do_you_show_data_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rf14j/how_do_you_show_data_projects/", "subreddit_subscribers": 939208, "created_utc": 1688573211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks,  I have just started doing a data science course, though with the advancement of AI and people like Mo Gawdat talking about the implications of AI in especially programming related jobs, I wanted to ask people who have been working in this field how relevant do you think data science as a  career would be in the future?  ", "author_fullname": "t2_ajbk60r1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Relevance with AI.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r0qka", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688533390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,  I have just started doing a data science course, though with the advancement of AI and people like Mo Gawdat talking about the implications of AI in especially programming related jobs, I wanted to ask people who have been working in this field how relevant do you think data science as a  career would be in the future?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14r0qka", "is_robot_indexable": true, "report_reasons": null, "author": "Leather_Depth1765", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14r0qka/data_science_relevance_with_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14r0qka/data_science_relevance_with_ai/", "subreddit_subscribers": 939208, "created_utc": 1688533390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Not even sure they\u2019re anything more than Frobes hype driven FOMO for business leaders, but maybe a proper regression analysis might be an appropriate source for these thing\u2026\n\nI\u2019m tasked to declare a set of \u201cleading KPIs\u201d as a team leader in analytics. These are supposed to be  for a very specific initiative (technically a knee jerk reaction to not hitting anywhere close to where our company needs to be in terms of our annual goals for the year). \n\nBasically, they want more conversions...\n\nProblem, they have absolutely no idea how to get them\u2026\n\nIgnoring all the details, Ive agreed to provide them with some very rudimentary optimization algorithm that aims to improve marketing response rate. Let\u2019s leave it at that for now.\n\nThey want a leading KPI for this\u2026 A leading KPI\u2026 for an optimization algorithm (basically just multi armed bandit application to segmented prospect groups for specific ads on the topic of conversion). We\u2019re not even sure the ads will work, but that\u2019s another optimization problem. \n\nAs I think about this, I realize all of data science aims to eliminate the need for these \u201cleading KPIs\u201d and instead build solutions that either:\n\n* Identify \u201cleading KPIs\u201d for manual operations in the form of regression terms and coefficients\n* Do away with manual decision making all together and let algos go brrrr refining business operations automatically, doing away with the needs for a human interpretable \u201cleading KPI\u201d\n* Predict future values of time series processes that may or may not ignore other independent variables, more often just decomposing a process into its additive forms and extrapolating potential future value ranges and probability distributions for those  - like, model says 68% chance of rainfall between 1\u201d and 3\u201d over next 30 days kind of thing, do with this what you will\n\nThe entire concept of a \u201cleading KPI\u201d is very sale sand operations productivity oriented, right? Hold time for a call center leads customer satisfaction. How much wood a wood chuck can chick leads whatever wood chucks do with the wood. A roofer can lay 3 shingles per minute when he\u2019s rested and 1 per minute when he is exhausted, therefore a roof can be finished in X time given Y breaks. A sales team can produce 10 leads per hour if they wear suits and 100 per hour if they go to the bar with a group of potential clients.\n\nHow does this even translate to data science? At most, I can think of things like VPN bandwidth, data warehouse performance, training hardware specs, cloud budget, team size, WIP, ad hoc request load, interruption frequency, vintage of teams last contemporary technology training, workstation specs, etc. \n\nThe rest really depends on deployment and utilization - like the marketing team does or does not ignore model results, or advertising is fully automated so marketing team can\u2019t ignore the results.\n\nIt\u2019s not like the number of models in production is any indicator of company performance. Quality of models, maybe\u2026 But really its about what aspects of a work day contribute to a productive team that is not burdened by distractions and allowed to do their work in stable, repeatable, unbiased ways that operate on theories based on observable realities. \n\nThat\u2019s it. \n\nGive me more people with better training and experience, leave us alone, define problems well and allow us the agency of telling you if what you want is feasible and actually something that can realistically be done. Give us enough budget to build and deploy the solution. Give us people to support and maintain it. Then we monitor \u201clagging KPIs\u201d in the range of profit, revenue, expenses, and how variants model performance measures contribute to those.\n\n&amp;#x200B;\n\nUnless I\u2019m supposed to say MRSE or F1 are my \u201cleading KPIs?\u201d My perspective is that they are not and are completely dependent on if the model even gets deployed or may even dictate if the model is deployed. I can\u2019t just say, \u201coh, all these hypothetical models I might build will absolutely hit an MRSE of 0.0012345 and that will contribute to increased conversion rate.\u201d Or am I viewing this wrong? ", "author_fullname": "t2_w100sesa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The concept of \u201cLeading KPIs\u201d is not compatible with Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qvre5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688517661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not even sure they\u2019re anything more than Frobes hype driven FOMO for business leaders, but maybe a proper regression analysis might be an appropriate source for these thing\u2026&lt;/p&gt;\n\n&lt;p&gt;I\u2019m tasked to declare a set of \u201cleading KPIs\u201d as a team leader in analytics. These are supposed to be  for a very specific initiative (technically a knee jerk reaction to not hitting anywhere close to where our company needs to be in terms of our annual goals for the year). &lt;/p&gt;\n\n&lt;p&gt;Basically, they want more conversions...&lt;/p&gt;\n\n&lt;p&gt;Problem, they have absolutely no idea how to get them\u2026&lt;/p&gt;\n\n&lt;p&gt;Ignoring all the details, Ive agreed to provide them with some very rudimentary optimization algorithm that aims to improve marketing response rate. Let\u2019s leave it at that for now.&lt;/p&gt;\n\n&lt;p&gt;They want a leading KPI for this\u2026 A leading KPI\u2026 for an optimization algorithm (basically just multi armed bandit application to segmented prospect groups for specific ads on the topic of conversion). We\u2019re not even sure the ads will work, but that\u2019s another optimization problem. &lt;/p&gt;\n\n&lt;p&gt;As I think about this, I realize all of data science aims to eliminate the need for these \u201cleading KPIs\u201d and instead build solutions that either:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Identify \u201cleading KPIs\u201d for manual operations in the form of regression terms and coefficients&lt;/li&gt;\n&lt;li&gt;Do away with manual decision making all together and let algos go brrrr refining business operations automatically, doing away with the needs for a human interpretable \u201cleading KPI\u201d&lt;/li&gt;\n&lt;li&gt;Predict future values of time series processes that may or may not ignore other independent variables, more often just decomposing a process into its additive forms and extrapolating potential future value ranges and probability distributions for those  - like, model says 68% chance of rainfall between 1\u201d and 3\u201d over next 30 days kind of thing, do with this what you will&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The entire concept of a \u201cleading KPI\u201d is very sale sand operations productivity oriented, right? Hold time for a call center leads customer satisfaction. How much wood a wood chuck can chick leads whatever wood chucks do with the wood. A roofer can lay 3 shingles per minute when he\u2019s rested and 1 per minute when he is exhausted, therefore a roof can be finished in X time given Y breaks. A sales team can produce 10 leads per hour if they wear suits and 100 per hour if they go to the bar with a group of potential clients.&lt;/p&gt;\n\n&lt;p&gt;How does this even translate to data science? At most, I can think of things like VPN bandwidth, data warehouse performance, training hardware specs, cloud budget, team size, WIP, ad hoc request load, interruption frequency, vintage of teams last contemporary technology training, workstation specs, etc. &lt;/p&gt;\n\n&lt;p&gt;The rest really depends on deployment and utilization - like the marketing team does or does not ignore model results, or advertising is fully automated so marketing team can\u2019t ignore the results.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s not like the number of models in production is any indicator of company performance. Quality of models, maybe\u2026 But really its about what aspects of a work day contribute to a productive team that is not burdened by distractions and allowed to do their work in stable, repeatable, unbiased ways that operate on theories based on observable realities. &lt;/p&gt;\n\n&lt;p&gt;That\u2019s it. &lt;/p&gt;\n\n&lt;p&gt;Give me more people with better training and experience, leave us alone, define problems well and allow us the agency of telling you if what you want is feasible and actually something that can realistically be done. Give us enough budget to build and deploy the solution. Give us people to support and maintain it. Then we monitor \u201clagging KPIs\u201d in the range of profit, revenue, expenses, and how variants model performance measures contribute to those.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Unless I\u2019m supposed to say MRSE or F1 are my \u201cleading KPIs?\u201d My perspective is that they are not and are completely dependent on if the model even gets deployed or may even dictate if the model is deployed. I can\u2019t just say, \u201coh, all these hypothetical models I might build will absolutely hit an MRSE of 0.0012345 and that will contribute to increased conversion rate.\u201d Or am I viewing this wrong? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qvre5", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Sir-5932", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qvre5/the_concept_of_leading_kpis_is_not_compatible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qvre5/the_concept_of_leading_kpis_is_not_compatible/", "subreddit_subscribers": 939208, "created_utc": 1688517661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\n\n\n\n\n\n\nLet's say that your current job only allows you to use excel, do you think it would be worth studying outside to prepare for new positions that use power bi, sql, python and others? Or do you think it wouldn't be of much value to learn something that I can't put into practice right away? Because all this would consume time and resources, let's say the time after work, whether on weekends or on weekdays. Or would I be better off using that time to learn things useful for my current job? What career advice would you give?", "author_fullname": "t2_cne2tl51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you study tools that are not applicable to your current job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rhp27", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688578791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say that your current job only allows you to use excel, do you think it would be worth studying outside to prepare for new positions that use power bi, sql, python and others? Or do you think it wouldn&amp;#39;t be of much value to learn something that I can&amp;#39;t put into practice right away? Because all this would consume time and resources, let&amp;#39;s say the time after work, whether on weekends or on weekdays. Or would I be better off using that time to learn things useful for my current job? What career advice would you give?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rhp27", "is_robot_indexable": true, "report_reasons": null, "author": "gintokiredditbr", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rhp27/do_you_study_tools_that_are_not_applicable_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rhp27/do_you_study_tools_that_are_not_applicable_to/", "subreddit_subscribers": 939208, "created_utc": 1688578791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have no biology background. But I look at this task and think to myself, this could use a spectral embedding technique like Laplacian Eigen-maps. Or any other technique (we've all seen the famous examples in scikit-learn to unroll the rainbow \"swiss roll\"). Has anyone else done this, and can they comment on the success of it.", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spectral Embedding for protein (un)-folding?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14reu8w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688572828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have no biology background. But I look at this task and think to myself, this could use a spectral embedding technique like Laplacian Eigen-maps. Or any other technique (we&amp;#39;ve all seen the famous examples in scikit-learn to unroll the rainbow &amp;quot;swiss roll&amp;quot;). Has anyone else done this, and can they comment on the success of it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14reu8w", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14reu8w/spectral_embedding_for_protein_unfolding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14reu8w/spectral_embedding_for_protein_unfolding/", "subreddit_subscribers": 939208, "created_utc": 1688572828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Most of the data i'm managing is nice to sketch up in a notebook, but to actually run it in a nice production environment I'm running them as python scripts. \n\nI like .ipynbs, but they have their limits. I would rather develop locally in VS and run a .py file, but I miss the rich text output of the notepad, basically. \n\nI'm sure VS code has some solution for this. What's the best way to solve this? Thanks", "author_fullname": "t2_aefxxhc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "notebook-like experience in VS code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rd1vl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688569071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the data i&amp;#39;m managing is nice to sketch up in a notebook, but to actually run it in a nice production environment I&amp;#39;m running them as python scripts. &lt;/p&gt;\n\n&lt;p&gt;I like .ipynbs, but they have their limits. I would rather develop locally in VS and run a .py file, but I miss the rich text output of the notepad, basically. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure VS code has some solution for this. What&amp;#39;s the best way to solve this? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rd1vl", "is_robot_indexable": true, "report_reasons": null, "author": "throwawayrandomvowel", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rd1vl/notebooklike_experience_in_vs_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rd1vl/notebooklike_experience_in_vs_code/", "subreddit_subscribers": 939208, "created_utc": 1688569071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**This post is several related questions rolled into one.**\n\n**First and most simply, what is** [this kind of graph](https://www.sgmoratilla.com/static/e7ac56cc3e90327b21f79ab7d144d7c5/7468b/github-contributios-activity.png) **called?** This image was taken from GitHub, where the graph represents total GitHub participation over a given period. It breaks participation down into four areas of open source contribution, devoting one axis to each, and sums to 100%. Presumably this type of chart could be generalized to have any number of axes.\n\n**Second, I'm looking for the optimal way to visualize the aggregate results of a simple ablation study.** I'm an ML research engineer, and at work I've been working on an ablation study for publication. The study is investigating what happens when we feed non-text features into transformer models. We have 4 types of features, so not a huge number, but more than you could simply throw onto an x-y plane without careful consideration. I've trained many models combinatorically, one for each combination of features from none to all. I have the metrics for all of these models. What I need now is a good way to succinctly visualize these results graphically/geometrically, rather than just saying \"hey here's a table\" with like 200 kappas. I'd like the reader to walk away with a sense of how much each feature contributes to model performance, relative to a baseline of no non-text features. Ideas?\n\n**Third, I'm wondering if the graph type linked in my initial paragraph is one way to visualize my study's results.** As I worked with four different features, I was thinking I could have one axis per feature. Then I could simply group the performance of all my models by feature, take the mean performance across all models that use each feature, then just plot those means (I don't think normalization would achieve anything as all axes would already be on the same scale). The math of this proposal would look like this (assuming only 3 features for simplicity, and thus a 3-axis visualization, though the concept is the same):\n\n&amp;#x200B;\n\n||feature 1|feature 3|feature 3|performance|\n|:-|:-|:-|:-|:-|\n|model 1|\u2713|\u2713|\u2713|0.8|\n|model 2|\u2713|\u2713||0.5|\n|model 3|\u2713||\u2713|0.7|\n|model 4||\u2713|\u2713|0.6|\n|model 5|\u2713|||0.2|\n|model 6||\u2713||0.4|\n|model 7|||\u2713|0.1|\n\n&amp;#x200B;\n\n|feature|mean performance|\n|:-|:-|\n|feature 1|(0.8 + 0.5 + 0.7 + 0.2) / 4 = **0.550**|\n|feature 2|(0.8 + 0.5 + 0.6 + 0.4) / 4 = **0.575**|\n|feature 3|(0.8 + 0.7 + 0.6 + 0.3) / 4 = **0.600**|\n\nSo the numbers in the final column of the final table are what would be plotted. These would determine how \"pointy\" the polygon is in each axis.\n\nIs that math defensible, and would the resultant visualization effectively communicate the relative contributions of each feature to the performance of my model? I've been thinking about this since Friday including reading some other ablation studies for inspiration but it's the best I could come up with", "author_fullname": "t2_x66s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Name that chart type! Trying to visualize multidimensional ablation study results", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qyrb2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688532582.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688526968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;This post is several related questions rolled into one.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;First and most simply, what is&lt;/strong&gt; &lt;a href=\"https://www.sgmoratilla.com/static/e7ac56cc3e90327b21f79ab7d144d7c5/7468b/github-contributios-activity.png\"&gt;this kind of graph&lt;/a&gt; &lt;strong&gt;called?&lt;/strong&gt; This image was taken from GitHub, where the graph represents total GitHub participation over a given period. It breaks participation down into four areas of open source contribution, devoting one axis to each, and sums to 100%. Presumably this type of chart could be generalized to have any number of axes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Second, I&amp;#39;m looking for the optimal way to visualize the aggregate results of a simple ablation study.&lt;/strong&gt; I&amp;#39;m an ML research engineer, and at work I&amp;#39;ve been working on an ablation study for publication. The study is investigating what happens when we feed non-text features into transformer models. We have 4 types of features, so not a huge number, but more than you could simply throw onto an x-y plane without careful consideration. I&amp;#39;ve trained many models combinatorically, one for each combination of features from none to all. I have the metrics for all of these models. What I need now is a good way to succinctly visualize these results graphically/geometrically, rather than just saying &amp;quot;hey here&amp;#39;s a table&amp;quot; with like 200 kappas. I&amp;#39;d like the reader to walk away with a sense of how much each feature contributes to model performance, relative to a baseline of no non-text features. Ideas?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Third, I&amp;#39;m wondering if the graph type linked in my initial paragraph is one way to visualize my study&amp;#39;s results.&lt;/strong&gt; As I worked with four different features, I was thinking I could have one axis per feature. Then I could simply group the performance of all my models by feature, take the mean performance across all models that use each feature, then just plot those means (I don&amp;#39;t think normalization would achieve anything as all axes would already be on the same scale). The math of this proposal would look like this (assuming only 3 features for simplicity, and thus a 3-axis visualization, though the concept is the same):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;feature 1&lt;/th&gt;\n&lt;th align=\"left\"&gt;feature 3&lt;/th&gt;\n&lt;th align=\"left\"&gt;feature 3&lt;/th&gt;\n&lt;th align=\"left\"&gt;performance&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 1&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.8&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 2&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 3&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.7&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 4&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 5&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.4&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;model 7&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;\u2713&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;feature&lt;/th&gt;\n&lt;th align=\"left\"&gt;mean performance&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;feature 1&lt;/td&gt;\n&lt;td align=\"left\"&gt;(0.8 + 0.5 + 0.7 + 0.2) / 4 = &lt;strong&gt;0.550&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;feature 2&lt;/td&gt;\n&lt;td align=\"left\"&gt;(0.8 + 0.5 + 0.6 + 0.4) / 4 = &lt;strong&gt;0.575&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;feature 3&lt;/td&gt;\n&lt;td align=\"left\"&gt;(0.8 + 0.7 + 0.6 + 0.3) / 4 = &lt;strong&gt;0.600&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;So the numbers in the final column of the final table are what would be plotted. These would determine how &amp;quot;pointy&amp;quot; the polygon is in each axis.&lt;/p&gt;\n\n&lt;p&gt;Is that math defensible, and would the resultant visualization effectively communicate the relative contributions of each feature to the performance of my model? I&amp;#39;ve been thinking about this since Friday including reading some other ablation studies for inspiration but it&amp;#39;s the best I could come up with&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?auto=webp&amp;v=enabled&amp;s=14e928f2e715587d4353a758b604481743a43175", "width": 1764, "height": 1406}, "resolutions": [{"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88c0922186107e6c7d22a501be157fb8871c34b3", "width": 108, "height": 86}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f2065ddd761ec458ad8406aa2249f120d7aa2ea", "width": 216, "height": 172}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05133b02c78a517b5bcc4e0974ec0dda69c35729", "width": 320, "height": 255}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ab3bcb43e1ce6df60b8a686b136aafb82e2352b", "width": 640, "height": 510}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6fb7079ed8a6fa565d1e98693609727d96ee4c7", "width": 960, "height": 765}, {"url": "https://external-preview.redd.it/a-EQ48jKbMX2Gh_UWDA1u12rJB3-99PA_rhF1a9Jido.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4b09260079681b565991faf0fe73f2f17d9eefe", "width": 1080, "height": 860}], "variants": {}, "id": "EZZn27rTOwtEKCC6oWZJvw6d58nuKqsBTCbE5DZvFdw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14qyrb2", "is_robot_indexable": true, "report_reasons": null, "author": "synthphreak", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14qyrb2/name_that_chart_type_trying_to_visualize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14qyrb2/name_that_chart_type_trying_to_visualize/", "subreddit_subscribers": 939208, "created_utc": 1688526968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_b6mvsfne9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you could ask the creators of pandas for one additional feature, what would it be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rob7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688593269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rob7v", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Hawk4549", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rob7v/if_you_could_ask_the_creators_of_pandas_for_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rob7v/if_you_could_ask_the_creators_of_pandas_for_one/", "subreddit_subscribers": 939208, "created_utc": 1688593269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI recently started my first  job as data scientist. I'm experiencing the very high ratio of men in the field and sometimes tend to feel \"different\" and alone because I feel like there could be some hidden homophobia in all these men. \n\nHave you ever felt that way ? \ud83d\ude15", "author_fullname": "t2_fvh7zgyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Too many men - not feeling safe as a gay man", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rofx9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688593571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I recently started my first  job as data scientist. I&amp;#39;m experiencing the very high ratio of men in the field and sometimes tend to feel &amp;quot;different&amp;quot; and alone because I feel like there could be some hidden homophobia in all these men. &lt;/p&gt;\n\n&lt;p&gt;Have you ever felt that way ? \ud83d\ude15&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14rofx9", "is_robot_indexable": true, "report_reasons": null, "author": "Ecstatic-Cut9870", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14rofx9/too_many_men_not_feeling_safe_as_a_gay_man/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14rofx9/too_many_men_not_feeling_safe_as_a_gay_man/", "subreddit_subscribers": 939208, "created_utc": 1688593571.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}