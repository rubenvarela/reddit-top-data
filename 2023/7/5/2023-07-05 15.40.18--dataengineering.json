{"kind": "Listing", "data": {"after": "t3_14r9tst", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.\n\nI have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next\n\nFor anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.\n\nThe resources I used were:\n\n1. [https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/](https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/) \\- used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics\n2. [https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc](https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc) \\- a good reference guide\n3. [https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF](https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF) \\- essentially 90% of the actual exam questions pretty decent explanations  \n\n\nP.S Sorry couldn't forget to include [Spark Internals Explanation](https://www.youtube.com/watch?v=7ooZ4S7Ay6Y)! A phenomenal resource to dive deep on how Spark works under the hood", "author_fullname": "t2_ic83gko1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got certified! - Databricks certified associate developer for apache spark 3.0 in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzt8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688544365.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688530389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got certified! I am a new data analyst who wants to hopefully move into the data engineering field.&lt;/p&gt;\n\n&lt;p&gt;I have done a few projects just finding it hard in the current market to find a job. Decided to keep working at my current job and in the meantime finish off a few certs to hopefully attract a few recruiters. Gonna go for the data engineer associate and professional next&lt;/p&gt;\n\n&lt;p&gt;For anyone wanting to get it, I highly recommend getting it, it stays forever(no expiry), fairly simple took me 2 weeks assuming you have general python syntax knowledge, plus access to documentation in the exam.&lt;/p&gt;\n\n&lt;p&gt;The resources I used were:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/\"&gt;https://www.udemy.com/course/databricks-certified-developer-for-apache-spark-30-practice-exams/&lt;/a&gt; - used this to test my knowledge and basically research what topics are more likely to appear, has a nice breadth of important topics&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc\"&gt;https://chowdhury-joyjit.medium.com/field-notes-for-the-databricks-certified-spark-developer-exam-ca0b6eb452fc&lt;/a&gt; - a good reference guide&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF\"&gt;https://www.udemy.com/course/databricks-certified-developer-apache-spark-30-python/?referralCode=D20A15144B8AF7D2C5CF&lt;/a&gt; - essentially 90% of the actual exam questions pretty decent explanations&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;P.S Sorry couldn&amp;#39;t forget to include &lt;a href=\"https://www.youtube.com/watch?v=7ooZ4S7Ay6Y\"&gt;Spark Internals Explanation&lt;/a&gt;! A phenomenal resource to dive deep on how Spark works under the hood&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qzt8y", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Debate_94", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzt8y/just_got_certified_databricks_certified_associate/", "subreddit_subscribers": 114159, "created_utc": 1688530389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am the only DE in the team, and we want to hire a senior DE soon. My manager has asked me to interview somebody with ~20 years of experience in data engineering while I have only ~4 YOE as a data engineer. When I looked at this candidate\u2019s resume, I got overwhelmed by the expertise they claimed to have. I feel I don\u2019t have enough knowledge to accurately assess this candidate. How should I go about interviewing this candidate? What sort of questions should I ask?", "author_fullname": "t2_cbdg7n9sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should you interview somebody with vastly more experience than yourself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qslvf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688508789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the only DE in the team, and we want to hire a senior DE soon. My manager has asked me to interview somebody with ~20 years of experience in data engineering while I have only ~4 YOE as a data engineer. When I looked at this candidate\u2019s resume, I got overwhelmed by the expertise they claimed to have. I feel I don\u2019t have enough knowledge to accurately assess this candidate. How should I go about interviewing this candidate? What sort of questions should I ask?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14qslvf", "is_robot_indexable": true, "report_reasons": null, "author": "fun_coordinator", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qslvf/how_should_you_interview_somebody_with_vastly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qslvf/how_should_you_interview_somebody_with_vastly/", "subreddit_subscribers": 114159, "created_utc": 1688508789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a small firm that is about thirty years behind in tech.  All of our data is in spreadsheets scattered across a vast and confusing folder tree. We are looking to use alteryx as a no-code ETL and eventually creating an azure database. I noticed most DEs use dagster or airflow. Does anybody have experience with a no code tool like Alteryx? I worry no-code equates to no flexibility", "author_fullname": "t2_4euwn6ok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody use Alteryx", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qi60z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688484263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a small firm that is about thirty years behind in tech.  All of our data is in spreadsheets scattered across a vast and confusing folder tree. We are looking to use alteryx as a no-code ETL and eventually creating an azure database. I noticed most DEs use dagster or airflow. Does anybody have experience with a no code tool like Alteryx? I worry no-code equates to no flexibility&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qi60z", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Enthusiasm-6194", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qi60z/anybody_use_alteryx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qi60z/anybody_use_alteryx/", "subreddit_subscribers": 114159, "created_utc": 1688484263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Link: https://trello.com/b/Rvw8Jygt/interview-preparation\n\nI have been looking for entry level or junior data engineering roles, and have been using a Trello board to help with interview preparation.\n\nIt contains lists of common interview questions, technical questions, and behavioural questions.\n\nI\u2019ve tried tagging behavioural questions based on attribute it\u2019s measuring (e.g., conflict management) so you can filter by these.\n\nFor the technical questions, these are a combination of questions I\u2019ve been asked, or questions you could be asked if applying for a data engineering or analyst role.\n\nFor each card/question you can write potential answers in the description field.\n\nYou can obviously customise it however you like, but hopefully is useful for some of you", "author_fullname": "t2_osh2xtjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created an interview preparation Trello template with technical &amp; behavioural questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ql6jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688491177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Link: &lt;a href=\"https://trello.com/b/Rvw8Jygt/interview-preparation\"&gt;https://trello.com/b/Rvw8Jygt/interview-preparation&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have been looking for entry level or junior data engineering roles, and have been using a Trello board to help with interview preparation.&lt;/p&gt;\n\n&lt;p&gt;It contains lists of common interview questions, technical questions, and behavioural questions.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried tagging behavioural questions based on attribute it\u2019s measuring (e.g., conflict management) so you can filter by these.&lt;/p&gt;\n\n&lt;p&gt;For the technical questions, these are a combination of questions I\u2019ve been asked, or questions you could be asked if applying for a data engineering or analyst role.&lt;/p&gt;\n\n&lt;p&gt;For each card/question you can write potential answers in the description field.&lt;/p&gt;\n\n&lt;p&gt;You can obviously customise it however you like, but hopefully is useful for some of you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14ql6jc", "is_robot_indexable": true, "report_reasons": null, "author": "TheDataPanda", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ql6jc/i_created_an_interview_preparation_trello/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ql6jc/i_created_an_interview_preparation_trello/", "subreddit_subscribers": 114159, "created_utc": 1688491177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have DE interview coming up  and I am thinking to prepare few questions based on handling ETL errors.\n\nA data pipeline should address these issues:\n\n1\u00b7 Partial loads (A scenarios where Partial processing of the files or records or any failures of ETL Jobs occurred; to clean up a few records and re-run the job)\n\n&amp;#x200B;\n\n2 \u00b7 Restart-ability (You have to re-run from a previous successful run because a downstream dependent job failed or reprocess process some data from history. for e.g. We need to run since last Monday or a random date)\n\n&amp;#x200B;\n\n3\u00b7 Re-processing the same files (A source issue where they sent multiple files; We need to pick the right records)\n\n&amp;#x200B;\n\n4 \u00b7 Catch-up loads (In case you missed executing jobs for specific runs and playing catch up; Batch Processing) .\n\nAny Answers on these would be super helpful. Thanks. \ud83d\ude4f ", "author_fullname": "t2_c4v6qwrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Interview question for handling ETL pipeline errors.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qiuds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688485836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have DE interview coming up  and I am thinking to prepare few questions based on handling ETL errors.&lt;/p&gt;\n\n&lt;p&gt;A data pipeline should address these issues:&lt;/p&gt;\n\n&lt;p&gt;1\u00b7 Partial loads (A scenarios where Partial processing of the files or records or any failures of ETL Jobs occurred; to clean up a few records and re-run the job)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2 \u00b7 Restart-ability (You have to re-run from a previous successful run because a downstream dependent job failed or reprocess process some data from history. for e.g. We need to run since last Monday or a random date)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;3\u00b7 Re-processing the same files (A source issue where they sent multiple files; We need to pick the right records)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;4 \u00b7 Catch-up loads (In case you missed executing jobs for specific runs and playing catch up; Batch Processing) .&lt;/p&gt;\n\n&lt;p&gt;Any Answers on these would be super helpful. Thanks. \ud83d\ude4f &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14qiuds", "is_robot_indexable": true, "report_reasons": null, "author": "HealthyCobbler1588", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qiuds/de_interview_question_for_handling_etl_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qiuds/de_interview_question_for_handling_etl_pipeline/", "subreddit_subscribers": 114159, "created_utc": 1688485836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I was first learning dbt I found a lot of really great resources (dbt docs, blog posts, slack threads etc.) and wanted to try to put that all together in one place for anyone else new to dbt, or anyone wanting to learn a bit more about it.   \nThe guide covers everything from \u2018what is dbt?\u2019 to advanced topics like model refactoring best practices.  \nI hope it's useful! **And if you spot anything missing, or ways to make it better, please let me know!**  \n\n\nDesktop link: [https://count.co/canvas/JpkaYdqr9oN](https://count.co/canvas/JpkaYdqr9oN)  \nMobile link: [https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914](https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914)  \n\n\nFull disclosure: I do work for [count.co](https://count.co), the canvas in which the guide was built. ", "author_fullname": "t2_1zfun4sx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I attempted to create the Ultimate Guide to dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r4v10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688547009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was first learning dbt I found a lot of really great resources (dbt docs, blog posts, slack threads etc.) and wanted to try to put that all together in one place for anyone else new to dbt, or anyone wanting to learn a bit more about it.&lt;br/&gt;\nThe guide covers everything from \u2018what is dbt?\u2019 to advanced topics like model refactoring best practices.&lt;br/&gt;\nI hope it&amp;#39;s useful! &lt;strong&gt;And if you spot anything missing, or ways to make it better, please let me know!&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Desktop link: &lt;a href=\"https://count.co/canvas/JpkaYdqr9oN\"&gt;https://count.co/canvas/JpkaYdqr9oN&lt;/a&gt;&lt;br/&gt;\nMobile link: &lt;a href=\"https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914\"&gt;https://taylor-count.medium.com/the-ultimate-guide-to-dbt-bad192ab4914&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Full disclosure: I do work for &lt;a href=\"https://count.co\"&gt;count.co&lt;/a&gt;, the canvas in which the guide was built. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?auto=webp&amp;v=enabled&amp;s=c90d7e97aa224a896783d02a2a830784cb2c0920", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bd97f02fcc00d06a42618c0358185b4bc650318", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb4ee7c5f99ac12f4224cd68ccf6e07358a570c8", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20558ea1403333413bd92f54c54785a76892a5b7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6edc187fbdad61643782e43cb3dad2664e040241", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea269da98515be9aa97a81600be483c293aee457", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/MF-nbdbNNFrBS6lXH6ovd5_QegasJhjA-jl9KdhYdLA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3fdea5709efc2342950519678dccbfa5b6a5bc9", "width": 1080, "height": 720}], "variants": {}, "id": "2h6z0wcxfeyGYPsAUSLRq1EjtP-b9N_kgrbXZ-BV1x0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14r4v10", "is_robot_indexable": true, "report_reasons": null, "author": "tbrownlow", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r4v10/i_attempted_to_create_the_ultimate_guide_to_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r4v10/i_attempted_to_create_the_ultimate_guide_to_dbt/", "subreddit_subscribers": 114159, "created_utc": 1688547009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). \n\nI get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. \n\nI have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). \n\nHow do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?", "author_fullname": "t2_pu047jjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Performance vs On-Prem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14quid6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688513977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is moving from on-Prem to Azure, and one thing I don\u2019t get about ADF/Databricks is how small items perform so poorly in Azure (or cloud enviros in general). &lt;/p&gt;\n\n&lt;p&gt;I get that they\u2019re built for scale, and the Spark cluster spin up has a floor of runtime. But this is an annoying limitation. &lt;/p&gt;\n\n&lt;p&gt;I have several jobs that are several small pipelines as one large job, which between ingestion and transforms are comparatively very slow in Azure. But, old on-premise ETL tools written in C did this so simply (think SSIS or BODS). &lt;/p&gt;\n\n&lt;p&gt;How do people run workloads in Azure especially when they have SLAs? I see more complicated items running much quicker, which is great, but how do fellow DE\u2019s do smaller loads in Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14quid6", "is_robot_indexable": true, "report_reasons": null, "author": "atlvernburn", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14quid6/azure_performance_vs_onprem/", "subreddit_subscribers": 114159, "created_utc": 1688513977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in my mid 20s, single, and have a hybrid job which gives me a crap ton of free time to just sit around wasting time. I already lift, read, etc. so I've got all the good habits I could possibly want to build. However, I would like to make more money.\n\nAre there any side hustles for an early career DE that don't have a huge barrier to entry or that aren't basically gambling?\n\nI've considered web apps but frankly I'm coming up with solutions without very well documented problems. Additionally the time required to build a good functional web app could easily be over a year to ever earn that first dollar.\n\nI've considered scripts for predicting sports card values or for gaining an edge in sports betting but once again that just seems like gambling with extra steps.\n\nI'm too early in my career for consulting.\n\nThe best idea I've come up with is some sort of DE/analytics blog with an emphasis on sports or small scale IoT projects.\n\nDoes anyone have any other suggestions? Should I just be focusing my time on learning new skills to get a raise and/or a new job?\n\n&amp;#x200B;", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any side hustles as a DE with smaller barriers to entry than building a full-scale web app?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qqy5s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688504686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in my mid 20s, single, and have a hybrid job which gives me a crap ton of free time to just sit around wasting time. I already lift, read, etc. so I&amp;#39;ve got all the good habits I could possibly want to build. However, I would like to make more money.&lt;/p&gt;\n\n&lt;p&gt;Are there any side hustles for an early career DE that don&amp;#39;t have a huge barrier to entry or that aren&amp;#39;t basically gambling?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered web apps but frankly I&amp;#39;m coming up with solutions without very well documented problems. Additionally the time required to build a good functional web app could easily be over a year to ever earn that first dollar.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered scripts for predicting sports card values or for gaining an edge in sports betting but once again that just seems like gambling with extra steps.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m too early in my career for consulting.&lt;/p&gt;\n\n&lt;p&gt;The best idea I&amp;#39;ve come up with is some sort of DE/analytics blog with an emphasis on sports or small scale IoT projects.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any other suggestions? Should I just be focusing my time on learning new skills to get a raise and/or a new job?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14qqy5s", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qqy5s/are_there_any_side_hustles_as_a_de_with_smaller/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qqy5s/are_there_any_side_hustles_as_a_de_with_smaller/", "subreddit_subscribers": 114159, "created_utc": 1688504686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a junior data analyst shifting towards a data engineering role. We are implementing a modern data stack with azure blob storage, azure synapse and databricks. We just have one source of data (homegrown ERP system developed in-house) using sql server. The ERP system is pretty bad in terms of data quality (poor data, lots of etl to do). What\u2019s the best way to approach data engineering? Our plan is use databricks notebooks for etl, synapse pipelines for orchestration, great expectations for validations. Our team is intermediate in Python, but looking to grow. Solution should be simple, yet scalable. Team of 5. Any suggestions/tips?", "author_fullname": "t2_56ltry44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing a modern data platform in a small team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qiyie", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688486091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a junior data analyst shifting towards a data engineering role. We are implementing a modern data stack with azure blob storage, azure synapse and databricks. We just have one source of data (homegrown ERP system developed in-house) using sql server. The ERP system is pretty bad in terms of data quality (poor data, lots of etl to do). What\u2019s the best way to approach data engineering? Our plan is use databricks notebooks for etl, synapse pipelines for orchestration, great expectations for validations. Our team is intermediate in Python, but looking to grow. Solution should be simple, yet scalable. Team of 5. Any suggestions/tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qiyie", "is_robot_indexable": true, "report_reasons": null, "author": "Specific-Passage", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qiyie/implementing_a_modern_data_platform_in_a_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qiyie/implementing_a_modern_data_platform_in_a_small/", "subreddit_subscribers": 114159, "created_utc": 1688486091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. A query optimizer that is more effective than manual optimization\n2. Faster log queries with less storage space consumed\n3. 20 times higher concurrency\n4. Enhanced Data Lakehouse capabilities (more data sources supported and faster performance)\n5. A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios\n6. Efficient management of memory and CPU resources\n7. Elastic scaling of computation resources and hot-cold data separation for much lower storage costs\n8. Faster, stabler, and smarter data ingestion\n9. No more OOM errors\n10. Support for Kubernetes deployment\n\n[Release Note](https://doris.apache.org/docs/dev/releasenotes/release-2.0-beta/)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris 2.0 Beta Now Available: Faster, Stabler, and More Versatile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r8zo3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688559364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;A query optimizer that is more effective than manual optimization&lt;/li&gt;\n&lt;li&gt;Faster log queries with less storage space consumed&lt;/li&gt;\n&lt;li&gt;20 times higher concurrency&lt;/li&gt;\n&lt;li&gt;Enhanced Data Lakehouse capabilities (more data sources supported and faster performance)&lt;/li&gt;\n&lt;li&gt;A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios&lt;/li&gt;\n&lt;li&gt;Efficient management of memory and CPU resources&lt;/li&gt;\n&lt;li&gt;Elastic scaling of computation resources and hot-cold data separation for much lower storage costs&lt;/li&gt;\n&lt;li&gt;Faster, stabler, and smarter data ingestion&lt;/li&gt;\n&lt;li&gt;No more OOM errors&lt;/li&gt;\n&lt;li&gt;Support for Kubernetes deployment&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://doris.apache.org/docs/dev/releasenotes/release-2.0-beta/\"&gt;Release Note&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14r8zo3", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r8zo3/apache_doris_20_beta_now_available_faster_stabler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r8zo3/apache_doris_20_beta_now_available_faster_stabler/", "subreddit_subscribers": 114159, "created_utc": 1688559364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently migrating my new teams pipeline from databricks notebook (all in dev, no cicd, or major tests. scheduled in databricks. All spark.sql code, no pyspark at all.) to snowflake +dbt. \n\nWhile everything is going well, I want to create a local development environment everyone on my team can use easily (mostly non engineers). One of the main pain points is that 3/4 of my team has windows computers since they are analysts. \n\nBest way to do this is creating some devcontainers with VScode. And while I've already done this and it's working quite nice, I want to take it a few steps further and want to keep all the development inside VScode. For example, right now, I tests some queries in snowflake worksheets and when it works, I basically copy paste the query to vscode and change the table format to dbt (source or ref). This is a bit tedious for me and for my analysts it will be worse since they are use to get results instantly in databricks notebooks. \n\nIs there actually a better way of developing with dbt? can i possibly run a dbt model and get the query result inside vscode directly (without having to change table name)? \n\nAny other tips would be appreciated. \n\n&amp;#x200B;", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better VSCODE local dev with snowflake+dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r5j5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688549124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently migrating my new teams pipeline from databricks notebook (all in dev, no cicd, or major tests. scheduled in databricks. All spark.sql code, no pyspark at all.) to snowflake +dbt. &lt;/p&gt;\n\n&lt;p&gt;While everything is going well, I want to create a local development environment everyone on my team can use easily (mostly non engineers). One of the main pain points is that 3/4 of my team has windows computers since they are analysts. &lt;/p&gt;\n\n&lt;p&gt;Best way to do this is creating some devcontainers with VScode. And while I&amp;#39;ve already done this and it&amp;#39;s working quite nice, I want to take it a few steps further and want to keep all the development inside VScode. For example, right now, I tests some queries in snowflake worksheets and when it works, I basically copy paste the query to vscode and change the table format to dbt (source or ref). This is a bit tedious for me and for my analysts it will be worse since they are use to get results instantly in databricks notebooks. &lt;/p&gt;\n\n&lt;p&gt;Is there actually a better way of developing with dbt? can i possibly run a dbt model and get the query result inside vscode directly (without having to change table name)? &lt;/p&gt;\n\n&lt;p&gt;Any other tips would be appreciated. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r5j5q", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r5j5q/better_vscode_local_dev_with_snowflakedbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r5j5q/better_vscode_local_dev_with_snowflakedbt/", "subreddit_subscribers": 114159, "created_utc": 1688549124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I wanna read the Kimball books as I've seen them mentioned many times as being a great source of quality information about how to do things.\n\nI see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling\n\nThe Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses\n\nThe Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data\n\n\nShould I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.\n\nThanks a lot guys. Really appreciate the help you've all been", "author_fullname": "t2_p5wlf0g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Kimball to Start with", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qusqd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688514805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I wanna read the Kimball books as I&amp;#39;ve seen them mentioned many times as being a great source of quality information about how to do things.&lt;/p&gt;\n\n&lt;p&gt;I see three books:\nThe Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse Lifecycle Toolkit: Expert methods for designing, developing, and deploying data warehouses&lt;/p&gt;\n\n&lt;p&gt;The Data Warehouse ETL Toolkit: Practical Techniques for extracting, cleaning, conforming, and delivering data&lt;/p&gt;\n\n&lt;p&gt;Should I start going through them in any particular order or just dive in where it seems appropriate? Also would it make more sense to get one of the more modern editions of the books or the content regardless of the edition is still relevant and worth it.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot guys. Really appreciate the help you&amp;#39;ve all been&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qusqd", "is_robot_indexable": true, "report_reasons": null, "author": "El_Cato_Crande", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qusqd/which_kimball_to_start_with/", "subreddit_subscribers": 114159, "created_utc": 1688514805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can we streamline the process of understanding source data? Frequently, questions like \"What business process generates this data and why?\" require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.\n\nTypically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.\n\nAny advice to make this better?", "author_fullname": "t2_55thi7w8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I ensure that my data model accurately represents the data in my OLAP DB? How can I be certain that my DIM and FACT tables effectively capture the business workflow, leading to optimized and efficient queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qvo0e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688517373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can we streamline the process of understanding source data? Frequently, questions like &amp;quot;What business process generates this data and why?&amp;quot; require accurate and prompt answers, but the current methods often make it difficult to achieve this efficiently.&lt;/p&gt;\n\n&lt;p&gt;Typically, the data team must engage with business users and stakeholders regularly, relying on self-learning to gain insights. Unfortunately, this process can be lengthy and arduous.&lt;/p&gt;\n\n&lt;p&gt;Any advice to make this better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qvo0e", "is_robot_indexable": true, "report_reasons": null, "author": "faizfablillah", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qvo0e/how_can_i_ensure_that_my_data_model_accurately/", "subreddit_subscribers": 114159, "created_utc": 1688517373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like your opinion of the Python library Dask. \n\nI made some tests with several datasets with a total of 8 GB and it performed a simple ETL process in 30 sec. \n\nI did the same process wit PySpark and it took 28 sec.  \nI also found this article talking about Spark vs Dask  \n[https://www.coiled.io/blog/moving-from-spark-to-dask](https://www.coiled.io/blog/moving-from-spark-to-dask) \n\nIs Dask that good to handle middle to big-size datasets?   \nThen why is a library not that well known? \n\n&amp;#x200B;", "author_fullname": "t2_7dy3sswp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dask for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r8spe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688558832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like your opinion of the Python library Dask. &lt;/p&gt;\n\n&lt;p&gt;I made some tests with several datasets with a total of 8 GB and it performed a simple ETL process in 30 sec. &lt;/p&gt;\n\n&lt;p&gt;I did the same process wit PySpark and it took 28 sec.&lt;br/&gt;\nI also found this article talking about Spark vs Dask&lt;br/&gt;\n&lt;a href=\"https://www.coiled.io/blog/moving-from-spark-to-dask\"&gt;https://www.coiled.io/blog/moving-from-spark-to-dask&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Is Dask that good to handle middle to big-size datasets?&lt;br/&gt;\nThen why is a library not that well known? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?auto=webp&amp;v=enabled&amp;s=985e0dac5a538651a27facacb88f439ffb706ab1", "width": 2049, "height": 1077}, "resolutions": [{"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b34463d6ffa31246495a19a91c892ec7bcc23ca7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e21104286c21d66fefead2c53a4995959da5675", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbd23e1c247e5be5adc30c6ce5cee34b97b4c220", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bcceb6db91e2355af81f4ae2f3b9e7bf02148b80", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d8fede23f3d1fd2fc38a01ec8fd06bed011bbf6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ZQoNcaEqGGEUJZxEYfQu_xL4hIkAn5CVic-No7cTi3w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa5d248f3a623fcc480dc7d3b25f4cdf1690212b", "width": 1080, "height": 567}], "variants": {}, "id": "f7eK9VqpVNGVOYBwzqp50W4KQEUY3gbUPuEbkbhVvp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r8spe", "is_robot_indexable": true, "report_reasons": null, "author": "Asleep-Organization7", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r8spe/dask_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r8spe/dask_for_data_engineering/", "subreddit_subscribers": 114159, "created_utc": 1688558832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone, \n\nWhat is the best resources for understanding how to build out a pipeline from scratch. I'm currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.\n\nIt had me thinking if I was to get the job I wouldn't know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.\n\nI figured I should get started now since it's always good to learn things start to finish.\n\nAny resources you could provide would be great (books, articles, other post, ect...)\n\nThanks in advance!", "author_fullname": "t2_5ejp13jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering start to finish", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qzi8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688529422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone, &lt;/p&gt;\n\n&lt;p&gt;What is the best resources for understanding how to build out a pipeline from scratch. I&amp;#39;m currently in an interview for a company that seems to have no pipeline set up based on my conversation with the hiring manager.&lt;/p&gt;\n\n&lt;p&gt;It had me thinking if I was to get the job I wouldn&amp;#39;t know where to start. Where can I find good resources on setting up a production and dev environment, setting up testing, integrating CI/CD, integrating ochestration tool like airflow and all the small details that go into setting up a new environment.&lt;/p&gt;\n\n&lt;p&gt;I figured I should get started now since it&amp;#39;s always good to learn things start to finish.&lt;/p&gt;\n\n&lt;p&gt;Any resources you could provide would be great (books, articles, other post, ect...)&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14qzi8p", "is_robot_indexable": true, "report_reasons": null, "author": "knowledgeMeUp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qzi8p/data_engineering_start_to_finish/", "subreddit_subscribers": 114159, "created_utc": 1688529422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. \n\nThese data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?", "author_fullname": "t2_dg51ak2mn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "user identity, machine identity and now we need data identity ? what do you think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14qws59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688520815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;thinking of creating some kind of data identity system which will put a data in some kind of envelope - add id, tags etc to that envelope and share that data envelope with whoever needs data access.          In short data bundle concept with identity tied in. &lt;/p&gt;\n\n&lt;p&gt;These data bundles are like container images which has registry, versioning which can be used by AI models to train a data. As good data will always be an issue going forward ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14qws59", "is_robot_indexable": true, "report_reasons": null, "author": "Extreme-Summer-2756", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14qws59/user_identity_machine_identity_and_now_we_need/", "subreddit_subscribers": 114159, "created_utc": 1688520815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a Junior DE from Argentina and got contacted via LinkedIn for a DE position in a Miami based Fintech company called fivvy.\n\nThe interview went great, however at the very end the recruiter asked me to write by hand a brief description of myself and the value I would add to the company, sign it and send them a picture so they could asses my personality traits with graphology in lieu of a psychological evaluation.\n\nI am really confused, and considering pulling back from the recruiting process. But maybe it is a cultural thing and I am reading too much into it.\n\nThe role itself is very similar to what I do in my current job(AWS, ETL using glue, requirements gathering etc.) But the pay is roughly 80% more", "author_fullname": "t2_11jrhn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common in the US to ask for a handwritten cover letter in DE(or at all)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rcq73", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688568386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a Junior DE from Argentina and got contacted via LinkedIn for a DE position in a Miami based Fintech company called fivvy.&lt;/p&gt;\n\n&lt;p&gt;The interview went great, however at the very end the recruiter asked me to write by hand a brief description of myself and the value I would add to the company, sign it and send them a picture so they could asses my personality traits with graphology in lieu of a psychological evaluation.&lt;/p&gt;\n\n&lt;p&gt;I am really confused, and considering pulling back from the recruiting process. But maybe it is a cultural thing and I am reading too much into it.&lt;/p&gt;\n\n&lt;p&gt;The role itself is very similar to what I do in my current job(AWS, ETL using glue, requirements gathering etc.) But the pay is roughly 80% more&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14rcq73", "is_robot_indexable": true, "report_reasons": null, "author": "IfThisThenWhat", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rcq73/is_it_common_in_the_us_to_ask_for_a_handwritten/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rcq73/is_it_common_in_the_us_to_ask_for_a_handwritten/", "subreddit_subscribers": 114159, "created_utc": 1688568386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently stumbled on a job opportunity that uses Oracle data integrator. As someone who is 'at home' with Oracle, seemed intriguing, but then I checked market share and found Informatica has much greater market share...   \n\n\non the other hand, I am more fond of 'hands-on tools', like writing scripts by myself, not utilizing any kind of GUI.   \nWhat is the relevance and prospects of tools like ODI and/or Informatica, and even Oracle's GoldenGate vs Spark and others?  \n\n\nwhen talking about this, obviously, I am talking about big corporate clients with some regulations and needs for support, etc etc..", "author_fullname": "t2_bnm2tai1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Informatica vs. Oracle Data Integrator vs Oracle GoldenGate vs others (Spark, Python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r6ltr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688552385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently stumbled on a job opportunity that uses Oracle data integrator. As someone who is &amp;#39;at home&amp;#39; with Oracle, seemed intriguing, but then I checked market share and found Informatica has much greater market share...   &lt;/p&gt;\n\n&lt;p&gt;on the other hand, I am more fond of &amp;#39;hands-on tools&amp;#39;, like writing scripts by myself, not utilizing any kind of GUI.&lt;br/&gt;\nWhat is the relevance and prospects of tools like ODI and/or Informatica, and even Oracle&amp;#39;s GoldenGate vs Spark and others?  &lt;/p&gt;\n\n&lt;p&gt;when talking about this, obviously, I am talking about big corporate clients with some regulations and needs for support, etc etc..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14r6ltr", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Cancel_7891", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r6ltr/informatica_vs_oracle_data_integrator_vs_oracle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r6ltr/informatica_vs_oracle_data_integrator_vs_oracle/", "subreddit_subscribers": 114159, "created_utc": 1688552385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nWhat do you mainly use for testing your spark jobs? Is it unittest or rather a pyspark specific library? \n\nCould you please elaborate on how the testing fits into your development process? At my current position there is no formal testing process, so I open up the console, create some dummy data that I feed into the dataframe, run some transformations and check the result with my eyes.\n\nI would like to learn some more professional way of running tests but don't know how to approach it, and, if possible, how to gradually improve my testing process.\n\nThank you", "author_fullname": "t2_gfx5s46h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing spark applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rchm7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688567851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;What do you mainly use for testing your spark jobs? Is it unittest or rather a pyspark specific library? &lt;/p&gt;\n\n&lt;p&gt;Could you please elaborate on how the testing fits into your development process? At my current position there is no formal testing process, so I open up the console, create some dummy data that I feed into the dataframe, run some transformations and check the result with my eyes.&lt;/p&gt;\n\n&lt;p&gt;I would like to learn some more professional way of running tests but don&amp;#39;t know how to approach it, and, if possible, how to gradually improve my testing process.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rchm7", "is_robot_indexable": true, "report_reasons": null, "author": "LeftHelicopter5297", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rchm7/testing_spark_applications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rchm7/testing_spark_applications/", "subreddit_subscribers": 114159, "created_utc": 1688567851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm currently working on a project to demonstrate my ability to develop end-to-end data pipelines. I'm wondering if there are any skills or tools that I may have overlooked. Currently, my process involves the following components:\n\n* I utilize Airflow as the orchestrator, which retrieves data from an online API.\n* Next, I perform data transformations using Spark.\n* The transformed data is then loaded into a PostgreSQL database.\n* I create various views from this data using PostgreSQL.\n* Finally, I use Grafana to automatically generate and display dashboards based on the views. \n* All of these components are implemented using Docker containers.\n\n1) Is there anything essential to the data engineer position that I may have omitted? Could you show the logic of your typical end-to-end data pipeline and what tech-stack do you use to do it?\n\n2) What's the best practice or ideal data pipeline/tech stack?\n\n3) How is your performance (data engineers) typically measured? (e.g. By the number of pipelines done?)", "author_fullname": "t2_3vzap1d5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Showcasing Complete ETL Pipeline Skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rcg9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688567760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a project to demonstrate my ability to develop end-to-end data pipelines. I&amp;#39;m wondering if there are any skills or tools that I may have overlooked. Currently, my process involves the following components:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I utilize Airflow as the orchestrator, which retrieves data from an online API.&lt;/li&gt;\n&lt;li&gt;Next, I perform data transformations using Spark.&lt;/li&gt;\n&lt;li&gt;The transformed data is then loaded into a PostgreSQL database.&lt;/li&gt;\n&lt;li&gt;I create various views from this data using PostgreSQL.&lt;/li&gt;\n&lt;li&gt;Finally, I use Grafana to automatically generate and display dashboards based on the views. &lt;/li&gt;\n&lt;li&gt;All of these components are implemented using Docker containers.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;1) Is there anything essential to the data engineer position that I may have omitted? Could you show the logic of your typical end-to-end data pipeline and what tech-stack do you use to do it?&lt;/p&gt;\n\n&lt;p&gt;2) What&amp;#39;s the best practice or ideal data pipeline/tech stack?&lt;/p&gt;\n\n&lt;p&gt;3) How is your performance (data engineers) typically measured? (e.g. By the number of pipelines done?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rcg9h", "is_robot_indexable": true, "report_reasons": null, "author": "conlake", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rcg9h/showcasing_complete_etl_pipeline_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rcg9h/showcasing_complete_etl_pipeline_skills/", "subreddit_subscribers": 114159, "created_utc": 1688567760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7rg2eq0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg won the table format war: But not in the way you thought it might", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_14rcaj9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XsYFMlNEZCDXJMqVj5ipNSy5AE0iyr_5rFyuLsdfKjQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688567397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bitsondatadev.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bitsondatadev.substack.com/p/iceberg-won-the-table-format-war", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?auto=webp&amp;v=enabled&amp;s=6b43e6782abb50094ef2d34a99021b60c20c639a", "width": 1080, "height": 1618}, "resolutions": [{"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e525d7b58e0d859466ef65335c697f07133fbe6c", "width": 108, "height": 161}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c941b71d9b3c6f5474c6bbdaa7dd20bd6aec5c2", "width": 216, "height": 323}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39f026b8f1273327c96114b4aa1a3482d371742d", "width": 320, "height": 479}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ad02b4e8ddf6f18a0a4bf17d725e4caa38d19e3", "width": 640, "height": 958}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=655ccbb038d6e012f114158f4c31150af8726079", "width": 960, "height": 1438}, {"url": "https://external-preview.redd.it/7DAiyTNK1X9i6v3wafYKrUAnFDyPbIkrl9mLCA8RUJU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b107211e8d9b291ec66e7691bf4b048f348c3d6", "width": 1080, "height": 1618}], "variants": {}, "id": "SDJCzYbCv7yEFiUYDPkYEbxyWOF93G9i_gU6hrmUfY4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rcaj9", "is_robot_indexable": true, "report_reasons": null, "author": "bitsondatadev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rcaj9/iceberg_won_the_table_format_war_but_not_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bitsondatadev.substack.com/p/iceberg-won-the-table-format-war", "subreddit_subscribers": 114159, "created_utc": 1688567397.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Engineering shop with many estimate date 1-10, est date 2 1-10, etc .. using it for powerbi. Should I split the table with one just dates and another all the others like Yes, no, proj desc, proj other info. Best approach?  a small sample below. There are  alot more. Just wondering.  \n[PROJV.PIN](https://PROJV.PIN) pin\\_char\n\n, PROJV.REGION\\_NUM \"Region\"\n\n, PROJV.PROGRAM\\_TYPE\\_CDE\\_DESC \"Program Type\"\n\n, PROJV.WORK\\_TYP\\_CDE\\_DESC \"Project Type of Work\"\n\n, (to\\_char(PROJV.EARLIEST\\_LET\\_DTE,'YYYY-MM-DD')) \"Let Date\"\n\n, PROJV.COUNTY\\_CONCAT \"County\"\n\n, PROJV.ROUTE \"Route\"\n\n, PROJV.TERMINI\\_TXT \"Project Description\"\n\n, PROJV.SCOPE\\_OF\\_WORK\\_TXT \"Scope of Work\"\n\n\\--     , PROJV.TRACTS\\_TEXT \"ROW Tract Info\"\n\n\\--     , PROJV.BEG\\_LM\\_NBR \"Beg LM\"\n\n\\--     , PROJV.END\\_LM\\_NBR  \"End LM\"\n\n, PROJV.PROJECT\\_LENGTH \"Project Length\"\n\n&amp;#x200B;\n\n\\--ATTRIBUTES\n\n, PAJ.BR\\_PROG \"Bridge Program Yr\"\n\n, BR\\_SYS.BR\\_SYS \"Bridge System\"\n\n, PROJV.BRNO\\_CONCAT \"Bridges\"\n\n, PAJ.GFT\\_YR \"GFT Year\"\n\n, PAJ.RR\\_IND \"Railroad Involved\"\n\n, PAJ.IA\\_IND IA\n\n, PAJ.DONE\\_UNDER \"Done Under Other PIN\"\n\n, PAJ.PARENT\\_PROJ \"Project Work Being Done On\"\n\n, PAJ.WK\\_PRGM \"Work Program Project\"\n\n, PAJ.ENV\\_DOC \"Environmental Document\"\n\n, PAJ.TAMP\\_CLASS \"TAMP Asset Class\"\n\n, PAJ.TAMP\\_WK \"TAMP Work Type\"\n\n, PAJ.TAMP\\_NHS \"TAMP NHS\"\n\n, PAJ.PPRM\\_NHS \"PPRM NHS\"", "author_fullname": "t2_jeg19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best approach of data engineering this kind of data for powerbi or tableau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rc102", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688566799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Engineering shop with many estimate date 1-10, est date 2 1-10, etc .. using it for powerbi. Should I split the table with one just dates and another all the others like Yes, no, proj desc, proj other info. Best approach?  a small sample below. There are  alot more. Just wondering.&lt;br/&gt;\n&lt;a href=\"https://PROJV.PIN\"&gt;PROJV.PIN&lt;/a&gt; pin_char&lt;/p&gt;\n\n&lt;p&gt;, PROJV.REGION_NUM &amp;quot;Region&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PROJV.PROGRAM_TYPE_CDE_DESC &amp;quot;Program Type&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PROJV.WORK_TYP_CDE_DESC &amp;quot;Project Type of Work&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, (to_char(PROJV.EARLIEST_LET_DTE,&amp;#39;YYYY-MM-DD&amp;#39;)) &amp;quot;Let Date&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PROJV.COUNTY_CONCAT &amp;quot;County&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PROJV.ROUTE &amp;quot;Route&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PROJV.TERMINI_TXT &amp;quot;Project Description&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PROJV.SCOPE_OF_WORK_TXT &amp;quot;Scope of Work&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;--     , PROJV.TRACTS_TEXT &amp;quot;ROW Tract Info&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;--     , PROJV.BEG_LM_NBR &amp;quot;Beg LM&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;--     , PROJV.END_LM_NBR  &amp;quot;End LM&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PROJV.PROJECT_LENGTH &amp;quot;Project Length&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;--ATTRIBUTES&lt;/p&gt;\n\n&lt;p&gt;, PAJ.BR_PROG &amp;quot;Bridge Program Yr&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, BR_SYS.BR_SYS &amp;quot;Bridge System&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PROJV.BRNO_CONCAT &amp;quot;Bridges&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.GFT_YR &amp;quot;GFT Year&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.RR_IND &amp;quot;Railroad Involved&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.IA_IND IA&lt;/p&gt;\n\n&lt;p&gt;, PAJ.DONE_UNDER &amp;quot;Done Under Other PIN&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.PARENT_PROJ &amp;quot;Project Work Being Done On&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.WK_PRGM &amp;quot;Work Program Project&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.ENV_DOC &amp;quot;Environmental Document&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.TAMP_CLASS &amp;quot;TAMP Asset Class&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.TAMP_WK &amp;quot;TAMP Work Type&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.TAMP_NHS &amp;quot;TAMP NHS&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;, PAJ.PPRM_NHS &amp;quot;PPRM NHS&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rc102", "is_robot_indexable": true, "report_reasons": null, "author": "pectin232", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rc102/best_approach_of_data_engineering_this_kind_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rc102/best_approach_of_data_engineering_this_kind_of/", "subreddit_subscribers": 114159, "created_utc": 1688566799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, wanted a second opinion on if this idea is one of those picking up a penny in front of a steam roller things. We are limited to using lambda to make an api call to trino and step functions as the orchestrator\n\nOption 1 - Explicit \n\n    Step function Task 1(Trino Transformation 1) &gt; Task 2(TT2) &gt; Task 3(TT3) \n\nOption 2 - \"recursion\" \n\n    Trigger(send step ID) &gt; Recursive Task(output next step Id), rerun function until end state is reached. \n\nWhat kind safeguard should I put in place to prevent infinite recursion? \n\nThanks!", "author_fullname": "t2_8lbog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a bad idea? Using \"recursion\" in AWS step functions to orchestrate sequential trino steps instead of explicitly assigning every step to a task.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rbu13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688566655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688566372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, wanted a second opinion on if this idea is one of those picking up a penny in front of a steam roller things. We are limited to using lambda to make an api call to trino and step functions as the orchestrator&lt;/p&gt;\n\n&lt;p&gt;Option 1 - Explicit &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Step function Task 1(Trino Transformation 1) &amp;gt; Task 2(TT2) &amp;gt; Task 3(TT3) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Option 2 - &amp;quot;recursion&amp;quot; &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Trigger(send step ID) &amp;gt; Recursive Task(output next step Id), rerun function until end state is reached. \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;What kind safeguard should I put in place to prevent infinite recursion? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rbu13", "is_robot_indexable": true, "report_reasons": null, "author": "AUGcodon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rbu13/is_this_a_bad_idea_using_recursion_in_aws_step/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rbu13/is_this_a_bad_idea_using_recursion_in_aws_step/", "subreddit_subscribers": 114159, "created_utc": 1688566372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI work as a mid DE and have some exposure to spark - it's only small things - read a file (mainly csv/json), use a predefined schema, apply some transformations, save it to orc. Everything was set up for me, airflow runs things, so I mainly need to make small edits in preexisting scripts and navigate airflow to the proper script. I don't even have access to spark UI and it all runs on-prem, on one machine. \n\nI would like to break into a spark heavy role, ideally databricks. I've done some courses, read two books on spark and whenever there's a chance to do something with spark at work, I volunteer to do it. I am also preparing for databricks spark certification (my job market is full of shitty consulting companies, I have no chance to land a job in a product company for now, as I'm not competent enough).\n\nThe job market in my country became quite rough recently and I would like to improve my chances to land a better position. I literally have no private git repo and I would like to change that, create some projects that I could link to in my CV.\n\nCould you recommend some projects that I could do after hours in something like a month or two and then perhaps build on? I would appreciate even vague ideas.\n\nThanks guys", "author_fullname": "t2_gfx5s46h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark project ideas for an already employed data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14rbmdo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688565885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I work as a mid DE and have some exposure to spark - it&amp;#39;s only small things - read a file (mainly csv/json), use a predefined schema, apply some transformations, save it to orc. Everything was set up for me, airflow runs things, so I mainly need to make small edits in preexisting scripts and navigate airflow to the proper script. I don&amp;#39;t even have access to spark UI and it all runs on-prem, on one machine. &lt;/p&gt;\n\n&lt;p&gt;I would like to break into a spark heavy role, ideally databricks. I&amp;#39;ve done some courses, read two books on spark and whenever there&amp;#39;s a chance to do something with spark at work, I volunteer to do it. I am also preparing for databricks spark certification (my job market is full of shitty consulting companies, I have no chance to land a job in a product company for now, as I&amp;#39;m not competent enough).&lt;/p&gt;\n\n&lt;p&gt;The job market in my country became quite rough recently and I would like to improve my chances to land a better position. I literally have no private git repo and I would like to change that, create some projects that I could link to in my CV.&lt;/p&gt;\n\n&lt;p&gt;Could you recommend some projects that I could do after hours in something like a month or two and then perhaps build on? I would appreciate even vague ideas.&lt;/p&gt;\n\n&lt;p&gt;Thanks guys&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14rbmdo", "is_robot_indexable": true, "report_reasons": null, "author": "LeftHelicopter5297", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rbmdo/pyspark_project_ideas_for_an_already_employed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rbmdo/pyspark_project_ideas_for_an_already_employed/", "subreddit_subscribers": 114159, "created_utc": 1688565885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data warehousing is a business process of creating and maintaining a data warehouse, which provides decision makers and other stakeholders with a consolidated view of historical data in support of data analysis and reporting. [https://www.dasca.org/world-of-big-data/article/data-warehouse-architecture-and-design-a-reflective-guide](https://www.dasca.org/world-of-big-data/article/data-warehouse-architecture-and-design-a-reflective-guide) ", "author_fullname": "t2_9de03cxq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse Architecture and Design: A Reflective Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14r9tst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688561539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data warehousing is a business process of creating and maintaining a data warehouse, which provides decision makers and other stakeholders with a consolidated view of historical data in support of data analysis and reporting. &lt;a href=\"https://www.dasca.org/world-of-big-data/article/data-warehouse-architecture-and-design-a-reflective-guide\"&gt;https://www.dasca.org/world-of-big-data/article/data-warehouse-architecture-and-design-a-reflective-guide&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2tmTBA7Cy6T5OJmm6Vl6Iy6UX_My7wMGS4Ni150b0RU.jpg?auto=webp&amp;v=enabled&amp;s=157d112950fe27f4ad501f440cbf75497580ffac", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/2tmTBA7Cy6T5OJmm6Vl6Iy6UX_My7wMGS4Ni150b0RU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5530b4536d80051b224487d09644634f6a792406", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/2tmTBA7Cy6T5OJmm6Vl6Iy6UX_My7wMGS4Ni150b0RU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45388d797418efa4838383728e51da3b64d01c82", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/2tmTBA7Cy6T5OJmm6Vl6Iy6UX_My7wMGS4Ni150b0RU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b076ff8f3b0bd02677d541977f7479b7b3b0c045", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/2tmTBA7Cy6T5OJmm6Vl6Iy6UX_My7wMGS4Ni150b0RU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d0fd08d5a3db0d977883f51690d5b65c4f80358", "width": 640, "height": 336}], "variants": {}, "id": "VgWmliN686rtckPJmZChzmQJgAxoA5mbZRXDS0t1loo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14r9tst", "is_robot_indexable": true, "report_reasons": null, "author": "Palaksharma22", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14r9tst/data_warehouse_architecture_and_design_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14r9tst/data_warehouse_architecture_and_design_a/", "subreddit_subscribers": 114159, "created_utc": 1688561539.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}