{"kind": "Listing", "data": {"after": "t3_154252k", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uu62zwts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fact", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_153o48v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 168, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 168, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kn2VeRL7dKE02ma838cuSRPnLHQrVqVdvja0DMkus7Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689752236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/glkf1eivkvcb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/glkf1eivkvcb1.jpg?auto=webp&amp;s=e99447cdb12d56a8fcb22529774b09d0e98e9a28", "width": 552, "height": 414}, "resolutions": [{"url": "https://preview.redd.it/glkf1eivkvcb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6916d3d15394f881e4d3c9973b868d60ee73f5e1", "width": 108, "height": 81}, {"url": "https://preview.redd.it/glkf1eivkvcb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f5d589dbfbac864bff82915ab383a8ac0b23546", "width": 216, "height": 162}, {"url": "https://preview.redd.it/glkf1eivkvcb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4b63873775811f460e2ddc4aa21baadabb2fd36", "width": 320, "height": 240}], "variants": {}, "id": "57DxVeWB5qdgJSeyFIqARGyquEhznuPKWtiu27RO7ek"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "153o48v", "is_robot_indexable": true, "report_reasons": null, "author": "Sailja_Jain", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153o48v/fact/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/glkf1eivkvcb1.jpg", "subreddit_subscribers": 116823, "created_utc": 1689752236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ummm weird question. At this point I dream in SQL sometimes and think I might think in it as much as I think in English. I think most lead data engineers know it super well.", "author_fullname": "t2_57mn29f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job application for a lead role \u201cPlease expand more on your experience with SQL\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153llcj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689744004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ummm weird question. At this point I dream in SQL sometimes and think I might think in it as much as I think in English. I think most lead data engineers know it super well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "153llcj", "is_robot_indexable": true, "report_reasons": null, "author": "k_dani_b", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153llcj/job_application_for_a_lead_role_please_expand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153llcj/job_application_for_a_lead_role_please_expand/", "subreddit_subscribers": 116823, "created_utc": 1689744004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_io93l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bridging the gap between IaC and Schema Management | Atlas | Open-source database schema management tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_153w8gb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jZyQUE5tMBKtFY7M9aXlkkguJO444ur05EqfqatbPEk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689776056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "atlasgo.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://atlasgo.io/blog/2023/07/19/bridging-the-gap-between-iac-and-schema-management", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LOWDQxtZoqPT6tKFrPYjlEmKFKLCXTrKMLW77pNWhhY.jpg?auto=webp&amp;s=d799bf3fbbae4d3e7bc4d96e463d8e63e27e64ca", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/LOWDQxtZoqPT6tKFrPYjlEmKFKLCXTrKMLW77pNWhhY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=821b930b0430b20ba6a62db39d4d179c6775190c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/LOWDQxtZoqPT6tKFrPYjlEmKFKLCXTrKMLW77pNWhhY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f9fbbcb84119df711bf3c224456043f49e0754c7", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/LOWDQxtZoqPT6tKFrPYjlEmKFKLCXTrKMLW77pNWhhY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d40963da30fab9e04cd5211a505f5d369ac86816", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/LOWDQxtZoqPT6tKFrPYjlEmKFKLCXTrKMLW77pNWhhY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=11896f760a027c746ccdf72422c45e0e015d904e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/LOWDQxtZoqPT6tKFrPYjlEmKFKLCXTrKMLW77pNWhhY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=db05a694a3196fce042cf43d00949cad2c718748", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/LOWDQxtZoqPT6tKFrPYjlEmKFKLCXTrKMLW77pNWhhY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2495a9f7e1ab3bdaa6d05269c4982331f873e518", "width": 1080, "height": 607}], "variants": {}, "id": "_O7gzcuYqhIrhryNdtPkpLoNou7--_Y8M3r_4gmAu2M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "153w8gb", "is_robot_indexable": true, "report_reasons": null, "author": "rotemtam", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153w8gb/bridging_the_gap_between_iac_and_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://atlasgo.io/blog/2023/07/19/bridging-the-gap-between-iac-and-schema-management", "subreddit_subscribers": 116823, "created_utc": 1689776056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, some context - I work in a medium size North American consulting company mostly comprising of civil/mechanical type engineers and an IT team mostly of software engineers and some cybersecurity/devops people. We are a Microsoft shop only, so Azure and Power Platform (relevant info). I am one of those \u201canalyst\u201d fulfilling data analyst/data scientist/data engineer roles for client projects but truly mostly doing data engineering work and I am the only one doing this stuff. Regardless to say, there is no formal recognition of any data-specific role at my company. I\u2019ve never heard \u201cdata engineer\u201d or even \u201cdata scientist\u201d words from my bosses. It\u2019s always me trying to include data type of lingo to plant a seed in their heads that there is a whole data world out there that the company is even doing client projects in but it all becomes \u201dapp development\u201d in managers\u2019 eyes but in reality we are doing things like moving GBs of data (thank god its not in TBs yet) in Azure SQL/blob, processing it with python/R (sometimes Azure Data Factory, if IT approves, who are also new to the data world) , database schemas, and developing PBI dashboards. \n\nAny Azure resource I need I have to explain to my main boss who is a civil engineer (not in IT but does .NET development, doesnt deal with the amount of data processing I have to do) and then that goes to IT. But he only understands Azure (or any cloud for that matter) from the lens of his \u201capp development\u201d work. And without his support IT can\u2019t approve because IT also dont know much abt pipelines/star schema/distributed computing/Spark and all this and there is no dedicated data engineer in IT to understand my pains and even my work\u2026.\n\nAnyways, today I was sharing how I plan to process this new set of files (about 60 GB, so not bad in terms of big data) for a project and this is what my boss said among other things, \u201cKeep the solution simple, avoid Azure if you can. Don\u2019t forget, Azure is really there for client facing apps, not for internal data processing.\u201d\u2026\u2026\u2026\u2026\u2026. bruh\u2026 :( \n\nAnd I have many managers like this who are civil/mechanical engineers doing .Net stuff and think every data pipeline is an \u201capp\u201d, every dashboard is an \u201capp\u201d, all database schemas shd be transactional and so even some IT people start making .NET compiled apps to clean up column names and do basic data transformations and math. And there was a time in the past where I was even being discouraged to use Python because it is not Microsoft. Their push - .NET - to do develop apps? No, to do ETL/statistics and other automating data workflows. Thankfully we are over that phase (I think) and I can use python, thanks to some senior machine learning experts who also use python.\n\nBut yes anyways, I am just so tired I don\u2019t know what to do. I have tried giving presentations on analytical vs transactional data needs, written emails of explaination regarding certain technical decisions of why we need for example Azure Data Factory and not Power Automate/Power Apps/Power \\_\\_\\_ for large/complex data transformation needs (oh yes they are easier on Power platform compared to anything Azure because Power \u201cApps\u201d and because a non data higher up boss who leads the \u201cdigital\u201d practices of our company uses Power platform/share\\[oint for his projects. And it works well for his document processing type work which is fine, but not when you are feeding 500 million rows for a realtime dashboard\u2026). I have explained where our competitors are in terms of their data abilities, I have shared where the world is in terms of data technology and everything but it is becoming growingly taxing to keep trying to convince non-data/software developers of why we need certain data tools/processes for data engineering/data science workflows (yes I m sorry, I group anything data all together for them). \n\nThe company is def not bad in terms of work life balance and they are all nice respectful people and with months and months of convincing sometimes they do approve on using certain data-specific tech but they keep going back\u2026just their lack of understanding of data world and yet their confidence that they know everything has been very tiring\u2026 but after 2 years of this may be I should stop caring and just give up\u2026.\n\nThank you for listening, I just wanted to vent it out since I dont have any friends in the data field. Have a wonderful rest of your week :)\n\n&amp;#x200B;", "author_fullname": "t2_hywcxnb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Struggles - My boss thinks Azure is not for internal data processing needs but only for client facing apps. What to do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1542hgz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689790400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, some context - I work in a medium size North American consulting company mostly comprising of civil/mechanical type engineers and an IT team mostly of software engineers and some cybersecurity/devops people. We are a Microsoft shop only, so Azure and Power Platform (relevant info). I am one of those \u201canalyst\u201d fulfilling data analyst/data scientist/data engineer roles for client projects but truly mostly doing data engineering work and I am the only one doing this stuff. Regardless to say, there is no formal recognition of any data-specific role at my company. I\u2019ve never heard \u201cdata engineer\u201d or even \u201cdata scientist\u201d words from my bosses. It\u2019s always me trying to include data type of lingo to plant a seed in their heads that there is a whole data world out there that the company is even doing client projects in but it all becomes \u201dapp development\u201d in managers\u2019 eyes but in reality we are doing things like moving GBs of data (thank god its not in TBs yet) in Azure SQL/blob, processing it with python/R (sometimes Azure Data Factory, if IT approves, who are also new to the data world) , database schemas, and developing PBI dashboards. &lt;/p&gt;\n\n&lt;p&gt;Any Azure resource I need I have to explain to my main boss who is a civil engineer (not in IT but does .NET development, doesnt deal with the amount of data processing I have to do) and then that goes to IT. But he only understands Azure (or any cloud for that matter) from the lens of his \u201capp development\u201d work. And without his support IT can\u2019t approve because IT also dont know much abt pipelines/star schema/distributed computing/Spark and all this and there is no dedicated data engineer in IT to understand my pains and even my work\u2026.&lt;/p&gt;\n\n&lt;p&gt;Anyways, today I was sharing how I plan to process this new set of files (about 60 GB, so not bad in terms of big data) for a project and this is what my boss said among other things, \u201cKeep the solution simple, avoid Azure if you can. Don\u2019t forget, Azure is really there for client facing apps, not for internal data processing.\u201d\u2026\u2026\u2026\u2026\u2026. bruh\u2026 :( &lt;/p&gt;\n\n&lt;p&gt;And I have many managers like this who are civil/mechanical engineers doing .Net stuff and think every data pipeline is an \u201capp\u201d, every dashboard is an \u201capp\u201d, all database schemas shd be transactional and so even some IT people start making .NET compiled apps to clean up column names and do basic data transformations and math. And there was a time in the past where I was even being discouraged to use Python because it is not Microsoft. Their push - .NET - to do develop apps? No, to do ETL/statistics and other automating data workflows. Thankfully we are over that phase (I think) and I can use python, thanks to some senior machine learning experts who also use python.&lt;/p&gt;\n\n&lt;p&gt;But yes anyways, I am just so tired I don\u2019t know what to do. I have tried giving presentations on analytical vs transactional data needs, written emails of explaination regarding certain technical decisions of why we need for example Azure Data Factory and not Power Automate/Power Apps/Power ___ for large/complex data transformation needs (oh yes they are easier on Power platform compared to anything Azure because Power \u201cApps\u201d and because a non data higher up boss who leads the \u201cdigital\u201d practices of our company uses Power platform/share[oint for his projects. And it works well for his document processing type work which is fine, but not when you are feeding 500 million rows for a realtime dashboard\u2026). I have explained where our competitors are in terms of their data abilities, I have shared where the world is in terms of data technology and everything but it is becoming growingly taxing to keep trying to convince non-data/software developers of why we need certain data tools/processes for data engineering/data science workflows (yes I m sorry, I group anything data all together for them). &lt;/p&gt;\n\n&lt;p&gt;The company is def not bad in terms of work life balance and they are all nice respectful people and with months and months of convincing sometimes they do approve on using certain data-specific tech but they keep going back\u2026just their lack of understanding of data world and yet their confidence that they know everything has been very tiring\u2026 but after 2 years of this may be I should stop caring and just give up\u2026.&lt;/p&gt;\n\n&lt;p&gt;Thank you for listening, I just wanted to vent it out since I dont have any friends in the data field. Have a wonderful rest of your week :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1542hgz", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Role_8051", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1542hgz/data_engineering_struggles_my_boss_thinks_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1542hgz/data_engineering_struggles_my_boss_thinks_azure/", "subreddit_subscribers": 116823, "created_utc": 1689790400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In your opinion - what' s the threshold of diminishing returns as far as postgres/database knowledge goes?\n\nFor context Im currently working as a data engineer and I've ended up doing most of the work on the database (it's a startup...). This is giving me experience with data modelling, schema design, writing methods on the database, performance monitoring and so on. \n\nI'm on the fence as to how useful this experience is, on the one hand I feel it's pretty valuable and can be hard to get  (most people _probably_ wouldn't have wanted me managing their prod db...). On the other - I'm _not_ doing things such as dataflows, pyspark and so on. My python is fairly solid mid level (package publishing, reasonable code/data patterns/structures, testing etc), so I'm not lacking ability to write python - I just haven't been working with cloud / distributed stuff.  \n\nObviously data engineering is a very broad brush - but I'm wondering what sort of database experience / knowledge people typically have here _beyond_ querying effectively and how valuable they feel it is. Do you have experience setting up postgres on a server from scratch, create and test backup&amp;restore, handle load balancing, bastion server etc etc... if not, do you care?\n\nSo - In your opinion - what' s the threshold of diminishing returns as far as postgres/databases goes?  \n\nThanks! :)", "author_fullname": "t2_tczfts4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is database knowledge beyond querying? At what point are returns diminishing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153qe9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689762841.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689760055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In your opinion - what&amp;#39; s the threshold of diminishing returns as far as postgres/database knowledge goes?&lt;/p&gt;\n\n&lt;p&gt;For context Im currently working as a data engineer and I&amp;#39;ve ended up doing most of the work on the database (it&amp;#39;s a startup...). This is giving me experience with data modelling, schema design, writing methods on the database, performance monitoring and so on. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on the fence as to how useful this experience is, on the one hand I feel it&amp;#39;s pretty valuable and can be hard to get  (most people &lt;em&gt;probably&lt;/em&gt; wouldn&amp;#39;t have wanted me managing their prod db...). On the other - I&amp;#39;m &lt;em&gt;not&lt;/em&gt; doing things such as dataflows, pyspark and so on. My python is fairly solid mid level (package publishing, reasonable code/data patterns/structures, testing etc), so I&amp;#39;m not lacking ability to write python - I just haven&amp;#39;t been working with cloud / distributed stuff.  &lt;/p&gt;\n\n&lt;p&gt;Obviously data engineering is a very broad brush - but I&amp;#39;m wondering what sort of database experience / knowledge people typically have here &lt;em&gt;beyond&lt;/em&gt; querying effectively and how valuable they feel it is. Do you have experience setting up postgres on a server from scratch, create and test backup&amp;amp;restore, handle load balancing, bastion server etc etc... if not, do you care?&lt;/p&gt;\n\n&lt;p&gt;So - In your opinion - what&amp;#39; s the threshold of diminishing returns as far as postgres/databases goes?  &lt;/p&gt;\n\n&lt;p&gt;Thanks! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "153qe9h", "is_robot_indexable": true, "report_reasons": null, "author": "Subject_Fix2471", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153qe9h/how_important_is_database_knowledge_beyond/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153qe9h/how_important_is_database_knowledge_beyond/", "subreddit_subscribers": 116823, "created_utc": 1689760055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been at my new company for about 4 months.  I have 2 years of CRUD backend experience and I was hired to replace a senior DE (but not as a senior myself) on a data warehouse team.  This engineer managed a few python applications and Spark + API ingestion processes for the DE team.  \n\nI am hired and first tasked to put these codebases in github, setup CI/CD processes, and help upskill the team in development of this side of our data stack.  It turns out the previous dev just did all of his development on production directly with no testing processes or documentation.  Okay, no big deal.  I'm able to get the code into our remote repos, build CI/CD pipeline with Jenkins (with the help of an adjacent devops team), and overall get the codebase updated to a more mature standing.  I've also worked with the devops team to build out docker images for each of the applications we manage so that we can have proper development environments. Now we have visibility, proper practices in place, and it's starting to look like actual engineering.\n\nNow comes the part where everything starts crashing down.  Since we have a more organized development practices, our new manager starts assigning tasks within these platforms to other engineers.  I come to find out that the senior engineer I replaced was the only data engineer who had touched these processes within the last year.  I also learn that none of the other DE's (including 4 senior DE's) have any experience with programming outside of SQL.  \n\nHere's a list of some of the issues I've run into:  \nEngineer wants me to give him prod access so he can do his development there instead of locally.\n\nSenior engineers don't know how to navigate a CLI.\n\nEngineers have no idea how to use git, and I am there personal git encyclopedia.\n\nEngineers breaking stuff with a git GUI, requiring me to fix it.\n\nEngineers pushing back on git usage entirely.\n\nSenior engineer with 12 years at the company does not know what a for-loop is.\n\nComplaints about me requiring unit testing and some form of documentation that the code works before pushing to production.\n\nSome engineers simply cannot comprehend how Docker works, and want my help to configure their windows laptop into a development environment (I am not helping you stand up a Postgres instance directly on your Windows OS).\n\nI am at my wits end.  I've essentially been designated as a mentor for the side of the DE house that I work in.  That's fine, but I was not hired as a senior, and it is really demotivating mentoring the people who I thought should be mentoring me.  I really do want to see the team succeed, but there has been so much pushback on following best-practices and learning new skills.  Is this common in the DE field?\n\n&amp;#x200B;", "author_fullname": "t2_4rifsjav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal for data engineers to be lacking basic technical skills?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1549emd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689806565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been at my new company for about 4 months.  I have 2 years of CRUD backend experience and I was hired to replace a senior DE (but not as a senior myself) on a data warehouse team.  This engineer managed a few python applications and Spark + API ingestion processes for the DE team.  &lt;/p&gt;\n\n&lt;p&gt;I am hired and first tasked to put these codebases in github, setup CI/CD processes, and help upskill the team in development of this side of our data stack.  It turns out the previous dev just did all of his development on production directly with no testing processes or documentation.  Okay, no big deal.  I&amp;#39;m able to get the code into our remote repos, build CI/CD pipeline with Jenkins (with the help of an adjacent devops team), and overall get the codebase updated to a more mature standing.  I&amp;#39;ve also worked with the devops team to build out docker images for each of the applications we manage so that we can have proper development environments. Now we have visibility, proper practices in place, and it&amp;#39;s starting to look like actual engineering.&lt;/p&gt;\n\n&lt;p&gt;Now comes the part where everything starts crashing down.  Since we have a more organized development practices, our new manager starts assigning tasks within these platforms to other engineers.  I come to find out that the senior engineer I replaced was the only data engineer who had touched these processes within the last year.  I also learn that none of the other DE&amp;#39;s (including 4 senior DE&amp;#39;s) have any experience with programming outside of SQL.  &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a list of some of the issues I&amp;#39;ve run into:&lt;br/&gt;\nEngineer wants me to give him prod access so he can do his development there instead of locally.&lt;/p&gt;\n\n&lt;p&gt;Senior engineers don&amp;#39;t know how to navigate a CLI.&lt;/p&gt;\n\n&lt;p&gt;Engineers have no idea how to use git, and I am there personal git encyclopedia.&lt;/p&gt;\n\n&lt;p&gt;Engineers breaking stuff with a git GUI, requiring me to fix it.&lt;/p&gt;\n\n&lt;p&gt;Engineers pushing back on git usage entirely.&lt;/p&gt;\n\n&lt;p&gt;Senior engineer with 12 years at the company does not know what a for-loop is.&lt;/p&gt;\n\n&lt;p&gt;Complaints about me requiring unit testing and some form of documentation that the code works before pushing to production.&lt;/p&gt;\n\n&lt;p&gt;Some engineers simply cannot comprehend how Docker works, and want my help to configure their windows laptop into a development environment (I am not helping you stand up a Postgres instance directly on your Windows OS).&lt;/p&gt;\n\n&lt;p&gt;I am at my wits end.  I&amp;#39;ve essentially been designated as a mentor for the side of the DE house that I work in.  That&amp;#39;s fine, but I was not hired as a senior, and it is really demotivating mentoring the people who I thought should be mentoring me.  I really do want to see the team succeed, but there has been so much pushback on following best-practices and learning new skills.  Is this common in the DE field?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1549emd", "is_robot_indexable": true, "report_reasons": null, "author": "Techthrowaway2222888", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1549emd/is_it_normal_for_data_engineers_to_be_lacking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1549emd/is_it_normal_for_data_engineers_to_be_lacking/", "subreddit_subscribers": 116823, "created_utc": 1689806565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I have good python skills, know swl good, have good knowledge of sql too. I wanted to ask where should I head next? I have done some internships too. Currently reading Data Warehousing Toolkit book to know about dimensional modeling etc. Any suggestions where should I head or if I am missing something? Thanks in advance", "author_fullname": "t2_afom76hbi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning data warehousing. Where to start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1542uyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689791269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I have good python skills, know swl good, have good knowledge of sql too. I wanted to ask where should I head next? I have done some internships too. Currently reading Data Warehousing Toolkit book to know about dimensional modeling etc. Any suggestions where should I head or if I am missing something? Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1542uyq", "is_robot_indexable": true, "report_reasons": null, "author": "Unusual-Entry7", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1542uyq/learning_data_warehousing_where_to_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1542uyq/learning_data_warehousing_where_to_start/", "subreddit_subscribers": 116823, "created_utc": 1689791269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to understand how to think about and architect the schema (ddl) and data migration strategy for some fairly complex data pipelines in databricks. i\u2019m really puzzled because i\u2019m coming from an applications (backend) background, largely with postgres/mysql. so for these, database migration is pretty mature and used everywhere. but when i search this up for delta lake/databricks, there\u2019s basically nothing. \n\nso maybe i\u2019m just not thinking about this in the data engineering way, or maybe there\u2019s some other terms i need to be using? how should i think about supporting structured, version-controlled changes to the table structures and the data they contain? \n\nam i way out of line to be thinking of implementing sqlalchemy alembic for delta lake? is there _any_ tool or even just discussion of how this is done? \n\ni can\u2019t possibly be the first person to have this this thought, but when i asked my databricks rep, i spent half an hour trying to explain what a schema migration even was, so clearly there\u2019s a disconnect somewhere.", "author_fullname": "t2_flpxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Schema Migration for Delta Lake on Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153xtyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689779717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to understand how to think about and architect the schema (ddl) and data migration strategy for some fairly complex data pipelines in databricks. i\u2019m really puzzled because i\u2019m coming from an applications (backend) background, largely with postgres/mysql. so for these, database migration is pretty mature and used everywhere. but when i search this up for delta lake/databricks, there\u2019s basically nothing. &lt;/p&gt;\n\n&lt;p&gt;so maybe i\u2019m just not thinking about this in the data engineering way, or maybe there\u2019s some other terms i need to be using? how should i think about supporting structured, version-controlled changes to the table structures and the data they contain? &lt;/p&gt;\n\n&lt;p&gt;am i way out of line to be thinking of implementing sqlalchemy alembic for delta lake? is there &lt;em&gt;any&lt;/em&gt; tool or even just discussion of how this is done? &lt;/p&gt;\n\n&lt;p&gt;i can\u2019t possibly be the first person to have this this thought, but when i asked my databricks rep, i spent half an hour trying to explain what a schema migration even was, so clearly there\u2019s a disconnect somewhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "153xtyq", "is_robot_indexable": true, "report_reasons": null, "author": "geeeffwhy", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153xtyq/schema_migration_for_delta_lake_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153xtyq/schema_migration_for_delta_lake_on_databricks/", "subreddit_subscribers": 116823, "created_utc": 1689779717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've done 3 different personal projects this month, and each one I run into thousands of problems with AWS, Azure, or GCP. I'm not trying to be a DevOps person but with how many cloud issues I've resolved, maybe I should be. Does anyone else feel these limitations? I just wanna get to the point on projects where I can utilize my SQL or Python without wading through 4 hours of cloud initialization\n\nIt feels like on all these projects, I spend 95% of the time working out issues with the cloud development and getting that running, and 5% on the actual transformations and orchestrations between the services once they're running.", "author_fullname": "t2_l3oy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does Data Engineering ever stop running into issues with the cloud service provider?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153i3me", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689734057.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689733696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve done 3 different personal projects this month, and each one I run into thousands of problems with AWS, Azure, or GCP. I&amp;#39;m not trying to be a DevOps person but with how many cloud issues I&amp;#39;ve resolved, maybe I should be. Does anyone else feel these limitations? I just wanna get to the point on projects where I can utilize my SQL or Python without wading through 4 hours of cloud initialization&lt;/p&gt;\n\n&lt;p&gt;It feels like on all these projects, I spend 95% of the time working out issues with the cloud development and getting that running, and 5% on the actual transformations and orchestrations between the services once they&amp;#39;re running.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "153i3me", "is_robot_indexable": true, "report_reasons": null, "author": "LeftShark", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153i3me/does_data_engineering_ever_stop_running_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153i3me/does_data_engineering_ever_stop_running_into/", "subreddit_subscribers": 116823, "created_utc": 1689733696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nMy (quant) teammate (Data Visualization Specialist) is working with a couple of proficient Data Engineers and a DBA. We're in the middle of transitioning from a solely SQL Server and Power BI environment to incorporating Azure Data Factory (for data ingestion), Data Bricks (for storage and transformation), and maintaining Power BI for self-service reporting. The data sources are scattered, and the data literacy is in the basement. \"We're pretty much burning it to the ground and starting over\" as my teammate (DE) puts it.\n\nAs we gear up for this bonfire, a few critical **questions pertaining to best practices** are surfacing, particularly surrounding the housing and management of our data models. I am hoping to tap into this community's wisdom and gain some insights into the following:\n\n1. **Location of Data Models:** What is the best practice in terms of where to place our data models? Is Azure Analysis Services (AAS) a feasible choice to hold enterprise-grade data models in the cloud, or should we lean towards Power BI's built-in datasets?\n2. **Exposing Data Models to Users:** What are the most effective ways to expose our data models to the business users who need them? We plan to leverage Power BI's roles and permissions features but are there other recommended strategies? We've set up security groups and spoken about the level of access during each stage prior to publishing.\n3. **Model Complexity and Size:** How can we accommodate larger datasets in the future, considering the model size limitations in Power BI? Does Azure Analysis Services or another platform provide a better solution for larger data models?\n\nOur goal is to provide each business group a dedicated PBI Workspace (in addition to the default individual workspaces). As expected, all reporting that comes out of these distributed development spaces will go through a pipeline from Development to Testing to Production, overseen by the Data Team before reaching the production space. \n\nThis business has grown by 400% in the last 5 years and has no real experience with proper data governance or infrastructure. Thankfully, we don't have a ton of data, only about 400GB. Help has arrived, but your insights and experiences regarding these questions would be greatly appreciated and would go a long way in helping us make informed decisions quickly (obviously we'll research and validate any advice given).\n\nLastly, if it isn't apparent, I'm unfamiliar with many of these matters (fortunately not as unfamiliar as most of our users), so please be as explicit as is convenient. Thank you in advance for your help, and I look forward to reading your responses.", "author_fullname": "t2_c9t8mf2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Infrastructure/Modeling Questions about Best Practices.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153z4uf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689782654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My (quant) teammate (Data Visualization Specialist) is working with a couple of proficient Data Engineers and a DBA. We&amp;#39;re in the middle of transitioning from a solely SQL Server and Power BI environment to incorporating Azure Data Factory (for data ingestion), Data Bricks (for storage and transformation), and maintaining Power BI for self-service reporting. The data sources are scattered, and the data literacy is in the basement. &amp;quot;We&amp;#39;re pretty much burning it to the ground and starting over&amp;quot; as my teammate (DE) puts it.&lt;/p&gt;\n\n&lt;p&gt;As we gear up for this bonfire, a few critical &lt;strong&gt;questions pertaining to best practices&lt;/strong&gt; are surfacing, particularly surrounding the housing and management of our data models. I am hoping to tap into this community&amp;#39;s wisdom and gain some insights into the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Location of Data Models:&lt;/strong&gt; What is the best practice in terms of where to place our data models? Is Azure Analysis Services (AAS) a feasible choice to hold enterprise-grade data models in the cloud, or should we lean towards Power BI&amp;#39;s built-in datasets?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Exposing Data Models to Users:&lt;/strong&gt; What are the most effective ways to expose our data models to the business users who need them? We plan to leverage Power BI&amp;#39;s roles and permissions features but are there other recommended strategies? We&amp;#39;ve set up security groups and spoken about the level of access during each stage prior to publishing.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Model Complexity and Size:&lt;/strong&gt; How can we accommodate larger datasets in the future, considering the model size limitations in Power BI? Does Azure Analysis Services or another platform provide a better solution for larger data models?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Our goal is to provide each business group a dedicated PBI Workspace (in addition to the default individual workspaces). As expected, all reporting that comes out of these distributed development spaces will go through a pipeline from Development to Testing to Production, overseen by the Data Team before reaching the production space. &lt;/p&gt;\n\n&lt;p&gt;This business has grown by 400% in the last 5 years and has no real experience with proper data governance or infrastructure. Thankfully, we don&amp;#39;t have a ton of data, only about 400GB. Help has arrived, but your insights and experiences regarding these questions would be greatly appreciated and would go a long way in helping us make informed decisions quickly (obviously we&amp;#39;ll research and validate any advice given).&lt;/p&gt;\n\n&lt;p&gt;Lastly, if it isn&amp;#39;t apparent, I&amp;#39;m unfamiliar with many of these matters (fortunately not as unfamiliar as most of our users), so please be as explicit as is convenient. Thank you in advance for your help, and I look forward to reading your responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "153z4uf", "is_robot_indexable": true, "report_reasons": null, "author": "GreenMellowphant", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153z4uf/infrastructuremodeling_questions_about_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153z4uf/infrastructuremodeling_questions_about_best/", "subreddit_subscribers": 116823, "created_utc": 1689782654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jboiz9k4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time Data Processing Pipeline With MongoDB, Kafka, Debezium And RisingWave", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_153m5jl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZN9e_WGYPBu8pHZr_Al8mfSxgeTvcLoaEBQ2sBh01xY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689745793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "boburadvocate.hashnode.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://boburadvocate.hashnode.dev/real-time-data-processing-pipeline-with-mongodb-kafka-debezium-and-risingwave", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/x7HeQHn6QdCHHO1_E2YIvoYd5vCGzdIuMi7dLA4bYVI.jpg?auto=webp&amp;s=d638cff8e9a623eeded7fc57f19d0114edef5e72", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/x7HeQHn6QdCHHO1_E2YIvoYd5vCGzdIuMi7dLA4bYVI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=103ee0c9d51930d798e8e2cf41ebadc311ea08f7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/x7HeQHn6QdCHHO1_E2YIvoYd5vCGzdIuMi7dLA4bYVI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a567d5f2f41e47494f2d35a8581843219910c62a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/x7HeQHn6QdCHHO1_E2YIvoYd5vCGzdIuMi7dLA4bYVI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=082f778886e3d01ad234fa144e05344c2ee67ef0", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/x7HeQHn6QdCHHO1_E2YIvoYd5vCGzdIuMi7dLA4bYVI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f6a6facecb4118d42af2f91fd15d306d2aaa5088", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/x7HeQHn6QdCHHO1_E2YIvoYd5vCGzdIuMi7dLA4bYVI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=eecadc0b4a26d7f0a2faa3cd1f2d98dbfecd5cc9", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/x7HeQHn6QdCHHO1_E2YIvoYd5vCGzdIuMi7dLA4bYVI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4f3e8e3e746d4530490228d21b8c84792e0cb115", "width": 1080, "height": 567}], "variants": {}, "id": "dyHGhC0uRgESlyQnmZZhi1OWOiKJBYUTlj8UbWtRiwk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "153m5jl", "is_robot_indexable": true, "report_reasons": null, "author": "bumurzokov", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153m5jl/realtime_data_processing_pipeline_with_mongodb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://boburadvocate.hashnode.dev/real-time-data-processing-pipeline-with-mongodb-kafka-debezium-and-risingwave", "subreddit_subscribers": 116823, "created_utc": 1689745793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,\n\nI am a recent graduate with a passion for working in the field of data engineering. After earning a Master's degree in Data Analytics Engineering and a Bachelor's in Management in Information Systems, I've managed to gain experience and develop key skills in this domain.\n\nMy proficiency lies in designing scalable data solutions, optimizing data infrastructure and pipelines, and managing large datasets. I am proficient in Python, R, SQL, C++, and Java, and have considerable experience with big data technologies such as Apache Spark, Apache Hadoop, Kafka, PySpark, and Snowflake. I've gained a good understanding of cloud tech involving AWS, DB2, and Oracle SQL. \n\nOver the past few years, I have held positions (as an intern) Senior backend developer in a renowned tech company and as a data engineer at a startup. My roles included developing real-time data ingestion pipelines, managing data warehouses, optimizing SQL queries, integrating RESTful APIs into database solutions, and ensuring data integrity, security, and compliance across all operations.\n\nDespite my experience, navigating the job search post-graduation has proven to be quite a challenge. I am reaching out to this community seeking advice:\n\n* What companies should a fresh graduate in data engineering consider for a good start?\n* Do you have any suggestions on how to stand out among a pool of candidates?\n* How do I strategize my job search? - Up until now, I've usually relied on LinkedIn, so should I broaden my search to other Job Portals?   \n\n\nI sincerely appreciate any advice or insights this community can offer. Here's to a shared passion for data engineering and the exciting journey it entails!\n\nBest Regards,   \nA Passionate Data Engineer", "author_fullname": "t2_5u73tpsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice: Navigating the Field of Data Engineering after the completion of my Master's Degree", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153ds3e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689722224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a recent graduate with a passion for working in the field of data engineering. After earning a Master&amp;#39;s degree in Data Analytics Engineering and a Bachelor&amp;#39;s in Management in Information Systems, I&amp;#39;ve managed to gain experience and develop key skills in this domain.&lt;/p&gt;\n\n&lt;p&gt;My proficiency lies in designing scalable data solutions, optimizing data infrastructure and pipelines, and managing large datasets. I am proficient in Python, R, SQL, C++, and Java, and have considerable experience with big data technologies such as Apache Spark, Apache Hadoop, Kafka, PySpark, and Snowflake. I&amp;#39;ve gained a good understanding of cloud tech involving AWS, DB2, and Oracle SQL. &lt;/p&gt;\n\n&lt;p&gt;Over the past few years, I have held positions (as an intern) Senior backend developer in a renowned tech company and as a data engineer at a startup. My roles included developing real-time data ingestion pipelines, managing data warehouses, optimizing SQL queries, integrating RESTful APIs into database solutions, and ensuring data integrity, security, and compliance across all operations.&lt;/p&gt;\n\n&lt;p&gt;Despite my experience, navigating the job search post-graduation has proven to be quite a challenge. I am reaching out to this community seeking advice:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What companies should a fresh graduate in data engineering consider for a good start?&lt;/li&gt;\n&lt;li&gt;Do you have any suggestions on how to stand out among a pool of candidates?&lt;/li&gt;\n&lt;li&gt;How do I strategize my job search? - Up until now, I&amp;#39;ve usually relied on LinkedIn, so should I broaden my search to other Job Portals?&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I sincerely appreciate any advice or insights this community can offer. Here&amp;#39;s to a shared passion for data engineering and the exciting journey it entails!&lt;/p&gt;\n\n&lt;p&gt;Best Regards,&lt;br/&gt;\nA Passionate Data Engineer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "153ds3e", "is_robot_indexable": true, "report_reasons": null, "author": "arcofiero", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153ds3e/seeking_advice_navigating_the_field_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153ds3e/seeking_advice_navigating_the_field_of_data/", "subreddit_subscribers": 116823, "created_utc": 1689722224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, is there a way to identify which all tables are being used or queried frequently in databricks.\nNote: no access to unity catalogue.", "author_fullname": "t2_f1s7yw3kw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to identify which all tables are used/queried frequently in databricks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1540pec", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689786252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, is there a way to identify which all tables are being used or queried frequently in databricks.\nNote: no access to unity catalogue.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1540pec", "is_robot_indexable": true, "report_reasons": null, "author": "fusebox12345", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1540pec/how_to_identify_which_all_tables_are_usedqueried/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1540pec/how_to_identify_which_all_tables_are_usedqueried/", "subreddit_subscribers": 116823, "created_utc": 1689786252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we have a data lake on AWS, data goes with its original format (or csv if extracted from a ddbb) into the landing zone, then gets converted into parquet and carried through the next zones.\n\nThe DA at my team came up with this idea of creating a reference table that would work as an index.\n\nSo for example, given a users table, create a reference table with only the id and the relevant timestamp column (for eg.: created\\_at, updated\\_at), add some fields like 'valid\\_from', 'valid\\_to' and 'is\\_current\\_row' and then join this reference table with the main one.On the next executions, the new records should be inserted into the main table and then, both the main and the reference tables should update values for 'valid\\*' and 'is\\_current\\_row'.\n\nSo the purpose of this is to use the index table for speeding up some queries since it holds less columns, and also be able to tell in which point in time the row was inserted/updated.\n\nFinally, all this data will be loaded into redshift.\n\nMy questions are, is this index table necessary since parquet is columnar and supports page-level indexes? Wouldn't be more convenient to use apache iceberg for handling the 'time travel'? It also provides more features like compacting files that otherwise would have to be done with sepparate script.\n\n&amp;#x200B;\n\nEdit: so i got a metting with the DA. She stated that the reason parquet would be less performant than using the index table (***id where current\\_row = true*** to get the max date value, and then use that value to load the corresponding partition) is more efficient than relying on parquet looking through metadata for each partition and checking the values until you find the current\\_row = true, since it will lead to multiple reads that will result in the current\\_row being false, until it finds the true one. So even though it will skip row groups, it will have many false positives. Is this correct? The only way to figure it out is by testing it, or are there some good practices i'm not following? ", "author_fullname": "t2_dpj60sgl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Create index (reference) table for parquet tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153zndo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689789345.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689783825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we have a data lake on AWS, data goes with its original format (or csv if extracted from a ddbb) into the landing zone, then gets converted into parquet and carried through the next zones.&lt;/p&gt;\n\n&lt;p&gt;The DA at my team came up with this idea of creating a reference table that would work as an index.&lt;/p&gt;\n\n&lt;p&gt;So for example, given a users table, create a reference table with only the id and the relevant timestamp column (for eg.: created_at, updated_at), add some fields like &amp;#39;valid_from&amp;#39;, &amp;#39;valid_to&amp;#39; and &amp;#39;is_current_row&amp;#39; and then join this reference table with the main one.On the next executions, the new records should be inserted into the main table and then, both the main and the reference tables should update values for &amp;#39;valid*&amp;#39; and &amp;#39;is_current_row&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;So the purpose of this is to use the index table for speeding up some queries since it holds less columns, and also be able to tell in which point in time the row was inserted/updated.&lt;/p&gt;\n\n&lt;p&gt;Finally, all this data will be loaded into redshift.&lt;/p&gt;\n\n&lt;p&gt;My questions are, is this index table necessary since parquet is columnar and supports page-level indexes? Wouldn&amp;#39;t be more convenient to use apache iceberg for handling the &amp;#39;time travel&amp;#39;? It also provides more features like compacting files that otherwise would have to be done with sepparate script.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: so i got a metting with the DA. She stated that the reason parquet would be less performant than using the index table (&lt;strong&gt;&lt;em&gt;id where current_row = true&lt;/em&gt;&lt;/strong&gt; to get the max date value, and then use that value to load the corresponding partition) is more efficient than relying on parquet looking through metadata for each partition and checking the values until you find the current_row = true, since it will lead to multiple reads that will result in the current_row being false, until it finds the true one. So even though it will skip row groups, it will have many false positives. Is this correct? The only way to figure it out is by testing it, or are there some good practices i&amp;#39;m not following? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "153zndo", "is_robot_indexable": true, "report_reasons": null, "author": "_unwin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153zndo/create_index_reference_table_for_parquet_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153zndo/create_index_reference_table_for_parquet_tables/", "subreddit_subscribers": 116823, "created_utc": 1689783825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work as a Data Engineer with 5 months experience in AWS. I have proficient knowledge in Python and SQL.\n\nI want to take the exam to learn about Microsoft Azure and all cloud related topics in Data Engineering.  I have never used Microsoft Azure and have no idea even where to start to learn. I am familiar with some of AWS tools like Glue, Athena, S3, Lamda, EC2. \n\nI am planning to take a week off work to revise and 2 hours a day for another week. \n\nMy question is,\n\n1. Can I pass this exam by learning from [Azure Data Engineer Associate](https://learn.microsoft.com/en-us/certifications/azure-data-engineer/?tab=tab-learning-paths#certification-exams)\n2. Is there any other website that can help prepare me for the exam. \n3. Is there a course or free learning that I can follow with hands on experience. ( I am guessing Azure has a free trial like AWS but I would need a guide to help me through) \n\nThanks  ", "author_fullname": "t2_e793a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing Advice for DP-203: Data Engineering on Microsoft Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153va24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689773784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work as a Data Engineer with 5 months experience in AWS. I have proficient knowledge in Python and SQL.&lt;/p&gt;\n\n&lt;p&gt;I want to take the exam to learn about Microsoft Azure and all cloud related topics in Data Engineering.  I have never used Microsoft Azure and have no idea even where to start to learn. I am familiar with some of AWS tools like Glue, Athena, S3, Lamda, EC2. &lt;/p&gt;\n\n&lt;p&gt;I am planning to take a week off work to revise and 2 hours a day for another week. &lt;/p&gt;\n\n&lt;p&gt;My question is,&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can I pass this exam by learning from &lt;a href=\"https://learn.microsoft.com/en-us/certifications/azure-data-engineer/?tab=tab-learning-paths#certification-exams\"&gt;Azure Data Engineer Associate&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Is there any other website that can help prepare me for the exam. &lt;/li&gt;\n&lt;li&gt;Is there a course or free learning that I can follow with hands on experience. ( I am guessing Azure has a free trial like AWS but I would need a guide to help me through) &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?auto=webp&amp;s=e62264227377a9581e2e2946169864d130fa3217", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b9526a51504048891d5e64783519fd5dc3cd83f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0150bc3ab1c6838c35ff951d69578f3d19ae4ed3", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1e830770227ae4802c5776d22f63d0f6aa71b15", "width": 320, "height": 320}], "variants": {}, "id": "LVmzWMJU1UZwRubzQYJZSar-z-Rq8ntUH65yhQyfxB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "153va24", "is_robot_indexable": true, "report_reasons": null, "author": "keyboard1ish", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153va24/preparing_advice_for_dp203_data_engineering_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153va24/preparing_advice_for_dp203_data_engineering_on/", "subreddit_subscribers": 116823, "created_utc": 1689773784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Started researching these open source data warehouses. One thing I'm confused about is, if using this type of tech, where do you do your transformation jobs? If I have a bunch of csv or parquet files in blob storage, if I load them into Doris/Starrocks, does it support transformation or should your data be cleaned and ready to go before loading it in these types of warehouses?  \n\nIf you're using either of these, what's your overall architecture look like?", "author_fullname": "t2_ffzuzn1vk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris/Starrocks Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153u367", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689770815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Started researching these open source data warehouses. One thing I&amp;#39;m confused about is, if using this type of tech, where do you do your transformation jobs? If I have a bunch of csv or parquet files in blob storage, if I load them into Doris/Starrocks, does it support transformation or should your data be cleaned and ready to go before loading it in these types of warehouses?  &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re using either of these, what&amp;#39;s your overall architecture look like?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "153u367", "is_robot_indexable": true, "report_reasons": null, "author": "Public_Fart42069", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153u367/apache_dorisstarrocks_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153u367/apache_dorisstarrocks_architecture/", "subreddit_subscribers": 116823, "created_utc": 1689770815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@stefentaime\\_10958/free-real-time-flight-status-pipeline-with-kafka-schemas-registry-avro-graphql-postgres-and-7ac59b63ea99](https://medium.com/@stefentaime_10958/free-real-time-flight-status-pipeline-with-kafka-schemas-registry-avro-graphql-postgres-and-7ac59b63ea99)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6v00mbnrducb1.png?width=1767&amp;format=png&amp;auto=webp&amp;s=45eff0b11287df6931a7b80c55859fa36b6ebc32", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free, Real-time Flight Status Pipeline with Kafka, Schemas Registry, Avro, GraphQL, Postgres, and React", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6v00mbnrducb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 44, "x": 108, "u": "https://preview.redd.it/6v00mbnrducb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=48b75a26e27698c23629f4c331f41b18e5221dda"}, {"y": 88, "x": 216, "u": "https://preview.redd.it/6v00mbnrducb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bc33223e13af1236b2570a36269c9dbf1fa7244a"}, {"y": 130, "x": 320, "u": "https://preview.redd.it/6v00mbnrducb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b54f75689e6c391d97c91b5448745e16f4741cf"}, {"y": 260, "x": 640, "u": "https://preview.redd.it/6v00mbnrducb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2ca137508497c723631431140446b24c86a08292"}, {"y": 391, "x": 960, "u": "https://preview.redd.it/6v00mbnrducb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d8364010d42d672089bc2fa3db15ee03250a99f4"}, {"y": 440, "x": 1080, "u": "https://preview.redd.it/6v00mbnrducb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e9be6389be23461dd7e11400e7be3a3b89ee4259"}], "s": {"y": 720, "x": 1767, "u": "https://preview.redd.it/6v00mbnrducb1.png?width=1767&amp;format=png&amp;auto=webp&amp;s=45eff0b11287df6931a7b80c55859fa36b6ebc32"}, "id": "6v00mbnrducb1"}}, "name": "t3_153jimw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/hYWnhj_sQpmown0aaFyYZbrqFFxLmlQ820Oz5GeLke8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1689737731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/free-real-time-flight-status-pipeline-with-kafka-schemas-registry-avro-graphql-postgres-and-7ac59b63ea99\"&gt;https://medium.com/@stefentaime_10958/free-real-time-flight-status-pipeline-with-kafka-schemas-registry-avro-graphql-postgres-and-7ac59b63ea99&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6v00mbnrducb1.png?width=1767&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=45eff0b11287df6931a7b80c55859fa36b6ebc32\"&gt;https://preview.redd.it/6v00mbnrducb1.png?width=1767&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=45eff0b11287df6931a7b80c55859fa36b6ebc32&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vljW1tlHbHwl74xdLalcCzjCf846TAfkQpKL0CkdrwA.jpg?auto=webp&amp;s=66627349895c28e6634d65d75fcfd42fd49486a6", "width": 1200, "height": 565}, "resolutions": [{"url": "https://external-preview.redd.it/vljW1tlHbHwl74xdLalcCzjCf846TAfkQpKL0CkdrwA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4555d40ee64100ccf805363527d7f5197955c25d", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/vljW1tlHbHwl74xdLalcCzjCf846TAfkQpKL0CkdrwA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b7e35b71ac63cddd0e2e77a4072c02201fc91b9b", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/vljW1tlHbHwl74xdLalcCzjCf846TAfkQpKL0CkdrwA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d7d0b8bc4a2545e39bc3039a5a0eaf1804a9820", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/vljW1tlHbHwl74xdLalcCzjCf846TAfkQpKL0CkdrwA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=22f7045baaa0f3976656490469811f482d7d5086", "width": 640, "height": 301}, {"url": "https://external-preview.redd.it/vljW1tlHbHwl74xdLalcCzjCf846TAfkQpKL0CkdrwA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc09743ab46d3a08537c8aac34aa665a82b9c4fa", "width": 960, "height": 452}, {"url": "https://external-preview.redd.it/vljW1tlHbHwl74xdLalcCzjCf846TAfkQpKL0CkdrwA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=abbc3e35dc236fe4369afb034cf5cef24ce31396", "width": 1080, "height": 508}], "variants": {}, "id": "-X-TpCor12_5vrjoVNLpOgJN1TPsQ4em-wmUcKvTC6g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "153jimw", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153jimw/free_realtime_flight_status_pipeline_with_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153jimw/free_realtime_flight_status_pipeline_with_kafka/", "subreddit_subscribers": 116823, "created_utc": 1689737731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious how often other engineers see any results of the effort and money sunk into your or your customer\u2019s company in the developing of their data estate. Pipelines are built, infrastructure stood up, dev ops incorporated, warehousing, reports, etc\u2026.what is the benefit? I love engineering but sometimes I feel bad for the those flipping the bill. There is this idea(on every major data products website) that there will be n-zettabytes of data worldwide by 202X and we can unlock all \u201cthis\u201d insight from the data, etc., etc. How often is a tangible report delivered that actually produces insight or generates ROI? I see very basic deliverables, but rarely a payoff that equates to the amount of resources sunk into the endeavor.", "author_fullname": "t2_74fehzbh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a ROI for the data engineering endeavor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153ioma", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689735343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious how often other engineers see any results of the effort and money sunk into your or your customer\u2019s company in the developing of their data estate. Pipelines are built, infrastructure stood up, dev ops incorporated, warehousing, reports, etc\u2026.what is the benefit? I love engineering but sometimes I feel bad for the those flipping the bill. There is this idea(on every major data products website) that there will be n-zettabytes of data worldwide by 202X and we can unlock all \u201cthis\u201d insight from the data, etc., etc. How often is a tangible report delivered that actually produces insight or generates ROI? I see very basic deliverables, but rarely a payoff that equates to the amount of resources sunk into the endeavor.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "153ioma", "is_robot_indexable": true, "report_reasons": null, "author": "afivegallonbucket", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/153ioma/is_there_a_roi_for_the_data_engineering_endeavor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/153ioma/is_there_a_roi_for_the_data_engineering_endeavor/", "subreddit_subscribers": 116823, "created_utc": 1689735343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking to start applying for my first DE job. I was thinking about making a portfolio website, but then I wasn\u2019t sure if it would be a good idea to delay job applying because of that. I\u2019m not from CS/data background, so I felt like I\u2019d really have to present my projects well, including the web development skills by building a portfolio web, in order to pass the interview screenings. I will eventually make one in the future, but since I want to get out of my current job so bad and since it is not a remote, I\u2019m leaning towards not making one right now. \nAnd also, how important is LinkedIn when searching for jobs? My current LI acc is restricted for some reason, and it\u2019s taking forever for them to resolve it..(apparently many people are experiencing this issue)\n\nThanks for any advice.", "author_fullname": "t2_luzwqwgm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is GitHub enough to show projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1548nku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689804746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to start applying for my first DE job. I was thinking about making a portfolio website, but then I wasn\u2019t sure if it would be a good idea to delay job applying because of that. I\u2019m not from CS/data background, so I felt like I\u2019d really have to present my projects well, including the web development skills by building a portfolio web, in order to pass the interview screenings. I will eventually make one in the future, but since I want to get out of my current job so bad and since it is not a remote, I\u2019m leaning towards not making one right now. \nAnd also, how important is LinkedIn when searching for jobs? My current LI acc is restricted for some reason, and it\u2019s taking forever for them to resolve it..(apparently many people are experiencing this issue)&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1548nku", "is_robot_indexable": true, "report_reasons": null, "author": "Neat_Historian9740", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1548nku/is_github_enough_to_show_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1548nku/is_github_enough_to_show_projects/", "subreddit_subscribers": 116823, "created_utc": 1689804746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHello there,\n\nPosted this on the Github subreddit without much response and I feel this somewhat more tailored towards this sub anyway.\n\nI work for a fairly large company that already uses GH, however the team I work with and others surrounding it do not (I am fairly new and the teams never bothered with it I guess)! Our manager wants us to start utilizing GH.\n\nDoes anyone have any tips/suggestions about where to start and which/what features are super helpful to teams? Anything like a checklist of \"must-haves\"?\n\nSome things to note - we are primarily backend devs/data engineers/data scientists. The overwhelming majority of our code is in T-SQL or Python/Jupyter. We also have A LOT of SSIS packages and some things in Databricks.\n\nI have a couple years experience working with it (creating/submitting PR's, squashing, basic things).\n\nSome early questions I have been trying to answer is if Code Spaces or Actions would be useful - how are your experiences with these? Does it make sense in a team of \\~15-20 people? And what kind of structure makes sense? Should we be operating out of one repo or many?\n\nThank you!", "author_fullname": "t2_gsch4oaq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Github tips/suggestions for small team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1548dlo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689804108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there,&lt;/p&gt;\n\n&lt;p&gt;Posted this on the Github subreddit without much response and I feel this somewhat more tailored towards this sub anyway.&lt;/p&gt;\n\n&lt;p&gt;I work for a fairly large company that already uses GH, however the team I work with and others surrounding it do not (I am fairly new and the teams never bothered with it I guess)! Our manager wants us to start utilizing GH.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any tips/suggestions about where to start and which/what features are super helpful to teams? Anything like a checklist of &amp;quot;must-haves&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;Some things to note - we are primarily backend devs/data engineers/data scientists. The overwhelming majority of our code is in T-SQL or Python/Jupyter. We also have A LOT of SSIS packages and some things in Databricks.&lt;/p&gt;\n\n&lt;p&gt;I have a couple years experience working with it (creating/submitting PR&amp;#39;s, squashing, basic things).&lt;/p&gt;\n\n&lt;p&gt;Some early questions I have been trying to answer is if Code Spaces or Actions would be useful - how are your experiences with these? Does it make sense in a team of ~15-20 people? And what kind of structure makes sense? Should we be operating out of one repo or many?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1548dlo", "is_robot_indexable": true, "report_reasons": null, "author": "xxEiGhTyxx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1548dlo/github_tipssuggestions_for_small_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1548dlo/github_tipssuggestions_for_small_team/", "subreddit_subscribers": 116823, "created_utc": 1689804108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4vrtl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Survey - 4 short questions] How is your data team structured? Who has what responsibilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1547nti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fziv044451.typeform.com%2Fto%2FEFhegEGs%3Ftypeform-embed%3Doembed%26typeform-medium%3Dembed-oembed%26format%3Djson&amp;display_name=Typeform&amp;url=https%3A%2F%2Fziv044451.typeform.com%2Fto%2FEFhegEGs&amp;image=https%3A%2F%2Fimages.typeform.com%2Fimages%2F2VWurKeiR4R7&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=typeform\" width=\"600\" height=\"400\" scrolling=\"no\" title=\"Typeform embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "height": 400}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "ziv044451.typeform.com", "oembed": {"provider_url": "https://typeform.com", "description": "Turn data collection into an experience with Typeform. Create beautiful online forms, surveys, quizzes, and so much more. Try it for FREE.", "title": "Data Team Responsibilities", "type": "rich", "mean_alpha": 87.0, "author_name": "Typeform", "height": 400, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fziv044451.typeform.com%2Fto%2FEFhegEGs%3Ftypeform-embed%3Doembed%26typeform-medium%3Dembed-oembed%26format%3Djson&amp;display_name=Typeform&amp;url=https%3A%2F%2Fziv044451.typeform.com%2Fto%2FEFhegEGs&amp;image=https%3A%2F%2Fimages.typeform.com%2Fimages%2F2VWurKeiR4R7&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=typeform\" width=\"600\" height=\"400\" scrolling=\"no\" title=\"Typeform embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "thumbnail_width": 1200, "version": "1.0", "provider_name": "Typeform", "thumbnail_url": "https://images.typeform.com/images/2VWurKeiR4R7", "thumbnail_height": 630, "author_url": "https://ziv044451.typeform.com/to/EFhegEGs"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fziv044451.typeform.com%2Fto%2FEFhegEGs%3Ftypeform-embed%3Doembed%26typeform-medium%3Dembed-oembed%26format%3Djson&amp;display_name=Typeform&amp;url=https%3A%2F%2Fziv044451.typeform.com%2Fto%2FEFhegEGs&amp;image=https%3A%2F%2Fimages.typeform.com%2Fimages%2F2VWurKeiR4R7&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=typeform\" width=\"600\" height=\"400\" scrolling=\"no\" title=\"Typeform embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1547nti", "height": 400}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/YlLISCEUd9YSRfs5L9g3X9giXg_kZKky4hwh2MXG8U4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689802432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ziv044451.typeform.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ziv044451.typeform.com/to/EFhegEGs", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dPZ6zZURl-yj2KkRR3PRSLTMc9-N9ps6uRjEB7vKV4o.jpg?auto=webp&amp;s=b6677ce2a42dc8ae1f9a0bc82415950fe78c9e5f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/dPZ6zZURl-yj2KkRR3PRSLTMc9-N9ps6uRjEB7vKV4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e142293435d2a455b172101f2af7587e9558673", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/dPZ6zZURl-yj2KkRR3PRSLTMc9-N9ps6uRjEB7vKV4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b7522240ed6a64029ac6f40c2a828a0157f771f0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/dPZ6zZURl-yj2KkRR3PRSLTMc9-N9ps6uRjEB7vKV4o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=43fcbc9dfe0b74661403b2ee45353264872bb216", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/dPZ6zZURl-yj2KkRR3PRSLTMc9-N9ps6uRjEB7vKV4o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8a96e0fc19ee3e92dca51262fe66975d97fa8754", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/dPZ6zZURl-yj2KkRR3PRSLTMc9-N9ps6uRjEB7vKV4o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=500543cc6b67c70004bf0dad4fa3e5ac560bce15", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/dPZ6zZURl-yj2KkRR3PRSLTMc9-N9ps6uRjEB7vKV4o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3393619ab074ff5650b0730ed2c15a416b3f9eb4", "width": 1080, "height": 567}], "variants": {}, "id": "RIOIruaZeUQnCoI4OYwFadUOTfsnV0c6NM5ulVqfORY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1547nti", "is_robot_indexable": true, "report_reasons": null, "author": "heyward22", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1547nti/survey_4_short_questions_how_is_your_data_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ziv044451.typeform.com/to/EFhegEGs", "subreddit_subscribers": 116823, "created_utc": 1689802432.0, "num_crossposts": 0, "media": {"type": "ziv044451.typeform.com", "oembed": {"provider_url": "https://typeform.com", "description": "Turn data collection into an experience with Typeform. Create beautiful online forms, surveys, quizzes, and so much more. Try it for FREE.", "title": "Data Team Responsibilities", "type": "rich", "mean_alpha": 87.0, "author_name": "Typeform", "height": 400, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fziv044451.typeform.com%2Fto%2FEFhegEGs%3Ftypeform-embed%3Doembed%26typeform-medium%3Dembed-oembed%26format%3Djson&amp;display_name=Typeform&amp;url=https%3A%2F%2Fziv044451.typeform.com%2Fto%2FEFhegEGs&amp;image=https%3A%2F%2Fimages.typeform.com%2Fimages%2F2VWurKeiR4R7&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=typeform\" width=\"600\" height=\"400\" scrolling=\"no\" title=\"Typeform embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "thumbnail_width": 1200, "version": "1.0", "provider_name": "Typeform", "thumbnail_url": "https://images.typeform.com/images/2VWurKeiR4R7", "thumbnail_height": 630, "author_url": "https://ziv044451.typeform.com/to/EFhegEGs"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I maintain code in Linux and \"git push\" changes to the origin, can view in browser. \n\nSeparately I work on Databricks notebooks - and manager asked me to sync to the same repo.\n\nI did that today and it's causing trouble when trying to git push/pull from Linux (branches diverged and other errors).\n\nIs this common practice? I see some possible solutions (git pull with --allow-unrelated-histories) but I wonder if it's a good idea. Will I see other problems like this? \n\nThere's no technical reason to use the same repo, it's just that they are related to the same project. \n\nBased on your experience, I want to talk to the manager (he's technical and reasonable). TIA! ", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manager wants me to sync two different code bases to the same Git repo. Is it a good idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1546cnh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689799401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I maintain code in Linux and &amp;quot;git push&amp;quot; changes to the origin, can view in browser. &lt;/p&gt;\n\n&lt;p&gt;Separately I work on Databricks notebooks - and manager asked me to sync to the same repo.&lt;/p&gt;\n\n&lt;p&gt;I did that today and it&amp;#39;s causing trouble when trying to git push/pull from Linux (branches diverged and other errors).&lt;/p&gt;\n\n&lt;p&gt;Is this common practice? I see some possible solutions (git pull with --allow-unrelated-histories) but I wonder if it&amp;#39;s a good idea. Will I see other problems like this? &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s no technical reason to use the same repo, it&amp;#39;s just that they are related to the same project. &lt;/p&gt;\n\n&lt;p&gt;Based on your experience, I want to talk to the manager (he&amp;#39;s technical and reasonable). TIA! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1546cnh", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1546cnh/manager_wants_me_to_sync_two_different_code_bases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1546cnh/manager_wants_me_to_sync_two_different_code_bases/", "subreddit_subscribers": 116823, "created_utc": 1689799401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just completed my first project and I have gotten some opinions from those outside the field for my English, now I'd like some technical review on maybe how to better present my article on how I dealt with Text Qualifiers: [The Rookie\u2019s Mistake](https://medium.com/@olufeoluwamac/the-rookies-mistake-d2b1238fde83)\n\nAlso does it pass as data reconstruction or is cleaning a safe umbrella term?", "author_fullname": "t2_e5tk1jtv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database \"Reconstruction\" Project Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1542sl3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689791114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just completed my first project and I have gotten some opinions from those outside the field for my English, now I&amp;#39;d like some technical review on maybe how to better present my article on how I dealt with Text Qualifiers: &lt;a href=\"https://medium.com/@olufeoluwamac/the-rookies-mistake-d2b1238fde83\"&gt;The Rookie\u2019s Mistake&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also does it pass as data reconstruction or is cleaning a safe umbrella term?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/92SwUsJGOyWYYikFAA3VcHAvVly45MJKGURRe5zq9R8.jpg?auto=webp&amp;s=0afc1a4085a8339e53bfb922125d559125658035", "width": 1200, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/92SwUsJGOyWYYikFAA3VcHAvVly45MJKGURRe5zq9R8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c3b09aaaf9dd789f951430e17ec3f7d79930f1d6", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/92SwUsJGOyWYYikFAA3VcHAvVly45MJKGURRe5zq9R8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ad72bcaa75cc78049c69ed8ac25b644f9796ba0", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/92SwUsJGOyWYYikFAA3VcHAvVly45MJKGURRe5zq9R8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8fd9a7777a1072d7f2ddc1a879fdc695cd23ebf1", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/92SwUsJGOyWYYikFAA3VcHAvVly45MJKGURRe5zq9R8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=664439e8c0fbaaa0ae312ef72ea4b462be1073c4", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/92SwUsJGOyWYYikFAA3VcHAvVly45MJKGURRe5zq9R8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=75ca5bcfc326bfb02f8f9d994d110725fc959237", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/92SwUsJGOyWYYikFAA3VcHAvVly45MJKGURRe5zq9R8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a7a3b1e08ed5f897f8a7db0f81b5d4b4d1debb91", "width": 1080, "height": 810}], "variants": {}, "id": "a96nxuATGctHsc8JGpx_yeXRRuqp3ucnj_JibmG7esA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1542sl3", "is_robot_indexable": true, "report_reasons": null, "author": "mjnr_19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1542sl3/database_reconstruction_project_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1542sl3/database_reconstruction_project_feedback/", "subreddit_subscribers": 116823, "created_utc": 1689791114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have pretty simple requirement. Read small .csv files in S3, perform light transformations, and load into an RDS Postgres table. Data is light enough where it makes sense (for me at least) to do the transformations in lambda with Pandas. My question is now that I have a dataframe in the lambda with the transformed data, what is the best approach from here to get that data in RDS? \n\n(Also open to overall architecture suggestions if what I\u2019m doing is bad)", "author_fullname": "t2_149bf9p2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "S3 -&gt; RDS Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1542n4f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689790761.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have pretty simple requirement. Read small .csv files in S3, perform light transformations, and load into an RDS Postgres table. Data is light enough where it makes sense (for me at least) to do the transformations in lambda with Pandas. My question is now that I have a dataframe in the lambda with the transformed data, what is the best approach from here to get that data in RDS? &lt;/p&gt;\n\n&lt;p&gt;(Also open to overall architecture suggestions if what I\u2019m doing is bad)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1542n4f", "is_robot_indexable": true, "report_reasons": null, "author": "INeedLegalHelp69", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1542n4f/s3_rds_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1542n4f/s3_rds_question/", "subreddit_subscribers": 116823, "created_utc": 1689790761.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all!\n\nI need help!\nWe expanded the size of the yvi directory partition and as a result, all JAR dependencies got deleted :(\n\nNow, when we run a Spark job, Spark attempts to download each JAR file for every user.\n\nHow can we fix this issue?\n\nWe are using Spark on AWS EKS.\n\nThanks for your assistance.", "author_fullname": "t2_4ndkyru3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark jar dependencies directory deleted", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154252k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689789621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;I need help!\nWe expanded the size of the yvi directory partition and as a result, all JAR dependencies got deleted :(&lt;/p&gt;\n\n&lt;p&gt;Now, when we run a Spark job, Spark attempts to download each JAR file for every user.&lt;/p&gt;\n\n&lt;p&gt;How can we fix this issue?&lt;/p&gt;\n\n&lt;p&gt;We are using Spark on AWS EKS.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your assistance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "154252k", "is_robot_indexable": true, "report_reasons": null, "author": "SmileHardy_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154252k/spark_jar_dependencies_directory_deleted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154252k/spark_jar_dependencies_directory_deleted/", "subreddit_subscribers": 116823, "created_utc": 1689789621.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}