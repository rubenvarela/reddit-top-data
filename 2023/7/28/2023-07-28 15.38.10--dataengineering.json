{"kind": "Listing", "data": {"after": "t3_15bd12s", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As someone who works in Snowflake day to day but has had little to no exposure to Databricks I'm curious to know from those who have worked with both, which do you prefer and what do you like/dislike about each?   \nYes, I know it's not exactly an apples to apples comparison but no one can deny these two companies are trying to compete with each other in the data marketplace.   \nThis isn't meant to be a comparison of which you think is necessarily *BETTER*... but more so which do you prefer working with, what have you enjoyed or disliked about either/both. Honestly just curious to hear opinions.", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who has worked with both Snowflake and Databricks and what do you enjoy/dislike about each?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15b85up", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 88, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 88, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690479473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As someone who works in Snowflake day to day but has had little to no exposure to Databricks I&amp;#39;m curious to know from those who have worked with both, which do you prefer and what do you like/dislike about each?&lt;br/&gt;\nYes, I know it&amp;#39;s not exactly an apples to apples comparison but no one can deny these two companies are trying to compete with each other in the data marketplace.&lt;br/&gt;\nThis isn&amp;#39;t meant to be a comparison of which you think is necessarily &lt;em&gt;BETTER&lt;/em&gt;... but more so which do you prefer working with, what have you enjoyed or disliked about either/both. Honestly just curious to hear opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15b85up", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15b85up/who_has_worked_with_both_snowflake_and_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15b85up/who_has_worked_with_both_snowflake_and_databricks/", "subreddit_subscribers": 118699, "created_utc": 1690479473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know we're all cool and blase and here for the money (except for us euro folks that are chronically underpayed) but i'm curious: what's the coolest data you've ever had to deal with in your projects? Maybe something bio related? space image data? massive network traffic data? ", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the coolest data you've worked with", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bs36m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690535024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know we&amp;#39;re all cool and blase and here for the money (except for us euro folks that are chronically underpayed) but i&amp;#39;m curious: what&amp;#39;s the coolest data you&amp;#39;ve ever had to deal with in your projects? Maybe something bio related? space image data? massive network traffic data? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15bs36m", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bs36m/whats_the_coolest_data_youve_worked_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bs36m/whats_the_coolest_data_youve_worked_with/", "subreddit_subscribers": 118699, "created_utc": 1690535024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last time, all the time hear that rust is a great language. How good it is for DE and what as a DE I can do with Rust?", "author_fullname": "t2_b1ud1vk1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How good Rust is for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ba7ei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690484334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last time, all the time hear that rust is a great language. How good it is for DE and what as a DE I can do with Rust?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ba7ei", "is_robot_indexable": true, "report_reasons": null, "author": "AdClean1116", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ba7ei/how_good_rust_is_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ba7ei/how_good_rust_is_for_de/", "subreddit_subscribers": 118699, "created_utc": 1690484334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There are plenty of tools, some are good, some are nice to have and some are just a pain in the ass.\nWhat is your favourite ETL/ELT tool?", "author_fullname": "t2_9pyk5rj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your favourite ETL/ELT tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bec37", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690493889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are plenty of tools, some are good, some are nice to have and some are just a pain in the ass.\nWhat is your favourite ETL/ELT tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15bec37", "is_robot_indexable": true, "report_reasons": null, "author": "seayk", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bec37/what_is_your_favourite_etlelt_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bec37/what_is_your_favourite_etlelt_tool/", "subreddit_subscribers": 118699, "created_utc": 1690493889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, great data people.\n\nThe **direct question** I want to understand is: Who is using Delta Lake outside Databricks environments?\n\nThe **indirect question** is: what is the \"type\" of companies and use cases using Delta Lake and Iceberg?  \n\n\nUsing Delta Lake when your data platform sits on Databricks is a no-brainer. It works just wonderfully (I used it myself). Delta Lake OSS is also a very good piece of software for itself.\n\nHowever, how is the usage distribution outside Databricks envs? \nI've heard Iceberg is more used for on-prem companies, mainly big tech. \nOn \"non-databricks-cloud\", Iceberg has better support AFAIK. For example, for Snowflake and BigQuery.\nOn the other hand, Delta-rs integration with Arrow made Delta available to all tools supporting Arrow, which is a huge step towards being a standard outside the JVM, like for ML tools. While Icerbeg still lives in the JVM mostly.\n\nSo, how is the market using Delta Lake and Iceberg outside Databricks, in your opinion and/or experience?", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who is using Delta Lake outside Databricks environments?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bap0n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690485477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, great data people.&lt;/p&gt;\n\n&lt;p&gt;The &lt;strong&gt;direct question&lt;/strong&gt; I want to understand is: Who is using Delta Lake outside Databricks environments?&lt;/p&gt;\n\n&lt;p&gt;The &lt;strong&gt;indirect question&lt;/strong&gt; is: what is the &amp;quot;type&amp;quot; of companies and use cases using Delta Lake and Iceberg?  &lt;/p&gt;\n\n&lt;p&gt;Using Delta Lake when your data platform sits on Databricks is a no-brainer. It works just wonderfully (I used it myself). Delta Lake OSS is also a very good piece of software for itself.&lt;/p&gt;\n\n&lt;p&gt;However, how is the usage distribution outside Databricks envs? \nI&amp;#39;ve heard Iceberg is more used for on-prem companies, mainly big tech. \nOn &amp;quot;non-databricks-cloud&amp;quot;, Iceberg has better support AFAIK. For example, for Snowflake and BigQuery.\nOn the other hand, Delta-rs integration with Arrow made Delta available to all tools supporting Arrow, which is a huge step towards being a standard outside the JVM, like for ML tools. While Icerbeg still lives in the JVM mostly.&lt;/p&gt;\n\n&lt;p&gt;So, how is the market using Delta Lake and Iceberg outside Databricks, in your opinion and/or experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15bap0n", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bap0n/who_is_using_delta_lake_outside_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bap0n/who_is_using_delta_lake_outside_databricks/", "subreddit_subscribers": 118699, "created_utc": 1690485477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am a big fan of this sub reddit as a lurker, and would like to dip my toes into the water.  You guys are rock stars.\n\n&amp;#x200B;\n\nMy question is how can I avoid rewriting code for batch and streaming pipelines?\n\nContext:\n\nI am designing an NLP application that will involve a pipeline that takes text, and transforms it into embeddings, and other engineered features.\n\nI am looking for a way to be able to reuse code from the batch model training pipeline, for the inference pipeline when the model is running in production? What key principles should I consider, and are there potential landmines to avoid?\n\nI am looking at using different frameworks and tools for their specific tasks rather than one massive platform. For example, using Airflow only as an orchestrator, due to it's many integrations with other tools that would be more suited for specialized jobs.\n\nThe idea is to use the executors are  a wrapper that calls other tools to avoid debugging multiple layers of the stack at once.\n\nIn production, we'll need to have an inference pipeline. However, Airflow of course is not meant to be an streaming pipeline, and from my research it appears that Airflow creates a lot of problems when it is not used the way it is intended to be used.\n\nA solution I have looked at is windowed inference, with a message broker that will collect messages from the web app in a queue, then process and transform the windowed batches several times a second.\n\nThe individual messages can be identified with a unique pass through key so that we can scale horizontally and don't need to worry as much about ordering the arrays so that they always need to come back in the right order.\n\nI am open to any suggestions\n\nOther Conceptual Holes in my knowledge:\n\nWhat is the role of a feature store in this?\n\nWhat are your opinions on Seldon Core for serving ML Models in inference, specifically ensemble models that pipe output to each other?\n\n&amp;#x200B;\n\nThank you for your time reading this\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_qa447ioz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to be able to reuse code for both batch and stream processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bpsoy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690527232.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690527034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am a big fan of this sub reddit as a lurker, and would like to dip my toes into the water.  You guys are rock stars.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is how can I avoid rewriting code for batch and streaming pipelines?&lt;/p&gt;\n\n&lt;p&gt;Context:&lt;/p&gt;\n\n&lt;p&gt;I am designing an NLP application that will involve a pipeline that takes text, and transforms it into embeddings, and other engineered features.&lt;/p&gt;\n\n&lt;p&gt;I am looking for a way to be able to reuse code from the batch model training pipeline, for the inference pipeline when the model is running in production? What key principles should I consider, and are there potential landmines to avoid?&lt;/p&gt;\n\n&lt;p&gt;I am looking at using different frameworks and tools for their specific tasks rather than one massive platform. For example, using Airflow only as an orchestrator, due to it&amp;#39;s many integrations with other tools that would be more suited for specialized jobs.&lt;/p&gt;\n\n&lt;p&gt;The idea is to use the executors are  a wrapper that calls other tools to avoid debugging multiple layers of the stack at once.&lt;/p&gt;\n\n&lt;p&gt;In production, we&amp;#39;ll need to have an inference pipeline. However, Airflow of course is not meant to be an streaming pipeline, and from my research it appears that Airflow creates a lot of problems when it is not used the way it is intended to be used.&lt;/p&gt;\n\n&lt;p&gt;A solution I have looked at is windowed inference, with a message broker that will collect messages from the web app in a queue, then process and transform the windowed batches several times a second.&lt;/p&gt;\n\n&lt;p&gt;The individual messages can be identified with a unique pass through key so that we can scale horizontally and don&amp;#39;t need to worry as much about ordering the arrays so that they always need to come back in the right order.&lt;/p&gt;\n\n&lt;p&gt;I am open to any suggestions&lt;/p&gt;\n\n&lt;p&gt;Other Conceptual Holes in my knowledge:&lt;/p&gt;\n\n&lt;p&gt;What is the role of a feature store in this?&lt;/p&gt;\n\n&lt;p&gt;What are your opinions on Seldon Core for serving ML Models in inference, specifically ensemble models that pipe output to each other?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time reading this&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15bpsoy", "is_robot_indexable": true, "report_reasons": null, "author": "jentlej", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bpsoy/how_to_be_able_to_reuse_code_for_both_batch_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bpsoy/how_to_be_able_to_reuse_code_for_both_batch_and/", "subreddit_subscribers": 118699, "created_utc": 1690527034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**DISCLAIMER**\n\nI am no data engineer and I don't know python or any programming language. I can put together stuff into VScode but thats about the extent of my programming abilities. \n\n&amp;#x200B;\n\n**INTRO &amp; CONTEXT**\n\nI\u2019m working on a personal project that takes a PDF containing medical lab results, extracts the data and processes the data into a new centralized schema. From that schema, data is imported into an Excel or Sheets table, which is used as a data source for a no-code website builder. (like Noloco)\n\nI designed the centralized database schema both as a JSON and as an Excel.\n\nI\u2019ve managed to extract some data successfully using AWS Textract GUI console demo. The outputs that AWS gives are JSONs and CSVs.\n\nI now need to transform the data from the AWS output, to match the centralized schema so I can map the data. And here is where im stuck..\n\n**PROBLEM**\n\nMy table has a hierarchical layout with nested rows under one column. I need to transform the data, split the first column into 2 columns, do some parsing etc.\n\nBut in order to transform the data I need to programmatically identify what data needs to be manipulated and somehow mark it. Theoretically, my table has 2 types of entries / records. Type 1 entries are singleTests and type 2 entries are collectionTests.\n\n[The table output sample and entries types.](https://preview.redd.it/ft5c4hn88jeb1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=e4b0b1fe7054739ed1fb65ffbeff6cf1aa1169e2)\n\nI need to think of a parsing logic or a logic to identify the data.\n\n* I first thought about **identification by keywords** and indeed there is an \u201cLC\u201d at the beginning of each record. That LC stands for Central Lab and its the location where the tests have been processed. The problem with this that LC appears irregularly and its not reliable.\n* The second method I thought was **identification by pattern**. For a singleTest there are always 2 rows, the first one having empty values (besides the first column). For a collectionTest, the first 2 rows are always empty (besides the first column). A collectionTest has a variable number of sub-tests.\n\nHere is a draft of the centralized schema database:\n\nhttps://preview.redd.it/fzj0thjd8jeb1.png?width=1428&amp;format=png&amp;auto=webp&amp;s=c06740e81178ea509d56aefa1849db26e50796cd\n\nIn this first iteration, the original TestName values that were spanning multiple rows have been split into CollectionName and CollectionMethod according to the entry type.\n\n&amp;#x200B;\n\n**NEED**\n\nI need a parsing logic implemented in python (pandas) that can identify entries types and mark them accordingly. Im not sure if a script can do this. Suggest alternatives if you know.\n\n&amp;#x200B;\n\n**PROGRESS**\n\nI\u2019ve tried about 25 iterations of threads with GPT-4 and Code Interpreter. The problem here is I don\u2019t know exactly what to ask since I don\u2019t know data science specific terms and what technique or collection of techniques should be used. Even so, I\u2019ve managed to get very close to marking the entries correctly with Code Interpreter but it seems that, even though it understands the logic, It can\u2019t write a working script.\n\n&amp;#x200B;\n\n**RESOURCES**\n\n* A Notion with my progress on the data identification logic with my prompts [LINK](https://dennis-kampien.notion.site/Parsing-logic-c70e92b49a8b433398a85d49a0d06343?pvs=4)\n* Links to the sheets containing the tables [LINK](https://docs.google.com/spreadsheets/d/1U7bbTX7qPVFb9FeSGzxxWZyDVk1q48lx/edit?usp=sharing&amp;ouid=107105976591677253200&amp;rtpof=true&amp;sd=true)\n* A link with a partial successful GPT thread [LINK](https://chat.openai.com/share/fbac4366-5b57-4dc4-82d0-f1cf946fa58f)\n\n&amp;#x200B;\n\n If you have ideas where else I can get help, would be appreciated. Thank you.  ", "author_fullname": "t2_14ss6y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help on Python (pandas) script for data identification logic. Working to extract and transform data from PDF\u2019s into Excel. (Long post)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 54, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ft5c4hn88jeb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/ft5c4hn88jeb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0ab8840e242592775ac67637541564549cd8a8d5"}, {"y": 84, "x": 216, "u": "https://preview.redd.it/ft5c4hn88jeb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1e8c30e3c03c79b8fc2b9f54a6590914e8339292"}, {"y": 124, "x": 320, "u": "https://preview.redd.it/ft5c4hn88jeb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=288d2bab0d4a2de8a2cd1708b231b51882b2ac25"}, {"y": 249, "x": 640, "u": "https://preview.redd.it/ft5c4hn88jeb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=caff806277a3bcb4200b33eee3a52bd2f1ba5026"}, {"y": 374, "x": 960, "u": "https://preview.redd.it/ft5c4hn88jeb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fca6fddfbcb2814fb6bdbce3f3c02d336f47169f"}, {"y": 421, "x": 1080, "u": "https://preview.redd.it/ft5c4hn88jeb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=33a4e65b84aaef814225f3ef6664b5b88b342b1e"}], "s": {"y": 624, "x": 1600, "u": "https://preview.redd.it/ft5c4hn88jeb1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=e4b0b1fe7054739ed1fb65ffbeff6cf1aa1169e2"}, "id": "ft5c4hn88jeb1"}, "fzj0thjd8jeb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 20, "x": 108, "u": "https://preview.redd.it/fzj0thjd8jeb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f2ad1cff2f1410be46cb494df6b9e050a5464a0d"}, {"y": 40, "x": 216, "u": "https://preview.redd.it/fzj0thjd8jeb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=862a962acc049d806c34236588d3fdb48e8f4511"}, {"y": 59, "x": 320, "u": "https://preview.redd.it/fzj0thjd8jeb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8de591af43390b23b44c89554fc03600bb1a06c3"}, {"y": 118, "x": 640, "u": "https://preview.redd.it/fzj0thjd8jeb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=84ae66308adeee36d66da091225fde18955c785b"}, {"y": 178, "x": 960, "u": "https://preview.redd.it/fzj0thjd8jeb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cdbe062dc0bda64c6ba2917e89ff60b6005d39c"}, {"y": 200, "x": 1080, "u": "https://preview.redd.it/fzj0thjd8jeb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=17c41336da949d82933fa4d19cfaf729430ce3f5"}], "s": {"y": 265, "x": 1428, "u": "https://preview.redd.it/fzj0thjd8jeb1.png?width=1428&amp;format=png&amp;auto=webp&amp;s=c06740e81178ea509d56aefa1849db26e50796cd"}, "id": "fzj0thjd8jeb1"}}, "name": "t3_15b68s8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b-fDRzF5urH9nJsyANLJage8vwRiW7cKtTDc42UNRzo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690474956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;DISCLAIMER&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I am no data engineer and I don&amp;#39;t know python or any programming language. I can put together stuff into VScode but thats about the extent of my programming abilities. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;INTRO &amp;amp; CONTEXT&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I\u2019m working on a personal project that takes a PDF containing medical lab results, extracts the data and processes the data into a new centralized schema. From that schema, data is imported into an Excel or Sheets table, which is used as a data source for a no-code website builder. (like Noloco)&lt;/p&gt;\n\n&lt;p&gt;I designed the centralized database schema both as a JSON and as an Excel.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve managed to extract some data successfully using AWS Textract GUI console demo. The outputs that AWS gives are JSONs and CSVs.&lt;/p&gt;\n\n&lt;p&gt;I now need to transform the data from the AWS output, to match the centralized schema so I can map the data. And here is where im stuck..&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;PROBLEM&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;My table has a hierarchical layout with nested rows under one column. I need to transform the data, split the first column into 2 columns, do some parsing etc.&lt;/p&gt;\n\n&lt;p&gt;But in order to transform the data I need to programmatically identify what data needs to be manipulated and somehow mark it. Theoretically, my table has 2 types of entries / records. Type 1 entries are singleTests and type 2 entries are collectionTests.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ft5c4hn88jeb1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e4b0b1fe7054739ed1fb65ffbeff6cf1aa1169e2\"&gt;The table output sample and entries types.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I need to think of a parsing logic or a logic to identify the data.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I first thought about &lt;strong&gt;identification by keywords&lt;/strong&gt; and indeed there is an \u201cLC\u201d at the beginning of each record. That LC stands for Central Lab and its the location where the tests have been processed. The problem with this that LC appears irregularly and its not reliable.&lt;/li&gt;\n&lt;li&gt;The second method I thought was &lt;strong&gt;identification by pattern&lt;/strong&gt;. For a singleTest there are always 2 rows, the first one having empty values (besides the first column). For a collectionTest, the first 2 rows are always empty (besides the first column). A collectionTest has a variable number of sub-tests.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here is a draft of the centralized schema database:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fzj0thjd8jeb1.png?width=1428&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c06740e81178ea509d56aefa1849db26e50796cd\"&gt;https://preview.redd.it/fzj0thjd8jeb1.png?width=1428&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c06740e81178ea509d56aefa1849db26e50796cd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In this first iteration, the original TestName values that were spanning multiple rows have been split into CollectionName and CollectionMethod according to the entry type.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;NEED&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I need a parsing logic implemented in python (pandas) that can identify entries types and mark them accordingly. Im not sure if a script can do this. Suggest alternatives if you know.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;PROGRESS&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried about 25 iterations of threads with GPT-4 and Code Interpreter. The problem here is I don\u2019t know exactly what to ask since I don\u2019t know data science specific terms and what technique or collection of techniques should be used. Even so, I\u2019ve managed to get very close to marking the entries correctly with Code Interpreter but it seems that, even though it understands the logic, It can\u2019t write a working script.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;RESOURCES&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A Notion with my progress on the data identification logic with my prompts &lt;a href=\"https://dennis-kampien.notion.site/Parsing-logic-c70e92b49a8b433398a85d49a0d06343?pvs=4\"&gt;LINK&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Links to the sheets containing the tables &lt;a href=\"https://docs.google.com/spreadsheets/d/1U7bbTX7qPVFb9FeSGzxxWZyDVk1q48lx/edit?usp=sharing&amp;amp;ouid=107105976591677253200&amp;amp;rtpof=true&amp;amp;sd=true\"&gt;LINK&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;A link with a partial successful GPT thread &lt;a href=\"https://chat.openai.com/share/fbac4366-5b57-4dc4-82d0-f1cf946fa58f\"&gt;LINK&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you have ideas where else I can get help, would be appreciated. Thank you.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15b68s8", "is_robot_indexable": true, "report_reasons": null, "author": "dkampien", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15b68s8/help_on_python_pandas_script_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15b68s8/help_on_python_pandas_script_for_data/", "subreddit_subscribers": 118699, "created_utc": 1690474956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After 2 years of experience in data science, having done multiple ETL pipelines, prediction models and some dashboards here and there, I've decided to mainly focus on data engineering. However, I'm currently applying for data engineering jobs in my country and not getting responses for my applications.\n\nI've decided to study and brush up my Airflow and Apache Spark skills as well as study to get the azure dp-203 cert. Could someone give me additional tips or maybe even insights into why I'm not hearing back from those applications?", "author_fullname": "t2_625bbvhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from DS to DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bfdkd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690496405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After 2 years of experience in data science, having done multiple ETL pipelines, prediction models and some dashboards here and there, I&amp;#39;ve decided to mainly focus on data engineering. However, I&amp;#39;m currently applying for data engineering jobs in my country and not getting responses for my applications.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve decided to study and brush up my Airflow and Apache Spark skills as well as study to get the azure dp-203 cert. Could someone give me additional tips or maybe even insights into why I&amp;#39;m not hearing back from those applications?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15bfdkd", "is_robot_indexable": true, "report_reasons": null, "author": "Bira-of-louders", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bfdkd/transitioning_from_ds_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bfdkd/transitioning_from_ds_to_de/", "subreddit_subscribers": 118699, "created_utc": 1690496405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nmy organization is in the process of establishing an end to end BI process and we have a good chance to make things right as it is basically non-existent. There are two main options when it comes to picking a data warehouse and I need your comments on how to analyze the situation best and make the right call:\n\n1. There is an existing on-prem data warehouse developed and maintained by an external vendor. It's Oracle based, and all data from operational system is deployed there. It has a very limited use, most data consumption is done directly from the data source (which is of course extremely inefficient). Limited use might suggest quality issues but I need to still delve into more analysis to understand better. \n2. Redshift (with data ingested through S3 with DBT) - this one is arranged by corporate in terms of   billing, contract, etc. but we need to take care of technical side (data modelling, integration, transformation, etc.). So we need to make sure we have the right resources in place.\n\nOrganization is pretty fixed on powerBI as bi tool so that would be non-negotiable.\n\nCurrent data size is around 2-3 TB and expected to increase 50% in the next 5 years.\n\nOption1 is easiest in short-term and the company already invested some money into it but I am not sure if it's the best long term and they are actually open to migrating. What facts do I need to get straight so that I make best informed decision?\n\nMany thanks.", "author_fullname": "t2_k3y42mr6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with data warehouse selection - on-prem Oracle vs AWS Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bu5ge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690541800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;my organization is in the process of establishing an end to end BI process and we have a good chance to make things right as it is basically non-existent. There are two main options when it comes to picking a data warehouse and I need your comments on how to analyze the situation best and make the right call:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;There is an existing on-prem data warehouse developed and maintained by an external vendor. It&amp;#39;s Oracle based, and all data from operational system is deployed there. It has a very limited use, most data consumption is done directly from the data source (which is of course extremely inefficient). Limited use might suggest quality issues but I need to still delve into more analysis to understand better. &lt;/li&gt;\n&lt;li&gt;Redshift (with data ingested through S3 with DBT) - this one is arranged by corporate in terms of   billing, contract, etc. but we need to take care of technical side (data modelling, integration, transformation, etc.). So we need to make sure we have the right resources in place.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Organization is pretty fixed on powerBI as bi tool so that would be non-negotiable.&lt;/p&gt;\n\n&lt;p&gt;Current data size is around 2-3 TB and expected to increase 50% in the next 5 years.&lt;/p&gt;\n\n&lt;p&gt;Option1 is easiest in short-term and the company already invested some money into it but I am not sure if it&amp;#39;s the best long term and they are actually open to migrating. What facts do I need to get straight so that I make best informed decision?&lt;/p&gt;\n\n&lt;p&gt;Many thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15bu5ge", "is_robot_indexable": true, "report_reasons": null, "author": "sportage0912", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bu5ge/help_with_data_warehouse_selection_onprem_oracle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bu5ge/help_with_data_warehouse_selection_onprem_oracle/", "subreddit_subscribers": 118699, "created_utc": 1690541800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all. Our team are looking to add some more structure to our data warehouse, so have been looking at all the different modelling methodologies (data vault, activity schema, Kimball etc.). We've identified Activity Schema as a really interesting option, that works well for us since we're an online business that works with events mostly.\n\nAnyone have experience working with Activity Schema, and can share what they thought of it? Equally interested in hearing anyone who tried it but didn't end up having a good time with it. \n\nSpec is here for anyone who hasn't heard of it: https://github.com/ActivitySchema/ActivitySchema/blob/main/2.0.md", "author_fullname": "t2_kc0dijh6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using Activity Schema for data modelling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bs5vm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690535287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all. Our team are looking to add some more structure to our data warehouse, so have been looking at all the different modelling methodologies (data vault, activity schema, Kimball etc.). We&amp;#39;ve identified Activity Schema as a really interesting option, that works well for us since we&amp;#39;re an online business that works with events mostly.&lt;/p&gt;\n\n&lt;p&gt;Anyone have experience working with Activity Schema, and can share what they thought of it? Equally interested in hearing anyone who tried it but didn&amp;#39;t end up having a good time with it. &lt;/p&gt;\n\n&lt;p&gt;Spec is here for anyone who hasn&amp;#39;t heard of it: &lt;a href=\"https://github.com/ActivitySchema/ActivitySchema/blob/main/2.0.md\"&gt;https://github.com/ActivitySchema/ActivitySchema/blob/main/2.0.md&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-vdVGrhllXT4hptXhleHPjZJN2jTzwUr52QiKuvPoQY.jpg?auto=webp&amp;s=e41ec8002730534aca9b9d4f7935dd17b790cd8d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/-vdVGrhllXT4hptXhleHPjZJN2jTzwUr52QiKuvPoQY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b90bbc592072fa1e460a597b62fd3dc334274fda", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/-vdVGrhllXT4hptXhleHPjZJN2jTzwUr52QiKuvPoQY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ad7ff15afe4e44500d40bde9e731bf2f20bc5ff1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/-vdVGrhllXT4hptXhleHPjZJN2jTzwUr52QiKuvPoQY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ed9f84747f7b5e7ea087bdf1264c241b716caa6d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/-vdVGrhllXT4hptXhleHPjZJN2jTzwUr52QiKuvPoQY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6439a48fb68bd425ea5acbe11b140a560ccc080d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/-vdVGrhllXT4hptXhleHPjZJN2jTzwUr52QiKuvPoQY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=013f6b82045286cd216e1708a627772148a90846", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/-vdVGrhllXT4hptXhleHPjZJN2jTzwUr52QiKuvPoQY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49b92f351a75678a56fcfd2bb41fc5f515942dfb", "width": 1080, "height": 540}], "variants": {}, "id": "VM-XtI2pJzxztoHgXUlTpjqvfd1Bq8M95FuLbNrE2UE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15bs5vm", "is_robot_indexable": true, "report_reasons": null, "author": "optimalbiscuit", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bs5vm/anyone_using_activity_schema_for_data_modelling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bs5vm/anyone_using_activity_schema_for_data_modelling/", "subreddit_subscribers": 118699, "created_utc": 1690535287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "last year I began in a new project,  hired by a consultancy firm, as a sr. data engineer (nearshore external consultant ).\n\nThis project was just big query and airflow, which made sense as I am a certified gcp pde. Then after 7 months the customer cancelled a lot of ext consultants after running short of budget, including me, but the consultancy told me to don't worry as they will be keeping paying me as usual while locating me in a new project with some other customer.\n\nSo, in that context, someone from HR arranged me into a call with a technical internal team to make sure my profile matches a specific requirement from other customer. These guys asked me if I had some experience working with Hana, which I said no, and also if I had experience working with snowflake, -again not-. \n\nSo I expected after that, that I was not a match and for they to keep trying with other candidates, but it appears that they gave me green light because now they arranged an interview with the customer, so now I am concerned about being assigned something that's really out of my toolbox.\n\nOf course I am open to learn new skills and assume challenge, but this sounds to me like starting from zero and I'm not sure it these skills make sense to learn, and also no idea about the learning curve I could expect.\n\nWhat should I do? I really want to stay in this company, but I'm not sure if I am supposed to accept whatever project they ask me.", "author_fullname": "t2_14crgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning curve for Hana + snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bnrwu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690520256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;last year I began in a new project,  hired by a consultancy firm, as a sr. data engineer (nearshore external consultant ).&lt;/p&gt;\n\n&lt;p&gt;This project was just big query and airflow, which made sense as I am a certified gcp pde. Then after 7 months the customer cancelled a lot of ext consultants after running short of budget, including me, but the consultancy told me to don&amp;#39;t worry as they will be keeping paying me as usual while locating me in a new project with some other customer.&lt;/p&gt;\n\n&lt;p&gt;So, in that context, someone from HR arranged me into a call with a technical internal team to make sure my profile matches a specific requirement from other customer. These guys asked me if I had some experience working with Hana, which I said no, and also if I had experience working with snowflake, -again not-. &lt;/p&gt;\n\n&lt;p&gt;So I expected after that, that I was not a match and for they to keep trying with other candidates, but it appears that they gave me green light because now they arranged an interview with the customer, so now I am concerned about being assigned something that&amp;#39;s really out of my toolbox.&lt;/p&gt;\n\n&lt;p&gt;Of course I am open to learn new skills and assume challenge, but this sounds to me like starting from zero and I&amp;#39;m not sure it these skills make sense to learn, and also no idea about the learning curve I could expect.&lt;/p&gt;\n\n&lt;p&gt;What should I do? I really want to stay in this company, but I&amp;#39;m not sure if I am supposed to accept whatever project they ask me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15bnrwu", "is_robot_indexable": true, "report_reasons": null, "author": "untalmau", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bnrwu/learning_curve_for_hana_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bnrwu/learning_curve_for_hana_snowflake/", "subreddit_subscribers": 118699, "created_utc": 1690520256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nI have a project where I need to migrate data from a mysql database to a postgres database. The tables are pretty much the same, except the target tables in postgres have an additional column with a uuid datatype. The default value for this column is an autogenerated uuid.\n\nIs it possible to setup a DMS task that can handle automatically insert a uuid value for every record it migrates, or will that automatically happen since the target tables additional column is defined so that it will generate a uuid value on default?", "author_fullname": "t2_87grrjv3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this AWS DMS task possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bmwrt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690517426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a project where I need to migrate data from a mysql database to a postgres database. The tables are pretty much the same, except the target tables in postgres have an additional column with a uuid datatype. The default value for this column is an autogenerated uuid.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to setup a DMS task that can handle automatically insert a uuid value for every record it migrates, or will that automatically happen since the target tables additional column is defined so that it will generate a uuid value on default?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15bmwrt", "is_robot_indexable": true, "report_reasons": null, "author": "No_Growth_9813", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bmwrt/is_this_aws_dms_task_possible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bmwrt/is_this_aws_dms_task_possible/", "subreddit_subscribers": 118699, "created_utc": 1690517426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the possible no-JVM tooling around stream processing? What I found:\n- bytewax\n- streamz\n- prefect\n- faust\n\n\nCould you recommend what works for you?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stream processing without JVM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15byd2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690552994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the possible no-JVM tooling around stream processing? What I found:\n- bytewax\n- streamz\n- prefect\n- faust&lt;/p&gt;\n\n&lt;p&gt;Could you recommend what works for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15byd2c", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15byd2c/stream_processing_without_jvm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15byd2c/stream_processing_without_jvm/", "subreddit_subscribers": 118699, "created_utc": 1690552994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, sorry in advance for my english first of all. I have a small company and we are using data warehousing program. Up till now, we take the flow of data of different warehouses, and we manually do the match with our database codification, to be able to utilize the data for statistic ecc.\n\nSince this takes a crapload of time and resources, we start wondering if there is a way/a program to do this work. I make an example:\n\nLet's take a single record (usually the montly flow of data from the warehouse is 10.000-20.000 records), the product description is \"Beautiful Water Still VAP 24 500\". In our database the product description is \"Water Beautiful Vap Still pz24 CL.50\" and the code is 000035. Our work is assign the code 000035 to the original description. Keep in mind that we have plenty of very very similar descriptions, that vary just in format or number of pieces (e.g. \"Water Beautiful Vap Still pz.24 CL.75\"), and this make all our custom solution (excel formulas i.e. v.lookup index match ecc.) struggle, since most of times they match the wrong product.\n\nSo my question is: there are programs that can do a perfect match, even if the description is misleading, incomplete and there are many similar result in the core database? \n\nSorry if this not the right place / the question is too stupid.", "author_fullname": "t2_13p257", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best solution to match different data sources into a single database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bxdth", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690550621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, sorry in advance for my english first of all. I have a small company and we are using data warehousing program. Up till now, we take the flow of data of different warehouses, and we manually do the match with our database codification, to be able to utilize the data for statistic ecc.&lt;/p&gt;\n\n&lt;p&gt;Since this takes a crapload of time and resources, we start wondering if there is a way/a program to do this work. I make an example:&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s take a single record (usually the montly flow of data from the warehouse is 10.000-20.000 records), the product description is &amp;quot;Beautiful Water Still VAP 24 500&amp;quot;. In our database the product description is &amp;quot;Water Beautiful Vap Still pz24 CL.50&amp;quot; and the code is 000035. Our work is assign the code 000035 to the original description. Keep in mind that we have plenty of very very similar descriptions, that vary just in format or number of pieces (e.g. &amp;quot;Water Beautiful Vap Still pz.24 CL.75&amp;quot;), and this make all our custom solution (excel formulas i.e. v.lookup index match ecc.) struggle, since most of times they match the wrong product.&lt;/p&gt;\n\n&lt;p&gt;So my question is: there are programs that can do a perfect match, even if the description is misleading, incomplete and there are many similar result in the core database? &lt;/p&gt;\n\n&lt;p&gt;Sorry if this not the right place / the question is too stupid.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15bxdth", "is_robot_indexable": true, "report_reasons": null, "author": "Leru76", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bxdth/whats_the_best_solution_to_match_different_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bxdth/whats_the_best_solution_to_match_different_data/", "subreddit_subscribers": 118699, "created_utc": 1690550621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello I\u2019m working with some students and want to give them some guidance for a project. They\u2019re analytics students. \n\nWe want to analyze 3 billion rows of data that are currently stored as 2500 or so flat files. We want to do some machine learning and present visualizations on a website. \n\nI generally work in sql server and anaconda but never with data sets this large.\n\nWe can use cloud technology, etc., but need to keep costs to a minimum.\n\nQuestion: how would you store the data? Azure? AWS? What tools would you use to query the data? How would you connect the DB to a machine learning tool and how would you display the results on the web?\n\nObv I can google though I just thought I would try here and see if anyone had quick recommendations. Thank you!", "author_fullname": "t2_6f5ggoc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to store and query 3 billion rows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bvyf1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690546921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello I\u2019m working with some students and want to give them some guidance for a project. They\u2019re analytics students. &lt;/p&gt;\n\n&lt;p&gt;We want to analyze 3 billion rows of data that are currently stored as 2500 or so flat files. We want to do some machine learning and present visualizations on a website. &lt;/p&gt;\n\n&lt;p&gt;I generally work in sql server and anaconda but never with data sets this large.&lt;/p&gt;\n\n&lt;p&gt;We can use cloud technology, etc., but need to keep costs to a minimum.&lt;/p&gt;\n\n&lt;p&gt;Question: how would you store the data? Azure? AWS? What tools would you use to query the data? How would you connect the DB to a machine learning tool and how would you display the results on the web?&lt;/p&gt;\n\n&lt;p&gt;Obv I can google though I just thought I would try here and see if anyone had quick recommendations. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15bvyf1", "is_robot_indexable": true, "report_reasons": null, "author": "wackomama", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bvyf1/how_to_store_and_query_3_billion_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bvyf1/how_to_store_and_query_3_billion_rows/", "subreddit_subscribers": 118699, "created_utc": 1690546921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_24uok5oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First steps with the Apache Kafka\u00ae Java client library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15bqsll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EKsvZ8OqzTXy56dqrLj3wDahbLIBv9TTE6MM3ep05No.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690530482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "aiven.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://aiven.io/developer/first-steps-kafka-java-client-library?utm_source=reddit&amp;utm_medium=organic&amp;utm_campaign=reddit_activation_Q3Q4_2023", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JhEVaNQw82gaTjeGol0t9rb7_f_qiOYY1NiVSzvwWP8.jpg?auto=webp&amp;s=9639f264b8b5f3b0a42d3e3e27e18b549bd3c3bd", "width": 1567, "height": 823}, "resolutions": [{"url": "https://external-preview.redd.it/JhEVaNQw82gaTjeGol0t9rb7_f_qiOYY1NiVSzvwWP8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=83eea29595dbf7c3b10762fb9b40d8b25181fc55", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/JhEVaNQw82gaTjeGol0t9rb7_f_qiOYY1NiVSzvwWP8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7361e0b4c6a3f6e9928a2242f8f36231b572e638", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/JhEVaNQw82gaTjeGol0t9rb7_f_qiOYY1NiVSzvwWP8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f017a61af45bbe67a3876d39a328f442088a5d77", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/JhEVaNQw82gaTjeGol0t9rb7_f_qiOYY1NiVSzvwWP8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cae2a7851fea29a04698ea5cbb18936ca8377636", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/JhEVaNQw82gaTjeGol0t9rb7_f_qiOYY1NiVSzvwWP8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=26e3b27de5b3164a771e5428167eec6c8cb05c9e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/JhEVaNQw82gaTjeGol0t9rb7_f_qiOYY1NiVSzvwWP8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=439869f88c5fd0b4e3ec2ab9fb86caf88feb7215", "width": 1080, "height": 567}], "variants": {}, "id": "v4EzfbmxFcEO4Wd-nJy14k6RfEo3F40nQ4Iq3cxLcwg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15bqsll", "is_robot_indexable": true, "report_reasons": null, "author": "Marksfik", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bqsll/first_steps_with_the_apache_kafka_java_client/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://aiven.io/developer/first-steps-kafka-java-client-library?utm_source=reddit&amp;utm_medium=organic&amp;utm_campaign=reddit_activation_Q3Q4_2023", "subreddit_subscribers": 118699, "created_utc": 1690530482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI am going to be designing a DB soon for a medium sized business and other than the foundational tenets of DB design, I was hoping for book suggestions/courses on curating good training data.  What are some pitfalls that I need to know about, how should I be tagging data, what data is important to tag, etc.  I have a good grasp on the business needs, but I am nervous about missing the low hanging fruit while in the early stages of design.\n\n&amp;#x200B;\n\nThanks for the suggestions!", "author_fullname": "t2_yrcdh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for learning how to do DB design with AI-centric tagging/annotating as a priority", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15banxs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690485405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I am going to be designing a DB soon for a medium sized business and other than the foundational tenets of DB design, I was hoping for book suggestions/courses on curating good training data.  What are some pitfalls that I need to know about, how should I be tagging data, what data is important to tag, etc.  I have a good grasp on the business needs, but I am nervous about missing the low hanging fruit while in the early stages of design.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for the suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15banxs", "is_robot_indexable": true, "report_reasons": null, "author": "TylerP3358", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15banxs/resources_for_learning_how_to_do_db_design_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15banxs/resources_for_learning_how_to_do_db_design_with/", "subreddit_subscribers": 118699, "created_utc": 1690485405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Reddit \ud83d\udc4b\n\nData documentation is still too messy. Editing YAML files is tedious and oftentimes when teams buy data cataloging tools they are faced with sparse and out of date documentation.\n\nI'm excited to show an early preview of a my new vs code extension - Docs Composer \u2728 for dbt core.\n\n  \nRead &amp; edit your dbt model docs side-by-side as you develop and leverage our AI assistant to help write a first draft for you.  \n\n\nIt's free and takes 30 seconds to get started. Reach out if you'd like to try it out!\n\n&amp;#x200B;\n\nhttps://reddit.com/link/15b5uxb/video/hjboe9u17jeb1/player", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a vs code extension to help write dbt docs for you", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hjboe9u17jeb1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/15b5uxb/asset/hjboe9u17jeb1/DASHPlaylist.mpd?a=1693150690%2CYjk3OTgyNzE2MmEwYTczYjQ5ZjFmMWU4ZjU0YTRjZjc5ODJjYzdlNGQwYWE4NGM5N2M1YzlhNWE3Y2QwNWRkNw%3D%3D&amp;v=1&amp;f=sd", "x": 1328, "y": 1080, "hlsUrl": "https://v.redd.it/link/15b5uxb/asset/hjboe9u17jeb1/HLSPlaylist.m3u8?a=1693150690%2CZTdjZGY2NTZmZTUxNmJjM2UzNWJiYTkxNjE0OTk0M2IzMTlhNmEwYmQ4MTYyODZmMjFkY2U3ZWUxMTEzZWNjMA%3D%3D&amp;v=1&amp;f=sd", "id": "hjboe9u17jeb1", "isGif": false}}, "name": "t3_15b5uxb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690474026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Reddit \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;Data documentation is still too messy. Editing YAML files is tedious and oftentimes when teams buy data cataloging tools they are faced with sparse and out of date documentation.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited to show an early preview of a my new vs code extension - Docs Composer \u2728 for dbt core.&lt;/p&gt;\n\n&lt;p&gt;Read &amp;amp; edit your dbt model docs side-by-side as you develop and leverage our AI assistant to help write a first draft for you.  &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s free and takes 30 seconds to get started. Reach out if you&amp;#39;d like to try it out!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/15b5uxb/video/hjboe9u17jeb1/player\"&gt;https://reddit.com/link/15b5uxb/video/hjboe9u17jeb1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15b5uxb", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15b5uxb/building_a_vs_code_extension_to_help_write_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15b5uxb/building_a_vs_code_extension_to_help_write_dbt/", "subreddit_subscribers": 118699, "created_utc": 1690474026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, \n\nIm preparing for azure dp -203 certification and I really want to practice services in azure. Due to some work issue I was not able to make use of $200 credits free trial, now it is over and asking for pay as u go subscription and here in this subscription it is charging amount for some of the resources, I hardly practiced anything. I need to practice different resources required for data engineering and do some projects which would help to get a job. I don't even have student id. May I please please know is there any other way we can access azure resources for free. \n\nI have already wasted most of my time is searching how can I acess free subscription to practice.\nIt would be really helpful if I get some tips here. \n\nThank you.", "author_fullname": "t2_adz0yno6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get free azure subscription(I do t have student id and by 1 month free trial credits are over)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15bzh0d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690555538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, &lt;/p&gt;\n\n&lt;p&gt;Im preparing for azure dp -203 certification and I really want to practice services in azure. Due to some work issue I was not able to make use of $200 credits free trial, now it is over and asking for pay as u go subscription and here in this subscription it is charging amount for some of the resources, I hardly practiced anything. I need to practice different resources required for data engineering and do some projects which would help to get a job. I don&amp;#39;t even have student id. May I please please know is there any other way we can access azure resources for free. &lt;/p&gt;\n\n&lt;p&gt;I have already wasted most of my time is searching how can I acess free subscription to practice.\nIt would be really helpful if I get some tips here. &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15bzh0d", "is_robot_indexable": true, "report_reasons": null, "author": "Brunda_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bzh0d/how_to_get_free_azure_subscriptioni_do_t_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bzh0d/how_to_get_free_azure_subscriptioni_do_t_have/", "subreddit_subscribers": 118699, "created_utc": 1690555538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi yall,\n\nCan you please help me list out concepts I need to review for this job? This is supposed a entry level job but I am a little overwhelmed by the requirements but I know if I prepare well I can do this!. Sending help!!\n\nQualifications\n\u2022\nBachelors Degree in Computer Science, Information Technology or other relevant field\n\u2022\nAt least 1 to 3 years of recent experience in Software Engineering, Data Engineering or Big Data\n\u2022\nAbility to work effectively within a team in a fast-paced changing environment\n\u2022\nSoftware development experience, ideally in Python, Spark, Kafka or Go, and a willingness to learn new software development languages to meet goals and objectives\n\u2022\nKnowledge of strategies for processing large amounts of structured and unstructured data, including integrating data from multiple sources\n\u2022\nKnowledge of data cleaning, wrangling, visualization and reporting\n\u2022\nAbility to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and experience\n\u2022\nExposure to databases, BI applications, data quality and performance tuning\n\u2022\nExcellent written, verbal and listening communication skills\nResponsibilities\n\u2022\nThe candidate will be responsible for big data engineering, data wrangling, and data analysis in the Cloud\n\u2022\nThe role will also contribute to defining and implementing Big Data Strategy for the organization along with driving implementation of IT solutions for the business\n\u2022\nCandidate will be working with other data engineers and data scientists to focus on applying data engineering, data science and machine learning approaches to solve business problems\n\u2022\nCollect and process raw data at scale for a variety of projects and initiatives\n\u2022\nCreate and maintain optimal data pipeline architecture by designing and implementing data ingestion solutions on AWS using AWS native services\n\u2022\nDesign and optimize data models on AWS Cloud using AWS data stores such as Redshift, RDS, S3\n\u2022\nIntegrate and assemble large, complex data sets that meet a broad range of business requirements\n\u2022\nDesign and develop data applications using selected tools and frameworks as required and requested for a variety of projects and initiatives\n\u2022\nRead, extract, transform, stage and load data to selected tools and frameworks as required and requested\n\u2022\nMonitoring and optimizing data performance\n\u2022\nCustomizing and managing integration tools, databases, warehouses, and analytical systems\n\u2022\nProcess unstructured data into a form suitable for analysis and assist in analysis of the processed data\n\u2022\nWorking directly with the technology and engineering teams to integrate data processing and business objectives\n\u2022\nEnsure performance, uptime, and scale, maintaining high standards of code quality and thoughtful design", "author_fullname": "t2_4y2z0em", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What concepts do I need to review for this JD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15bz9ia", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690555055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi yall,&lt;/p&gt;\n\n&lt;p&gt;Can you please help me list out concepts I need to review for this job? This is supposed a entry level job but I am a little overwhelmed by the requirements but I know if I prepare well I can do this!. Sending help!!&lt;/p&gt;\n\n&lt;p&gt;Qualifications\n\u2022\nBachelors Degree in Computer Science, Information Technology or other relevant field\n\u2022\nAt least 1 to 3 years of recent experience in Software Engineering, Data Engineering or Big Data\n\u2022\nAbility to work effectively within a team in a fast-paced changing environment\n\u2022\nSoftware development experience, ideally in Python, Spark, Kafka or Go, and a willingness to learn new software development languages to meet goals and objectives\n\u2022\nKnowledge of strategies for processing large amounts of structured and unstructured data, including integrating data from multiple sources\n\u2022\nKnowledge of data cleaning, wrangling, visualization and reporting\n\u2022\nAbility to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and experience\n\u2022\nExposure to databases, BI applications, data quality and performance tuning\n\u2022\nExcellent written, verbal and listening communication skills\nResponsibilities\n\u2022\nThe candidate will be responsible for big data engineering, data wrangling, and data analysis in the Cloud\n\u2022\nThe role will also contribute to defining and implementing Big Data Strategy for the organization along with driving implementation of IT solutions for the business\n\u2022\nCandidate will be working with other data engineers and data scientists to focus on applying data engineering, data science and machine learning approaches to solve business problems\n\u2022\nCollect and process raw data at scale for a variety of projects and initiatives\n\u2022\nCreate and maintain optimal data pipeline architecture by designing and implementing data ingestion solutions on AWS using AWS native services\n\u2022\nDesign and optimize data models on AWS Cloud using AWS data stores such as Redshift, RDS, S3\n\u2022\nIntegrate and assemble large, complex data sets that meet a broad range of business requirements\n\u2022\nDesign and develop data applications using selected tools and frameworks as required and requested for a variety of projects and initiatives\n\u2022\nRead, extract, transform, stage and load data to selected tools and frameworks as required and requested\n\u2022\nMonitoring and optimizing data performance\n\u2022\nCustomizing and managing integration tools, databases, warehouses, and analytical systems\n\u2022\nProcess unstructured data into a form suitable for analysis and assist in analysis of the processed data\n\u2022\nWorking directly with the technology and engineering teams to integrate data processing and business objectives\n\u2022\nEnsure performance, uptime, and scale, maintaining high standards of code quality and thoughtful design&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15bz9ia", "is_robot_indexable": true, "report_reasons": null, "author": "buianhthy1412", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bz9ia/what_concepts_do_i_need_to_review_for_this_jd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bz9ia/what_concepts_do_i_need_to_review_for_this_jd/", "subreddit_subscribers": 118699, "created_utc": 1690555055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, here's the situation:\n\n4 years ago I started as an intern in a small company, and then just leveled up there to senior DE.\n\nSince I was an intern obviously there wasn't a technical interview, just a couple \"let's know each other\" talks with HR and the hiring manager.\n\nRecently I interviewed with another company, another small one, which is looking for a senior DE to move forward their data endeavors (they don't have a dedicated data team yet).\n\nThe first interview was with their tech lead, who just today confirmed we're moving forward, and the next interview will be a technical one, with the tech lead + another SWE at their company.\n\nI really have no idea WTF to expect. I am confident in my skills, but I also know I don't really perform well in an \"exam setting\", so I'm afraid my brain will freeze.\n\nAny advice you have is more than welcome", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First technical interview with another company, not sure what to expect. Advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15byxaz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690554274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, here&amp;#39;s the situation:&lt;/p&gt;\n\n&lt;p&gt;4 years ago I started as an intern in a small company, and then just leveled up there to senior DE.&lt;/p&gt;\n\n&lt;p&gt;Since I was an intern obviously there wasn&amp;#39;t a technical interview, just a couple &amp;quot;let&amp;#39;s know each other&amp;quot; talks with HR and the hiring manager.&lt;/p&gt;\n\n&lt;p&gt;Recently I interviewed with another company, another small one, which is looking for a senior DE to move forward their data endeavors (they don&amp;#39;t have a dedicated data team yet).&lt;/p&gt;\n\n&lt;p&gt;The first interview was with their tech lead, who just today confirmed we&amp;#39;re moving forward, and the next interview will be a technical one, with the tech lead + another SWE at their company.&lt;/p&gt;\n\n&lt;p&gt;I really have no idea WTF to expect. I am confident in my skills, but I also know I don&amp;#39;t really perform well in an &amp;quot;exam setting&amp;quot;, so I&amp;#39;m afraid my brain will freeze.&lt;/p&gt;\n\n&lt;p&gt;Any advice you have is more than welcome&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15byxaz", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15byxaz/first_technical_interview_with_another_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15byxaz/first_technical_interview_with_another_company/", "subreddit_subscribers": 118699, "created_utc": 1690554274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I see there are posts every week about database certifications and such.  I compiled a list late last year which I'm sharing below.  Please let me know of any that I have missed.  Or any dead links and wrong information for that matter.  Certifications are in the eye of the beholder; some employers value them, and others don't.\n\nHere is a link if you want to bookmark my most recent list.\n\n [Database Certification List - Advanced SQL Puzzles](https://advancedsqlpuzzles.com/2022/11/18/database-certification-list/) \n\n**And below is just a copy and paste from the above link.**\n\nEnjoy!!\n\n\\-------------------------------------------------------------------------------------------\n\n[**Microsoft**](https://learn.microsoft.com/en-us/certifications/)\n\nMicrosoft has unfortunately sunsetted its SQL Developer focused certifications ([70-761](https://learn.microsoft.com/en-us/certifications/exams/70-761) and [70-762](https://learn.microsoft.com/en-us/certifications/exams/70-762)) and is focusing on role-based cloud certifications.\u00a0\n\n* [DP-900: Microsoft Azure Data Fundamentals](https://learn.microsoft.com/en-us/certifications/exams/dp-900)\n* [Exam DP-203: Data Engineering on Microsoft Azure](https://learn.microsoft.com/en-us/certifications/exams/dp-203)\n* [Exam DP-300: Administering Microsoft Azure SQL Solutions](https://learn.microsoft.com/en-us/certifications/exams/dp-300)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Amazon**](https://aws.amazon.com/certification/)\n\nAmazon offers the following database certification.\n\n* [AWS Certified Database \u2013 Specialty exam (DBS-C01)](https://aws.amazon.com/certification/certified-database-specialty/)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Google**](https://cloud.google.com/certification)\n\nAnd let\u2019s not forget about Google and their cloud platform.\n\n* [Professional Cloud Database Engineer](https://cloud.google.com/certification/cloud-database-engineer)\n* [Professional Data Engineer](https://cloud.google.com/certification/data-engineer)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Oracle**](https://education.oracle.com/certification)\n\nOracle has numerous certifications ranging from high availability to administration to development. Here are a couple that I recommend. The 1Z0-149 is absurdly difficult, btw.\n\n* [Oracle Database SQL Certified Associate Certification (1Z0-071)](https://education.oracle.com/oracle-database-sql-certified-associate/trackp_457)\n* [Oracle Database PL/SQL Developer Certified Professional (1Z0-149)](https://education.oracle.com/oracle-database-pl-sql-developer-certified-professional/trackp_OCPPLSQL19C)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**MySQL**](https://education.oracle.com/certification)\n\nOracle also offers MySQL certifications as it purchased Sun Microsystems in 2010.\n\nMySQL is free and open-source software under the terms of the GNU General Public License, and is also available under a variety of proprietary licenses. MySQL was owned and sponsored by the Swedish company MySQL AB, which was bought by Sun Microsystems (now Oracle Corporation).\n\n* [MySQL 8.0 Database Developer Oracle Certified Professional (1Z0-909)](https://education.oracle.com/mysql-80-database-developer-oracle-certified-professional/trackp_MYSQLPRG80OCP)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**MariaDB**](https://education.oracle.com/certification)\n\nMariaDB is a popular open-source relational database management system (RDBMS) that was initially developed as a fork of MySQL by the original developers of MySQL. It was created in response to concerns over Oracle\u2019s acquisition of MySQL in 2010 and its potential impact on the open-source nature of the MySQL project.\n\nMariaDB offers a database administrator exam, but not a developer exam.\n\n* [MariaDB Certification Exam](https://mariadb.com/wp-content/uploads/2019/02/mariadb-certification-exam_datasheet_1005.pdf)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**PostgreSQL**](https://www.enterprisedb.com/)\n\nPostgreSQL is a free and open-source relational database management system emphasizing extensibility and SQL compliance. Because it is open-source, there are no vendor certifications, but there is a company called [EDB ](https://www.enterprisedb.com/)that offers solutions, training, and certifications for PostgreSQL. Their [certifications](https://www.enterprisedb.com/training/postgres-certification) appear to be focused on the DBA side.\n\n* [PostgreSQL 12 Associate Certification](https://www.enterprisedb.com/course/postgresql-12-associate-certification)\n* [PostgreSQL 12 Professional Certification](https://www.enterprisedb.com/training/postgres-certification)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**IBM**](https://www.ibm.com/training/credentials/)\n\nDB2 is a set of relational database products offered by IBM that traces its root all the way back to the 1970s. Currently IBM appears to be withdrawing many of its DB2 certifications and issuing new certification exams. The following appears to be the only DB2 exam currently offered, which is more DBA focused.\n\n* [Exam C1000-122: Db2 12 for z/OS DBA Fundamentals](https://www.ibm.com/training/certification/C8003803)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Databricks**](https://www.databricks.com/learn/certification#certifications)\n\nDatabricks offers an associate and professional level data engineering certifications. These are great resources for understanding the product features.\n\n* [Databricks Certified Data Engineer Associate](https://www.databricks.com/learn/certification/data-engineer-associate)\n* [Databricks Certified Data Engineer Professional](https://www.databricks.com/learn/certification/data-engineer-professional)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Snowflake**](https://www.snowflake.com/certifications/)\n\nSnowflake is a fully managed multi-cluster shared data architecture platform that capitalizes on the resources of the cloud. The SnowPro Core certification highlights the product features the best.\n\n* [\\[COF-C02\\] SnowPro Core Certification](https://learn.snowflake.com/courses/course-v1:snowflake+CERT-SPC-GUIDE+B/about?_ga=2.109990149.1818508944.1668788648-1953636227.1655820550)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Teradata**](https://www.teradata.com/University/Certification)\n\nTeradata (formed in 1979) provides cloud database and analytics-related software, products, and services.\n\n* [Vantage Certified Associate Exam 2.3 (TDVAN1)](https://www.teradata.com/University/Certification/Vantage-Certifications/Associate-Exam-2-3)\n* [Vantage Data Engineering Exam (TDVAN4)](https://www.teradata.com/University/Certification/Vantage-Certifications/Data-Engineering-Exam)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**MongoDB**](https://university.mongodb.com/certification?_ga=2.155916475.143515463.1668790358-1726176162.1668790358)\n\nMongoDB is a source-available cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with optional schemas. MongoDB is developed by MongoDB Inc. and licensed under the Server Side Public License which is deemed non-free by several distributions.\n\nIt appears MongoDB offers certifications tailored to various languages like C#, Java, Python and Node.js.\n\n* [MongoDB Associate Developer Exam](https://learn.mongodb.com/pages/mongodb-associate-developer-exam?_ga=2.155876411.143515463.1668790358-1726176162.1668790358)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**SAP HANA**](https://training.sap.com/certification/)\n\nSAP HANA (High-performance ANalytic Appliance) is a multi-model database that stores data in its memory instead of keeping it on a disk. There are a number of HANA certifications that you can choose from. The following appears to be the most SQL focused.\n\n* [SAP Certified Development Associate \u2013 SAP HANA 2.0 SPS05](https://training.sap.com/certification/c_hanadev_17-sap-certified-development-associate---sap-hana-20-sps05-g/)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n**Below are a few vendor neutral certifications that you may be interest in.**\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**CIW Database Design Specialist**](https://ciwcertified.com/ciw-certifications)\n\nCIW has vendor neutral IT certifications focusing on web professionals, but it does offer a Database Design Specialist certification. This certification focuses on concepts such as the relational model, relational algebra, design, modeling, and the SQL language. The [study guide for the exam](https://www.amazon.com/Study-Guide-1D0-541-Specialist-Certification/dp/1941404073) is a great encapsulation of many database concepts that we should all know.\n\n* [1D0-541: CIW Database Design Specialist](https://ciwcertified.com/ciw-certifications/web-development-series/database-design-specialist)\n\n[**ICCP**](https://iccp.org/index.html)\n\nThe Institute for the Certification of Computing Professionals (ICCP) is a non-profit (501(c)(6)) institution for professional certification in the Computer engineering and Information technology industry. It was founded in 1973 by 8 professional computer societies to promote certification and professionalism in the industry, lower the cost of development and administration of certification for all of the societies and act as the central resource for job standards and performance criteria.\n\nHere are a couple of their certifications that may be of intetest\n\n* [Certified Data Professional (CDP)](https://iccp.org/certified-data-professional-cdp.html)\n* [Certified Big Data Professional (CBDP)](https://iccp.org/certified-big-data-professional.html)\n\n[**DAMA International**](https://cdmp.info/)\n\nCertified Data Management Professional (CDMP) is a globally recognized Data Management Certification program run by DAMA International.\n\nThis exam is centered around [DMBOK ](https://www.dama.org/cpages/body-of-knowledge)and is geared more towards Data Management and Data Governance.\n\n* [About CDMP \u2013 Certified Data Management Professionals](https://cdmp.info/about/)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n**Below are a few educational websites that advertise certifications, but these (most probably) do not meet the stricter guidelines of the above certifications. Regardless, they may be a good option for students beginning their learning path.**\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**W3 Schools**](https://campus.w3schools.com/collections/course-catalog)\n\nW3Schools is a freemium educational website for learning coding online. Initially released in 1998, it derives its name from the World Wide Web but is not affiliated with the W3 Consortium. W3Schools offers courses covering all aspects of web development.\n\n* [Certified SQL Developer](https://campus.w3schools.com/collections/course-catalog/products/sql-course)\n\n[**Datacamp**](https://www.datacamp.com/certification)\n\nDataCamp is\u00a0an online learning platform that helps students build data skills at their own pace.\n\n* [Data Analyst Certification](https://www.datacamp.com/certification/data-analyst)\n* [Data Scientist Certification](https://www.datacamp.com/certification/data-scientist)\n\nYou have reached the end! Happy coding!", "author_fullname": "t2_4d58zyiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A List of Database Certifications Here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15bycwi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690552984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see there are posts every week about database certifications and such.  I compiled a list late last year which I&amp;#39;m sharing below.  Please let me know of any that I have missed.  Or any dead links and wrong information for that matter.  Certifications are in the eye of the beholder; some employers value them, and others don&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;Here is a link if you want to bookmark my most recent list.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://advancedsqlpuzzles.com/2022/11/18/database-certification-list/\"&gt;Database Certification List - Advanced SQL Puzzles&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;And below is just a copy and paste from the above link.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Enjoy!!&lt;/p&gt;\n\n&lt;p&gt;-------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/certifications/\"&gt;&lt;strong&gt;Microsoft&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Microsoft has unfortunately sunsetted its SQL Developer focused certifications (&lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/70-761\"&gt;70-761&lt;/a&gt; and &lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/70-762\"&gt;70-762&lt;/a&gt;) and is focusing on role-based cloud certifications.\u00a0&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/dp-900\"&gt;DP-900: Microsoft Azure Data Fundamentals&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/dp-203\"&gt;Exam DP-203: Data Engineering on Microsoft Azure&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/dp-300\"&gt;Exam DP-300: Administering Microsoft Azure SQL Solutions&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://aws.amazon.com/certification/\"&gt;&lt;strong&gt;Amazon&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Amazon offers the following database certification.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://aws.amazon.com/certification/certified-database-specialty/\"&gt;AWS Certified Database \u2013 Specialty exam (DBS-C01)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cloud.google.com/certification\"&gt;&lt;strong&gt;Google&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And let\u2019s not forget about Google and their cloud platform.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://cloud.google.com/certification/cloud-database-engineer\"&gt;Professional Cloud Database Engineer&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://cloud.google.com/certification/data-engineer\"&gt;Professional Data Engineer&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://education.oracle.com/certification\"&gt;&lt;strong&gt;Oracle&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Oracle has numerous certifications ranging from high availability to administration to development. Here are a couple that I recommend. The 1Z0-149 is absurdly difficult, btw.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://education.oracle.com/oracle-database-sql-certified-associate/trackp_457\"&gt;Oracle Database SQL Certified Associate Certification (1Z0-071)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://education.oracle.com/oracle-database-pl-sql-developer-certified-professional/trackp_OCPPLSQL19C\"&gt;Oracle Database PL/SQL Developer Certified Professional (1Z0-149)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://education.oracle.com/certification\"&gt;&lt;strong&gt;MySQL&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Oracle also offers MySQL certifications as it purchased Sun Microsystems in 2010.&lt;/p&gt;\n\n&lt;p&gt;MySQL is free and open-source software under the terms of the GNU General Public License, and is also available under a variety of proprietary licenses. MySQL was owned and sponsored by the Swedish company MySQL AB, which was bought by Sun Microsystems (now Oracle Corporation).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://education.oracle.com/mysql-80-database-developer-oracle-certified-professional/trackp_MYSQLPRG80OCP\"&gt;MySQL 8.0 Database Developer Oracle Certified Professional (1Z0-909)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://education.oracle.com/certification\"&gt;&lt;strong&gt;MariaDB&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;MariaDB is a popular open-source relational database management system (RDBMS) that was initially developed as a fork of MySQL by the original developers of MySQL. It was created in response to concerns over Oracle\u2019s acquisition of MySQL in 2010 and its potential impact on the open-source nature of the MySQL project.&lt;/p&gt;\n\n&lt;p&gt;MariaDB offers a database administrator exam, but not a developer exam.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://mariadb.com/wp-content/uploads/2019/02/mariadb-certification-exam_datasheet_1005.pdf\"&gt;MariaDB Certification Exam&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.enterprisedb.com/\"&gt;&lt;strong&gt;PostgreSQL&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;PostgreSQL is a free and open-source relational database management system emphasizing extensibility and SQL compliance. Because it is open-source, there are no vendor certifications, but there is a company called &lt;a href=\"https://www.enterprisedb.com/\"&gt;EDB &lt;/a&gt;that offers solutions, training, and certifications for PostgreSQL. Their &lt;a href=\"https://www.enterprisedb.com/training/postgres-certification\"&gt;certifications&lt;/a&gt; appear to be focused on the DBA side.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.enterprisedb.com/course/postgresql-12-associate-certification\"&gt;PostgreSQL 12 Associate Certification&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.enterprisedb.com/training/postgres-certification\"&gt;PostgreSQL 12 Professional Certification&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ibm.com/training/credentials/\"&gt;&lt;strong&gt;IBM&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;DB2 is a set of relational database products offered by IBM that traces its root all the way back to the 1970s. Currently IBM appears to be withdrawing many of its DB2 certifications and issuing new certification exams. The following appears to be the only DB2 exam currently offered, which is more DBA focused.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.ibm.com/training/certification/C8003803\"&gt;Exam C1000-122: Db2 12 for z/OS DBA Fundamentals&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/learn/certification#certifications\"&gt;&lt;strong&gt;Databricks&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Databricks offers an associate and professional level data engineering certifications. These are great resources for understanding the product features.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.databricks.com/learn/certification/data-engineer-associate\"&gt;Databricks Certified Data Engineer Associate&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.databricks.com/learn/certification/data-engineer-professional\"&gt;Databricks Certified Data Engineer Professional&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.snowflake.com/certifications/\"&gt;&lt;strong&gt;Snowflake&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Snowflake is a fully managed multi-cluster shared data architecture platform that capitalizes on the resources of the cloud. The SnowPro Core certification highlights the product features the best.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://learn.snowflake.com/courses/course-v1:snowflake+CERT-SPC-GUIDE+B/about?_ga=2.109990149.1818508944.1668788648-1953636227.1655820550\"&gt;[COF-C02] SnowPro Core Certification&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.teradata.com/University/Certification\"&gt;&lt;strong&gt;Teradata&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Teradata (formed in 1979) provides cloud database and analytics-related software, products, and services.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.teradata.com/University/Certification/Vantage-Certifications/Associate-Exam-2-3\"&gt;Vantage Certified Associate Exam 2.3 (TDVAN1)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.teradata.com/University/Certification/Vantage-Certifications/Data-Engineering-Exam\"&gt;Vantage Data Engineering Exam (TDVAN4)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://university.mongodb.com/certification?_ga=2.155916475.143515463.1668790358-1726176162.1668790358\"&gt;&lt;strong&gt;MongoDB&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;MongoDB is a source-available cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with optional schemas. MongoDB is developed by MongoDB Inc. and licensed under the Server Side Public License which is deemed non-free by several distributions.&lt;/p&gt;\n\n&lt;p&gt;It appears MongoDB offers certifications tailored to various languages like C#, Java, Python and Node.js.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://learn.mongodb.com/pages/mongodb-associate-developer-exam?_ga=2.155876411.143515463.1668790358-1726176162.1668790358\"&gt;MongoDB Associate Developer Exam&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://training.sap.com/certification/\"&gt;&lt;strong&gt;SAP HANA&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;SAP HANA (High-performance ANalytic Appliance) is a multi-model database that stores data in its memory instead of keeping it on a disk. There are a number of HANA certifications that you can choose from. The following appears to be the most SQL focused.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://training.sap.com/certification/c_hanadev_17-sap-certified-development-associate---sap-hana-20-sps05-g/\"&gt;SAP Certified Development Associate \u2013 SAP HANA 2.0 SPS05&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Below are a few vendor neutral certifications that you may be interest in.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ciwcertified.com/ciw-certifications\"&gt;&lt;strong&gt;CIW Database Design Specialist&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;CIW has vendor neutral IT certifications focusing on web professionals, but it does offer a Database Design Specialist certification. This certification focuses on concepts such as the relational model, relational algebra, design, modeling, and the SQL language. The &lt;a href=\"https://www.amazon.com/Study-Guide-1D0-541-Specialist-Certification/dp/1941404073\"&gt;study guide for the exam&lt;/a&gt; is a great encapsulation of many database concepts that we should all know.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://ciwcertified.com/ciw-certifications/web-development-series/database-design-specialist\"&gt;1D0-541: CIW Database Design Specialist&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://iccp.org/index.html\"&gt;&lt;strong&gt;ICCP&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The Institute for the Certification of Computing Professionals (ICCP) is a non-profit (501(c)(6)) institution for professional certification in the Computer engineering and Information technology industry. It was founded in 1973 by 8 professional computer societies to promote certification and professionalism in the industry, lower the cost of development and administration of certification for all of the societies and act as the central resource for job standards and performance criteria.&lt;/p&gt;\n\n&lt;p&gt;Here are a couple of their certifications that may be of intetest&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://iccp.org/certified-data-professional-cdp.html\"&gt;Certified Data Professional (CDP)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://iccp.org/certified-big-data-professional.html\"&gt;Certified Big Data Professional (CBDP)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://cdmp.info/\"&gt;&lt;strong&gt;DAMA International&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Certified Data Management Professional (CDMP) is a globally recognized Data Management Certification program run by DAMA International.&lt;/p&gt;\n\n&lt;p&gt;This exam is centered around &lt;a href=\"https://www.dama.org/cpages/body-of-knowledge\"&gt;DMBOK &lt;/a&gt;and is geared more towards Data Management and Data Governance.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://cdmp.info/about/\"&gt;About CDMP \u2013 Certified Data Management Professionals&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Below are a few educational websites that advertise certifications, but these (most probably) do not meet the stricter guidelines of the above certifications. Regardless, they may be a good option for students beginning their learning path.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://campus.w3schools.com/collections/course-catalog\"&gt;&lt;strong&gt;W3 Schools&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;W3Schools is a freemium educational website for learning coding online. Initially released in 1998, it derives its name from the World Wide Web but is not affiliated with the W3 Consortium. W3Schools offers courses covering all aspects of web development.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://campus.w3schools.com/collections/course-catalog/products/sql-course\"&gt;Certified SQL Developer&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacamp.com/certification\"&gt;&lt;strong&gt;Datacamp&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;DataCamp is\u00a0an online learning platform that helps students build data skills at their own pace.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.datacamp.com/certification/data-analyst\"&gt;Data Analyst Certification&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.datacamp.com/certification/data-scientist\"&gt;Data Scientist Certification&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You have reached the end! Happy coding!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15bycwi", "is_robot_indexable": true, "report_reasons": null, "author": "sequel-beagle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bycwi/a_list_of_database_certifications_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bycwi/a_list_of_database_certifications_here/", "subreddit_subscribers": 118699, "created_utc": 1690552984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data analyst slowly transitioning into data engineering. I have good knowledge of python modules related to data analysis.\n\nNow, our vendor has provided APIs to request data. For example, let's say there is a sales API. The API format is such that I will have to enter date_1 and date_2 to get sales from date_1 to date_2.\n\nwww.dumnyurl.com/saleslines/date_1/date_2\n\nI want to create a dashboard or interface where I can have the end user enter date_1 and date_2 and then a button to retrieve the data. \n\nMy org. currently have powerbi but there doesn't seem to be this functionality in powerbi. I also read about using dash, but how would I be able to provide access to the dashboard to only people in my organisation and stop outside access. Can something low cost be done on Azure cloud for this?\n\nI was just wondering if anyone has worked on something like this before or if there are any recommended solutions.", "author_fullname": "t2_t05ji4fs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Options for creating an end user interface for an API call", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bx2hn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690549841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst slowly transitioning into data engineering. I have good knowledge of python modules related to data analysis.&lt;/p&gt;\n\n&lt;p&gt;Now, our vendor has provided APIs to request data. For example, let&amp;#39;s say there is a sales API. The API format is such that I will have to enter date_1 and date_2 to get sales from date_1 to date_2.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.dumnyurl.com/saleslines/date_1/date_2\"&gt;www.dumnyurl.com/saleslines/date_1/date_2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I want to create a dashboard or interface where I can have the end user enter date_1 and date_2 and then a button to retrieve the data. &lt;/p&gt;\n\n&lt;p&gt;My org. currently have powerbi but there doesn&amp;#39;t seem to be this functionality in powerbi. I also read about using dash, but how would I be able to provide access to the dashboard to only people in my organisation and stop outside access. Can something low cost be done on Azure cloud for this?&lt;/p&gt;\n\n&lt;p&gt;I was just wondering if anyone has worked on something like this before or if there are any recommended solutions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15bx2hn", "is_robot_indexable": true, "report_reasons": null, "author": "kkchn001", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bx2hn/options_for_creating_an_end_user_interface_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bx2hn/options_for_creating_an_end_user_interface_for_an/", "subreddit_subscribers": 118699, "created_utc": 1690549841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First of all, I am from Mexico with 9 years in the data world. SQL, Python, Pyspark, Pandas, (trying polars), Airflow, Autosys, Linux, EC2, EKS, Git, Graphana and other stuff that is not related to modern Data Engineering (SSIS, C#, etc)\n\n&amp;#x200B;\n\nI was in a US based company working for 6 years and got tons of experience but my salary was very low, so I tried to do some freelancing and then I found a job as Data Engineer. When I entered, they told me, lol just joking, you have to do some reports in Excel.I only stood there 3 weeks until another company where I had a process ongoing called me to offer me also a Data Engineer position and more salary and I said, sure.\n\n&amp;#x200B;\n\nIt's been 1 year since I am in that company and again, the only thing for data is that I use SQL but I do not build pipelines, I do not do analysis or even automate process. Just manually insert data (around 1 record per week) and answer some tech support tickets. Of course I have been trying to find another job related to Data Engineer but the thing is the salary is way worse than before. I got hired during the pandemic and nowadays they are offering like half of what I am currently making and they do not believe my current salary.\n\nThe interviews had been a mess, either they ghost me, they tell me that they can only offer half of what I am asking or they expect me to do some insane stuff and either they just ghost me again, or at the end they offer me even less money. One example, for a Data Engineer position, they requested to build a API using docker that can insert and query data, they told me that I have only 2 hours to do it and they never said me to download stuff in my personal computer to do it. I was able to make it using FastAPI and they were really surprised that I was able to do it in such a short time, but then they started to lowball me, like 30% less of what I accepted on the first negotiation.\n\nI see a lot of success stories here but it seems it only applies for US or some european countries but here is hard. I am thinking of applying directly to US companies but I haven't found a way to do it, I tried LinkedIn but also no luck there. Is there any place for folks like us that don't live in countries with good jobs for Data Engineering?", "author_fullname": "t2_gdhxcn2h6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there something wrong by applying in my country?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bkwnl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690511320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, I am from Mexico with 9 years in the data world. SQL, Python, Pyspark, Pandas, (trying polars), Airflow, Autosys, Linux, EC2, EKS, Git, Graphana and other stuff that is not related to modern Data Engineering (SSIS, C#, etc)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was in a US based company working for 6 years and got tons of experience but my salary was very low, so I tried to do some freelancing and then I found a job as Data Engineer. When I entered, they told me, lol just joking, you have to do some reports in Excel.I only stood there 3 weeks until another company where I had a process ongoing called me to offer me also a Data Engineer position and more salary and I said, sure.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s been 1 year since I am in that company and again, the only thing for data is that I use SQL but I do not build pipelines, I do not do analysis or even automate process. Just manually insert data (around 1 record per week) and answer some tech support tickets. Of course I have been trying to find another job related to Data Engineer but the thing is the salary is way worse than before. I got hired during the pandemic and nowadays they are offering like half of what I am currently making and they do not believe my current salary.&lt;/p&gt;\n\n&lt;p&gt;The interviews had been a mess, either they ghost me, they tell me that they can only offer half of what I am asking or they expect me to do some insane stuff and either they just ghost me again, or at the end they offer me even less money. One example, for a Data Engineer position, they requested to build a API using docker that can insert and query data, they told me that I have only 2 hours to do it and they never said me to download stuff in my personal computer to do it. I was able to make it using FastAPI and they were really surprised that I was able to do it in such a short time, but then they started to lowball me, like 30% less of what I accepted on the first negotiation.&lt;/p&gt;\n\n&lt;p&gt;I see a lot of success stories here but it seems it only applies for US or some european countries but here is hard. I am thinking of applying directly to US companies but I haven&amp;#39;t found a way to do it, I tried LinkedIn but also no luck there. Is there any place for folks like us that don&amp;#39;t live in countries with good jobs for Data Engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15bkwnl", "is_robot_indexable": true, "report_reasons": null, "author": "DataSenpai", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bkwnl/is_there_something_wrong_by_applying_in_my_country/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bkwnl/is_there_something_wrong_by_applying_in_my_country/", "subreddit_subscribers": 118699, "created_utc": 1690511320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "SQL Server shop here moving to Databricks with Unity Catalog. We've started to curate data in Databricks and we are getting column to column level lineage captured at transform. I'm expecting this to be game changimg for us. Anyone else getting many to many column level linage like this with other stacks?", "author_fullname": "t2_4cuwr0py", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Column to column lineage at transform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bd12s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690490853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SQL Server shop here moving to Databricks with Unity Catalog. We&amp;#39;ve started to curate data in Databricks and we are getting column to column level lineage captured at transform. I&amp;#39;m expecting this to be game changimg for us. Anyone else getting many to many column level linage like this with other stacks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15bd12s", "is_robot_indexable": true, "report_reasons": null, "author": "chcahx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bd12s/column_to_column_lineage_at_transform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bd12s/column_to_column_lineage_at_transform/", "subreddit_subscribers": 118699, "created_utc": 1690490853.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}