{"kind": "Listing", "data": {"after": "t3_154b2jo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As the title implies, I would like to set up a dead man's switch in the case of my eventual, unpredicted demise.\n\nI do not have anything to hide, but I simply can't stomach the thought of someone having access to my accounts and private data once I am gone, not even my immediate family. I see those as an extension of my online footprint and wouldn't be able to die in peace knowing some random might access my accounts and the interactions I've had throughout the years.\n\nHow should I approach this feat? Any suggestions?\n\nEdit: Thanks everyone for the replies, I shall look into the suggestions made.", "author_fullname": "t2_i7iqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dead Man's Switch - How to approach it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1548ugv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 122, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 122, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689860081.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689805199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title implies, I would like to set up a dead man&amp;#39;s switch in the case of my eventual, unpredicted demise.&lt;/p&gt;\n\n&lt;p&gt;I do not have anything to hide, but I simply can&amp;#39;t stomach the thought of someone having access to my accounts and private data once I am gone, not even my immediate family. I see those as an extension of my online footprint and wouldn&amp;#39;t be able to die in peace knowing some random might access my accounts and the interactions I&amp;#39;ve had throughout the years.&lt;/p&gt;\n\n&lt;p&gt;How should I approach this feat? Any suggestions?&lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks everyone for the replies, I shall look into the suggestions made.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1548ugv", "is_robot_indexable": true, "report_reasons": null, "author": "Zeno1441", "discussion_type": null, "num_comments": 100, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1548ugv/dead_mans_switch_how_to_approach_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1548ugv/dead_mans_switch_how_to_approach_it/", "subreddit_subscribers": 693418, "created_utc": 1689805199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've recently started using MakeMKV to rip digital copies of some discs to free up physical storage space in my office.    \n\nOne of them is a 6-part series (one part on each disc). The first five ripped perfectly, no issues at all. The sixth one appears to be fine, but it just doesn't complete.    \n\nIt gets to the final stage \"Saving to MKV file\" and the progress bar is around 98% but it just stays there for hours on end. I don't get any error message or indication of what is happening.    \n\nHas anyone experienced this? Sorry for creating a thread here - I would have contained it to r/MakeMkv but the sub is still locked for the \"protest\". Thanks in advance.    \n\nHere is the full log from the current rip, which is still stuck at the end of the file creation stage:    \n\n&gt; MakeMKV v1.17.4 win(x64-release) started  \n&gt; Using direct disc access mode  \n&gt; Evaluation version, 27 day(s) out of 30 remaining  \n&gt; Loaded content hash table, will verify integrity of M2TS files.  \n&gt; File 00007.mpls was added as title #0  \n&gt; File 00006.mpls was added as title #1  \n&gt; File 00005.m2ts was added as title #2  \n&gt; File 00002.m2ts was added as title #3  \n&gt; File 00001.m2ts was added as title #4  \n&gt; File 00000.m2ts was added as title #5  \n&gt; File 00013.m2ts was added as title #6  \n&gt; Operation successfully completed  \n&gt; Saving 1 titles into directory D:/Video", "author_fullname": "t2_6l4yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having a problem with MakeMKV (and that sub is still locked)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154mevw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689846437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently started using MakeMKV to rip digital copies of some discs to free up physical storage space in my office.    &lt;/p&gt;\n\n&lt;p&gt;One of them is a 6-part series (one part on each disc). The first five ripped perfectly, no issues at all. The sixth one appears to be fine, but it just doesn&amp;#39;t complete.    &lt;/p&gt;\n\n&lt;p&gt;It gets to the final stage &amp;quot;Saving to MKV file&amp;quot; and the progress bar is around 98% but it just stays there for hours on end. I don&amp;#39;t get any error message or indication of what is happening.    &lt;/p&gt;\n\n&lt;p&gt;Has anyone experienced this? Sorry for creating a thread here - I would have contained it to &lt;a href=\"/r/MakeMkv\"&gt;r/MakeMkv&lt;/a&gt; but the sub is still locked for the &amp;quot;protest&amp;quot;. Thanks in advance.    &lt;/p&gt;\n\n&lt;p&gt;Here is the full log from the current rip, which is still stuck at the end of the file creation stage:    &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;MakeMKV v1.17.4 win(x64-release) started&lt;br/&gt;\nUsing direct disc access mode&lt;br/&gt;\nEvaluation version, 27 day(s) out of 30 remaining&lt;br/&gt;\nLoaded content hash table, will verify integrity of M2TS files.&lt;br/&gt;\nFile 00007.mpls was added as title #0&lt;br/&gt;\nFile 00006.mpls was added as title #1&lt;br/&gt;\nFile 00005.m2ts was added as title #2&lt;br/&gt;\nFile 00002.m2ts was added as title #3&lt;br/&gt;\nFile 00001.m2ts was added as title #4&lt;br/&gt;\nFile 00000.m2ts was added as title #5&lt;br/&gt;\nFile 00013.m2ts was added as title #6&lt;br/&gt;\nOperation successfully completed&lt;br/&gt;\nSaving 1 titles into directory D:/Video&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154mevw", "is_robot_indexable": true, "report_reasons": null, "author": "SundayRed", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154mevw/having_a_problem_with_makemkv_and_that_sub_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154mevw/having_a_problem_with_makemkv_and_that_sub_is/", "subreddit_subscribers": 693418, "created_utc": 1689846437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI am looking to migrate away from my existing 60TB NAS of 7 years to a new and intentionally overkill NAS rack-mounted setup. If you could lend me your eyes and expertise it will be much appreciated as there is going to be some serious $$ going into this, thanks!\n\n## Requirements\n\n* At least 300TB usable space, with a scalability path towards 1PB in the future\n* Hard drive redundancy\n* Rack-mounted\n* Support running containers\n* Support Plex and hardware transcoding\n* Support running CPU-intensive things, like tdarr, Radarr, Sonarr, etc\n\nI will be running Ubuntu + HashiCorp Nomad since I\u2019m very familiar with that tech stack. I\u2019ve narrowed down the build to consist of two machines which seems like it will meet these requirements: a main server connected to a JBOD.\n\n## Server\n\n* CPU: Intel Core i7-13700K 3.4 GHz 16-Core Processor ($409.00 @ Amazon)\n* CPU Cooler: ARCTIC Liquid Freezer II 280 72.8 CFM Liquid CPU Cooler ($109.99 @ Amazon)\n* Thermal Compound: Arctic Silver 5 High-Density Polysynthetic Silver 3.5 g Thermal Paste ($7.65 @ Amazon)\n* Motherboard: Asus TUF GAMING Z790-PLUS WIFI ATX LGA1700 Motherboard ($269.99 @ Amazon)\n* Memory: G.Skill Trident Z5 RGB 64 GB (2 x 32 GB) DDR5-6400 CL32 Memory ($224.99 @ Amazon)\n* Storage: Samsung 990 Pro 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive ($149.99 @ B&amp;H)\n* Storage: Samsung 990 Pro 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive ($149.99 @ B&amp;H)\n* Power Supply: Corsair RM850x 850 W 80+ Gold Certified Fully Modular ATX Power Supply ($188.87 @ Amazon)\n* Custom: Sliger CX4170a ($239.00)\n* Custom: LSI MegaRAID LSI00332 (9286-8e) PCI-Express 3.0 x8 SATA / SAS RAID  ($79.00 @ Amazon)\n\nThe dual NVMe will be mirrored for redundancy and will contain the OS, system files, and act as a scratch disk (downloads and extraction for better performance). Would it better to separate the OS and put it on its own disk \u2013\u00a0if so should it be another NVMe or SSD? \n\n## JBOD\n\n* Case: **NetApp DS4246**\n* For mounting on Rack: **NetApp DS4246 Rail Kit**\n* Cable to link server with JBOD: **QSFP SFF-8436 Cable**\n* Hard drives: **24 x 22TB Seagate Ironwolf**\n\nI\u2019m planning on doing RAIDZ2, which should give me 352TB of usable space.\n\nThanks, feel free to poke holes and let me know your thoughts!", "author_fullname": "t2_c7g08877", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New 300TB+ Data Hoarding Build Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1542qm6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689792440.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689790981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am looking to migrate away from my existing 60TB NAS of 7 years to a new and intentionally overkill NAS rack-mounted setup. If you could lend me your eyes and expertise it will be much appreciated as there is going to be some serious $$ going into this, thanks!&lt;/p&gt;\n\n&lt;h2&gt;Requirements&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;At least 300TB usable space, with a scalability path towards 1PB in the future&lt;/li&gt;\n&lt;li&gt;Hard drive redundancy&lt;/li&gt;\n&lt;li&gt;Rack-mounted&lt;/li&gt;\n&lt;li&gt;Support running containers&lt;/li&gt;\n&lt;li&gt;Support Plex and hardware transcoding&lt;/li&gt;\n&lt;li&gt;Support running CPU-intensive things, like tdarr, Radarr, Sonarr, etc&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I will be running Ubuntu + HashiCorp Nomad since I\u2019m very familiar with that tech stack. I\u2019ve narrowed down the build to consist of two machines which seems like it will meet these requirements: a main server connected to a JBOD.&lt;/p&gt;\n\n&lt;h2&gt;Server&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;CPU: Intel Core i7-13700K 3.4 GHz 16-Core Processor ($409.00 @ Amazon)&lt;/li&gt;\n&lt;li&gt;CPU Cooler: ARCTIC Liquid Freezer II 280 72.8 CFM Liquid CPU Cooler ($109.99 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Thermal Compound: Arctic Silver 5 High-Density Polysynthetic Silver 3.5 g Thermal Paste ($7.65 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Motherboard: Asus TUF GAMING Z790-PLUS WIFI ATX LGA1700 Motherboard ($269.99 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Memory: G.Skill Trident Z5 RGB 64 GB (2 x 32 GB) DDR5-6400 CL32 Memory ($224.99 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Storage: Samsung 990 Pro 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive ($149.99 @ B&amp;amp;H)&lt;/li&gt;\n&lt;li&gt;Storage: Samsung 990 Pro 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive ($149.99 @ B&amp;amp;H)&lt;/li&gt;\n&lt;li&gt;Power Supply: Corsair RM850x 850 W 80+ Gold Certified Fully Modular ATX Power Supply ($188.87 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Custom: Sliger CX4170a ($239.00)&lt;/li&gt;\n&lt;li&gt;Custom: LSI MegaRAID LSI00332 (9286-8e) PCI-Express 3.0 x8 SATA / SAS RAID  ($79.00 @ Amazon)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The dual NVMe will be mirrored for redundancy and will contain the OS, system files, and act as a scratch disk (downloads and extraction for better performance). Would it better to separate the OS and put it on its own disk \u2013\u00a0if so should it be another NVMe or SSD? &lt;/p&gt;\n\n&lt;h2&gt;JBOD&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Case: &lt;strong&gt;NetApp DS4246&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;For mounting on Rack: &lt;strong&gt;NetApp DS4246 Rail Kit&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Cable to link server with JBOD: &lt;strong&gt;QSFP SFF-8436 Cable&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Hard drives: &lt;strong&gt;24 x 22TB Seagate Ironwolf&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m planning on doing RAIDZ2, which should give me 352TB of usable space.&lt;/p&gt;\n\n&lt;p&gt;Thanks, feel free to poke holes and let me know your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1542qm6", "is_robot_indexable": true, "report_reasons": null, "author": "fat_keepsake", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1542qm6/new_300tb_data_hoarding_build_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1542qm6/new_300tb_data_hoarding_build_advice/", "subreddit_subscribers": 693418, "created_utc": 1689790981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI am building a NAS storage with a capacity of approx. 300TB for post-production. Most of the workflow consists of copying the raw data, creating a proxy, and editing is done from the proxy data, which is 30x smaller. Only grading and final export is done from raw data. The server will only be NAS storage, no VMs or containers. Both systems are priced similarly. But the QNAP warranty is in the form of almost non-existent, since they are almost out of stock, so the store would say that they are out of stock, and they will return the money and the data is...\n\n&amp;#x200B;\n\nBasically it will be either:\n\n1) TS-h2477XU-RP using ZFS [https://www.qnap.com/en-us/product/ts-h2477xu-rp](https://www.qnap.com/en-us/product/ts-h2477xu-rp)\n\n2) Custom solution with supermicro see below\n\n&amp;#x200B;\n\nCase: [Supermicro CSE-847BE1C4-R1K23LPB](https://www.supermicro.com/en/products/chassis/4u/847/sc847be1c4-r1k23lpb)\n\nMBO: Supermicro MBD-H12SSL-C-B\n\nCPU: [AMD EPYC Milan 7313P 16c](https://www.supermicro.com/en/products/motherboard/h12ssl-c)\n\nRAM: 4x Micron 64 GB DDR4 288-PIN-3200MHz ECC = 256GB\n\nHBA: Broadcom LSI HBA Tri-Mode 9400-16i 16x\n\nNIC: Supermicro AOC-S40G-I2Q (controller Intel  XL710)\n\nL2arc: 2x Samsung PM9A3 1.9TB NVMe in mirror\n\nBoot: Dual Samsung 870 EVO, 2.5\", 250GB\n\nHDD: 24x Toshiba 3.5\" 20 TB, 7.2K SATA III 512MB - MG10ACA20TE\n\n\\+ the server is built by a company that provides a 5-year NBD warranty\n\n&amp;#x200B;\n\nQuestions:\n\n\\- Regardless of the system, the layout will be 4x vdev, raidz2 6x hdd\n\n\\- yes, 12 disks are as a reserve for further expansion\n\n\\- am I planning to run it on TrueNas, or would something else be better?\n\n\\- I plan on Truenas Scale for better AMD support is that reasonable?\n\n\\- originally I thought 128GB of ram, but maybe at least 256GB will be needed?\n\n\\- I expect a reading speed of about 2GB/s, is this realistic?\n\n\\- I read earlier that AMD is worse off with truenas, is it better now?\n\n\\- MBO has 2x SAS3 on LSI 9303, is it good to use it or is it safer to have a dedicated HBA. Anyway, I will have to have an HBA, only it would be smaller (LSI 9500-8i Tri-Mode).\n\n\\- Use L2arc in the 2TB mirror or should I rather take a smaller second SSD for sLOG\n\n\\- according to the manual, both backplanes in the box have dual SAS connectors and the throughput should be doubled after connecting both. Is that so? Experiences? Is it necessary to set it up somehow?\n\n\\- I assume that theoretically most of the proxy data could be sent from L2arc because only they will be used during editing in 90% of the cases. Would it make sense to have a larger L2arc?\n\n\\- Do you have experience with Toshiba hdd? So far, the tests at Backblaze are going well, and we already have a few of them running here.\n\n&amp;#x200B;\n\nThank you all so much for your comments. Don't spare me at all, I want to debug it as much as possible.", "author_fullname": "t2_92azv115", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building NAS 300TB with Supermicro gear for video editing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154risn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689861089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am building a NAS storage with a capacity of approx. 300TB for post-production. Most of the workflow consists of copying the raw data, creating a proxy, and editing is done from the proxy data, which is 30x smaller. Only grading and final export is done from raw data. The server will only be NAS storage, no VMs or containers. Both systems are priced similarly. But the QNAP warranty is in the form of almost non-existent, since they are almost out of stock, so the store would say that they are out of stock, and they will return the money and the data is...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basically it will be either:&lt;/p&gt;\n\n&lt;p&gt;1) TS-h2477XU-RP using ZFS &lt;a href=\"https://www.qnap.com/en-us/product/ts-h2477xu-rp\"&gt;https://www.qnap.com/en-us/product/ts-h2477xu-rp&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;2) Custom solution with supermicro see below&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Case: &lt;a href=\"https://www.supermicro.com/en/products/chassis/4u/847/sc847be1c4-r1k23lpb\"&gt;Supermicro CSE-847BE1C4-R1K23LPB&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;MBO: Supermicro MBD-H12SSL-C-B&lt;/p&gt;\n\n&lt;p&gt;CPU: &lt;a href=\"https://www.supermicro.com/en/products/motherboard/h12ssl-c\"&gt;AMD EPYC Milan 7313P 16c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;RAM: 4x Micron 64 GB DDR4 288-PIN-3200MHz ECC = 256GB&lt;/p&gt;\n\n&lt;p&gt;HBA: Broadcom LSI HBA Tri-Mode 9400-16i 16x&lt;/p&gt;\n\n&lt;p&gt;NIC: Supermicro AOC-S40G-I2Q (controller Intel  XL710)&lt;/p&gt;\n\n&lt;p&gt;L2arc: 2x Samsung PM9A3 1.9TB NVMe in mirror&lt;/p&gt;\n\n&lt;p&gt;Boot: Dual Samsung 870 EVO, 2.5&amp;quot;, 250GB&lt;/p&gt;\n\n&lt;p&gt;HDD: 24x Toshiba 3.5&amp;quot; 20 TB, 7.2K SATA III 512MB - MG10ACA20TE&lt;/p&gt;\n\n&lt;p&gt;+ the server is built by a company that provides a 5-year NBD warranty&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Questions:&lt;/p&gt;\n\n&lt;p&gt;- Regardless of the system, the layout will be 4x vdev, raidz2 6x hdd&lt;/p&gt;\n\n&lt;p&gt;- yes, 12 disks are as a reserve for further expansion&lt;/p&gt;\n\n&lt;p&gt;- am I planning to run it on TrueNas, or would something else be better?&lt;/p&gt;\n\n&lt;p&gt;- I plan on Truenas Scale for better AMD support is that reasonable?&lt;/p&gt;\n\n&lt;p&gt;- originally I thought 128GB of ram, but maybe at least 256GB will be needed?&lt;/p&gt;\n\n&lt;p&gt;- I expect a reading speed of about 2GB/s, is this realistic?&lt;/p&gt;\n\n&lt;p&gt;- I read earlier that AMD is worse off with truenas, is it better now?&lt;/p&gt;\n\n&lt;p&gt;- MBO has 2x SAS3 on LSI 9303, is it good to use it or is it safer to have a dedicated HBA. Anyway, I will have to have an HBA, only it would be smaller (LSI 9500-8i Tri-Mode).&lt;/p&gt;\n\n&lt;p&gt;- Use L2arc in the 2TB mirror or should I rather take a smaller second SSD for sLOG&lt;/p&gt;\n\n&lt;p&gt;- according to the manual, both backplanes in the box have dual SAS connectors and the throughput should be doubled after connecting both. Is that so? Experiences? Is it necessary to set it up somehow?&lt;/p&gt;\n\n&lt;p&gt;- I assume that theoretically most of the proxy data could be sent from L2arc because only they will be used during editing in 90% of the cases. Would it make sense to have a larger L2arc?&lt;/p&gt;\n\n&lt;p&gt;- Do you have experience with Toshiba hdd? So far, the tests at Backblaze are going well, and we already have a few of them running here.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you all so much for your comments. Don&amp;#39;t spare me at all, I want to debug it as much as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HDhgxrbPntEKbYqp2Q4kEeMFfMLzz8o4t3fvqKLDlZI.jpg?auto=webp&amp;s=f021243eae4fddd26d2f8b418b387f8dbf9d123a", "width": 1000, "height": 625}, "resolutions": [{"url": "https://external-preview.redd.it/HDhgxrbPntEKbYqp2Q4kEeMFfMLzz8o4t3fvqKLDlZI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9225a16b38c463b96b5f44196e707a00fcf12587", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/HDhgxrbPntEKbYqp2Q4kEeMFfMLzz8o4t3fvqKLDlZI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0cac10b8bd8f7a9086ee6135bc979a49038ef039", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/HDhgxrbPntEKbYqp2Q4kEeMFfMLzz8o4t3fvqKLDlZI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a155b24b5b078e503f323210bf7de69ff2a0d5bd", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/HDhgxrbPntEKbYqp2Q4kEeMFfMLzz8o4t3fvqKLDlZI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ba54301d60fe8d249687cbc487eeb2fbde606bc5", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/HDhgxrbPntEKbYqp2Q4kEeMFfMLzz8o4t3fvqKLDlZI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b0a69015ccfa60674a335d9d7066a960944229e5", "width": 960, "height": 600}], "variants": {}, "id": "omhZ9wD3EcuQEZNczdUIdGmvNaOG9FI6ddVOBLGQJiQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154risn", "is_robot_indexable": true, "report_reasons": null, "author": "Matej_54185", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154risn/building_nas_300tb_with_supermicro_gear_for_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154risn/building_nas_300tb_with_supermicro_gear_for_video/", "subreddit_subscribers": 693418, "created_utc": 1689861089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've just built myself a new home server with a 47TB ZFS array which should keep me going for a while. Yesterday, I copied about 12TB of Linux ISO's into a temporary dataset.  The plan for today was to move it to it's final location (various chunks are going to different datasets). Imagine my surprise when I issue a mv command expecting it to take seconds and I watch it start copying and removing files. Doh! Don't I feel like an idiot. Just because they are physically on the same array doesn't mean the OS can avoid copying the data across datasets.\n\nIf there is a way to move files faster I'm all ears but I suspect I'm stuck waiting for it. On the upside this array of spinning rust is surprisingly fast.", "author_fullname": "t2_nu461", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Today I learnt something new about ZFS datasets and moving files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154q5na", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689857690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just built myself a new home server with a 47TB ZFS array which should keep me going for a while. Yesterday, I copied about 12TB of Linux ISO&amp;#39;s into a temporary dataset.  The plan for today was to move it to it&amp;#39;s final location (various chunks are going to different datasets). Imagine my surprise when I issue a mv command expecting it to take seconds and I watch it start copying and removing files. Doh! Don&amp;#39;t I feel like an idiot. Just because they are physically on the same array doesn&amp;#39;t mean the OS can avoid copying the data across datasets.&lt;/p&gt;\n\n&lt;p&gt;If there is a way to move files faster I&amp;#39;m all ears but I suspect I&amp;#39;m stuck waiting for it. On the upside this array of spinning rust is surprisingly fast.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154q5na", "is_robot_indexable": true, "report_reasons": null, "author": "Wobblycogs", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154q5na/today_i_learnt_something_new_about_zfs_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154q5na/today_i_learnt_something_new_about_zfs_datasets/", "subreddit_subscribers": 693418, "created_utc": 1689857690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My dad is a photographer and, through some messy process, has ended up with nearly 14tb of photos. To hear him tell it, there are probably two or three duplicates of most original files. And, because he's a photog, a lot of his photos are very similar (but not identical). Do any of you good folks know of a piece of software he could use to delete exact duplicates (and exact duplicates only)?", "author_fullname": "t2_eq1a4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best software for finding duplicates among 14tb of photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1549y5s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689807944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My dad is a photographer and, through some messy process, has ended up with nearly 14tb of photos. To hear him tell it, there are probably two or three duplicates of most original files. And, because he&amp;#39;s a photog, a lot of his photos are very similar (but not identical). Do any of you good folks know of a piece of software he could use to delete exact duplicates (and exact duplicates only)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1549y5s", "is_robot_indexable": true, "report_reasons": null, "author": "MrCharlieBones", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1549y5s/best_software_for_finding_duplicates_among_14tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1549y5s/best_software_for_finding_duplicates_among_14tb/", "subreddit_subscribers": 693418, "created_utc": 1689807944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using the Internet Archive Command Line Interface for a while now to hoard retro computer (mainly Commodore 64 related) magazines and books. \n\nI've also been using it to do the same with Commodore 64 software as well. These are typically stored in a .d64 file which is an image of an physical Commodore 1541 floppy disk. The .d64 file can be \"loaded\" into the Vice emulator or used on real Commodore computer hardware using an SD2IEC or Pi1541 which then works like an original floppy disk drive.\n\nI've used this command to download all of the .d64 files in the collection \"softwarelibrary\\_c64\";\n\nia download --search 'collection:softwarelibrary\\_c64'  --glob=\"\\*.d64\"\n\nScattered through the output were some failed downloads. Investigation shows these to be items where the software was in a .tap file, an image of a Commodore 64 cassette tape. \n\nI'd like to download both .d64 and .tap files in the same command... but I can't see a way to configure the above command to do this? The IA Command Line Interface help doesn't really show how to do this... or even if it's possible. \n\nIs there a way to download all items from \"softwarelibrary\\_c64\" collections containing both .d64 and .tap files with one IA command?\n\n&amp;#x200B;", "author_fullname": "t2_bsosk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading multiple file types from Internet Archive using --glob", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15498gs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689806145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using the Internet Archive Command Line Interface for a while now to hoard retro computer (mainly Commodore 64 related) magazines and books. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also been using it to do the same with Commodore 64 software as well. These are typically stored in a .d64 file which is an image of an physical Commodore 1541 floppy disk. The .d64 file can be &amp;quot;loaded&amp;quot; into the Vice emulator or used on real Commodore computer hardware using an SD2IEC or Pi1541 which then works like an original floppy disk drive.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used this command to download all of the .d64 files in the collection &amp;quot;softwarelibrary_c64&amp;quot;;&lt;/p&gt;\n\n&lt;p&gt;ia download --search &amp;#39;collection:softwarelibrary_c64&amp;#39;  --glob=&amp;quot;*.d64&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Scattered through the output were some failed downloads. Investigation shows these to be items where the software was in a .tap file, an image of a Commodore 64 cassette tape. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to download both .d64 and .tap files in the same command... but I can&amp;#39;t see a way to configure the above command to do this? The IA Command Line Interface help doesn&amp;#39;t really show how to do this... or even if it&amp;#39;s possible. &lt;/p&gt;\n\n&lt;p&gt;Is there a way to download all items from &amp;quot;softwarelibrary_c64&amp;quot; collections containing both .d64 and .tap files with one IA command?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15498gs", "is_robot_indexable": true, "report_reasons": null, "author": "original_lunokhod", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15498gs/downloading_multiple_file_types_from_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15498gs/downloading_multiple_file_types_from_internet/", "subreddit_subscribers": 693418, "created_utc": 1689806145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there, folks.\n\nThis time I'd like to ask for more help in the process of building my own system. The thing is that I have some questions because I am not an expert about how to build one myself. I'm a blind person, so if you can be specific about how things work together, I'd really appreciate it. Ideally I'd like to build a reliable system capable of using 8 drives at a relatively cheap price. I would use the system mostly for Plex (4-5 transcodes at a time, only 1080), NextCloud, Django testing and some docker containers. I have tried to search for this kind of systems in local shops, but apparently this is not easy here. So I searched in Amazon for some hardware and I have so far the following, excluding drives:\n\n* Case: Antec P101 Silent.\n* Motherboard: ASRock Z690 PG Riptide.\n* Intel Core i3-13100.\n* Power Supply: Gigabyte GP-P650B.\n* 2x 16 GB crucial DDR4 RAM at 3200 MHZ.\n\nquestions:\n\n1. Do you think will there be a compatibility issue with one of those components? this is my first build, so I am not sure about pretty much anything right now.\n2. Is there something You'd change?\n3. Do I have to buy a cooler, fans or something like that?\n4. If I would put 8 drives on the case, should I buy cables or something else separately? How could I search for this?\n\nSorry if this sounds too obvious, but I'd like to get as more details as possible before buying everything and realicing that there's something wrong with a component, cables missing or something similar.", "author_fullname": "t2_3vncnb2s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First NAS build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1547y2a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689803076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, folks.&lt;/p&gt;\n\n&lt;p&gt;This time I&amp;#39;d like to ask for more help in the process of building my own system. The thing is that I have some questions because I am not an expert about how to build one myself. I&amp;#39;m a blind person, so if you can be specific about how things work together, I&amp;#39;d really appreciate it. Ideally I&amp;#39;d like to build a reliable system capable of using 8 drives at a relatively cheap price. I would use the system mostly for Plex (4-5 transcodes at a time, only 1080), NextCloud, Django testing and some docker containers. I have tried to search for this kind of systems in local shops, but apparently this is not easy here. So I searched in Amazon for some hardware and I have so far the following, excluding drives:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Case: Antec P101 Silent.&lt;/li&gt;\n&lt;li&gt;Motherboard: ASRock Z690 PG Riptide.&lt;/li&gt;\n&lt;li&gt;Intel Core i3-13100.&lt;/li&gt;\n&lt;li&gt;Power Supply: Gigabyte GP-P650B.&lt;/li&gt;\n&lt;li&gt;2x 16 GB crucial DDR4 RAM at 3200 MHZ.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do you think will there be a compatibility issue with one of those components? this is my first build, so I am not sure about pretty much anything right now.&lt;/li&gt;\n&lt;li&gt;Is there something You&amp;#39;d change?&lt;/li&gt;\n&lt;li&gt;Do I have to buy a cooler, fans or something like that?&lt;/li&gt;\n&lt;li&gt;If I would put 8 drives on the case, should I buy cables or something else separately? How could I search for this?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Sorry if this sounds too obvious, but I&amp;#39;d like to get as more details as possible before buying everything and realicing that there&amp;#39;s something wrong with a component, cables missing or something similar.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1547y2a", "is_robot_indexable": true, "report_reasons": null, "author": "manuelcortez00", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1547y2a/first_nas_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1547y2a/first_nas_build/", "subreddit_subscribers": 693418, "created_utc": 1689803076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Some very arrogant guy is making trading calls that he deletes a while after IF they turn out to be false, boasts about it if right and uses this to promote his thousand dollars courses.\n\nSo, I'm looking for a tool to hold him accountable for his selectively deleted tweets, I know there is a similar service but only for public personalities. I want a tool for someone that isn't as known to the public.\narchive.org almost does the job but sometimes it doesn't save the replies or the attached video media.", "author_fullname": "t2_5l24a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a tool that saves tweets and helps keep people accountable for deleted tweets? AKA a tweet downloader", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_154wo0x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689872516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some very arrogant guy is making trading calls that he deletes a while after IF they turn out to be false, boasts about it if right and uses this to promote his thousand dollars courses.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m looking for a tool to hold him accountable for his selectively deleted tweets, I know there is a similar service but only for public personalities. I want a tool for someone that isn&amp;#39;t as known to the public.\narchive.org almost does the job but sometimes it doesn&amp;#39;t save the replies or the attached video media.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154wo0x", "is_robot_indexable": true, "report_reasons": null, "author": "Poilaucul", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154wo0x/is_there_a_tool_that_saves_tweets_and_helps_keep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154wo0x/is_there_a_tool_that_saves_tweets_and_helps_keep/", "subreddit_subscribers": 693418, "created_utc": 1689872516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "2 questions:\n\n1.) file sync backup methods seem to do well when say your harddrive blows up, you still have a backup on the other drive, but what if a bunch of your files get corrupted, and the synch then overwrites your backup with the changed corrupted files? \n\nhow do you protect against this?\n\n2.) what is your personal backup solution? what is the logic and structure behind your solution and what tools do you use?", "author_fullname": "t2_v8vogl0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do you protect against potential folder/file synch backup issues?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154obgg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689852543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;2 questions:&lt;/p&gt;\n\n&lt;p&gt;1.) file sync backup methods seem to do well when say your harddrive blows up, you still have a backup on the other drive, but what if a bunch of your files get corrupted, and the synch then overwrites your backup with the changed corrupted files? &lt;/p&gt;\n\n&lt;p&gt;how do you protect against this?&lt;/p&gt;\n\n&lt;p&gt;2.) what is your personal backup solution? what is the logic and structure behind your solution and what tools do you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154obgg", "is_robot_indexable": true, "report_reasons": null, "author": "mathestnoobest", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154obgg/how_do_you_protect_against_potential_folderfile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154obgg/how_do_you_protect_against_potential_folderfile/", "subreddit_subscribers": 693418, "created_utc": 1689852543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are any of you using multi-bay drive enclosures successfully with Linux without errors? I have mostly migrated my homelab and systems to a mix of Ubuntu (22.04 LTS and MATE) and Debian (LMDE, CasaOS, Raspberry Pi OS, and headless).\n\nI have had no end of trouble with Orico's enclosures, after investing in them reasonably heavily. Consistently, whatever information they are sending to Ubuntu leads Ubuntu to report huge drive sizes and the actual drive as a partition at the front (so it thinks an 8TB drive is about a 125,000TB drive with 7.28 TB partition at the front and 118,214.53 unallocated). It doesn't matter what system was used to create the file system or whether it's NTFS or ext4. (Exfat also had some issues but at that point it seemed like an anomaly, so I can't say whether it played out the same or slightly differently). \n\nThey do seem to behave okay with Windows (or Windows can invisibly reconcile any differences in what's reported) and I am coming around to the idea that I may need to keep one Windows machine in the system. (Not only for this issue; Robocopy is easier and faster than Rsync, and my backup machine connects read-only so Syncthing isn't feasible). But I would much rather get something that behaves well across the board. Any suggestions?\n\n*Edit* Forgot to mention - I don't need, and in fact would prefer not to have hardware RAID, JBOD is fine/preferred. I have really good software RAID in TrueNAS Scale, this is for making standalone cold and offsite backups.", "author_fullname": "t2_komty5a5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for multi-drive enclosures?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154f4qo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689822785.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689822129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are any of you using multi-bay drive enclosures successfully with Linux without errors? I have mostly migrated my homelab and systems to a mix of Ubuntu (22.04 LTS and MATE) and Debian (LMDE, CasaOS, Raspberry Pi OS, and headless).&lt;/p&gt;\n\n&lt;p&gt;I have had no end of trouble with Orico&amp;#39;s enclosures, after investing in them reasonably heavily. Consistently, whatever information they are sending to Ubuntu leads Ubuntu to report huge drive sizes and the actual drive as a partition at the front (so it thinks an 8TB drive is about a 125,000TB drive with 7.28 TB partition at the front and 118,214.53 unallocated). It doesn&amp;#39;t matter what system was used to create the file system or whether it&amp;#39;s NTFS or ext4. (Exfat also had some issues but at that point it seemed like an anomaly, so I can&amp;#39;t say whether it played out the same or slightly differently). &lt;/p&gt;\n\n&lt;p&gt;They do seem to behave okay with Windows (or Windows can invisibly reconcile any differences in what&amp;#39;s reported) and I am coming around to the idea that I may need to keep one Windows machine in the system. (Not only for this issue; Robocopy is easier and faster than Rsync, and my backup machine connects read-only so Syncthing isn&amp;#39;t feasible). But I would much rather get something that behaves well across the board. Any suggestions?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit&lt;/em&gt; Forgot to mention - I don&amp;#39;t need, and in fact would prefer not to have hardware RAID, JBOD is fine/preferred. I have really good software RAID in TrueNAS Scale, this is for making standalone cold and offsite backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "25TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154f4qo", "is_robot_indexable": true, "report_reasons": null, "author": "nurseynurseygander", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/154f4qo/recommendations_for_multidrive_enclosures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154f4qo/recommendations_for_multidrive_enclosures/", "subreddit_subscribers": 693418, "created_utc": 1689822129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I always get this error\n\n \n\n    brew install danirukun/ytarchive/ytarchive\n    \n\n`Error: ytarchive: SHA256 mismatch`\n\n`Expected: f61ac9b3606476306c208dd87961a3ca846efa92eaad651fa0270293c13a54c2 Actual: 055d3e7129c737105d28f743bd3ce02fef57b116f95a8f3601a25c163634a252 File: /Users/YMB/Library/Caches/Homebrew/downloads/bb308be7810c4f190dfd69f5c6a1d9e0d40e9c833dd4c7a78ffa44cbacd25de8--ytarchive-latest.tar.gz`", "author_fullname": "t2_baozka1v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to install ytarchive on mac?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154638c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689798783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I always get this error&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;brew install danirukun/ytarchive/ytarchive\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;code&gt;Error: ytarchive: SHA256 mismatch&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Expected: f61ac9b3606476306c208dd87961a3ca846efa92eaad651fa0270293c13a54c2 Actual: 055d3e7129c737105d28f743bd3ce02fef57b116f95a8f3601a25c163634a252 File: /Users/YMB/Library/Caches/Homebrew/downloads/bb308be7810c4f190dfd69f5c6a1d9e0d40e9c833dd4c7a78ffa44cbacd25de8--ytarchive-latest.tar.gz&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154638c", "is_robot_indexable": true, "report_reasons": null, "author": "Vegetable_Dream_5251", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154638c/how_to_install_ytarchive_on_mac/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154638c/how_to_install_ytarchive_on_mac/", "subreddit_subscribers": 693418, "created_utc": 1689798783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just bought a 4 bay  QNAP TR-004 DAS and was looking for some recommendations on what hard drives to get. Is just using any type fine? Can I do something like 3 4tb and 1 10tb or do they all have to be the same storage size? I also saw something about SMR and CMR, just a lot of overwhelming info for a  newbie.", "author_fullname": "t2_3q5rxmp9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD recommendations for a QNAP DAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1545nrp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689797768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just bought a 4 bay  QNAP TR-004 DAS and was looking for some recommendations on what hard drives to get. Is just using any type fine? Can I do something like 3 4tb and 1 10tb or do they all have to be the same storage size? I also saw something about SMR and CMR, just a lot of overwhelming info for a  newbie.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1545nrp", "is_robot_indexable": true, "report_reasons": null, "author": "AromaticMode", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1545nrp/hdd_recommendations_for_a_qnap_das/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1545nrp/hdd_recommendations_for_a_qnap_das/", "subreddit_subscribers": 693418, "created_utc": 1689797768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 7 hdds on my nas that I spindown after 120min of no use, been thinking on ways to reduce power consumption on my machine and many of those drives are less than 1tb in size, was wondering if there was any way to see how much time do the drives spin vs not or idle, to see if its worth it to remove some/most for a bigger capacity drive that could waste less energy, also if I remove disks I could also remove my dell h200 saving a bit extra.\n\nFor now I have around 9% load on my ups (apc back-ups xs 700u) and would love to reduce it as much as possible.\n\nAlso anyone know how to get a quick and dirty rough power consumption from the ups load? It says its 390w nominal power, but dont know if I should just multiply 390 by 9%?", "author_fullname": "t2_11qmx3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any1 know how to get a hdd spindown vs spinning ratio/graps/data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1544iz4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689798966.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689795142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 7 hdds on my nas that I spindown after 120min of no use, been thinking on ways to reduce power consumption on my machine and many of those drives are less than 1tb in size, was wondering if there was any way to see how much time do the drives spin vs not or idle, to see if its worth it to remove some/most for a bigger capacity drive that could waste less energy, also if I remove disks I could also remove my dell h200 saving a bit extra.&lt;/p&gt;\n\n&lt;p&gt;For now I have around 9% load on my ups (apc back-ups xs 700u) and would love to reduce it as much as possible.&lt;/p&gt;\n\n&lt;p&gt;Also anyone know how to get a quick and dirty rough power consumption from the ups load? It says its 390w nominal power, but dont know if I should just multiply 390 by 9%?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1544iz4", "is_robot_indexable": true, "report_reasons": null, "author": "blazethedragon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1544iz4/any1_know_how_to_get_a_hdd_spindown_vs_spinning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1544iz4/any1_know_how_to_get_a_hdd_spindown_vs_spinning/", "subreddit_subscribers": 693418, "created_utc": 1689795142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nThis external drive works flawlessly on everyone else\u2019s computer but mine. \nI don\u2019t think this is a typical issue so I\u2019d appreciate anyone who reads on and could try and help me.\n\nI\u2019ve already tried all the most common fixes.\n\nI can\u2019t afford to format the drive.\n\n(I\u2019m on a win 10 machine btw latest version of win 10)\n\nOk.. so I have this external ssd drive (Samsung T7 1TB) which I\u2019ve had for a year or so, which has a lot of important things saved to it, today when I went to use it, I found it was not shown with my other drives (when looking under \u201cthis pc\u201d) \n\nI tried what seems like everything under the Sun man, and can\u2019t figure out why the drive won\u2019t show up anymore. \n\nHere\u2019s what I tried: \n\n- Unplugging and replugging it back in\n- restarting then unplugging and replugging it back in\n- downloading the official drivers for the external hard drive (Samsung software doesn\u2019t detect the drive) \n- tried a different cable for the external drive\n- tried a different port for the external drive\n- tried a different port + cable for the external drive\n- plugged the external drive into 2 other computers (which it worked perfectly on\u2026?)\n- cmd sfc /scannow\n- updating windows to the latest version of win 10\n- uninstalling all usb drivers through device manager and restarting pc\n-tried changing the drive letter in disk partition (it doesn\u2019t show up in there)\n-tried changing the drive letter in disk partition on another computer, then plugging it back into the computer the drive doesn\u2019t work on\n\n- and probably some other things which I can\u2019t even remember\u2026\n\nHere\u2019s what I think the issue may be:\n\nI think somehow a driver is conflicting with how my pc interprets that external ssd, and not making it show up properly.\n\n Now, I have 2 externals, one is an external hdd, works fine, how the external hdd works fine and the other one doesn\u2019t, I can\u2019t answer but that\u2019s my only guess really now. \n\nI\u2019m going to try booting in safe mode and seeing if the external drive shows up but I doubt it.\n\nOther things to note:\n\nThe drive shows up under device manager, but under a tab called \u201clibusbk device\u201d idk if it was always like that.", "author_fullname": "t2_n9af935g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weird external drive issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154q39f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689857509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This external drive works flawlessly on everyone else\u2019s computer but mine. \nI don\u2019t think this is a typical issue so I\u2019d appreciate anyone who reads on and could try and help me.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve already tried all the most common fixes.&lt;/p&gt;\n\n&lt;p&gt;I can\u2019t afford to format the drive.&lt;/p&gt;\n\n&lt;p&gt;(I\u2019m on a win 10 machine btw latest version of win 10)&lt;/p&gt;\n\n&lt;p&gt;Ok.. so I have this external ssd drive (Samsung T7 1TB) which I\u2019ve had for a year or so, which has a lot of important things saved to it, today when I went to use it, I found it was not shown with my other drives (when looking under \u201cthis pc\u201d) &lt;/p&gt;\n\n&lt;p&gt;I tried what seems like everything under the Sun man, and can\u2019t figure out why the drive won\u2019t show up anymore. &lt;/p&gt;\n\n&lt;p&gt;Here\u2019s what I tried: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Unplugging and replugging it back in&lt;/li&gt;\n&lt;li&gt;restarting then unplugging and replugging it back in&lt;/li&gt;\n&lt;li&gt;downloading the official drivers for the external hard drive (Samsung software doesn\u2019t detect the drive) &lt;/li&gt;\n&lt;li&gt;tried a different cable for the external drive&lt;/li&gt;\n&lt;li&gt;tried a different port for the external drive&lt;/li&gt;\n&lt;li&gt;tried a different port + cable for the external drive&lt;/li&gt;\n&lt;li&gt;plugged the external drive into 2 other computers (which it worked perfectly on\u2026?)&lt;/li&gt;\n&lt;li&gt;cmd sfc /scannow&lt;/li&gt;\n&lt;li&gt;updating windows to the latest version of win 10&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;uninstalling all usb drivers through device manager and restarting pc\n-tried changing the drive letter in disk partition (it doesn\u2019t show up in there)\n-tried changing the drive letter in disk partition on another computer, then plugging it back into the computer the drive doesn\u2019t work on&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;and probably some other things which I can\u2019t even remember\u2026&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here\u2019s what I think the issue may be:&lt;/p&gt;\n\n&lt;p&gt;I think somehow a driver is conflicting with how my pc interprets that external ssd, and not making it show up properly.&lt;/p&gt;\n\n&lt;p&gt;Now, I have 2 externals, one is an external hdd, works fine, how the external hdd works fine and the other one doesn\u2019t, I can\u2019t answer but that\u2019s my only guess really now. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m going to try booting in safe mode and seeing if the external drive shows up but I doubt it.&lt;/p&gt;\n\n&lt;p&gt;Other things to note:&lt;/p&gt;\n\n&lt;p&gt;The drive shows up under device manager, but under a tab called \u201clibusbk device\u201d idk if it was always like that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154q39f", "is_robot_indexable": true, "report_reasons": null, "author": "No-Diamond9473", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154q39f/weird_external_drive_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154q39f/weird_external_drive_issue/", "subreddit_subscribers": 693418, "created_utc": 1689857509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI have an old HDD, which I still actively use  to this day.  It's in my desktop and is used for secondary storage - doesn't need to fast, just reliable. All important stuff is also backed up externally,\n\nIts served me very well, Its a Samsung HD154UI Ecogreen F2\n\n[https://www.hdsentinel.com/storageinfo\\_details.php?lang=en&amp;model=SAMSUNG%20HD154UI](https://www.hdsentinel.com/storageinfo_details.php?lang=en&amp;model=SAMSUNG%20HD154UI)\n\n&amp;#x200B;\n\nJust checked and I purchased it in June 2009 !  Its in my desktop and therefore powered on most of the time every day  although doesn't get written/read much (maybe 10 times a month). I have checked SMART Status and it all seems fine (power on hours exactly 5 years, power cycle count 5700 and no errors).\n\n&amp;#x200B;\n\nThe question is what do I replace it with, what will be just as reliable ? (do I even need to replace it?) Do I leave it,  or go for another HDD or SSD - reliability is pthe rimary concern. \n\n&amp;#x200B;\n\nAlso, if I do replace with an SSD I do not have any spare M2 slot, so it have to be a SATA SSD.\n\n&amp;#x200B;", "author_fullname": "t2_7f7iv7dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD - How Long ?(!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154l0a4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689841700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have an old HDD, which I still actively use  to this day.  It&amp;#39;s in my desktop and is used for secondary storage - doesn&amp;#39;t need to fast, just reliable. All important stuff is also backed up externally,&lt;/p&gt;\n\n&lt;p&gt;Its served me very well, Its a Samsung HD154UI Ecogreen F2&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.hdsentinel.com/storageinfo_details.php?lang=en&amp;amp;model=SAMSUNG%20HD154UI\"&gt;https://www.hdsentinel.com/storageinfo_details.php?lang=en&amp;amp;model=SAMSUNG%20HD154UI&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Just checked and I purchased it in June 2009 !  Its in my desktop and therefore powered on most of the time every day  although doesn&amp;#39;t get written/read much (maybe 10 times a month). I have checked SMART Status and it all seems fine (power on hours exactly 5 years, power cycle count 5700 and no errors).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The question is what do I replace it with, what will be just as reliable ? (do I even need to replace it?) Do I leave it,  or go for another HDD or SSD - reliability is pthe rimary concern. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also, if I do replace with an SSD I do not have any spare M2 slot, so it have to be a SATA SSD.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154l0a4", "is_robot_indexable": true, "report_reasons": null, "author": "Techville345", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154l0a4/hdd_how_long/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154l0a4/hdd_how_long/", "subreddit_subscribers": 693418, "created_utc": 1689841700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have quite a number of more obscure discs from different countries that are basically not on any database. I was looking through the metadata options, but they all seemed to just be trying to take the track info from a database that they are not on. This makes things quite a pain as I would need to manually set all of the metadata on the tracks myself after ripping them. ", "author_fullname": "t2_blk7dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to make EAC use the disc metadata as opposed to a database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154bmgn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689812347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have quite a number of more obscure discs from different countries that are basically not on any database. I was looking through the metadata options, but they all seemed to just be trying to take the track info from a database that they are not on. This makes things quite a pain as I would need to manually set all of the metadata on the tracks myself after ripping them. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154bmgn", "is_robot_indexable": true, "report_reasons": null, "author": "Zyvyn", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154bmgn/is_it_possible_to_make_eac_use_the_disc_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154bmgn/is_it_possible_to_make_eac_use_the_disc_metadata/", "subreddit_subscribers": 693418, "created_utc": 1689812347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It\u2019s a WD Blue SA510 less then 3 months old. Drive won\u2019t power on. Is not recognized in windows partition manager.", "author_fullname": "t2_4gz5coy7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does WD manufacture warranty cover data recovery on a failed drive in the US?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154u3du", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689866920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s a WD Blue SA510 less then 3 months old. Drive won\u2019t power on. Is not recognized in windows partition manager.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154u3du", "is_robot_indexable": true, "report_reasons": null, "author": "Plex_Master", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154u3du/does_wd_manufacture_warranty_cover_data_recovery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154u3du/does_wd_manufacture_warranty_cover_data_recovery/", "subreddit_subscribers": 693418, "created_utc": 1689866920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\nI've 3 x 16TB SATA drives I'm looking to mount as a single spanned volume in Windows 11. Like MergerFS, requirement would be if a drive failed only data on that drive would be lost, remaining two would be fine (unless they failed too).\n\nWindows storage spaces does not do this by the looks. Only program I can find that does is StableBit.\n\nAny other options I should be looking at?", "author_fullname": "t2_16z1he", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MergerFS equivalent for Windows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154o76o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689852170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve 3 x 16TB SATA drives I&amp;#39;m looking to mount as a single spanned volume in Windows 11. Like MergerFS, requirement would be if a drive failed only data on that drive would be lost, remaining two would be fine (unless they failed too).&lt;/p&gt;\n\n&lt;p&gt;Windows storage spaces does not do this by the looks. Only program I can find that does is StableBit.&lt;/p&gt;\n\n&lt;p&gt;Any other options I should be looking at?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154o76o", "is_robot_indexable": true, "report_reasons": null, "author": "Nicoloks", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154o76o/mergerfs_equivalent_for_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154o76o/mergerfs_equivalent_for_windows/", "subreddit_subscribers": 693418, "created_utc": 1689852170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI've been looking for HDD docking stations with at least 2 bays of 3.5\" drives with 20TB supported per bay, looked on amazon and some local webshops but couldn't find any. \n\nDoes anyone know where I can find them? I'm not looking for a NAS, just a USB docking station.", "author_fullname": "t2_113exr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD Docking stations for 20TB HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154l65l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689842284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking for HDD docking stations with at least 2 bays of 3.5&amp;quot; drives with 20TB supported per bay, looked on amazon and some local webshops but couldn&amp;#39;t find any. &lt;/p&gt;\n\n&lt;p&gt;Does anyone know where I can find them? I&amp;#39;m not looking for a NAS, just a USB docking station.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154l65l", "is_robot_indexable": true, "report_reasons": null, "author": "kevinj933", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154l65l/hdd_docking_stations_for_20tb_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154l65l/hdd_docking_stations_for_20tb_hdds/", "subreddit_subscribers": 693418, "created_utc": 1689842284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have it partitioned half for Time Machine and half for other files initially had non-time machine volume as APFS encrypted and got \\~750 MB/s  read and write but when I connected to a 10gbps USB C hub I only get 230/180 read/write which was abysmal. When I decrypted the volume the USB C hub read out in the 600s. but when connected directly to my MacBook the speeds dropped by \\~100 MB/s for both read and write. Why could this be? I am on Ventura 13.4.1. \n\nTo Summarize: \n\nAPFS encrypted:\n\nMacBook: \\~750/750 MB/s\n\nUSB C Hub: \\~230/180 MB/s \n\n&amp;#x200B;\n\nAPFS (decrypted): \n\nMacBook: \\~680/680 MB/s\n\nUSB C Hub: \\~680/570 MB/s \n\n&amp;#x200B;\n\nI don't know why encryption slows down the via the hub so much and it also makes no sense for encrypted to the faster than decrypted when connected directly to the MacBook. I would like to keep the drive encrypted but the extreme speed penalty on a hub is unacceptable. Is there a way to simply password protect the drive? ", "author_fullname": "t2_7pg7o64p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 TB Samsung T7 Shield Odd Black Magic Tests m1 air", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154cp3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689815255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have it partitioned half for Time Machine and half for other files initially had non-time machine volume as APFS encrypted and got ~750 MB/s  read and write but when I connected to a 10gbps USB C hub I only get 230/180 read/write which was abysmal. When I decrypted the volume the USB C hub read out in the 600s. but when connected directly to my MacBook the speeds dropped by ~100 MB/s for both read and write. Why could this be? I am on Ventura 13.4.1. &lt;/p&gt;\n\n&lt;p&gt;To Summarize: &lt;/p&gt;\n\n&lt;p&gt;APFS encrypted:&lt;/p&gt;\n\n&lt;p&gt;MacBook: ~750/750 MB/s&lt;/p&gt;\n\n&lt;p&gt;USB C Hub: ~230/180 MB/s &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;APFS (decrypted): &lt;/p&gt;\n\n&lt;p&gt;MacBook: ~680/680 MB/s&lt;/p&gt;\n\n&lt;p&gt;USB C Hub: ~680/570 MB/s &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know why encryption slows down the via the hub so much and it also makes no sense for encrypted to the faster than decrypted when connected directly to the MacBook. I would like to keep the drive encrypted but the extreme speed penalty on a hub is unacceptable. Is there a way to simply password protect the drive? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154cp3a", "is_robot_indexable": true, "report_reasons": null, "author": "samurai489", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154cp3a/1_tb_samsung_t7_shield_odd_black_magic_tests_m1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154cp3a/1_tb_samsung_t7_shield_odd_black_magic_tests_m1/", "subreddit_subscribers": 693418, "created_utc": 1689815255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So to summarise. \n\n\nI had a laptop and a 500gb m.2 nvme SSD. I THINK I setup bitlocker on the drive. \n\nI then removed the SSD as I was returning the laptop to the shop I bought it from (irrelevant). \n\nI now have tried to secure erase the m.2 in parted magic, but it fails every time. \n\nThe last time I had this issue, I had to enter the PSID unlock, but I can\u2019t see one on this m.2 drive. \n\nSo given I can\u2019t physically install the drive into the same motherboard with the TPM chip, is it now impossible to use this SSD again?\n\nThanks", "author_fullname": "t2_rjp4ke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "M.2 SSD had bitlocker, I no longer can access the motherboard. Is the drive screwed? More in post", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154b9i1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689811380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So to summarise. &lt;/p&gt;\n\n&lt;p&gt;I had a laptop and a 500gb m.2 nvme SSD. I THINK I setup bitlocker on the drive. &lt;/p&gt;\n\n&lt;p&gt;I then removed the SSD as I was returning the laptop to the shop I bought it from (irrelevant). &lt;/p&gt;\n\n&lt;p&gt;I now have tried to secure erase the m.2 in parted magic, but it fails every time. &lt;/p&gt;\n\n&lt;p&gt;The last time I had this issue, I had to enter the PSID unlock, but I can\u2019t see one on this m.2 drive. &lt;/p&gt;\n\n&lt;p&gt;So given I can\u2019t physically install the drive into the same motherboard with the TPM chip, is it now impossible to use this SSD again?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154b9i1", "is_robot_indexable": true, "report_reasons": null, "author": "Silent-OCN", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154b9i1/m2_ssd_had_bitlocker_i_no_longer_can_access_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154b9i1/m2_ssd_had_bitlocker_i_no_longer_can_access_the/", "subreddit_subscribers": 693418, "created_utc": 1689811380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I tried encryption software that came with external drive\u2026 and data transfer became painfully slow.\n\nWhat is the best way to encrypt data without compromising data transfer speeds?", "author_fullname": "t2_43qukrfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the easiest and most flexible way to encrypt hoards of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154qr93", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689859193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried encryption software that came with external drive\u2026 and data transfer became painfully slow.&lt;/p&gt;\n\n&lt;p&gt;What is the best way to encrypt data without compromising data transfer speeds?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154qr93", "is_robot_indexable": true, "report_reasons": null, "author": "danuser8", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154qr93/what_is_the_easiest_and_most_flexible_way_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154qr93/what_is_the_easiest_and_most_flexible_way_to/", "subreddit_subscribers": 693418, "created_utc": 1689859193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 20 TB of files on a server and 20 TB on a NAS. I want to swap the files so the server files go to the NAS and the NAS files go to the server.\n\nBoth devices only have 2 TB free. So I can't finish the one move before doing the other. And it's a set of diverse and complex folders so it's not simple to just do them piecemeal. \n\nNo individual file should be more than 50 GB (I don't think).\n\nAny ideas?", "author_fullname": "t2_1l9k4odb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Utility/script to swap files between drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154elzy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689820628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 20 TB of files on a server and 20 TB on a NAS. I want to swap the files so the server files go to the NAS and the NAS files go to the server.&lt;/p&gt;\n\n&lt;p&gt;Both devices only have 2 TB free. So I can&amp;#39;t finish the one move before doing the other. And it&amp;#39;s a set of diverse and complex folders so it&amp;#39;s not simple to just do them piecemeal. &lt;/p&gt;\n\n&lt;p&gt;No individual file should be more than 50 GB (I don&amp;#39;t think).&lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154elzy", "is_robot_indexable": true, "report_reasons": null, "author": "ShelZuuz", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154elzy/utilityscript_to_swap_files_between_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154elzy/utilityscript_to_swap_files_between_drives/", "subreddit_subscribers": 693418, "created_utc": 1689820628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "IDK if this is the right place to post this question. If it's not pls direct me to the right place.   \n\n  \nI've gotten into upscaling videos I have collected and I decided to repurpose my old gaming laptop to do that. It isn't up to the task and I don't want to use my new gaming desktop to do it. I've been thinking of selling my laptop and getting 2 used 3090s and putting those in my Proxmox Supermicro datahoarder machine, creating 2 Windows VMs and using those to do the video upscaling but I'm worried about how the power draw works on the power supplies.  \n  \nIt has 2 PWS-1K28P-SQ power supplies. There are 2 CPUs with a TDP of 135 each. 36 drives which can reach 9-10watts each. So all that plus the 3090s I'm worried this will go over 1280 watts. If it does go over that will the 2nd power supply kick in? Like how does that work?", "author_fullname": "t2_8r7k9uf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about power draw on Supermicro chassis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154b2jo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689810877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;IDK if this is the right place to post this question. If it&amp;#39;s not pls direct me to the right place.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve gotten into upscaling videos I have collected and I decided to repurpose my old gaming laptop to do that. It isn&amp;#39;t up to the task and I don&amp;#39;t want to use my new gaming desktop to do it. I&amp;#39;ve been thinking of selling my laptop and getting 2 used 3090s and putting those in my Proxmox Supermicro datahoarder machine, creating 2 Windows VMs and using those to do the video upscaling but I&amp;#39;m worried about how the power draw works on the power supplies.  &lt;/p&gt;\n\n&lt;p&gt;It has 2 PWS-1K28P-SQ power supplies. There are 2 CPUs with a TDP of 135 each. 36 drives which can reach 9-10watts each. So all that plus the 3090s I&amp;#39;m worried this will go over 1280 watts. If it does go over that will the 2nd power supply kick in? Like how does that work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154b2jo", "is_robot_indexable": true, "report_reasons": null, "author": "TheBipolarChihuahua", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154b2jo/question_about_power_draw_on_supermicro_chassis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154b2jo/question_about_power_draw_on_supermicro_chassis/", "subreddit_subscribers": 693418, "created_utc": 1689810877.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}