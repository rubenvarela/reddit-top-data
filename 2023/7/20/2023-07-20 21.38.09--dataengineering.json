{"kind": "Listing", "data": {"after": "t3_154x3o4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been at my new company for about 4 months.  I have 2 years of CRUD backend experience and I was hired to replace a senior DE (but not as a senior myself) on a data warehouse team.  This engineer managed a few python applications and Spark + API ingestion processes for the DE team.  \n\nI am hired and first tasked to put these codebases in github, setup CI/CD processes, and help upskill the team in development of this side of our data stack.  It turns out the previous dev just did all of his development on production directly with no testing processes or documentation.  Okay, no big deal.  I'm able to get the code into our remote repos, build CI/CD pipeline with Jenkins (with the help of an adjacent devops team), and overall get the codebase updated to a more mature standing.  I've also worked with the devops team to build out docker images for each of the applications we manage so that we can have proper development environments. Now we have visibility, proper practices in place, and it's starting to look like actual engineering.\n\nNow comes the part where everything starts crashing down.  Since we have a more organized development practices, our new manager starts assigning tasks within these platforms to other engineers.  I come to find out that the senior engineer I replaced was the only data engineer who had touched these processes within the last year.  I also learn that none of the other DE's (including 4 senior DE's) have any experience with programming outside of SQL.  \n\nHere's a list of some of the issues I've run into:  \nEngineer wants me to give him prod access so he can do his development there instead of locally.\n\nSenior engineers don't know how to navigate a CLI.\n\nEngineers have no idea how to use git, and I am there personal git encyclopedia.\n\nEngineers breaking stuff with a git GUI, requiring me to fix it.\n\nEngineers pushing back on git usage entirely.\n\nSenior engineer with 12 years at the company does not know what a for-loop is.\n\nComplaints about me requiring unit testing and some form of documentation that the code works before pushing to production.\n\nSome engineers simply cannot comprehend how Docker works, and want my help to configure their windows laptop into a development environment (I am not helping you stand up a Postgres instance directly on your Windows OS).\n\nI am at my wits end.  I've essentially been designated as a mentor for the side of the DE house that I work in.  That's fine, but I was not hired as a senior, and it is really demotivating mentoring the people who I thought should be mentoring me.  I really do want to see the team succeed, but there has been so much pushback on following best-practices and learning new skills.  Is this common in the DE field?\n\n&amp;#x200B;", "author_fullname": "t2_4rifsjav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal for data engineers to be lacking basic technical skills?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1549emd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 195, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 195, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689806565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been at my new company for about 4 months.  I have 2 years of CRUD backend experience and I was hired to replace a senior DE (but not as a senior myself) on a data warehouse team.  This engineer managed a few python applications and Spark + API ingestion processes for the DE team.  &lt;/p&gt;\n\n&lt;p&gt;I am hired and first tasked to put these codebases in github, setup CI/CD processes, and help upskill the team in development of this side of our data stack.  It turns out the previous dev just did all of his development on production directly with no testing processes or documentation.  Okay, no big deal.  I&amp;#39;m able to get the code into our remote repos, build CI/CD pipeline with Jenkins (with the help of an adjacent devops team), and overall get the codebase updated to a more mature standing.  I&amp;#39;ve also worked with the devops team to build out docker images for each of the applications we manage so that we can have proper development environments. Now we have visibility, proper practices in place, and it&amp;#39;s starting to look like actual engineering.&lt;/p&gt;\n\n&lt;p&gt;Now comes the part where everything starts crashing down.  Since we have a more organized development practices, our new manager starts assigning tasks within these platforms to other engineers.  I come to find out that the senior engineer I replaced was the only data engineer who had touched these processes within the last year.  I also learn that none of the other DE&amp;#39;s (including 4 senior DE&amp;#39;s) have any experience with programming outside of SQL.  &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a list of some of the issues I&amp;#39;ve run into:&lt;br/&gt;\nEngineer wants me to give him prod access so he can do his development there instead of locally.&lt;/p&gt;\n\n&lt;p&gt;Senior engineers don&amp;#39;t know how to navigate a CLI.&lt;/p&gt;\n\n&lt;p&gt;Engineers have no idea how to use git, and I am there personal git encyclopedia.&lt;/p&gt;\n\n&lt;p&gt;Engineers breaking stuff with a git GUI, requiring me to fix it.&lt;/p&gt;\n\n&lt;p&gt;Engineers pushing back on git usage entirely.&lt;/p&gt;\n\n&lt;p&gt;Senior engineer with 12 years at the company does not know what a for-loop is.&lt;/p&gt;\n\n&lt;p&gt;Complaints about me requiring unit testing and some form of documentation that the code works before pushing to production.&lt;/p&gt;\n\n&lt;p&gt;Some engineers simply cannot comprehend how Docker works, and want my help to configure their windows laptop into a development environment (I am not helping you stand up a Postgres instance directly on your Windows OS).&lt;/p&gt;\n\n&lt;p&gt;I am at my wits end.  I&amp;#39;ve essentially been designated as a mentor for the side of the DE house that I work in.  That&amp;#39;s fine, but I was not hired as a senior, and it is really demotivating mentoring the people who I thought should be mentoring me.  I really do want to see the team succeed, but there has been so much pushback on following best-practices and learning new skills.  Is this common in the DE field?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1549emd", "is_robot_indexable": true, "report_reasons": null, "author": "Techthrowaway2222888", "discussion_type": null, "num_comments": 150, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1549emd/is_it_normal_for_data_engineers_to_be_lacking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1549emd/is_it_normal_for_data_engineers_to_be_lacking/", "subreddit_subscribers": 117029, "created_utc": 1689806565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just a quick rant. Thankfully I don\u2019t have to deal with this woman anymore since I\u2019m changing companies soon. \n\nWe had a legacy process of sql queries running on notebooks done by non-engineers. \n\nNow, the company decided that because this product brings a lot of money, it should be maintained by actual engineers. My team started working on this \u201cmigration\u201d and now that almost everything is done, this PO wants to have access to change code, etc. She is questioning every engineering decision Ive made like if she knew. Aside from not knowing what git is, I got a funny (not really funny) passive aggressive question \u201cwhy do you have everything starting with feature on github, better rename it to something we all know what it means\u201d. This is just the tip of the iceberg lol.\n\nI honestly feel sorry for my teammates that will have to deal with her after I\u2019m gone. \n\nHope no one in this sub is going through this lol.", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u201cTechnical\u201d PO driving me and my team nuts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154qdwf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689858267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a quick rant. Thankfully I don\u2019t have to deal with this woman anymore since I\u2019m changing companies soon. &lt;/p&gt;\n\n&lt;p&gt;We had a legacy process of sql queries running on notebooks done by non-engineers. &lt;/p&gt;\n\n&lt;p&gt;Now, the company decided that because this product brings a lot of money, it should be maintained by actual engineers. My team started working on this \u201cmigration\u201d and now that almost everything is done, this PO wants to have access to change code, etc. She is questioning every engineering decision Ive made like if she knew. Aside from not knowing what git is, I got a funny (not really funny) passive aggressive question \u201cwhy do you have everything starting with feature on github, better rename it to something we all know what it means\u201d. This is just the tip of the iceberg lol.&lt;/p&gt;\n\n&lt;p&gt;I honestly feel sorry for my teammates that will have to deal with her after I\u2019m gone. &lt;/p&gt;\n\n&lt;p&gt;Hope no one in this sub is going through this lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "154qdwf", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154qdwf/technical_po_driving_me_and_my_team_nuts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154qdwf/technical_po_driving_me_and_my_team_nuts/", "subreddit_subscribers": 117029, "created_utc": 1689858267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am (Data) engineer with near to 5 years of experience in Data. \n\nMy experience consists of working majorly on SQL (have got intermediate level expertise) and in past 1 year am working on Snowflake sql and ETL tools (Datastage &amp; Snaplogic - but not too deep).. Apart from these know some basics on Power BI &amp; recently started on Python).. \n\nI am STUCK as I feel like more of Support Engineer than Dev &amp; have no idea on what to do next as DE is becoming code heavy &amp; I don\u2019t like  advance BI tool work as it\u2019s slow, frustrating with those DAX &amp; M language. \n\nSo should I continue in DE (by learning any visual ETL tool like ADF) OR\n become Data Analyst (but BI tools are must here which I am not comfortable due to above)\nOR \nis becoming Data Scientist possible? \n\nREALLY NEED HELP \ud83d\ude4f\ud83c\udffb", "author_fullname": "t2_cw3fmfvos", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice in deciding DE Career path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154jdep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689835969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am (Data) engineer with near to 5 years of experience in Data. &lt;/p&gt;\n\n&lt;p&gt;My experience consists of working majorly on SQL (have got intermediate level expertise) and in past 1 year am working on Snowflake sql and ETL tools (Datastage &amp;amp; Snaplogic - but not too deep).. Apart from these know some basics on Power BI &amp;amp; recently started on Python).. &lt;/p&gt;\n\n&lt;p&gt;I am STUCK as I feel like more of Support Engineer than Dev &amp;amp; have no idea on what to do next as DE is becoming code heavy &amp;amp; I don\u2019t like  advance BI tool work as it\u2019s slow, frustrating with those DAX &amp;amp; M language. &lt;/p&gt;\n\n&lt;p&gt;So should I continue in DE (by learning any visual ETL tool like ADF) OR\n become Data Analyst (but BI tools are must here which I am not comfortable due to above)\nOR \nis becoming Data Scientist possible? &lt;/p&gt;\n\n&lt;p&gt;REALLY NEED HELP \ud83d\ude4f\ud83c\udffb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "154jdep", "is_robot_indexable": true, "report_reasons": null, "author": "raj_gd", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154jdep/need_advice_in_deciding_de_career_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154jdep/need_advice_in_deciding_de_career_path/", "subreddit_subscribers": 117029, "created_utc": 1689835969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Had a systems design interview that I failed because I wasn't sure how to answer this question.\n\nMy naive ass said I would store it all on an in-mem db like redis and set the params there and just call the process that way.\n\nNot sure if there's a better way", "author_fullname": "t2_4jzrd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you have 100 different data sources and each one needs to have a different config file. What's the best way to design this process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154g5w3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689825254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had a systems design interview that I failed because I wasn&amp;#39;t sure how to answer this question.&lt;/p&gt;\n\n&lt;p&gt;My naive ass said I would store it all on an in-mem db like redis and set the params there and just call the process that way.&lt;/p&gt;\n\n&lt;p&gt;Not sure if there&amp;#39;s a better way&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "154g5w3", "is_robot_indexable": true, "report_reasons": null, "author": "epictaco", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154g5w3/if_you_have_100_different_data_sources_and_each/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154g5w3/if_you_have_100_different_data_sources_and_each/", "subreddit_subscribers": 117029, "created_utc": 1689825254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I need some suggestions for projects involving Spark or Spark Streaming with Kafka and ELK, as I have searched but haven't found anything yet. I am just a little bit confused. Can anyone please help me? ", "author_fullname": "t2_feara4tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I would like some project suggestions involving Spark.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154pq2q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689856510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need some suggestions for projects involving Spark or Spark Streaming with Kafka and ELK, as I have searched but haven&amp;#39;t found anything yet. I am just a little bit confused. Can anyone please help me? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "154pq2q", "is_robot_indexable": true, "report_reasons": null, "author": "Kratos_1412", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154pq2q/i_would_like_some_project_suggestions_involving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154pq2q/i_would_like_some_project_suggestions_involving/", "subreddit_subscribers": 117029, "created_utc": 1689856510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow DEs!\n\nI've been exploring the idea of seeing tables as mathematical functions, where each column is a lookup function of the table's index:\n\nMath: `f(x)=y` Table: `column(index)=value`\n\nWhich means, theoretically, changes to the values in a table could be considered alterations to the table's \"code\". I come from a software engineering background, so my immediate reaction to this thought is that changes to code should always be tracked in a version control system so that:\n\n1. Differences between old and new code can be identified\n2. Code changes can be staged for testing compatibility\n3. We can track change metadata about who made the changes and when they were made\n4. Changes can be reverted to an old version\n\nI've seen hints here and there of people trying to solve these problems. For each of the above version control attributes, below are the current technologies that come to mind to solve the same problem (keep in mind I am fairly new to the industry and haven't used any of these)\n\n1. DataFold's data-diff tool\n2. dbt-tests\n3. change data capture\n4. database time travel\n\nSo I'm thinking that the data engineering field will eventually develop its own version of git for databases, but I would love to hear other people's opinions on whether there is a need or if it is even feasible.", "author_fullname": "t2_vaz49s8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data as Code - Git like history for Databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154wh3y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689872108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow DEs!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been exploring the idea of seeing tables as mathematical functions, where each column is a lookup function of the table&amp;#39;s index:&lt;/p&gt;\n\n&lt;p&gt;Math: &lt;code&gt;f(x)=y&lt;/code&gt; Table: &lt;code&gt;column(index)=value&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Which means, theoretically, changes to the values in a table could be considered alterations to the table&amp;#39;s &amp;quot;code&amp;quot;. I come from a software engineering background, so my immediate reaction to this thought is that changes to code should always be tracked in a version control system so that:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Differences between old and new code can be identified&lt;/li&gt;\n&lt;li&gt;Code changes can be staged for testing compatibility&lt;/li&gt;\n&lt;li&gt;We can track change metadata about who made the changes and when they were made&lt;/li&gt;\n&lt;li&gt;Changes can be reverted to an old version&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve seen hints here and there of people trying to solve these problems. For each of the above version control attributes, below are the current technologies that come to mind to solve the same problem (keep in mind I am fairly new to the industry and haven&amp;#39;t used any of these)&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;DataFold&amp;#39;s data-diff tool&lt;/li&gt;\n&lt;li&gt;dbt-tests&lt;/li&gt;\n&lt;li&gt;change data capture&lt;/li&gt;\n&lt;li&gt;database time travel&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So I&amp;#39;m thinking that the data engineering field will eventually develop its own version of git for databases, but I would love to hear other people&amp;#39;s opinions on whether there is a need or if it is even feasible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "154wh3y", "is_robot_indexable": true, "report_reasons": null, "author": "stringofsense", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154wh3y/data_as_code_git_like_history_for_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154wh3y/data_as_code_git_like_history_for_databases/", "subreddit_subscribers": 117029, "created_utc": 1689872108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are working on a streaming spark data pipeline that reads events from multiple Kafka topics, perform some stateful operations on the data and outputs it to another Kafka topic.\nToday when we want to deploy a new version, we need to stop the currently running jobs, upload the jars to synapse (yes we are using synapse), and then run it again, picking up from where the checkpoint left off. checkpoint is crucial here btw because it stores data about state which helps with the stateful operations.\n\nHas anyone who's doing similar stuff achieved zero down time deployments without losing data and with minimum side effects?\nI would love to hear about your techniques.\n\nThanks!", "author_fullname": "t2_epwdhiqls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How did you get zero down time in your streaming data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154v5vj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689869211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are working on a streaming spark data pipeline that reads events from multiple Kafka topics, perform some stateful operations on the data and outputs it to another Kafka topic.\nToday when we want to deploy a new version, we need to stop the currently running jobs, upload the jars to synapse (yes we are using synapse), and then run it again, picking up from where the checkpoint left off. checkpoint is crucial here btw because it stores data about state which helps with the stateful operations.&lt;/p&gt;\n\n&lt;p&gt;Has anyone who&amp;#39;s doing similar stuff achieved zero down time deployments without losing data and with minimum side effects?\nI would love to hear about your techniques.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "154v5vj", "is_robot_indexable": true, "report_reasons": null, "author": "data_is_great", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154v5vj/how_did_you_get_zero_down_time_in_your_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154v5vj/how_did_you_get_zero_down_time_in_your_streaming/", "subreddit_subscribers": 117029, "created_utc": 1689869211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Did you perhaps singlehanded do [data engineering task]?\n\nOr did you solve [difficult data engineering problem]?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the most impressive thing you\u2019ve ever done as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154zbbu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689878337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did you perhaps singlehanded do [data engineering task]?&lt;/p&gt;\n\n&lt;p&gt;Or did you solve [difficult data engineering problem]?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "154zbbu", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154zbbu/what_is_the_most_impressive_thing_youve_ever_done/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154zbbu/what_is_the_most_impressive_thing_youve_ever_done/", "subreddit_subscribers": 117029, "created_utc": 1689878337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHello there,\n\nPosted this on the Github subreddit without much response and I feel this somewhat more tailored towards this sub anyway.\n\nI work for a fairly large company that already uses GH, however the team I work with and others surrounding it do not (I am fairly new and the teams never bothered with it I guess)! Our manager wants us to start utilizing GH.\n\nDoes anyone have any tips/suggestions about where to start and which/what features are super helpful to teams? Anything like a checklist of \"must-haves\"?\n\nSome things to note - we are primarily backend devs/data engineers/data scientists. The overwhelming majority of our code is in T-SQL or Python/Jupyter. We also have A LOT of SSIS packages and some things in Databricks.\n\nI have a couple years experience working with it (creating/submitting PR's, squashing, basic things).\n\nSome early questions I have been trying to answer is if Code Spaces or Actions would be useful - how are your experiences with these? Does it make sense in a team of \\~15-20 people? And what kind of structure makes sense? Should we be operating out of one repo or many?\n\nThank you!", "author_fullname": "t2_gsch4oaq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Github tips/suggestions for small team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1548dlo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689804108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there,&lt;/p&gt;\n\n&lt;p&gt;Posted this on the Github subreddit without much response and I feel this somewhat more tailored towards this sub anyway.&lt;/p&gt;\n\n&lt;p&gt;I work for a fairly large company that already uses GH, however the team I work with and others surrounding it do not (I am fairly new and the teams never bothered with it I guess)! Our manager wants us to start utilizing GH.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any tips/suggestions about where to start and which/what features are super helpful to teams? Anything like a checklist of &amp;quot;must-haves&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;Some things to note - we are primarily backend devs/data engineers/data scientists. The overwhelming majority of our code is in T-SQL or Python/Jupyter. We also have A LOT of SSIS packages and some things in Databricks.&lt;/p&gt;\n\n&lt;p&gt;I have a couple years experience working with it (creating/submitting PR&amp;#39;s, squashing, basic things).&lt;/p&gt;\n\n&lt;p&gt;Some early questions I have been trying to answer is if Code Spaces or Actions would be useful - how are your experiences with these? Does it make sense in a team of ~15-20 people? And what kind of structure makes sense? Should we be operating out of one repo or many?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1548dlo", "is_robot_indexable": true, "report_reasons": null, "author": "xxEiGhTyxx", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1548dlo/github_tipssuggestions_for_small_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1548dlo/github_tipssuggestions_for_small_team/", "subreddit_subscribers": 117029, "created_utc": 1689804108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For audit purposes, how do you keep track of what database or other resources permissions have been granted, who has approved, etc.?\n\nAre you managing this with spreadsheets, or a dedicated tool?", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does your permissions approval process look like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154ufoc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689867669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For audit purposes, how do you keep track of what database or other resources permissions have been granted, who has approved, etc.?&lt;/p&gt;\n\n&lt;p&gt;Are you managing this with spreadsheets, or a dedicated tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "154ufoc", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154ufoc/what_does_your_permissions_approval_process_look/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154ufoc/what_does_your_permissions_approval_process_look/", "subreddit_subscribers": 117029, "created_utc": 1689867669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I get what the binary data type is, but am unsure on when I should be leaving a field as binary and when I should be storing it as a string.\n\nIs the sole difference that it's not being represented in a specific string format like UTF-8?\n\nIs there performance overhead on casting that to a string on reads that would make it beneficial to cast to string during an initial table write?\n\nAnother way to ask the question: Should only binary data be stored as binary or is there an advantage to storing text/string/json data as binary?", "author_fullname": "t2_gs0mp007", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta tables: Binary vs String data types", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154tym1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689867895.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689866625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I get what the binary data type is, but am unsure on when I should be leaving a field as binary and when I should be storing it as a string.&lt;/p&gt;\n\n&lt;p&gt;Is the sole difference that it&amp;#39;s not being represented in a specific string format like UTF-8?&lt;/p&gt;\n\n&lt;p&gt;Is there performance overhead on casting that to a string on reads that would make it beneficial to cast to string during an initial table write?&lt;/p&gt;\n\n&lt;p&gt;Another way to ask the question: Should only binary data be stored as binary or is there an advantage to storing text/string/json data as binary?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "154tym1", "is_robot_indexable": true, "report_reasons": null, "author": "RandomWalk55", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154tym1/delta_tables_binary_vs_string_data_types/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154tym1/delta_tables_binary_vs_string_data_types/", "subreddit_subscribers": 117029, "created_utc": 1689866625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4tv0n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Athena Provisioned Capacity Review", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_154szgo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MlGe4emC5mxF-O-YiOCHrfM966nOfJamNFbQG2Q0ino.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689864471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bit.kevinslin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bit.kevinslin.com/p/athena-provisioned-capacity", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PqA-zJUJEgaV5WIWYsRoP2SO-B3WRM89SdCwdK321bA.jpg?auto=webp&amp;s=8eb0b7746d6fd8235530df42cb132be0c06ddea0", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/PqA-zJUJEgaV5WIWYsRoP2SO-B3WRM89SdCwdK321bA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e04bb3da92d14f7b71b816b0db79f91716706d2d", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/PqA-zJUJEgaV5WIWYsRoP2SO-B3WRM89SdCwdK321bA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ccf9a3792d196825affec568401488959f01eb3f", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/PqA-zJUJEgaV5WIWYsRoP2SO-B3WRM89SdCwdK321bA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6504618e8e79ab699c7df70d931108cdeea587c1", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/PqA-zJUJEgaV5WIWYsRoP2SO-B3WRM89SdCwdK321bA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=223c55c4a3a37a3bf354cba6f41b81e84beed303", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/PqA-zJUJEgaV5WIWYsRoP2SO-B3WRM89SdCwdK321bA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=13238e9d11ef49a57b13aae1481e6b5da42f5e54", "width": 960, "height": 562}], "variants": {}, "id": "MAwhWfFlfZREUljbE5PsJPHjgIf3RbYYEyMz3G4plSU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "154szgo", "is_robot_indexable": true, "report_reasons": null, "author": "kevins8", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154szgo/athena_provisioned_capacity_review/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bit.kevinslin.com/p/athena-provisioned-capacity", "subreddit_subscribers": 117029, "created_utc": 1689864471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nAs many of us are in the process of job hunting or preparing for interviews, it would be extremely helpful to gain insights into the types of questions being asked in recent system design interviews.\nPlease include\n\nCompany:\nTopic:\n\nYour contributions are much appreciated and I hope that we can learn a lot from each other's experiences.\r\n\r\n #Software #SystemDesign #System #Intervie", "author_fullname": "t2_mi42h86v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Share System Design interview topic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154i6yc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689831838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;As many of us are in the process of job hunting or preparing for interviews, it would be extremely helpful to gain insights into the types of questions being asked in recent system design interviews.\nPlease include&lt;/p&gt;\n\n&lt;p&gt;Company:\nTopic:&lt;/p&gt;\n\n&lt;p&gt;Your contributions are much appreciated and I hope that we can learn a lot from each other&amp;#39;s experiences.&lt;/p&gt;\n\n&lt;p&gt;#Software #SystemDesign #System #Intervie&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "154i6yc", "is_robot_indexable": true, "report_reasons": null, "author": "pauloj1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154i6yc/share_system_design_interview_topic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154i6yc/share_system_design_interview_topic/", "subreddit_subscribers": 117029, "created_utc": 1689831838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking to start applying for my first DE job. I was thinking about making a portfolio website, but then I wasn\u2019t sure if it would be a good idea to delay job applying because of that. I\u2019m not from CS/data background, so I felt like I\u2019d really have to present my projects well, including the web development skills by building a portfolio web, in order to pass the interview screenings. I will eventually make one in the future, but since I want to get out of my current job so bad and since it is not a remote, I\u2019m leaning towards not making one right now. \nAnd also, how important is LinkedIn when searching for jobs? My current LI acc is restricted for some reason, and it\u2019s taking forever for them to resolve it..(apparently many people are experiencing this issue)\n\nThanks for any advice.", "author_fullname": "t2_luzwqwgm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is GitHub enough to show projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1548nku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689804746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to start applying for my first DE job. I was thinking about making a portfolio website, but then I wasn\u2019t sure if it would be a good idea to delay job applying because of that. I\u2019m not from CS/data background, so I felt like I\u2019d really have to present my projects well, including the web development skills by building a portfolio web, in order to pass the interview screenings. I will eventually make one in the future, but since I want to get out of my current job so bad and since it is not a remote, I\u2019m leaning towards not making one right now. \nAnd also, how important is LinkedIn when searching for jobs? My current LI acc is restricted for some reason, and it\u2019s taking forever for them to resolve it..(apparently many people are experiencing this issue)&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1548nku", "is_robot_indexable": true, "report_reasons": null, "author": "Neat_Historian9740", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1548nku/is_github_enough_to_show_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1548nku/is_github_enough_to_show_projects/", "subreddit_subscribers": 117029, "created_utc": 1689804746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\nI'm working on a project and need your guidance. I'm attempting to build a solution that daily downloads a file from a REST API, makes another call to the same API to indicate I want another measurement for the day (to be retrieved \"tomorrow\"), and then stores this file in a specific format: id-date.json. This process is repeated for 3 different IDs, resulting in 3 files per day.\n\nI have a background in Python and am using Azure. My current approach uses Azure Functions, with Python v2 selected for the runtime. The documentation suggested using the `func.write_blob` decorator, but I couldn't get it to work, so I switched to the `azure.storage` module. While I'm able to run it locally, I'm facing issues with deployment.\n\nMy questions for the community:\n\n1. Am I on the right track, or should I consider a different tool or methodology for this task?\n2. For those of you who've done something similar, how did you tackle this problem? \n\nThis seems like a common workflow, yet I've struggled to find a simple, straightforward example. Any tips, suggestions, or pointers to resources would be greatly appreciated!\n\nThanks in advance!", "author_fullname": "t2_r81va7is", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help with Automating Daily REST API Calls and File Storage using Python and Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154yptu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689877025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a project and need your guidance. I&amp;#39;m attempting to build a solution that daily downloads a file from a REST API, makes another call to the same API to indicate I want another measurement for the day (to be retrieved &amp;quot;tomorrow&amp;quot;), and then stores this file in a specific format: id-date.json. This process is repeated for 3 different IDs, resulting in 3 files per day.&lt;/p&gt;\n\n&lt;p&gt;I have a background in Python and am using Azure. My current approach uses Azure Functions, with Python v2 selected for the runtime. The documentation suggested using the &lt;code&gt;func.write_blob&lt;/code&gt; decorator, but I couldn&amp;#39;t get it to work, so I switched to the &lt;code&gt;azure.storage&lt;/code&gt; module. While I&amp;#39;m able to run it locally, I&amp;#39;m facing issues with deployment.&lt;/p&gt;\n\n&lt;p&gt;My questions for the community:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Am I on the right track, or should I consider a different tool or methodology for this task?&lt;/li&gt;\n&lt;li&gt;For those of you who&amp;#39;ve done something similar, how did you tackle this problem? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This seems like a common workflow, yet I&amp;#39;ve struggled to find a simple, straightforward example. Any tips, suggestions, or pointers to resources would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "154yptu", "is_robot_indexable": true, "report_reasons": null, "author": "Next_Sink9778", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154yptu/need_help_with_automating_daily_rest_api_calls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154yptu/need_help_with_automating_daily_rest_api_calls/", "subreddit_subscribers": 117029, "created_utc": 1689877025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been exploring open-sourced tools to ensure data quality and implement an alerting system based on SQL-based validation rules. During my research, I came across Dataform. I would appreciate your opinion on whether it is the most suitable tool for my use case.\n\nI have tried Great Expectations but have come to the opinion that it is not well-suited for SQL-based validation.", "author_fullname": "t2_8vje3f0m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Dataform relevant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154h3p2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689828170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been exploring open-sourced tools to ensure data quality and implement an alerting system based on SQL-based validation rules. During my research, I came across Dataform. I would appreciate your opinion on whether it is the most suitable tool for my use case.&lt;/p&gt;\n\n&lt;p&gt;I have tried Great Expectations but have come to the opinion that it is not well-suited for SQL-based validation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "154h3p2", "is_robot_indexable": true, "report_reasons": null, "author": "Itchy_Advantage_6267", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154h3p2/is_dataform_relevant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154h3p2/is_dataform_relevant/", "subreddit_subscribers": 117029, "created_utc": 1689828170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working as the sole DE on a non tech team. I am free to use whichever tool/tech I want. As I want to transition to backend dev, I want to learn and implement microservices, rest apis, lambdas. I am looking for suggestions on how and where I can use this in my role. P.S: We use GUI ETL tools to get data from external databases, use python to get data from external apis and push all to redshift. All jobs are on AWS instance. The data in redshift is the source for tableau dashboards", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing microservices, API in DE context", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154exvt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689821595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working as the sole DE on a non tech team. I am free to use whichever tool/tech I want. As I want to transition to backend dev, I want to learn and implement microservices, rest apis, lambdas. I am looking for suggestions on how and where I can use this in my role. P.S: We use GUI ETL tools to get data from external databases, use python to get data from external apis and push all to redshift. All jobs are on AWS instance. The data in redshift is the source for tableau dashboards&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "154exvt", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154exvt/implementing_microservices_api_in_de_context/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154exvt/implementing_microservices_api_in_de_context/", "subreddit_subscribers": 117029, "created_utc": 1689821595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Came to Reddit to scroll for a bit. Scroll stopped at the first 2 posts on r/dataengineering.\n\nTop 2 posts are associated with skill gaps in product management and data engineering. Have an idea and I want to validate if it makes sense. So here goes...\n\nI am considering **offering my time for 3 free sessions of up to 60 minutes every week to discuss data careers, data architecture, data products, learning resources etc. with data practitioners**.\n\nI am also happy to record these conversations and share the recordings with you, or as podcast episodes to share and contribute to building your brand. (Flexible on this point)\n\nIf you are raising your eyebrows at 'free sessions'... Kudos to you for thinking critically. Here is my reasoning.\n\n**Why do I want to do this? What's in it for me?** *(Discovery and research as always)*\n\n* I want to prioritize learning from actual experiences over scrolling through social media and internet newsletters.\n* I work for a company building a composable data platform and iterating through a data product management mastermind with a handful of my past coworkers.\n* I am already talking to our current users and my existing network and I want to broaden the scope of my research beyond my echo chamber.\n\n**Is my time valuable to you?** *(Maybe... you decide)*\n\n* I am currently a Head of product at a sufficiently funded startup working to fix a few basic broken building blocks of data pipelines.\n* Prior to this I have led data and platform products in eCommerce, automotive manufacturing, surveillance, healthcare and life sciences.\n* I worked as a hands on data engineer from 2009 to 2014 and a software engineer from 2006 to 2009.\n* Through the last 10 years I have:\n   * Mentored several (100s) of data engineers, architects, product managers over the last 10 years.\n   * Managed teams of 12 to 60 people.\n   * Been in interview panels for data roles.\n   * Been in the instructor panel and advisory groups for technical training companies.\n\n**Who is this for?**\n\n* Senior data engineers/architects with experience in scalable data pipelines and data products.\n* Have experience with deploying data pipelines using tools like Kafka, Kinesis, Data Flow, Beam, Pulsar, K-Streams, Spark, Flink etc. (I am interested in diving deeper into this ecosystem right now)\n\nIf this resonates with you - **Book some time on** [**my calendar**](https://app.reclaim.ai/m/drc/high-priority-meeting)\n\nIf you have any questions or feedback, I will look for them in the comments.\n\nThat's it! My 1/10 \\*anonymous\\* self promotional content. Fingers crossed.", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Purposeful networking sessions, *therapy sessions*, coaching/mentoring conversations with data folks [Free]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15532vo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689886740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Came to Reddit to scroll for a bit. Scroll stopped at the first 2 posts on &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Top 2 posts are associated with skill gaps in product management and data engineering. Have an idea and I want to validate if it makes sense. So here goes...&lt;/p&gt;\n\n&lt;p&gt;I am considering &lt;strong&gt;offering my time for 3 free sessions of up to 60 minutes every week to discuss data careers, data architecture, data products, learning resources etc. with data practitioners&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;I am also happy to record these conversations and share the recordings with you, or as podcast episodes to share and contribute to building your brand. (Flexible on this point)&lt;/p&gt;\n\n&lt;p&gt;If you are raising your eyebrows at &amp;#39;free sessions&amp;#39;... Kudos to you for thinking critically. Here is my reasoning.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why do I want to do this? What&amp;#39;s in it for me?&lt;/strong&gt; &lt;em&gt;(Discovery and research as always)&lt;/em&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I want to prioritize learning from actual experiences over scrolling through social media and internet newsletters.&lt;/li&gt;\n&lt;li&gt;I work for a company building a composable data platform and iterating through a data product management mastermind with a handful of my past coworkers.&lt;/li&gt;\n&lt;li&gt;I am already talking to our current users and my existing network and I want to broaden the scope of my research beyond my echo chamber.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Is my time valuable to you?&lt;/strong&gt; &lt;em&gt;(Maybe... you decide)&lt;/em&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I am currently a Head of product at a sufficiently funded startup working to fix a few basic broken building blocks of data pipelines.&lt;/li&gt;\n&lt;li&gt;Prior to this I have led data and platform products in eCommerce, automotive manufacturing, surveillance, healthcare and life sciences.&lt;/li&gt;\n&lt;li&gt;I worked as a hands on data engineer from 2009 to 2014 and a software engineer from 2006 to 2009.&lt;/li&gt;\n&lt;li&gt;Through the last 10 years I have:\n\n&lt;ul&gt;\n&lt;li&gt;Mentored several (100s) of data engineers, architects, product managers over the last 10 years.&lt;/li&gt;\n&lt;li&gt;Managed teams of 12 to 60 people.&lt;/li&gt;\n&lt;li&gt;Been in interview panels for data roles.&lt;/li&gt;\n&lt;li&gt;Been in the instructor panel and advisory groups for technical training companies.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Who is this for?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Senior data engineers/architects with experience in scalable data pipelines and data products.&lt;/li&gt;\n&lt;li&gt;Have experience with deploying data pipelines using tools like Kafka, Kinesis, Data Flow, Beam, Pulsar, K-Streams, Spark, Flink etc. (I am interested in diving deeper into this ecosystem right now)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If this resonates with you - &lt;strong&gt;Book some time on&lt;/strong&gt; &lt;a href=\"https://app.reclaim.ai/m/drc/high-priority-meeting\"&gt;&lt;strong&gt;my calendar&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you have any questions or feedback, I will look for them in the comments.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s it! My 1/10 *anonymous* self promotional content. Fingers crossed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JJ8-l-skRdlFc0hTH4NZcPCCVg7s_cy4tnHGT6K7RtM.jpg?auto=webp&amp;s=2010e51e52ab26fe3a578b55469133f32a24685b", "width": 672, "height": 429}, "resolutions": [{"url": "https://external-preview.redd.it/JJ8-l-skRdlFc0hTH4NZcPCCVg7s_cy4tnHGT6K7RtM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=abe534a6d607969b5a65e4b64231cb8a98ba4752", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/JJ8-l-skRdlFc0hTH4NZcPCCVg7s_cy4tnHGT6K7RtM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=62e488a23869a114885c5661772ab97704572a6a", "width": 216, "height": 137}, {"url": "https://external-preview.redd.it/JJ8-l-skRdlFc0hTH4NZcPCCVg7s_cy4tnHGT6K7RtM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=64b8078140860ea28cb02e0fb781357527599912", "width": 320, "height": 204}, {"url": "https://external-preview.redd.it/JJ8-l-skRdlFc0hTH4NZcPCCVg7s_cy4tnHGT6K7RtM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6fb8c3fb6cb193ea7111de34b09d79276a9b0b63", "width": 640, "height": 408}], "variants": {}, "id": "4rEzINWv8yA14zzwIXLze5cdnyTs_q30mV3yRfnVCz4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15532vo", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15532vo/purposeful_networking_sessions_therapy_sessions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15532vo/purposeful_networking_sessions_therapy_sessions/", "subreddit_subscribers": 117029, "created_utc": 1689886740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you have a source system that typically sends data into your data lake every hour, how can you handle delayed data or missing data altogether? what if the source system sends incomplete data?\n\nI'd imagine there are a few options:\n\n\\- your pipeline can be event-driven (lambda, CF) so lateness doesn't matter, whatever arrives is processed accordingly\n\n\\- your pipeline has sensors (a la airflow) that wait for data to arrive and fail or timeout after a given window\n\n\\- your pipeline has the ability to keep track of data that is \"supposed\" to be there and queues it up for a later data pull / streaming window.\n\n\\- your pipeline uses data quality checks (Deequ, GX, etc.) that determine if a batch of data fails to meet a certain requirement and then retries (?)\n\n&amp;#x200B;\n\nHow do you handle this scenario at your companies? What services do you use?", "author_fullname": "t2_ksjg7gi8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best approach to handle missing data or late data coming from source systems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15520f1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689884382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you have a source system that typically sends data into your data lake every hour, how can you handle delayed data or missing data altogether? what if the source system sends incomplete data?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d imagine there are a few options:&lt;/p&gt;\n\n&lt;p&gt;- your pipeline can be event-driven (lambda, CF) so lateness doesn&amp;#39;t matter, whatever arrives is processed accordingly&lt;/p&gt;\n\n&lt;p&gt;- your pipeline has sensors (a la airflow) that wait for data to arrive and fail or timeout after a given window&lt;/p&gt;\n\n&lt;p&gt;- your pipeline has the ability to keep track of data that is &amp;quot;supposed&amp;quot; to be there and queues it up for a later data pull / streaming window.&lt;/p&gt;\n\n&lt;p&gt;- your pipeline uses data quality checks (Deequ, GX, etc.) that determine if a batch of data fails to meet a certain requirement and then retries (?)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How do you handle this scenario at your companies? What services do you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15520f1", "is_robot_indexable": true, "report_reasons": null, "author": "cyoogler", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15520f1/what_is_the_best_approach_to_handle_missing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15520f1/what_is_the_best_approach_to_handle_missing_data/", "subreddit_subscribers": 117029, "created_utc": 1689884382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After university I got hired as the only engineer to a data team serving dozens of companies (within the company). Since then, Ive done everything from setting up data loaders,  pipelines, and self hosted airflow myself. Recently got a SQL/Python developer helping me do dbt migrations. Feeling pretty bummed out that I never had a full team around me to bounce ideas off of and I need to learn new things by myself. The people I help love me but I was wondering what size everybodys data engineering team is? Any advice for someone in my position to stay mentally strong?\n\n[View Poll](https://www.reddit.com/poll/1551x6d)", "author_fullname": "t2_kmq0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many data engineers are on your team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1551x6d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689884169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After university I got hired as the only engineer to a data team serving dozens of companies (within the company). Since then, Ive done everything from setting up data loaders,  pipelines, and self hosted airflow myself. Recently got a SQL/Python developer helping me do dbt migrations. Feeling pretty bummed out that I never had a full team around me to bounce ideas off of and I need to learn new things by myself. The people I help love me but I was wondering what size everybodys data engineering team is? Any advice for someone in my position to stay mentally strong?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1551x6d\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1551x6d", "is_robot_indexable": true, "report_reasons": null, "author": "specificanaldolphin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1690056969639, "options": [{"text": "1-2", "id": "23982640"}, {"text": "3-5", "id": "23982641"}, {"text": "6-10", "id": "23982642"}, {"text": "10-15", "id": "23982643"}, {"text": "16-20", "id": "23982644"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 40, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1551x6d/how_many_data_engineers_are_on_your_team/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/1551x6d/how_many_data_engineers_are_on_your_team/", "subreddit_subscribers": 117029, "created_utc": 1689884169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI am doing a redesign of our datalake (Azure) structure to support incremental loads.\n\nIt needs to support easy deletion of data from specific users. User data is in jsonl format.\n\nWould it make sense to just dump new data into json files, one new file per patient with new data? And then tag or prefix the filename with user ids?\n\nOr does it make more sense to use parquet files and partition by date or similar? I am not aware of any easy way to remove specific rows from parquet files.", "author_fullname": "t2_lixpgvfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datalake file structure design for easy deletion of specific user data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15510hy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689882120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I am doing a redesign of our datalake (Azure) structure to support incremental loads.&lt;/p&gt;\n\n&lt;p&gt;It needs to support easy deletion of data from specific users. User data is in jsonl format.&lt;/p&gt;\n\n&lt;p&gt;Would it make sense to just dump new data into json files, one new file per patient with new data? And then tag or prefix the filename with user ids?&lt;/p&gt;\n\n&lt;p&gt;Or does it make more sense to use parquet files and partition by date or similar? I am not aware of any easy way to remove specific rows from parquet files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15510hy", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping-Nail-250", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15510hy/datalake_file_structure_design_for_easy_deletion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15510hy/datalake_file_structure_design_for_easy_deletion/", "subreddit_subscribers": 117029, "created_utc": 1689882120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In terms of data engineering as a field, think of a seasoned data engineer as an ocean, and I'm just stepping into a plastic kiddie pool you get from Walmart. I've just begun to learn how to create an API in Python that creates a dataset and a table in BigQuery using an API key... What I want to know now is if it's important for my learning to understand how to move data from BigQuery to something like Snowflake? Perhaps I'm thinking about it inefficiently, and instead, I should be trying to now learn how to API into SF and replicate the creating of tables and importing data, not pipe from 1 data warehouse to another? ", "author_fullname": "t2_vnan4h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it important to learn how to move data from one DW to another? i.e. BQ&gt;Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154zy6w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689879733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In terms of data engineering as a field, think of a seasoned data engineer as an ocean, and I&amp;#39;m just stepping into a plastic kiddie pool you get from Walmart. I&amp;#39;ve just begun to learn how to create an API in Python that creates a dataset and a table in BigQuery using an API key... What I want to know now is if it&amp;#39;s important for my learning to understand how to move data from BigQuery to something like Snowflake? Perhaps I&amp;#39;m thinking about it inefficiently, and instead, I should be trying to now learn how to API into SF and replicate the creating of tables and importing data, not pipe from 1 data warehouse to another? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "154zy6w", "is_robot_indexable": true, "report_reasons": null, "author": "Analyst2163", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154zy6w/is_it_important_to_learn_how_to_move_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154zy6w/is_it_important_to_learn_how_to_move_data_from/", "subreddit_subscribers": 117029, "created_utc": 1689879733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI'm slowly learning more and more about data pipelines and dats engineering. I get how data engineering and pipeline creation works but every time I hear kubernetes it's like a black box to me. \n\nWhat do you do with kubernetes in data engineering. I know airflow is usually set up with kubernetes but idk what that generally means. \n\nAny resources you can provide or direction you can point me in would be helpful. Just trying to fill this gap in the data engineering life cycle that I don't understand.", "author_fullname": "t2_5ejp13jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering and Kubernetes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154yvxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689877384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m slowly learning more and more about data pipelines and dats engineering. I get how data engineering and pipeline creation works but every time I hear kubernetes it&amp;#39;s like a black box to me. &lt;/p&gt;\n\n&lt;p&gt;What do you do with kubernetes in data engineering. I know airflow is usually set up with kubernetes but idk what that generally means. &lt;/p&gt;\n\n&lt;p&gt;Any resources you can provide or direction you can point me in would be helpful. Just trying to fill this gap in the data engineering life cycle that I don&amp;#39;t understand.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "154yvxw", "is_robot_indexable": true, "report_reasons": null, "author": "knowledgeMeUp", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154yvxw/data_engineering_and_kubernetes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154yvxw/data_engineering_and_kubernetes/", "subreddit_subscribers": 117029, "created_utc": 1689877384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The evolution to the \"live data stack\" is getting easier with more options for streaming transformations + analytics (Flink, Druid, Materialize, Clickhouse, etc.), but I'm curious for a rough breakdown of data teams using it.\n\nFor folks using it in production - I'd also love to know the stack.\n\nEDIT: Typo, or \u2192 for\n\n[View Poll](https://www.reddit.com/poll/154xf4x)", "author_fullname": "t2_d09iwdzdc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is your data team using real-time streaming analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154xf4x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689883822.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689874189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The evolution to the &amp;quot;live data stack&amp;quot; is getting easier with more options for streaming transformations + analytics (Flink, Druid, Materialize, Clickhouse, etc.), but I&amp;#39;m curious for a rough breakdown of data teams using it.&lt;/p&gt;\n\n&lt;p&gt;For folks using it in production - I&amp;#39;d also love to know the stack.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Typo, or \u2192 for&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/154xf4x\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "154xf4x", "is_robot_indexable": true, "report_reasons": null, "author": "arthur-dataland-io", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1690133389372, "options": [{"text": "No", "id": "23980266"}, {"text": "No, but we have plans to do it in the next 2-3 years.", "id": "23980267"}, {"text": "Yes, but we're still exploring.", "id": "23980268"}, {"text": "Yes, we use it in production.", "id": "23980269"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 97, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154xf4x/is_your_data_team_using_realtime_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/154xf4x/is_your_data_team_using_realtime_streaming/", "subreddit_subscribers": 117029, "created_utc": 1689874189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I\u2019m currently interning as a Data Engineer and my project is solely a building a dashboard. I was looking forward to working on pipelines, data architecture, that sort of thing. \n\nMy question is, is building dashboards usually part of the job description of Data Engineers? I don\u2019t want to sound like I\u2019m complaining - building dashboards is a new challenge for me but I guess I was really excited going into the role and was slightly disappointed when I was assigned my project. \n\n\nAlso to note: I recognize the fact that they probably wont give an intern any business critical work - just wanted to get your guys\u2019 experience on what Data Engineers should expect their day to day to look like.", "author_fullname": "t2_42olh7qs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dashboarding as DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154x3o4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689873482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I\u2019m currently interning as a Data Engineer and my project is solely a building a dashboard. I was looking forward to working on pipelines, data architecture, that sort of thing. &lt;/p&gt;\n\n&lt;p&gt;My question is, is building dashboards usually part of the job description of Data Engineers? I don\u2019t want to sound like I\u2019m complaining - building dashboards is a new challenge for me but I guess I was really excited going into the role and was slightly disappointed when I was assigned my project. &lt;/p&gt;\n\n&lt;p&gt;Also to note: I recognize the fact that they probably wont give an intern any business critical work - just wanted to get your guys\u2019 experience on what Data Engineers should expect their day to day to look like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "154x3o4", "is_robot_indexable": true, "report_reasons": null, "author": "sakeoyakudon", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/154x3o4/dashboarding_as_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/154x3o4/dashboarding_as_de/", "subreddit_subscribers": 117029, "created_utc": 1689873482.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}