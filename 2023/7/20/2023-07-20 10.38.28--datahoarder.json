{"kind": "Listing", "data": {"after": "t3_153w48n", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Ordered 4x 12TB hard drives from a pretty well rated shop and that's how they shipped them to me...\nCurrently running a full SMART on them, and later will try a burn-in test (not sure how to even yet but will look it up).\n\nTo say I'm disappointed is an understatement tho...", "author_fullname": "t2_ebu8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "That's not the kind of packaging I'd I want to see when ordering 1000+\u20ac of hard drives...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"mhcjbhw8iwcb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/mhcjbhw8iwcb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd03d7e0bd90992ae404d516c10955b6a87899f8"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/mhcjbhw8iwcb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=91bb39a4be612168b5c773e8a98df5db9d378e9e"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/mhcjbhw8iwcb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e2a2815ad2eb63d20661b55c3a779ee24338de7"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/mhcjbhw8iwcb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ba4758ae3fdd204d65bec7c898cd05704c5d164"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/mhcjbhw8iwcb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f45986ecd7f1cf6caf2278daa929c943accbaa58"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/mhcjbhw8iwcb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=047fe188b777f4c6cdb3cac8b2164d36bc70095f"}], "s": {"y": 1644, "x": 2192, "u": "https://preview.redd.it/mhcjbhw8iwcb1.jpg?width=2192&amp;format=pjpg&amp;auto=webp&amp;s=b07b70bc38e7cbcf21cf4a2db8fc98e2488cf68e"}, "id": "mhcjbhw8iwcb1"}, "ba1fsiw8iwcb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/ba1fsiw8iwcb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a70f29b567b8fabe5baad56cc39c9ccf8a78333d"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/ba1fsiw8iwcb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=51e87e0c9524747964dbe8c2d39109ae7367be61"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/ba1fsiw8iwcb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1d5ea0a0dd67ded38fb3cd21932c97dd288de12"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/ba1fsiw8iwcb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=633ca350a580ddbe05d3ce29764ea2275a4073ea"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/ba1fsiw8iwcb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=26162f7b0e732945e9935aa7e1c0ef40d43ca8e0"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/ba1fsiw8iwcb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=83e78276d1c44806683c83ba594e9e63222a41be"}], "s": {"y": 1644, "x": 2192, "u": "https://preview.redd.it/ba1fsiw8iwcb1.jpg?width=2192&amp;format=pjpg&amp;auto=webp&amp;s=4ac1ef41edfb87824295107552bd36ec8deb559a"}, "id": "ba1fsiw8iwcb1"}, "5upkzhw8iwcb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/5upkzhw8iwcb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e2af1915493ac0c4d634b1aa265b7c90999436d"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/5upkzhw8iwcb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9e1f62bdbf206319a186d5749fb4046051663e8"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/5upkzhw8iwcb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab650c8b40b8aa1e35223bf15ee1f0ee78e80c83"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/5upkzhw8iwcb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e73d9e63b2c01474a4af607c14ff4c79afe21d3"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/5upkzhw8iwcb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5c2c86a61859fc5037364f3d0b12a24ea5e3bf06"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/5upkzhw8iwcb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99c90397d299cac82a5c76ca9bbdd5df7d9b7baa"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/5upkzhw8iwcb1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=11f095d889285af0c2ecd4361d9e1fcd81325dbf"}, "id": "5upkzhw8iwcb1"}, "ukb1whw8iwcb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/ukb1whw8iwcb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5726999800552f3975b4d833b3338ad937a9e45b"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/ukb1whw8iwcb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=943501ebac15781c60081dc08542786bd478c797"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/ukb1whw8iwcb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e53f7cd40aad2c1012a62610018b210d9ef1aaa"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/ukb1whw8iwcb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6eec92922e0e723427deb6111a2a662fe54b908c"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/ukb1whw8iwcb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bf1ec30ee78bbbe096c85b99d6349744746e6bdc"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/ukb1whw8iwcb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=340eddf53892e12081b0403b6a9f9d2e82b9b5c6"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/ukb1whw8iwcb1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=a2c688a4ebc9fab0dc3bf57b8740d5b897775526"}, "id": "ukb1whw8iwcb1"}, "kydvuhw8iwcb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/kydvuhw8iwcb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3bbe38ee1bebef618922200a0c24143054691ba2"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/kydvuhw8iwcb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dcca8e1e90aa4560777b11efebf05a21b18d519f"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/kydvuhw8iwcb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=959b56e33fc6096e2afa53383717f299a5ada12e"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/kydvuhw8iwcb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=229f72822a79f04d4f12b7a1383dc805a42405e9"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/kydvuhw8iwcb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad866d0d785d21c33686cb458c39d588157590af"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/kydvuhw8iwcb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5c04fe64c2ae91165b82e814f119733f5d25b650"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/kydvuhw8iwcb1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=97c312802e7c641d07865d45c86e3eced5b7c460"}, "id": "kydvuhw8iwcb1"}}, "name": "t3_153rgn7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 457, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "mhcjbhw8iwcb1", "id": 303656070}, {"media_id": "ba1fsiw8iwcb1", "id": 303656071}, {"media_id": "ukb1whw8iwcb1", "id": 303656072}, {"media_id": "kydvuhw8iwcb1", "id": 303656073}, {"media_id": "5upkzhw8iwcb1", "id": 303656074}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 457, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CXumEl7EMFOwQ3IvSzwS35Qf64Ur2GkL9Vz1q8cFdnA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689763439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ordered 4x 12TB hard drives from a pretty well rated shop and that&amp;#39;s how they shipped them to me...\nCurrently running a full SMART on them, and later will try a burn-in test (not sure how to even yet but will look it up).&lt;/p&gt;\n\n&lt;p&gt;To say I&amp;#39;m disappointed is an understatement tho...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/153rgn7", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "153rgn7", "is_robot_indexable": true, "report_reasons": null, "author": "EpicLPer", "discussion_type": null, "num_comments": 116, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/153rgn7/thats_not_the_kind_of_packaging_id_i_want_to_see/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/153rgn7", "subreddit_subscribers": 693383, "created_utc": 1689763439.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As the title implies, I would like to set up a dead man's switch in the case of my eventual, unpredicted demise.\n\nI do not have anything to hide, but I simply can't stomach the thought of someone having access to my accounts and private data once I am gone, not even my immediate family. I see those as an extension of my online footprint and wouldn't be able to die in peace knowing some random might access my accounts and the interactions I've had throughout the years.\n\nHow should I approach this feat? Any suggestions?", "author_fullname": "t2_i7iqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dead Man's Switch - How to approach it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1548ugv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689805199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title implies, I would like to set up a dead man&amp;#39;s switch in the case of my eventual, unpredicted demise.&lt;/p&gt;\n\n&lt;p&gt;I do not have anything to hide, but I simply can&amp;#39;t stomach the thought of someone having access to my accounts and private data once I am gone, not even my immediate family. I see those as an extension of my online footprint and wouldn&amp;#39;t be able to die in peace knowing some random might access my accounts and the interactions I&amp;#39;ve had throughout the years.&lt;/p&gt;\n\n&lt;p&gt;How should I approach this feat? Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1548ugv", "is_robot_indexable": true, "report_reasons": null, "author": "Zeno1441", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1548ugv/dead_mans_switch_how_to_approach_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1548ugv/dead_mans_switch_how_to_approach_it/", "subreddit_subscribers": 693383, "created_utc": 1689805199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/k6wrcw3aqxcb1.jpg?width=960&amp;format=pjpg&amp;auto=webp&amp;s=6e2847a759733e7fa176461bf83a25559da6eab5\n\nThe community merch store from valve ([https://valvestore.forfansbyfans.com/](https://valvestore.forfansbyfans.com/)) is going to close on and probably go offline on July 31. The store is also full with many high res artworks from various Valve titles.\n\nEntire Website + Media is around 2.8GB and consists of following domains.  \nMain Website: [https://valvestore.forfansbyfans.com/](https://valvestore.forfansbyfans.com/)  \nImage Host: [https://vsimgs3.forfansbyfans.com/](https://vsimgs3.forfansbyfans.com/) \\+ [https://vsimg.forfansbyfans.com/](https://vsimg.forfansbyfans.com/)  \nExternal JS: [https://fast.wistia.net/](https://fast.wistia.net/) [https://www.googletagmanager.com/gtag/](https://www.googletagmanager.com/gtag/)  [https://apis.google.com/](https://apis.google.com/)", "author_fullname": "t2_8jnr5wv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Valve Merch Shop closing on July 30 | With many Artworks from CSGO, Dota L4D....", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"k6wrcw3aqxcb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 82, "x": 108, "u": "https://preview.redd.it/k6wrcw3aqxcb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6de56119c9431ad43142fe05fe06b2730d48fa9a"}, {"y": 164, "x": 216, "u": "https://preview.redd.it/k6wrcw3aqxcb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c0449399518314edf62e25f21c9c2df2ddd5e6cd"}, {"y": 243, "x": 320, "u": "https://preview.redd.it/k6wrcw3aqxcb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f8b847f8be615dbc2f526ea0400f753ebcf42884"}, {"y": 486, "x": 640, "u": "https://preview.redd.it/k6wrcw3aqxcb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=655b14a9cb68fb6988836108c8c26f5344b16ad8"}, {"y": 730, "x": 960, "u": "https://preview.redd.it/k6wrcw3aqxcb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8bb94f26e668d1dcbedf6f36edadeade2eac6462"}], "s": {"y": 730, "x": 960, "u": "https://preview.redd.it/k6wrcw3aqxcb1.jpg?width=960&amp;format=pjpg&amp;auto=webp&amp;s=6e2847a759733e7fa176461bf83a25559da6eab5"}, "id": "k6wrcw3aqxcb1"}}, "name": "t3_153x5q2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lS7FkVqlZyiyQY6lC6mAPW9Z9BSpfpD--XSXTgGfYhc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1689778207.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/k6wrcw3aqxcb1.jpg?width=960&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=6e2847a759733e7fa176461bf83a25559da6eab5\"&gt;https://preview.redd.it/k6wrcw3aqxcb1.jpg?width=960&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=6e2847a759733e7fa176461bf83a25559da6eab5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The community merch store from valve (&lt;a href=\"https://valvestore.forfansbyfans.com/\"&gt;https://valvestore.forfansbyfans.com/&lt;/a&gt;) is going to close on and probably go offline on July 31. The store is also full with many high res artworks from various Valve titles.&lt;/p&gt;\n\n&lt;p&gt;Entire Website + Media is around 2.8GB and consists of following domains.&lt;br/&gt;\nMain Website: &lt;a href=\"https://valvestore.forfansbyfans.com/\"&gt;https://valvestore.forfansbyfans.com/&lt;/a&gt;&lt;br/&gt;\nImage Host: &lt;a href=\"https://vsimgs3.forfansbyfans.com/\"&gt;https://vsimgs3.forfansbyfans.com/&lt;/a&gt; + &lt;a href=\"https://vsimg.forfansbyfans.com/\"&gt;https://vsimg.forfansbyfans.com/&lt;/a&gt;&lt;br/&gt;\nExternal JS: &lt;a href=\"https://fast.wistia.net/\"&gt;https://fast.wistia.net/&lt;/a&gt; &lt;a href=\"https://www.googletagmanager.com/gtag/\"&gt;https://www.googletagmanager.com/gtag/&lt;/a&gt;  &lt;a href=\"https://apis.google.com/\"&gt;https://apis.google.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BhiEVE3tGGUG1EfSmBtcJzJ1Z0hsQ02xUl8SqTR6BTQ.jpg?auto=webp&amp;s=6a8477b50d126feec50ef84c9f0906c09ffdfe70", "width": 1800, "height": 920}, "resolutions": [{"url": "https://external-preview.redd.it/BhiEVE3tGGUG1EfSmBtcJzJ1Z0hsQ02xUl8SqTR6BTQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f15033d402157801826934d116425bd8c5ccc3c", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/BhiEVE3tGGUG1EfSmBtcJzJ1Z0hsQ02xUl8SqTR6BTQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=63ed045e536da31fef7904197f608ce7d24d9057", "width": 216, "height": 110}, {"url": "https://external-preview.redd.it/BhiEVE3tGGUG1EfSmBtcJzJ1Z0hsQ02xUl8SqTR6BTQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d6efede1e8d4701a075fcab7f05eaa6de9c18f4a", "width": 320, "height": 163}, {"url": "https://external-preview.redd.it/BhiEVE3tGGUG1EfSmBtcJzJ1Z0hsQ02xUl8SqTR6BTQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2245511a443a9f725253b9c34b321fe92422c7c4", "width": 640, "height": 327}, {"url": "https://external-preview.redd.it/BhiEVE3tGGUG1EfSmBtcJzJ1Z0hsQ02xUl8SqTR6BTQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=98ea9a5328ec738a4dcff44142c2eaa87359a5a8", "width": 960, "height": 490}, {"url": "https://external-preview.redd.it/BhiEVE3tGGUG1EfSmBtcJzJ1Z0hsQ02xUl8SqTR6BTQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2797570f178ad7c74761b3ed4232688c79034e3d", "width": 1080, "height": 552}], "variants": {}, "id": "zLQMJmYnqbYoIl6VKAebTU-YW_T4q2SBvmx5ufA8BT8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "153x5q2", "is_robot_indexable": true, "report_reasons": null, "author": "Pommes254", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/153x5q2/valve_merch_shop_closing_on_july_30_with_many/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/153x5q2/valve_merch_shop_closing_on_july_30_with_many/", "subreddit_subscribers": 693383, "created_utc": 1689778207.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI am looking to migrate away from my existing 60TB NAS of 7 years to a new and intentionally overkill NAS rack-mounted setup. If you could lend me your eyes and expertise it will be much appreciated as there is going to be some serious $$ going into this, thanks!\n\n## Requirements\n\n* At least 300TB usable space, with a scalability path towards 1PB in the future\n* Hard drive redundancy\n* Rack-mounted\n* Support running containers\n* Support Plex and hardware transcoding\n* Support running CPU-intensive things, like tdarr, Radarr, Sonarr, etc\n\nI will be running Ubuntu + HashiCorp Nomad since I\u2019m very familiar with that tech stack. I\u2019ve narrowed down the build to consist of two machines which seems like it will meet these requirements: a main server connected to a JBOD.\n\n## Server\n\n* CPU: Intel Core i7-13700K 3.4 GHz 16-Core Processor ($409.00 @ Amazon)\n* CPU Cooler: ARCTIC Liquid Freezer II 280 72.8 CFM Liquid CPU Cooler ($109.99 @ Amazon)\n* Thermal Compound: Arctic Silver 5 High-Density Polysynthetic Silver 3.5 g Thermal Paste ($7.65 @ Amazon)\n* Motherboard: Asus TUF GAMING Z790-PLUS WIFI ATX LGA1700 Motherboard ($269.99 @ Amazon)\n* Memory: G.Skill Trident Z5 RGB 64 GB (2 x 32 GB) DDR5-6400 CL32 Memory ($224.99 @ Amazon)\n* Storage: Samsung 990 Pro 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive ($149.99 @ B&amp;H)\n* Storage: Samsung 990 Pro 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive ($149.99 @ B&amp;H)\n* Power Supply: Corsair RM850x 850 W 80+ Gold Certified Fully Modular ATX Power Supply ($188.87 @ Amazon)\n* Custom: Sliger CX4170a ($239.00)\n* Custom: LSI MegaRAID LSI00332 (9286-8e) PCI-Express 3.0 x8 SATA / SAS RAID  ($79.00 @ Amazon)\n\nThe dual NVMe will be mirrored for redundancy and will contain the OS, system files, and act as a scratch disk (downloads and extraction for better performance). Would it better to separate the OS and put it on its own disk \u2013\u00a0if so should it be another NVMe or SSD? \n\n## JBOD\n\n* Case: **NetApp DS4246**\n* For mounting on Rack: **NetApp DS4246 Rail Kit**\n* Cable to link server with JBOD: **QSFP SFF-8436 Cable**\n* Hard drives: **24 x 22TB Seagate Ironwolf**\n\nI\u2019m planning on doing RAIDZ2, which should give me 352TB of usable space.\n\nThanks, feel free to poke holes and let me know your thoughts!", "author_fullname": "t2_c7g08877", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New 300TB+ Data Hoarding Build Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1542qm6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689792440.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689790981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am looking to migrate away from my existing 60TB NAS of 7 years to a new and intentionally overkill NAS rack-mounted setup. If you could lend me your eyes and expertise it will be much appreciated as there is going to be some serious $$ going into this, thanks!&lt;/p&gt;\n\n&lt;h2&gt;Requirements&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;At least 300TB usable space, with a scalability path towards 1PB in the future&lt;/li&gt;\n&lt;li&gt;Hard drive redundancy&lt;/li&gt;\n&lt;li&gt;Rack-mounted&lt;/li&gt;\n&lt;li&gt;Support running containers&lt;/li&gt;\n&lt;li&gt;Support Plex and hardware transcoding&lt;/li&gt;\n&lt;li&gt;Support running CPU-intensive things, like tdarr, Radarr, Sonarr, etc&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I will be running Ubuntu + HashiCorp Nomad since I\u2019m very familiar with that tech stack. I\u2019ve narrowed down the build to consist of two machines which seems like it will meet these requirements: a main server connected to a JBOD.&lt;/p&gt;\n\n&lt;h2&gt;Server&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;CPU: Intel Core i7-13700K 3.4 GHz 16-Core Processor ($409.00 @ Amazon)&lt;/li&gt;\n&lt;li&gt;CPU Cooler: ARCTIC Liquid Freezer II 280 72.8 CFM Liquid CPU Cooler ($109.99 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Thermal Compound: Arctic Silver 5 High-Density Polysynthetic Silver 3.5 g Thermal Paste ($7.65 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Motherboard: Asus TUF GAMING Z790-PLUS WIFI ATX LGA1700 Motherboard ($269.99 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Memory: G.Skill Trident Z5 RGB 64 GB (2 x 32 GB) DDR5-6400 CL32 Memory ($224.99 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Storage: Samsung 990 Pro 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive ($149.99 @ B&amp;amp;H)&lt;/li&gt;\n&lt;li&gt;Storage: Samsung 990 Pro 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive ($149.99 @ B&amp;amp;H)&lt;/li&gt;\n&lt;li&gt;Power Supply: Corsair RM850x 850 W 80+ Gold Certified Fully Modular ATX Power Supply ($188.87 @ Amazon)&lt;/li&gt;\n&lt;li&gt;Custom: Sliger CX4170a ($239.00)&lt;/li&gt;\n&lt;li&gt;Custom: LSI MegaRAID LSI00332 (9286-8e) PCI-Express 3.0 x8 SATA / SAS RAID  ($79.00 @ Amazon)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The dual NVMe will be mirrored for redundancy and will contain the OS, system files, and act as a scratch disk (downloads and extraction for better performance). Would it better to separate the OS and put it on its own disk \u2013\u00a0if so should it be another NVMe or SSD? &lt;/p&gt;\n\n&lt;h2&gt;JBOD&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Case: &lt;strong&gt;NetApp DS4246&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;For mounting on Rack: &lt;strong&gt;NetApp DS4246 Rail Kit&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Cable to link server with JBOD: &lt;strong&gt;QSFP SFF-8436 Cable&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Hard drives: &lt;strong&gt;24 x 22TB Seagate Ironwolf&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m planning on doing RAIDZ2, which should give me 352TB of usable space.&lt;/p&gt;\n\n&lt;p&gt;Thanks, feel free to poke holes and let me know your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1542qm6", "is_robot_indexable": true, "report_reasons": null, "author": "fat_keepsake", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1542qm6/new_300tb_data_hoarding_build_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1542qm6/new_300tb_data_hoarding_build_advice/", "subreddit_subscribers": 693383, "created_utc": 1689790981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Besides the Wayback Machine. Back in 2019, my old YouTube channel got hacked, and in short I couldn't prove that the channel was mine because they hacked my email, as well, and eventually the channel was terminated due to the hacker violating many YouTube rules. I had hundreds of videos on there with many precious memories. I have searched day in and day out to find a way to view at least one of the old videos, because I have the link to it. However, my YouTube channel was very small and was not archived at all so I have had zero luck because I'm not very tech-savvy. Apologies if this post isn't allowed, or doesn't make sense, I've tried googling forever and found [this](https://www.reddit.com/r/DataHoarder/comments/lt2uxi/finding_deleted_youtube_videos/) post, but I'm still clueless if this would actually work or not since the video I have the link for had only about 50-100 views.", "author_fullname": "t2_khxbe9hb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a website where I can find videos from (small) terminated YouTube channels?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154epva", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689820942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Besides the Wayback Machine. Back in 2019, my old YouTube channel got hacked, and in short I couldn&amp;#39;t prove that the channel was mine because they hacked my email, as well, and eventually the channel was terminated due to the hacker violating many YouTube rules. I had hundreds of videos on there with many precious memories. I have searched day in and day out to find a way to view at least one of the old videos, because I have the link to it. However, my YouTube channel was very small and was not archived at all so I have had zero luck because I&amp;#39;m not very tech-savvy. Apologies if this post isn&amp;#39;t allowed, or doesn&amp;#39;t make sense, I&amp;#39;ve tried googling forever and found &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/lt2uxi/finding_deleted_youtube_videos/\"&gt;this&lt;/a&gt; post, but I&amp;#39;m still clueless if this would actually work or not since the video I have the link for had only about 50-100 views.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154epva", "is_robot_indexable": true, "report_reasons": null, "author": "clumsy_panda17", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154epva/is_there_a_website_where_i_can_find_videos_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154epva/is_there_a_website_where_i_can_find_videos_from/", "subreddit_subscribers": 693383, "created_utc": 1689820942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using the Internet Archive Command Line Interface for a while now to hoard retro computer (mainly Commodore 64 related) magazines and books. \n\nI've also been using it to do the same with Commodore 64 software as well. These are typically stored in a .d64 file which is an image of an physical Commodore 1541 floppy disk. The .d64 file can be \"loaded\" into the Vice emulator or used on real Commodore computer hardware using an SD2IEC or Pi1541 which then works like an original floppy disk drive.\n\nI've used this command to download all of the .d64 files in the collection \"softwarelibrary\\_c64\";\n\nia download --search 'collection:softwarelibrary\\_c64'  --glob=\"\\*.d64\"\n\nScattered through the output were some failed downloads. Investigation shows these to be items where the software was in a .tap file, an image of a Commodore 64 cassette tape. \n\nI'd like to download both .d64 and .tap files in the same command... but I can't see a way to configure the above command to do this? The IA Command Line Interface help doesn't really show how to do this... or even if it's possible. \n\nIs there a way to download all items from \"softwarelibrary\\_c64\" collections containing both .d64 and .tap files with one IA command?\n\n&amp;#x200B;", "author_fullname": "t2_bsosk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading multiple file types from Internet Archive using --glob", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15498gs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689806145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using the Internet Archive Command Line Interface for a while now to hoard retro computer (mainly Commodore 64 related) magazines and books. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also been using it to do the same with Commodore 64 software as well. These are typically stored in a .d64 file which is an image of an physical Commodore 1541 floppy disk. The .d64 file can be &amp;quot;loaded&amp;quot; into the Vice emulator or used on real Commodore computer hardware using an SD2IEC or Pi1541 which then works like an original floppy disk drive.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used this command to download all of the .d64 files in the collection &amp;quot;softwarelibrary_c64&amp;quot;;&lt;/p&gt;\n\n&lt;p&gt;ia download --search &amp;#39;collection:softwarelibrary_c64&amp;#39;  --glob=&amp;quot;*.d64&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Scattered through the output were some failed downloads. Investigation shows these to be items where the software was in a .tap file, an image of a Commodore 64 cassette tape. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to download both .d64 and .tap files in the same command... but I can&amp;#39;t see a way to configure the above command to do this? The IA Command Line Interface help doesn&amp;#39;t really show how to do this... or even if it&amp;#39;s possible. &lt;/p&gt;\n\n&lt;p&gt;Is there a way to download all items from &amp;quot;softwarelibrary_c64&amp;quot; collections containing both .d64 and .tap files with one IA command?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15498gs", "is_robot_indexable": true, "report_reasons": null, "author": "original_lunokhod", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15498gs/downloading_multiple_file_types_from_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15498gs/downloading_multiple_file_types_from_internet/", "subreddit_subscribers": 693383, "created_utc": 1689806145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My dad is a photographer and, through some messy process, has ended up with nearly 14tb of photos. To hear him tell it, there are probably two or three duplicates of most original files. And, because he's a photog, a lot of his photos are very similar (but not identical). Do any of you good folks know of a piece of software he could use to delete exact duplicates (and exact duplicates only)?", "author_fullname": "t2_eq1a4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best software for finding duplicates among 14tb of photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1549y5s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689807944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My dad is a photographer and, through some messy process, has ended up with nearly 14tb of photos. To hear him tell it, there are probably two or three duplicates of most original files. And, because he&amp;#39;s a photog, a lot of his photos are very similar (but not identical). Do any of you good folks know of a piece of software he could use to delete exact duplicates (and exact duplicates only)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1549y5s", "is_robot_indexable": true, "report_reasons": null, "author": "MrCharlieBones", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1549y5s/best_software_for_finding_duplicates_among_14tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1549y5s/best_software_for_finding_duplicates_among_14tb/", "subreddit_subscribers": 693383, "created_utc": 1689807944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there, folks.\n\nThis time I'd like to ask for more help in the process of building my own system. The thing is that I have some questions because I am not an expert about how to build one myself. I'm a blind person, so if you can be specific about how things work together, I'd really appreciate it. Ideally I'd like to build a reliable system capable of using 8 drives at a relatively cheap price. I would use the system mostly for Plex (4-5 transcodes at a time, only 1080), NextCloud, Django testing and some docker containers. I have tried to search for this kind of systems in local shops, but apparently this is not easy here. So I searched in Amazon for some hardware and I have so far the following, excluding drives:\n\n* Case: Antec P101 Silent.\n* Motherboard: ASRock Z690 PG Riptide.\n* Intel Core i3-13100.\n* Power Supply: Gigabyte GP-P650B.\n* 2x 16 GB crucial DDR4 RAM at 3200 MHZ.\n\nquestions:\n\n1. Do you think will there be a compatibility issue with one of those components? this is my first build, so I am not sure about pretty much anything right now.\n2. Is there something You'd change?\n3. Do I have to buy a cooler, fans or something like that?\n4. If I would put 8 drives on the case, should I buy cables or something else separately? How could I search for this?\n\nSorry if this sounds too obvious, but I'd like to get as more details as possible before buying everything and realicing that there's something wrong with a component, cables missing or something similar.", "author_fullname": "t2_3vncnb2s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First NAS build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1547y2a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689803076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, folks.&lt;/p&gt;\n\n&lt;p&gt;This time I&amp;#39;d like to ask for more help in the process of building my own system. The thing is that I have some questions because I am not an expert about how to build one myself. I&amp;#39;m a blind person, so if you can be specific about how things work together, I&amp;#39;d really appreciate it. Ideally I&amp;#39;d like to build a reliable system capable of using 8 drives at a relatively cheap price. I would use the system mostly for Plex (4-5 transcodes at a time, only 1080), NextCloud, Django testing and some docker containers. I have tried to search for this kind of systems in local shops, but apparently this is not easy here. So I searched in Amazon for some hardware and I have so far the following, excluding drives:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Case: Antec P101 Silent.&lt;/li&gt;\n&lt;li&gt;Motherboard: ASRock Z690 PG Riptide.&lt;/li&gt;\n&lt;li&gt;Intel Core i3-13100.&lt;/li&gt;\n&lt;li&gt;Power Supply: Gigabyte GP-P650B.&lt;/li&gt;\n&lt;li&gt;2x 16 GB crucial DDR4 RAM at 3200 MHZ.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do you think will there be a compatibility issue with one of those components? this is my first build, so I am not sure about pretty much anything right now.&lt;/li&gt;\n&lt;li&gt;Is there something You&amp;#39;d change?&lt;/li&gt;\n&lt;li&gt;Do I have to buy a cooler, fans or something like that?&lt;/li&gt;\n&lt;li&gt;If I would put 8 drives on the case, should I buy cables or something else separately? How could I search for this?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Sorry if this sounds too obvious, but I&amp;#39;d like to get as more details as possible before buying everything and realicing that there&amp;#39;s something wrong with a component, cables missing or something similar.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1547y2a", "is_robot_indexable": true, "report_reasons": null, "author": "manuelcortez00", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1547y2a/first_nas_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1547y2a/first_nas_build/", "subreddit_subscribers": 693383, "created_utc": 1689803076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Background:  \nI am a fairly heavy data hoarder and I need a cross platform photo management software. I run a Windows Server for storage and currently just have the photos in a loosely organized folder structure that backs up to cloud storage. I use MacOS photos at the moment and run yearly exports to avoid paying for more icloud but I also have close to 100Gb of scanned family photo's that I would like to tag and organize.\n\nIts partially me, partially aged hardware that lead me here. My Mac Pro had to be retired for lack of software support and a failing PSU and moving to M2 killed off a lot of my tools to manage photos. Then I scanned and digitized 100Gb of physical media with no easy way to tag and manage the files. The move off the old hardware lead to a lot of duplicate copies that I need to merge to make sure I don't lose anything.   \n\n\nSummary:\n\n* Photos are Stored on Windows Server with network share\n* Edited on M2 Mac\n* Viewed on Windows Workstation and ios\n* Need to tag and organize by adding metadata\n* would like to be platform agnostic and avoid proprietary databases if possible.\n* OK with paying for software as long as it isn't subscription.", "author_fullname": "t2_75p0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cross Platform Software for Photo Management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1540n6u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689786110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background:&lt;br/&gt;\nI am a fairly heavy data hoarder and I need a cross platform photo management software. I run a Windows Server for storage and currently just have the photos in a loosely organized folder structure that backs up to cloud storage. I use MacOS photos at the moment and run yearly exports to avoid paying for more icloud but I also have close to 100Gb of scanned family photo&amp;#39;s that I would like to tag and organize.&lt;/p&gt;\n\n&lt;p&gt;Its partially me, partially aged hardware that lead me here. My Mac Pro had to be retired for lack of software support and a failing PSU and moving to M2 killed off a lot of my tools to manage photos. Then I scanned and digitized 100Gb of physical media with no easy way to tag and manage the files. The move off the old hardware lead to a lot of duplicate copies that I need to merge to make sure I don&amp;#39;t lose anything.   &lt;/p&gt;\n\n&lt;p&gt;Summary:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Photos are Stored on Windows Server with network share&lt;/li&gt;\n&lt;li&gt;Edited on M2 Mac&lt;/li&gt;\n&lt;li&gt;Viewed on Windows Workstation and ios&lt;/li&gt;\n&lt;li&gt;Need to tag and organize by adding metadata&lt;/li&gt;\n&lt;li&gt;would like to be platform agnostic and avoid proprietary databases if possible.&lt;/li&gt;\n&lt;li&gt;OK with paying for software as long as it isn&amp;#39;t subscription.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16 TB + 12 TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1540n6u", "is_robot_indexable": true, "report_reasons": null, "author": "zkilling", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1540n6u/cross_platform_software_for_photo_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1540n6u/cross_platform_software_for_photo_management/", "subreddit_subscribers": 693383, "created_utc": 1689786110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to move about 200GB of data to a friend's PC.  \nForget internet transfer.  \nI'm thinking of either USB 3.2 pen drive of 256GB, or using a SSD to USB adapter with a 1TB SSD. Adapter: https://www.amazon.co.uk/Sabrent-2-5-Inch-Adapter-Optimized-EC-SSHD-USB-3-0-SSD-SATA-2-5/dp/B011M8YACM.  \nThe SSD is faster I believe, and is cheaper per GB in terms of cost.\nWhich is the more feasible do you think?", "author_fullname": "t2_y8err", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "USB Flash Drive or SSD-USB Adapter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153ronm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689764114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to move about 200GB of data to a friend&amp;#39;s PC.&lt;br/&gt;\nForget internet transfer.&lt;br/&gt;\nI&amp;#39;m thinking of either USB 3.2 pen drive of 256GB, or using a SSD to USB adapter with a 1TB SSD. Adapter: &lt;a href=\"https://www.amazon.co.uk/Sabrent-2-5-Inch-Adapter-Optimized-EC-SSHD-USB-3-0-SSD-SATA-2-5/dp/B011M8YACM\"&gt;https://www.amazon.co.uk/Sabrent-2-5-Inch-Adapter-Optimized-EC-SSHD-USB-3-0-SSD-SATA-2-5/dp/B011M8YACM&lt;/a&gt;.&lt;br/&gt;\nThe SSD is faster I believe, and is cheaper per GB in terms of cost.\nWhich is the more feasible do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "153ronm", "is_robot_indexable": true, "report_reasons": null, "author": "Triumerate", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/153ronm/usb_flash_drive_or_ssdusb_adapter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/153ronm/usb_flash_drive_or_ssdusb_adapter/", "subreddit_subscribers": 693383, "created_utc": 1689764114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've recently started using MakeMKV to rip digital copies of some discs to free up physical storage space in my office.    \n\nOne of them is a 6-part series (one part on each disc). The first five ripped perfectly, no issues at all. The sixth one appears to be fine, but it just doesn't complete.    \n\nIt gets to the final stage \"Saving to MKV file\" and the progress bar is around 98% but it just stays there for hours on end. I don't get any error message or indication of what is happening.    \n\nHas anyone experienced this? Sorry for creating a thread here - I would have contained it to r/MakeMkv but the sub is still locked for the \"protest\". Thanks in advance.    \n\nHere is the full log from the current rip, which is still stuck at the end of the file creation stage:    \n\n&gt; MakeMKV v1.17.4 win(x64-release) started  \n&gt; Using direct disc access mode  \n&gt; Evaluation version, 27 day(s) out of 30 remaining  \n&gt; Loaded content hash table, will verify integrity of M2TS files.  \n&gt; File 00007.mpls was added as title #0  \n&gt; File 00006.mpls was added as title #1  \n&gt; File 00005.m2ts was added as title #2  \n&gt; File 00002.m2ts was added as title #3  \n&gt; File 00001.m2ts was added as title #4  \n&gt; File 00000.m2ts was added as title #5  \n&gt; File 00013.m2ts was added as title #6  \n&gt; Operation successfully completed  \n&gt; Saving 1 titles into directory D:/Video", "author_fullname": "t2_6l4yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having a problem with MakeMKV (and that sub is still locked)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_154mevw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689846437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently started using MakeMKV to rip digital copies of some discs to free up physical storage space in my office.    &lt;/p&gt;\n\n&lt;p&gt;One of them is a 6-part series (one part on each disc). The first five ripped perfectly, no issues at all. The sixth one appears to be fine, but it just doesn&amp;#39;t complete.    &lt;/p&gt;\n\n&lt;p&gt;It gets to the final stage &amp;quot;Saving to MKV file&amp;quot; and the progress bar is around 98% but it just stays there for hours on end. I don&amp;#39;t get any error message or indication of what is happening.    &lt;/p&gt;\n\n&lt;p&gt;Has anyone experienced this? Sorry for creating a thread here - I would have contained it to &lt;a href=\"/r/MakeMkv\"&gt;r/MakeMkv&lt;/a&gt; but the sub is still locked for the &amp;quot;protest&amp;quot;. Thanks in advance.    &lt;/p&gt;\n\n&lt;p&gt;Here is the full log from the current rip, which is still stuck at the end of the file creation stage:    &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;MakeMKV v1.17.4 win(x64-release) started&lt;br/&gt;\nUsing direct disc access mode&lt;br/&gt;\nEvaluation version, 27 day(s) out of 30 remaining&lt;br/&gt;\nLoaded content hash table, will verify integrity of M2TS files.&lt;br/&gt;\nFile 00007.mpls was added as title #0&lt;br/&gt;\nFile 00006.mpls was added as title #1&lt;br/&gt;\nFile 00005.m2ts was added as title #2&lt;br/&gt;\nFile 00002.m2ts was added as title #3&lt;br/&gt;\nFile 00001.m2ts was added as title #4&lt;br/&gt;\nFile 00000.m2ts was added as title #5&lt;br/&gt;\nFile 00013.m2ts was added as title #6&lt;br/&gt;\nOperation successfully completed&lt;br/&gt;\nSaving 1 titles into directory D:/Video&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154mevw", "is_robot_indexable": true, "report_reasons": null, "author": "SundayRed", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154mevw/having_a_problem_with_makemkv_and_that_sub_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154mevw/having_a_problem_with_makemkv_and_that_sub_is/", "subreddit_subscribers": 693383, "created_utc": 1689846437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI've been looking for HDD docking stations with at least 2 bays of 3.5\" drives with 20TB supported per bay, looked on amazon and some local webshops but couldn't find any. \n\nDoes anyone know where I can find them? I'm not looking for a NAS, just a USB docking station.", "author_fullname": "t2_113exr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD Docking stations for 20TB HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154l65l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689842284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking for HDD docking stations with at least 2 bays of 3.5&amp;quot; drives with 20TB supported per bay, looked on amazon and some local webshops but couldn&amp;#39;t find any. &lt;/p&gt;\n\n&lt;p&gt;Does anyone know where I can find them? I&amp;#39;m not looking for a NAS, just a USB docking station.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154l65l", "is_robot_indexable": true, "report_reasons": null, "author": "kevinj933", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154l65l/hdd_docking_stations_for_20tb_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154l65l/hdd_docking_stations_for_20tb_hdds/", "subreddit_subscribers": 693383, "created_utc": 1689842284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have quite a number of more obscure discs from different countries that are basically not on any database. I was looking through the metadata options, but they all seemed to just be trying to take the track info from a database that they are not on. This makes things quite a pain as I would need to manually set all of the metadata on the tracks myself after ripping them. ", "author_fullname": "t2_blk7dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to make EAC use the disc metadata as opposed to a database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154bmgn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689812347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have quite a number of more obscure discs from different countries that are basically not on any database. I was looking through the metadata options, but they all seemed to just be trying to take the track info from a database that they are not on. This makes things quite a pain as I would need to manually set all of the metadata on the tracks myself after ripping them. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154bmgn", "is_robot_indexable": true, "report_reasons": null, "author": "Zyvyn", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154bmgn/is_it_possible_to_make_eac_use_the_disc_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154bmgn/is_it_possible_to_make_eac_use_the_disc_metadata/", "subreddit_subscribers": 693383, "created_utc": 1689812347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So to summarise. \n\n\nI had a laptop and a 500gb m.2 nvme SSD. I THINK I setup bitlocker on the drive. \n\nI then removed the SSD as I was returning the laptop to the shop I bought it from (irrelevant). \n\nI now have tried to secure erase the m.2 in parted magic, but it fails every time. \n\nThe last time I had this issue, I had to enter the PSID unlock, but I can\u2019t see one on this m.2 drive. \n\nSo given I can\u2019t physically install the drive into the same motherboard with the TPM chip, is it now impossible to use this SSD again?\n\nThanks", "author_fullname": "t2_rjp4ke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "M.2 SSD had bitlocker, I no longer can access the motherboard. Is the drive screwed? More in post", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154b9i1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689811380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So to summarise. &lt;/p&gt;\n\n&lt;p&gt;I had a laptop and a 500gb m.2 nvme SSD. I THINK I setup bitlocker on the drive. &lt;/p&gt;\n\n&lt;p&gt;I then removed the SSD as I was returning the laptop to the shop I bought it from (irrelevant). &lt;/p&gt;\n\n&lt;p&gt;I now have tried to secure erase the m.2 in parted magic, but it fails every time. &lt;/p&gt;\n\n&lt;p&gt;The last time I had this issue, I had to enter the PSID unlock, but I can\u2019t see one on this m.2 drive. &lt;/p&gt;\n\n&lt;p&gt;So given I can\u2019t physically install the drive into the same motherboard with the TPM chip, is it now impossible to use this SSD again?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154b9i1", "is_robot_indexable": true, "report_reasons": null, "author": "Silent-OCN", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154b9i1/m2_ssd_had_bitlocker_i_no_longer_can_access_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154b9i1/m2_ssd_had_bitlocker_i_no_longer_can_access_the/", "subreddit_subscribers": 693383, "created_utc": 1689811380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I always get this error\n\n \n\n    brew install danirukun/ytarchive/ytarchive\n    \n\n`Error: ytarchive: SHA256 mismatch`\n\n`Expected: f61ac9b3606476306c208dd87961a3ca846efa92eaad651fa0270293c13a54c2 Actual: 055d3e7129c737105d28f743bd3ce02fef57b116f95a8f3601a25c163634a252 File: /Users/YMB/Library/Caches/Homebrew/downloads/bb308be7810c4f190dfd69f5c6a1d9e0d40e9c833dd4c7a78ffa44cbacd25de8--ytarchive-latest.tar.gz`", "author_fullname": "t2_baozka1v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to install ytarchive on mac?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154638c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689798783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I always get this error&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;brew install danirukun/ytarchive/ytarchive\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;code&gt;Error: ytarchive: SHA256 mismatch&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Expected: f61ac9b3606476306c208dd87961a3ca846efa92eaad651fa0270293c13a54c2 Actual: 055d3e7129c737105d28f743bd3ce02fef57b116f95a8f3601a25c163634a252 File: /Users/YMB/Library/Caches/Homebrew/downloads/bb308be7810c4f190dfd69f5c6a1d9e0d40e9c833dd4c7a78ffa44cbacd25de8--ytarchive-latest.tar.gz&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154638c", "is_robot_indexable": true, "report_reasons": null, "author": "Vegetable_Dream_5251", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154638c/how_to_install_ytarchive_on_mac/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154638c/how_to_install_ytarchive_on_mac/", "subreddit_subscribers": 693383, "created_utc": 1689798783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just bought a 4 bay  QNAP TR-004 DAS and was looking for some recommendations on what hard drives to get. Is just using any type fine? Can I do something like 3 4tb and 1 10tb or do they all have to be the same storage size? I also saw something about SMR and CMR, just a lot of overwhelming info for a  newbie.", "author_fullname": "t2_3q5rxmp9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD recommendations for a QNAP DAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1545nrp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689797768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just bought a 4 bay  QNAP TR-004 DAS and was looking for some recommendations on what hard drives to get. Is just using any type fine? Can I do something like 3 4tb and 1 10tb or do they all have to be the same storage size? I also saw something about SMR and CMR, just a lot of overwhelming info for a  newbie.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1545nrp", "is_robot_indexable": true, "report_reasons": null, "author": "AromaticMode", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1545nrp/hdd_recommendations_for_a_qnap_das/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1545nrp/hdd_recommendations_for_a_qnap_das/", "subreddit_subscribers": 693383, "created_utc": 1689797768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 7 hdds on my nas that I spindown after 120min of no use, been thinking on ways to reduce power consumption on my machine and many of those drives are less than 1tb in size, was wondering if there was any way to see how much time do the drives spin vs not or idle, to see if its worth it to remove some/most for a bigger capacity drive that could waste less energy, also if I remove disks I could also remove my dell h200 saving a bit extra.\n\nFor now I have around 9% load on my ups (apc back-ups xs 700u) and would love to reduce it as much as possible.\n\nAlso anyone know how to get a quick and dirty rough power consumption from the ups load? It says its 390w nominal power, but dont know if I should just multiply 390 by 9%?", "author_fullname": "t2_11qmx3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any1 know how to get a hdd spindown vs spinning ratio/graps/data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1544iz4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689798966.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689795142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 7 hdds on my nas that I spindown after 120min of no use, been thinking on ways to reduce power consumption on my machine and many of those drives are less than 1tb in size, was wondering if there was any way to see how much time do the drives spin vs not or idle, to see if its worth it to remove some/most for a bigger capacity drive that could waste less energy, also if I remove disks I could also remove my dell h200 saving a bit extra.&lt;/p&gt;\n\n&lt;p&gt;For now I have around 9% load on my ups (apc back-ups xs 700u) and would love to reduce it as much as possible.&lt;/p&gt;\n\n&lt;p&gt;Also anyone know how to get a quick and dirty rough power consumption from the ups load? It says its 390w nominal power, but dont know if I should just multiply 390 by 9%?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1544iz4", "is_robot_indexable": true, "report_reasons": null, "author": "blazethedragon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1544iz4/any1_know_how_to_get_a_hdd_spindown_vs_spinning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1544iz4/any1_know_how_to_get_a_hdd_spindown_vs_spinning/", "subreddit_subscribers": 693383, "created_utc": 1689795142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Providers advertising a large quota and very often without any limits only of course not wanting people to actually use too much aren't new, they've been at it at least since [2007 and before](https://web.archive.org/web/20071024031338/http://blog.dreamhosters.com/2007/10/21/using-dreamhost-for-personal-storage-backups/) when Dreamhost, Bluehost and another bunch of similar services were fighting between each other quoting larger and larger GB numbers (and in the end no limits) just to chase away users using any relatively high amount of storage.  \n\nHowever, I can't remember even once seeing some systematic review **and tests** of a large number of such services (and there aren't that many at any given time). Mostly everything is either some not-so-hidden advertisement for a particular service or something really light with a bunch of screenshots of the interface. You get this by now canonically bad example with ArsTechnica's [Ars Archivum: Top cloud backup services worth your money](https://arstechnica.com/information-technology/2023/02/ars-archivum-top-cloud-backup-services-worth-your-money/) \"since we only had 2**G**B of test data\" like you couldn't find or generate TBs of data on a whim.   \n\nThis isn't anything deep about abusing the ToS or false advertisement, or \"what were you expecting to store 1.5PBs for $12/month\". It's just about very concrete details about the characteristics and usefulness of such services. Some will say 10TBs but let you nowhere close. Some will say no limits but they mean strictly 10 or even 2TBs. Some will expand your space from time to time but not too much.     \n\nThis would be a very low-effort creatively and moderate work to set it up. Of course, we're talking about real tech journalists, not people getting stuck into \"I have just 2**G**B of test data, how in the world could I ever get more?!\". And it has the potential to be **the** reference article for this matter, globally, potentially for years. It can get updates in a few months, or next year, as the situation changes. Can be perfectly similar with BackBlaze's hard drive stats, the thing everyone quotes - except that this is easier to set up, anyone with a little knowledge and a half-decent internet connection can do it.", "author_fullname": "t2_116tti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Technology Journalism has a blind spot regarding large storage clouds, anyone up to fix it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_154l75b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689842389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Providers advertising a large quota and very often without any limits only of course not wanting people to actually use too much aren&amp;#39;t new, they&amp;#39;ve been at it at least since &lt;a href=\"https://web.archive.org/web/20071024031338/http://blog.dreamhosters.com/2007/10/21/using-dreamhost-for-personal-storage-backups/\"&gt;2007 and before&lt;/a&gt; when Dreamhost, Bluehost and another bunch of similar services were fighting between each other quoting larger and larger GB numbers (and in the end no limits) just to chase away users using any relatively high amount of storage.  &lt;/p&gt;\n\n&lt;p&gt;However, I can&amp;#39;t remember even once seeing some systematic review &lt;strong&gt;and tests&lt;/strong&gt; of a large number of such services (and there aren&amp;#39;t that many at any given time). Mostly everything is either some not-so-hidden advertisement for a particular service or something really light with a bunch of screenshots of the interface. You get this by now canonically bad example with ArsTechnica&amp;#39;s &lt;a href=\"https://arstechnica.com/information-technology/2023/02/ars-archivum-top-cloud-backup-services-worth-your-money/\"&gt;Ars Archivum: Top cloud backup services worth your money&lt;/a&gt; &amp;quot;since we only had 2&lt;strong&gt;G&lt;/strong&gt;B of test data&amp;quot; like you couldn&amp;#39;t find or generate TBs of data on a whim.   &lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t anything deep about abusing the ToS or false advertisement, or &amp;quot;what were you expecting to store 1.5PBs for $12/month&amp;quot;. It&amp;#39;s just about very concrete details about the characteristics and usefulness of such services. Some will say 10TBs but let you nowhere close. Some will say no limits but they mean strictly 10 or even 2TBs. Some will expand your space from time to time but not too much.     &lt;/p&gt;\n\n&lt;p&gt;This would be a very low-effort creatively and moderate work to set it up. Of course, we&amp;#39;re talking about real tech journalists, not people getting stuck into &amp;quot;I have just 2&lt;strong&gt;G&lt;/strong&gt;B of test data, how in the world could I ever get more?!&amp;quot;. And it has the potential to be &lt;strong&gt;the&lt;/strong&gt; reference article for this matter, globally, potentially for years. It can get updates in a few months, or next year, as the situation changes. Can be perfectly similar with BackBlaze&amp;#39;s hard drive stats, the thing everyone quotes - except that this is easier to set up, anyone with a little knowledge and a half-decent internet connection can do it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154l75b", "is_robot_indexable": true, "report_reasons": null, "author": "dr100", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154l75b/technology_journalism_has_a_blind_spot_regarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154l75b/technology_journalism_has_a_blind_spot_regarding/", "subreddit_subscribers": 693383, "created_utc": 1689842389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are any of you using multi-bay drive enclosures successfully with Linux without errors? I have mostly migrated my homelab and systems to a mix of Ubuntu (22.04 LTS and MATE) and Debian (LMDE, CasaOS, Raspberry Pi OS, and headless).\n\nI have had no end of trouble with Orico's enclosures, after investing in them reasonably heavily. Consistently, whatever information they are sending to Ubuntu leads Ubuntu to report huge drive sizes and the actual drive as a partition at the front (so it thinks an 8TB drive is about a 125,000TB drive with 7.28 TB partition at the front and 118,214.53 unallocated). It doesn't matter what system was used to create the file system or whether it's NTFS or ext4. (Exfat also had some issues but at that point it seemed like an anomaly, so I can't say whether it played out the same or slightly differently). \n\nThey do seem to behave okay with Windows (or Windows can invisibly reconcile any differences in what's reported) and I am coming around to the idea that I may need to keep one Windows machine in the system. (Not only for this issue; Robocopy is easier and faster than Rsync, and my backup machine connects read-only so Syncthing isn't feasible). But I would much rather get something that behaves well across the board. Any suggestions?\n\n*Edit* Forgot to mention - I don't need, and in fact would prefer not to have hardware RAID, JBOD is fine/preferred. I have really good software RAID in TrueNAS Scale, this is for making standalone cold and offsite backups.", "author_fullname": "t2_komty5a5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for multi-drive enclosures?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154f4qo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689822785.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689822129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are any of you using multi-bay drive enclosures successfully with Linux without errors? I have mostly migrated my homelab and systems to a mix of Ubuntu (22.04 LTS and MATE) and Debian (LMDE, CasaOS, Raspberry Pi OS, and headless).&lt;/p&gt;\n\n&lt;p&gt;I have had no end of trouble with Orico&amp;#39;s enclosures, after investing in them reasonably heavily. Consistently, whatever information they are sending to Ubuntu leads Ubuntu to report huge drive sizes and the actual drive as a partition at the front (so it thinks an 8TB drive is about a 125,000TB drive with 7.28 TB partition at the front and 118,214.53 unallocated). It doesn&amp;#39;t matter what system was used to create the file system or whether it&amp;#39;s NTFS or ext4. (Exfat also had some issues but at that point it seemed like an anomaly, so I can&amp;#39;t say whether it played out the same or slightly differently). &lt;/p&gt;\n\n&lt;p&gt;They do seem to behave okay with Windows (or Windows can invisibly reconcile any differences in what&amp;#39;s reported) and I am coming around to the idea that I may need to keep one Windows machine in the system. (Not only for this issue; Robocopy is easier and faster than Rsync, and my backup machine connects read-only so Syncthing isn&amp;#39;t feasible). But I would much rather get something that behaves well across the board. Any suggestions?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit&lt;/em&gt; Forgot to mention - I don&amp;#39;t need, and in fact would prefer not to have hardware RAID, JBOD is fine/preferred. I have really good software RAID in TrueNAS Scale, this is for making standalone cold and offsite backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "25TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154f4qo", "is_robot_indexable": true, "report_reasons": null, "author": "nurseynurseygander", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/154f4qo/recommendations_for_multidrive_enclosures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154f4qo/recommendations_for_multidrive_enclosures/", "subreddit_subscribers": 693383, "created_utc": 1689822129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "We are a small church group looking to get a sustainable storage device for the long term. A 16 TB storage would do, What would you advise I go in for?", "author_fullname": "t2_gsxhlph5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "16Tb media storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154doen", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689818027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are a small church group looking to get a sustainable storage device for the long term. A 16 TB storage would do, What would you advise I go in for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154doen", "is_robot_indexable": true, "report_reasons": null, "author": "InitialLast6763", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154doen/16tb_media_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154doen/16tb_media_storage/", "subreddit_subscribers": 693383, "created_utc": 1689818027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 20 TB of files on a server and 20 TB on a NAS. I want to swap the files so the server files go to the NAS and the NAS files go to the server.\n\nBoth devices only have 2 TB free. So I can't finish the one move before doing the other. And it's a set of diverse and complex folders so it's not simple to just do them piecemeal. \n\nNo individual file should be more than 50 GB (I don't think).\n\nAny ideas?", "author_fullname": "t2_1l9k4odb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Utility/script to swap files between drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154elzy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689820628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 20 TB of files on a server and 20 TB on a NAS. I want to swap the files so the server files go to the NAS and the NAS files go to the server.&lt;/p&gt;\n\n&lt;p&gt;Both devices only have 2 TB free. So I can&amp;#39;t finish the one move before doing the other. And it&amp;#39;s a set of diverse and complex folders so it&amp;#39;s not simple to just do them piecemeal. &lt;/p&gt;\n\n&lt;p&gt;No individual file should be more than 50 GB (I don&amp;#39;t think).&lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154elzy", "is_robot_indexable": true, "report_reasons": null, "author": "ShelZuuz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154elzy/utilityscript_to_swap_files_between_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154elzy/utilityscript_to_swap_files_between_drives/", "subreddit_subscribers": 693383, "created_utc": 1689820628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have it partitioned half for Time Machine and half for other files initially had non-time machine volume as APFS encrypted and got \\~750 MB/s  read and write but when I connected to a 10gbps USB C hub I only get 230/180 read/write which was abysmal. When I decrypted the volume the USB C hub read out in the 600s. but when connected directly to my MacBook the speeds dropped by \\~100 MB/s for both read and write. Why could this be? I am on Ventura 13.4.1. \n\nTo Summarize: \n\nAPFS encrypted:\n\nMacBook: \\~750/750 MB/s\n\nUSB C Hub: \\~230/180 MB/s \n\n&amp;#x200B;\n\nAPFS (decrypted): \n\nMacBook: \\~680/680 MB/s\n\nUSB C Hub: \\~680/570 MB/s \n\n&amp;#x200B;\n\nI don't know why encryption slows down the via the hub so much and it also makes no sense for encrypted to the faster than decrypted when connected directly to the MacBook. I would like to keep the drive encrypted but the extreme speed penalty on a hub is unacceptable. Is there a way to simply password protect the drive? ", "author_fullname": "t2_7pg7o64p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 TB Samsung T7 Shield Odd Black Magic Tests m1 air", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154cp3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689815255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have it partitioned half for Time Machine and half for other files initially had non-time machine volume as APFS encrypted and got ~750 MB/s  read and write but when I connected to a 10gbps USB C hub I only get 230/180 read/write which was abysmal. When I decrypted the volume the USB C hub read out in the 600s. but when connected directly to my MacBook the speeds dropped by ~100 MB/s for both read and write. Why could this be? I am on Ventura 13.4.1. &lt;/p&gt;\n\n&lt;p&gt;To Summarize: &lt;/p&gt;\n\n&lt;p&gt;APFS encrypted:&lt;/p&gt;\n\n&lt;p&gt;MacBook: ~750/750 MB/s&lt;/p&gt;\n\n&lt;p&gt;USB C Hub: ~230/180 MB/s &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;APFS (decrypted): &lt;/p&gt;\n\n&lt;p&gt;MacBook: ~680/680 MB/s&lt;/p&gt;\n\n&lt;p&gt;USB C Hub: ~680/570 MB/s &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know why encryption slows down the via the hub so much and it also makes no sense for encrypted to the faster than decrypted when connected directly to the MacBook. I would like to keep the drive encrypted but the extreme speed penalty on a hub is unacceptable. Is there a way to simply password protect the drive? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154cp3a", "is_robot_indexable": true, "report_reasons": null, "author": "samurai489", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154cp3a/1_tb_samsung_t7_shield_odd_black_magic_tests_m1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154cp3a/1_tb_samsung_t7_shield_odd_black_magic_tests_m1/", "subreddit_subscribers": 693383, "created_utc": 1689815255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "IDK if this is the right place to post this question. If it's not pls direct me to the right place.   \n\n  \nI've gotten into upscaling videos I have collected and I decided to repurpose my old gaming laptop to do that. It isn't up to the task and I don't want to use my new gaming desktop to do it. I've been thinking of selling my laptop and getting 2 used 3090s and putting those in my Proxmox Supermicro datahoarder machine, creating 2 Windows VMs and using those to do the video upscaling but I'm worried about how the power draw works on the power supplies.  \n  \nIt has 2 PWS-1K28P-SQ power supplies. There are 2 CPUs with a TDP of 135 each. 36 drives which can reach 9-10watts each. So all that plus the 3090s I'm worried this will go over 1280 watts. If it does go over that will the 2nd power supply kick in? Like how does that work?", "author_fullname": "t2_8r7k9uf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about power draw on Supermicro chassis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154b2jo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689810877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;IDK if this is the right place to post this question. If it&amp;#39;s not pls direct me to the right place.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve gotten into upscaling videos I have collected and I decided to repurpose my old gaming laptop to do that. It isn&amp;#39;t up to the task and I don&amp;#39;t want to use my new gaming desktop to do it. I&amp;#39;ve been thinking of selling my laptop and getting 2 used 3090s and putting those in my Proxmox Supermicro datahoarder machine, creating 2 Windows VMs and using those to do the video upscaling but I&amp;#39;m worried about how the power draw works on the power supplies.  &lt;/p&gt;\n\n&lt;p&gt;It has 2 PWS-1K28P-SQ power supplies. There are 2 CPUs with a TDP of 135 each. 36 drives which can reach 9-10watts each. So all that plus the 3090s I&amp;#39;m worried this will go over 1280 watts. If it does go over that will the 2nd power supply kick in? Like how does that work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154b2jo", "is_robot_indexable": true, "report_reasons": null, "author": "TheBipolarChihuahua", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154b2jo/question_about_power_draw_on_supermicro_chassis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154b2jo/question_about_power_draw_on_supermicro_chassis/", "subreddit_subscribers": 693383, "created_utc": 1689810877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I have 6 blogs on blogger/blogspot and i want to save all of them at one time instead of saving them one by one. Is there a tool for blogger/blogspot that allows me to save all of my blogs at once. I use different email accounts for each blog, but all of my email accounts I use on each blog are connected on gmail (I have Chrome browser and Chromebook)\n\nthankx", "author_fullname": "t2_fpam464i3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blogger", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_154a32t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689808303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have 6 blogs on blogger/blogspot and i want to save all of them at one time instead of saving them one by one. Is there a tool for blogger/blogspot that allows me to save all of my blogs at once. I use different email accounts for each blog, but all of my email accounts I use on each blog are connected on gmail (I have Chrome browser and Chromebook)&lt;/p&gt;\n\n&lt;p&gt;thankx&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "154a32t", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Row-2889", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/154a32t/blogger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/154a32t/blogger/", "subreddit_subscribers": 693383, "created_utc": 1689808303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey \n\nmy two 18tb (WD HC550) disks arrived today and so did the dual hdd dock. I gave them a surface scan using Minitool Partition Wizard and /immediately/ both started to show errors. So i stopped the test. I checked an older 6TB disk with Minitool partition surface scan to see if maybe it was the dock that was bad - and that disk looked perfect.   \n\n\ni didnt wait for any of the tests to finish as the 18tb would show red dots immediately.\n\nSo now, i'm leaving them doing an erase test followed by smart-extended test on HDDScan over the next few days.\n\nShould I be worried that minitool partitionwizard said theres a bad block? Might it just be giving me false positives ? I guess i'll know the answer when HDDScan finishes in a day or two. \n\nhave others had tests apps give false positives before?", "author_fullname": "t2_timugpjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "new disk burn-in test. Minitool partition surface scan vs hddscan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_153w48n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689775778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;/p&gt;\n\n&lt;p&gt;my two 18tb (WD HC550) disks arrived today and so did the dual hdd dock. I gave them a surface scan using Minitool Partition Wizard and /immediately/ both started to show errors. So i stopped the test. I checked an older 6TB disk with Minitool partition surface scan to see if maybe it was the dock that was bad - and that disk looked perfect.   &lt;/p&gt;\n\n&lt;p&gt;i didnt wait for any of the tests to finish as the 18tb would show red dots immediately.&lt;/p&gt;\n\n&lt;p&gt;So now, i&amp;#39;m leaving them doing an erase test followed by smart-extended test on HDDScan over the next few days.&lt;/p&gt;\n\n&lt;p&gt;Should I be worried that minitool partitionwizard said theres a bad block? Might it just be giving me false positives ? I guess i&amp;#39;ll know the answer when HDDScan finishes in a day or two. &lt;/p&gt;\n\n&lt;p&gt;have others had tests apps give false positives before?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "153w48n", "is_robot_indexable": true, "report_reasons": null, "author": "Downtown-Pear-6509", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/153w48n/new_disk_burnin_test_minitool_partition_surface/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/153w48n/new_disk_burnin_test_minitool_partition_surface/", "subreddit_subscribers": 693383, "created_utc": 1689775778.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}