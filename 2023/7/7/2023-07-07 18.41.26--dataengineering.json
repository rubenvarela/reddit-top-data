{"kind": "Listing", "data": {"after": "t3_14t7fuy", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n\n\n\n\n\n\n\n\n\n\nHi guys, in my current job I only have the possibility to use excel, but I think of learning sql, python and others as a way to have better jobs. The point is that for that I would need a daily practice, which I could only achieve with personal projects. Do you think this is a valid way to keep the knowledge with me and show that I master the tool? or would a recruiter/employer not care too much about this? Honestly, I'm a little discouraged about learning only through courses and not having the opportunity to put anything into a project, I think that way I would understand better. Anyway, thanks for advice.", "author_fullname": "t2_cne2tl51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think it's valuable to maintain a personal portfolio even though you have a job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sh6f0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688667193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, in my current job I only have the possibility to use excel, but I think of learning sql, python and others as a way to have better jobs. The point is that for that I would need a daily practice, which I could only achieve with personal projects. Do you think this is a valid way to keep the knowledge with me and show that I master the tool? or would a recruiter/employer not care too much about this? Honestly, I&amp;#39;m a little discouraged about learning only through courses and not having the opportunity to put anything into a project, I think that way I would understand better. Anyway, thanks for advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14sh6f0", "is_robot_indexable": true, "report_reasons": null, "author": "gintokiredditbr", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sh6f0/do_you_think_its_valuable_to_maintain_a_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sh6f0/do_you_think_its_valuable_to_maintain_a_personal/", "subreddit_subscribers": 114558, "created_utc": 1688667193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It very much looks like DS becomes over-saturated with passionate and (self)educated employees.  \nAdditionally, AI such as co-pilots and no-code environments make this domain even more competitive.\n\nLook at the number of subreddit members r/datascience \\~ 1 million, r/dataengineering \\~ 10 times less\n\nDo you think that DE will be the next DS (sexiest job...)?  \nWhat do you think is worth to put time and effort in to get one step ahead - is this really platform engineering, distributive computing (Kubernetes) or something else?", "author_fullname": "t2_s9fqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data engineering the next data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14syob6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688710904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It very much looks like DS becomes over-saturated with passionate and (self)educated employees.&lt;br/&gt;\nAdditionally, AI such as co-pilots and no-code environments make this domain even more competitive.&lt;/p&gt;\n\n&lt;p&gt;Look at the number of subreddit members &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt; ~ 1 million, &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; ~ 10 times less&lt;/p&gt;\n\n&lt;p&gt;Do you think that DE will be the next DS (sexiest job...)?&lt;br/&gt;\nWhat do you think is worth to put time and effort in to get one step ahead - is this really platform engineering, distributive computing (Kubernetes) or something else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14syob6", "is_robot_indexable": true, "report_reasons": null, "author": "scriptosens", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14syob6/is_data_engineering_the_next_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14syob6/is_data_engineering_the_next_data_science/", "subreddit_subscribers": 114558, "created_utc": 1688710904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have only ever worked as a data analyst, and someone told me that I should consider data engineering because I'm actually pretty damn good at Python, SQL, Tableau, Power BI, Google BigQuery, SQL server. I've never used anything else crazy though like azure, snowflake, anything like that, and I have never been a DBA. But I do understand normal forms of data, and basic understandings of joins and one to many kind of stuff. \n\n\nGuess I'm really curious though what software is used in data engineering if I ever wanted to pursue that kind of career? Not that I know if I'm ready yet. I don't think I have the credentials yet", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What DBMS do you use mostly in your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14t536x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688730690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have only ever worked as a data analyst, and someone told me that I should consider data engineering because I&amp;#39;m actually pretty damn good at Python, SQL, Tableau, Power BI, Google BigQuery, SQL server. I&amp;#39;ve never used anything else crazy though like azure, snowflake, anything like that, and I have never been a DBA. But I do understand normal forms of data, and basic understandings of joins and one to many kind of stuff. &lt;/p&gt;\n\n&lt;p&gt;Guess I&amp;#39;m really curious though what software is used in data engineering if I ever wanted to pursue that kind of career? Not that I know if I&amp;#39;m ready yet. I don&amp;#39;t think I have the credentials yet&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14t536x", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t536x/what_dbms_do_you_use_mostly_in_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14t536x/what_dbms_do_you_use_mostly_in_your_job/", "subreddit_subscribers": 114558, "created_utc": 1688730690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I recently completed my first end-to-end data engineering project, aimed at strengthening my data engineering skills. The project is not complicated, but since I am used to only analyzing and modeling perfectly curated data (I am a data scientist) without getting involved in pipelines either putting models into production, I think it is a good start. \n\nArchitecture:  \n\n\n[ELT Architecture](https://preview.redd.it/ncxt2ysldeab1.png?width=1280&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4e3b58ec5ff56ef361076bc6eacd534c9570cb80)\n\n The project focuses on processing data from Formula 2 races.  The pipeline consists of several stages, including data retrieval, data cleaning, and storage in an S3 bucket. Additionally, the processed data is formatted to update the existing dataset hosted on Kaggle. The entire process is automated, leveraging the FIA calendar and race\\_id (despite their unorganized nature). Definitely not the best architecture, but the goal was to test multiple AWS services\n\nGitHub Repository: [here](https://github.com/Alarchemn/F2-Data-Pipeline)\n\nKaggle dataset: [here](https://www.kaggle.com/datasets/alarchemn/formula-2-dataset)\n\nI come from academia, PhD in nonlinear control engineering full of hard math. Migrating to real, executable projects is truly exciting.", "author_fullname": "t2_802hx5xi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First End-to-End Data Engineering Project: Formula 2 Data Pipeline for for Automated Updates of a Kaggle's dataset.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ncxt2ysldeab1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de3d106cef3cbe0547dc325434de4b6aecf9dd27"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8485aabb9d90787fbb9a056bf8b5ae91a682a016"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95ced63f842ffc673e62f7cba92c9afb6a1ffa7d"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53ef3a6cb3f0c010fa75193c0dc58253d6fc66ac"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ac73ed9b211962320c8be98f7b2d51de7d73060"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=954209739b130478ae5bab07a05edc0282dc50a2"}], "s": {"y": 720, "x": 1280, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=1280&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4e3b58ec5ff56ef361076bc6eacd534c9570cb80"}, "id": "ncxt2ysldeab1"}}, "name": "t3_14sjl7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pbIcvlJY4ovNaxfWeb5fOYQMf5R59tkrNu1NqqM-qFg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1688672647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently completed my first end-to-end data engineering project, aimed at strengthening my data engineering skills. The project is not complicated, but since I am used to only analyzing and modeling perfectly curated data (I am a data scientist) without getting involved in pipelines either putting models into production, I think it is a good start. &lt;/p&gt;\n\n&lt;p&gt;Architecture:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ncxt2ysldeab1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4e3b58ec5ff56ef361076bc6eacd534c9570cb80\"&gt;ELT Architecture&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The project focuses on processing data from Formula 2 races.  The pipeline consists of several stages, including data retrieval, data cleaning, and storage in an S3 bucket. Additionally, the processed data is formatted to update the existing dataset hosted on Kaggle. The entire process is automated, leveraging the FIA calendar and race_id (despite their unorganized nature). Definitely not the best architecture, but the goal was to test multiple AWS services&lt;/p&gt;\n\n&lt;p&gt;GitHub Repository: &lt;a href=\"https://github.com/Alarchemn/F2-Data-Pipeline\"&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Kaggle dataset: &lt;a href=\"https://www.kaggle.com/datasets/alarchemn/formula-2-dataset\"&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I come from academia, PhD in nonlinear control engineering full of hard math. Migrating to real, executable projects is truly exciting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?auto=webp&amp;v=enabled&amp;s=81fd7c3b399bc5fdd44656253abb501f7ba4926b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c87307180946a7ba8fdabcde422471d5925dac87", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=166887ea9aad89e6c6e5ed5671bf3bde1c21421a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3ca8834b84e826ffdd7f22246149c8b85d31357", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6435b51aeb9604007509ed31d13a0ed00bac3182", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a39903abb48f42367f59e5ac317d1054318a9cf", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99be992595a6a36fbf73dc3116e410dad6455030", "width": 1080, "height": 540}], "variants": {}, "id": "EQtC0QZfwwOYAdeS6vgMcmirb41drpfQe4xmnXw2TBM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "14sjl7h", "is_robot_indexable": true, "report_reasons": null, "author": "NationOfSheeps", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sjl7h/first_endtoend_data_engineering_project_formula_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sjl7h/first_endtoend_data_engineering_project_formula_2/", "subreddit_subscribers": 114558, "created_utc": 1688672647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I'm looking to see if Airflow is the best solution for what I need or if there is some other package that might be better suited.\n\nQuick background: My work involves processing video data. First ingesting it, transcoding it, running it through several AI models (computer vision, audio processing, etc) to find the most interesting moments, and then making 10-30sec clips of those moments. It's not strictly a 100% data-centered task: the ingestion part involves downloading from remote devices and normalizing the video, the AI part involves several stages of running models but also includes some compute-heavy analysis of usually 4-500k db records per stream, and the final output stage is almost purely using ffmpeg to cut clips from the original stream.\n\nNevertheless, it is a pipeline, with about 10 stages, and I thought Airflow would be a good way of managing it. The idea of defining a DAG for each type of stream, defining which steps need to occur (some in sequence, some concurrent, etc), dispatching tasks as they come up, and monitoring the pipeline is basically what I'm looking for, and Airflow seems to be very good for this.\n\nBut there are several concerns I have about Airflow and I'm wondering if these are easily addressed, or if there might be a different orchestrator that would be better.\n\n1. It seems Airflow is really designed to be cron on steroids. That is, it's designed for static jobs that are run on a set schedule. But my pipeline doesn't run on a schedule. It's triggered each time a new video is available. So sometimes there could be no jobs, and sometimes there could be a hundred videos that need to be processed. Does Airflow do well with these sorts of unscheduled jobs and would I run into any scalability issues if, at peak times, it needs to orchestrate several thousand videos all in various stages of the pipeline?\n2. Regarding static jobs, how static do jobs or DAGs need to be? While for probably 90% of our videos, the DAG would be fairly static (would need to pass a few parameters to specify which video to process), some videos require more dynamic DAGs, where based on a preliminary analysis of the video, a DAG would be created for that specific video. Does Airflow support truly dynamic, one-time DAGs, where we could essentially write a custom DAG for each video at the first step of processing and then have Airflow manage it from there (and then cleanup the DAG once the video is done)? Like I mentioned, we don't need this sort of fully dynamic feature right now, but it would be nice to have for future needs.\n3. How flexible is error and failure mode handling? While half of our errors can be fixed by simply restarting the step, the other half require looking at the actual error and re-routing to a different step or DAG entirely. For example, if a specific AI model finds no detections, the video might need to be sent to an entirely different pipeline with a different set of models / tasks, and then rejoin at the output phase to create the final clips.\n\nSo those are my main concerns. I guess the tl;dr version is, how flexible / dynamic are Airflow DAGs in practice? Can we write them to make decisions mid-pipeline about which path to go down (i.e. due to an error, or other conditions)? At the extreme, is it easy to write a completely custom DAG for each job? Or is there a better orchestrator to do this?\n\nThanks for any insight you can share!", "author_fullname": "t2_xaqri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow or something else for orchestrating non-data-centric pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14t7jpx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688736967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m looking to see if Airflow is the best solution for what I need or if there is some other package that might be better suited.&lt;/p&gt;\n\n&lt;p&gt;Quick background: My work involves processing video data. First ingesting it, transcoding it, running it through several AI models (computer vision, audio processing, etc) to find the most interesting moments, and then making 10-30sec clips of those moments. It&amp;#39;s not strictly a 100% data-centered task: the ingestion part involves downloading from remote devices and normalizing the video, the AI part involves several stages of running models but also includes some compute-heavy analysis of usually 4-500k db records per stream, and the final output stage is almost purely using ffmpeg to cut clips from the original stream.&lt;/p&gt;\n\n&lt;p&gt;Nevertheless, it is a pipeline, with about 10 stages, and I thought Airflow would be a good way of managing it. The idea of defining a DAG for each type of stream, defining which steps need to occur (some in sequence, some concurrent, etc), dispatching tasks as they come up, and monitoring the pipeline is basically what I&amp;#39;m looking for, and Airflow seems to be very good for this.&lt;/p&gt;\n\n&lt;p&gt;But there are several concerns I have about Airflow and I&amp;#39;m wondering if these are easily addressed, or if there might be a different orchestrator that would be better.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;It seems Airflow is really designed to be cron on steroids. That is, it&amp;#39;s designed for static jobs that are run on a set schedule. But my pipeline doesn&amp;#39;t run on a schedule. It&amp;#39;s triggered each time a new video is available. So sometimes there could be no jobs, and sometimes there could be a hundred videos that need to be processed. Does Airflow do well with these sorts of unscheduled jobs and would I run into any scalability issues if, at peak times, it needs to orchestrate several thousand videos all in various stages of the pipeline?&lt;/li&gt;\n&lt;li&gt;Regarding static jobs, how static do jobs or DAGs need to be? While for probably 90% of our videos, the DAG would be fairly static (would need to pass a few parameters to specify which video to process), some videos require more dynamic DAGs, where based on a preliminary analysis of the video, a DAG would be created for that specific video. Does Airflow support truly dynamic, one-time DAGs, where we could essentially write a custom DAG for each video at the first step of processing and then have Airflow manage it from there (and then cleanup the DAG once the video is done)? Like I mentioned, we don&amp;#39;t need this sort of fully dynamic feature right now, but it would be nice to have for future needs.&lt;/li&gt;\n&lt;li&gt;How flexible is error and failure mode handling? While half of our errors can be fixed by simply restarting the step, the other half require looking at the actual error and re-routing to a different step or DAG entirely. For example, if a specific AI model finds no detections, the video might need to be sent to an entirely different pipeline with a different set of models / tasks, and then rejoin at the output phase to create the final clips.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So those are my main concerns. I guess the tl;dr version is, how flexible / dynamic are Airflow DAGs in practice? Can we write them to make decisions mid-pipeline about which path to go down (i.e. due to an error, or other conditions)? At the extreme, is it easy to write a completely custom DAG for each job? Or is there a better orchestrator to do this?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any insight you can share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14t7jpx", "is_robot_indexable": true, "report_reasons": null, "author": "Wallaby99", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t7jpx/airflow_or_something_else_for_orchestrating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14t7jpx/airflow_or_something_else_for_orchestrating/", "subreddit_subscribers": 114558, "created_utc": 1688736967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Who sets up and manages the database connected to an application? Is it the software engineer, data engineer, database administrator? \n\nDon\u2019t shoot me for the basic question :)", "author_fullname": "t2_fwqwbjia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14syany", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688709736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Who sets up and manages the database connected to an application? Is it the software engineer, data engineer, database administrator? &lt;/p&gt;\n\n&lt;p&gt;Don\u2019t shoot me for the basic question :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14syany", "is_robot_indexable": true, "report_reasons": null, "author": "space-trader-92", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14syany/database_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14syany/database_question/", "subreddit_subscribers": 114558, "created_utc": 1688709736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_75heuca3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ByteDance Open Sources Its Cloud Native Data Warehouse ByConity | ByConity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14t5flu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/D3cz-2bsDFKimg1wsrAfDM3h0tyAXxxHMCz5GtG34FM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688731567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "byconity.github.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://byconity.github.io/blog/2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-wPxS3IJ1JTv9vZFeVIghBQ-CCba8FKVcMCGMZAlg6o.jpg?auto=webp&amp;v=enabled&amp;s=c4ff1ff84741b29b7d302a9b62f8a206066ea0f4", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/-wPxS3IJ1JTv9vZFeVIghBQ-CCba8FKVcMCGMZAlg6o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5091b91c7912953b978f02a3bcbafffb3cfc7c5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-wPxS3IJ1JTv9vZFeVIghBQ-CCba8FKVcMCGMZAlg6o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eeccdea4aafcd44051b22167029b69d26d64e771", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-wPxS3IJ1JTv9vZFeVIghBQ-CCba8FKVcMCGMZAlg6o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ea855e33d775c95780791056aa276222149e1d7", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/-wPxS3IJ1JTv9vZFeVIghBQ-CCba8FKVcMCGMZAlg6o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b8454874453dad2b0df73b0fc98f76285bac3e5", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/-wPxS3IJ1JTv9vZFeVIghBQ-CCba8FKVcMCGMZAlg6o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb1d2019f11d31e7bc589e4bbd7cedaa65e4fb19", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/-wPxS3IJ1JTv9vZFeVIghBQ-CCba8FKVcMCGMZAlg6o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1660c6a1a0e0d1f0d88a8505e9ef2be7e5ee8cd6", "width": 1080, "height": 567}], "variants": {}, "id": "2AKDmDFMHTAcOqZu_Vn5jn9WbhZqeiFh5_O8eGJblTw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14t5flu", "is_robot_indexable": true, "report_reasons": null, "author": "Junior-Salary-6859", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t5flu/bytedance_open_sources_its_cloud_native_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://byconity.github.io/blog/2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse", "subreddit_subscribers": 114558, "created_utc": 1688731567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone used their orchestration tool to refresh the BI dashboards that are pulling in those tables? This would be for only BI tools that are caching data locally. \n\nThe DAG would be source -&gt; transformations -&gt; ping BI tool API to start refresh. \n\nThis is something I have gone back and forth in my mind on. I have never seen any team put it into production but I could see some benefits. \n\nLet me know your thought!", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Orchestration Tool to refresh BI tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sp81z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688685190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone used their orchestration tool to refresh the BI dashboards that are pulling in those tables? This would be for only BI tools that are caching data locally. &lt;/p&gt;\n\n&lt;p&gt;The DAG would be source -&amp;gt; transformations -&amp;gt; ping BI tool API to start refresh. &lt;/p&gt;\n\n&lt;p&gt;This is something I have gone back and forth in my mind on. I have never seen any team put it into production but I could see some benefits. &lt;/p&gt;\n\n&lt;p&gt;Let me know your thought!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14sp81z", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sp81z/using_orchestration_tool_to_refresh_bi_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sp81z/using_orchestration_tool_to_refresh_bi_tool/", "subreddit_subscribers": 114558, "created_utc": 1688685190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it worth pursuing the Terraform certification in data engineering? My role is DevOps focussed, I really like the IaC component, and enjoy working with Terraform. Is it a step in the wrong direction?", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terraform Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sot3r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688684268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it worth pursuing the Terraform certification in data engineering? My role is DevOps focussed, I really like the IaC component, and enjoy working with Terraform. Is it a step in the wrong direction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14sot3r", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sot3r/terraform_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sot3r/terraform_certification/", "subreddit_subscribers": 114558, "created_utc": 1688684268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello DEs of Reddit, \n\nI am in the last year of my master's in a CS-related field (cloud computing), and I am a bit torn between choosing a career in DE or MLE. I have experience in both data science through Kaggle competitions and a few internships in small companies and 3 years of experience as a backend developer.\n\nI don't want to pursue a career as a data scientist anymore, as I found that I enjoy coding and building real software much more than creating Jupyter notebooks, besides,  the DS job market is over-saturated. I started learning some DE skills such as Kafka and I recently got my first AWS certification. \n\nHowever, I am afraid that I would get a boring DE job, I absolutely hate doing sysadmin and DBA tasks even though I am good with SQL, I prefer building streaming systems, and data pipelines and enjoy data modelling to some extent. This fear of ending up doing boring DE tasks with old unused technologies has pushed me to consider MLE as a career track since I have some experience with ML and I find it pretty exciting being an MLE means I can build ML-centric software that is production ready, however, I don't know how hard it is to get an entry MLE job (in Europe) compared to DE. \n\nThus I can't decide on which skills I should learn: continue learning DE skills (Kafka, Airflow, DBT, Data Warehousing, etc) or focus on getting MLE skills (Spark, Tensorflow, PyTorch, AWS, Kubernetes, etc). I would be grateful if you could give me some input on this topic \\^\\^.\n\n&amp;#x200B;", "author_fullname": "t2_nq65wse7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't decide between MLE or DE as a Career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14t9gvo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688741526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DEs of Reddit, &lt;/p&gt;\n\n&lt;p&gt;I am in the last year of my master&amp;#39;s in a CS-related field (cloud computing), and I am a bit torn between choosing a career in DE or MLE. I have experience in both data science through Kaggle competitions and a few internships in small companies and 3 years of experience as a backend developer.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to pursue a career as a data scientist anymore, as I found that I enjoy coding and building real software much more than creating Jupyter notebooks, besides,  the DS job market is over-saturated. I started learning some DE skills such as Kafka and I recently got my first AWS certification. &lt;/p&gt;\n\n&lt;p&gt;However, I am afraid that I would get a boring DE job, I absolutely hate doing sysadmin and DBA tasks even though I am good with SQL, I prefer building streaming systems, and data pipelines and enjoy data modelling to some extent. This fear of ending up doing boring DE tasks with old unused technologies has pushed me to consider MLE as a career track since I have some experience with ML and I find it pretty exciting being an MLE means I can build ML-centric software that is production ready, however, I don&amp;#39;t know how hard it is to get an entry MLE job (in Europe) compared to DE. &lt;/p&gt;\n\n&lt;p&gt;Thus I can&amp;#39;t decide on which skills I should learn: continue learning DE skills (Kafka, Airflow, DBT, Data Warehousing, etc) or focus on getting MLE skills (Spark, Tensorflow, PyTorch, AWS, Kubernetes, etc). I would be grateful if you could give me some input on this topic ^^.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14t9gvo", "is_robot_indexable": true, "report_reasons": null, "author": "lancelot_of_camelot", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t9gvo/cant_decide_between_mle_or_de_as_a_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14t9gvo/cant_decide_between_mle_or_de_as_a_career/", "subreddit_subscribers": 114558, "created_utc": 1688741526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I understand that Docker containers eliminate the issue of 'it works on my computer,' but I have encountered a problem while developing an application using Docker Compose, where memory disk and RAM are utilized on the host computer (which is outside the Docker containerization).\n\nConsequently, if I run this Docker Compose on a computer with low RAM or limited memory disk, it will result in an error, which defeats the purpose of Docker containerization. So, I have a few questions:\n\n1. What are the best practices for managing memory disk and RAM requirements for Docker containers?\n\n\n2. Are there any other potential issues that I should be aware of or able to configure when running the same Docker container on a different computer? This particular issue caught me off guard, and while it makes sense to me, I want to be prepared for any other potential challenges that may arise in the future", "author_fullname": "t2_3vzap1d5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What could go wrong with docker containers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14t92fo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688740561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand that Docker containers eliminate the issue of &amp;#39;it works on my computer,&amp;#39; but I have encountered a problem while developing an application using Docker Compose, where memory disk and RAM are utilized on the host computer (which is outside the Docker containerization).&lt;/p&gt;\n\n&lt;p&gt;Consequently, if I run this Docker Compose on a computer with low RAM or limited memory disk, it will result in an error, which defeats the purpose of Docker containerization. So, I have a few questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What are the best practices for managing memory disk and RAM requirements for Docker containers?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Are there any other potential issues that I should be aware of or able to configure when running the same Docker container on a different computer? This particular issue caught me off guard, and while it makes sense to me, I want to be prepared for any other potential challenges that may arise in the future&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14t92fo", "is_robot_indexable": true, "report_reasons": null, "author": "conlake", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t92fo/what_could_go_wrong_with_docker_containers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14t92fo/what_could_go_wrong_with_docker_containers/", "subreddit_subscribers": 114558, "created_utc": 1688740561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  \nI'm a DE with few years of experience. I just finished getting all the AWS associate certifications and I was wondering what I should be focusing on next. \n\nSQL: I know some SQL, but I'm not an expert. I was thinking getting leetcode and grinding the easy/mediums there.\n\nCloud: Maybe do Azure certifications or start studying for AWS Data Analytics speciality or SA PRO\n\nProjects: Complete DataTalkClub Data Engineering zoomcamp. I hear good things about this.  \n\n\nMaybe something completely different?  \nMy goal is to advance my skills to acquire more money in the job market.\n\n&amp;#x200B;", "author_fullname": "t2_27cwkjid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What next after AWS certifications?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14t6bjc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688733919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;br/&gt;\nI&amp;#39;m a DE with few years of experience. I just finished getting all the AWS associate certifications and I was wondering what I should be focusing on next. &lt;/p&gt;\n\n&lt;p&gt;SQL: I know some SQL, but I&amp;#39;m not an expert. I was thinking getting leetcode and grinding the easy/mediums there.&lt;/p&gt;\n\n&lt;p&gt;Cloud: Maybe do Azure certifications or start studying for AWS Data Analytics speciality or SA PRO&lt;/p&gt;\n\n&lt;p&gt;Projects: Complete DataTalkClub Data Engineering zoomcamp. I hear good things about this.  &lt;/p&gt;\n\n&lt;p&gt;Maybe something completely different?&lt;br/&gt;\nMy goal is to advance my skills to acquire more money in the job market.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14t6bjc", "is_robot_indexable": true, "report_reasons": null, "author": "Usurper__", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t6bjc/what_next_after_aws_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14t6bjc/what_next_after_aws_certifications/", "subreddit_subscribers": 114558, "created_utc": 1688733919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently discovered a YouTuber called \"the data janitor\" who articulates very clearly things that I've rarely heard elsewhere when it comes to getting into data engineering. He has very strong opinions on what are the ways of getting into data engineering and machine learning engineering. I was wondering if some of you know him and if, for those of you who are in a data engineer role, if his takes make sense or not from your point of view. I know the guy\u2019s very assertive \u201cno BS\u201d tone is not everyone\u2019s cup of tea, but I would like to have a discussion on what he actually says instead of his style or the fact that he also promotes his own education platform in his videos.  \n  \n  \nBasically the takeaways from his videos are as follows:  \n  \n1) Data engineer is not an entry-level role. If you don't have at least one year of experience in a data-related role (data analyst, DBA, etc), there's 99% chance you won\u2019t be hired as a data engineer.  \n  \n2) A person who wants to become a data engineer shouldn't try to become that first (almost impossible), but should focus instead on a real entry level role such as data analyst.  \n  \n3) Data roles (DE, DA, MLE, etc) are primarily SQL heavy roles. You can't get away from SQL. Because SQL is not sexy, bootcamps want you to believe that you\u2019ll also need a significant amount of Python (more sexy), but 90% of the time, you don\u2019t.  \n  \n4) Data roles are very different from software engineering roles. A data analyst is better suited at becoming a data engineer than a DevOps or a Back-end dev.  \n  \n5) Certifications and certificates of completion are totally different. Certificates of completion (Coursera, Datacamp, etc) that you obtain by simply watching videos and filling blanks are worthless to recruiters. On the other hand, certifications, i.e. you have to take an exam in a physical test center or online proctored and you pass/fail the exam, can definitely have some value, but mostly if they come from the big three (Google, Microsoft, AWS) or traditional tech corporations (Oracle, Cisco, IBM, \u2026). Some of those certifications are very hard to get and thus very respected (example: MySQL 8.0 Database Developer 1Z0-909 from Oracle). Certifications are not worth as much as actual work experience, but it\u2019s still a non-falsifiable signal that you know a tool/framework well enough for a job.  \n  \n6) He thinks that without prior data experience, if you want to get into data engineering, your primary objective should be to get into a data analyst role first, and to get this role, you need two skills, Power BI and SQL. To signal those skills, two recognized certifications can help if you don\u2019t have any professional experience with them: **PL-300 Microsoft Power BI Data Analyst**, and (since Microsoft deprecated most of its former SQL certs) **DP-300 Administering Microsoft Azure SQL Solutions**. He claims that having those two certifications on a resume can definitely get you interviews for entry-level data analyst roles if you don't have any experience in the field.  \n  \n  \nThoughts?  \n  \nFor those who are/have been data engineers, do you agree with him or not? Does it depend on the field we're talking (big/legacy tech VS smaller companies maybe)? Or is it broadly true/false?  \n  \nWhat I like about him is that he seems very frank and honest about his view of the professional data world, very different from the typical too-good-to-be-true takes that you see here and there that sounds like \"don't worry anon you'll find a job in data if you send enough resumes, plenty of opportunities out there :3\", either because people want you to sign-up to their bootcamp, or just not hurt your feelings.", "author_fullname": "t2_12modp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on the data janitor (youtube)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14tdmv2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688751188.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688750868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently discovered a YouTuber called &amp;quot;the data janitor&amp;quot; who articulates very clearly things that I&amp;#39;ve rarely heard elsewhere when it comes to getting into data engineering. He has very strong opinions on what are the ways of getting into data engineering and machine learning engineering. I was wondering if some of you know him and if, for those of you who are in a data engineer role, if his takes make sense or not from your point of view. I know the guy\u2019s very assertive \u201cno BS\u201d tone is not everyone\u2019s cup of tea, but I would like to have a discussion on what he actually says instead of his style or the fact that he also promotes his own education platform in his videos.  &lt;/p&gt;\n\n&lt;p&gt;Basically the takeaways from his videos are as follows:  &lt;/p&gt;\n\n&lt;p&gt;1) Data engineer is not an entry-level role. If you don&amp;#39;t have at least one year of experience in a data-related role (data analyst, DBA, etc), there&amp;#39;s 99% chance you won\u2019t be hired as a data engineer.  &lt;/p&gt;\n\n&lt;p&gt;2) A person who wants to become a data engineer shouldn&amp;#39;t try to become that first (almost impossible), but should focus instead on a real entry level role such as data analyst.  &lt;/p&gt;\n\n&lt;p&gt;3) Data roles (DE, DA, MLE, etc) are primarily SQL heavy roles. You can&amp;#39;t get away from SQL. Because SQL is not sexy, bootcamps want you to believe that you\u2019ll also need a significant amount of Python (more sexy), but 90% of the time, you don\u2019t.  &lt;/p&gt;\n\n&lt;p&gt;4) Data roles are very different from software engineering roles. A data analyst is better suited at becoming a data engineer than a DevOps or a Back-end dev.  &lt;/p&gt;\n\n&lt;p&gt;5) Certifications and certificates of completion are totally different. Certificates of completion (Coursera, Datacamp, etc) that you obtain by simply watching videos and filling blanks are worthless to recruiters. On the other hand, certifications, i.e. you have to take an exam in a physical test center or online proctored and you pass/fail the exam, can definitely have some value, but mostly if they come from the big three (Google, Microsoft, AWS) or traditional tech corporations (Oracle, Cisco, IBM, \u2026). Some of those certifications are very hard to get and thus very respected (example: MySQL 8.0 Database Developer 1Z0-909 from Oracle). Certifications are not worth as much as actual work experience, but it\u2019s still a non-falsifiable signal that you know a tool/framework well enough for a job.  &lt;/p&gt;\n\n&lt;p&gt;6) He thinks that without prior data experience, if you want to get into data engineering, your primary objective should be to get into a data analyst role first, and to get this role, you need two skills, Power BI and SQL. To signal those skills, two recognized certifications can help if you don\u2019t have any professional experience with them: &lt;strong&gt;PL-300 Microsoft Power BI Data Analyst&lt;/strong&gt;, and (since Microsoft deprecated most of its former SQL certs) &lt;strong&gt;DP-300 Administering Microsoft Azure SQL Solutions&lt;/strong&gt;. He claims that having those two certifications on a resume can definitely get you interviews for entry-level data analyst roles if you don&amp;#39;t have any experience in the field.  &lt;/p&gt;\n\n&lt;p&gt;Thoughts?  &lt;/p&gt;\n\n&lt;p&gt;For those who are/have been data engineers, do you agree with him or not? Does it depend on the field we&amp;#39;re talking (big/legacy tech VS smaller companies maybe)? Or is it broadly true/false?  &lt;/p&gt;\n\n&lt;p&gt;What I like about him is that he seems very frank and honest about his view of the professional data world, very different from the typical too-good-to-be-true takes that you see here and there that sounds like &amp;quot;don&amp;#39;t worry anon you&amp;#39;ll find a job in data if you send enough resumes, plenty of opportunities out there :3&amp;quot;, either because people want you to sign-up to their bootcamp, or just not hurt your feelings.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14tdmv2", "is_robot_indexable": true, "report_reasons": null, "author": "Nabugu", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14tdmv2/thoughts_on_the_data_janitor_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14tdmv2/thoughts_on_the_data_janitor_youtube/", "subreddit_subscribers": 114558, "created_utc": 1688750868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ballista (Rust) vs Apache Spark. A Tale of Woe.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 34, "top_awarded_type": null, "hide_score": true, "name": "t3_14tdo5y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/M4hl43rp28jFBJbYfOZ1ldSRa6S8JzWJ5FuTR-3H1zA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688750955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confessionsofadataguy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confessionsofadataguy.com/ballista-vs-apache-spark-rust-vs-scala/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6CoC76gRLzTRh9kLZy9mjLbR3qFLP9YMZCacHbndKeg.jpg?auto=webp&amp;v=enabled&amp;s=8c953c2e4badd8237361cfc47b848c723142f049", "width": 1030, "height": 256}, "resolutions": [{"url": "https://external-preview.redd.it/6CoC76gRLzTRh9kLZy9mjLbR3qFLP9YMZCacHbndKeg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=804b71dd673be0ae026a7ef2fbdca035de1e92fc", "width": 108, "height": 26}, {"url": "https://external-preview.redd.it/6CoC76gRLzTRh9kLZy9mjLbR3qFLP9YMZCacHbndKeg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=522223bb8ed44885297ab97361148288f11c2797", "width": 216, "height": 53}, {"url": "https://external-preview.redd.it/6CoC76gRLzTRh9kLZy9mjLbR3qFLP9YMZCacHbndKeg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05e795b0bf9d7ddc0a898a11a0da610125c4502a", "width": 320, "height": 79}, {"url": "https://external-preview.redd.it/6CoC76gRLzTRh9kLZy9mjLbR3qFLP9YMZCacHbndKeg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3d4566124e014c29f04380a727f5aa02ec4883f", "width": 640, "height": 159}, {"url": "https://external-preview.redd.it/6CoC76gRLzTRh9kLZy9mjLbR3qFLP9YMZCacHbndKeg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a4d6b04ce1038a16128faeb2f05dbfeaba3a199", "width": 960, "height": 238}], "variants": {}, "id": "qE0Ogq09go835bYZqetYe499gYh-vENTOe4Jt_8xz40"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14tdo5y", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14tdo5y/ballista_rust_vs_apache_spark_a_tale_of_woe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confessionsofadataguy.com/ballista-vs-apache-spark-rust-vs-scala/", "subreddit_subscribers": 114558, "created_utc": 1688750955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the preferred method of deploying Data Lakehouses in Databricks?\n\nI\u2019m used to the SQL Server world with database projects in SSDT with table, views and stored procedures (etc.) and use state-based deployment of the SQL objects.", "author_fullname": "t2_6os62tc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD for Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ta1b3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688742764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the preferred method of deploying Data Lakehouses in Databricks?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m used to the SQL Server world with database projects in SSDT with table, views and stored procedures (etc.) and use state-based deployment of the SQL objects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ta1b3", "is_robot_indexable": true, "report_reasons": null, "author": "JKMikkelsen", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ta1b3/cicd_for_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ta1b3/cicd_for_databricks/", "subreddit_subscribers": 114558, "created_utc": 1688742764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  \n\n\nWe're using Delta Live Tables with Auto Loader in a project. The data is stored in ADLS, but within a specific folder there are several different file types:  \n\n\nweatherFile\\_321.json  \nweatherFile\\_123.json  \nweatherFile\\_132.json   \nlocationFile\\_231.json  \nlocationFile\\_231.json  \ntemperatureFile\\_212.json  \ntemperatureFile\\_122.json  \nhumidityFile\\_983.json  \nhumidityFile\\_839.json  \n...  \netc.  \n\n\nMy path is defined as follows:\n\njson\\_path = \"abfss://&lt;storage-container&gt;@&lt;storage-account&gt;.dfs.core.windows.net/weatherLandingZone/raw/2023/7/6/\"  \n\n\nNow, is there a way to use file pattern matching in Databricks using wildcards so that I would be able to ingest only certain files? Something like this:\n\n\"abfss://&lt;storage-container&gt;@&lt;storage-account&gt;.dfs.core.windows.net/weatherLandingZone/raw/2023/7/6/**weatherFile\\_\\***\"  \n\n\nThanks!", "author_fullname": "t2_nu50f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File pattern matching Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14t786q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688736164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!  &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re using Delta Live Tables with Auto Loader in a project. The data is stored in ADLS, but within a specific folder there are several different file types:  &lt;/p&gt;\n\n&lt;p&gt;weatherFile_321.json&lt;br/&gt;\nweatherFile_123.json&lt;br/&gt;\nweatherFile_132.json&lt;br/&gt;\nlocationFile_231.json&lt;br/&gt;\nlocationFile_231.json&lt;br/&gt;\ntemperatureFile_212.json&lt;br/&gt;\ntemperatureFile_122.json&lt;br/&gt;\nhumidityFile_983.json&lt;br/&gt;\nhumidityFile_839.json&lt;br/&gt;\n...&lt;br/&gt;\netc.  &lt;/p&gt;\n\n&lt;p&gt;My path is defined as follows:&lt;/p&gt;\n\n&lt;p&gt;json_path = &amp;quot;abfss://&amp;lt;storage-container&amp;gt;@&amp;lt;storage-account&amp;gt;.dfs.core.windows.net/weatherLandingZone/raw/2023/7/6/&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;Now, is there a way to use file pattern matching in Databricks using wildcards so that I would be able to ingest only certain files? Something like this:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;abfss://&amp;lt;storage-container&amp;gt;@&amp;lt;storage-account&amp;gt;.dfs.core.windows.net/weatherLandingZone/raw/2023/7/6/&lt;strong&gt;weatherFile_\\&lt;/strong&gt;*&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14t786q", "is_robot_indexable": true, "report_reasons": null, "author": "sugarbuzzlightyear", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t786q/file_pattern_matching_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14t786q/file_pattern_matching_databricks/", "subreddit_subscribers": 114558, "created_utc": 1688736164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working since last 18 months as Data Analyst but it was more of support role. I did not get much exposure to Snowflake,SQL, ETL procedures. I have been laid off. Been trying to get job since then..got close but could not get selected. \n\nI am good in sql and okay in snowflake through whatever i have practiced through one of Udemy course. \n \nSo will core snowpro core certification will help me get job?  Will it be great option in long term too? \n\nThanks.", "author_fullname": "t2_bncwj1wq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can Snowflake core certification get me good job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14syhsh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688710341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working since last 18 months as Data Analyst but it was more of support role. I did not get much exposure to Snowflake,SQL, ETL procedures. I have been laid off. Been trying to get job since then..got close but could not get selected. &lt;/p&gt;\n\n&lt;p&gt;I am good in sql and okay in snowflake through whatever i have practiced through one of Udemy course. &lt;/p&gt;\n\n&lt;p&gt;So will core snowpro core certification will help me get job?  Will it be great option in long term too? &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14syhsh", "is_robot_indexable": true, "report_reasons": null, "author": "Intelligent_Ad7284", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14syhsh/can_snowflake_core_certification_get_me_good_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14syhsh/can_snowflake_core_certification_get_me_good_job/", "subreddit_subscribers": 114558, "created_utc": 1688710341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently undertaking a summer internship at a healthcare analytics company where I've been tasked with expanding our reporting capabilities to include Medicare data. While we're well-versed in Medicaid reporting, this is something new that the company is trying and I have been assigned on this project to figure out if there is a way to create reports using the Medicare data. I'm reaching out to the community for any insights or advice regarding working with Medicare CCLF (Claim and Claim Line Feed) data. I am the only intern as it is a small company and I am working alone on this project!\n\nI am struggling in identifying the attribution field within the data. Since we provide separate reports to each clinic, it's crucial  to differentiate the data based on clinics. Unfortunately, I haven't been able to locate this field in the Claims files yet. However, I have figured out how to calculate Part A and Part B claims from the data.\n\nCurrently, I'm planning to initiate the ETL (Extract, Transform, Load) process by loading the fixed width files into SQL Server. My approach involves creating tables and utilizing Bulk Insert. I would appreciate any feedback or suggestions if anyone has experience working with Medicare data or any recommendations on how to proceed.\n\nThank you in advance for your help and valuable insights!", "author_fullname": "t2_67a2wkjc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with Medicare CCLF Data - Seeking Insights and Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sh2zb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688666976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently undertaking a summer internship at a healthcare analytics company where I&amp;#39;ve been tasked with expanding our reporting capabilities to include Medicare data. While we&amp;#39;re well-versed in Medicaid reporting, this is something new that the company is trying and I have been assigned on this project to figure out if there is a way to create reports using the Medicare data. I&amp;#39;m reaching out to the community for any insights or advice regarding working with Medicare CCLF (Claim and Claim Line Feed) data. I am the only intern as it is a small company and I am working alone on this project!&lt;/p&gt;\n\n&lt;p&gt;I am struggling in identifying the attribution field within the data. Since we provide separate reports to each clinic, it&amp;#39;s crucial  to differentiate the data based on clinics. Unfortunately, I haven&amp;#39;t been able to locate this field in the Claims files yet. However, I have figured out how to calculate Part A and Part B claims from the data.&lt;/p&gt;\n\n&lt;p&gt;Currently, I&amp;#39;m planning to initiate the ETL (Extract, Transform, Load) process by loading the fixed width files into SQL Server. My approach involves creating tables and utilizing Bulk Insert. I would appreciate any feedback or suggestions if anyone has experience working with Medicare data or any recommendations on how to proceed.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help and valuable insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14sh2zb", "is_robot_indexable": true, "report_reasons": null, "author": "Uchiha_pandu", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sh2zb/working_with_medicare_cclf_data_seeking_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sh2zb/working_with_medicare_cclf_data_seeking_insights/", "subreddit_subscribers": 114558, "created_utc": 1688666976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been learning about pipelines and it seems like a no-brainer, am I missing something?", "author_fullname": "t2_img2xgzp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is keeping companies on hadoop + HIVE instead of spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14tebqr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688752493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been learning about pipelines and it seems like a no-brainer, am I missing something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14tebqr", "is_robot_indexable": true, "report_reasons": null, "author": "yonz-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14tebqr/what_is_keeping_companies_on_hadoop_hive_instead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14tebqr/what_is_keeping_companies_on_hadoop_hive_instead/", "subreddit_subscribers": 114558, "created_utc": 1688752493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am fairly new to the domain and to this here Reddit community. I am trying to ramp up quickly coming from a more app-development background. I am not on Threads yet, and honestly, I need a new app/channel like a hole in the head. Do people here recommend getting into Threads specifically to follow DE topics? I am told that it is less vendor-infected than LinkedIn and Twitter... but it's early days?  \nAlso, thanks to the community here - Reddit has been great to gain perspective and discover new resources!", "author_fullname": "t2_7yk2o6hxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Eng on Twitter vs. Threads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14teai2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688752410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am fairly new to the domain and to this here Reddit community. I am trying to ramp up quickly coming from a more app-development background. I am not on Threads yet, and honestly, I need a new app/channel like a hole in the head. Do people here recommend getting into Threads specifically to follow DE topics? I am told that it is less vendor-infected than LinkedIn and Twitter... but it&amp;#39;s early days?&lt;br/&gt;\nAlso, thanks to the community here - Reddit has been great to gain perspective and discover new resources!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14teai2", "is_robot_indexable": true, "report_reasons": null, "author": "grahamdietz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14teai2/data_eng_on_twitter_vs_threads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14teai2/data_eng_on_twitter_vs_threads/", "subreddit_subscribers": 114558, "created_utc": 1688752410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone complete the Data Engineering Zoomcamp while working? \n\nI want to switch jobs in 2 months max. How many hours would you say are required to complete all the material and the project? \n\nI understand the certificate is not available until the next cohort.", "author_fullname": "t2_9630n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Zoomcamp Timeliness - Total Hours required", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tby7e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688747075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone complete the Data Engineering Zoomcamp while working? &lt;/p&gt;\n\n&lt;p&gt;I want to switch jobs in 2 months max. How many hours would you say are required to complete all the material and the project? &lt;/p&gt;\n\n&lt;p&gt;I understand the certificate is not available until the next cohort.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14tby7e", "is_robot_indexable": true, "report_reasons": null, "author": "Amanlikeyou", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14tby7e/data_engineering_zoomcamp_timeliness_total_hours/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14tby7e/data_engineering_zoomcamp_timeliness_total_hours/", "subreddit_subscribers": 114558, "created_utc": 1688747075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A project I'm working on is finally getting large enough to the point where we need to programmatically declare the schema for each of our table, and ideally version control it\n\nFor reference, I'm interfacing with a MySQL database through sqlalchemy mostly\n\nI've played around with alembic a little bit, and it looks pretty good so far. Are there any other tools that you guys use for version controlling schemas?", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for version control of your database schema?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14tbs9q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688746696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A project I&amp;#39;m working on is finally getting large enough to the point where we need to programmatically declare the schema for each of our table, and ideally version control it&lt;/p&gt;\n\n&lt;p&gt;For reference, I&amp;#39;m interfacing with a MySQL database through sqlalchemy mostly&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve played around with alembic a little bit, and it looks pretty good so far. Are there any other tools that you guys use for version controlling schemas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14tbs9q", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14tbs9q/what_do_you_use_for_version_control_of_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14tbs9q/what_do_you_use_for_version_control_of_your/", "subreddit_subscribers": 114558, "created_utc": 1688746696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'd like to ask for opinion and feedback.\n\nWhat it does :\n1. Go to base_url.com/sitemap.xml\n2. If there is an xml file again and haven't been visited yet, fetch that xml url.\n3.) Retrieve all found url inside the xml url.\n\n\n```\nclass SitemapCrawl :\n    _PATT_RE = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()&lt;&gt;]+|\\(([^\\s()&lt;&gt;]+|(\\([^\\s()&lt;&gt;]+\\)))*\\))+(?:\\(([^\\s()&lt;&gt;]+|(\\([^\\s()&lt;&gt;]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,&lt;&gt;?\u00ab\u00bb\u201c\u201d\u2018\u2019]))\"\n    _FIND_URL = lambda self, text : re.findall(re.compile(self._PATT_RE), text)\n    _visited = set()\n\n    def _get_sitemap(self, url : str) -&gt; Tuple[ Deque[str], Set[str] ] :\n        found_urls = set()\n        xml_urls = set()\n\n        try :\n            with httpx.Client(verify = True, follow_redirects = True, headers = {\"User-Agent\" : \"\"}) as sess :\n                resp = sess.get(url)\n        except (httpx.HTTPError, httpx.ConnectTimeout, httpx.ConnectError) as e :\n            resp = None\n        self._visited.add(url)\n        \n        if resp is not None :\n            que_url = [ i[0] for i in self._FIND_URL(resp.text) ]\n\n            for url in que_url :\n                if url.endswith(\".xml\") :\n                    xml_urls.add(url)\n                elif url.endswith(\".xml\") == False :\n                    found_urls.add(url)\n            return deque(xml_urls), found_urls\n        return None, None\n\n    def get_sitemap_url(self, start_url : str) -&gt; Deque[str] :\n        xml_urls, found_urls = self._get_sitemap(start_url)\n\n        while xml_urls :\n            curr_url = xml_urls.popleft()\n            curr_xml_url, curr_found_url = self._get_sitemap(curr_url)\n            \n            if curr_xml_url is not None and curr_found_url is not None :\n                for i in curr_xml_url :\n                    if i not in self._visited :\n                        xml_urls.append(i)\n\n                for i in curr_found_url :\n                    found_urls.add(i)\n\n        return found_urls\n```\n\nQuestion and problems :\n- Why does it get stuck in a url at times and doesn't go to the next url ? (There is a for loop function that loops over list of base_url.com/sitemap.xml)\n- Any tips and feedback how to make this code more robust ?  (It still has a lot of weakness)\n- How would you speed this up and why ? (Without getting blocked by the site)\n\nThanks !", "author_fullname": "t2_qj15embb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for code review on web crawling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14t9ocg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688747633.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688741999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;d like to ask for opinion and feedback.&lt;/p&gt;\n\n&lt;p&gt;What it does :\n1. Go to base_url.com/sitemap.xml\n2. If there is an xml file again and haven&amp;#39;t been visited yet, fetch that xml url.\n3.) Retrieve all found url inside the xml url.&lt;/p&gt;\n\n&lt;p&gt;``&lt;code&gt;\nclass SitemapCrawl :\n    _PATT_RE = r&amp;quot;(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()&amp;lt;&amp;gt;]+|\\(([^\\s()&amp;lt;&amp;gt;]+|(\\([^\\s()&amp;lt;&amp;gt;]+\\)))*\\))+(?:\\(([^\\s()&amp;lt;&amp;gt;]+|(\\([^\\s()&amp;lt;&amp;gt;]+\\)))*\\)|[^\\s&lt;/code&gt;!()[]{};:&amp;#39;\\&amp;quot;.,&amp;lt;&amp;gt;?\u00ab\u00bb\u201c\u201d\u2018\u2019]))&amp;quot;\n    _FIND_URL = lambda self, text : re.findall(re.compile(self._PATT_RE), text)\n    _visited = set()&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def _get_sitemap(self, url : str) -&amp;gt; Tuple[ Deque[str], Set[str] ] :\n    found_urls = set()\n    xml_urls = set()\n\n    try :\n        with httpx.Client(verify = True, follow_redirects = True, headers = {&amp;quot;User-Agent&amp;quot; : &amp;quot;&amp;quot;}) as sess :\n            resp = sess.get(url)\n    except (httpx.HTTPError, httpx.ConnectTimeout, httpx.ConnectError) as e :\n        resp = None\n    self._visited.add(url)\n\n    if resp is not None :\n        que_url = [ i[0] for i in self._FIND_URL(resp.text) ]\n\n        for url in que_url :\n            if url.endswith(&amp;quot;.xml&amp;quot;) :\n                xml_urls.add(url)\n            elif url.endswith(&amp;quot;.xml&amp;quot;) == False :\n                found_urls.add(url)\n        return deque(xml_urls), found_urls\n    return None, None\n\ndef get_sitemap_url(self, start_url : str) -&amp;gt; Deque[str] :\n    xml_urls, found_urls = self._get_sitemap(start_url)\n\n    while xml_urls :\n        curr_url = xml_urls.popleft()\n        curr_xml_url, curr_found_url = self._get_sitemap(curr_url)\n\n        if curr_xml_url is not None and curr_found_url is not None :\n            for i in curr_xml_url :\n                if i not in self._visited :\n                    xml_urls.append(i)\n\n            for i in curr_found_url :\n                found_urls.add(i)\n\n    return found_urls\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;Question and problems :\n- Why does it get stuck in a url at times and doesn&amp;#39;t go to the next url ? (There is a for loop function that loops over list of base_url.com/sitemap.xml)\n- Any tips and feedback how to make this code more robust ?  (It still has a lot of weakness)\n- How would you speed this up and why ? (Without getting blocked by the site)&lt;/p&gt;\n\n&lt;p&gt;Thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14t9ocg", "is_robot_indexable": true, "report_reasons": null, "author": "Grouchy_Document7786", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t9ocg/looking_for_code_review_on_web_crawling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14t9ocg/looking_for_code_review_on_web_crawling/", "subreddit_subscribers": 114558, "created_utc": 1688741999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I previously worked as a Senior Operations Analyst and just completed my MBA. My work used to involve heavy analytics and report building in PowerBI. \n\nMost of my reports required me to build out complicated datasets that I'd then hand over to our architect team to implement.  I realized that building out the data was my favorite part of my position. \n\nDue to my proximity with our architect team and them being happy with the work I provided them, I was offered a position as a BI Architect/Engineer which I accepted.\n\nMy new role involves zero data analytics or report creation. Instead, 100% of my time is spent designing and creating data pipelines used by our analysts and data scientists.\n\nWe're very heavy in SSMS but are switching to AWS and redshift.\n\nI'm currently enrolled in an MS in data analytics (very heavy in machine learning)... However, I feel with my new role and career track it may be worth it to pursue a MSCS since my undergrad was a Fine Arts degree.  Alternatively, I could finish my MSDA and pursue certificates.\n\nMy company provides 5k a year in school reimbursement and I personally love being a student. So cost/time are not huge in my decision making process. Currently working remote making 95k + 10% bonus in the midwest.\n\nI'm looking for what will give me the most job security in the future and allow me to expand my DE skills.", "author_fullname": "t2_1h8uoabl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New BI Engineer. Should I pursue an MSCS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14t87us", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688738585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I previously worked as a Senior Operations Analyst and just completed my MBA. My work used to involve heavy analytics and report building in PowerBI. &lt;/p&gt;\n\n&lt;p&gt;Most of my reports required me to build out complicated datasets that I&amp;#39;d then hand over to our architect team to implement.  I realized that building out the data was my favorite part of my position. &lt;/p&gt;\n\n&lt;p&gt;Due to my proximity with our architect team and them being happy with the work I provided them, I was offered a position as a BI Architect/Engineer which I accepted.&lt;/p&gt;\n\n&lt;p&gt;My new role involves zero data analytics or report creation. Instead, 100% of my time is spent designing and creating data pipelines used by our analysts and data scientists.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re very heavy in SSMS but are switching to AWS and redshift.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently enrolled in an MS in data analytics (very heavy in machine learning)... However, I feel with my new role and career track it may be worth it to pursue a MSCS since my undergrad was a Fine Arts degree.  Alternatively, I could finish my MSDA and pursue certificates.&lt;/p&gt;\n\n&lt;p&gt;My company provides 5k a year in school reimbursement and I personally love being a student. So cost/time are not huge in my decision making process. Currently working remote making 95k + 10% bonus in the midwest.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for what will give me the most job security in the future and allow me to expand my DE skills.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14t87us", "is_robot_indexable": true, "report_reasons": null, "author": "Linkfan92", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t87us/new_bi_engineer_should_i_pursue_an_mscs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14t87us/new_bi_engineer_should_i_pursue_an_mscs/", "subreddit_subscribers": 114558, "created_utc": 1688738585.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are designing data vault model with 100s of source tables..\n\n for which I see we have to create 100s of model objects for HUB,SAT,LINK, etc.\n\nWill it be efficient to load the source and target models mapping into a config table and process them using a loop or do we have to create model and script for each of them manually?\n\nHow did you handle in your case?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt design question for data vault", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14t7fuy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688736682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are designing data vault model with 100s of source tables..&lt;/p&gt;\n\n&lt;p&gt;for which I see we have to create 100s of model objects for HUB,SAT,LINK, etc.&lt;/p&gt;\n\n&lt;p&gt;Will it be efficient to load the source and target models mapping into a config table and process them using a loop or do we have to create model and script for each of them manually?&lt;/p&gt;\n\n&lt;p&gt;How did you handle in your case?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14t7fuy", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14t7fuy/dbt_design_question_for_data_vault/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14t7fuy/dbt_design_question_for_data_vault/", "subreddit_subscribers": 114558, "created_utc": 1688736682.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}