{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7rg2eq0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ibis: The last dataframe API you'll need to learn? I hope...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_14scpwd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1f7xjfOAIYhpUkFu30A1o6jJdHN4LtkvOgb5HEUxrJA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688657666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/om8sn7dv4dab1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/om8sn7dv4dab1.jpg?auto=webp&amp;v=enabled&amp;s=26a2c5b45f93e3dbc55c183d60c946d77c71c5ce", "width": 615, "height": 406}, "resolutions": [{"url": "https://preview.redd.it/om8sn7dv4dab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=397852187f977618b9e62e77eaa5f87d001122c1", "width": 108, "height": 71}, {"url": "https://preview.redd.it/om8sn7dv4dab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78aeea75f0b6ccefd9b74982f2ce3f3c1b9c5767", "width": 216, "height": 142}, {"url": "https://preview.redd.it/om8sn7dv4dab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea8a159eb5a40eb15902c745172174fd357d2122", "width": 320, "height": 211}], "variants": {}, "id": "cnILZOqZaLQq33SHBJ1wzl4YNngafQy5H9zcR2B6SzI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14scpwd", "is_robot_indexable": true, "report_reasons": null, "author": "bitsondatadev", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14scpwd/ibis_the_last_dataframe_api_youll_need_to_learn_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/om8sn7dv4dab1.jpg", "subreddit_subscribers": 114461, "created_utc": 1688657666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Job requirements are ridiculous, On LinkedIn Data Engineer roles require 3+ years of experience and Machine learning Roles require around 7+ years of experience. I was preparing for a data engineer role but perhaps there's no point in doing that anymore, Maybe I should start focusing on being a data analyst and then switch jobs?? What advice would you guys give to a guy in college interested in the field of data??", "author_fullname": "t2_3hhrw7ib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No entry level jobs for data engineer or machine learning engineer??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s0d0h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688624978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Job requirements are ridiculous, On LinkedIn Data Engineer roles require 3+ years of experience and Machine learning Roles require around 7+ years of experience. I was preparing for a data engineer role but perhaps there&amp;#39;s no point in doing that anymore, Maybe I should start focusing on being a data analyst and then switch jobs?? What advice would you guys give to a guy in college interested in the field of data??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14s0d0h", "is_robot_indexable": true, "report_reasons": null, "author": "AnishNehete", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s0d0h/no_entry_level_jobs_for_data_engineer_or_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s0d0h/no_entry_level_jobs_for_data_engineer_or_machine/", "subreddit_subscribers": 114461, "created_utc": 1688624978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got into data engineering since there are a lot of open source tools to play around with.\n\nNow, recruiters are looking into experience with Databricks instead of Spark.\n\nSnowflake instead of Postgres and MySQL.\n\nYou also need certifications on AWS, Azure or GCP which despite having free credits, at some point will require you to pay with your credit card to use any of the services.\n\nI know that there are still lot of open source pipelines and free tools but the direction for most groups seem to be closed source and pay to use.", "author_fullname": "t2_a0i580op", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering getting closed source?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ryr4w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688620266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got into data engineering since there are a lot of open source tools to play around with.&lt;/p&gt;\n\n&lt;p&gt;Now, recruiters are looking into experience with Databricks instead of Spark.&lt;/p&gt;\n\n&lt;p&gt;Snowflake instead of Postgres and MySQL.&lt;/p&gt;\n\n&lt;p&gt;You also need certifications on AWS, Azure or GCP which despite having free credits, at some point will require you to pay with your credit card to use any of the services.&lt;/p&gt;\n\n&lt;p&gt;I know that there are still lot of open source pipelines and free tools but the direction for most groups seem to be closed source and pay to use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ryr4w", "is_robot_indexable": true, "report_reasons": null, "author": "lezzgooooo", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ryr4w/data_engineering_getting_closed_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ryr4w/data_engineering_getting_closed_source/", "subreddit_subscribers": 114461, "created_utc": 1688620266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n\n\n\n\n\n\n\n\n\n\nHi guys, in my current job I only have the possibility to use excel, but I think of learning sql, python and others as a way to have better jobs. The point is that for that I would need a daily practice, which I could only achieve with personal projects. Do you think this is a valid way to keep the knowledge with me and show that I master the tool? or would a recruiter/employer not care too much about this? Honestly, I'm a little discouraged about learning only through courses and not having the opportunity to put anything into a project, I think that way I would understand better. Anyway, thanks for advice.", "author_fullname": "t2_cne2tl51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think it's valuable to maintain a personal portfolio even though you have a job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sh6f0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688667193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, in my current job I only have the possibility to use excel, but I think of learning sql, python and others as a way to have better jobs. The point is that for that I would need a daily practice, which I could only achieve with personal projects. Do you think this is a valid way to keep the knowledge with me and show that I master the tool? or would a recruiter/employer not care too much about this? Honestly, I&amp;#39;m a little discouraged about learning only through courses and not having the opportunity to put anything into a project, I think that way I would understand better. Anyway, thanks for advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14sh6f0", "is_robot_indexable": true, "report_reasons": null, "author": "gintokiredditbr", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sh6f0/do_you_think_its_valuable_to_maintain_a_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sh6f0/do_you_think_its_valuable_to_maintain_a_personal/", "subreddit_subscribers": 114461, "created_utc": 1688667193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the fundamental differences between Data Warehousing workloads between Databricks and Redshift?\n\nAssuming cost is not a factor, what features are present in one that are not in another?\n\nDatabricks announced Materialized views which is something that Redshift has had for a while.\n\nRedshift has Dynamic Data Masking which I believe Databricks doesn't have the equivalent\n\nBoth seem to have the merge command available.\n\nRedshift can be used natively with Step Functions for orchestration which is somewhat the equivalent of DB workflows\n\nDatabricks has built in quality rules with DLT and I'm not aware of anything similar in Redshift \n\nI get the huge difference in approaches but I'm after more low level features that are available in one and not in the other that make the life of a Data Warehouse engineer easier?\n\nThanks! \n\nNote: this is not a which one is better discussion but more so a healthy comparison between both", "author_fullname": "t2_4luizwuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks vs Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s2msk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688632065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the fundamental differences between Data Warehousing workloads between Databricks and Redshift?&lt;/p&gt;\n\n&lt;p&gt;Assuming cost is not a factor, what features are present in one that are not in another?&lt;/p&gt;\n\n&lt;p&gt;Databricks announced Materialized views which is something that Redshift has had for a while.&lt;/p&gt;\n\n&lt;p&gt;Redshift has Dynamic Data Masking which I believe Databricks doesn&amp;#39;t have the equivalent&lt;/p&gt;\n\n&lt;p&gt;Both seem to have the merge command available.&lt;/p&gt;\n\n&lt;p&gt;Redshift can be used natively with Step Functions for orchestration which is somewhat the equivalent of DB workflows&lt;/p&gt;\n\n&lt;p&gt;Databricks has built in quality rules with DLT and I&amp;#39;m not aware of anything similar in Redshift &lt;/p&gt;\n\n&lt;p&gt;I get the huge difference in approaches but I&amp;#39;m after more low level features that are available in one and not in the other that make the life of a Data Warehouse engineer easier?&lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n\n&lt;p&gt;Note: this is not a which one is better discussion but more so a healthy comparison between both&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14s2msk", "is_robot_indexable": true, "report_reasons": null, "author": "the_travelo_", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s2msk/databricks_vs_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s2msk/databricks_vs_redshift/", "subreddit_subscribers": 114461, "created_utc": 1688632065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I've been an academic bioinformatician for 5 years with only a BS working in different advanced academic roles. I want to leave academia for good and parlay my skills into data engineering. I've noticed that where I've excelled in bioinformatics has been setting up well-documented, reproducible pipelines that preprocess and even sometimes analyze large datasets, and that's the kind of work I enjoy the most; I am best in the role of a technician of sorts. The issue is, I am obviously not immediately suited for this type of work, because while I am skilled in R, Python, HPC environments, and specialized genetic analyses, I have not had to work with SQL pretty much ever and don't have many of the common skills in the average data engineer job listing.\n\nI got into the field I'm in by taking an internship at the university where I was getting a master's degree and then dropping out of my master's degree once I got a firm foot in the door (plus the master's degree felt like a scam). I would like to avoid getting a master's degree because I have a strong feeling that most of them are scams, though that is a filter for many recruiters. Is there like an internship or apprenticeship equivalent for data engineering? I am willing to take a temporary pay cut to work in this field and learn as much as I can. I don't need to be a biotech data engineer but that would help since they would most appreciate my background experience.\n\nAlso I am just looking for any and all advice on how to break in.\n\nThank you!", "author_fullname": "t2_50ogt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bioinformatician of 5 years looking to pivot to data engineering and would like some advice on how to enter the field", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sfwgc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688664408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I&amp;#39;ve been an academic bioinformatician for 5 years with only a BS working in different advanced academic roles. I want to leave academia for good and parlay my skills into data engineering. I&amp;#39;ve noticed that where I&amp;#39;ve excelled in bioinformatics has been setting up well-documented, reproducible pipelines that preprocess and even sometimes analyze large datasets, and that&amp;#39;s the kind of work I enjoy the most; I am best in the role of a technician of sorts. The issue is, I am obviously not immediately suited for this type of work, because while I am skilled in R, Python, HPC environments, and specialized genetic analyses, I have not had to work with SQL pretty much ever and don&amp;#39;t have many of the common skills in the average data engineer job listing.&lt;/p&gt;\n\n&lt;p&gt;I got into the field I&amp;#39;m in by taking an internship at the university where I was getting a master&amp;#39;s degree and then dropping out of my master&amp;#39;s degree once I got a firm foot in the door (plus the master&amp;#39;s degree felt like a scam). I would like to avoid getting a master&amp;#39;s degree because I have a strong feeling that most of them are scams, though that is a filter for many recruiters. Is there like an internship or apprenticeship equivalent for data engineering? I am willing to take a temporary pay cut to work in this field and learn as much as I can. I don&amp;#39;t need to be a biotech data engineer but that would help since they would most appreciate my background experience.&lt;/p&gt;\n\n&lt;p&gt;Also I am just looking for any and all advice on how to break in.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14sfwgc", "is_robot_indexable": true, "report_reasons": null, "author": "buffbuf", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sfwgc/bioinformatician_of_5_years_looking_to_pivot_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sfwgc/bioinformatician_of_5_years_looking_to_pivot_to/", "subreddit_subscribers": 114461, "created_utc": 1688664408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nMy team is in the process of building out an Azure data lake using delta lake tables.  When we started the development, we utilized hive\\_metastore instead of unity catalog; but some unity features are now catching our eye.\n\nThere's some documentation out there regarding the upgrade process, but all of these upgrade scenarios only work on **external** tables managed by hive\\_metastore.  Unfortunately, we are currently using **managed** tables within hive\\_metastore. Documentation/blogs for managed table upgrades seems sparse.\n\n[This MS article](https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/migrate#--upgrade-a-table-to-unity-catalog) talks about the external upgrade process using the wizard, but only briefly talks about the upgrade process for managed tables at the bottom (basically just running CTAS statements).\n\nHas anyone gone through this upgrade process?  Specifically from managed tables to Unity?\n\nThank you very much for any info/stories/lessons learned!\n\n&amp;#x200B;", "author_fullname": "t2_4mzchybu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading from hive_metastore (Managed Tables) to Unity Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rwj7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688614050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;My team is in the process of building out an Azure data lake using delta lake tables.  When we started the development, we utilized hive_metastore instead of unity catalog; but some unity features are now catching our eye.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s some documentation out there regarding the upgrade process, but all of these upgrade scenarios only work on &lt;strong&gt;external&lt;/strong&gt; tables managed by hive_metastore.  Unfortunately, we are currently using &lt;strong&gt;managed&lt;/strong&gt; tables within hive_metastore. Documentation/blogs for managed table upgrades seems sparse.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/migrate#--upgrade-a-table-to-unity-catalog\"&gt;This MS article&lt;/a&gt; talks about the external upgrade process using the wizard, but only briefly talks about the upgrade process for managed tables at the bottom (basically just running CTAS statements).&lt;/p&gt;\n\n&lt;p&gt;Has anyone gone through this upgrade process?  Specifically from managed tables to Unity?&lt;/p&gt;\n\n&lt;p&gt;Thank you very much for any info/stories/lessons learned!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?auto=webp&amp;v=enabled&amp;s=8e9dd29e55be5f9d4be03f8a2ca6dc669418c160", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c681715b246565ff9e7dfd8843f18ead842afeb2", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b70c2ce2562a35082ef9647f1b3db65e880827dd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=448b5cac6633b9e14f4209e70d3996bf0d0f97b6", "width": 320, "height": 320}], "variants": {}, "id": "LVmzWMJU1UZwRubzQYJZSar-z-Rq8ntUH65yhQyfxB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rwj7h", "is_robot_indexable": true, "report_reasons": null, "author": "oneDatumPlease", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rwj7h/upgrading_from_hive_metastore_managed_tables_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rwj7h/upgrading_from_hive_metastore_managed_tables_to/", "subreddit_subscribers": 114461, "created_utc": 1688614050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I recently completed my first end-to-end data engineering project, aimed at strengthening my data engineering skills. The project is not complicated, but since I am used to only analyzing and modeling perfectly curated data (I am a data scientist) without getting involved in pipelines either putting models into production, I think it is a good start. \n\nArchitecture:  \n\n\n[ELT Architecture](https://preview.redd.it/ncxt2ysldeab1.png?width=1280&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4e3b58ec5ff56ef361076bc6eacd534c9570cb80)\n\n The project focuses on processing data from Formula 2 races.  The pipeline consists of several stages, including data retrieval, data cleaning, and storage in an S3 bucket. Additionally, the processed data is formatted to update the existing dataset hosted on Kaggle. The entire process is automated, leveraging the FIA calendar and race\\_id (despite their unorganized nature). Definitely not the best architecture, but the goal was to test multiple AWS services\n\nGitHub Repository: [here](https://github.com/Alarchemn/F2-Data-Pipeline)\n\nKaggle dataset: [here](https://www.kaggle.com/datasets/alarchemn/formula-2-dataset)\n\nI come from academia, PhD in nonlinear control engineering full of hard math. Migrating to real, executable projects is truly exciting.", "author_fullname": "t2_802hx5xi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First End-to-End Data Engineering Project: Formula 2 Data Pipeline for for Automated Updates of a Kaggle's dataset.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ncxt2ysldeab1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de3d106cef3cbe0547dc325434de4b6aecf9dd27"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8485aabb9d90787fbb9a056bf8b5ae91a682a016"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95ced63f842ffc673e62f7cba92c9afb6a1ffa7d"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53ef3a6cb3f0c010fa75193c0dc58253d6fc66ac"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ac73ed9b211962320c8be98f7b2d51de7d73060"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=954209739b130478ae5bab07a05edc0282dc50a2"}], "s": {"y": 720, "x": 1280, "u": "https://preview.redd.it/ncxt2ysldeab1.png?width=1280&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4e3b58ec5ff56ef361076bc6eacd534c9570cb80"}, "id": "ncxt2ysldeab1"}}, "name": "t3_14sjl7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pbIcvlJY4ovNaxfWeb5fOYQMf5R59tkrNu1NqqM-qFg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1688672647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently completed my first end-to-end data engineering project, aimed at strengthening my data engineering skills. The project is not complicated, but since I am used to only analyzing and modeling perfectly curated data (I am a data scientist) without getting involved in pipelines either putting models into production, I think it is a good start. &lt;/p&gt;\n\n&lt;p&gt;Architecture:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ncxt2ysldeab1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4e3b58ec5ff56ef361076bc6eacd534c9570cb80\"&gt;ELT Architecture&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The project focuses on processing data from Formula 2 races.  The pipeline consists of several stages, including data retrieval, data cleaning, and storage in an S3 bucket. Additionally, the processed data is formatted to update the existing dataset hosted on Kaggle. The entire process is automated, leveraging the FIA calendar and race_id (despite their unorganized nature). Definitely not the best architecture, but the goal was to test multiple AWS services&lt;/p&gt;\n\n&lt;p&gt;GitHub Repository: &lt;a href=\"https://github.com/Alarchemn/F2-Data-Pipeline\"&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Kaggle dataset: &lt;a href=\"https://www.kaggle.com/datasets/alarchemn/formula-2-dataset\"&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I come from academia, PhD in nonlinear control engineering full of hard math. Migrating to real, executable projects is truly exciting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?auto=webp&amp;v=enabled&amp;s=81fd7c3b399bc5fdd44656253abb501f7ba4926b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c87307180946a7ba8fdabcde422471d5925dac87", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=166887ea9aad89e6c6e5ed5671bf3bde1c21421a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3ca8834b84e826ffdd7f22246149c8b85d31357", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6435b51aeb9604007509ed31d13a0ed00bac3182", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a39903abb48f42367f59e5ac317d1054318a9cf", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/knvK2hZG5K_ezhV8FowUJK2ErRNE4qemsP8W6lu4xq8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99be992595a6a36fbf73dc3116e410dad6455030", "width": 1080, "height": 540}], "variants": {}, "id": "EQtC0QZfwwOYAdeS6vgMcmirb41drpfQe4xmnXw2TBM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "14sjl7h", "is_robot_indexable": true, "report_reasons": null, "author": "NationOfSheeps", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sjl7h/first_endtoend_data_engineering_project_formula_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sjl7h/first_endtoend_data_engineering_project_formula_2/", "subreddit_subscribers": 114461, "created_utc": 1688672647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone used their orchestration tool to refresh the BI dashboards that are pulling in those tables? This would be for only BI tools that are caching data locally. \n\nThe DAG would be source -&gt; transformations -&gt; ping BI tool API to start refresh. \n\nThis is something I have gone back and forth in my mind on. I have never seen any team put it into production but I could see some benefits. \n\nLet me know your thought!", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Orchestration Tool to refresh BI tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sp81z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688685190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone used their orchestration tool to refresh the BI dashboards that are pulling in those tables? This would be for only BI tools that are caching data locally. &lt;/p&gt;\n\n&lt;p&gt;The DAG would be source -&amp;gt; transformations -&amp;gt; ping BI tool API to start refresh. &lt;/p&gt;\n\n&lt;p&gt;This is something I have gone back and forth in my mind on. I have never seen any team put it into production but I could see some benefits. &lt;/p&gt;\n\n&lt;p&gt;Let me know your thought!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14sp81z", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sp81z/using_orchestration_tool_to_refresh_bi_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sp81z/using_orchestration_tool_to_refresh_bi_tool/", "subreddit_subscribers": 114461, "created_utc": 1688685190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it worth pursuing the Terraform certification in data engineering? My role is DevOps focussed, I really like the IaC component, and enjoy working with Terraform. Is it a step in the wrong direction?", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terraform Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sot3r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688684268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it worth pursuing the Terraform certification in data engineering? My role is DevOps focussed, I really like the IaC component, and enjoy working with Terraform. Is it a step in the wrong direction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14sot3r", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sot3r/terraform_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sot3r/terraform_certification/", "subreddit_subscribers": 114461, "created_utc": 1688684268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nJust started working as a DE at a startup company. I was wondering, how long did it take for you guys get familiar with the data model of the company you're working for? \n\nI'm pretty proficient in SQL and Python, but I feel like I'm unable to help with the more complex tasks because I'm not too familiar with the data model yet. I often use the information_schema tables to find the tables I'm looking for. Should I be able to memorize the tables at some point? \n\nAny tips on how I can speed up the process of getting the know the data structures?", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE new on the job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sf3co", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688662659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;Just started working as a DE at a startup company. I was wondering, how long did it take for you guys get familiar with the data model of the company you&amp;#39;re working for? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty proficient in SQL and Python, but I feel like I&amp;#39;m unable to help with the more complex tasks because I&amp;#39;m not too familiar with the data model yet. I often use the information_schema tables to find the tables I&amp;#39;m looking for. Should I be able to memorize the tables at some point? &lt;/p&gt;\n\n&lt;p&gt;Any tips on how I can speed up the process of getting the know the data structures?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14sf3co", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sf3co/de_new_on_the_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sf3co/de_new_on_the_job/", "subreddit_subscribers": 114461, "created_utc": 1688662659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHello developers,\n\nPLEASE HELP ME OUT AS I AM IN A DILEMMA AND UNABLE TO MAKE A DECISION\n\nBackground: B.Tech CSE, 2 years of experience as Data Engineer in WITCH. Tech stack (AZURE,  \nDATABRICKS, PYSPARK, SQL, PYTHON). I am good at creating batch pipelines and data  \ntransformation. I have also solved 250+ leetcode questions and loves DSA.\n\nI am looking for switch into product based companies, I am unable to decide should I prepare for SDE roles or for Data engineer roles  \nThere is very little information regarding Data engineering job opportunities in youtube and other sites.  \nSomehow i feel like data engineering is 2nd rated compared to SDE roles.  \nThere are so many software developers in FAANG but very very few data engineers, why is that?  \nAll I see data engineering job opportunities in WITCH companies?\n\nShould I study DSA and system design and aim for SDE 2, SDE 1 role or stay in Data engineering lane?  \nAny advice is highly appreciated.\n\nThank you", "author_fullname": "t2_fbzgslhg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer vs Backend developer role ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sdqfc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688659805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello developers,&lt;/p&gt;\n\n&lt;p&gt;PLEASE HELP ME OUT AS I AM IN A DILEMMA AND UNABLE TO MAKE A DECISION&lt;/p&gt;\n\n&lt;p&gt;Background: B.Tech CSE, 2 years of experience as Data Engineer in WITCH. Tech stack (AZURE,&lt;br/&gt;\nDATABRICKS, PYSPARK, SQL, PYTHON). I am good at creating batch pipelines and data&lt;br/&gt;\ntransformation. I have also solved 250+ leetcode questions and loves DSA.&lt;/p&gt;\n\n&lt;p&gt;I am looking for switch into product based companies, I am unable to decide should I prepare for SDE roles or for Data engineer roles&lt;br/&gt;\nThere is very little information regarding Data engineering job opportunities in youtube and other sites.&lt;br/&gt;\nSomehow i feel like data engineering is 2nd rated compared to SDE roles.&lt;br/&gt;\nThere are so many software developers in FAANG but very very few data engineers, why is that?&lt;br/&gt;\nAll I see data engineering job opportunities in WITCH companies?&lt;/p&gt;\n\n&lt;p&gt;Should I study DSA and system design and aim for SDE 2, SDE 1 role or stay in Data engineering lane?&lt;br/&gt;\nAny advice is highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14sdqfc", "is_robot_indexable": true, "report_reasons": null, "author": "R_A_D_E_O_N", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sdqfc/data_engineer_vs_backend_developer_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sdqfc/data_engineer_vs_backend_developer_role/", "subreddit_subscribers": 114461, "created_utc": 1688659805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. We have our data in Bigquery and the data-checks are going to be a core part of our data platform. Moreover, we would need to scale it to hundreds of clients and run daily checks as well as periodic checks. \n\nI investigated for a while and I decided to go with elementary ([https://github.com/elementary-data/elementary/tree/master](https://github.com/elementary-data/elementary/tree/master)), since we use dbt and it has kind of a nice UI. However, we've been running into \"query too complex\" errors in bigquery since a very early stage of our system, so I don't think it will scale very good. We discarded great expectations for the cumbersomeness of it and because we didn't really like it.\n\nNow, we are thinking on implementing our own solution, since we have a more narrow use case than great expectations or elementary could have, so we wouldn't need that much features. However, I am not sure what would be the best tech to use.\n\nSomething like elementary for data in bigquery?  \nPandera using pandas or pyspark dataframes?  \nUse polars and create our own queries?  \nOur own SparkSQL code in a cluster?\n\nI hear you!", "author_fullname": "t2_chl6zxlwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deploy data checks at scale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s8te8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688649077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. We have our data in Bigquery and the data-checks are going to be a core part of our data platform. Moreover, we would need to scale it to hundreds of clients and run daily checks as well as periodic checks. &lt;/p&gt;\n\n&lt;p&gt;I investigated for a while and I decided to go with elementary (&lt;a href=\"https://github.com/elementary-data/elementary/tree/master\"&gt;https://github.com/elementary-data/elementary/tree/master&lt;/a&gt;), since we use dbt and it has kind of a nice UI. However, we&amp;#39;ve been running into &amp;quot;query too complex&amp;quot; errors in bigquery since a very early stage of our system, so I don&amp;#39;t think it will scale very good. We discarded great expectations for the cumbersomeness of it and because we didn&amp;#39;t really like it.&lt;/p&gt;\n\n&lt;p&gt;Now, we are thinking on implementing our own solution, since we have a more narrow use case than great expectations or elementary could have, so we wouldn&amp;#39;t need that much features. However, I am not sure what would be the best tech to use.&lt;/p&gt;\n\n&lt;p&gt;Something like elementary for data in bigquery?&lt;br/&gt;\nPandera using pandas or pyspark dataframes?&lt;br/&gt;\nUse polars and create our own queries?&lt;br/&gt;\nOur own SparkSQL code in a cluster?&lt;/p&gt;\n\n&lt;p&gt;I hear you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?auto=webp&amp;v=enabled&amp;s=634e5ec84f7d8897d421cfdc161efa7805d444b0", "width": 3168, "height": 792}, "resolutions": [{"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=498c2fddb4d2684ba4cc9d399fb431b5dd281658", "width": 108, "height": 27}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e6d15bcfabed1bc27af505ad731f07c0c756c9f", "width": 216, "height": 54}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a8f90762fbf3577e9eb79d3feac89fe33805e29", "width": 320, "height": 80}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c427279e08eedcf270ab4efb0a12718cc9650fbb", "width": 640, "height": 160}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7eef48fd5437b9ba8b7935666c1bf7d5036c4c0d", "width": 960, "height": 240}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bde5bbaa1d8e2fa7da7958ba290616a1d961486d", "width": 1080, "height": 270}], "variants": {}, "id": "rqjJjwLJeYpUH4-kw1hYUZ0GgiauI67rZbnHZR7OTag"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14s8te8", "is_robot_indexable": true, "report_reasons": null, "author": "JLTDE", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s8te8/how_to_deploy_data_checks_at_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s8te8/how_to_deploy_data_checks_at_scale/", "subreddit_subscribers": 114461, "created_utc": 1688649077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company wants me and my friends not to sleep on a regular basis and monitor ETL jobs all the time. Is this normal for companies or I am in a dead-end position?", "author_fullname": "t2_hecq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "7/24 ETL Job Monitoring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sjfg6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688672255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company wants me and my friends not to sleep on a regular basis and monitor ETL jobs all the time. Is this normal for companies or I am in a dead-end position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14sjfg6", "is_robot_indexable": true, "report_reasons": null, "author": "rayman903", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sjfg6/724_etl_job_monitoring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sjfg6/724_etl_job_monitoring/", "subreddit_subscribers": 114461, "created_utc": 1688672255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently undertaking a summer internship at a healthcare analytics company where I've been tasked with expanding our reporting capabilities to include Medicare data. While we're well-versed in Medicaid reporting, this is something new that the company is trying and I have been assigned on this project to figure out if there is a way to create reports using the Medicare data. I'm reaching out to the community for any insights or advice regarding working with Medicare CCLF (Claim and Claim Line Feed) data. I am the only intern as it is a small company and I am working alone on this project!\n\nI am struggling in identifying the attribution field within the data. Since we provide separate reports to each clinic, it's crucial  to differentiate the data based on clinics. Unfortunately, I haven't been able to locate this field in the Claims files yet. However, I have figured out how to calculate Part A and Part B claims from the data.\n\nCurrently, I'm planning to initiate the ETL (Extract, Transform, Load) process by loading the fixed width files into SQL Server. My approach involves creating tables and utilizing Bulk Insert. I would appreciate any feedback or suggestions if anyone has experience working with Medicare data or any recommendations on how to proceed.\n\nThank you in advance for your help and valuable insights!", "author_fullname": "t2_67a2wkjc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with Medicare CCLF Data - Seeking Insights and Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sh2zb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688666976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently undertaking a summer internship at a healthcare analytics company where I&amp;#39;ve been tasked with expanding our reporting capabilities to include Medicare data. While we&amp;#39;re well-versed in Medicaid reporting, this is something new that the company is trying and I have been assigned on this project to figure out if there is a way to create reports using the Medicare data. I&amp;#39;m reaching out to the community for any insights or advice regarding working with Medicare CCLF (Claim and Claim Line Feed) data. I am the only intern as it is a small company and I am working alone on this project!&lt;/p&gt;\n\n&lt;p&gt;I am struggling in identifying the attribution field within the data. Since we provide separate reports to each clinic, it&amp;#39;s crucial  to differentiate the data based on clinics. Unfortunately, I haven&amp;#39;t been able to locate this field in the Claims files yet. However, I have figured out how to calculate Part A and Part B claims from the data.&lt;/p&gt;\n\n&lt;p&gt;Currently, I&amp;#39;m planning to initiate the ETL (Extract, Transform, Load) process by loading the fixed width files into SQL Server. My approach involves creating tables and utilizing Bulk Insert. I would appreciate any feedback or suggestions if anyone has experience working with Medicare data or any recommendations on how to proceed.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help and valuable insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14sh2zb", "is_robot_indexable": true, "report_reasons": null, "author": "Uchiha_pandu", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sh2zb/working_with_medicare_cclf_data_seeking_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sh2zb/working_with_medicare_cclf_data_seeking_insights/", "subreddit_subscribers": 114461, "created_utc": 1688666976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm keen to canvas wider opinion so any input is appreciated. \n\nI have a data factory that accepts 5 parameters and then generates Excel extracts. What would you view as the best option to make input of these parameters and self-service execution of the pipeline available to end-users of the extracts? \n\nThanks in advance.", "author_fullname": "t2_lmanh1xe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Front-End for Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sgjs7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688665828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m keen to canvas wider opinion so any input is appreciated. &lt;/p&gt;\n\n&lt;p&gt;I have a data factory that accepts 5 parameters and then generates Excel extracts. What would you view as the best option to make input of these parameters and self-service execution of the pipeline available to end-users of the extracts? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14sgjs7", "is_robot_indexable": true, "report_reasons": null, "author": "TheFirstGlassPilot", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14sgjs7/frontend_for_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14sgjs7/frontend_for_azure_data_factory/", "subreddit_subscribers": 114461, "created_utc": 1688665828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "*Disclaimer: I'm now asking for a project on BigQuery, so specific answers for BigQuery will help a lot in the short run. But, I would love to understand it better conceptually, so I'll be able to apply it to other systems as well.*   \n\n\nUsually, when optimizing a \"big data\" table we would partition and/or cluster it.   \nBoth allow one-to-many hierarchically \"indexing\" more than one field.   \nThe classic partition example would be time:  \n```\nyear/month/day/hour  \n``` \nSame for clustering, if we cluster by `col_a` and then by `col_b`, it means a one-to-many between `col_a` to `col_b`, for example:  \n```\n  col_a   col_b  \n ------- ------- \n  a1      b1     \n  a1      b2     \n  a2      b3     \n  a2      b4     \n\n```\n  \nHow about a case where we have?\n\n```\n  col_a   col_b  \n ------- ------- \n  a1      b1     \n  a1      b2     \n  a2      b1     \n  a2      b2     \n```\n\nIn this case, the relationship is many to many, and common query pattern predicates would use `col_a`, `col_b`, or both.  \n\n\nHow would we optimize such a table to reduce data scans?  \n\n\nThank you. :)", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to optimize data modeling to reduce data scan for many-to-many \"partition/clustering\" fields?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s6clc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688643509.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688642869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Disclaimer: I&amp;#39;m now asking for a project on BigQuery, so specific answers for BigQuery will help a lot in the short run. But, I would love to understand it better conceptually, so I&amp;#39;ll be able to apply it to other systems as well.&lt;/em&gt;   &lt;/p&gt;\n\n&lt;p&gt;Usually, when optimizing a &amp;quot;big data&amp;quot; table we would partition and/or cluster it.&lt;br/&gt;\nBoth allow one-to-many hierarchically &amp;quot;indexing&amp;quot; more than one field.&lt;br/&gt;\nThe classic partition example would be time:&lt;br/&gt;\n&lt;code&gt;\nyear/month/day/hour  \n&lt;/code&gt; \nSame for clustering, if we cluster by &lt;code&gt;col_a&lt;/code&gt; and then by &lt;code&gt;col_b&lt;/code&gt;, it means a one-to-many between &lt;code&gt;col_a&lt;/code&gt; to &lt;code&gt;col_b&lt;/code&gt;, for example:&lt;br/&gt;\n```\n  col_a   col_b  &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;a1      b1&lt;br/&gt;\n  a1      b2&lt;br/&gt;\n  a2      b3&lt;br/&gt;\n  a2      b4     &lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;How about a case where we have?&lt;/p&gt;\n\n&lt;p&gt;```\n  col_a   col_b  &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;a1      b1&lt;br/&gt;\n  a1      b2&lt;br/&gt;\n  a2      b1&lt;br/&gt;\n  a2      b2&lt;br/&gt;\n```&lt;/p&gt;\n\n&lt;p&gt;In this case, the relationship is many to many, and common query pattern predicates would use &lt;code&gt;col_a&lt;/code&gt;, &lt;code&gt;col_b&lt;/code&gt;, or both.  &lt;/p&gt;\n\n&lt;p&gt;How would we optimize such a table to reduce data scans?  &lt;/p&gt;\n\n&lt;p&gt;Thank you. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14s6clc", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s6clc/how_to_optimize_data_modeling_to_reduce_data_scan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s6clc/how_to_optimize_data_modeling_to_reduce_data_scan/", "subreddit_subscribers": 114461, "created_utc": 1688642869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am exploring azure Devops for ARM deployment as part of infrastructure provisioning.\nWhat is the need for a CI build. Why can't I directly release the code changes?", "author_fullname": "t2_3vjykfp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the need of CI build?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s3b1w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688634119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am exploring azure Devops for ARM deployment as part of infrastructure provisioning.\nWhat is the need for a CI build. Why can&amp;#39;t I directly release the code changes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14s3b1w", "is_robot_indexable": true, "report_reasons": null, "author": "akhilseban", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s3b1w/what_is_the_need_of_ci_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s3b1w/what_is_the_need_of_ci_build/", "subreddit_subscribers": 114461, "created_utc": 1688634119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, need help with this problem. This is already a functioning code, however, it replaces all the active\\_count it has inputted to null whenever there's a new active\\_count to input. \n\nI think the problem is in my case method, is there any way I could ignore active\\_count whenever generated\\_date is not equal to current date?\n\n&amp;#x200B;\n\n    with \n    cte_date_generator as (\n    \n        select -1 + row_number() over(order by 0) index, start_date + index generated_date \n        from (select '2023-07-01'::date start_date, current_date()::date end_date)\n        join table(generator(rowcount =&gt; 20000 )) x\n        qualify index &lt; 1 + end_date - start_date\n        order by generated_date desc\n    \n    )\n    \n    select \n        generated_date,\n        case \n        when generated_date = CAST(current_timestamp as date) \n            then (select count(*) from my_table) \n            end as active_count\n    from cte_date_generator \n\n&amp;#x200B;", "author_fullname": "t2_cokcobrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in DBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ryzco", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688620929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, need help with this problem. This is already a functioning code, however, it replaces all the active_count it has inputted to null whenever there&amp;#39;s a new active_count to input. &lt;/p&gt;\n\n&lt;p&gt;I think the problem is in my case method, is there any way I could ignore active_count whenever generated_date is not equal to current date?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with \ncte_date_generator as (\n\n    select -1 + row_number() over(order by 0) index, start_date + index generated_date \n    from (select &amp;#39;2023-07-01&amp;#39;::date start_date, current_date()::date end_date)\n    join table(generator(rowcount =&amp;gt; 20000 )) x\n    qualify index &amp;lt; 1 + end_date - start_date\n    order by generated_date desc\n\n)\n\nselect \n    generated_date,\n    case \n    when generated_date = CAST(current_timestamp as date) \n        then (select count(*) from my_table) \n        end as active_count\nfrom cte_date_generator \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ryzco", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious_Goose_659", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ryzco/need_help_in_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ryzco/need_help_in_dbt/", "subreddit_subscribers": 114461, "created_utc": 1688620929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a csv file sitting in S3 and what I need to do is migrate this into some actual database and not just a csv file in S3... How do I do this portion? So some feedback I've heard so far is (since the file is small, only around 800 - 900 records of data to start with) use Lambda to write it row by row into a database of my choice in AWS RDS (for example I could use postgres). \n\nHow do I access this data in the database from an app I'd want to build (like how do I perform search with a specific NLP algorithm over the database)? What if my user wants to perform a search using some query and I want to use some NLP algorithm that I develop to match the query with the closest record or top 5 records in the database. I'll be writing the NLP algorithm / possible search code in Python but the front-end may be built with something else, is that an issue? \n\nIs there anyone that's well versed with this type of stuff and doesn't mind if I chatted with them regarding all this? That would help a ton!", "author_fullname": "t2_5692by6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to figure out best way to do this", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rwet1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688613702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a csv file sitting in S3 and what I need to do is migrate this into some actual database and not just a csv file in S3... How do I do this portion? So some feedback I&amp;#39;ve heard so far is (since the file is small, only around 800 - 900 records of data to start with) use Lambda to write it row by row into a database of my choice in AWS RDS (for example I could use postgres). &lt;/p&gt;\n\n&lt;p&gt;How do I access this data in the database from an app I&amp;#39;d want to build (like how do I perform search with a specific NLP algorithm over the database)? What if my user wants to perform a search using some query and I want to use some NLP algorithm that I develop to match the query with the closest record or top 5 records in the database. I&amp;#39;ll be writing the NLP algorithm / possible search code in Python but the front-end may be built with something else, is that an issue? &lt;/p&gt;\n\n&lt;p&gt;Is there anyone that&amp;#39;s well versed with this type of stuff and doesn&amp;#39;t mind if I chatted with them regarding all this? That would help a ton!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rwet1", "is_robot_indexable": true, "report_reasons": null, "author": "anasp1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rwet1/struggling_to_figure_out_best_way_to_do_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rwet1/struggling_to_figure_out_best_way_to_do_this/", "subreddit_subscribers": 114461, "created_utc": 1688613702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://dataengineeracademy.com/blog/how-to-create-a-sql-query-using-ai-in-less-time/](https://dataengineeracademy.com/blog/how-to-create-a-sql-query-using-ai-in-less-time/)", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Create a SQL Query Using AI in Less Time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14spz88", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688687014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://dataengineeracademy.com/blog/how-to-create-a-sql-query-using-ai-in-less-time/\"&gt;https://dataengineeracademy.com/blog/how-to-create-a-sql-query-using-ai-in-less-time/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nb21ftOLlqY-GNPNrJXgATv-N3PE7G96rNZrbfOgVIk.jpg?auto=webp&amp;v=enabled&amp;s=3155a82174536c2718820bef79714a2d031e5fae", "width": 436, "height": 312}, "resolutions": [{"url": "https://external-preview.redd.it/nb21ftOLlqY-GNPNrJXgATv-N3PE7G96rNZrbfOgVIk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c461f03352174bffefb85de7cf03285dd06a62ea", "width": 108, "height": 77}, {"url": "https://external-preview.redd.it/nb21ftOLlqY-GNPNrJXgATv-N3PE7G96rNZrbfOgVIk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2081bb9bc39b1165c8e2f32250776056caaee912", "width": 216, "height": 154}, {"url": "https://external-preview.redd.it/nb21ftOLlqY-GNPNrJXgATv-N3PE7G96rNZrbfOgVIk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2796cd48b77d5939ce5c4a6c3c101059cf7d004", "width": 320, "height": 228}], "variants": {}, "id": "byNz0In4M6d6GEwuq8yJygsuTdhPADiRuAMzTH4AU0s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "CEO of DE Academy/Amazon/Lyft/Author", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14spz88", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14spz88/how_to_create_a_sql_query_using_ai_in_less_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14spz88/how_to_create_a_sql_query_using_ai_in_less_time/", "subreddit_subscribers": 114461, "created_utc": 1688687014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\ud83d\udce3Wait, what? Apache Iceberg won the table format war, apparently \ud83d\ude04  \n\n\n**\ud83d\udc49\ud83c\udffb** [**Iceberg won the table format war (But not in the way you thought it might)**](https://bitsondatadev.substack.com/p/iceberg-won-the-table-format-war)  \n\n\n\ud83d\ude44 You might roll your eyes given that the author (Brian \u041elsen) works for Tabular but IMHO it's a pretty even assessment of the current situation \u2705  \n\n\nI like Brian's optimism about the power of open standards to force the hand of vendors to do the right thing for users. I don't know if it will play out that way\u2014and there are definitely some of the big vendors playing the \"open-source washing\" game \u2744\ufe0f  \n\n\nBut given three formats of approx the same capabilities, adopting based on the strength of its true openness seems like as good a basis as any other.  \n\n\n**What do folk here think?** \n\n\\- Will one of the formats \"win\" and others \"lose\"?  \n\\- Will we just end up with a generic layer atop the others (UniForm etc) with a slight friction to bias the user to select the default (i.e. in the case of UniForm, Delta)?  \n\n\n**obXKCD**\n\n&amp;#x200B;\n\nhttps://preview.redd.it/8ryczu4b8bab1.png?width=500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a702cc3782892725beb239d887734cbc2facd5cd", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udce3 Apache Iceberg has won the table format war", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8ryczu4b8bab1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 61, "x": 108, "u": "https://preview.redd.it/8ryczu4b8bab1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=682117c15861ba2dd21800d35b81e8e405da1149"}, {"y": 122, "x": 216, "u": "https://preview.redd.it/8ryczu4b8bab1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4d40ee537ada274ebec03a8624090706257ed6b"}, {"y": 181, "x": 320, "u": "https://preview.redd.it/8ryczu4b8bab1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc7e1dfcaebcc5fc15bdfc3064290f7b5cc9dda3"}], "s": {"y": 283, "x": 500, "u": "https://preview.redd.it/8ryczu4b8bab1.png?width=500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a702cc3782892725beb239d887734cbc2facd5cd"}, "id": "8ryczu4b8bab1"}}, "name": "t3_14s3c1s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4jrqSC0B7QWKsvGwtEgeo9APdmTL1ETSMXCeavTIkbM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688634196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\udce3Wait, what? Apache Iceberg won the table format war, apparently \ud83d\ude04  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udc49\ud83c\udffb&lt;/strong&gt; &lt;a href=\"https://bitsondatadev.substack.com/p/iceberg-won-the-table-format-war\"&gt;&lt;strong&gt;Iceberg won the table format war (But not in the way you thought it might)&lt;/strong&gt;&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;\ud83d\ude44 You might roll your eyes given that the author (Brian \u041elsen) works for Tabular but IMHO it&amp;#39;s a pretty even assessment of the current situation \u2705  &lt;/p&gt;\n\n&lt;p&gt;I like Brian&amp;#39;s optimism about the power of open standards to force the hand of vendors to do the right thing for users. I don&amp;#39;t know if it will play out that way\u2014and there are definitely some of the big vendors playing the &amp;quot;open-source washing&amp;quot; game \u2744\ufe0f  &lt;/p&gt;\n\n&lt;p&gt;But given three formats of approx the same capabilities, adopting based on the strength of its true openness seems like as good a basis as any other.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What do folk here think?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;- Will one of the formats &amp;quot;win&amp;quot; and others &amp;quot;lose&amp;quot;?&lt;br/&gt;\n- Will we just end up with a generic layer atop the others (UniForm etc) with a slight friction to bias the user to select the default (i.e. in the case of UniForm, Delta)?  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;obXKCD&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8ryczu4b8bab1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a702cc3782892725beb239d887734cbc2facd5cd\"&gt;https://preview.redd.it/8ryczu4b8bab1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a702cc3782892725beb239d887734cbc2facd5cd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14s3c1s", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s3c1s/apache_iceberg_has_won_the_table_format_war/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s3c1s/apache_iceberg_has_won_the_table_format_war/", "subreddit_subscribers": 114461, "created_utc": 1688634196.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}