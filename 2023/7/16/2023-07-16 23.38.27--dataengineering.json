{"kind": "Listing", "data": {"after": null, "dist": 15, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vnan4h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this fear-mongering, or is this actually truthful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_150qcx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 222, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 222, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/o2JMp8tfb-do6aAWGCPMnW7oj8KPB6DkubFKUUiQTy0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689463491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/poz94nkcq7cb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/poz94nkcq7cb1.png?auto=webp&amp;s=81dbb2eb92ccbdcb64d8b712e169c18ea40a2b4b", "width": 720, "height": 1379}, "resolutions": [{"url": "https://preview.redd.it/poz94nkcq7cb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=15d543fef641980dfc8e8fef5804e1a626ab06b9", "width": 108, "height": 206}, {"url": "https://preview.redd.it/poz94nkcq7cb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e4a37d2427db1d2e091b0bacbd1c9e690a46850", "width": 216, "height": 413}, {"url": "https://preview.redd.it/poz94nkcq7cb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef166217248c2cd05e3d38ccc39e76c888cc0826", "width": 320, "height": 612}, {"url": "https://preview.redd.it/poz94nkcq7cb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a4489e639555acfdc83d3894b7a71da0c1448838", "width": 640, "height": 1225}], "variants": {}, "id": "QY8zPFNWPPZmEjKy9OcLaxUWN6wZODGHsYliCVXC7v0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150qcx2", "is_robot_indexable": true, "report_reasons": null, "author": "Analyst2163", "discussion_type": null, "num_comments": 115, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150qcx2/is_this_fearmongering_or_is_this_actually_truthful/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/poz94nkcq7cb1.png", "subreddit_subscribers": 116189, "created_utc": 1689463491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Current software engineering education in colleges still targets building up OLTP systems.As a graduate you may know ACID, OS details, remote RPC really well, but after working 10 years, there is still a chance that you don't know what \"tumbling window\" is.\n\nWhy not just learn data engineering in your own time, you may ask.  The problem is they are \"unknown unknowns\".  You don't know you need to think of solutions from data engineer point of view.\n\nMost software engineers only know that DE is just used for data science, is about building data pipelines for them. They don't know that DE patterns can actually help in SE domain.\n\nOne example is a project I took part in. We were supposed to build a real time trading risk monitoring system. Nobody was aware of Kafka Streams so we just handled the incoming data using plain Java code, stored the time window in a nosql db and used a single processing application, no cluster. \n\nIronically the DE team was part of the project. And we just treated them as a downstream and sent some audit information to generate reports.\n\nThat's typical in the industry. There is a big gap between SE and DE.  Why? Because lots of people are not trained in school for the DE solutions and not lucky enough to meet colleagues who are aware of this.", "author_fullname": "t2_10j5re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "There should be data engineering courses in colleges", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150yzmo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689489867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Current software engineering education in colleges still targets building up OLTP systems.As a graduate you may know ACID, OS details, remote RPC really well, but after working 10 years, there is still a chance that you don&amp;#39;t know what &amp;quot;tumbling window&amp;quot; is.&lt;/p&gt;\n\n&lt;p&gt;Why not just learn data engineering in your own time, you may ask.  The problem is they are &amp;quot;unknown unknowns&amp;quot;.  You don&amp;#39;t know you need to think of solutions from data engineer point of view.&lt;/p&gt;\n\n&lt;p&gt;Most software engineers only know that DE is just used for data science, is about building data pipelines for them. They don&amp;#39;t know that DE patterns can actually help in SE domain.&lt;/p&gt;\n\n&lt;p&gt;One example is a project I took part in. We were supposed to build a real time trading risk monitoring system. Nobody was aware of Kafka Streams so we just handled the incoming data using plain Java code, stored the time window in a nosql db and used a single processing application, no cluster. &lt;/p&gt;\n\n&lt;p&gt;Ironically the DE team was part of the project. And we just treated them as a downstream and sent some audit information to generate reports.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s typical in the industry. There is a big gap between SE and DE.  Why? Because lots of people are not trained in school for the DE solutions and not lucky enough to meet colleagues who are aware of this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150yzmo", "is_robot_indexable": true, "report_reasons": null, "author": "shaunyip", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150yzmo/there_should_be_data_engineering_courses_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150yzmo/there_should_be_data_engineering_courses_in/", "subreddit_subscribers": 116189, "created_utc": 1689489867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Coming from a finance background, I've always been interested in trading &amp; investing.  \nAs I transition into tech and data for my career, I wanted to create my very first DE project that combines these two interests of mine:  \n[https://github.com/hieuimba/stock-mkt-dashboard](https://github.com/hieuimba/stock-mkt-dashboard)  \n\n\nI'm proud of how it turned out and I would appreciate any feedback &amp; improvement ideas!  \nAlso, where do I go from here? I want to get my hands on larger datasets and work with more complex tools so how do I expand given my existing stack?", "author_fullname": "t2_svuc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a Stock Market Dashboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151edrn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689534039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Coming from a finance background, I&amp;#39;ve always been interested in trading &amp;amp; investing.&lt;br/&gt;\nAs I transition into tech and data for my career, I wanted to create my very first DE project that combines these two interests of mine:&lt;br/&gt;\n&lt;a href=\"https://github.com/hieuimba/stock-mkt-dashboard\"&gt;https://github.com/hieuimba/stock-mkt-dashboard&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m proud of how it turned out and I would appreciate any feedback &amp;amp; improvement ideas!&lt;br/&gt;\nAlso, where do I go from here? I want to get my hands on larger datasets and work with more complex tools so how do I expand given my existing stack?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?auto=webp&amp;s=32d077e612ecefd6faf10ea49e75e492c18e98d3", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf0640c9569bf292fd17f900ed87e5d01247c770", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4a5d75a477e23e1b71325c421978eed5394fc27", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c389594e29d6c8fbd46f916fb1406e207eb4d0f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cdc6b7a89dffc2df7f29e24167a2ce3e270c582d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f8e36aad8ae5756beed212dcaf5a0d7e7a898ac4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/2T8IT5s2RhpX3XkZxHIpnvyJb2_lbdcCkSniZXrNR4g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=29e5dbcd99562da33a9329007bf0412eeb2f40d5", "width": 1080, "height": 540}], "variants": {}, "id": "YdPea6g25mPIeHgw4yscB9-r1lXHQs-QhNTU3xR-x-U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "151edrn", "is_robot_indexable": true, "report_reasons": null, "author": "hieuimba", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151edrn/i_made_a_stock_market_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151edrn/i_made_a_stock_market_dashboard/", "subreddit_subscribers": 116189, "created_utc": 1689534039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Parquet is nice, but it does a bad job at compressing columns of numerical data. It's a real shame, since exabytes of data are written in Parquet and similar formats. I made a codec (https://github.com/mwlon/pcodec) that can be wrapped in as an \"encoder\" for better compression ratio at no cost to compression/decompression speed on average (compared to .zstd.parquet).\n\nI'm planning to test out a forked parquet using pcodec. Let me know if you're interested in collaborating.", "author_fullname": "t2_8cr1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone want to partake in making a cracked Parquet PoC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1518w59", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1689520768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Parquet is nice, but it does a bad job at compressing columns of numerical data. It&amp;#39;s a real shame, since exabytes of data are written in Parquet and similar formats. I made a codec (&lt;a href=\"https://github.com/mwlon/pcodec\"&gt;https://github.com/mwlon/pcodec&lt;/a&gt;) that can be wrapped in as an &amp;quot;encoder&amp;quot; for better compression ratio at no cost to compression/decompression speed on average (compared to .zstd.parquet).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to test out a forked parquet using pcodec. Let me know if you&amp;#39;re interested in collaborating.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?auto=webp&amp;s=f4c89ce9020fabae5f3ac29418814bbd2f43707d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce66a1c7eb60b7356b7dd936aab79c12038ea2a5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a80230e483befadad4615e656f64d81fe2b7b5b4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31f65fb7f25f8a78b0831efa2326fbaa38721716", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=29d5192a1e1140906d55278403b0dcc460437819", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a62f960c516ced9fcbefeabcea340137cb006c6", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/M5ni8xNvUsnzYf5s_j2hPPhWxMde13ncI8Rb39ltw7M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ba13edf9bbe1c1095e31bfbd7c24c2444b977cb5", "width": 1080, "height": 540}], "variants": {}, "id": "-gqh9jkdtisE1lLOccWycdvX2Md7OQ7SBxrc6mgpImQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1518w59", "is_robot_indexable": true, "report_reasons": null, "author": "mwlon", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1518w59/anyone_want_to_partake_in_making_a_cracked/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1518w59/anyone_want_to_partake_in_making_a_cracked/", "subreddit_subscribers": 116189, "created_utc": 1689520768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am joining a company that uses Snowflake. My past experiences have been with Teradata and Redshift. Any advice on the best way to model the data for performance and cost savings? It will be used for self service reporting with BI tools. Star schema or wide table? Any indexes or partition strategy?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150x8zd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689484069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am joining a company that uses Snowflake. My past experiences have been with Teradata and Redshift. Any advice on the best way to model the data for performance and cost savings? It will be used for self service reporting with BI tools. Star schema or wide table? Any indexes or partition strategy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "150x8zd", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150x8zd/data_modeling_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150x8zd/data_modeling_snowflake/", "subreddit_subscribers": 116189, "created_utc": 1689484069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everybody,\n\nI\u2019m making a POC  using Airbyte as a spun a VM in GCP.\n\nI noticed a lot of connectors were alpha or beta. How robust is the tool? Has anyone been using it in a Fortune 500 company?", "author_fullname": "t2_851if4wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte in Production - Robust?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1510pua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689495814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m making a POC  using Airbyte as a spun a VM in GCP.&lt;/p&gt;\n\n&lt;p&gt;I noticed a lot of connectors were alpha or beta. How robust is the tool? Has anyone been using it in a Fortune 500 company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1510pua", "is_robot_indexable": true, "report_reasons": null, "author": "No-Dress-3160", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1510pua/airbyte_in_production_robust/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1510pua/airbyte_in_production_robust/", "subreddit_subscribers": 116189, "created_utc": 1689495814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nWorking on my first data warehouse project and learning online on the way using tutorials, articles, youtube videos etc.\n\nI'm using data meant to mimic an OLTP database for a dvd rental company, and I'm at the stage of implementing my dimension and fact tables.\n\nThe fact table I'm currently building out is an inventory table - I want it to be a snapshot every month of a dvd's stock, including how many dvd were lost that month,  and some other aggregates.\n\nOne thing I can't wrap my head around though is how to implement a date dimension - currently none of my other attributes capture a timestamp that can facilitate this.\n\nand tutorials online don't really go into the details of how to build a snapshot fact table so that i can define the grain as 'week', 'month' etc.\n\nI don't understand how my fact table can make a reference to a date dimension if my other dimensions don't contain a date attribute?\n\nI'm attaching a photo of my model below in case it helps paint a better picture.\n\nhttps://preview.redd.it/f957h9t15ecb1.png?width=1376&amp;format=png&amp;auto=webp&amp;s=17ffdf934ba9650196211d46ee299cf8ac86d18b", "author_fullname": "t2_96memylv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing date dimensions in DW?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"f957h9t15ecb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f653e959cba54e99034391e2444e5caab395a4cf"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3e263c73d2f0610e787959c47eab940664d0e63"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=51f9057f8f4fcee89d3d165dca32bc6c5f5d3d85"}, {"y": 357, "x": 640, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d952cbd2c1e560a63910b0a2adab488e1737369"}, {"y": 536, "x": 960, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=16528a31ec7ffaea7819e1ec9d69fba7dd8cc6f8"}, {"y": 603, "x": 1080, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0b0d59a181be5a125704636c5ec03f0e279cd858"}], "s": {"y": 769, "x": 1376, "u": "https://preview.redd.it/f957h9t15ecb1.png?width=1376&amp;format=png&amp;auto=webp&amp;s=17ffdf934ba9650196211d46ee299cf8ac86d18b"}, "id": "f957h9t15ecb1"}}, "name": "t3_151he4d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/QdvyJoHkIcWkwy3lTWvsN9hZspFQJsSMiBH3tcpdrU8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689541032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Working on my first data warehouse project and learning online on the way using tutorials, articles, youtube videos etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using data meant to mimic an OLTP database for a dvd rental company, and I&amp;#39;m at the stage of implementing my dimension and fact tables.&lt;/p&gt;\n\n&lt;p&gt;The fact table I&amp;#39;m currently building out is an inventory table - I want it to be a snapshot every month of a dvd&amp;#39;s stock, including how many dvd were lost that month,  and some other aggregates.&lt;/p&gt;\n\n&lt;p&gt;One thing I can&amp;#39;t wrap my head around though is how to implement a date dimension - currently none of my other attributes capture a timestamp that can facilitate this.&lt;/p&gt;\n\n&lt;p&gt;and tutorials online don&amp;#39;t really go into the details of how to build a snapshot fact table so that i can define the grain as &amp;#39;week&amp;#39;, &amp;#39;month&amp;#39; etc.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t understand how my fact table can make a reference to a date dimension if my other dimensions don&amp;#39;t contain a date attribute?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m attaching a photo of my model below in case it helps paint a better picture.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/f957h9t15ecb1.png?width=1376&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17ffdf934ba9650196211d46ee299cf8ac86d18b\"&gt;https://preview.redd.it/f957h9t15ecb1.png?width=1376&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17ffdf934ba9650196211d46ee299cf8ac86d18b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151he4d", "is_robot_indexable": true, "report_reasons": null, "author": "jazzopardi203", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151he4d/implementing_date_dimensions_in_dw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151he4d/implementing_date_dimensions_in_dw/", "subreddit_subscribers": 116189, "created_utc": 1689541032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, friends on reddit!\n\nI would like to share with you a demo using VulcanSQL + LangChain + Cohere + Streamlit to demonstrate how VulcanSQL can easily create &amp; share secure data APIs.\n\nVulcanSQL has built-in data privacy mechanisms such as dynamic data masking, row/column level security, etc., to ensure your sensitive data stays where it belongs to you.\n\nVulcanSQL: [https://vulcansql.com/](https://vulcansql.com/)  \nVulcanSQL data privacy docs: [https://vulcansql.com/docs/data-privacy/overview](https://vulcansql.com/docs/data-privacy/overview)  \nDemo: [https://yelp-dataset-demo.fly.dev/](https://yelp-dataset-demo.fly.dev/)  \nSource code: [https://github.com/Canner/vulcan-sql-examples/tree/main/yelp-dataset-api](https://github.com/Canner/vulcan-sql-examples/tree/main/yelp-dataset-api)\n\nThe attached image is the application flow diagram of the demo  \n\n\nhttps://preview.redd.it/z8zgv1edu9cb1.jpg?width=1460&amp;format=pjpg&amp;auto=webp&amp;s=5c74cfbff7f2c100d3c017fe4e670ff64aa7fed5", "author_fullname": "t2_1vdngj8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No more data breaches with VulcanSQL!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"z8zgv1edu9cb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 73, "x": 108, "u": "https://preview.redd.it/z8zgv1edu9cb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b84bcf97463de4cdbd6b81c21a4116803bd8646a"}, {"y": 146, "x": 216, "u": "https://preview.redd.it/z8zgv1edu9cb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f83a5680e53b84ce7e07f9c382372b7eba7b2c8d"}, {"y": 216, "x": 320, "u": "https://preview.redd.it/z8zgv1edu9cb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d4c5f3257c96a0094ecbbae54b414781f99e03b"}, {"y": 432, "x": 640, "u": "https://preview.redd.it/z8zgv1edu9cb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c70cca348d2dd0177a1117e09eec131f001ded9a"}, {"y": 648, "x": 960, "u": "https://preview.redd.it/z8zgv1edu9cb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a0077ca3c475a759d5c51457e202ab74a228fb82"}, {"y": 730, "x": 1080, "u": "https://preview.redd.it/z8zgv1edu9cb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a0e585da2ae48b54d5edcb965105def79c54d0a2"}], "s": {"y": 987, "x": 1460, "u": "https://preview.redd.it/z8zgv1edu9cb1.jpg?width=1460&amp;format=pjpg&amp;auto=webp&amp;s=5c74cfbff7f2c100d3c017fe4e670ff64aa7fed5"}, "id": "z8zgv1edu9cb1"}}, "name": "t3_150yt6l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vEyy2SVwfs-aj-up3xIx17_x8r3H3b2QXFF2U3-mdrw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1689489251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, friends on reddit!&lt;/p&gt;\n\n&lt;p&gt;I would like to share with you a demo using VulcanSQL + LangChain + Cohere + Streamlit to demonstrate how VulcanSQL can easily create &amp;amp; share secure data APIs.&lt;/p&gt;\n\n&lt;p&gt;VulcanSQL has built-in data privacy mechanisms such as dynamic data masking, row/column level security, etc., to ensure your sensitive data stays where it belongs to you.&lt;/p&gt;\n\n&lt;p&gt;VulcanSQL: &lt;a href=\"https://vulcansql.com/\"&gt;https://vulcansql.com/&lt;/a&gt;&lt;br/&gt;\nVulcanSQL data privacy docs: &lt;a href=\"https://vulcansql.com/docs/data-privacy/overview\"&gt;https://vulcansql.com/docs/data-privacy/overview&lt;/a&gt;&lt;br/&gt;\nDemo: &lt;a href=\"https://yelp-dataset-demo.fly.dev/\"&gt;https://yelp-dataset-demo.fly.dev/&lt;/a&gt;&lt;br/&gt;\nSource code: &lt;a href=\"https://github.com/Canner/vulcan-sql-examples/tree/main/yelp-dataset-api\"&gt;https://github.com/Canner/vulcan-sql-examples/tree/main/yelp-dataset-api&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The attached image is the application flow diagram of the demo  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z8zgv1edu9cb1.jpg?width=1460&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5c74cfbff7f2c100d3c017fe4e670ff64aa7fed5\"&gt;https://preview.redd.it/z8zgv1edu9cb1.jpg?width=1460&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5c74cfbff7f2c100d3c017fe4e670ff64aa7fed5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?auto=webp&amp;s=c5ae3b01714b4756198d147169f6c8697ddcbb9e", "width": 1896, "height": 972}, "resolutions": [{"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=55c1de601780b438677efcd067f71c1e62ce52a5", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4419cf8f7396db722ee46238621a2fa80878835c", "width": 216, "height": 110}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6fbccae81fac4da1a0dfa8c942dd814d20dc5a8a", "width": 320, "height": 164}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8eb736e41275ffd79b186f321e0cc298e2971dd0", "width": 640, "height": 328}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1c8bf75b3d813b7024b0f18a5e03670f45df6243", "width": 960, "height": 492}, {"url": "https://external-preview.redd.it/SIC644ezFhjgQy6PZYav9Ap09e9LcgKvFyVf2lgDVj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6903316292587fdbf31a8af42c50c73c0cec8e0a", "width": 1080, "height": 553}], "variants": {}, "id": "7_XxcEdZcvt6ayYQHB7LhwUPC73RNr8NakKfG8vfPEY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "150yt6l", "is_robot_indexable": true, "report_reasons": null, "author": "cyyeh", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150yt6l/no_more_data_breaches_with_vulcansql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150yt6l/no_more_data_breaches_with_vulcansql/", "subreddit_subscribers": 116189, "created_utc": 1689489251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m about to embark on my self taught DE journey and I just realized I haven\u2019t had my own personal computer since college.\n\nI am having a hard time between navigating between Mac\u2019s, Dells etc and was wondering if anyone could recommend a laptop (preferably less than 1K) which would make my journey seamless (I\u2019ve heard certain laptops or operating systems make installing some DE tools/environments a nightmare).\n\n\nAgain sincerely appreciate!", "author_fullname": "t2_oasgyrv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for computer to learn Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150yoxn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689488823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m about to embark on my self taught DE journey and I just realized I haven\u2019t had my own personal computer since college.&lt;/p&gt;\n\n&lt;p&gt;I am having a hard time between navigating between Mac\u2019s, Dells etc and was wondering if anyone could recommend a laptop (preferably less than 1K) which would make my journey seamless (I\u2019ve heard certain laptops or operating systems make installing some DE tools/environments a nightmare).&lt;/p&gt;\n\n&lt;p&gt;Again sincerely appreciate!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "150yoxn", "is_robot_indexable": true, "report_reasons": null, "author": "Weary-Individual-309", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150yoxn/recommendations_for_computer_to_learn_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150yoxn/recommendations_for_computer_to_learn_data/", "subreddit_subscribers": 116189, "created_utc": 1689488823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a recent grad from the class of 2023 with a degree in Business and Marketing education. I want to pursue a career in data and fell in love with the concept of data engineering. I\u2019ve done a Google data analytics course back in 2021 so I have familiarity with SQL, Tableau, Power BI, Excel. Im really thinking of pursing a masters in DS or in statistics but not sure what programs I should pursue to help me land my first job in data engineering. Any master program recommendations or programs you recommend would be great.", "author_fullname": "t2_s47yjlr8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Master program do you recommend I take?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150qtj0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689464702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a recent grad from the class of 2023 with a degree in Business and Marketing education. I want to pursue a career in data and fell in love with the concept of data engineering. I\u2019ve done a Google data analytics course back in 2021 so I have familiarity with SQL, Tableau, Power BI, Excel. Im really thinking of pursing a masters in DS or in statistics but not sure what programs I should pursue to help me land my first job in data engineering. Any master program recommendations or programs you recommend would be great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "150qtj0", "is_robot_indexable": true, "report_reasons": null, "author": "shouldawouldacoulda0", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150qtj0/what_master_program_do_you_recommend_i_take/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150qtj0/what_master_program_do_you_recommend_i_take/", "subreddit_subscribers": 116189, "created_utc": 1689464702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doing a practice fun project to learn DE. I can obtain a dataset from Kaggle by downloading it. But I wanted to know if there's a way to get it from API?\n\n\nAlternatively, any way to learn how to API pull data to SQL server, azure, BigQuery etc? I have all of them. Learning databases now.", "author_fullname": "t2_vnan4h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there an API to retrieve data from Kaggle for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151g1t2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689537923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doing a practice fun project to learn DE. I can obtain a dataset from Kaggle by downloading it. But I wanted to know if there&amp;#39;s a way to get it from API?&lt;/p&gt;\n\n&lt;p&gt;Alternatively, any way to learn how to API pull data to SQL server, azure, BigQuery etc? I have all of them. Learning databases now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "151g1t2", "is_robot_indexable": true, "report_reasons": null, "author": "Analyst2163", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151g1t2/is_there_an_api_to_retrieve_data_from_kaggle_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151g1t2/is_there_an_api_to_retrieve_data_from_kaggle_for/", "subreddit_subscribers": 116189, "created_utc": 1689537923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thought I'd post this here for review to see if others see obvious flaws or better approaches.\n\nThe larger context is this store is internal to another more complex store that has specific needs for it's permanent storage.\n\nKeys are always integers.  Values are fixed length byte arrays.  Efficiency matters but volume is fairly low 10k reads/writes second  at most.  This would be using SSD volumes dedicated for this data.\n\nOther off the shelf stores tend to have caveats.  LSM tends to scale poorly with larger data sets, and most other stores just have a lot of overhead and complexity around stuff I don't need.\n\nThe basic file format is a file is assigned a key range.  And the start of the file contains an array covering the entire range.  Each array index contains a 1 byte flag and a 4 byte value containing the block index into the actual data.\n\nThe data area starts immediately after the index array and is variable.  It's comprised of fixed length blocks that are sized in a multiple of the disk block size.\n\nInserts are just appended into the data area.  Compaction is fairly straight forward move active blocks from the end to unused blocks. Implementation probably not important so won't cover that.\n\nAllocating the index up front will always have wasted space in the file with the highest key range.  But it's a flexible design that allows for arbitrary ranges and merging files if needed.  I'm ok with the amount of wasted space here since it's relatively small.\n\nAn insert will append to the data area and return the write offset.  That is then written into the index.  An update will seek/read the index and then seek/write into the value area.\n\nReading is two seeks/reads.", "author_fullname": "t2_16rrd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Key/value store design for integer keys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151d8m7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689531306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thought I&amp;#39;d post this here for review to see if others see obvious flaws or better approaches.&lt;/p&gt;\n\n&lt;p&gt;The larger context is this store is internal to another more complex store that has specific needs for it&amp;#39;s permanent storage.&lt;/p&gt;\n\n&lt;p&gt;Keys are always integers.  Values are fixed length byte arrays.  Efficiency matters but volume is fairly low 10k reads/writes second  at most.  This would be using SSD volumes dedicated for this data.&lt;/p&gt;\n\n&lt;p&gt;Other off the shelf stores tend to have caveats.  LSM tends to scale poorly with larger data sets, and most other stores just have a lot of overhead and complexity around stuff I don&amp;#39;t need.&lt;/p&gt;\n\n&lt;p&gt;The basic file format is a file is assigned a key range.  And the start of the file contains an array covering the entire range.  Each array index contains a 1 byte flag and a 4 byte value containing the block index into the actual data.&lt;/p&gt;\n\n&lt;p&gt;The data area starts immediately after the index array and is variable.  It&amp;#39;s comprised of fixed length blocks that are sized in a multiple of the disk block size.&lt;/p&gt;\n\n&lt;p&gt;Inserts are just appended into the data area.  Compaction is fairly straight forward move active blocks from the end to unused blocks. Implementation probably not important so won&amp;#39;t cover that.&lt;/p&gt;\n\n&lt;p&gt;Allocating the index up front will always have wasted space in the file with the highest key range.  But it&amp;#39;s a flexible design that allows for arbitrary ranges and merging files if needed.  I&amp;#39;m ok with the amount of wasted space here since it&amp;#39;s relatively small.&lt;/p&gt;\n\n&lt;p&gt;An insert will append to the data area and return the write offset.  That is then written into the index.  An update will seek/read the index and then seek/write into the value area.&lt;/p&gt;\n\n&lt;p&gt;Reading is two seeks/reads.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151d8m7", "is_robot_indexable": true, "report_reasons": null, "author": "chris_ochs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151d8m7/keyvalue_store_design_for_integer_keys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151d8m7/keyvalue_store_design_for_integer_keys/", "subreddit_subscribers": 116189, "created_utc": 1689531306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm working on a project that involves storing a large combolist in a database and implementing efficient search functionality for user email addresses within the combolist. The combolist can scale to tens of gigabytes and include billions of entries, and I want to achieve the lowest search time possible.\n\nA combolist in cybersecurity terms is a collection of leaked credentials that comes in email,password pairs and it comes in this form:\n\n\\`email:password\\`\n\nIn short; I'm trying to implement a functionality similar to websites like [haveibeenpwned.com](https://haveibeenpwned.com/) and [dehashed.com](https://dehashed.com/) where a user can lookup if their email has been leaked in a data breach.\n\nWhat is the approach that I should follow here?", "author_fullname": "t2_1djg5mwi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing a functionality similar to haveibeenpwned.com", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151bfxc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689527042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project that involves storing a large combolist in a database and implementing efficient search functionality for user email addresses within the combolist. The combolist can scale to tens of gigabytes and include billions of entries, and I want to achieve the lowest search time possible.&lt;/p&gt;\n\n&lt;p&gt;A combolist in cybersecurity terms is a collection of leaked credentials that comes in email,password pairs and it comes in this form:&lt;/p&gt;\n\n&lt;p&gt;`email:password`&lt;/p&gt;\n\n&lt;p&gt;In short; I&amp;#39;m trying to implement a functionality similar to websites like &lt;a href=\"https://haveibeenpwned.com/\"&gt;haveibeenpwned.com&lt;/a&gt; and &lt;a href=\"https://dehashed.com/\"&gt;dehashed.com&lt;/a&gt; where a user can lookup if their email has been leaked in a data breach.&lt;/p&gt;\n\n&lt;p&gt;What is the approach that I should follow here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JgoK2vb5F1tWOtLBG355-_1fZe6mAd2sv-z81pzUg-E.jpg?auto=webp&amp;s=422b5268c714145f80b9ccb3aad3a035e0aeaa67", "width": 290, "height": 290}, "resolutions": [{"url": "https://external-preview.redd.it/JgoK2vb5F1tWOtLBG355-_1fZe6mAd2sv-z81pzUg-E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=88d9bb65039d93063c545092ebc2f6fa400c1752", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/JgoK2vb5F1tWOtLBG355-_1fZe6mAd2sv-z81pzUg-E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fca8a9ea885a67f855560950fa48b0114ecbb076", "width": 216, "height": 216}], "variants": {}, "id": "RLxH_r3XdD8c_M4b_l_4b30RHRm83xODkzcXGu8dSsM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "151bfxc", "is_robot_indexable": true, "report_reasons": null, "author": "leShawarmaMan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/151bfxc/implementing_a_functionality_similar_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/151bfxc/implementing_a_functionality_similar_to/", "subreddit_subscribers": 116189, "created_utc": 1689527042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's a simple project I have a data as hudi table in s3 partitioned on year month day \nWant to create a iceberg table of out of it partitioned on field capturedate Nd save it on another s3 bucket \nI'm using aws glue \n\nI have tried multiple ways even last resort chatgpt also failed \nI donnot have the permission to use the iceberg connector from aws market place pls suggest how to solve and an example links anything is welcomed need to submit tomorrow my job is a stake, I'm new to DE so encountering problems \n\nIf push come to shove I'll get aws connector bit if you can suggest all the possible ways with or without connector as well is welcomed !!!! \nPls help \n\nThanks in advance \nI'll ans if anyone has any queries \n\n\nThanks !!!!", "author_fullname": "t2_arz03l52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Neeed help with a project pls !!!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1519m26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689522572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a simple project I have a data as hudi table in s3 partitioned on year month day \nWant to create a iceberg table of out of it partitioned on field capturedate Nd save it on another s3 bucket \nI&amp;#39;m using aws glue &lt;/p&gt;\n\n&lt;p&gt;I have tried multiple ways even last resort chatgpt also failed \nI donnot have the permission to use the iceberg connector from aws market place pls suggest how to solve and an example links anything is welcomed need to submit tomorrow my job is a stake, I&amp;#39;m new to DE so encountering problems &lt;/p&gt;\n\n&lt;p&gt;If push come to shove I&amp;#39;ll get aws connector bit if you can suggest all the possible ways with or without connector as well is welcomed !!!! \nPls help &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance \nI&amp;#39;ll ans if anyone has any queries &lt;/p&gt;\n\n&lt;p&gt;Thanks !!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1519m26", "is_robot_indexable": true, "report_reasons": null, "author": "sam-sinister", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1519m26/neeed_help_with_a_project_pls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1519m26/neeed_help_with_a_project_pls/", "subreddit_subscribers": 116189, "created_utc": 1689522572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3gguq8q9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Profession Is Celebrated More By Society? A Data-Driven Dive into Madame Tussaud\u2019s", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1516mcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1689514940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "aazar.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://aazar.me/post/which-profession-is-celebrated-more-by-society", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1516mcp", "is_robot_indexable": true, "report_reasons": null, "author": "44za12", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1516mcp/which_profession_is_celebrated_more_by_society_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://aazar.me/post/which-profession-is-celebrated-more-by-society", "subreddit_subscribers": 116189, "created_utc": 1689514940.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}