{"kind": "Listing", "data": {"after": "t3_150fime", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just an anecdotal story of how having import stuff backup off site can be a life saver.\n\nLike many here I store a ton of media on my server at home including photos I take with my DSLR. trips/weddings/family etc etc.\n\nWell today I was looking through my Lightroom and noticed that one of my folders from a big europe trip we did in the spring was missing. I don't know how it got deleted but it was gone and I couldn't find it anywhere.\n\nThen I remembered that I have a backup of all my photos to backblaze via a duplicati docker that automatically backs up my photos. It just runs on its own and I don't even think about it. So I checked my backblaze backup and there it was. That folder with 100gb of photos from our trip. \n\nSo ya, if you have stuff you really do not want to lose I highly suggest setting up an off-site backup for the important stuff, especially if you host your own physical server.\n\nIt's not that expensive to do either. I think my 2TB+ backup is like $10/m for peace of mind.", "author_fullname": "t2_53a1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having an off-site backup saved my ass today.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150c4p6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 167, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 167, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689427841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just an anecdotal story of how having import stuff backup off site can be a life saver.&lt;/p&gt;\n\n&lt;p&gt;Like many here I store a ton of media on my server at home including photos I take with my DSLR. trips/weddings/family etc etc.&lt;/p&gt;\n\n&lt;p&gt;Well today I was looking through my Lightroom and noticed that one of my folders from a big europe trip we did in the spring was missing. I don&amp;#39;t know how it got deleted but it was gone and I couldn&amp;#39;t find it anywhere.&lt;/p&gt;\n\n&lt;p&gt;Then I remembered that I have a backup of all my photos to backblaze via a duplicati docker that automatically backs up my photos. It just runs on its own and I don&amp;#39;t even think about it. So I checked my backblaze backup and there it was. That folder with 100gb of photos from our trip. &lt;/p&gt;\n\n&lt;p&gt;So ya, if you have stuff you really do not want to lose I highly suggest setting up an off-site backup for the important stuff, especially if you host your own physical server.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not that expensive to do either. I think my 2TB+ backup is like $10/m for peace of mind.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "44TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150c4p6", "is_robot_indexable": true, "report_reasons": null, "author": "Strid3r21", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/150c4p6/having_an_offsite_backup_saved_my_ass_today/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150c4p6/having_an_offsite_backup_saved_my_ass_today/", "subreddit_subscribers": 692832, "created_utc": 1689427841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I run a thrift store/pawn shop, I frequently get HDD's and some SSD's that I use to fix up old computers for resale, never anything significant thou, until around a year ago !\n\nI realised many digital satellite decoders/ PVR/DVR have built in HDD's, it is really significant because people tend to throw them away, give them away, or sell them really cheap, opening them up !,  mostly I've found 1Tb drives, with a odd 2Tb here and there, from what I've seen, it is really difficult to activate a used decoder, so people tend to just get a new one, I don't know if this is the case in America, but this has made my backup and storage a breeze at an almost free price.\n\n I ask for them at every auction, thrift  store and pawn shop, and people readily give them to me for free, everyone knows it's difficult to reactivate those things (Here in South Africa), and I get exited every time, it feels like a HACK ! xD\n\nThe most I've paid for one of these decoders is 0.1% of the price of the HDD inside, hence the title, hope someone finds this post useful, happy hoarding ! ", "author_fullname": "t2_u4plgrjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "0.1% the price of data storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150hby9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 152, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 152, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689440982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I run a thrift store/pawn shop, I frequently get HDD&amp;#39;s and some SSD&amp;#39;s that I use to fix up old computers for resale, never anything significant thou, until around a year ago !&lt;/p&gt;\n\n&lt;p&gt;I realised many digital satellite decoders/ PVR/DVR have built in HDD&amp;#39;s, it is really significant because people tend to throw them away, give them away, or sell them really cheap, opening them up !,  mostly I&amp;#39;ve found 1Tb drives, with a odd 2Tb here and there, from what I&amp;#39;ve seen, it is really difficult to activate a used decoder, so people tend to just get a new one, I don&amp;#39;t know if this is the case in America, but this has made my backup and storage a breeze at an almost free price.&lt;/p&gt;\n\n&lt;p&gt;I ask for them at every auction, thrift  store and pawn shop, and people readily give them to me for free, everyone knows it&amp;#39;s difficult to reactivate those things (Here in South Africa), and I get exited every time, it feels like a HACK ! xD&lt;/p&gt;\n\n&lt;p&gt;The most I&amp;#39;ve paid for one of these decoders is 0.1% of the price of the HDD inside, hence the title, hope someone finds this post useful, happy hoarding ! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150hby9", "is_robot_indexable": true, "report_reasons": null, "author": "Training_Age_Reed", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150hby9/01_the_price_of_data_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150hby9/01_the_price_of_data_storage/", "subreddit_subscribers": 692832, "created_utc": 1689440982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was reading an interesting study about 1.4 MILLION enterprise SSDs, the data was collected via their enterprise monitoring software for 2.5 years (via weekly telemetry data), and was published in 2020.\n\n* Study: [https://www.usenix.org/system/files/fast20-maneas.pdf](https://www.usenix.org/system/files/fast20-maneas.pdf)\n* Official Article (with video): [https://www.usenix.org/conference/fast20/presentation/maneas](https://www.usenix.org/conference/fast20/presentation/maneas)\n* Another Article: [https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/](https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/)\n\nThe study found interesting things, such as: Always update your firmware, because you will massively reduce the amount of data loss over time if you have the latest firmware.\n\n&amp;#x200B;\n\n**But the most interesting column is on page 8 of the PDF, middle graph \"(b) 3D-TLC drives\".**\n\nGroup \"A\" of that graph refers to all kinds of \"total failures\" of the drive (explained on page 5). There are two types of \"total failures\": Either that the drive reported actual on-board DRAM errors (ECC errors in the RAM itself) meaning the hardware was broken and unable to read data properly anymore, OR that the drive became completely non-responsive and vanished from the system. The most serious failures.\n\nSo, on page 8's graphs, they show that 800GB-3800GB 3D-TLC SSDs had a very low \"total drive failure\" rate. But as soon as you got to 8000GB and 15000GB, the drives had a MASSIVE increase in risk that the entire drive has hardware errors and dies, becomes non-responsive, etc.\n\n&amp;#x200B;\n\nHere are some relevant quotes about how larger capacities have lower reliability:\n\n&amp;#x200B;\n\n* \"We also looked for differences in the reasons for replacement between smaller and larger capacity drives and made an interesting observation: for the largest capacity drives, the rate of predictable failures (S.M.A.R.T. data) is lower than for smaller capacity drives. In contrast, the most severe failure reason, i.e., an unresponsive drive, occurs at a much higher rate for the larger capacity drives than for the smaller capacity drives.\"\n* \"Among the eMLC drives, the 3800GB and 3840GB capacities, and among the 3D-TLC drives, the 8TB and 15TB capacities, have very high rates of replacement due to an unresponsive drive, compared to smaller capacities. They also have a lower rate of replacements due to predictive failures. This means that the replacement rate associated with high capacity drives is not only bigger, but also has potentially more severe consequences.\"\n* \"It may be possible that the severe failures and unpredictability of such failures is an artifact of the larger DRAM footprint associated with large flash capacity, rather than the flash capacity itself. Potential for such impact could be mitigated by upcoming architectures such as Zoned Storage (ZNS) \\[4, 30\\] that obviate the need for large Flash Translation Layer (FTL) tables in DRAM and consequently reducing the DRAM footprint.\"\n* Summary: \"Drives with very large capacities not only see a higher replacement rate overall, but also see more severe failures and fewer of the (more benign) predictive failures.\"\n\n&amp;#x200B;\n\nI have transcribed the MEDIAN values of the 3D-TLC \"total drive failure\" rates (as a percentage of all drives in operation) as closely as I could from the graphs:\n\n&amp;#x200B;\n\n* Annual failure rates at category \"A\" (highest severity), as a percentage of all SSDs of that particular size and NAND type (3D-TLC):\n* 800 GB: 0.01875% (0.1875 drives per 1000 die every year)\n* 960 GB: 0.025% (0.25 drives per 1000 die every year)\n* 1600 GB: 0.0055% (0.055 drives per 1000 die every year)\n* 3800 GB: 0.02625% (0.2625 drives per 1000 die every year)\n* 8000 GB: 0.2275% (2.275 drives per 1000 die every year)\n* 15000 GB: 0.1625% (1.625 drives per 1000 die every year)\n* In summary: 8 TB+ SSDs have roughly 10x more \"total drive death\" events than smaller SSDs. And they have less S.M.A.R.T. warning signals before death, meaning the deaths are less predictable.\n\n&amp;#x200B;\n\nAs a bonus fact, they also studied the failure rate related to age:\n\n* \"We observe an unexpectedly long period of infant mortality with a shape that differs from the common \u201cbathtub\u201d model often used in reliability theory. The bathtub model assumes a short initial period of high failure rates, which then quickly drops.\"\n* \"Instead, we observe for both 3D-TLC and eMLC drives, a long period (12\u201315 months) of increasing failure rates, followed by a lengthy period (another 6\u201312 months) of slowly decreasing failure rates, before rates finally stabilize. That means that, given typical drive lifetimes of 5 years, drives spend 20-40% of their life in infant mortality.\"\n* In short, the \"infant mortality\" rate of SSDs is roughly 27 months (slightly over 2 years), before you can say \"this drive is safe, it won't suddenly die due to hardware failure\".\n* After those 27 months, they say that almost all failures are due to predictable errors that show up in S.M.A.R.T. data, such as NAND degradation/read errors.\n\n&amp;#x200B;\n\nSo... I am already torn between buying a 4 TB vs 8 TB Samsung PM9A3 enterprise drive (U.2 connector 2.5\"), and this study make me even more confused...\n\n[https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/](https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/)\n\n&amp;#x200B;\n\nI basically have fear of missing out. The 4 TB drive \"might not be big enough and then I have to buy yet another drive\", and the 8 TB drive is only 65% more expensive for double the capacity. It's a really good deal right now.\n\nOn the other hand, 8 TB is a ton of data to lose if the entire drive just completely dies (I only have redundant backups for the most important data), and if 8 TB+ drives still have vastly more catastrophic hardware failures, well, then that's bad...\n\nThoughts?", "author_fullname": "t2_dmkidisb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enterprise SSD reliability: Does size still matter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150orlb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689464666.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689459432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading an interesting study about 1.4 MILLION enterprise SSDs, the data was collected via their enterprise monitoring software for 2.5 years (via weekly telemetry data), and was published in 2020.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Study: &lt;a href=\"https://www.usenix.org/system/files/fast20-maneas.pdf\"&gt;https://www.usenix.org/system/files/fast20-maneas.pdf&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Official Article (with video): &lt;a href=\"https://www.usenix.org/conference/fast20/presentation/maneas\"&gt;https://www.usenix.org/conference/fast20/presentation/maneas&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Another Article: &lt;a href=\"https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/\"&gt;https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The study found interesting things, such as: Always update your firmware, because you will massively reduce the amount of data loss over time if you have the latest firmware.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;But the most interesting column is on page 8 of the PDF, middle graph &amp;quot;(b) 3D-TLC drives&amp;quot;.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Group &amp;quot;A&amp;quot; of that graph refers to all kinds of &amp;quot;total failures&amp;quot; of the drive (explained on page 5). There are two types of &amp;quot;total failures&amp;quot;: Either that the drive reported actual on-board DRAM errors (ECC errors in the RAM itself) meaning the hardware was broken and unable to read data properly anymore, OR that the drive became completely non-responsive and vanished from the system. The most serious failures.&lt;/p&gt;\n\n&lt;p&gt;So, on page 8&amp;#39;s graphs, they show that 800GB-3800GB 3D-TLC SSDs had a very low &amp;quot;total drive failure&amp;quot; rate. But as soon as you got to 8000GB and 15000GB, the drives had a MASSIVE increase in risk that the entire drive has hardware errors and dies, becomes non-responsive, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here are some relevant quotes about how larger capacities have lower reliability:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;We also looked for differences in the reasons for replacement between smaller and larger capacity drives and made an interesting observation: for the largest capacity drives, the rate of predictable failures (S.M.A.R.T. data) is lower than for smaller capacity drives. In contrast, the most severe failure reason, i.e., an unresponsive drive, occurs at a much higher rate for the larger capacity drives than for the smaller capacity drives.&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;Among the eMLC drives, the 3800GB and 3840GB capacities, and among the 3D-TLC drives, the 8TB and 15TB capacities, have very high rates of replacement due to an unresponsive drive, compared to smaller capacities. They also have a lower rate of replacements due to predictive failures. This means that the replacement rate associated with high capacity drives is not only bigger, but also has potentially more severe consequences.&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;It may be possible that the severe failures and unpredictability of such failures is an artifact of the larger DRAM footprint associated with large flash capacity, rather than the flash capacity itself. Potential for such impact could be mitigated by upcoming architectures such as Zoned Storage (ZNS) [4, 30] that obviate the need for large Flash Translation Layer (FTL) tables in DRAM and consequently reducing the DRAM footprint.&amp;quot;&lt;/li&gt;\n&lt;li&gt;Summary: &amp;quot;Drives with very large capacities not only see a higher replacement rate overall, but also see more severe failures and fewer of the (more benign) predictive failures.&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have transcribed the MEDIAN values of the 3D-TLC &amp;quot;total drive failure&amp;quot; rates (as a percentage of all drives in operation) as closely as I could from the graphs:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Annual failure rates at category &amp;quot;A&amp;quot; (highest severity), as a percentage of all SSDs of that particular size and NAND type (3D-TLC):&lt;/li&gt;\n&lt;li&gt;800 GB: 0.01875% (0.1875 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;960 GB: 0.025% (0.25 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;1600 GB: 0.0055% (0.055 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;3800 GB: 0.02625% (0.2625 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;8000 GB: 0.2275% (2.275 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;15000 GB: 0.1625% (1.625 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;In summary: 8 TB+ SSDs have roughly 10x more &amp;quot;total drive death&amp;quot; events than smaller SSDs. And they have less S.M.A.R.T. warning signals before death, meaning the deaths are less predictable.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As a bonus fact, they also studied the failure rate related to age:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;We observe an unexpectedly long period of infant mortality with a shape that differs from the common \u201cbathtub\u201d model often used in reliability theory. The bathtub model assumes a short initial period of high failure rates, which then quickly drops.&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;Instead, we observe for both 3D-TLC and eMLC drives, a long period (12\u201315 months) of increasing failure rates, followed by a lengthy period (another 6\u201312 months) of slowly decreasing failure rates, before rates finally stabilize. That means that, given typical drive lifetimes of 5 years, drives spend 20-40% of their life in infant mortality.&amp;quot;&lt;/li&gt;\n&lt;li&gt;In short, the &amp;quot;infant mortality&amp;quot; rate of SSDs is roughly 27 months (slightly over 2 years), before you can say &amp;quot;this drive is safe, it won&amp;#39;t suddenly die due to hardware failure&amp;quot;.&lt;/li&gt;\n&lt;li&gt;After those 27 months, they say that almost all failures are due to predictable errors that show up in S.M.A.R.T. data, such as NAND degradation/read errors.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So... I am already torn between buying a 4 TB vs 8 TB Samsung PM9A3 enterprise drive (U.2 connector 2.5&amp;quot;), and this study make me even more confused...&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/\"&gt;https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I basically have fear of missing out. The 4 TB drive &amp;quot;might not be big enough and then I have to buy yet another drive&amp;quot;, and the 8 TB drive is only 65% more expensive for double the capacity. It&amp;#39;s a really good deal right now.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, 8 TB is a ton of data to lose if the entire drive just completely dies (I only have redundant backups for the most important data), and if 8 TB+ drives still have vastly more catastrophic hardware failures, well, then that&amp;#39;s bad...&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "150orlb", "is_robot_indexable": true, "report_reasons": null, "author": "GoastRiter", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150orlb/enterprise_ssd_reliability_does_size_still_matter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150orlb/enterprise_ssd_reliability_does_size_still_matter/", "subreddit_subscribers": 692832, "created_utc": 1689459432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Something like this could probably shift the paradigm of how we store files and create directories. Would you spend your free time organizing your files if you know that a simple search could get you exactly to what you need in a few seconds?\n\nIt's very similar to Spotify search, where you can type in part of the lyrics of a song and it will find you the song. Or in MacOS, you can search by text inside photos and it will grab all the images that contain that text (no more spending my weekends on meticulously tagging and organizing my screenshots folder).\n\nSo is there anything like that already out there that would achieve this especially on Windows?\n\n*Edit*: a local search engine ideally powered by LLMs which would search your entire local hard drive and find matches. LLM-powered means instead of searching using a very specific string of words, you'd be able to \"describe\" what you're looking for in your hard drive without mentioning the file name, tags, Metadata. \n\n```-- \"Find me that video where I was walking next to a river with ice cream in my hand\"```\n\nor \n\n```-- Can you look into my Obsidian notes and summarize all my notes that relate to concept XYZ. Also see if you can find any screenshots that I might have saved that might relate to this topic or check my offline YouTube video archive to see if you can find any snippets or talks that relate to this \"```", "author_fullname": "t2_3bnahjfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With all the AI hype and GPT stuff, are there already any tools/software that make searching and sorting files smarter and faster? Such as the MacOS search inside images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1511tpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": "", "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689509621.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689499743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Something like this could probably shift the paradigm of how we store files and create directories. Would you spend your free time organizing your files if you know that a simple search could get you exactly to what you need in a few seconds?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s very similar to Spotify search, where you can type in part of the lyrics of a song and it will find you the song. Or in MacOS, you can search by text inside photos and it will grab all the images that contain that text (no more spending my weekends on meticulously tagging and organizing my screenshots folder).&lt;/p&gt;\n\n&lt;p&gt;So is there anything like that already out there that would achieve this especially on Windows?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit&lt;/em&gt;: a local search engine ideally powered by LLMs which would search your entire local hard drive and find matches. LLM-powered means instead of searching using a very specific string of words, you&amp;#39;d be able to &amp;quot;describe&amp;quot; what you&amp;#39;re looking for in your hard drive without mentioning the file name, tags, Metadata. &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;-- &amp;quot;Find me that video where I was walking next to a river with ice cream in my hand&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;or &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;-- Can you look into my Obsidian notes and summarize all my notes that relate to concept XYZ. Also see if you can find any screenshots that I might have saved that might relate to this topic or check my offline YouTube video archive to see if you can find any snippets or talks that relate to this &amp;quot;&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1511tpx", "is_robot_indexable": true, "report_reasons": null, "author": "egobamyasi", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1511tpx/with_all_the_ai_hype_and_gpt_stuff_are_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1511tpx/with_all_the_ai_hype_and_gpt_stuff_are_there/", "subreddit_subscribers": 692832, "created_utc": 1689499743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a number of laptop backups, very old (oldest ~8-9 yrs back) laptop backups, which were taken at random dates and a lot of the backup just repeats itself (~195 GB total). Basically a copy paste of most of the folders from the laptop to a harddrive at different points of time.\n\nI was going through the backups, and found a lot of photos, which I have never seen. I would love to find all such \"lost\" photos in these backups. And a way to de-dup the duplicate ones (there will be duplicates)\n\nThe other documents in these backups are pretty much useless for me, apart from the photos. Is there a quick way to extract photos from these huge backups?\n\nI tried searching for a software which could do this, but was unable to find one.\n\nI have a feeling that this might be a common use-case and that there must be a solution outside, just that I don't have the proper key-word to search with.\n\nAny help is appreciated!\n\n\n\nPS:\n- I also tried writing a small script which could extract photos (recursively search all files, check if image, move) but that gives me very very huge list of images (I think they are internal laptop/windows images, and are of no use to me). \n- Is there a good way of doing this? I could also filter on the image size, but these backups also contain a lot of small images aswell - whatsapp images, screenshots, etc. which are small in size too (so this only won't work).\n- One more disadvantage is - the script is very slow (or atleast I think that there must be better optimized way of doing this).\n- I would still not know if what I am writing will cover all the photos in the disk. Basically will have to spend a lot of time testing, running, etc.", "author_fullname": "t2_blvc1ovuy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting all photos from a laptop backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15108wx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689496045.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689494176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a number of laptop backups, very old (oldest ~8-9 yrs back) laptop backups, which were taken at random dates and a lot of the backup just repeats itself (~195 GB total). Basically a copy paste of most of the folders from the laptop to a harddrive at different points of time.&lt;/p&gt;\n\n&lt;p&gt;I was going through the backups, and found a lot of photos, which I have never seen. I would love to find all such &amp;quot;lost&amp;quot; photos in these backups. And a way to de-dup the duplicate ones (there will be duplicates)&lt;/p&gt;\n\n&lt;p&gt;The other documents in these backups are pretty much useless for me, apart from the photos. Is there a quick way to extract photos from these huge backups?&lt;/p&gt;\n\n&lt;p&gt;I tried searching for a software which could do this, but was unable to find one.&lt;/p&gt;\n\n&lt;p&gt;I have a feeling that this might be a common use-case and that there must be a solution outside, just that I don&amp;#39;t have the proper key-word to search with.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated!&lt;/p&gt;\n\n&lt;p&gt;PS:\n- I also tried writing a small script which could extract photos (recursively search all files, check if image, move) but that gives me very very huge list of images (I think they are internal laptop/windows images, and are of no use to me). \n- Is there a good way of doing this? I could also filter on the image size, but these backups also contain a lot of small images aswell - whatsapp images, screenshots, etc. which are small in size too (so this only won&amp;#39;t work).\n- One more disadvantage is - the script is very slow (or atleast I think that there must be better optimized way of doing this).\n- I would still not know if what I am writing will cover all the photos in the disk. Basically will have to spend a lot of time testing, running, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15108wx", "is_robot_indexable": true, "report_reasons": null, "author": "MeasurementSad6631", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15108wx/extracting_all_photos_from_a_laptop_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15108wx/extracting_all_photos_from_a_laptop_backup/", "subreddit_subscribers": 692832, "created_utc": 1689494176.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone! I've recently been looking all over the internet for an xml dump of fandom (formerly known as wikia) wikis from the years 2016 to 2018. I've seen dumps from 2015 and 2020, but the 2018 dump doesn't seem to have the specific wiki I'm looking for. Where would I look for more information?\n\n&amp;#x200B;", "author_fullname": "t2_21qnqkln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to Find Website Dump", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150qz0n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689465126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! I&amp;#39;ve recently been looking all over the internet for an xml dump of fandom (formerly known as wikia) wikis from the years 2016 to 2018. I&amp;#39;ve seen dumps from 2015 and 2020, but the 2018 dump doesn&amp;#39;t seem to have the specific wiki I&amp;#39;m looking for. Where would I look for more information?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150qz0n", "is_robot_indexable": true, "report_reasons": null, "author": "TemporarilyResolute", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150qz0n/trying_to_find_website_dump/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150qz0n/trying_to_find_website_dump/", "subreddit_subscribers": 692832, "created_utc": 1689465126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi folks,\n\nI'm a filmmaker and video editor seeking to improve my data workflow.\n\nHere's my current workflow:\n\n1. Dump media from camera/sound SD cards onto Samsung (T5) 2TB SSD.\n2. Copy media and project files once a day to secondary Samsung (T5) 2 TB SSD.\n3. Copy media and project files once a day to OWC Thunderbay 4 raid 5 array for on-site, long-term backup.\n4. Copy media and project files (weekly-ish) to a cloud drive for off-site, long-term backup.\n\nUntil recently everything goes fine editing on a Samsung 2TB, but the latest project is a feature which continues to expand, now exceeding the capacity of one 2TB drive. This is where the challenge has come.\n\nIn order to deal with the increase for the current project, I upgraded to some crucial 4TB drives. Even though these were rated for higher speeds, these were dramatically slower than the Samsung SSDs. I returned them and ordered a Samsung T7 4TB, which has worked in a pinch, but now I'm wondering if I should reconsider which drives to use for my 2 active SSDs: the main edit and the main backup.\n\nI have read up a lot about NVME, enclosures, etc etc, but I just wanted to put this out to folks who might be on a workflow and have something relevant for this moment in 2023. Things are changing so fast all the time, maybe there's a good solution I haven't seen yet.\n\nSamsung has been reliable for me but I'm happy to try anything that works. I've batted around maybe doing the following:\n\n1. Just using the Samsung T7 4TBs for now as active edit and active backup, cross the next bridge when I get there.\n2. Investing in some kind of SSD raid array for the active project/active backup. I've had okay luck with OWC products.\n3. NVME enclosure with something like a WD black -- 2x2TB or 4TB?\n\nActive edit speed is key--must not lag or bottleneck at the SSD, and file transfer speed for the overnight dump/backup really is essential.\n\nEditors, data hoarders, what's your take? Thanks in advance. ", "author_fullname": "t2_k6qlwad5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video Editing Workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150b13j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689424802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a filmmaker and video editor seeking to improve my data workflow.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my current workflow:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Dump media from camera/sound SD cards onto Samsung (T5) 2TB SSD.&lt;/li&gt;\n&lt;li&gt;Copy media and project files once a day to secondary Samsung (T5) 2 TB SSD.&lt;/li&gt;\n&lt;li&gt;Copy media and project files once a day to OWC Thunderbay 4 raid 5 array for on-site, long-term backup.&lt;/li&gt;\n&lt;li&gt;Copy media and project files (weekly-ish) to a cloud drive for off-site, long-term backup.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Until recently everything goes fine editing on a Samsung 2TB, but the latest project is a feature which continues to expand, now exceeding the capacity of one 2TB drive. This is where the challenge has come.&lt;/p&gt;\n\n&lt;p&gt;In order to deal with the increase for the current project, I upgraded to some crucial 4TB drives. Even though these were rated for higher speeds, these were dramatically slower than the Samsung SSDs. I returned them and ordered a Samsung T7 4TB, which has worked in a pinch, but now I&amp;#39;m wondering if I should reconsider which drives to use for my 2 active SSDs: the main edit and the main backup.&lt;/p&gt;\n\n&lt;p&gt;I have read up a lot about NVME, enclosures, etc etc, but I just wanted to put this out to folks who might be on a workflow and have something relevant for this moment in 2023. Things are changing so fast all the time, maybe there&amp;#39;s a good solution I haven&amp;#39;t seen yet.&lt;/p&gt;\n\n&lt;p&gt;Samsung has been reliable for me but I&amp;#39;m happy to try anything that works. I&amp;#39;ve batted around maybe doing the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Just using the Samsung T7 4TBs for now as active edit and active backup, cross the next bridge when I get there.&lt;/li&gt;\n&lt;li&gt;Investing in some kind of SSD raid array for the active project/active backup. I&amp;#39;ve had okay luck with OWC products.&lt;/li&gt;\n&lt;li&gt;NVME enclosure with something like a WD black -- 2x2TB or 4TB?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Active edit speed is key--must not lag or bottleneck at the SSD, and file transfer speed for the overnight dump/backup really is essential.&lt;/p&gt;\n\n&lt;p&gt;Editors, data hoarders, what&amp;#39;s your take? Thanks in advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150b13j", "is_robot_indexable": true, "report_reasons": null, "author": "RobertoBandissimo", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150b13j/video_editing_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150b13j/video_editing_workflow/", "subreddit_subscribers": 692832, "created_utc": 1689424802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My pool is a mix of duplicated and unduplicated files across 7 drives (52.8 TB total). My StableBit Scanner says I have 512 byte bad sector in one of the drives. DrivePool immediately copies unduplicated files on the drive with the bad sector across other drives. After it finishes, it did a remeasure and pool organization is green with \"file distribution not normal\". For some reason, the bad drive shows I have around 400GB unduplicated data, which I really want to backup just in case. My pool statistics shows:\n\n* 21.9 TB unduplicated\n* 24.6 TB duplicated\n* 6.05 TB unusable for duplication\n\nIs 512 byte bad sector something to worry about? Should I keep my drive or replace it? I'm not sure what to do next from here. Thank you in advance.\n\n&amp;#x200B;", "author_fullname": "t2_u50yq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "StableBit DrivePool/Scanner says I have 512 byte bad sector...what to do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15120jl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689500416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My pool is a mix of duplicated and unduplicated files across 7 drives (52.8 TB total). My StableBit Scanner says I have 512 byte bad sector in one of the drives. DrivePool immediately copies unduplicated files on the drive with the bad sector across other drives. After it finishes, it did a remeasure and pool organization is green with &amp;quot;file distribution not normal&amp;quot;. For some reason, the bad drive shows I have around 400GB unduplicated data, which I really want to backup just in case. My pool statistics shows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;21.9 TB unduplicated&lt;/li&gt;\n&lt;li&gt;24.6 TB duplicated&lt;/li&gt;\n&lt;li&gt;6.05 TB unusable for duplication&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is 512 byte bad sector something to worry about? Should I keep my drive or replace it? I&amp;#39;m not sure what to do next from here. Thank you in advance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15120jl", "is_robot_indexable": true, "report_reasons": null, "author": "neohanime", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15120jl/stablebit_drivepoolscanner_says_i_have_512_byte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15120jl/stablebit_drivepoolscanner_says_i_have_512_byte/", "subreddit_subscribers": 692832, "created_utc": 1689500416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Recently acquired a couple of 12-bay synology NASes loaded with drives, after a family friend passed away. \n\nUnsure if the contents are worth saving, but it appears the first enclosure I started messing with, a DS2415, is suffering from the \u201catom power problem\u201d, with blinking power and alert lights upon trying to startup.  I\u2019ve removed and numbered the drives for now. \n\nIs there any other way for me to view these drives, outside of getting them into a new 12-bay enclosure? Will that even work? I can\u2019t move them into the other enclosure I got from them because it is an expansion unit.", "author_fullname": "t2_ablys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reconstructing/salvaging a 12-drive RAID without the 12-bay enclosure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150x4zh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689483717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently acquired a couple of 12-bay synology NASes loaded with drives, after a family friend passed away. &lt;/p&gt;\n\n&lt;p&gt;Unsure if the contents are worth saving, but it appears the first enclosure I started messing with, a DS2415, is suffering from the \u201catom power problem\u201d, with blinking power and alert lights upon trying to startup.  I\u2019ve removed and numbered the drives for now. &lt;/p&gt;\n\n&lt;p&gt;Is there any other way for me to view these drives, outside of getting them into a new 12-bay enclosure? Will that even work? I can\u2019t move them into the other enclosure I got from them because it is an expansion unit.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150x4zh", "is_robot_indexable": true, "report_reasons": null, "author": "JayVeeBee", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150x4zh/reconstructingsalvaging_a_12drive_raid_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150x4zh/reconstructingsalvaging_a_12drive_raid_without/", "subreddit_subscribers": 692832, "created_utc": 1689483717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm having trouble **only** wgetting this URL : [https://forum.spacehey.com/topic?id=3959](https://forum.spacehey.com/topic?id=3959) and all the links that branch out of it, only 1 level away from the link.\n\n    When I run wget -e robots=off --recursive -np -k --html-extension \"https://forum.spacehey.com/topic?id=3959\"\n\nit starts downloading all of the forum pages and all the user profiles, even those that did not participate in that specific thread. I just want \\`topic?id=3959  \n to be downloaded, plus the user profiles or links that might branch out from the link, but no deeper than 1 level. Not sure if I'm explaining myself correctly.", "author_fullname": "t2_2rewrxo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with Wget", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150q5z7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689462973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m having trouble &lt;strong&gt;only&lt;/strong&gt; wgetting this URL : &lt;a href=\"https://forum.spacehey.com/topic?id=3959\"&gt;https://forum.spacehey.com/topic?id=3959&lt;/a&gt; and all the links that branch out of it, only 1 level away from the link.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;When I run wget -e robots=off --recursive -np -k --html-extension &amp;quot;https://forum.spacehey.com/topic?id=3959&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;it starts downloading all of the forum pages and all the user profiles, even those that did not participate in that specific thread. I just want `topic?id=3959&lt;br/&gt;\n to be downloaded, plus the user profiles or links that might branch out from the link, but no deeper than 1 level. Not sure if I&amp;#39;m explaining myself correctly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?auto=webp&amp;s=3857ed03a465a31599b65c323030194450e8bc09", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=722e416e8ee490729a17976e9f4bbe7c3e078871", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f35418a5521952a5db5b0452b454e3a32b03a46", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d16b9e2c1149bb5979da229871a45ec1d23d7dfc", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=536746646c1dded870ef8ae904c9414d295e6926", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=acee12e384beec774f373142492cf49d80ee2300", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8453b2a3662b55ed0db129bc72c0d660403065ee", "width": 1080, "height": 540}], "variants": {}, "id": "ztoUwoXJpe58a61I-q3Dg8eJzueXuf-NZZ1WQ20Kpgo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150q5z7", "is_robot_indexable": true, "report_reasons": null, "author": "iPodClassic7", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150q5z7/need_help_with_wget/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150q5z7/need_help_with_wget/", "subreddit_subscribers": 692832, "created_utc": 1689462973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have roughly 14 drives with 5-8 copies of files on them. My PC situation is I have my main PC and a second \"storage\" PC where I would like to have backed up files but also just files that I no longer have on my main PC (90GB game folders so I don't need to download it again when I want to launch the game next year maybe).\n\nIdeally, I would just like an excel spreadsheet with all the file hashes and attributes and paths. Then I can see what file is where and remove unneeded copies. Unfortunately, excel does not like lists with half a million entries and also manually sorting will be very slow.\n\nIs there any software that can generate a \"map\" from one hard drive, then I can open this \"map\" on a different hard drive, compare if some parts of the folder structure and content is identical, then I can organise based on those, not on individual files?", "author_fullname": "t2_cjhkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organising years' worth of chaotic backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150jgn9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689446211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have roughly 14 drives with 5-8 copies of files on them. My PC situation is I have my main PC and a second &amp;quot;storage&amp;quot; PC where I would like to have backed up files but also just files that I no longer have on my main PC (90GB game folders so I don&amp;#39;t need to download it again when I want to launch the game next year maybe).&lt;/p&gt;\n\n&lt;p&gt;Ideally, I would just like an excel spreadsheet with all the file hashes and attributes and paths. Then I can see what file is where and remove unneeded copies. Unfortunately, excel does not like lists with half a million entries and also manually sorting will be very slow.&lt;/p&gt;\n\n&lt;p&gt;Is there any software that can generate a &amp;quot;map&amp;quot; from one hard drive, then I can open this &amp;quot;map&amp;quot; on a different hard drive, compare if some parts of the folder structure and content is identical, then I can organise based on those, not on individual files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150jgn9", "is_robot_indexable": true, "report_reasons": null, "author": "jeo123911", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150jgn9/organising_years_worth_of_chaotic_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150jgn9/organising_years_worth_of_chaotic_backups/", "subreddit_subscribers": 692832, "created_utc": 1689446211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to encrypt files for storage, and I need them to be easily accessible on Windows, macOS, and Linux (Android and iOS would be good but not necessary). The decryption solution should be easy to set up. For example, if I have the files on a USB stick and I want to access them on a computer that isn't mine, something like VeraCrypt won't work since it requires an install alongside MacFUSE on Mac. I don't necessarily need a GUI to make it work. The encryption should also be secure, so that it doesn't matter if I \"lose\" the files (although I don't intend to share them, it's a possibility). I'd prefer to encrypt files individually, but larger (not multiple gigs) archives would also be okay.\n\nI was thinking of 7-Zip as a possibility. It provides a decent CLI tool as well as a great GUI on Windows. Are there any considerations I should make when using it? Can I \"accidentally\" encrypt with a bad cipher or leave filenames unencrypted?\n\nIf this isn't the right place to post this, please direct me to a better one.", "author_fullname": "t2_56xaugqc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to encrypt files for cross-platform access with minimal setup required to access them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1514jrs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689508960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to encrypt files for storage, and I need them to be easily accessible on Windows, macOS, and Linux (Android and iOS would be good but not necessary). The decryption solution should be easy to set up. For example, if I have the files on a USB stick and I want to access them on a computer that isn&amp;#39;t mine, something like VeraCrypt won&amp;#39;t work since it requires an install alongside MacFUSE on Mac. I don&amp;#39;t necessarily need a GUI to make it work. The encryption should also be secure, so that it doesn&amp;#39;t matter if I &amp;quot;lose&amp;quot; the files (although I don&amp;#39;t intend to share them, it&amp;#39;s a possibility). I&amp;#39;d prefer to encrypt files individually, but larger (not multiple gigs) archives would also be okay.&lt;/p&gt;\n\n&lt;p&gt;I was thinking of 7-Zip as a possibility. It provides a decent CLI tool as well as a great GUI on Windows. Are there any considerations I should make when using it? Can I &amp;quot;accidentally&amp;quot; encrypt with a bad cipher or leave filenames unencrypted?&lt;/p&gt;\n\n&lt;p&gt;If this isn&amp;#39;t the right place to post this, please direct me to a better one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1514jrs", "is_robot_indexable": true, "report_reasons": null, "author": "ItseKeisari", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1514jrs/what_is_the_best_way_to_encrypt_files_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1514jrs/what_is_the_best_way_to_encrypt_files_for/", "subreddit_subscribers": 692832, "created_utc": 1689508960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I seem to have been getting error messages since Friday evening when trying to use my iDrive e2 bucket in Frankfurt?\n\nIs the full region down or just my server?\n\nI have also noticed they have reduced their yearly price to $20 for 1TB (was $40 before)", "author_fullname": "t2_lwumyho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "iDrive e2 Frankfurt down since Friday evening?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15136lt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689504451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I seem to have been getting error messages since Friday evening when trying to use my iDrive e2 bucket in Frankfurt?&lt;/p&gt;\n\n&lt;p&gt;Is the full region down or just my server?&lt;/p&gt;\n\n&lt;p&gt;I have also noticed they have reduced their yearly price to $20 for 1TB (was $40 before)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15136lt", "is_robot_indexable": true, "report_reasons": null, "author": "TedBob99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15136lt/idrive_e2_frankfurt_down_since_friday_evening/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15136lt/idrive_e2_frankfurt_down_since_friday_evening/", "subreddit_subscribers": 692832, "created_utc": 1689504451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking to download all photos from users albums in original HQ format. I understand there was a project but it was discontinued.\n\nAn example would be: [https://weibo.com/u/5732554220?tabtype=album](https://weibo.com/u/5732554220?tabtype=album) with an almost infinite scroll for several years of professional content.\n\nHopefully with a GUI as I'm big enough to admit I'm not savvy enough to use Gibhub projects.", "author_fullname": "t2_a7s673lu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a current Weibo album downloader?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15124wf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689500833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to download all photos from users albums in original HQ format. I understand there was a project but it was discontinued.&lt;/p&gt;\n\n&lt;p&gt;An example would be: &lt;a href=\"https://weibo.com/u/5732554220?tabtype=album\"&gt;https://weibo.com/u/5732554220?tabtype=album&lt;/a&gt; with an almost infinite scroll for several years of professional content.&lt;/p&gt;\n\n&lt;p&gt;Hopefully with a GUI as I&amp;#39;m big enough to admit I&amp;#39;m not savvy enough to use Gibhub projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15124wf", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated-Distance740", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15124wf/is_there_a_current_weibo_album_downloader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15124wf/is_there_a_current_weibo_album_downloader/", "subreddit_subscribers": 692832, "created_utc": 1689500833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What are the pros and cons of these two cables?", "author_fullname": "t2_cay5lyps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I buy usb c or usb 3 micro b ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1511l5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DfP6GfvsitkTS5VfIYzxC7NvgMngy6swGjXbi0l5pPY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689498892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the pros and cons of these two cables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/5ltg0wwlnacb1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/5ltg0wwlnacb1.png?auto=webp&amp;s=33c0f71628fc85dc3c9daa2c299e688a4c9f4d97", "width": 1080, "height": 1290}, "resolutions": [{"url": "https://preview.redd.it/5ltg0wwlnacb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d75aead931a1ae359a71ff4d8b6842a07efc3ebf", "width": 108, "height": 129}, {"url": "https://preview.redd.it/5ltg0wwlnacb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=95349f261df1ad4d1f6dcbe1670c3bc7f951f56f", "width": 216, "height": 258}, {"url": "https://preview.redd.it/5ltg0wwlnacb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dffa11e50da2d9bcb498c17b8b258d0358aafaa", "width": 320, "height": 382}, {"url": "https://preview.redd.it/5ltg0wwlnacb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3863e4ed51efe53ff5bcbea3b8262180d732172f", "width": 640, "height": 764}, {"url": "https://preview.redd.it/5ltg0wwlnacb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=50900ee02985d58a1bc1784fbd059f674257fdbb", "width": 960, "height": 1146}, {"url": "https://preview.redd.it/5ltg0wwlnacb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=251d8d0dfafef1a224beb69e2e6f9c5fd342f04c", "width": 1080, "height": 1290}], "variants": {}, "id": "c6bTHNuPtOVAiQClLRTbDal-vBM7V2uKvCArJJz0JpI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1511l5f", "is_robot_indexable": true, "report_reasons": null, "author": "Professional-Pace204", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1511l5f/should_i_buy_usb_c_or_usb_3_micro_b/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/5ltg0wwlnacb1.png", "subreddit_subscribers": 692832, "created_utc": 1689498892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using Storage Spaces for years to store relatively unimportant data and it's worked fine with two 18TB internal drives and two 8TB external drives. I was finally running out of room so I decided to add two new 18TB drives attached via a USB Docking Station. Got the new drives/docking station, started to optimize, and immediately started getting errors that one of the old drives had failed. \n\nFast-forward a bit and I have to stop optimization, and after stopping it and reconnecting all drives, all the drives  read as \"OK.\" So I start trying to optimize again. This time things go even worse. One of the old drives read as \"failed\" and, for some reason, Storage Spaces automatically prepares it to remove even though I didn't tell it to, and I get a \"warning\" on one of the new drives. So optimization completes, and I try unplugging/replugging everything again, but this time it doesn't work. The old drive will only read \"ready to remove\" and new drives now both have Warning marks. So I remove the old drive and eventually reconnnect it using a different USB port. Now getting the message \"Error Unrecognized Configuration Reset Drive\" which, according to a Google search, will wipe the drive. \n\nMy Storage Spaces volume is still accessible but a lot of data is missing/inaccessible. Most of it I could get back if I wanted to put in the time/effort, but I'd be willing to pay some if I could recover it without having to manually find/download everything I'd saved, but I don't know what my options are. Any advice/recommendations? I know of, eg, ReClaime, but it's like $300 and I have no idea how successful it would be. I've got to think the data is recoverable given that none of the drives have actually failed and the data is still there. ", "author_fullname": "t2_b04kmo9u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage Spaces Fails to Optimize: Data Lost? Help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150zkpk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689491866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using Storage Spaces for years to store relatively unimportant data and it&amp;#39;s worked fine with two 18TB internal drives and two 8TB external drives. I was finally running out of room so I decided to add two new 18TB drives attached via a USB Docking Station. Got the new drives/docking station, started to optimize, and immediately started getting errors that one of the old drives had failed. &lt;/p&gt;\n\n&lt;p&gt;Fast-forward a bit and I have to stop optimization, and after stopping it and reconnecting all drives, all the drives  read as &amp;quot;OK.&amp;quot; So I start trying to optimize again. This time things go even worse. One of the old drives read as &amp;quot;failed&amp;quot; and, for some reason, Storage Spaces automatically prepares it to remove even though I didn&amp;#39;t tell it to, and I get a &amp;quot;warning&amp;quot; on one of the new drives. So optimization completes, and I try unplugging/replugging everything again, but this time it doesn&amp;#39;t work. The old drive will only read &amp;quot;ready to remove&amp;quot; and new drives now both have Warning marks. So I remove the old drive and eventually reconnnect it using a different USB port. Now getting the message &amp;quot;Error Unrecognized Configuration Reset Drive&amp;quot; which, according to a Google search, will wipe the drive. &lt;/p&gt;\n\n&lt;p&gt;My Storage Spaces volume is still accessible but a lot of data is missing/inaccessible. Most of it I could get back if I wanted to put in the time/effort, but I&amp;#39;d be willing to pay some if I could recover it without having to manually find/download everything I&amp;#39;d saved, but I don&amp;#39;t know what my options are. Any advice/recommendations? I know of, eg, ReClaime, but it&amp;#39;s like $300 and I have no idea how successful it would be. I&amp;#39;ve got to think the data is recoverable given that none of the drives have actually failed and the data is still there. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150zkpk", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious_War5435", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150zkpk/storage_spaces_fails_to_optimize_data_lost_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150zkpk/storage_spaces_fails_to_optimize_data_lost_help/", "subreddit_subscribers": 692832, "created_utc": 1689491866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have too much digital stuff. I am deleting everything I don\u2019t need. I\u2019ve about 10 years worth of stuff to go through, and it will take a long time. My fear of deleting anything first happened when my first computer got a virus and I lost everything + losing stuff due to files becoming corrupt. Even though my \u2018hoarding\u2019 is pretty mild, I don\u2019t like having to keep stuff \u2018just in case.\u2019 Especially if I genuinely don\u2019t need it anymore. \n\nMy digital clutter clutters my mind. If I see something and either don\u2019t need it or don\u2019t see myself reopening the file, I am getting rid of it. It makes me feel uncomfortable just deleting shit, but I have to delete and forget about it. I signed up to lots of accounts and emails as well, which are all in the process of getting deleted.\n\nYou guys might laugh at this but I have only around 2-5 TB worth of stuff, which might seem like nothing around here, but I find it overwhelming and extremely burdensome. Respect to all of you who are able to manage all that, jesus.", "author_fullname": "t2_d0lx00uz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am tired", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150x71e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689483892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have too much digital stuff. I am deleting everything I don\u2019t need. I\u2019ve about 10 years worth of stuff to go through, and it will take a long time. My fear of deleting anything first happened when my first computer got a virus and I lost everything + losing stuff due to files becoming corrupt. Even though my \u2018hoarding\u2019 is pretty mild, I don\u2019t like having to keep stuff \u2018just in case.\u2019 Especially if I genuinely don\u2019t need it anymore. &lt;/p&gt;\n\n&lt;p&gt;My digital clutter clutters my mind. If I see something and either don\u2019t need it or don\u2019t see myself reopening the file, I am getting rid of it. It makes me feel uncomfortable just deleting shit, but I have to delete and forget about it. I signed up to lots of accounts and emails as well, which are all in the process of getting deleted.&lt;/p&gt;\n\n&lt;p&gt;You guys might laugh at this but I have only around 2-5 TB worth of stuff, which might seem like nothing around here, but I find it overwhelming and extremely burdensome. Respect to all of you who are able to manage all that, jesus.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "150x71e", "is_robot_indexable": true, "report_reasons": null, "author": "OkPoet6127", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150x71e/i_am_tired/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150x71e/i_am_tired/", "subreddit_subscribers": 692832, "created_utc": 1689483892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a software to archive my folder history as I go through changes with updates, etc. Screenshots would be tedious and then it occured to me that I could use instead a mirroring feature where the folders and sub-folders have the same path, so if my folder contains a sub-folder, \"2020\" and within it, \"Personal\" and \"screenshots\". In the mirrored archive, I can still click on 2020 to access personal. The files are deceptive. Preferably, they do have properties but can't be opened or used. Basically, they are like the thumbnails that our phones and computers make as cache. Except they retain all the properties and information except for file size.\n\nI was inspired by Wayback Machine for this idea. You can search YouTube from a bygone time but the videos don't work.\n\nSo far, while googling a software like this, all I get is mirror folder softwares that synchronizes and makes backups of folders. Please help!\n\nI think this idea is a great way to have an archive of folder history.", "author_fullname": "t2_oouyyvk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mirror folder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150u2df", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689474042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a software to archive my folder history as I go through changes with updates, etc. Screenshots would be tedious and then it occured to me that I could use instead a mirroring feature where the folders and sub-folders have the same path, so if my folder contains a sub-folder, &amp;quot;2020&amp;quot; and within it, &amp;quot;Personal&amp;quot; and &amp;quot;screenshots&amp;quot;. In the mirrored archive, I can still click on 2020 to access personal. The files are deceptive. Preferably, they do have properties but can&amp;#39;t be opened or used. Basically, they are like the thumbnails that our phones and computers make as cache. Except they retain all the properties and information except for file size.&lt;/p&gt;\n\n&lt;p&gt;I was inspired by Wayback Machine for this idea. You can search YouTube from a bygone time but the videos don&amp;#39;t work.&lt;/p&gt;\n\n&lt;p&gt;So far, while googling a software like this, all I get is mirror folder softwares that synchronizes and makes backups of folders. Please help!&lt;/p&gt;\n\n&lt;p&gt;I think this idea is a great way to have an archive of folder history.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150u2df", "is_robot_indexable": true, "report_reasons": null, "author": "Pale-Dragonfly-3139", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150u2df/mirror_folder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150u2df/mirror_folder/", "subreddit_subscribers": 692832, "created_utc": 1689474042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently running 8x16TB sata drives in TeueNas Scale with the onboard sata. I want to fill up my total slots for disk of storage by adding 4 or 6 more drives. The choices on Amazon seem to be the same cards the sell on AliExpress, while the Amazon cards are double the price. My current thinking is adding 4-6 more drives ( custom ATX setup ), going with raid z, having 1 as parity and 1 as a hotspare. So total 14 drives, 13 in raid z with the parity and one sitting there as a hotspare.\n\nBrowing around the the cards, it seems like once you go past 4 slots on 1 card, some of the 6 slot pcie 1x cards employ a double on board chip solution. \n\nIs their a card with 6 sata adapters on the card with only 1 chip to handle all the processing? If so, which SOC should I look for?\n\nAlso, do you think a 4 sata adapter would be much different from a 6 slot adapter?\n\nAnyways, just looking for suggestions on a 6x sata pcie 1x card that would best fit my needs.\n\nThanks!", "author_fullname": "t2_76tlc1a2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Chip For PCIE Sata Expander?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150o9mi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689458214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently running 8x16TB sata drives in TeueNas Scale with the onboard sata. I want to fill up my total slots for disk of storage by adding 4 or 6 more drives. The choices on Amazon seem to be the same cards the sell on AliExpress, while the Amazon cards are double the price. My current thinking is adding 4-6 more drives ( custom ATX setup ), going with raid z, having 1 as parity and 1 as a hotspare. So total 14 drives, 13 in raid z with the parity and one sitting there as a hotspare.&lt;/p&gt;\n\n&lt;p&gt;Browing around the the cards, it seems like once you go past 4 slots on 1 card, some of the 6 slot pcie 1x cards employ a double on board chip solution. &lt;/p&gt;\n\n&lt;p&gt;Is their a card with 6 sata adapters on the card with only 1 chip to handle all the processing? If so, which SOC should I look for?&lt;/p&gt;\n\n&lt;p&gt;Also, do you think a 4 sata adapter would be much different from a 6 slot adapter?&lt;/p&gt;\n\n&lt;p&gt;Anyways, just looking for suggestions on a 6x sata pcie 1x card that would best fit my needs.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150o9mi", "is_robot_indexable": true, "report_reasons": null, "author": "Vast-Program7060", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/150o9mi/best_chip_for_pcie_sata_expander/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150o9mi/best_chip_for_pcie_sata_expander/", "subreddit_subscribers": 692832, "created_utc": 1689458214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all - I'm building a new home server using an LSI host bus adapter that I got off eBay for $40. This is my first time using an HBA as I typically plugged my drives directly into the SATA ports on the mobo. I'm using a lot of the same componentry from my previous PC build (mobo, RAM, CPU, GPU, drives) but got a new case (Fractal Define 7XL - love it!) and a new power supply.\n\nThe seller was linked from a few different Reddit threads and the listing says they've sold 1,200+ of this card.. with all the positive reviews I figured it would be a safe purchase. But after I had plugged it into the PCI-e slot, connected it up, etc... when I turned on my power supply a spark on one of the HBA's on-board chips sparked a small flame and started smoking - so I instantly powered down the system. It burned a hole through the chip... pic attached.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/nuduc8nr77cb1.jpg?width=1536&amp;format=pjpg&amp;auto=webp&amp;s=002af9e543e47f443e145144b6e6c3155881a5e2\n\nWas this just a bad card and I should give them another chance and ask for a replacement? Or am I better off seeking a more reputable place to buy it than this seller on eBay? My motherboard only has 6 SATA connections but this has me nervous about using an HBA now\n\n[LSI 9211-8i 6G SAS HBA FW:P20 IT Mode ZFS FreeNAS unRAID 2\\* SFF-8087 SATA US | eBay](https://www.ebay.com/itm/133702989762)", "author_fullname": "t2_7sxyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "eBay ordered LSI SAS 9210 host bus adapter caught fire... shoddy chip?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nuduc8nr77cb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae4f5d20cac8dec41dcb86a7c358f59d3efb74dc"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=067f344055128fc103d35ba381255bf383f300a4"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=af00e0db2c3254672943844b2c3871f18bce388a"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0087a483c4c93aaac307c86390d05d5601fa3330"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=09f8e4019ff0701a07d13babc441cdbde97a5178"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=baae4f126b8052e8531410b34c42bb27680420f1"}], "s": {"y": 2048, "x": 1536, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=1536&amp;format=pjpg&amp;auto=webp&amp;s=002af9e543e47f443e145144b6e6c3155881a5e2"}, "id": "nuduc8nr77cb1"}}, "name": "t3_150nunp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_75XOemTR6MCuMf98TKJnolEgtWnchVnBW0ky33jjso.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689457174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - I&amp;#39;m building a new home server using an LSI host bus adapter that I got off eBay for $40. This is my first time using an HBA as I typically plugged my drives directly into the SATA ports on the mobo. I&amp;#39;m using a lot of the same componentry from my previous PC build (mobo, RAM, CPU, GPU, drives) but got a new case (Fractal Define 7XL - love it!) and a new power supply.&lt;/p&gt;\n\n&lt;p&gt;The seller was linked from a few different Reddit threads and the listing says they&amp;#39;ve sold 1,200+ of this card.. with all the positive reviews I figured it would be a safe purchase. But after I had plugged it into the PCI-e slot, connected it up, etc... when I turned on my power supply a spark on one of the HBA&amp;#39;s on-board chips sparked a small flame and started smoking - so I instantly powered down the system. It burned a hole through the chip... pic attached.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nuduc8nr77cb1.jpg?width=1536&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=002af9e543e47f443e145144b6e6c3155881a5e2\"&gt;https://preview.redd.it/nuduc8nr77cb1.jpg?width=1536&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=002af9e543e47f443e145144b6e6c3155881a5e2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Was this just a bad card and I should give them another chance and ask for a replacement? Or am I better off seeking a more reputable place to buy it than this seller on eBay? My motherboard only has 6 SATA connections but this has me nervous about using an HBA now&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ebay.com/itm/133702989762\"&gt;LSI 9211-8i 6G SAS HBA FW:P20 IT Mode ZFS FreeNAS unRAID 2* SFF-8087 SATA US | eBay&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "116TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150nunp", "is_robot_indexable": true, "report_reasons": null, "author": "mykeyhope", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/150nunp/ebay_ordered_lsi_sas_9210_host_bus_adapter_caught/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150nunp/ebay_ordered_lsi_sas_9210_host_bus_adapter_caught/", "subreddit_subscribers": 692832, "created_utc": 1689457174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! The drives on my PCs are starting to fill with stuff I just don't want to delete, so I'm looking to consolidate my data to something central that I can access from any of the various devices in the house. There's a lot of data on random drives lying around too, that should probably get moved into one location.\n\nI've done a but of googling but I'm new to this sort of thing, so I was wondering what you'd suggest.    \nMore important than anything else is cheap - I really don't want to be spending $4-500+ on this if I don't have to.\n\nWhat I'm planning on using it for:\n\n* Security camera storage. Right now I've a book-sized Windows office pc repurposed as a BlueIris server handling this and shunting any clip the software finds interesting to an external drive for storage. I may add more than the single camera at some point and will likely need more storage as a result.\n\n* Plex: The baby-server has been handling this, broadcasting to the various TVs in the house, though I don't have a huge collection of stuff.\n\n* Getting the family's data out of the half-dozen external drives that sit in a closet so I don't have to deal with the annual game of 'please dig through all our drives so I can find that one photo that was scanned 12 years ago'\n\n* Centralizing my own data like 3d print files somewhere I can find them, being able to load the file on the printer without having to walk between computers would be nice\n\n* Secondary/external Steam library so I don't have to download every game 2-3 times\n\n* I am apparently physically incapable of deleting any video game screenshot I take\n\n* Maybe a home minecraft server if I'm feeling adventurous\n\nTo that end, should I: \n\n* Just get a bigger external or a DAS for the pint-sized cameraplex server and make it do triple-duty? Though I'm a little worried asking it to do more will overload the poor thing.\n\n* Recycle my old gaming PC and shove a bunch of drives in it? I have a Ryzen-based rig just sitting there gathering dust, waiting for a PSU (and a case that I haven't lost all the screws to) to become a PC again.\n\n* Buy an antique NAS box off ebay? There seem to be quite a few cheap ones.\n\n* Something else?", "author_fullname": "t2_dokx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Baby's first NAS, or what's the best way to properly hoard my data on the cheap?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150m13w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689452645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! The drives on my PCs are starting to fill with stuff I just don&amp;#39;t want to delete, so I&amp;#39;m looking to consolidate my data to something central that I can access from any of the various devices in the house. There&amp;#39;s a lot of data on random drives lying around too, that should probably get moved into one location.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done a but of googling but I&amp;#39;m new to this sort of thing, so I was wondering what you&amp;#39;d suggest.&lt;br/&gt;\nMore important than anything else is cheap - I really don&amp;#39;t want to be spending $4-500+ on this if I don&amp;#39;t have to.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m planning on using it for:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Security camera storage. Right now I&amp;#39;ve a book-sized Windows office pc repurposed as a BlueIris server handling this and shunting any clip the software finds interesting to an external drive for storage. I may add more than the single camera at some point and will likely need more storage as a result.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Plex: The baby-server has been handling this, broadcasting to the various TVs in the house, though I don&amp;#39;t have a huge collection of stuff.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Getting the family&amp;#39;s data out of the half-dozen external drives that sit in a closet so I don&amp;#39;t have to deal with the annual game of &amp;#39;please dig through all our drives so I can find that one photo that was scanned 12 years ago&amp;#39;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Centralizing my own data like 3d print files somewhere I can find them, being able to load the file on the printer without having to walk between computers would be nice&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Secondary/external Steam library so I don&amp;#39;t have to download every game 2-3 times&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I am apparently physically incapable of deleting any video game screenshot I take&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Maybe a home minecraft server if I&amp;#39;m feeling adventurous&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To that end, should I: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Just get a bigger external or a DAS for the pint-sized cameraplex server and make it do triple-duty? Though I&amp;#39;m a little worried asking it to do more will overload the poor thing.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Recycle my old gaming PC and shove a bunch of drives in it? I have a Ryzen-based rig just sitting there gathering dust, waiting for a PSU (and a case that I haven&amp;#39;t lost all the screws to) to become a PC again.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Buy an antique NAS box off ebay? There seem to be quite a few cheap ones.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Something else?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150m13w", "is_robot_indexable": true, "report_reasons": null, "author": "lol-science", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150m13w/babys_first_nas_or_whats_the_best_way_to_properly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150m13w/babys_first_nas_or_whats_the_best_way_to_properly/", "subreddit_subscribers": 692832, "created_utc": 1689452645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My work has a machine which saves data files to a connected desktop, and also has a direct usb port for connecting to hard drives as well. I'm looking for some network connected drive that could receive files via USB connection from the machine/computer, and simultaneously upload them to a personal cloud that can be accessed in real time from home. Is it possible to do this without connecting such a drive directly to a router but instead wirelessly to my work wifi network? I don't have ready access to a router at my work, and I would prefer not to use direct wall ethernet.\n\nI'd prefers something with minimal required storage space, the files in question are not large and so I'm not super concerned about having the optimal connection- just so long as the drive immediately puts the files on the cloud once they're transferred from the machine.", "author_fullname": "t2_ga8ehf2v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using NAS with wireless network connection as opposed to direct connection to router", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150k2e1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689447717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My work has a machine which saves data files to a connected desktop, and also has a direct usb port for connecting to hard drives as well. I&amp;#39;m looking for some network connected drive that could receive files via USB connection from the machine/computer, and simultaneously upload them to a personal cloud that can be accessed in real time from home. Is it possible to do this without connecting such a drive directly to a router but instead wirelessly to my work wifi network? I don&amp;#39;t have ready access to a router at my work, and I would prefer not to use direct wall ethernet.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d prefers something with minimal required storage space, the files in question are not large and so I&amp;#39;m not super concerned about having the optimal connection- just so long as the drive immediately puts the files on the cloud once they&amp;#39;re transferred from the machine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150k2e1", "is_robot_indexable": true, "report_reasons": null, "author": "fkatenn", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150k2e1/using_nas_with_wireless_network_connection_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150k2e1/using_nas_with_wireless_network_connection_as/", "subreddit_subscribers": 692832, "created_utc": 1689447717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "3-2-1 backup strategy. They're all\\* promoting it. Only, most of us aren't businesses with tape drives, so the only strategy there is to go Cloud, which conveniently solves the \"1\" for off-site, too. B-B-But why?\n\nI was planning two copies on-site: NAS and chonky backup HDDs, and then rotating those chonky HDDs with an \"off-site\" stash at my parent's or brother's.\n\nDoes this satisfy the 3-2-1 strategy? Or are we concerning ourselves with EM-pulse attack that wipes &gt;! (snigger) !&lt; all three instances of my HDDs? Or, I suppose an encryption virus. In which case should I be looking into a ginormous pile of Blu-Ray discs, r-r-right? Like ... giiiiiinnnnoooorrrrmous!\n\ntl;dr I don't like Cloud back-up solutions for I have WAAAAAAY too much data and don't want to blow thousands-a-year on this. Plus, don't like them sifting through my data and am too lazy to wait patiently to encrypt terabyte upon terabyte of data. Help me overcome my addiction!", "author_fullname": "t2_gxodt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3-2-1 backup strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150g0dt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689437726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;3-2-1 backup strategy. They&amp;#39;re all* promoting it. Only, most of us aren&amp;#39;t businesses with tape drives, so the only strategy there is to go Cloud, which conveniently solves the &amp;quot;1&amp;quot; for off-site, too. B-B-But why?&lt;/p&gt;\n\n&lt;p&gt;I was planning two copies on-site: NAS and chonky backup HDDs, and then rotating those chonky HDDs with an &amp;quot;off-site&amp;quot; stash at my parent&amp;#39;s or brother&amp;#39;s.&lt;/p&gt;\n\n&lt;p&gt;Does this satisfy the 3-2-1 strategy? Or are we concerning ourselves with EM-pulse attack that wipes &amp;gt;! (snigger) !&amp;lt; all three instances of my HDDs? Or, I suppose an encryption virus. In which case should I be looking into a ginormous pile of Blu-Ray discs, r-r-right? Like ... giiiiiinnnnoooorrrrmous!&lt;/p&gt;\n\n&lt;p&gt;tl;dr I don&amp;#39;t like Cloud back-up solutions for I have WAAAAAAY too much data and don&amp;#39;t want to blow thousands-a-year on this. Plus, don&amp;#39;t like them sifting through my data and am too lazy to wait patiently to encrypt terabyte upon terabyte of data. Help me overcome my addiction!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150g0dt", "is_robot_indexable": true, "report_reasons": null, "author": "ara9ond", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150g0dt/321_backup_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150g0dt/321_backup_strategy/", "subreddit_subscribers": 692832, "created_utc": 1689437726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I want to get my first NAS server to store my media collection plus stream it to other devices without my PC. Collection includes stuff like movies, game copies and books, and streaming is mostly intended for movies up to 4K and books.\n\nI don\u2019t want to spend time maintaining DIY setup so I\u2019m leaning towards Synology NAS server 4-6 cases.\n\nI tried to ask around on what to pick and how to setup, but all I got is to stick to RAID1 Mirror system (I had bad experience losing media because of dead HDDs so better be safe now) and to keep one small SSD drive as a buffer to do most writing processes and preserve the HDDs longevity with mostly read-only.\n\nSo because of that I\u2019ve upped my requirements to 5-6 cases and actually leaning towards 6 case option since it\u2019s not that much more expensive, but with SSD buffer it means only 5 HDDs max and with RAID1 it must be even so 4 HDDs max. \n\nMaybe there\u2019re options on how to deal with it but keep using all 6 cases? Or there\u2019s something I misunderstood? Or maybe I should approach this from different angle?", "author_fullname": "t2_16fkyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noob wants to buy first NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150bzos", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689427459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I want to get my first NAS server to store my media collection plus stream it to other devices without my PC. Collection includes stuff like movies, game copies and books, and streaming is mostly intended for movies up to 4K and books.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t want to spend time maintaining DIY setup so I\u2019m leaning towards Synology NAS server 4-6 cases.&lt;/p&gt;\n\n&lt;p&gt;I tried to ask around on what to pick and how to setup, but all I got is to stick to RAID1 Mirror system (I had bad experience losing media because of dead HDDs so better be safe now) and to keep one small SSD drive as a buffer to do most writing processes and preserve the HDDs longevity with mostly read-only.&lt;/p&gt;\n\n&lt;p&gt;So because of that I\u2019ve upped my requirements to 5-6 cases and actually leaning towards 6 case option since it\u2019s not that much more expensive, but with SSD buffer it means only 5 HDDs max and with RAID1 it must be even so 4 HDDs max. &lt;/p&gt;\n\n&lt;p&gt;Maybe there\u2019re options on how to deal with it but keep using all 6 cases? Or there\u2019s something I misunderstood? Or maybe I should approach this from different angle?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150bzos", "is_robot_indexable": true, "report_reasons": null, "author": "KiRa937", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150bzos/noob_wants_to_buy_first_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150bzos/noob_wants_to_buy_first_nas/", "subreddit_subscribers": 692832, "created_utc": 1689427459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Current setup: Macbook M1 Pro connected via TB cable to a OWC Thunderbay 4 with 4x8TB drives in RAID5 which is using up 12TB of the available 24TB space. Speeds are okay at 500-600 MB/s read and write.  The RAID5 is backed up to a Synology DS918+ in the basement which then copies to an external 18TB HDD. Also backed up to BackBlaze.\n\nThe RAID5 is software RAID and I am now facing a $100/year 'subscription' to maintain the software through future Mac OS updates.\n\nSo now I'm looking for alternative storage that is not dependent on 3rd party software and hopefully offers better speeds. \n\nI had considered moving to NVMe drives (4x4TB) in a SPAN but worry about the data integrity of that option. Also my head was spinning after trying to figure out which enclosures would actually get me speeds over 700 MB/s without relying on RAID.  Also briefly looked at a TrueNAS but not sure of the speeds there and I know nothing of ZFS.\n\nGreatly appreciate any suggestions. My current SoftRAID license 'expires' 7/24 but really is only an issue when the next MacOS drops.\n\nThanks!", "author_fullname": "t2_nb9qkqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Photographer looking for alternative direct storage as move from OWC SoftRAID", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150fime", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689436516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Current setup: Macbook M1 Pro connected via TB cable to a OWC Thunderbay 4 with 4x8TB drives in RAID5 which is using up 12TB of the available 24TB space. Speeds are okay at 500-600 MB/s read and write.  The RAID5 is backed up to a Synology DS918+ in the basement which then copies to an external 18TB HDD. Also backed up to BackBlaze.&lt;/p&gt;\n\n&lt;p&gt;The RAID5 is software RAID and I am now facing a $100/year &amp;#39;subscription&amp;#39; to maintain the software through future Mac OS updates.&lt;/p&gt;\n\n&lt;p&gt;So now I&amp;#39;m looking for alternative storage that is not dependent on 3rd party software and hopefully offers better speeds. &lt;/p&gt;\n\n&lt;p&gt;I had considered moving to NVMe drives (4x4TB) in a SPAN but worry about the data integrity of that option. Also my head was spinning after trying to figure out which enclosures would actually get me speeds over 700 MB/s without relying on RAID.  Also briefly looked at a TrueNAS but not sure of the speeds there and I know nothing of ZFS.&lt;/p&gt;\n\n&lt;p&gt;Greatly appreciate any suggestions. My current SoftRAID license &amp;#39;expires&amp;#39; 7/24 but really is only an issue when the next MacOS drops.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150fime", "is_robot_indexable": true, "report_reasons": null, "author": "100Kinthebank", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150fime/photographer_looking_for_alternative_direct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150fime/photographer_looking_for_alternative_direct/", "subreddit_subscribers": 692832, "created_utc": 1689436516.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}