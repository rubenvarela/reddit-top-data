{"kind": "Listing", "data": {"after": "t3_151avoh", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Something like this could probably shift the paradigm of how we store files and create directories. Would you spend your free time organizing your files if you know that a simple search could get you exactly to what you need in a few seconds?\n\nIt's very similar to Spotify search, where you can type in part of the lyrics of a song and it will find you the song. Or in MacOS, you can search by text inside photos and it will grab all the images that contain that text (no more spending my weekends on meticulously tagging and organizing my screenshots folder).\n\nSo is there anything like that already out there that would achieve this especially on Windows?\n\n*Edit*: a local search engine ideally powered by LLMs which would search your entire local hard drive and find matches. LLM-powered means instead of searching using a very specific string of words, you'd be able to \"describe\" what you're looking for in your hard drive without mentioning the file name, tags, Metadata. \n\n```-- \"Find me that video where I was walking next to a river with ice cream in my hand\"```\n\nor \n\n```-- Can you look into my Obsidian notes and summarize all my notes that relate to concept XYZ. Also see if you can find any screenshots that I might have saved that might relate to this topic or check my offline YouTube video archive to see if you can find any snippets or talks that relate to this \"```", "author_fullname": "t2_3bnahjfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With all the AI hype and GPT stuff, are there already any tools/software that make searching and sorting files smarter and faster? Such as the MacOS search inside images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1511tpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": "", "subreddit_type": "public", "ups": 81, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689509621.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689499743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Something like this could probably shift the paradigm of how we store files and create directories. Would you spend your free time organizing your files if you know that a simple search could get you exactly to what you need in a few seconds?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s very similar to Spotify search, where you can type in part of the lyrics of a song and it will find you the song. Or in MacOS, you can search by text inside photos and it will grab all the images that contain that text (no more spending my weekends on meticulously tagging and organizing my screenshots folder).&lt;/p&gt;\n\n&lt;p&gt;So is there anything like that already out there that would achieve this especially on Windows?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit&lt;/em&gt;: a local search engine ideally powered by LLMs which would search your entire local hard drive and find matches. LLM-powered means instead of searching using a very specific string of words, you&amp;#39;d be able to &amp;quot;describe&amp;quot; what you&amp;#39;re looking for in your hard drive without mentioning the file name, tags, Metadata. &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;-- &amp;quot;Find me that video where I was walking next to a river with ice cream in my hand&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;or &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;-- Can you look into my Obsidian notes and summarize all my notes that relate to concept XYZ. Also see if you can find any screenshots that I might have saved that might relate to this topic or check my offline YouTube video archive to see if you can find any snippets or talks that relate to this &amp;quot;&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1511tpx", "is_robot_indexable": true, "report_reasons": null, "author": "egobamyasi", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1511tpx/with_all_the_ai_hype_and_gpt_stuff_are_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1511tpx/with_all_the_ai_hype_and_gpt_stuff_are_there/", "subreddit_subscribers": 692877, "created_utc": 1689499743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was reading an interesting study about 1.4 MILLION enterprise SSDs, the data was collected via their enterprise monitoring software for 2.5 years (via weekly telemetry data), and was published in 2020.\n\n* Study: [https://www.usenix.org/system/files/fast20-maneas.pdf](https://www.usenix.org/system/files/fast20-maneas.pdf)\n* Official Article (with video): [https://www.usenix.org/conference/fast20/presentation/maneas](https://www.usenix.org/conference/fast20/presentation/maneas)\n* Another Article: [https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/](https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/)\n\nThe study found interesting things, such as: Always update your firmware, because you will massively reduce the amount of data loss over time if you have the latest firmware.\n\n&amp;#x200B;\n\n**But the most interesting column is on page 8 of the PDF, middle graph \"(b) 3D-TLC drives\".**\n\nGroup \"A\" of that graph refers to all kinds of \"total failures\" of the drive (explained on page 5). There are two types of \"total failures\": Either that the drive reported actual on-board DRAM errors (ECC errors in the RAM itself) meaning the hardware was broken and unable to read data properly anymore, OR that the drive became completely non-responsive and vanished from the system. The most serious failures.\n\nSo, on page 8's graphs, they show that 800GB-3800GB 3D-TLC SSDs had a very low \"total drive failure\" rate. But as soon as you got to 8000GB and 15000GB, the drives had a MASSIVE increase in risk that the entire drive has hardware errors and dies, becomes non-responsive, etc.\n\n&amp;#x200B;\n\nHere are some relevant quotes about how larger capacities have lower reliability:\n\n&amp;#x200B;\n\n* \"We also looked for differences in the reasons for replacement between smaller and larger capacity drives and made an interesting observation: for the largest capacity drives, the rate of predictable failures (S.M.A.R.T. data) is lower than for smaller capacity drives. In contrast, the most severe failure reason, i.e., an unresponsive drive, occurs at a much higher rate for the larger capacity drives than for the smaller capacity drives.\"\n* \"Among the eMLC drives, the 3800GB and 3840GB capacities, and among the 3D-TLC drives, the 8TB and 15TB capacities, have very high rates of replacement due to an unresponsive drive, compared to smaller capacities. They also have a lower rate of replacements due to predictive failures. This means that the replacement rate associated with high capacity drives is not only bigger, but also has potentially more severe consequences.\"\n* \"It may be possible that the severe failures and unpredictability of such failures is an artifact of the larger DRAM footprint associated with large flash capacity, rather than the flash capacity itself. Potential for such impact could be mitigated by upcoming architectures such as Zoned Storage (ZNS) \\[4, 30\\] that obviate the need for large Flash Translation Layer (FTL) tables in DRAM and consequently reducing the DRAM footprint.\"\n* Summary: \"Drives with very large capacities not only see a higher replacement rate overall, but also see more severe failures and fewer of the (more benign) predictive failures.\"\n\n&amp;#x200B;\n\nI have transcribed the MEDIAN values of the 3D-TLC \"total drive failure\" rates (as a percentage of all drives in operation) as closely as I could from the graphs:\n\n&amp;#x200B;\n\n* Annual failure rates at category \"A\" (highest severity), as a percentage of all SSDs of that particular size and NAND type (3D-TLC):\n* 800 GB: 0.01875% (0.1875 drives per 1000 die every year)\n* 960 GB: 0.025% (0.25 drives per 1000 die every year)\n* 1600 GB: 0.0055% (0.055 drives per 1000 die every year)\n* 3800 GB: 0.02625% (0.2625 drives per 1000 die every year)\n* 8000 GB: 0.2275% (2.275 drives per 1000 die every year)\n* 15000 GB: 0.1625% (1.625 drives per 1000 die every year)\n* In summary: 8 TB+ SSDs have roughly 10x more \"total drive death\" events than smaller SSDs. And they have less S.M.A.R.T. warning signals before death, meaning the deaths are less predictable.\n\n&amp;#x200B;\n\nAs a bonus fact, they also studied the failure rate related to age:\n\n* \"We observe an unexpectedly long period of infant mortality with a shape that differs from the common \u201cbathtub\u201d model often used in reliability theory. The bathtub model assumes a short initial period of high failure rates, which then quickly drops.\"\n* \"Instead, we observe for both 3D-TLC and eMLC drives, a long period (12\u201315 months) of increasing failure rates, followed by a lengthy period (another 6\u201312 months) of slowly decreasing failure rates, before rates finally stabilize. That means that, given typical drive lifetimes of 5 years, drives spend 20-40% of their life in infant mortality.\"\n* In short, the \"infant mortality\" rate of SSDs is roughly 27 months (slightly over 2 years), before you can say \"this drive is safe, it won't suddenly die due to hardware failure\".\n* After those 27 months, they say that almost all failures are due to predictable errors that show up in S.M.A.R.T. data, such as NAND degradation/read errors.\n* Although keep in mind that the study didn't look at super long term data (5+ years) since this is enterprise, where drives are always replaced within a few years of deployment. So it is likely that a bunch of \"old age\" deaths would creep up at consumer usage where SSDs are kept for 5+ years.\n\n&amp;#x200B;\n\nSo... I am already torn between buying a 4 TB vs 8 TB Samsung PM9A3 enterprise drive (U.2 connector 2.5\"), and this study make me even more confused...\n\n[https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/](https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/)\n\n&amp;#x200B;\n\nI basically have fear of missing out. The 4 TB drive \"might not be big enough and then I have to buy yet another drive\", and the 8 TB drive is only 65% more expensive for double the capacity. It's a really good deal right now.\n\nOn the other hand, 8 TB is a ton of data to lose if the entire drive just completely dies (I only have redundant backups for the most important data), and if 8 TB+ drives still have vastly more catastrophic hardware failures, well, then that's bad...\n\nThoughts?", "author_fullname": "t2_dmkidisb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enterprise SSD reliability: Does size still matter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150orlb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689515674.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689459432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading an interesting study about 1.4 MILLION enterprise SSDs, the data was collected via their enterprise monitoring software for 2.5 years (via weekly telemetry data), and was published in 2020.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Study: &lt;a href=\"https://www.usenix.org/system/files/fast20-maneas.pdf\"&gt;https://www.usenix.org/system/files/fast20-maneas.pdf&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Official Article (with video): &lt;a href=\"https://www.usenix.org/conference/fast20/presentation/maneas\"&gt;https://www.usenix.org/conference/fast20/presentation/maneas&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Another Article: &lt;a href=\"https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/\"&gt;https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The study found interesting things, such as: Always update your firmware, because you will massively reduce the amount of data loss over time if you have the latest firmware.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;But the most interesting column is on page 8 of the PDF, middle graph &amp;quot;(b) 3D-TLC drives&amp;quot;.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Group &amp;quot;A&amp;quot; of that graph refers to all kinds of &amp;quot;total failures&amp;quot; of the drive (explained on page 5). There are two types of &amp;quot;total failures&amp;quot;: Either that the drive reported actual on-board DRAM errors (ECC errors in the RAM itself) meaning the hardware was broken and unable to read data properly anymore, OR that the drive became completely non-responsive and vanished from the system. The most serious failures.&lt;/p&gt;\n\n&lt;p&gt;So, on page 8&amp;#39;s graphs, they show that 800GB-3800GB 3D-TLC SSDs had a very low &amp;quot;total drive failure&amp;quot; rate. But as soon as you got to 8000GB and 15000GB, the drives had a MASSIVE increase in risk that the entire drive has hardware errors and dies, becomes non-responsive, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here are some relevant quotes about how larger capacities have lower reliability:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;We also looked for differences in the reasons for replacement between smaller and larger capacity drives and made an interesting observation: for the largest capacity drives, the rate of predictable failures (S.M.A.R.T. data) is lower than for smaller capacity drives. In contrast, the most severe failure reason, i.e., an unresponsive drive, occurs at a much higher rate for the larger capacity drives than for the smaller capacity drives.&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;Among the eMLC drives, the 3800GB and 3840GB capacities, and among the 3D-TLC drives, the 8TB and 15TB capacities, have very high rates of replacement due to an unresponsive drive, compared to smaller capacities. They also have a lower rate of replacements due to predictive failures. This means that the replacement rate associated with high capacity drives is not only bigger, but also has potentially more severe consequences.&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;It may be possible that the severe failures and unpredictability of such failures is an artifact of the larger DRAM footprint associated with large flash capacity, rather than the flash capacity itself. Potential for such impact could be mitigated by upcoming architectures such as Zoned Storage (ZNS) [4, 30] that obviate the need for large Flash Translation Layer (FTL) tables in DRAM and consequently reducing the DRAM footprint.&amp;quot;&lt;/li&gt;\n&lt;li&gt;Summary: &amp;quot;Drives with very large capacities not only see a higher replacement rate overall, but also see more severe failures and fewer of the (more benign) predictive failures.&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have transcribed the MEDIAN values of the 3D-TLC &amp;quot;total drive failure&amp;quot; rates (as a percentage of all drives in operation) as closely as I could from the graphs:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Annual failure rates at category &amp;quot;A&amp;quot; (highest severity), as a percentage of all SSDs of that particular size and NAND type (3D-TLC):&lt;/li&gt;\n&lt;li&gt;800 GB: 0.01875% (0.1875 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;960 GB: 0.025% (0.25 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;1600 GB: 0.0055% (0.055 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;3800 GB: 0.02625% (0.2625 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;8000 GB: 0.2275% (2.275 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;15000 GB: 0.1625% (1.625 drives per 1000 die every year)&lt;/li&gt;\n&lt;li&gt;In summary: 8 TB+ SSDs have roughly 10x more &amp;quot;total drive death&amp;quot; events than smaller SSDs. And they have less S.M.A.R.T. warning signals before death, meaning the deaths are less predictable.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As a bonus fact, they also studied the failure rate related to age:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;We observe an unexpectedly long period of infant mortality with a shape that differs from the common \u201cbathtub\u201d model often used in reliability theory. The bathtub model assumes a short initial period of high failure rates, which then quickly drops.&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;Instead, we observe for both 3D-TLC and eMLC drives, a long period (12\u201315 months) of increasing failure rates, followed by a lengthy period (another 6\u201312 months) of slowly decreasing failure rates, before rates finally stabilize. That means that, given typical drive lifetimes of 5 years, drives spend 20-40% of their life in infant mortality.&amp;quot;&lt;/li&gt;\n&lt;li&gt;In short, the &amp;quot;infant mortality&amp;quot; rate of SSDs is roughly 27 months (slightly over 2 years), before you can say &amp;quot;this drive is safe, it won&amp;#39;t suddenly die due to hardware failure&amp;quot;.&lt;/li&gt;\n&lt;li&gt;After those 27 months, they say that almost all failures are due to predictable errors that show up in S.M.A.R.T. data, such as NAND degradation/read errors.&lt;/li&gt;\n&lt;li&gt;Although keep in mind that the study didn&amp;#39;t look at super long term data (5+ years) since this is enterprise, where drives are always replaced within a few years of deployment. So it is likely that a bunch of &amp;quot;old age&amp;quot; deaths would creep up at consumer usage where SSDs are kept for 5+ years.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So... I am already torn between buying a 4 TB vs 8 TB Samsung PM9A3 enterprise drive (U.2 connector 2.5&amp;quot;), and this study make me even more confused...&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/\"&gt;https://www.zdnet.com/article/ssd-reliability-in-the-enterprise/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I basically have fear of missing out. The 4 TB drive &amp;quot;might not be big enough and then I have to buy yet another drive&amp;quot;, and the 8 TB drive is only 65% more expensive for double the capacity. It&amp;#39;s a really good deal right now.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, 8 TB is a ton of data to lose if the entire drive just completely dies (I only have redundant backups for the most important data), and if 8 TB+ drives still have vastly more catastrophic hardware failures, well, then that&amp;#39;s bad...&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "150orlb", "is_robot_indexable": true, "report_reasons": null, "author": "GoastRiter", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150orlb/enterprise_ssd_reliability_does_size_still_matter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150orlb/enterprise_ssd_reliability_does_size_still_matter/", "subreddit_subscribers": 692877, "created_utc": 1689459432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 12TB (ST12000NM001G) and 2TB (ST2000LX001) HDD in my PC. The 12TB I bought new last October, while the 2TB I bought new around 4 years ago. The 2TB drive was first used for around 3 years in my PS4 for gaming.\r\n\r\nThis 1st July, CrystalDiskInfo is reporting Caution for the 12TB drive. This is because of 100 reallocated sectors. When I searched online about this, I found that this is something that happens, and it is okay to keep using the drive unless the number keeps going up. However, some expressed that anything other than 0 is a risk and the drive must be replaced.\r\n\r\nThe drive is fairly new and is not used constantly. When investigating further I found the following:\r\n\r\nThe 12TB drive has 100 current, 100 worst, 10 threshold, and 000000000038 raw value in CrystalDiskInfo for Reallocated Sectores Count. It is marked as yellow. However, the 2TB drive has 100 current, 100 worst, 36 threshold, and 000000000000 raw value in CrystalDiskInfo for Reallocated Sectores Count and marked as blue. How is the current and worst value the same with a different and all-zero raw value? How is it also not yellow if the other drive has the same current value and yellow?\r\n\r\nThings get even weirder when I check the same values with Samsung Magician. The ECC Error Rate is critical for the 12TB drive in Samsung magician but good in CrystalDiskInfo. The values are 12/2/0 for Current/Worst/Threshold and EE034D raw.\r\n\r\nCan someone help me understand why the CrystalDiskInfo is reporting Good and Caution for the same value and why Samsung Magician has a different opinion to the values?\r\n\r\nThanks", "author_fullname": "t2_2dhcdz13", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interpreting SMART Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15163g5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689513493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 12TB (ST12000NM001G) and 2TB (ST2000LX001) HDD in my PC. The 12TB I bought new last October, while the 2TB I bought new around 4 years ago. The 2TB drive was first used for around 3 years in my PS4 for gaming.&lt;/p&gt;\n\n&lt;p&gt;This 1st July, CrystalDiskInfo is reporting Caution for the 12TB drive. This is because of 100 reallocated sectors. When I searched online about this, I found that this is something that happens, and it is okay to keep using the drive unless the number keeps going up. However, some expressed that anything other than 0 is a risk and the drive must be replaced.&lt;/p&gt;\n\n&lt;p&gt;The drive is fairly new and is not used constantly. When investigating further I found the following:&lt;/p&gt;\n\n&lt;p&gt;The 12TB drive has 100 current, 100 worst, 10 threshold, and 000000000038 raw value in CrystalDiskInfo for Reallocated Sectores Count. It is marked as yellow. However, the 2TB drive has 100 current, 100 worst, 36 threshold, and 000000000000 raw value in CrystalDiskInfo for Reallocated Sectores Count and marked as blue. How is the current and worst value the same with a different and all-zero raw value? How is it also not yellow if the other drive has the same current value and yellow?&lt;/p&gt;\n\n&lt;p&gt;Things get even weirder when I check the same values with Samsung Magician. The ECC Error Rate is critical for the 12TB drive in Samsung magician but good in CrystalDiskInfo. The values are 12/2/0 for Current/Worst/Threshold and EE034D raw.&lt;/p&gt;\n\n&lt;p&gt;Can someone help me understand why the CrystalDiskInfo is reporting Good and Caution for the same value and why Samsung Magician has a different opinion to the values?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15163g5", "is_robot_indexable": true, "report_reasons": null, "author": "ISuckAtNames387", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15163g5/interpreting_smart_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15163g5/interpreting_smart_data/", "subreddit_subscribers": 692877, "created_utc": 1689513493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for some advice on how to revamp my backups. I've already went down several extremely weird paths but I think it's time to give up and get some help.\n\nMy machines look like this:\n1. TrueNAS (Source) : ~48TB\n2. Windows (\"GUI\" + Local Backup) : 3TB\n3. Orange Pi 5+ (Offsite Backup) : 1TB\n4. Raspberry Pi 4B (Offsite Backup) : 1TB\n5. Mango Pi Pro (Usage TBD) : ???\n6. Storj (Cloud Backup) : 150GB x2\n7. Oracle Cloud (Cloud Backup) : 150GB x2\n\nI'm looking to do partial backups since I can live without most of the data, but I really want to keep about 1TB of it safe from multiple copies going down simultaneously. I had originally planned on doing a PULL configuration from each target machine with read only access, so if TrueNAS gets compromised it doesn't matter because it barely knows the target machines exist. If one of the target machines gets compromised, it only has read access so it doesn't matter much either. But then maintenance and reporting gets a bit squirrely so that's not great either.... But I think a PUSH configuration on TrueNAS with a locked down user should achieve mostly the same effect. \n\nThe target machines (2?, 3, 4, 7) can run ZFS so in the event TrueNAS becomes compromised it can overwrite the backup folder, but that'll just fill up the drive while the snapshots hosted on the target machines are still intact. If the target machines become compromised then they don't have access to TrueNAS at all. I can't really do snapshots on Storj, but they're freebie accounts so I wasn't going to rely on them anyway.\n\nThis seems like a decent compromise between security and ease of use. I can monitor the status of my backups from a central location (TrueNAS's UI) without SSH'ing into half a dozen machines or figuring out grafana / prometheus. Also if the backup parameters change (what goes where, ignore files X, Y, Z, etc) then I can do that from one location as well. Also I can save TrueNAS's single configuration easily without worrying about which individual machines have which version of a backup script.\n\nI'm trying to avoid dedicated backup programs because I don't trust them or myself to set them up. I've been using Kopia which is easily accessible and intuitive, but I've also had it silently lose a chunk randomly corrupting the repository with literally no way of knowing from the GUI. There are a bunch of other programs out there like Dupliacy, Duplicati, restic, bacula but they all have their downsides. Some of them don't have a GUI for windows or are WAY too complicated which is a nogo for an idiot user like me. Or they just don't have some fairly basic features like backing up from a network location (Veaam windows...) But you know what hasn't failed me? ZFS. But since I don't want to replicate entire datasets everywhere and not every location is capable of running ZFS, that rules out ZFS send / recv. The rsync task probably works but I know for sure cloud sync works, so that is probably what I'll go with.\n\nSo to recap;\n1. TrueNAS -&gt; Cloud Sync Task -&gt; Bunch of storage -&gt; ZFS snapshot\n2. The accounts TrueNAS has access to will have no privleges outside of the backup folder\n\nDoes this make sense? Am I missing something? Thanks in advance!", "author_fullname": "t2_upalof7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to redo some backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1515ivg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689511908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for some advice on how to revamp my backups. I&amp;#39;ve already went down several extremely weird paths but I think it&amp;#39;s time to give up and get some help.&lt;/p&gt;\n\n&lt;p&gt;My machines look like this:\n1. TrueNAS (Source) : ~48TB\n2. Windows (&amp;quot;GUI&amp;quot; + Local Backup) : 3TB\n3. Orange Pi 5+ (Offsite Backup) : 1TB\n4. Raspberry Pi 4B (Offsite Backup) : 1TB\n5. Mango Pi Pro (Usage TBD) : ???\n6. Storj (Cloud Backup) : 150GB x2\n7. Oracle Cloud (Cloud Backup) : 150GB x2&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to do partial backups since I can live without most of the data, but I really want to keep about 1TB of it safe from multiple copies going down simultaneously. I had originally planned on doing a PULL configuration from each target machine with read only access, so if TrueNAS gets compromised it doesn&amp;#39;t matter because it barely knows the target machines exist. If one of the target machines gets compromised, it only has read access so it doesn&amp;#39;t matter much either. But then maintenance and reporting gets a bit squirrely so that&amp;#39;s not great either.... But I think a PUSH configuration on TrueNAS with a locked down user should achieve mostly the same effect. &lt;/p&gt;\n\n&lt;p&gt;The target machines (2?, 3, 4, 7) can run ZFS so in the event TrueNAS becomes compromised it can overwrite the backup folder, but that&amp;#39;ll just fill up the drive while the snapshots hosted on the target machines are still intact. If the target machines become compromised then they don&amp;#39;t have access to TrueNAS at all. I can&amp;#39;t really do snapshots on Storj, but they&amp;#39;re freebie accounts so I wasn&amp;#39;t going to rely on them anyway.&lt;/p&gt;\n\n&lt;p&gt;This seems like a decent compromise between security and ease of use. I can monitor the status of my backups from a central location (TrueNAS&amp;#39;s UI) without SSH&amp;#39;ing into half a dozen machines or figuring out grafana / prometheus. Also if the backup parameters change (what goes where, ignore files X, Y, Z, etc) then I can do that from one location as well. Also I can save TrueNAS&amp;#39;s single configuration easily without worrying about which individual machines have which version of a backup script.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to avoid dedicated backup programs because I don&amp;#39;t trust them or myself to set them up. I&amp;#39;ve been using Kopia which is easily accessible and intuitive, but I&amp;#39;ve also had it silently lose a chunk randomly corrupting the repository with literally no way of knowing from the GUI. There are a bunch of other programs out there like Dupliacy, Duplicati, restic, bacula but they all have their downsides. Some of them don&amp;#39;t have a GUI for windows or are WAY too complicated which is a nogo for an idiot user like me. Or they just don&amp;#39;t have some fairly basic features like backing up from a network location (Veaam windows...) But you know what hasn&amp;#39;t failed me? ZFS. But since I don&amp;#39;t want to replicate entire datasets everywhere and not every location is capable of running ZFS, that rules out ZFS send / recv. The rsync task probably works but I know for sure cloud sync works, so that is probably what I&amp;#39;ll go with.&lt;/p&gt;\n\n&lt;p&gt;So to recap;\n1. TrueNAS -&amp;gt; Cloud Sync Task -&amp;gt; Bunch of storage -&amp;gt; ZFS snapshot\n2. The accounts TrueNAS has access to will have no privleges outside of the backup folder&lt;/p&gt;\n\n&lt;p&gt;Does this make sense? Am I missing something? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "vTrueNAS 72TB / Hyper-V", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1515ivg", "is_robot_indexable": true, "report_reasons": null, "author": "Party_9001", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1515ivg/looking_to_redo_some_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1515ivg/looking_to_redo_some_backups/", "subreddit_subscribers": 692877, "created_utc": 1689511908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone! I've recently been looking all over the internet for an xml dump of fandom (formerly known as wikia) wikis from the years 2016 to 2018. I've seen dumps from 2015 and 2020, but the 2018 dump doesn't seem to have the specific wiki I'm looking for. Where would I look for more information?\n\n&amp;#x200B;", "author_fullname": "t2_21qnqkln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to Find Website Dump", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150qz0n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689465126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! I&amp;#39;ve recently been looking all over the internet for an xml dump of fandom (formerly known as wikia) wikis from the years 2016 to 2018. I&amp;#39;ve seen dumps from 2015 and 2020, but the 2018 dump doesn&amp;#39;t seem to have the specific wiki I&amp;#39;m looking for. Where would I look for more information?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150qz0n", "is_robot_indexable": true, "report_reasons": null, "author": "TemporarilyResolute", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150qz0n/trying_to_find_website_dump/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150qz0n/trying_to_find_website_dump/", "subreddit_subscribers": 692877, "created_utc": 1689465126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Seems it would be wise to hoard programs/files that will be useful in offline scenarios. Something that converts imperial to metric for example, or common tables and charts for things like electrical and plumbing come to mind. Wikipedia mirror makes good sense. I've grabbed mauals for every tool and appliance I own. \n\nHayes repair manuals for cars take some digging but are available, the question is whether to grab only the cars you have, or all that are available? I've only bothered with certain brands but I can see an argument for downloading everything. \n\nPersonally I found some of the compilations like \"the ark\" to be full of junk. Open to suggestions for anything I mentioned above and more", "author_fullname": "t2_ay7tp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Programs to hoard for offline computers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_151btrm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689527960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems it would be wise to hoard programs/files that will be useful in offline scenarios. Something that converts imperial to metric for example, or common tables and charts for things like electrical and plumbing come to mind. Wikipedia mirror makes good sense. I&amp;#39;ve grabbed mauals for every tool and appliance I own. &lt;/p&gt;\n\n&lt;p&gt;Hayes repair manuals for cars take some digging but are available, the question is whether to grab only the cars you have, or all that are available? I&amp;#39;ve only bothered with certain brands but I can see an argument for downloading everything. &lt;/p&gt;\n\n&lt;p&gt;Personally I found some of the compilations like &amp;quot;the ark&amp;quot; to be full of junk. Open to suggestions for anything I mentioned above and more&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "124TB ZFS and Synology + Cloud", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "151btrm", "is_robot_indexable": true, "report_reasons": null, "author": "erik530195", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/151btrm/programs_to_hoard_for_offline_computers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/151btrm/programs_to_hoard_for_offline_computers/", "subreddit_subscribers": 692877, "created_utc": 1689527960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a number of laptop backups, very old (oldest ~8-9 yrs back) laptop backups, which were taken at random dates and a lot of the backup just repeats itself (~195 GB total). Basically a copy paste of most of the folders from the laptop to a harddrive at different points of time.\n\nI was going through the backups, and found a lot of photos, which I have never seen. I would love to find all such \"lost\" photos in these backups. And a way to de-dup the duplicate ones (there will be duplicates)\n\nThe other documents in these backups are pretty much useless for me, apart from the photos. Is there a quick way to extract photos from these huge backups?\n\nI tried searching for a software which could do this, but was unable to find one.\n\nI have a feeling that this might be a common use-case and that there must be a solution outside, just that I don't have the proper key-word to search with.\n\nAny help is appreciated!\n\n\n\nPS:\n- I also tried writing a small script which could extract photos (recursively search all files, check if image, move) but that gives me very very huge list of images (I think they are internal laptop/windows images, and are of no use to me). \n- Is there a good way of doing this? I could also filter on the image size, but these backups also contain a lot of small images aswell - whatsapp images, screenshots, etc. which are small in size too (so this only won't work).\n- One more disadvantage is - the script is very slow (or atleast I think that there must be better optimized way of doing this).\n- I would still not know if what I am writing will cover all the photos in the disk. Basically will have to spend a lot of time testing, running, etc.", "author_fullname": "t2_blvc1ovuy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting all photos from a laptop backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15108wx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689496045.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689494176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a number of laptop backups, very old (oldest ~8-9 yrs back) laptop backups, which were taken at random dates and a lot of the backup just repeats itself (~195 GB total). Basically a copy paste of most of the folders from the laptop to a harddrive at different points of time.&lt;/p&gt;\n\n&lt;p&gt;I was going through the backups, and found a lot of photos, which I have never seen. I would love to find all such &amp;quot;lost&amp;quot; photos in these backups. And a way to de-dup the duplicate ones (there will be duplicates)&lt;/p&gt;\n\n&lt;p&gt;The other documents in these backups are pretty much useless for me, apart from the photos. Is there a quick way to extract photos from these huge backups?&lt;/p&gt;\n\n&lt;p&gt;I tried searching for a software which could do this, but was unable to find one.&lt;/p&gt;\n\n&lt;p&gt;I have a feeling that this might be a common use-case and that there must be a solution outside, just that I don&amp;#39;t have the proper key-word to search with.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated!&lt;/p&gt;\n\n&lt;p&gt;PS:\n- I also tried writing a small script which could extract photos (recursively search all files, check if image, move) but that gives me very very huge list of images (I think they are internal laptop/windows images, and are of no use to me). \n- Is there a good way of doing this? I could also filter on the image size, but these backups also contain a lot of small images aswell - whatsapp images, screenshots, etc. which are small in size too (so this only won&amp;#39;t work).\n- One more disadvantage is - the script is very slow (or atleast I think that there must be better optimized way of doing this).\n- I would still not know if what I am writing will cover all the photos in the disk. Basically will have to spend a lot of time testing, running, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15108wx", "is_robot_indexable": true, "report_reasons": null, "author": "MeasurementSad6631", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15108wx/extracting_all_photos_from_a_laptop_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15108wx/extracting_all_photos_from_a_laptop_backup/", "subreddit_subscribers": 692877, "created_utc": 1689494176.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have too much digital stuff. I am deleting everything I don\u2019t need. I\u2019ve about 10 years worth of stuff to go through, and it will take a long time. My fear of deleting anything first happened when my first computer got a virus and I lost everything + losing stuff due to files becoming corrupt. Even though my \u2018hoarding\u2019 is pretty mild, I don\u2019t like having to keep stuff \u2018just in case.\u2019 Especially if I genuinely don\u2019t need it anymore. \n\nMy digital clutter clutters my mind. If I see something and either don\u2019t need it or don\u2019t see myself reopening the file, I am getting rid of it. It makes me feel uncomfortable just deleting shit, but I have to delete and forget about it. I signed up to lots of accounts and emails as well, which are all in the process of getting deleted.\n\nYou guys might laugh at this but I have only around 2-5 TB worth of stuff, which might seem like nothing around here, but I find it overwhelming and extremely burdensome. Respect to all of you who are able to manage all that, jesus.\n\nEdit: Thanks guys, I didn\u2019t even know my post was approved because it got rejected at first due to my account being new. I really appreciate your comments and advice. It\u2019s great to relate to you all.", "author_fullname": "t2_d0lx00uz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am tired", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150x71e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689521066.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689483892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have too much digital stuff. I am deleting everything I don\u2019t need. I\u2019ve about 10 years worth of stuff to go through, and it will take a long time. My fear of deleting anything first happened when my first computer got a virus and I lost everything + losing stuff due to files becoming corrupt. Even though my \u2018hoarding\u2019 is pretty mild, I don\u2019t like having to keep stuff \u2018just in case.\u2019 Especially if I genuinely don\u2019t need it anymore. &lt;/p&gt;\n\n&lt;p&gt;My digital clutter clutters my mind. If I see something and either don\u2019t need it or don\u2019t see myself reopening the file, I am getting rid of it. It makes me feel uncomfortable just deleting shit, but I have to delete and forget about it. I signed up to lots of accounts and emails as well, which are all in the process of getting deleted.&lt;/p&gt;\n\n&lt;p&gt;You guys might laugh at this but I have only around 2-5 TB worth of stuff, which might seem like nothing around here, but I find it overwhelming and extremely burdensome. Respect to all of you who are able to manage all that, jesus.&lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks guys, I didn\u2019t even know my post was approved because it got rejected at first due to my account being new. I really appreciate your comments and advice. It\u2019s great to relate to you all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "150x71e", "is_robot_indexable": true, "report_reasons": null, "author": "OkPoet6127", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150x71e/i_am_tired/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150x71e/i_am_tired/", "subreddit_subscribers": 692877, "created_utc": 1689483892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm having trouble **only** wgetting this URL : [https://forum.spacehey.com/topic?id=3959](https://forum.spacehey.com/topic?id=3959) and all the links that branch out of it, only 1 level away from the link.\n\n    When I run wget -e robots=off --recursive -np -k --html-extension \"https://forum.spacehey.com/topic?id=3959\"\n\nit starts downloading all of the forum pages and all the user profiles, even those that did not participate in that specific thread. I just want \\`topic?id=3959  \n to be downloaded, plus the user profiles or links that might branch out from the link, but no deeper than 1 level. Not sure if I'm explaining myself correctly.", "author_fullname": "t2_2rewrxo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with Wget", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150q5z7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689462973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m having trouble &lt;strong&gt;only&lt;/strong&gt; wgetting this URL : &lt;a href=\"https://forum.spacehey.com/topic?id=3959\"&gt;https://forum.spacehey.com/topic?id=3959&lt;/a&gt; and all the links that branch out of it, only 1 level away from the link.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;When I run wget -e robots=off --recursive -np -k --html-extension &amp;quot;https://forum.spacehey.com/topic?id=3959&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;it starts downloading all of the forum pages and all the user profiles, even those that did not participate in that specific thread. I just want `topic?id=3959&lt;br/&gt;\n to be downloaded, plus the user profiles or links that might branch out from the link, but no deeper than 1 level. Not sure if I&amp;#39;m explaining myself correctly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?auto=webp&amp;s=3857ed03a465a31599b65c323030194450e8bc09", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=722e416e8ee490729a17976e9f4bbe7c3e078871", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f35418a5521952a5db5b0452b454e3a32b03a46", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d16b9e2c1149bb5979da229871a45ec1d23d7dfc", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=536746646c1dded870ef8ae904c9414d295e6926", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=acee12e384beec774f373142492cf49d80ee2300", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/0y8CB3eptKH-IvGYyo1L3CsMuqXRNLabvt1qH36-QxU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8453b2a3662b55ed0db129bc72c0d660403065ee", "width": 1080, "height": 540}], "variants": {}, "id": "ztoUwoXJpe58a61I-q3Dg8eJzueXuf-NZZ1WQ20Kpgo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150q5z7", "is_robot_indexable": true, "report_reasons": null, "author": "iPodClassic7", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150q5z7/need_help_with_wget/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150q5z7/need_help_with_wget/", "subreddit_subscribers": 692877, "created_utc": 1689462973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have roughly 14 drives with 5-8 copies of files on them. My PC situation is I have my main PC and a second \"storage\" PC where I would like to have backed up files but also just files that I no longer have on my main PC (90GB game folders so I don't need to download it again when I want to launch the game next year maybe).\n\nIdeally, I would just like an excel spreadsheet with all the file hashes and attributes and paths. Then I can see what file is where and remove unneeded copies. Unfortunately, excel does not like lists with half a million entries and also manually sorting will be very slow.\n\nIs there any software that can generate a \"map\" from one hard drive, then I can open this \"map\" on a different hard drive, compare if some parts of the folder structure and content is identical, then I can organise based on those, not on individual files?", "author_fullname": "t2_cjhkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organising years' worth of chaotic backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150jgn9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689446211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have roughly 14 drives with 5-8 copies of files on them. My PC situation is I have my main PC and a second &amp;quot;storage&amp;quot; PC where I would like to have backed up files but also just files that I no longer have on my main PC (90GB game folders so I don&amp;#39;t need to download it again when I want to launch the game next year maybe).&lt;/p&gt;\n\n&lt;p&gt;Ideally, I would just like an excel spreadsheet with all the file hashes and attributes and paths. Then I can see what file is where and remove unneeded copies. Unfortunately, excel does not like lists with half a million entries and also manually sorting will be very slow.&lt;/p&gt;\n\n&lt;p&gt;Is there any software that can generate a &amp;quot;map&amp;quot; from one hard drive, then I can open this &amp;quot;map&amp;quot; on a different hard drive, compare if some parts of the folder structure and content is identical, then I can organise based on those, not on individual files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150jgn9", "is_robot_indexable": true, "report_reasons": null, "author": "jeo123911", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150jgn9/organising_years_worth_of_chaotic_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150jgn9/organising_years_worth_of_chaotic_backups/", "subreddit_subscribers": 692877, "created_utc": 1689446211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m looking for recommendations for 2TB, 4TB and 8TB SATA SSD\u2019s due to the whole Samsung SSD failure issues.", "author_fullname": "t2_15jrzb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best SATA ssd to buy at the moment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_151bxoi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689528215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for recommendations for 2TB, 4TB and 8TB SATA SSD\u2019s due to the whole Samsung SSD failure issues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "151bxoi", "is_robot_indexable": true, "report_reasons": null, "author": "xkcx123", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/151bxoi/what_is_the_best_sata_ssd_to_buy_at_the_moment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/151bxoi/what_is_the_best_sata_ssd_to_buy_at_the_moment/", "subreddit_subscribers": 692877, "created_utc": 1689528215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long ago PC only needed one power connector to the motherboard. Then as CPU started getting more powerful, came the need for extra 12v. Some of the higher end motherboard uses 2 of the 8 pin connectors.\n\nLong ago video cards could use power from the slot. Some of the powerful AGP needed extra power and had a 4 pin connector on it. Today's high end video card uses 2 8-pin PCIe power or even 12 pin connector.\n\nSome USB cards also needed extra power for driving external USB 3.x devices at over 2A per port.\n\nI was just reading into the recently released PCIe 5.0 NVME drive, it uses a hefty 12w of power. It got me thinking, could one day we find them with an extra connector such as the old floppy disk drive connector or something to get more power?  I think the max from m.2 port is 25w?", "author_fullname": "t2_y5py1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could NVME drives one day need external power connection?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_151a17m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689523596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long ago PC only needed one power connector to the motherboard. Then as CPU started getting more powerful, came the need for extra 12v. Some of the higher end motherboard uses 2 of the 8 pin connectors.&lt;/p&gt;\n\n&lt;p&gt;Long ago video cards could use power from the slot. Some of the powerful AGP needed extra power and had a 4 pin connector on it. Today&amp;#39;s high end video card uses 2 8-pin PCIe power or even 12 pin connector.&lt;/p&gt;\n\n&lt;p&gt;Some USB cards also needed extra power for driving external USB 3.x devices at over 2A per port.&lt;/p&gt;\n\n&lt;p&gt;I was just reading into the recently released PCIe 5.0 NVME drive, it uses a hefty 12w of power. It got me thinking, could one day we find them with an extra connector such as the old floppy disk drive connector or something to get more power?  I think the max from m.2 port is 25w?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "151a17m", "is_robot_indexable": true, "report_reasons": null, "author": "tomytronics", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/151a17m/could_nvme_drives_one_day_need_external_power/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/151a17m/could_nvme_drives_one_day_need_external_power/", "subreddit_subscribers": 692877, "created_utc": 1689523596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i currently have 4 external hard drives all backing up various data, all with mismatched backup and stuff (I'll fix it later, this was completely unrelated to the post)\n\nare there any external hard drive bays made to store hard drives to keep them safe from physical damage? i just want a cheap solution to keeping them safe, not a costly one that connects to the internet and provides other knick knacks\n\nI'm searching for a temporary solution to keep my external HDDs safe from physical damage until i start earning enough to create better back ups\n\nfor more details:\n1x2 TB Seagate HDD (&lt;1 year old)\n2x1 TB Seagate HDD (between 1-4 years old)\n1x1.5 TB Seagate HDD (&gt;4 years old)", "author_fullname": "t2_85ypvsyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "safe storage solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1519l3p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689522500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i currently have 4 external hard drives all backing up various data, all with mismatched backup and stuff (I&amp;#39;ll fix it later, this was completely unrelated to the post)&lt;/p&gt;\n\n&lt;p&gt;are there any external hard drive bays made to store hard drives to keep them safe from physical damage? i just want a cheap solution to keeping them safe, not a costly one that connects to the internet and provides other knick knacks&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m searching for a temporary solution to keep my external HDDs safe from physical damage until i start earning enough to create better back ups&lt;/p&gt;\n\n&lt;p&gt;for more details:\n1x2 TB Seagate HDD (&amp;lt;1 year old)\n2x1 TB Seagate HDD (between 1-4 years old)\n1x1.5 TB Seagate HDD (&amp;gt;4 years old)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1519l3p", "is_robot_indexable": true, "report_reasons": null, "author": "TriggeredTrigz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1519l3p/safe_storage_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1519l3p/safe_storage_solution/", "subreddit_subscribers": 692877, "created_utc": 1689522500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, Sorry for a newbie question. I did use the search, I found it hard to get past the recent Google restrictions posts, or maybe I really am the first to ask this, but I couldn't find an answer either way. I'm hoping you data storage exists can help me. \n\nI only keep about 1.5-2TB data on the paid for Google workspace thing. I have 2 accounts, one for myself and one for my wife. It's got some work stuff on but it's mostly personal crap and photos etc. I don't want to lose any of it really.\n\nIs there a way of syncing my Google data to say Wasabi or AWS or some other service without changing the way I use it now so that I have a second backup should Google lose it/ban me or whatever bad scenario might happen?\n\nDo I even need to worry about it?\n\nAny thoughts appreciated. I'm not against getting a local NAS or something if that's the best route, I'm also happy to pay another cloud provider. I care more about convenience than cost.", "author_fullname": "t2_4y08k82j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dual cloud backup, gcloud + ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1519ios", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689522332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, Sorry for a newbie question. I did use the search, I found it hard to get past the recent Google restrictions posts, or maybe I really am the first to ask this, but I couldn&amp;#39;t find an answer either way. I&amp;#39;m hoping you data storage exists can help me. &lt;/p&gt;\n\n&lt;p&gt;I only keep about 1.5-2TB data on the paid for Google workspace thing. I have 2 accounts, one for myself and one for my wife. It&amp;#39;s got some work stuff on but it&amp;#39;s mostly personal crap and photos etc. I don&amp;#39;t want to lose any of it really.&lt;/p&gt;\n\n&lt;p&gt;Is there a way of syncing my Google data to say Wasabi or AWS or some other service without changing the way I use it now so that I have a second backup should Google lose it/ban me or whatever bad scenario might happen?&lt;/p&gt;\n\n&lt;p&gt;Do I even need to worry about it?&lt;/p&gt;\n\n&lt;p&gt;Any thoughts appreciated. I&amp;#39;m not against getting a local NAS or something if that&amp;#39;s the best route, I&amp;#39;m also happy to pay another cloud provider. I care more about convenience than cost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1519ios", "is_robot_indexable": true, "report_reasons": null, "author": "jeffreyshran", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1519ios/dual_cloud_backup_gcloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1519ios/dual_cloud_backup_gcloud/", "subreddit_subscribers": 692877, "created_utc": 1689522332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Current main NAS setup:\n- 2 x 3TB mirror (WS reds, new drives) for important stuff\n- 2 x 1TB stripe (8y old drives) for plex media/torrents - \n\nBackup NAS setup:\n- 1 x 4TB (WD red, new drive) Backup for the important stuff (the media drives don't have a backup)\n\nOther unused, old drives I have:\n - 3 x 1TB WD blues\n\nNow, as I don't live in the US and drive prices are all over the place I can't just purchase 3 x 16TB drives an put all the stuff on them.\n\nThe main 3TB mirror setup is half full and won't need much expanding for the years to come. \nThe media drives are what concerns me, the stripe pool (2TB in total) is almost full and expanding every month. The safety of this pool is in the negative so to say, so I need to change something.\n\nWhat to do if you want to reuse as many drives as possible?\n- Purchase new 2 x 3TB drives (mirror) just for the media stuff?\n- Purchase two very large drives (mirror), put everything on them and use the 2 x 3TB ones in the backup machine to backup everything, not just the important stuff?\n- Use a different configuration altogether (non mirror)?", "author_fullname": "t2_1hsjxygy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on old/new drives combination for max value and safety", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1514uwo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689509909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Current main NAS setup:\n- 2 x 3TB mirror (WS reds, new drives) for important stuff\n- 2 x 1TB stripe (8y old drives) for plex media/torrents - &lt;/p&gt;\n\n&lt;p&gt;Backup NAS setup:\n- 1 x 4TB (WD red, new drive) Backup for the important stuff (the media drives don&amp;#39;t have a backup)&lt;/p&gt;\n\n&lt;p&gt;Other unused, old drives I have:\n - 3 x 1TB WD blues&lt;/p&gt;\n\n&lt;p&gt;Now, as I don&amp;#39;t live in the US and drive prices are all over the place I can&amp;#39;t just purchase 3 x 16TB drives an put all the stuff on them.&lt;/p&gt;\n\n&lt;p&gt;The main 3TB mirror setup is half full and won&amp;#39;t need much expanding for the years to come. \nThe media drives are what concerns me, the stripe pool (2TB in total) is almost full and expanding every month. The safety of this pool is in the negative so to say, so I need to change something.&lt;/p&gt;\n\n&lt;p&gt;What to do if you want to reuse as many drives as possible?\n- Purchase new 2 x 3TB drives (mirror) just for the media stuff?\n- Purchase two very large drives (mirror), put everything on them and use the 2 x 3TB ones in the backup machine to backup everything, not just the important stuff?\n- Use a different configuration altogether (non mirror)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1514uwo", "is_robot_indexable": true, "report_reasons": null, "author": "DAndreyD", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1514uwo/advice_on_oldnew_drives_combination_for_max_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1514uwo/advice_on_oldnew_drives_combination_for_max_value/", "subreddit_subscribers": 692877, "created_utc": 1689509909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I seem to have been getting error messages since Friday evening when trying to use my iDrive e2 bucket in Frankfurt?\n\nIs the full region down or just my server?\n\nI have also noticed they have reduced their yearly price to $20 for 1TB (was $40 before)", "author_fullname": "t2_lwumyho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "iDrive e2 Frankfurt down since Friday evening?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15136lt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689504451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I seem to have been getting error messages since Friday evening when trying to use my iDrive e2 bucket in Frankfurt?&lt;/p&gt;\n\n&lt;p&gt;Is the full region down or just my server?&lt;/p&gt;\n\n&lt;p&gt;I have also noticed they have reduced their yearly price to $20 for 1TB (was $40 before)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15136lt", "is_robot_indexable": true, "report_reasons": null, "author": "TedBob99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15136lt/idrive_e2_frankfurt_down_since_friday_evening/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15136lt/idrive_e2_frankfurt_down_since_friday_evening/", "subreddit_subscribers": 692877, "created_utc": 1689504451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking to download all photos from users albums in original HQ format. I understand there was a project but it was discontinued.\n\nAn example would be: [https://weibo.com/u/5732554220?tabtype=album](https://weibo.com/u/5732554220?tabtype=album) with an almost infinite scroll for several years of professional content.\n\nHopefully with a GUI as I'm big enough to admit I'm not savvy enough to use Gibhub projects.", "author_fullname": "t2_a7s673lu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a current Weibo album downloader?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15124wf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689500833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to download all photos from users albums in original HQ format. I understand there was a project but it was discontinued.&lt;/p&gt;\n\n&lt;p&gt;An example would be: &lt;a href=\"https://weibo.com/u/5732554220?tabtype=album\"&gt;https://weibo.com/u/5732554220?tabtype=album&lt;/a&gt; with an almost infinite scroll for several years of professional content.&lt;/p&gt;\n\n&lt;p&gt;Hopefully with a GUI as I&amp;#39;m big enough to admit I&amp;#39;m not savvy enough to use Gibhub projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15124wf", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated-Distance740", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15124wf/is_there_a_current_weibo_album_downloader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15124wf/is_there_a_current_weibo_album_downloader/", "subreddit_subscribers": 692877, "created_utc": 1689500833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My pool is a mix of duplicated and unduplicated files across 7 drives (52.8 TB total). My StableBit Scanner says I have 512 byte bad sector in one of the drives. DrivePool immediately copies unduplicated files on the drive with the bad sector across other drives. After it finishes, it did a remeasure and pool organization is green with \"file distribution not normal\". For some reason, the bad drive shows I have around 400GB unduplicated data, which I really want to backup just in case. My pool statistics shows:\n\n* 21.9 TB unduplicated\n* 24.6 TB duplicated\n* 6.05 TB unusable for duplication\n\nIs 512 byte bad sector something to worry about? Should I keep my drive or replace it? I'm not sure what to do next from here. Thank you in advance.\n\n&amp;#x200B;", "author_fullname": "t2_u50yq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "StableBit DrivePool/Scanner says I have 512 byte bad sector...what to do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15120jl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689500416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My pool is a mix of duplicated and unduplicated files across 7 drives (52.8 TB total). My StableBit Scanner says I have 512 byte bad sector in one of the drives. DrivePool immediately copies unduplicated files on the drive with the bad sector across other drives. After it finishes, it did a remeasure and pool organization is green with &amp;quot;file distribution not normal&amp;quot;. For some reason, the bad drive shows I have around 400GB unduplicated data, which I really want to backup just in case. My pool statistics shows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;21.9 TB unduplicated&lt;/li&gt;\n&lt;li&gt;24.6 TB duplicated&lt;/li&gt;\n&lt;li&gt;6.05 TB unusable for duplication&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is 512 byte bad sector something to worry about? Should I keep my drive or replace it? I&amp;#39;m not sure what to do next from here. Thank you in advance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15120jl", "is_robot_indexable": true, "report_reasons": null, "author": "neohanime", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15120jl/stablebit_drivepoolscanner_says_i_have_512_byte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15120jl/stablebit_drivepoolscanner_says_i_have_512_byte/", "subreddit_subscribers": 692877, "created_utc": 1689500416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Recently acquired a couple of 12-bay synology NASes loaded with drives, after a family friend passed away. \n\nUnsure if the contents are worth saving, but it appears the first enclosure I started messing with, a DS2415, is suffering from the \u201catom power problem\u201d, with blinking power and alert lights upon trying to startup.  I\u2019ve removed and numbered the drives for now. \n\nIs there any other way for me to view these drives, outside of getting them into a new 12-bay enclosure? Will that even work? I can\u2019t move them into the other enclosure I got from them because it is an expansion unit.", "author_fullname": "t2_ablys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reconstructing/salvaging a 12-drive RAID without the 12-bay enclosure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150x4zh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689483717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently acquired a couple of 12-bay synology NASes loaded with drives, after a family friend passed away. &lt;/p&gt;\n\n&lt;p&gt;Unsure if the contents are worth saving, but it appears the first enclosure I started messing with, a DS2415, is suffering from the \u201catom power problem\u201d, with blinking power and alert lights upon trying to startup.  I\u2019ve removed and numbered the drives for now. &lt;/p&gt;\n\n&lt;p&gt;Is there any other way for me to view these drives, outside of getting them into a new 12-bay enclosure? Will that even work? I can\u2019t move them into the other enclosure I got from them because it is an expansion unit.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150x4zh", "is_robot_indexable": true, "report_reasons": null, "author": "JayVeeBee", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150x4zh/reconstructingsalvaging_a_12drive_raid_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150x4zh/reconstructingsalvaging_a_12drive_raid_without/", "subreddit_subscribers": 692877, "created_utc": 1689483717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a software to archive my folder history as I go through changes with updates, etc. Screenshots would be tedious and then it occured to me that I could use instead a mirroring feature where the folders and sub-folders have the same path, so if my folder contains a sub-folder, \"2020\" and within it, \"Personal\" and \"screenshots\". In the mirrored archive, I can still click on 2020 to access personal. The files are deceptive. Preferably, they do have properties but can't be opened or used. Basically, they are like the thumbnails that our phones and computers make as cache. Except they retain all the properties and information except for file size.\n\nI was inspired by Wayback Machine for this idea. You can search YouTube from a bygone time but the videos don't work.\n\nSo far, while googling a software like this, all I get is mirror folder softwares that synchronizes and makes backups of folders. Please help!\n\nI think this idea is a great way to have an archive of folder history.", "author_fullname": "t2_oouyyvk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mirror folder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150u2df", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689474042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a software to archive my folder history as I go through changes with updates, etc. Screenshots would be tedious and then it occured to me that I could use instead a mirroring feature where the folders and sub-folders have the same path, so if my folder contains a sub-folder, &amp;quot;2020&amp;quot; and within it, &amp;quot;Personal&amp;quot; and &amp;quot;screenshots&amp;quot;. In the mirrored archive, I can still click on 2020 to access personal. The files are deceptive. Preferably, they do have properties but can&amp;#39;t be opened or used. Basically, they are like the thumbnails that our phones and computers make as cache. Except they retain all the properties and information except for file size.&lt;/p&gt;\n\n&lt;p&gt;I was inspired by Wayback Machine for this idea. You can search YouTube from a bygone time but the videos don&amp;#39;t work.&lt;/p&gt;\n\n&lt;p&gt;So far, while googling a software like this, all I get is mirror folder softwares that synchronizes and makes backups of folders. Please help!&lt;/p&gt;\n\n&lt;p&gt;I think this idea is a great way to have an archive of folder history.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150u2df", "is_robot_indexable": true, "report_reasons": null, "author": "Pale-Dragonfly-3139", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150u2df/mirror_folder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150u2df/mirror_folder/", "subreddit_subscribers": 692877, "created_utc": 1689474042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently running 8x16TB sata drives in TeueNas Scale with the onboard sata. I want to fill up my total slots for disk of storage by adding 4 or 6 more drives. The choices on Amazon seem to be the same cards the sell on AliExpress, while the Amazon cards are double the price. My current thinking is adding 4-6 more drives ( custom ATX setup ), going with raid z, having 1 as parity and 1 as a hotspare. So total 14 drives, 13 in raid z with the parity and one sitting there as a hotspare.\n\nBrowing around the the cards, it seems like once you go past 4 slots on 1 card, some of the 6 slot pcie 1x cards employ a double on board chip solution. \n\nIs their a card with 6 sata adapters on the card with only 1 chip to handle all the processing? If so, which SOC should I look for?\n\nAlso, do you think a 4 sata adapter would be much different from a 6 slot adapter?\n\nAnyways, just looking for suggestions on a 6x sata pcie 1x card that would best fit my needs.\n\nThanks!", "author_fullname": "t2_76tlc1a2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Chip For PCIE Sata Expander?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150o9mi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689458214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently running 8x16TB sata drives in TeueNas Scale with the onboard sata. I want to fill up my total slots for disk of storage by adding 4 or 6 more drives. The choices on Amazon seem to be the same cards the sell on AliExpress, while the Amazon cards are double the price. My current thinking is adding 4-6 more drives ( custom ATX setup ), going with raid z, having 1 as parity and 1 as a hotspare. So total 14 drives, 13 in raid z with the parity and one sitting there as a hotspare.&lt;/p&gt;\n\n&lt;p&gt;Browing around the the cards, it seems like once you go past 4 slots on 1 card, some of the 6 slot pcie 1x cards employ a double on board chip solution. &lt;/p&gt;\n\n&lt;p&gt;Is their a card with 6 sata adapters on the card with only 1 chip to handle all the processing? If so, which SOC should I look for?&lt;/p&gt;\n\n&lt;p&gt;Also, do you think a 4 sata adapter would be much different from a 6 slot adapter?&lt;/p&gt;\n\n&lt;p&gt;Anyways, just looking for suggestions on a 6x sata pcie 1x card that would best fit my needs.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150o9mi", "is_robot_indexable": true, "report_reasons": null, "author": "Vast-Program7060", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/150o9mi/best_chip_for_pcie_sata_expander/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150o9mi/best_chip_for_pcie_sata_expander/", "subreddit_subscribers": 692877, "created_utc": 1689458214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all - I'm building a new home server using an LSI host bus adapter that I got off eBay for $40. This is my first time using an HBA as I typically plugged my drives directly into the SATA ports on the mobo. I'm using a lot of the same componentry from my previous PC build (mobo, RAM, CPU, GPU, drives) but got a new case (Fractal Define 7XL - love it!) and a new power supply.\n\nThe seller was linked from a few different Reddit threads and the listing says they've sold 1,200+ of this card.. with all the positive reviews I figured it would be a safe purchase. But after I had plugged it into the PCI-e slot, connected it up, etc... when I turned on my power supply a spark on one of the HBA's on-board chips sparked a small flame and started smoking - so I instantly powered down the system. It burned a hole through the chip... pic attached.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/nuduc8nr77cb1.jpg?width=1536&amp;format=pjpg&amp;auto=webp&amp;s=002af9e543e47f443e145144b6e6c3155881a5e2\n\nWas this just a bad card and I should give them another chance and ask for a replacement? Or am I better off seeking a more reputable place to buy it than this seller on eBay? My motherboard only has 6 SATA connections but this has me nervous about using an HBA now\n\n[LSI 9211-8i 6G SAS HBA FW:P20 IT Mode ZFS FreeNAS unRAID 2\\* SFF-8087 SATA US | eBay](https://www.ebay.com/itm/133702989762)", "author_fullname": "t2_7sxyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "eBay ordered LSI SAS 9210 host bus adapter caught fire... shoddy chip?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nuduc8nr77cb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae4f5d20cac8dec41dcb86a7c358f59d3efb74dc"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=067f344055128fc103d35ba381255bf383f300a4"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=af00e0db2c3254672943844b2c3871f18bce388a"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0087a483c4c93aaac307c86390d05d5601fa3330"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=09f8e4019ff0701a07d13babc441cdbde97a5178"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=baae4f126b8052e8531410b34c42bb27680420f1"}], "s": {"y": 2048, "x": 1536, "u": "https://preview.redd.it/nuduc8nr77cb1.jpg?width=1536&amp;format=pjpg&amp;auto=webp&amp;s=002af9e543e47f443e145144b6e6c3155881a5e2"}, "id": "nuduc8nr77cb1"}}, "name": "t3_150nunp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_75XOemTR6MCuMf98TKJnolEgtWnchVnBW0ky33jjso.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689457174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - I&amp;#39;m building a new home server using an LSI host bus adapter that I got off eBay for $40. This is my first time using an HBA as I typically plugged my drives directly into the SATA ports on the mobo. I&amp;#39;m using a lot of the same componentry from my previous PC build (mobo, RAM, CPU, GPU, drives) but got a new case (Fractal Define 7XL - love it!) and a new power supply.&lt;/p&gt;\n\n&lt;p&gt;The seller was linked from a few different Reddit threads and the listing says they&amp;#39;ve sold 1,200+ of this card.. with all the positive reviews I figured it would be a safe purchase. But after I had plugged it into the PCI-e slot, connected it up, etc... when I turned on my power supply a spark on one of the HBA&amp;#39;s on-board chips sparked a small flame and started smoking - so I instantly powered down the system. It burned a hole through the chip... pic attached.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nuduc8nr77cb1.jpg?width=1536&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=002af9e543e47f443e145144b6e6c3155881a5e2\"&gt;https://preview.redd.it/nuduc8nr77cb1.jpg?width=1536&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=002af9e543e47f443e145144b6e6c3155881a5e2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Was this just a bad card and I should give them another chance and ask for a replacement? Or am I better off seeking a more reputable place to buy it than this seller on eBay? My motherboard only has 6 SATA connections but this has me nervous about using an HBA now&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ebay.com/itm/133702989762\"&gt;LSI 9211-8i 6G SAS HBA FW:P20 IT Mode ZFS FreeNAS unRAID 2* SFF-8087 SATA US | eBay&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "116TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150nunp", "is_robot_indexable": true, "report_reasons": null, "author": "mykeyhope", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/150nunp/ebay_ordered_lsi_sas_9210_host_bus_adapter_caught/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150nunp/ebay_ordered_lsi_sas_9210_host_bus_adapter_caught/", "subreddit_subscribers": 692877, "created_utc": 1689457174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! The drives on my PCs are starting to fill with stuff I just don't want to delete, so I'm looking to consolidate my data to something central that I can access from any of the various devices in the house. There's a lot of data on random drives lying around too, that should probably get moved into one location.\n\nI've done a but of googling but I'm new to this sort of thing, so I was wondering what you'd suggest.    \nMore important than anything else is cheap - I really don't want to be spending $4-500+ on this if I don't have to.\n\nWhat I'm planning on using it for:\n\n* Security camera storage. Right now I've a book-sized Windows office pc repurposed as a BlueIris server handling this and shunting any clip the software finds interesting to an external drive for storage. I may add more than the single camera at some point and will likely need more storage as a result.\n\n* Plex: The baby-server has been handling this, broadcasting to the various TVs in the house, though I don't have a huge collection of stuff.\n\n* Getting the family's data out of the half-dozen external drives that sit in a closet so I don't have to deal with the annual game of 'please dig through all our drives so I can find that one photo that was scanned 12 years ago'\n\n* Centralizing my own data like 3d print files somewhere I can find them, being able to load the file on the printer without having to walk between computers would be nice\n\n* Secondary/external Steam library so I don't have to download every game 2-3 times\n\n* I am apparently physically incapable of deleting any video game screenshot I take\n\n* Maybe a home minecraft server if I'm feeling adventurous\n\nTo that end, should I: \n\n* Just get a bigger external or a DAS for the pint-sized cameraplex server and make it do triple-duty? Though I'm a little worried asking it to do more will overload the poor thing.\n\n* Recycle my old gaming PC and shove a bunch of drives in it? I have a Ryzen-based rig just sitting there gathering dust, waiting for a PSU (and a case that I haven't lost all the screws to) to become a PC again.\n\n* Buy an antique NAS box off ebay? There seem to be quite a few cheap ones.\n\n* Something else?", "author_fullname": "t2_dokx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Baby's first NAS, or what's the best way to properly hoard my data on the cheap?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150m13w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689452645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! The drives on my PCs are starting to fill with stuff I just don&amp;#39;t want to delete, so I&amp;#39;m looking to consolidate my data to something central that I can access from any of the various devices in the house. There&amp;#39;s a lot of data on random drives lying around too, that should probably get moved into one location.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done a but of googling but I&amp;#39;m new to this sort of thing, so I was wondering what you&amp;#39;d suggest.&lt;br/&gt;\nMore important than anything else is cheap - I really don&amp;#39;t want to be spending $4-500+ on this if I don&amp;#39;t have to.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m planning on using it for:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Security camera storage. Right now I&amp;#39;ve a book-sized Windows office pc repurposed as a BlueIris server handling this and shunting any clip the software finds interesting to an external drive for storage. I may add more than the single camera at some point and will likely need more storage as a result.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Plex: The baby-server has been handling this, broadcasting to the various TVs in the house, though I don&amp;#39;t have a huge collection of stuff.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Getting the family&amp;#39;s data out of the half-dozen external drives that sit in a closet so I don&amp;#39;t have to deal with the annual game of &amp;#39;please dig through all our drives so I can find that one photo that was scanned 12 years ago&amp;#39;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Centralizing my own data like 3d print files somewhere I can find them, being able to load the file on the printer without having to walk between computers would be nice&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Secondary/external Steam library so I don&amp;#39;t have to download every game 2-3 times&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I am apparently physically incapable of deleting any video game screenshot I take&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Maybe a home minecraft server if I&amp;#39;m feeling adventurous&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To that end, should I: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Just get a bigger external or a DAS for the pint-sized cameraplex server and make it do triple-duty? Though I&amp;#39;m a little worried asking it to do more will overload the poor thing.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Recycle my old gaming PC and shove a bunch of drives in it? I have a Ryzen-based rig just sitting there gathering dust, waiting for a PSU (and a case that I haven&amp;#39;t lost all the screws to) to become a PC again.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Buy an antique NAS box off ebay? There seem to be quite a few cheap ones.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Something else?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150m13w", "is_robot_indexable": true, "report_reasons": null, "author": "lol-science", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150m13w/babys_first_nas_or_whats_the_best_way_to_properly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150m13w/babys_first_nas_or_whats_the_best_way_to_properly/", "subreddit_subscribers": 692877, "created_utc": 1689452645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My work has a machine which saves data files to a connected desktop, and also has a direct usb port for connecting to hard drives as well. I'm looking for some network connected drive that could receive files via USB connection from the machine/computer, and simultaneously upload them to a personal cloud that can be accessed in real time from home. Is it possible to do this without connecting such a drive directly to a router but instead wirelessly to my work wifi network? I don't have ready access to a router at my work, and I would prefer not to use direct wall ethernet.\n\nI'd prefers something with minimal required storage space, the files in question are not large and so I'm not super concerned about having the optimal connection- just so long as the drive immediately puts the files on the cloud once they're transferred from the machine.", "author_fullname": "t2_ga8ehf2v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using NAS with wireless network connection as opposed to direct connection to router", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150k2e1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689447717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My work has a machine which saves data files to a connected desktop, and also has a direct usb port for connecting to hard drives as well. I&amp;#39;m looking for some network connected drive that could receive files via USB connection from the machine/computer, and simultaneously upload them to a personal cloud that can be accessed in real time from home. Is it possible to do this without connecting such a drive directly to a router but instead wirelessly to my work wifi network? I don&amp;#39;t have ready access to a router at my work, and I would prefer not to use direct wall ethernet.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d prefers something with minimal required storage space, the files in question are not large and so I&amp;#39;m not super concerned about having the optimal connection- just so long as the drive immediately puts the files on the cloud once they&amp;#39;re transferred from the machine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "150k2e1", "is_robot_indexable": true, "report_reasons": null, "author": "fkatenn", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/150k2e1/using_nas_with_wireless_network_connection_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/150k2e1/using_nas_with_wireless_network_connection_as/", "subreddit_subscribers": 692877, "created_utc": 1689447717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an 6 yrs old WD 2TB HDD, dropped it by accident , still spinning no signs of head crash or any physical damage but does not show up . I was looking if it could be fixed and how much would it take . The data is really important but I cant really cannot spend too much for data extraction ", "author_fullname": "t2_brtfbspo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with a crashed HDD, No head crash or physical damage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_151avoh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689525683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an 6 yrs old WD 2TB HDD, dropped it by accident , still spinning no signs of head crash or any physical damage but does not show up . I was looking if it could be fixed and how much would it take . The data is really important but I cant really cannot spend too much for data extraction &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "151avoh", "is_robot_indexable": true, "report_reasons": null, "author": "Top_Top_315", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/151avoh/need_help_with_a_crashed_hdd_no_head_crash_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/151avoh/need_help_with_a_crashed_hdd_no_head_crash_or/", "subreddit_subscribers": 692877, "created_utc": 1689525683.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}