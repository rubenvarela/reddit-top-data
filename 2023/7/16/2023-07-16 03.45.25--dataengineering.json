{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vnan4h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this fear-mongering, or is this actually truthful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_150qcx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/o2JMp8tfb-do6aAWGCPMnW7oj8KPB6DkubFKUUiQTy0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689463491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/poz94nkcq7cb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/poz94nkcq7cb1.png?auto=webp&amp;s=81dbb2eb92ccbdcb64d8b712e169c18ea40a2b4b", "width": 720, "height": 1379}, "resolutions": [{"url": "https://preview.redd.it/poz94nkcq7cb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=15d543fef641980dfc8e8fef5804e1a626ab06b9", "width": 108, "height": 206}, {"url": "https://preview.redd.it/poz94nkcq7cb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e4a37d2427db1d2e091b0bacbd1c9e690a46850", "width": 216, "height": 413}, {"url": "https://preview.redd.it/poz94nkcq7cb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef166217248c2cd05e3d38ccc39e76c888cc0826", "width": 320, "height": 612}, {"url": "https://preview.redd.it/poz94nkcq7cb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a4489e639555acfdc83d3894b7a71da0c1448838", "width": 640, "height": 1225}], "variants": {}, "id": "QY8zPFNWPPZmEjKy9OcLaxUWN6wZODGHsYliCVXC7v0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150qcx2", "is_robot_indexable": true, "report_reasons": null, "author": "Analyst2163", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150qcx2/is_this_fearmongering_or_is_this_actually_truthful/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/poz94nkcq7cb1.png", "subreddit_subscribers": 116004, "created_utc": 1689463491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a student preparing to get a job as a data engineer.\n\n1. linux, Python, SQL, JAVA or Scala\n2. Cloud Knowledge\n3. Docker, Kubernetes\n4. Server security + data security/quality\n5. Database (\"Cassandra\", \"Mongo\", \"Mysql\", \"postgres\", \"redis\")\n6. ELK or (fluentd, Opensearch)\n7. Kafka\n8. Spark Stream or Flink\n9. Spark or Trino\n10. table format ( Iceberg/deltalake/ Hudi)\n11. snowflake/ Redshfit / Bigquery   \n12.  OLAP Data Modeling  \n13. Airflow\n\n  \nI only wrote down the essentials.  \nThere are many good tools like dbt, lakeFS, etcBut in addition  \nCompanies may still require Hadoop Echo System (Hive/HDFS/Hbase).  \nThey might ask us to build a dashboard with javascript or python.  \nThey can also ask us to create the web.  \n\n\nFrom number 1 to 13, each one has a very difficult and difficult concept to master.What I'm really curious about is how much I need to know and how much I need to master them to apply for a company.\n\nI'm sorry. Actually, I was whining because I got hit with reality while studying.", "author_fullname": "t2_6pkq7jrch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do data engineers have so much to learn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150mfrd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689469567.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689453652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a student preparing to get a job as a data engineer.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;linux, Python, SQL, JAVA or Scala&lt;/li&gt;\n&lt;li&gt;Cloud Knowledge&lt;/li&gt;\n&lt;li&gt;Docker, Kubernetes&lt;/li&gt;\n&lt;li&gt;Server security + data security/quality&lt;/li&gt;\n&lt;li&gt;Database (&amp;quot;Cassandra&amp;quot;, &amp;quot;Mongo&amp;quot;, &amp;quot;Mysql&amp;quot;, &amp;quot;postgres&amp;quot;, &amp;quot;redis&amp;quot;)&lt;/li&gt;\n&lt;li&gt;ELK or (fluentd, Opensearch)&lt;/li&gt;\n&lt;li&gt;Kafka&lt;/li&gt;\n&lt;li&gt;Spark Stream or Flink&lt;/li&gt;\n&lt;li&gt;Spark or Trino&lt;/li&gt;\n&lt;li&gt;table format ( Iceberg/deltalake/ Hudi)&lt;/li&gt;\n&lt;li&gt;snowflake/ Redshfit / Bigquery&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt; OLAP Data Modeling&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Airflow&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I only wrote down the essentials.&lt;br/&gt;\nThere are many good tools like dbt, lakeFS, etcBut in addition&lt;br/&gt;\nCompanies may still require Hadoop Echo System (Hive/HDFS/Hbase).&lt;br/&gt;\nThey might ask us to build a dashboard with javascript or python.&lt;br/&gt;\nThey can also ask us to create the web.  &lt;/p&gt;\n\n&lt;p&gt;From number 1 to 13, each one has a very difficult and difficult concept to master.What I&amp;#39;m really curious about is how much I need to know and how much I need to master them to apply for a company.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sorry. Actually, I was whining because I got hit with reality while studying.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150mfrd", "is_robot_indexable": true, "report_reasons": null, "author": "Hankaul", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150mfrd/why_do_data_engineers_have_so_much_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150mfrd/why_do_data_engineers_have_so_much_to_learn/", "subreddit_subscribers": 116004, "created_utc": 1689453652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I used SQL my whole life and I don't have issues with data modeling or querying in general. But when I see jobs asking for a good level in SQL, I wonder what does good mean ? What are the items that I should really know to qualify as ready for an SQL DE job ?", "author_fullname": "t2_um2qwii8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should a DE really know in SQL to succeed in an entry level job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150e59x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689433102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used SQL my whole life and I don&amp;#39;t have issues with data modeling or querying in general. But when I see jobs asking for a good level in SQL, I wonder what does good mean ? What are the items that I should really know to qualify as ready for an SQL DE job ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150e59x", "is_robot_indexable": true, "report_reasons": null, "author": "NoChemical1223", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150e59x/what_should_a_de_really_know_in_sql_to_succeed_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150e59x/what_should_a_de_really_know_in_sql_to_succeed_in/", "subreddit_subscribers": 116004, "created_utc": 1689433102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI currently do my etl task with spark. It is simple ETL jobs. The amount of data is small to medium. I essentially work with on-prem data, but some may be stored in S3 buckets or Redshift.\n\nI have good knowledge of SQL.\n\nSince I am looking for a new job, I wonder if I should learn SSIS to do ETL, since a lot of companies use it, or is AWS Glue and Pyspark is sufficient to tackle ETL tasks.\n\nIs it worth to learning SSIS ? What are the pros and cons ?\n\nThank you.", "author_fullname": "t2_dtr7r94xd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark VS SSIS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1509lyr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689420528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I currently do my etl task with spark. It is simple ETL jobs. The amount of data is small to medium. I essentially work with on-prem data, but some may be stored in S3 buckets or Redshift.&lt;/p&gt;\n\n&lt;p&gt;I have good knowledge of SQL.&lt;/p&gt;\n\n&lt;p&gt;Since I am looking for a new job, I wonder if I should learn SSIS to do ETL, since a lot of companies use it, or is AWS Glue and Pyspark is sufficient to tackle ETL tasks.&lt;/p&gt;\n\n&lt;p&gt;Is it worth to learning SSIS ? What are the pros and cons ?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1509lyr", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Finish673", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1509lyr/pyspark_vs_ssis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1509lyr/pyspark_vs_ssis/", "subreddit_subscribers": 116004, "created_utc": 1689420528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm going through some of the dbt training courses on their website. Across multiple videos and presenters, they seem to use the syntax \"GROUP BY 1\" in their SQL code. I honestly had to Google wtf that meant lol.\n\nPlease correct me if I'm overgeneralizing, but it seems like in almost every case, you should just use the column name in the group by clause. \n\nI'm very new to dbt, so please let me know if there's a good reason to use GROUP BY 1 rather than the column name.", "author_fullname": "t2_vw2sv4u4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why use \"GROUP BY 1\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150korq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689449247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m going through some of the dbt training courses on their website. Across multiple videos and presenters, they seem to use the syntax &amp;quot;GROUP BY 1&amp;quot; in their SQL code. I honestly had to Google wtf that meant lol.&lt;/p&gt;\n\n&lt;p&gt;Please correct me if I&amp;#39;m overgeneralizing, but it seems like in almost every case, you should just use the column name in the group by clause. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m very new to dbt, so please let me know if there&amp;#39;s a good reason to use GROUP BY 1 rather than the column name.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150korq", "is_robot_indexable": true, "report_reasons": null, "author": "aria_____51", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150korq/why_use_group_by_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150korq/why_use_group_by_1/", "subreddit_subscribers": 116004, "created_utc": 1689449247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is something. I'm feeling bad since it happened yesterday.\n\nSomehow I got promoted from a Sr Data Engineer role to a Sr Data Analyst with a salary increase. \n\nI mean it's good but since I do both roles it's awkward since the title should be something like analytics engineer, which is more attractive for any job seeking in the future.\n\nI have a lot of confidence in my boss. I plan to tell him to reconsider the title based on all my functions.\n\nWhat do you think about\u00a0this\u00a0guys? am I wrong?", "author_fullname": "t2_2doz54hy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got \"promoted\" from Sr DE to Sr DA \u00bf?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150knwq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689449186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is something. I&amp;#39;m feeling bad since it happened yesterday.&lt;/p&gt;\n\n&lt;p&gt;Somehow I got promoted from a Sr Data Engineer role to a Sr Data Analyst with a salary increase. &lt;/p&gt;\n\n&lt;p&gt;I mean it&amp;#39;s good but since I do both roles it&amp;#39;s awkward since the title should be something like analytics engineer, which is more attractive for any job seeking in the future.&lt;/p&gt;\n\n&lt;p&gt;I have a lot of confidence in my boss. I plan to tell him to reconsider the title based on all my functions.&lt;/p&gt;\n\n&lt;p&gt;What do you think about\u00a0this\u00a0guys? am I wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150knwq", "is_robot_indexable": true, "report_reasons": null, "author": "erwingm10", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/150knwq/just_got_promoted_from_sr_de_to_sr_da/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150knwq/just_got_promoted_from_sr_de_to_sr_da/", "subreddit_subscribers": 116004, "created_utc": 1689449186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently learning data engineering and taking cs50, should I just watch all the videos? Or should I go through all the practice problems? I'm currently on week 4 and have been going through the practice problems, but that's moving pretty slowly since I'm also reading a textbook on data warehousing. Would it be better to just watch all the videos on cs50 so I can move through it quicker?\n\nFor some background info, I'm a data analyst with no degree. I no longer do any type of data analysis, instead I'm doing ETL, OLAP cube building, and automating for my departments reports. I'll also start focusing on pre-processing data on clients where our current processes can't handle the data quantity, and I'm helping come up with some data pipelines to automate some manual processes. None of this is focused on super high volume data.\n\nI want to build a strong foundation in computer science since I have no degree, but I also want to learn at a decent rate since I'm already doing some data engineering to an extent.\n\ntl;dr - If you were learning data engineering again and taking cs50, would you just watch the lectures or do all the work?", "author_fullname": "t2_8e28mn79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I skim cs50 or do all the work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150gzsj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689440176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently learning data engineering and taking cs50, should I just watch all the videos? Or should I go through all the practice problems? I&amp;#39;m currently on week 4 and have been going through the practice problems, but that&amp;#39;s moving pretty slowly since I&amp;#39;m also reading a textbook on data warehousing. Would it be better to just watch all the videos on cs50 so I can move through it quicker?&lt;/p&gt;\n\n&lt;p&gt;For some background info, I&amp;#39;m a data analyst with no degree. I no longer do any type of data analysis, instead I&amp;#39;m doing ETL, OLAP cube building, and automating for my departments reports. I&amp;#39;ll also start focusing on pre-processing data on clients where our current processes can&amp;#39;t handle the data quantity, and I&amp;#39;m helping come up with some data pipelines to automate some manual processes. None of this is focused on super high volume data.&lt;/p&gt;\n\n&lt;p&gt;I want to build a strong foundation in computer science since I have no degree, but I also want to learn at a decent rate since I&amp;#39;m already doing some data engineering to an extent.&lt;/p&gt;\n\n&lt;p&gt;tl;dr - If you were learning data engineering again and taking cs50, would you just watch the lectures or do all the work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "150gzsj", "is_robot_indexable": true, "report_reasons": null, "author": "Icy-Big2472", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150gzsj/should_i_skim_cs50_or_do_all_the_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150gzsj/should_i_skim_cs50_or_do_all_the_work/", "subreddit_subscribers": 116004, "created_utc": 1689440176.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI recently joined a company where I am given the role of a data engineer. They have plans of converting it to a full-stack data engineer role (not really sure if that's a thing). This decision was made entirely by them without any prior discussion. Was eventually let to know but I wasn't told this at the time of joining. I have mainly worked in backend development and data engineering space before. I am worried they would move me completely to frontend which I neither have prior experience in nor the inclination. Their explanation is that it would give me an end-to-end picture of the product and also reduce dependency on FE team for backend features we have worked on. But I am not particularly interested in adding on that skill set and instead focus on learning what else there is in the area I have been working so far. But the following thoughts are worrying me:  \n1. Will saying no be taken as \"I don't wish to grow and learn\"   \n2. I am okay with maybe ramping up to resolve bugs and add small features but being part of a complete design story or overhaul is not something I am interested in but the discussion indicated it might be the case in the future if it comes to that.  \n\n\nIf given a choice I would avoid frontend work. But wanted to know what the general opinion is around this and what would be suggested. \n\nTIA", "author_fullname": "t2_a40fenez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "full stack DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150cc7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689428407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I recently joined a company where I am given the role of a data engineer. They have plans of converting it to a full-stack data engineer role (not really sure if that&amp;#39;s a thing). This decision was made entirely by them without any prior discussion. Was eventually let to know but I wasn&amp;#39;t told this at the time of joining. I have mainly worked in backend development and data engineering space before. I am worried they would move me completely to frontend which I neither have prior experience in nor the inclination. Their explanation is that it would give me an end-to-end picture of the product and also reduce dependency on FE team for backend features we have worked on. But I am not particularly interested in adding on that skill set and instead focus on learning what else there is in the area I have been working so far. But the following thoughts are worrying me:&lt;br/&gt;\n1. Will saying no be taken as &amp;quot;I don&amp;#39;t wish to grow and learn&amp;quot;&lt;br/&gt;\n2. I am okay with maybe ramping up to resolve bugs and add small features but being part of a complete design story or overhaul is not something I am interested in but the discussion indicated it might be the case in the future if it comes to that.  &lt;/p&gt;\n\n&lt;p&gt;If given a choice I would avoid frontend work. But wanted to know what the general opinion is around this and what would be suggested. &lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150cc7j", "is_robot_indexable": true, "report_reasons": null, "author": "puzzled-cognition", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150cc7j/full_stack_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150cc7j/full_stack_de/", "subreddit_subscribers": 116004, "created_utc": 1689428407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team have some large workloads which we are currently running on Azure Databricks. On an ad-hoc hasis, we occasionally do some large simulations for analytics purposes over all of our historic data which require large costly clusters. It works ok, but since we use cheap Spot instances, 80% of the resulting bill is for the Databricks DBU cost rather than the underlying infrastructure. \n\nSince the jobs don't rely on any of the Databricks closed-source tech, and they're ad-hoc so don't form part of any other integrated workflows, I'd like to see if there's a good option for running these jobs on self managed clusters so that I can cut down the bill.\n\nHaving done some research, there was historically a library called [AZTK](https://github.com/Azure/aztk) (Azure Distributed Data Engineering Toolkit) which provided a simple CLI for creating Spark Clusters on Azure Batch. However, it's no longer being maintained.\n\nDoes anyone have any other recommendations?", "author_fullname": "t2_173s1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplest solution for self managed spark cluster on Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150budt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689427048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team have some large workloads which we are currently running on Azure Databricks. On an ad-hoc hasis, we occasionally do some large simulations for analytics purposes over all of our historic data which require large costly clusters. It works ok, but since we use cheap Spot instances, 80% of the resulting bill is for the Databricks DBU cost rather than the underlying infrastructure. &lt;/p&gt;\n\n&lt;p&gt;Since the jobs don&amp;#39;t rely on any of the Databricks closed-source tech, and they&amp;#39;re ad-hoc so don&amp;#39;t form part of any other integrated workflows, I&amp;#39;d like to see if there&amp;#39;s a good option for running these jobs on self managed clusters so that I can cut down the bill.&lt;/p&gt;\n\n&lt;p&gt;Having done some research, there was historically a library called &lt;a href=\"https://github.com/Azure/aztk\"&gt;AZTK&lt;/a&gt; (Azure Distributed Data Engineering Toolkit) which provided a simple CLI for creating Spark Clusters on Azure Batch. However, it&amp;#39;s no longer being maintained.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any other recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YfCCaKDU6xNxdB0_jSf3seyilHcwFVgMouFFowBqioE.jpg?auto=webp&amp;s=b06c012cb41ecc749eb5f90c904274d46a26840d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/YfCCaKDU6xNxdB0_jSf3seyilHcwFVgMouFFowBqioE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=adbb3b707613aca52feaf697def8a8a2b342215b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/YfCCaKDU6xNxdB0_jSf3seyilHcwFVgMouFFowBqioE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bd8add2cbde77c9734804c7207c81c1563a7673d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/YfCCaKDU6xNxdB0_jSf3seyilHcwFVgMouFFowBqioE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba3432a3dc98d43482ee02b50d7bd61c03caa6ee", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/YfCCaKDU6xNxdB0_jSf3seyilHcwFVgMouFFowBqioE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=86aea326065a814d88ab3c561665790878990f58", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/YfCCaKDU6xNxdB0_jSf3seyilHcwFVgMouFFowBqioE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bca8ae50018d5ace9308ece2d856c6e9cfe52b70", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/YfCCaKDU6xNxdB0_jSf3seyilHcwFVgMouFFowBqioE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e9bee3ef5f4fbc546675378d5e70503fdc99b8fa", "width": 1080, "height": 540}], "variants": {}, "id": "q67RFzude0ccMbhzCzeXcdZFMywLc15tAjithvMoja4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "150budt", "is_robot_indexable": true, "report_reasons": null, "author": "Pancakeman123000", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150budt/simplest_solution_for_self_managed_spark_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150budt/simplest_solution_for_self_managed_spark_cluster/", "subreddit_subscribers": 116004, "created_utc": 1689427048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently trying to learn Apache Airflow and I have read and heard many times that Apache Airflow is an orchestration tool and should not be used to process data.\n\nHowever, some things are not clear to me:\n\n1. Does this mean I should not use the `PythonOperator` to transform my data but instead use something like the `SparkOperator`?\n2. If I can use the `PythonOperator` to transform my data, where exactly is the process done? On a worker (if I use Celery Executor) or on a POD (if I use Kubernetes Executor)? How is that different from using Apache Airflow as a processing tool?\n3. Also, If I can use the `PythonOperator` to transform my data, then how exactly does one use Apache Airflow to process data? \n\n&amp;#x200B;", "author_fullname": "t2_c8f4gnokr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where data is processed when using PythonOperator?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150j1ge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689445198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently trying to learn Apache Airflow and I have read and heard many times that Apache Airflow is an orchestration tool and should not be used to process data.&lt;/p&gt;\n\n&lt;p&gt;However, some things are not clear to me:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Does this mean I should not use the &lt;code&gt;PythonOperator&lt;/code&gt; to transform my data but instead use something like the &lt;code&gt;SparkOperator&lt;/code&gt;?&lt;/li&gt;\n&lt;li&gt;If I can use the &lt;code&gt;PythonOperator&lt;/code&gt; to transform my data, where exactly is the process done? On a worker (if I use Celery Executor) or on a POD (if I use Kubernetes Executor)? How is that different from using Apache Airflow as a processing tool?&lt;/li&gt;\n&lt;li&gt;Also, If I can use the &lt;code&gt;PythonOperator&lt;/code&gt; to transform my data, then how exactly does one use Apache Airflow to process data? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "150j1ge", "is_robot_indexable": true, "report_reasons": null, "author": "NoobAllTheWay", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150j1ge/where_data_is_processed_when_using_pythonoperator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150j1ge/where_data_is_processed_when_using_pythonoperator/", "subreddit_subscribers": 116004, "created_utc": 1689445198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, In the company I work for we use PySpark on EMR or Glue Jobs for Big Data processing.\n\nFor small data cases we use AWS SDK for Pandas (awswrangler) on Lambda.\n\nIs there anyway to use polars in this manner while also reading and writing to Glue Catalog tables?", "author_fullname": "t2_5fmit0v9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small Data processing with Polars @AWS lambda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150fgvc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689436394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, In the company I work for we use PySpark on EMR or Glue Jobs for Big Data processing.&lt;/p&gt;\n\n&lt;p&gt;For small data cases we use AWS SDK for Pandas (awswrangler) on Lambda.&lt;/p&gt;\n\n&lt;p&gt;Is there anyway to use polars in this manner while also reading and writing to Glue Catalog tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150fgvc", "is_robot_indexable": true, "report_reasons": null, "author": "gabbom_XCII", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150fgvc/small_data_processing_with_polars_aws_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150fgvc/small_data_processing_with_polars_aws_lambda/", "subreddit_subscribers": 116004, "created_utc": 1689436394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was curious if there are examples of projects for pulling in machine sensor data from different locations via api? Looking to do a project and specifically how to handle outages and incremental jobs for a location or certain machines that may go offline while the rest are running smoothly.", "author_fullname": "t2_b5za7mst", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Example of Incremental Sensor Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150i6w3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689443087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was curious if there are examples of projects for pulling in machine sensor data from different locations via api? Looking to do a project and specifically how to handle outages and incremental jobs for a location or certain machines that may go offline while the rest are running smoothly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150i6w3", "is_robot_indexable": true, "report_reasons": null, "author": "No_Cover_Undercover", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150i6w3/example_of_incremental_sensor_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150i6w3/example_of_incremental_sensor_project/", "subreddit_subscribers": 116004, "created_utc": 1689443087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, \n\nSo I work at a small clinic and have recently been charged with consolidating our various data sources into one single database so that analytics can be performed in a fast, easier way. Our sources include excel sheets and csv files created in-house, and reports downloaded in these formats from medical web-portals. \n\nWhat would be the best way (and technology) to go about creating a single database system where I can eventually create automated systems for all these different data sources to be consolidated in one database system? \n\n&amp;#x200B;\n\nThank you\n\n(P.S. I do have a computer science degree, but I haven't worked too much with architecting database systems/infrastructure, mostly running SQL queries, and ML algorithms with existing datasets)", "author_fullname": "t2_7a3r9mqm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBMS options for a small clinic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150jm2q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689446581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;So I work at a small clinic and have recently been charged with consolidating our various data sources into one single database so that analytics can be performed in a fast, easier way. Our sources include excel sheets and csv files created in-house, and reports downloaded in these formats from medical web-portals. &lt;/p&gt;\n\n&lt;p&gt;What would be the best way (and technology) to go about creating a single database system where I can eventually create automated systems for all these different data sources to be consolidated in one database system? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n\n&lt;p&gt;(P.S. I do have a computer science degree, but I haven&amp;#39;t worked too much with architecting database systems/infrastructure, mostly running SQL queries, and ML algorithms with existing datasets)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "150jm2q", "is_robot_indexable": true, "report_reasons": null, "author": "juiceleft88", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150jm2q/dbms_options_for_a_small_clinic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150jm2q/dbms_options_for_a_small_clinic/", "subreddit_subscribers": 116004, "created_utc": 1689446581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data engineer with 2 years of experience in Azure cloud. \n\nI have basic knowledge of Power BI, SQL Server, SSIS, and SSAS, I got an offer in business analysis using these on-prem tools and it's a much better salary.  \n\nMy worry is that I will switch to technologies that are getting old and cloud data engineer looks pretty prosperous in the future. \n\nAny suggestions\n\n&amp;#x200B;\n\n[View Poll](https://www.reddit.com/poll/150o5ey)", "author_fullname": "t2_84h380u0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud data Engineering or on-prem Business Analyst", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150o5ey", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689457915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data engineer with 2 years of experience in Azure cloud. &lt;/p&gt;\n\n&lt;p&gt;I have basic knowledge of Power BI, SQL Server, SSIS, and SSAS, I got an offer in business analysis using these on-prem tools and it&amp;#39;s a much better salary.  &lt;/p&gt;\n\n&lt;p&gt;My worry is that I will switch to technologies that are getting old and cloud data engineer looks pretty prosperous in the future. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/150o5ey\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "150o5ey", "is_robot_indexable": true, "report_reasons": null, "author": "TProfessional", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1689630715610, "options": [{"text": "Stick to Cloud Engineering", "id": "23907744"}, {"text": "It worth to learn the on-prem", "id": "23907745"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 41, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150o5ey/cloud_data_engineering_or_onprem_business_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/150o5ey/cloud_data_engineering_or_onprem_business_analyst/", "subreddit_subscribers": 116004, "created_utc": 1689457915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone here familiar working with Syndigo PXM or MDM solution? \n\nI\u2019m starting thinking if is this really the future career? \n\nI need your advise what are the trends for DE role. \ud83d\ude0a", "author_fullname": "t2_7cswt26k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Syndigo MDM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150f1yp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689435350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone here familiar working with Syndigo PXM or MDM solution? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m starting thinking if is this really the future career? &lt;/p&gt;\n\n&lt;p&gt;I need your advise what are the trends for DE role. \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "150f1yp", "is_robot_indexable": true, "report_reasons": null, "author": "Federal_Ad179", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150f1yp/syndigo_mdm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150f1yp/syndigo_mdm/", "subreddit_subscribers": 116004, "created_utc": 1689435350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to Snowflake and I was trying to read about different types of tables. I understood how fail-safe is an internal mechanism in Snowflake that is kept for operational purposes.\n\n But the fail-safe is for 7 days beyond the retention period is what Snowflake docs mention. So in that case, if my retention period is 7 days, then fail-safe will be for another 7 days, which means I have to pay storage costs for 14 days of data for each table right? \n\nWhy can't fail-safe be just as retention period and not on top of retention period? This will save costs considerably if it is a large table. \n\nPS: I know about fail-safe not being a option that can be leveraged by developers. In case of operational failures, Snowflake support team can help recovering the data and that's the reason for fail-safe. ", "author_fullname": "t2_2xxs9nne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding fail-safe in Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15052dq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689405440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to Snowflake and I was trying to read about different types of tables. I understood how fail-safe is an internal mechanism in Snowflake that is kept for operational purposes.&lt;/p&gt;\n\n&lt;p&gt;But the fail-safe is for 7 days beyond the retention period is what Snowflake docs mention. So in that case, if my retention period is 7 days, then fail-safe will be for another 7 days, which means I have to pay storage costs for 14 days of data for each table right? &lt;/p&gt;\n\n&lt;p&gt;Why can&amp;#39;t fail-safe be just as retention period and not on top of retention period? This will save costs considerably if it is a large table. &lt;/p&gt;\n\n&lt;p&gt;PS: I know about fail-safe not being a option that can be leveraged by developers. In case of operational failures, Snowflake support team can help recovering the data and that&amp;#39;s the reason for fail-safe. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15052dq", "is_robot_indexable": true, "report_reasons": null, "author": "inglocines", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15052dq/understanding_failsafe_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15052dq/understanding_failsafe_in_snowflake/", "subreddit_subscribers": 116004, "created_utc": 1689405440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings everyone,\n\nWe are on the verge of initiating a significant overhaul of our team's structure, data value stream, data modeling, and the data warehouse's modeling segment.\n\nGiven the context of our company, with approximately 3,000 - 5,000 employees all depending on data for their tasks, and considering there isn't a pre-existing blueprint for their data maturity journey, how should we proceed?\n\nWhat is an effective, step-by-step approach that has been proven successful in similar situations?", "author_fullname": "t2_55thi7w8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Do You Build Target Operating Model for a Company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150ssbc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689470235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings everyone,&lt;/p&gt;\n\n&lt;p&gt;We are on the verge of initiating a significant overhaul of our team&amp;#39;s structure, data value stream, data modeling, and the data warehouse&amp;#39;s modeling segment.&lt;/p&gt;\n\n&lt;p&gt;Given the context of our company, with approximately 3,000 - 5,000 employees all depending on data for their tasks, and considering there isn&amp;#39;t a pre-existing blueprint for their data maturity journey, how should we proceed?&lt;/p&gt;\n\n&lt;p&gt;What is an effective, step-by-step approach that has been proven successful in similar situations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "150ssbc", "is_robot_indexable": true, "report_reasons": null, "author": "faizfablillah", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150ssbc/how_do_you_build_target_operating_model_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150ssbc/how_do_you_build_target_operating_model_for_a/", "subreddit_subscribers": 116004, "created_utc": 1689470235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a recent grad from the class of 2023 with a degree in Business and Marketing education. I want to pursue a career in data and fell in love with the concept of data engineering. I\u2019ve done a Google data analytics course back in 2021 so I have familiarity with SQL, Tableau, Power BI, Excel. Im really thinking of pursing a masters in DS or in statistics but not sure what programs I should pursue to help me land my first job in data engineering. Any master program recommendations or programs you recommend would be great.", "author_fullname": "t2_s47yjlr8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Master program do you recommend I take?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150qtj0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689464702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a recent grad from the class of 2023 with a degree in Business and Marketing education. I want to pursue a career in data and fell in love with the concept of data engineering. I\u2019ve done a Google data analytics course back in 2021 so I have familiarity with SQL, Tableau, Power BI, Excel. Im really thinking of pursing a masters in DS or in statistics but not sure what programs I should pursue to help me land my first job in data engineering. Any master program recommendations or programs you recommend would be great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "150qtj0", "is_robot_indexable": true, "report_reasons": null, "author": "shouldawouldacoulda0", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150qtj0/what_master_program_do_you_recommend_i_take/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150qtj0/what_master_program_do_you_recommend_i_take/", "subreddit_subscribers": 116004, "created_utc": 1689464702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I'm kinda new to data-engineering\n\nI'm currently working on revamping our data warehouse setup in Snowflake and would like to implement DBT into our workflow. I'm seeking guidance and recommendations from those experienced in Snowflake and DBT on how to optimize our current approach. Here's a summary of our existing setup:\n\n1. We create views on our stage database, which act as the source for our data warehouse.\n2. To merge the data into our data warehouse, we rely on a stored procedure that incorporates these views.\n\nWhile our current setup is functional, we believe incorporating DBT could help improve performance, maintainability, and scalability. We are particularly interested in addressing the following questions:\n\n1. What are the recommended steps for transitioning to DBT for data warehouse management in Snowflake?\n2. How can we extract data from our stage database efficiently using DBT?\n3. Are there any best practices for optimizing data loading using DBT in Snowflake?\n\nWe are excited to explore the potential of DBT and would appreciate any insights, resources, or personal experiences related to implementing DBT in a Snowflake data warehouse setup. Whether it's tutorials, case studies, or practical tips, your expertise will be invaluable in our transition.\n\nSpecifically, we would like to know:\n\n1. How can DBT models be leveraged to streamline our workflow and reduce complexity?\n2. Are there any features or techniques in DBT that can enhance the performance of our data loading process?\n3. Are there any recommended strategies for managing transformations and data quality checks using DBT?\n\nThank you in advance for your time and expertise! I look forward to learning from your experiences and integrating DBT seamlessly into our Snowflake data warehouse setup.", "author_fullname": "t2_2yutl8h5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on implementing DBT for Snowflake data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_150mmbt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689454099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m kinda new to data-engineering&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on revamping our data warehouse setup in Snowflake and would like to implement DBT into our workflow. I&amp;#39;m seeking guidance and recommendations from those experienced in Snowflake and DBT on how to optimize our current approach. Here&amp;#39;s a summary of our existing setup:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We create views on our stage database, which act as the source for our data warehouse.&lt;/li&gt;\n&lt;li&gt;To merge the data into our data warehouse, we rely on a stored procedure that incorporates these views.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;While our current setup is functional, we believe incorporating DBT could help improve performance, maintainability, and scalability. We are particularly interested in addressing the following questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What are the recommended steps for transitioning to DBT for data warehouse management in Snowflake?&lt;/li&gt;\n&lt;li&gt;How can we extract data from our stage database efficiently using DBT?&lt;/li&gt;\n&lt;li&gt;Are there any best practices for optimizing data loading using DBT in Snowflake?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We are excited to explore the potential of DBT and would appreciate any insights, resources, or personal experiences related to implementing DBT in a Snowflake data warehouse setup. Whether it&amp;#39;s tutorials, case studies, or practical tips, your expertise will be invaluable in our transition.&lt;/p&gt;\n\n&lt;p&gt;Specifically, we would like to know:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How can DBT models be leveraged to streamline our workflow and reduce complexity?&lt;/li&gt;\n&lt;li&gt;Are there any features or techniques in DBT that can enhance the performance of our data loading process?&lt;/li&gt;\n&lt;li&gt;Are there any recommended strategies for managing transformations and data quality checks using DBT?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you in advance for your time and expertise! I look forward to learning from your experiences and integrating DBT seamlessly into our Snowflake data warehouse setup.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "150mmbt", "is_robot_indexable": true, "report_reasons": null, "author": "vgowthamvk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/150mmbt/seeking_advice_on_implementing_dbt_for_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/150mmbt/seeking_advice_on_implementing_dbt_for_snowflake/", "subreddit_subscribers": 116004, "created_utc": 1689454099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to purchase a MacBook for my basic tasks relating to data engineering. For instance, running Apache Spark Server and executing PySpark jobs and/or running Apache Airflow Server and executing the code for workflow orchestration.\n\nCurrently, I am using a virtual machine inside my Windows Laptop. So, I am sure that any MacBook Air will outperform deadly with respect to the setup that I am currently using. Plus, I have had enough of reading reviews and watching comparisons between M1 Air and M2 Air.\n\nThis I am posting because I want to get to know the experience from the personal user instead.\n\nI am confused about purchasing which MacBook Air only for personal use considering I will not be replacing it in a year or two.", "author_fullname": "t2_kmi1m0w3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "M1 vs M2 MBA for tasks relating to PySpark or Apache Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15082zu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689415630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to purchase a MacBook for my basic tasks relating to data engineering. For instance, running Apache Spark Server and executing PySpark jobs and/or running Apache Airflow Server and executing the code for workflow orchestration.&lt;/p&gt;\n\n&lt;p&gt;Currently, I am using a virtual machine inside my Windows Laptop. So, I am sure that any MacBook Air will outperform deadly with respect to the setup that I am currently using. Plus, I have had enough of reading reviews and watching comparisons between M1 Air and M2 Air.&lt;/p&gt;\n\n&lt;p&gt;This I am posting because I want to get to know the experience from the personal user instead.&lt;/p&gt;\n\n&lt;p&gt;I am confused about purchasing which MacBook Air only for personal use considering I will not be replacing it in a year or two.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15082zu", "is_robot_indexable": true, "report_reasons": null, "author": "Prudent-Writing-5724", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15082zu/m1_vs_m2_mba_for_tasks_relating_to_pyspark_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15082zu/m1_vs_m2_mba_for_tasks_relating_to_pyspark_or/", "subreddit_subscribers": 116004, "created_utc": 1689415630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ftuqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unit Testing for data engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_150dzb6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.42, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JeG6AEPTyH8uzy3n39-MUYvqhB5xnPdGBpLIW8W9o_Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689432670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/unit-testing-for-data-engineers", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hvYyopF-cZX2WKFRSrbTx_PslHjwqnrG0kQHfuNLsJk.jpg?auto=webp&amp;s=c51efa238a37f2c964e17c669be93c6b29f2fd9f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/hvYyopF-cZX2WKFRSrbTx_PslHjwqnrG0kQHfuNLsJk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e811f98c026cb8f9131ff033c9c32d0f24c7f2aa", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/hvYyopF-cZX2WKFRSrbTx_PslHjwqnrG0kQHfuNLsJk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=404960819ee2fd33af872657472c95c26ece4a4f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/hvYyopF-cZX2WKFRSrbTx_PslHjwqnrG0kQHfuNLsJk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82d740b30ba7f26b5c6dcefe1783d5bf59a90e7f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/hvYyopF-cZX2WKFRSrbTx_PslHjwqnrG0kQHfuNLsJk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d7c5e19e213c8e0547788dc2a8f2a8c32eecf28", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/hvYyopF-cZX2WKFRSrbTx_PslHjwqnrG0kQHfuNLsJk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f41758a992ddd35178cd2f501f4fc7f14b8e9542", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/hvYyopF-cZX2WKFRSrbTx_PslHjwqnrG0kQHfuNLsJk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de802c91aa8ab836fdcf1869220eb01cc40a7b09", "width": 1080, "height": 540}], "variants": {}, "id": "APy3ZRoodILM2d2MRzQ4YrvSvSJa9Z19Xya3CDQkmVQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "150dzb6", "is_robot_indexable": true, "report_reasons": null, "author": "philonoist", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150dzb6/unit_testing_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/unit-testing-for-data-engineers", "subreddit_subscribers": 116004, "created_utc": 1689432670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ftuqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Chat-GPT plugins and Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_150dwlj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/67Z-n6kzGpks-2jD6sMBkFlrxkeUtZ7IEghhHW3r2oE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689432477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "juhache.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://juhache.substack.com/p/chat-gpt-plugins-and-data-engineering", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/01GMlJes8670cvCY8gSaOU-U6g_UPO7l1w4wCeD-UPY.jpg?auto=webp&amp;s=13a1917ae36d972b4368bcf804defb913747c46f", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/01GMlJes8670cvCY8gSaOU-U6g_UPO7l1w4wCeD-UPY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ffc3de90b908118fbd7f037aabe80c74b51a2ed", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/01GMlJes8670cvCY8gSaOU-U6g_UPO7l1w4wCeD-UPY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a87dce3e137c9af896cc581e449f12eaee419088", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/01GMlJes8670cvCY8gSaOU-U6g_UPO7l1w4wCeD-UPY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ca960a8a642de15ca86b4e8f973b56ec72008182", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/01GMlJes8670cvCY8gSaOU-U6g_UPO7l1w4wCeD-UPY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6463906b55c177dfdfc2c7f0c7acdaada0509d7b", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/01GMlJes8670cvCY8gSaOU-U6g_UPO7l1w4wCeD-UPY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a675d07ab79df5ef91cee1025ab32069fc4ef7d", "width": 960, "height": 562}], "variants": {}, "id": "9DsW5dB33_z07FSvheGgB0Z9t7wSr8pHJ8z5z_o0muA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "150dwlj", "is_robot_indexable": true, "report_reasons": null, "author": "philonoist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/150dwlj/chatgpt_plugins_and_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://juhache.substack.com/p/chat-gpt-plugins-and-data-engineering", "subreddit_subscribers": 116004, "created_utc": 1689432477.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}