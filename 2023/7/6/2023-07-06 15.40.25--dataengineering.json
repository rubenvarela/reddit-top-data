{"kind": "Listing", "data": {"after": "t3_14rwet1", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working in an organisation that is going through a process to migrate everything to a consolidated cloud platform (Azure).  Our BI stack moving forward is Power BI, ADF / Synapse, Databricks and Azure Datalake.  I'm not an infrastructure guy, but I've been working with out infrastructure team and some consultants in getting our platform setup and secured.\n\nFirstly, my overwhelming experience over the past few weeks has been that setting something up in the cloud is super simple... but setting something up in the cloud *and ensuring it meets basic security requirements* is considerably more complicated.  Really, *really* complicated.  Unsurprisingly, it's a specific skill.\n\nSecondly, the big pitch for cloud services is that you \"only pay for what you use\".  The problem is that *everything* costs and it often costs a lot.  And while cloud providers give you some options to manage costs, a lot of this is lip service.  For example, we have VM's setup as a gateway to our on-premise systems.  These only need to be switched on while ETL jobs are running.  You'd think that ADF or Synapse pipelines would have a basic connector for managing Azure VMs.... but, nope.  You can do this programatically using Python or Powershell... but those need to be running somewhere, like Azure Function which, you guessed it, costs more money.  Not to mention the time and effort to develop something.  \n\nThis leads me to me third issue...  scalability.  Cloud services pitch nearly infinite scalability, but they are talking about scaling *up*.  Scaling downwards?  Not so much.  Want to run a Python notebook in Synapse?  The minimum cluster uses nodes with 4 vCores and 32GB memory, and you must have *at least three nodes*.  My 'hello world' script (metaphorically speaking) doesn't need 12 cores and 96GB memory.\n\nDon't get me wrong... I get it... cloud services open up all sorts of options for large businesses.  But how many orgs have been massively oversold on cloud?  How many thought it would reduce headcount in their infrastructure teams, when these teams were already running on bare bones in the first place?  And how many thought cloud services would give them levels of scalability that they'll never actually need?", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is cloud a big scam?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rt3ur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 128, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 128, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688604986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working in an organisation that is going through a process to migrate everything to a consolidated cloud platform (Azure).  Our BI stack moving forward is Power BI, ADF / Synapse, Databricks and Azure Datalake.  I&amp;#39;m not an infrastructure guy, but I&amp;#39;ve been working with out infrastructure team and some consultants in getting our platform setup and secured.&lt;/p&gt;\n\n&lt;p&gt;Firstly, my overwhelming experience over the past few weeks has been that setting something up in the cloud is super simple... but setting something up in the cloud &lt;em&gt;and ensuring it meets basic security requirements&lt;/em&gt; is considerably more complicated.  Really, &lt;em&gt;really&lt;/em&gt; complicated.  Unsurprisingly, it&amp;#39;s a specific skill.&lt;/p&gt;\n\n&lt;p&gt;Secondly, the big pitch for cloud services is that you &amp;quot;only pay for what you use&amp;quot;.  The problem is that &lt;em&gt;everything&lt;/em&gt; costs and it often costs a lot.  And while cloud providers give you some options to manage costs, a lot of this is lip service.  For example, we have VM&amp;#39;s setup as a gateway to our on-premise systems.  These only need to be switched on while ETL jobs are running.  You&amp;#39;d think that ADF or Synapse pipelines would have a basic connector for managing Azure VMs.... but, nope.  You can do this programatically using Python or Powershell... but those need to be running somewhere, like Azure Function which, you guessed it, costs more money.  Not to mention the time and effort to develop something.  &lt;/p&gt;\n\n&lt;p&gt;This leads me to me third issue...  scalability.  Cloud services pitch nearly infinite scalability, but they are talking about scaling &lt;em&gt;up&lt;/em&gt;.  Scaling downwards?  Not so much.  Want to run a Python notebook in Synapse?  The minimum cluster uses nodes with 4 vCores and 32GB memory, and you must have &lt;em&gt;at least three nodes&lt;/em&gt;.  My &amp;#39;hello world&amp;#39; script (metaphorically speaking) doesn&amp;#39;t need 12 cores and 96GB memory.&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t get me wrong... I get it... cloud services open up all sorts of options for large businesses.  But how many orgs have been massively oversold on cloud?  How many thought it would reduce headcount in their infrastructure teams, when these teams were already running on bare bones in the first place?  And how many thought cloud services would give them levels of scalability that they&amp;#39;ll never actually need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rt3ur", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 82, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rt3ur/is_cloud_a_big_scam/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rt3ur/is_cloud_a_big_scam/", "subreddit_subscribers": 114363, "created_utc": 1688604986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I get the sense during interviews that some people are more focused on trying to figure out anything I don't know, rather than talking about skills that actually pertain to the role. \n\nA lot of times, people with traditional computer science backgrounds talk to me in interviews like I'm an \"exhibit\". Getting comments like, \"Oh, I've always wanted to meet a self-taught person\", or \"You've done well so far, for a self-taught engineer.\" \n\nThen proceed to ask me questions about something oddly specific like linting, or data warehouse processing algorithms. \n\nI feel like I have to be \"beyond perfect\" in a lot of situations, and even then people will still waste my time, and go with someone with a more traditional computer science background. \n\nIt's really exhausting, and is making me consider doing a post-bach or masters, just so I don't have to deal with this anymore. \n\nContext - I'm a senior data engineer who leads a team with a lot of members that have under-graduate or masters degrees in comp sci or data science. ", "author_fullname": "t2_fhmml14j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any self-taught data engineers here who feel like there are a lot of people who are focused on discrediting you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rqj5o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688598315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I get the sense during interviews that some people are more focused on trying to figure out anything I don&amp;#39;t know, rather than talking about skills that actually pertain to the role. &lt;/p&gt;\n\n&lt;p&gt;A lot of times, people with traditional computer science backgrounds talk to me in interviews like I&amp;#39;m an &amp;quot;exhibit&amp;quot;. Getting comments like, &amp;quot;Oh, I&amp;#39;ve always wanted to meet a self-taught person&amp;quot;, or &amp;quot;You&amp;#39;ve done well so far, for a self-taught engineer.&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Then proceed to ask me questions about something oddly specific like linting, or data warehouse processing algorithms. &lt;/p&gt;\n\n&lt;p&gt;I feel like I have to be &amp;quot;beyond perfect&amp;quot; in a lot of situations, and even then people will still waste my time, and go with someone with a more traditional computer science background. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s really exhausting, and is making me consider doing a post-bach or masters, just so I don&amp;#39;t have to deal with this anymore. &lt;/p&gt;\n\n&lt;p&gt;Context - I&amp;#39;m a senior data engineer who leads a team with a lot of members that have under-graduate or masters degrees in comp sci or data science. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rqj5o", "is_robot_indexable": true, "report_reasons": null, "author": "Capable-Jicama2155", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rqj5o/any_selftaught_data_engineers_here_who_feel_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rqj5o/any_selftaught_data_engineers_here_who_feel_like/", "subreddit_subscribers": 114363, "created_utc": 1688598315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My organization is trying to modernize and have put an unfortunate soul (me) in charge of creating a CI/CD pipeline for our products. Our goal is to use Jenkins to communicate via Webhooks from our DevOps platform, but there's been a number of roadblocks given our IT infrastructure. I've also had some trouble communicating *why* CI/CD is important.\n\nI'm curious what others have experienced in setting up a CI/CD platform.", "author_fullname": "t2_98rrwspa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a CI/CD pipeline difficult to set up in your experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rmmkp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688589964.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688589545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My organization is trying to modernize and have put an unfortunate soul (me) in charge of creating a CI/CD pipeline for our products. Our goal is to use Jenkins to communicate via Webhooks from our DevOps platform, but there&amp;#39;s been a number of roadblocks given our IT infrastructure. I&amp;#39;ve also had some trouble communicating &lt;em&gt;why&lt;/em&gt; CI/CD is important.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious what others have experienced in setting up a CI/CD platform.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rmmkp", "is_robot_indexable": true, "report_reasons": null, "author": "what_duck", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14rmmkp/is_a_cicd_pipeline_difficult_to_set_up_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rmmkp/is_a_cicd_pipeline_difficult_to_set_up_in_your/", "subreddit_subscribers": 114363, "created_utc": 1688589545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Start Your Stream Processing Journey With Just 4 Lines of Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_14rr4j7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rM33fV24PR34ncxBY2HaZlva5wASxIaGBQgQP93lhu0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688599769.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/better-programming/start-your-stream-processing-journey-with-just-4-lines-of-code-5863573268b9", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VkM_bZlEhsbXIcGRTmiETAOzLt9gZXAT2bnZFgdgwYY.jpg?auto=webp&amp;v=enabled&amp;s=96037c2e4187449c5b60edeb74f14c5aef604cc3", "width": 1200, "height": 656}, "resolutions": [{"url": "https://external-preview.redd.it/VkM_bZlEhsbXIcGRTmiETAOzLt9gZXAT2bnZFgdgwYY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce44d4af323d22fcd15d40142cc99e098c9ce0e3", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/VkM_bZlEhsbXIcGRTmiETAOzLt9gZXAT2bnZFgdgwYY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39ccdaafb9b1f72e6d773303bdfe25b123c31522", "width": 216, "height": 118}, {"url": "https://external-preview.redd.it/VkM_bZlEhsbXIcGRTmiETAOzLt9gZXAT2bnZFgdgwYY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff69588a49f6398321e181e71ccde381316177d2", "width": 320, "height": 174}, {"url": "https://external-preview.redd.it/VkM_bZlEhsbXIcGRTmiETAOzLt9gZXAT2bnZFgdgwYY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64655938ffcf192ac5c2e0e706cda496e631dc91", "width": 640, "height": 349}, {"url": "https://external-preview.redd.it/VkM_bZlEhsbXIcGRTmiETAOzLt9gZXAT2bnZFgdgwYY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1341b1f6b373ee7c4ccd2a4de90d29283c6bb08b", "width": 960, "height": 524}, {"url": "https://external-preview.redd.it/VkM_bZlEhsbXIcGRTmiETAOzLt9gZXAT2bnZFgdgwYY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fad8c6a56097d367729f4c86ccd40ec6038662d9", "width": 1080, "height": 590}], "variants": {}, "id": "tGrp97P5DujoEKMZj9j77D-T_3XhXYaGgGwklqTvcFk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rr4j7", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rr4j7/start_your_stream_processing_journey_with_just_4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/better-programming/start-your-stream-processing-journey-with-just-4-lines-of-code-5863573268b9", "subreddit_subscribers": 114363, "created_utc": 1688599769.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently got a job after completing my Bachelors, as a trainee/junior data engineer in a Fintech , During my college times everyone was talking about SDE/backend/frontend/mobile-dev jobs and I have idea about them that a good developer can earn good with few years of experience.But Data engineering was unheard of and I knew a few things about data science and understood that these 2 are different .\n\nCan you help me by answering these 4 questions in short?\n(even yes /no answers will be appreciated)\n\n1.)Since the demand of Software developers is high and they are in demand everywhere, do data engineers have similar kind of demand in big MNCs and faang type companies.Since Data is increasing day by day and every co. I think would use them so this job profile should be hot but I haven't heard about this job till I got my current job offer.\n\n2.)I have explored frontend and backend web dev , and somewhat liked backend web dev using node js, and while practicing DSA and writing backend I started a liking towards programming, so do data engineers get to code enough ?\n\n3.) I got a basic intro to SQL in my college and then I didn't got much interested in it , so do you guys already have a interest in SQL when you choose Data engineer at first or you started enjoying it when you started working with it?\n\n4.)Can you share that salaries of software developer in your company vs your salary as a data engineer with same year of experience.Is there a huge difference or is it somewhat similar.", "author_fullname": "t2_jh44nvdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do data Engineers get paid Similar to software developers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14res9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688572706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently got a job after completing my Bachelors, as a trainee/junior data engineer in a Fintech , During my college times everyone was talking about SDE/backend/frontend/mobile-dev jobs and I have idea about them that a good developer can earn good with few years of experience.But Data engineering was unheard of and I knew a few things about data science and understood that these 2 are different .&lt;/p&gt;\n\n&lt;p&gt;Can you help me by answering these 4 questions in short?\n(even yes /no answers will be appreciated)&lt;/p&gt;\n\n&lt;p&gt;1.)Since the demand of Software developers is high and they are in demand everywhere, do data engineers have similar kind of demand in big MNCs and faang type companies.Since Data is increasing day by day and every co. I think would use them so this job profile should be hot but I haven&amp;#39;t heard about this job till I got my current job offer.&lt;/p&gt;\n\n&lt;p&gt;2.)I have explored frontend and backend web dev , and somewhat liked backend web dev using node js, and while practicing DSA and writing backend I started a liking towards programming, so do data engineers get to code enough ?&lt;/p&gt;\n\n&lt;p&gt;3.) I got a basic intro to SQL in my college and then I didn&amp;#39;t got much interested in it , so do you guys already have a interest in SQL when you choose Data engineer at first or you started enjoying it when you started working with it?&lt;/p&gt;\n\n&lt;p&gt;4.)Can you share that salaries of software developer in your company vs your salary as a data engineer with same year of experience.Is there a huge difference or is it somewhat similar.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14res9p", "is_robot_indexable": true, "report_reasons": null, "author": "micky_357000", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14res9p/do_data_engineers_get_paid_similar_to_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14res9p/do_data_engineers_get_paid_similar_to_software/", "subreddit_subscribers": 114363, "created_utc": 1688572706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Job requirements are ridiculous, On LinkedIn Data Engineer roles require 3+ years of experience and Machine learning Roles require around 7+ years of experience. I was preparing for a data engineer role but perhaps there's no point in doing that anymore, Maybe I should start focusing on being a data analyst and then switch jobs?? What advice would you guys give to a guy in college interested in the field of data??", "author_fullname": "t2_3hhrw7ib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No entry level jobs for data engineer or machine learning engineer??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s0d0h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688624978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Job requirements are ridiculous, On LinkedIn Data Engineer roles require 3+ years of experience and Machine learning Roles require around 7+ years of experience. I was preparing for a data engineer role but perhaps there&amp;#39;s no point in doing that anymore, Maybe I should start focusing on being a data analyst and then switch jobs?? What advice would you guys give to a guy in college interested in the field of data??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14s0d0h", "is_robot_indexable": true, "report_reasons": null, "author": "AnishNehete", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s0d0h/no_entry_level_jobs_for_data_engineer_or_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s0d0h/no_entry_level_jobs_for_data_engineer_or_machine/", "subreddit_subscribers": 114363, "created_utc": 1688624978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I plan on starting a simple ETL pipeline using Airflow and Kafka and want your guys' opinion on what I plan to do.\n\nI am using the [random user API](https://randomuser.me/api/) to get the data, then performing a simple transformation to prepare it to be put into its respective tables. I plan to simulate spikes of user data generating using a random number generator via Airflow and then pass the data into Kafka using producer nodes. Then I can put the data into a PostgreSQL RDS instance for the data to be stored. I know I don't need to use Kafka, but I want to dabble in Kafka a little to gain some experience. On the note of experience, I know the basic jist of Kafka and Airflow, but I am by no means an expert on either of them; I want to apply the knowledge I have learned so far.\n\nHere is what the DAG would look like:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64\n\n&amp;#x200B;\n\nHere is what the data model would look like:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=655c0eb2d4f5f1034199871f479cec86029f4446\n\n&amp;#x200B;\n\nHere is my [GitHub](https://github.com/Nishal3/) if you want to see and critique my other projects.", "author_fullname": "t2_3arqiq34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Data Engineering Project with Kafka and Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 12, "top_awarded_type": null, "hide_score": false, "media_metadata": {"01epxslza6ab1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 9, "x": 108, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84e4414faacf34bab670573e90939bdf706d18e1"}, {"y": 18, "x": 216, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=638e7a75ac5361579e82a258453133cc6bb18245"}, {"y": 27, "x": 320, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f41f67c8d53ce2403756a59203cb07d28fb133b3"}, {"y": 55, "x": 640, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2c65ddfd03037ac0117eadca4ed0310c03e95e2"}, {"y": 82, "x": 960, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1f20926c6a1b3f7acf25c82333fed1b77c2be9c"}], "s": {"y": 90, "x": 1046, "u": "https://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64"}, "id": "01epxslza6ab1"}, "varxvs70b6ab1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80356744fcd1539a924fc938c05d34ab0098fb43"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce5190fbb4f8d074f3ec88f32897b45d352f0b36"}, {"y": 150, "x": 320, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd7b29c7290da1333ea6980cb8dad64c1b7f77db"}, {"y": 300, "x": 640, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3661598793f34af557ac951512f8c1486ec27453"}, {"y": 451, "x": 960, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1eb10957b2ddb649302821ce8e0ddad18052fbad"}, {"y": 507, "x": 1080, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2804a9739228cac3bda0cfebce10aeb95db00c47"}], "s": {"y": 564, "x": 1200, "u": "https://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=655c0eb2d4f5f1034199871f479cec86029f4446"}, "id": "varxvs70b6ab1"}}, "name": "t3_14rfp9v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eZcC3yPDi1xZFKdBoki8y5_BheHkwheH-I60n_qWzxI.jpg", "edited": 1688577655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688574605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I plan on starting a simple ETL pipeline using Airflow and Kafka and want your guys&amp;#39; opinion on what I plan to do.&lt;/p&gt;\n\n&lt;p&gt;I am using the &lt;a href=\"https://randomuser.me/api/\"&gt;random user API&lt;/a&gt; to get the data, then performing a simple transformation to prepare it to be put into its respective tables. I plan to simulate spikes of user data generating using a random number generator via Airflow and then pass the data into Kafka using producer nodes. Then I can put the data into a PostgreSQL RDS instance for the data to be stored. I know I don&amp;#39;t need to use Kafka, but I want to dabble in Kafka a little to gain some experience. On the note of experience, I know the basic jist of Kafka and Airflow, but I am by no means an expert on either of them; I want to apply the knowledge I have learned so far.&lt;/p&gt;\n\n&lt;p&gt;Here is what the DAG would look like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64\"&gt;https://preview.redd.it/01epxslza6ab1.jpg?width=1046&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1655078aa95b232ba08a6bf70bdb2a2193bc3e64&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is what the data model would look like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=655c0eb2d4f5f1034199871f479cec86029f4446\"&gt;https://preview.redd.it/varxvs70b6ab1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=655c0eb2d4f5f1034199871f479cec86029f4446&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is my &lt;a href=\"https://github.com/Nishal3/\"&gt;GitHub&lt;/a&gt; if you want to see and critique my other projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rfp9v", "is_robot_indexable": true, "report_reasons": null, "author": "RepresentativePen297", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rfp9v/beginner_data_engineering_project_with_kafka_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rfp9v/beginner_data_engineering_project_with_kafka_and/", "subreddit_subscribers": 114363, "created_utc": 1688574605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Every Major Announcement at Snowflake Summit 2023 and 1 Word Never Mentioned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "name": "t3_14roylf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dReVV7G2VUQpzoOs4ibJgMNunvywct2RJX65zpfGl7E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688594696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/summit-2023", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?auto=webp&amp;v=enabled&amp;s=0352906f85b88e570a23caff7459e8ca8bb0a199", "width": 1200, "height": 681}, "resolutions": [{"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6b003ba5cc8d94470bd887537a884fff3897135", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6662a48c2d494b2178152935027a7126d71a9bb", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6c508cc66d9646c54c0776562f119623378c10e", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7651f62818d66a56e3cf767344f092785aca2621", "width": 640, "height": 363}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=849a4f468e289eaa1761c390c88c168f543e2814", "width": 960, "height": 544}, {"url": "https://external-preview.redd.it/GHdW1VwxUq5ZbNRWScgcwEDvxOiwTMbqdp5cQMZHwrs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64f89276363ebd2c3537c4f7cc0ec646bb5da275", "width": 1080, "height": 612}], "variants": {}, "id": "iG_2gOkQJ7vEPRvHmIKIANcgo69jtGBrPK32a06sAtc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14roylf", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14roylf/every_major_announcement_at_snowflake_summit_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/summit-2023", "subreddit_subscribers": 114363, "created_utc": 1688594696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the fundamental differences between Data Warehousing workloads between Databricks and Redshift?\n\nAssuming cost is not a factor, what features are present in one that are not in another?\n\nDatabricks announced Materialized views which is something that Redshift has had for a while.\n\nRedshift has Dynamic Data Masking which I believe Databricks doesn't have the equivalent\n\nBoth seem to have the merge command available.\n\nRedshift can be used natively with Step Functions for orchestration which is somewhat the equivalent of DB workflows\n\nDatabricks has built in quality rules with DLT and I'm not aware of anything similar in Redshift \n\nI get the huge difference in approaches but I'm after more low level features that are available in one and not in the other that make the life of a Data Warehouse engineer easier?\n\nThanks! \n\nNote: this is not a which one is better discussion but more so a healthy comparison between both", "author_fullname": "t2_4luizwuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks vs Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s2msk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688632065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the fundamental differences between Data Warehousing workloads between Databricks and Redshift?&lt;/p&gt;\n\n&lt;p&gt;Assuming cost is not a factor, what features are present in one that are not in another?&lt;/p&gt;\n\n&lt;p&gt;Databricks announced Materialized views which is something that Redshift has had for a while.&lt;/p&gt;\n\n&lt;p&gt;Redshift has Dynamic Data Masking which I believe Databricks doesn&amp;#39;t have the equivalent&lt;/p&gt;\n\n&lt;p&gt;Both seem to have the merge command available.&lt;/p&gt;\n\n&lt;p&gt;Redshift can be used natively with Step Functions for orchestration which is somewhat the equivalent of DB workflows&lt;/p&gt;\n\n&lt;p&gt;Databricks has built in quality rules with DLT and I&amp;#39;m not aware of anything similar in Redshift &lt;/p&gt;\n\n&lt;p&gt;I get the huge difference in approaches but I&amp;#39;m after more low level features that are available in one and not in the other that make the life of a Data Warehouse engineer easier?&lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n\n&lt;p&gt;Note: this is not a which one is better discussion but more so a healthy comparison between both&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14s2msk", "is_robot_indexable": true, "report_reasons": null, "author": "the_travelo_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s2msk/databricks_vs_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s2msk/databricks_vs_redshift/", "subreddit_subscribers": 114363, "created_utc": 1688632065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nMy team is in the process of building out an Azure data lake using delta lake tables.  When we started the development, we utilized hive\\_metastore instead of unity catalog; but some unity features are now catching our eye.\n\nThere's some documentation out there regarding the upgrade process, but all of these upgrade scenarios only work on **external** tables managed by hive\\_metastore.  Unfortunately, we are currently using **managed** tables within hive\\_metastore. Documentation/blogs for managed table upgrades seems sparse.\n\n[This MS article](https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/migrate#--upgrade-a-table-to-unity-catalog) talks about the external upgrade process using the wizard, but only briefly talks about the upgrade process for managed tables at the bottom (basically just running CTAS statements).\n\nHas anyone gone through this upgrade process?  Specifically from managed tables to Unity?\n\nThank you very much for any info/stories/lessons learned!\n\n&amp;#x200B;", "author_fullname": "t2_4mzchybu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading from hive_metastore (Managed Tables) to Unity Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rwj7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688614050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;My team is in the process of building out an Azure data lake using delta lake tables.  When we started the development, we utilized hive_metastore instead of unity catalog; but some unity features are now catching our eye.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s some documentation out there regarding the upgrade process, but all of these upgrade scenarios only work on &lt;strong&gt;external&lt;/strong&gt; tables managed by hive_metastore.  Unfortunately, we are currently using &lt;strong&gt;managed&lt;/strong&gt; tables within hive_metastore. Documentation/blogs for managed table upgrades seems sparse.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/migrate#--upgrade-a-table-to-unity-catalog\"&gt;This MS article&lt;/a&gt; talks about the external upgrade process using the wizard, but only briefly talks about the upgrade process for managed tables at the bottom (basically just running CTAS statements).&lt;/p&gt;\n\n&lt;p&gt;Has anyone gone through this upgrade process?  Specifically from managed tables to Unity?&lt;/p&gt;\n\n&lt;p&gt;Thank you very much for any info/stories/lessons learned!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?auto=webp&amp;v=enabled&amp;s=8e9dd29e55be5f9d4be03f8a2ca6dc669418c160", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c681715b246565ff9e7dfd8843f18ead842afeb2", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b70c2ce2562a35082ef9647f1b3db65e880827dd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=448b5cac6633b9e14f4209e70d3996bf0d0f97b6", "width": 320, "height": 320}], "variants": {}, "id": "LVmzWMJU1UZwRubzQYJZSar-z-Rq8ntUH65yhQyfxB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rwj7h", "is_robot_indexable": true, "report_reasons": null, "author": "oneDatumPlease", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rwj7h/upgrading_from_hive_metastore_managed_tables_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rwj7h/upgrading_from_hive_metastore_managed_tables_to/", "subreddit_subscribers": 114363, "created_utc": 1688614050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe are starting a new team to work don data engineering/data warehouse at my current company. Over the last couple of weeks, I am doing lot of reading to identify a correct tech stack.\n\nConsiderations:\n\n1. Our DB is in the range of couple of hundred GBs, not huge in terms of TBs\n2. In the short future, we would want to get started with reporting (BI) with an eye on Data Science/ML later \n3. We're an AWS heavy shop. So naturally, our first consideration is RedShift.\n\nDuring my short research, I have heard good things about SnowFlake and Redshift seems to be underwhelming as data warehouse. But, considering our data size and cost, I'm not sure Snowflake would be a good choice for us.\n\nSo any suggestions on the techstack (building ETL pipeline, orchestration tools, data warehouse with ability or providing supportive tools to build self serving reports) would be greatly appreciated.\n\nThank you", "author_fullname": "t2_2gcm7kx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with choosing techstack for a new DE team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rildp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688580682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We are starting a new team to work don data engineering/data warehouse at my current company. Over the last couple of weeks, I am doing lot of reading to identify a correct tech stack.&lt;/p&gt;\n\n&lt;p&gt;Considerations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Our DB is in the range of couple of hundred GBs, not huge in terms of TBs&lt;/li&gt;\n&lt;li&gt;In the short future, we would want to get started with reporting (BI) with an eye on Data Science/ML later &lt;/li&gt;\n&lt;li&gt;We&amp;#39;re an AWS heavy shop. So naturally, our first consideration is RedShift.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;During my short research, I have heard good things about SnowFlake and Redshift seems to be underwhelming as data warehouse. But, considering our data size and cost, I&amp;#39;m not sure Snowflake would be a good choice for us.&lt;/p&gt;\n\n&lt;p&gt;So any suggestions on the techstack (building ETL pipeline, orchestration tools, data warehouse with ability or providing supportive tools to build self serving reports) would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rildp", "is_robot_indexable": true, "report_reasons": null, "author": "sasu1992", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rildp/help_with_choosing_techstack_for_a_new_de_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rildp/help_with_choosing_techstack_for_a_new_de_team/", "subreddit_subscribers": 114363, "created_utc": 1688580682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_11542k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implement AI data pipelines with Langchain, Airbyte, and Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_14rhh9l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yWcVfn-tLMgAI7K286VmrEybc86CmyhunF3lTZ9hgxY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688578305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/tutorials/implement-ai-data-pipelines-with-langchain-airbyte-and-dagster", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?auto=webp&amp;v=enabled&amp;s=1af6048fcc13938bfecab53fb0e90911c070be09", "width": 1000, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88dd319e2433f7c5a955b28528634d479371c768", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c013286161a3276a638993530a3045d0cc05b0ee", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66581eb66efeccbe1086349b85b378a8e9b5f5cd", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8363a081c698d1000e4e4fcabfacf1b1ea9e2c80", "width": 640, "height": 401}, {"url": "https://external-preview.redd.it/xnkzSq_CDInZdpt1jbE2hIqIS5fVmJ484kP5EPFBfa4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7028277736d139a2066ccffb094c7efa4a56baba", "width": 960, "height": 602}], "variants": {}, "id": "6UwY4HhvOQZGtlu_FO200MjNRPVvIqZC_OnXRYlDO6Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rhh9l", "is_robot_indexable": true, "report_reasons": null, "author": "jeanlaf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rhh9l/implement_ai_data_pipelines_with_langchain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/tutorials/implement-ai-data-pipelines-with-langchain-airbyte-and-dagster", "subreddit_subscribers": 114363, "created_utc": 1688578305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\nLet's say that your current job only allows you to use excel, do you think it would be worth studying outside to prepare for new positions that use power bi, sql, python and others? Or do you think it wouldn't be of much value to learn something that I can't put into practice right away? Because all this would consume time and resources, let's say the time after work, whether on weekends or on weekdays. Or would I be better off using that time to learn things useful for my current job? What career advice would you give?", "author_fullname": "t2_cne2tl51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you study tools that are not applicable to your current job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rrqnr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688601303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say that your current job only allows you to use excel, do you think it would be worth studying outside to prepare for new positions that use power bi, sql, python and others? Or do you think it wouldn&amp;#39;t be of much value to learn something that I can&amp;#39;t put into practice right away? Because all this would consume time and resources, let&amp;#39;s say the time after work, whether on weekends or on weekdays. Or would I be better off using that time to learn things useful for my current job? What career advice would you give?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rrqnr", "is_robot_indexable": true, "report_reasons": null, "author": "gintokiredditbr", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rrqnr/do_you_study_tools_that_are_not_applicable_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rrqnr/do_you_study_tools_that_are_not_applicable_to/", "subreddit_subscribers": 114363, "created_utc": 1688601303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Data Engineers,\n\nWe recently [announced](https://www.reddit.com/r/dataengineering/comments/14dgupv/new_de_community_looking_for_mods/) that we would be opening up a new community for data engineering professionals to network and join in-person events. We had over 300+ signups on the waitlist with data engineers from over 33 countries. We've sent out emails to everyone on the waitlist - if you didn't receive an email, please check your spam folder or reach out to info@dataengineering.wiki.\n\nWe are now generally accepting members and you can [join here](https://community.dataengineering.wiki/). \ud83e\udd73\n\n&amp;#x200B;\n\n[This could be you](https://i.redd.it/7t1ig7dlf6ab1.gif)\n\nWe've had a lot of offers to help out and we've put together a few ways you can get involved in the professional community. If you're interested in any of these, please message the mod team:\n\n1. **Volunteer to speak:** we are putting together some local and virtual meetups and are looking for speakers to share something they are passionate about.\n2. **Help organize a meetup:** if you're interested in starting a local meetup in your area let us know and we can connect you with speakers and resources to help you get it started.\n3. **Join as an existing meetup:** we can create a space just for your local area which you can customize and use for free to operate your existing meetup.\n4. **Contribute to our newsletter:** we run a free monthly newsletter and are always looking for interesting ideas to share.\n5. **Share your story:** share your written story about how you got to where you are today and give advice and inspire others who might want to take the same path.\n6. **Share your feedback:** most importantly, we need your feedback to keep improving this community. If you would be willing to leave us a review that we can use externally, please let us know!\n\nAs always, we are listening to your feedback and using it to shape the community and we cannot do it without you. Thank you to everyone who has offered their time, help, and expertise to make our community great.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Professional Data Engineering Community", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7t1ig7dlf6ab1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/7t1ig7dlf6ab1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=c0824e0a9dd0c41e701f9b59130398d415814e74"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/7t1ig7dlf6ab1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=bd846bacdb14cd24a6a23be46392e1e3faace672"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/7t1ig7dlf6ab1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=ed8eb361cb9119cb29387cb047bc9befa992df4d"}], "s": {"y": 270, "gif": "https://i.redd.it/7t1ig7dlf6ab1.gif", "mp4": "https://preview.redd.it/7t1ig7dlf6ab1.gif?format=mp4&amp;v=enabled&amp;s=e337a1528c70290c68f4827092d5ebcb097201a0", "x": 480}, "id": "7t1ig7dlf6ab1"}}, "name": "t3_14rguyt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/-USL2EfsHXULEhtptOG1XKYcO-1oop69-iMrWTy__88.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688577029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;We recently &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14dgupv/new_de_community_looking_for_mods/\"&gt;announced&lt;/a&gt; that we would be opening up a new community for data engineering professionals to network and join in-person events. We had over 300+ signups on the waitlist with data engineers from over 33 countries. We&amp;#39;ve sent out emails to everyone on the waitlist - if you didn&amp;#39;t receive an email, please check your spam folder or reach out to &lt;a href=\"mailto:info@dataengineering.wiki\"&gt;info@dataengineering.wiki&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;We are now generally accepting members and you can &lt;a href=\"https://community.dataengineering.wiki/\"&gt;join here&lt;/a&gt;. \ud83e\udd73&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/7t1ig7dlf6ab1.gif\"&gt;This could be you&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve had a lot of offers to help out and we&amp;#39;ve put together a few ways you can get involved in the professional community. If you&amp;#39;re interested in any of these, please message the mod team:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Volunteer to speak:&lt;/strong&gt; we are putting together some local and virtual meetups and are looking for speakers to share something they are passionate about.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Help organize a meetup:&lt;/strong&gt; if you&amp;#39;re interested in starting a local meetup in your area let us know and we can connect you with speakers and resources to help you get it started.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Join as an existing meetup:&lt;/strong&gt; we can create a space just for your local area which you can customize and use for free to operate your existing meetup.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Contribute to our newsletter:&lt;/strong&gt; we run a free monthly newsletter and are always looking for interesting ideas to share.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Share your story:&lt;/strong&gt; share your written story about how you got to where you are today and give advice and inspire others who might want to take the same path.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Share your feedback:&lt;/strong&gt; most importantly, we need your feedback to keep improving this community. If you would be willing to leave us a review that we can use externally, please let us know!&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;As always, we are listening to your feedback and using it to shape the community and we cannot do it without you. Thank you to everyone who has offered their time, help, and expertise to make our community great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5d8a87e8-a952-11eb-9a8a-0e3979f03641", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "14rguyt", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rguyt/professional_data_engineering_community/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rguyt/professional_data_engineering_community/", "subreddit_subscribers": 114363, "created_utc": 1688577029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got into data engineering since there are a lot of open source tools to play around with.\n\nNow, recruiters are looking into experience with Databricks instead of Spark.\n\nSnowflake instead of Postgres and MySQL.\n\nYou also need certifications on AWS, Azure or GCP which despite having free credits, at some point will require you to pay with your credit card to use any of the services.\n\nI know that there are still lot of open source pipelines and free tools but the direction for most groups seem to be closed source and pay to use.", "author_fullname": "t2_a0i580op", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering getting closed source?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ryr4w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688620266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got into data engineering since there are a lot of open source tools to play around with.&lt;/p&gt;\n\n&lt;p&gt;Now, recruiters are looking into experience with Databricks instead of Spark.&lt;/p&gt;\n\n&lt;p&gt;Snowflake instead of Postgres and MySQL.&lt;/p&gt;\n\n&lt;p&gt;You also need certifications on AWS, Azure or GCP which despite having free credits, at some point will require you to pay with your credit card to use any of the services.&lt;/p&gt;\n\n&lt;p&gt;I know that there are still lot of open source pipelines and free tools but the direction for most groups seem to be closed source and pay to use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ryr4w", "is_robot_indexable": true, "report_reasons": null, "author": "lezzgooooo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ryr4w/data_engineering_getting_closed_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ryr4w/data_engineering_getting_closed_source/", "subreddit_subscribers": 114363, "created_utc": 1688620266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I kind of got into data engineering by chance but my interest after reading a few chapters from 'Design Data Intensive Applications' book is in database engines and tools like Kafka or Spark. I wonder how people break into this field of development. Most of discussions I find is about SQL and writing Python scripts which is something I do as well but I imagine it'd more be interesting in developing the tools underlying instead. I found r/databasedevelopment pretty good but it's not that active.", "author_fullname": "t2_56ggy9bk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does it take to break to into database engine development or tools like Kafka?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rrelb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688600458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I kind of got into data engineering by chance but my interest after reading a few chapters from &amp;#39;Design Data Intensive Applications&amp;#39; book is in database engines and tools like Kafka or Spark. I wonder how people break into this field of development. Most of discussions I find is about SQL and writing Python scripts which is something I do as well but I imagine it&amp;#39;d more be interesting in developing the tools underlying instead. I found &lt;a href=\"/r/databasedevelopment\"&gt;r/databasedevelopment&lt;/a&gt; pretty good but it&amp;#39;s not that active.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14rrelb", "is_robot_indexable": true, "report_reasons": null, "author": "snabx", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rrelb/what_does_it_take_to_break_to_into_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rrelb/what_does_it_take_to_break_to_into_database/", "subreddit_subscribers": 114363, "created_utc": 1688600458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One thing I've realized in my career:\nSimilar to the \"no one has gotten fired for hiring IBM\" trope, we are solidly in a a 20 year era where due to Microsoft by and large keeping their enterprise licensing bundled and their terms of service similar and more consolidated for Lawyers to interpret, for any medium to large company already on Microsoft for office, word, 365, teams, etc. had a massive incumbency advantage to adopt Microsoft.\n\nTo me this \"bundling\" is somewhat anti competitive and is a natural monopoly of sorts. It's in aggregate efficient for the world for lawyers to need to review less contracts and info sec people to review less policies, but it leads to insane market concentration.\n\nIf any of y'all had the pain of working for a fortune 500 company with strict IT approval/compliance processes, y'all will know of the pain for getting any software approved and installed.  It takes tremendous time and political capital to get anything done. For example just today because GitHub copilot is under the Microsoft umbrella and part of our \"greenlist\", we were able to fast track our approvals and get it on our corporate counsels plate of work, whereas if we went with something less known like say a model that say a startup like anthropic builds, due to relative unknowns, it woildve taken out lawyers month to get comfortable.\n\nAs an ultimate end user and middle manager pushing sisyphean boulders, this makes me excited in the short term the cloud platforms are buying up various parts of the AI toolkit (ex. Neeva, mosaiqML etc.) and integrating + bundling it together.\n\nAs an economist and hopeful future startup founder, though this incumbent natural monopoly and market power due to having a legal \"moat\" doesn't feel right to me.", "author_fullname": "t2_decct72a5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going with Microsoft as default option due to less new stuff for lawyers to read?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rkg4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688586378.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688584691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One thing I&amp;#39;ve realized in my career:\nSimilar to the &amp;quot;no one has gotten fired for hiring IBM&amp;quot; trope, we are solidly in a a 20 year era where due to Microsoft by and large keeping their enterprise licensing bundled and their terms of service similar and more consolidated for Lawyers to interpret, for any medium to large company already on Microsoft for office, word, 365, teams, etc. had a massive incumbency advantage to adopt Microsoft.&lt;/p&gt;\n\n&lt;p&gt;To me this &amp;quot;bundling&amp;quot; is somewhat anti competitive and is a natural monopoly of sorts. It&amp;#39;s in aggregate efficient for the world for lawyers to need to review less contracts and info sec people to review less policies, but it leads to insane market concentration.&lt;/p&gt;\n\n&lt;p&gt;If any of y&amp;#39;all had the pain of working for a fortune 500 company with strict IT approval/compliance processes, y&amp;#39;all will know of the pain for getting any software approved and installed.  It takes tremendous time and political capital to get anything done. For example just today because GitHub copilot is under the Microsoft umbrella and part of our &amp;quot;greenlist&amp;quot;, we were able to fast track our approvals and get it on our corporate counsels plate of work, whereas if we went with something less known like say a model that say a startup like anthropic builds, due to relative unknowns, it woildve taken out lawyers month to get comfortable.&lt;/p&gt;\n\n&lt;p&gt;As an ultimate end user and middle manager pushing sisyphean boulders, this makes me excited in the short term the cloud platforms are buying up various parts of the AI toolkit (ex. Neeva, mosaiqML etc.) and integrating + bundling it together.&lt;/p&gt;\n\n&lt;p&gt;As an economist and hopeful future startup founder, though this incumbent natural monopoly and market power due to having a legal &amp;quot;moat&amp;quot; doesn&amp;#39;t feel right to me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14rkg4r", "is_robot_indexable": true, "report_reasons": null, "author": "Dull_Lettuce_4622", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rkg4r/going_with_microsoft_as_default_option_due_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rkg4r/going_with_microsoft_as_default_option_due_to/", "subreddit_subscribers": 114363, "created_utc": 1688584691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3ve2psi7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to ingest records from Cosmos DB using Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14rg8sp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K9HWxxNow5rZ1qHfE85vs6WW8VUI2Nepbluw3PUw1JA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688575754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "harshmatharu.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://harshmatharu.com/blog/ingest-records-from-cosmosdb-using-spark", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?auto=webp&amp;v=enabled&amp;s=1de2aca917b90b3cc72b9ff239383268a0dc0b51", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74737eb465d78c5776ace82d6198ea07b3974837", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a58e0d510f9fd695ba5af32714ed3d876300827", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcfa83755ef2e572549fcfcf59e6cad69dd4e958", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eca423e4ee6c122e76905f0c73a2367123a7005f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bac243d049140155ee5fbcb7bf090bf78b39c170", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4gahHiXsP7w0ZB4_0XFc_EUZFYxWnqXmKfZ5dVZnc6w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1760d0644c4d83951578a257fb8666dce146b79", "width": 1080, "height": 540}], "variants": {}, "id": "A8iVhGJK0JkIk30sZdO6ZQLeU7OXOeoPiLa7dFQ7U0M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rg8sp", "is_robot_indexable": true, "report_reasons": null, "author": "Dramatic_Necessary_3", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rg8sp/how_to_ingest_records_from_cosmos_db_using_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://harshmatharu.com/blog/ingest-records-from-cosmosdb-using-spark", "subreddit_subscribers": 114363, "created_utc": 1688575754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data processing becomes critical when training a robust machine learning model. We occasionally need to restructure and add new data to the datasets to increase the efficiency of the data.\n\nWe'll look at how to combine multiple datasets and merge multiple datasets with the same and different column names in this article. We'll use the `pandas` library's following functions to carry out these operations.\n\n* `pandas.concat()`\n* `pandas.merge()`\n* `pandas.DataFrame.join()`\n\nThe `concat()` function in `pandas` is a go-to option for combining the DataFrames due to its simplicity. However, if we want more control over how the data is joined and on which column in the DataFrame, the `merge()` function is a good choice. If we want to join data based on the index, we should use the `join()` method.\n\n**Here is the guide for performing the joining, merging, and combining multiple datasets using pandas\ud83d\udc47\ud83d\udc47\ud83d\udc47**\n\n[Join, Merge, and Combine Multiple Datasets Using pandas](https://geekpython.in/multiple-datasets-integration-using-pandas)", "author_fullname": "t2_pb3nzmce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Join, Merge, and Combine Multiple Datasets Using pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rfc42", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688573885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data processing becomes critical when training a robust machine learning model. We occasionally need to restructure and add new data to the datasets to increase the efficiency of the data.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ll look at how to combine multiple datasets and merge multiple datasets with the same and different column names in this article. We&amp;#39;ll use the &lt;code&gt;pandas&lt;/code&gt; library&amp;#39;s following functions to carry out these operations.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;pandas.concat()&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;pandas.merge()&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;pandas.DataFrame.join()&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The &lt;code&gt;concat()&lt;/code&gt; function in &lt;code&gt;pandas&lt;/code&gt; is a go-to option for combining the DataFrames due to its simplicity. However, if we want more control over how the data is joined and on which column in the DataFrame, the &lt;code&gt;merge()&lt;/code&gt; function is a good choice. If we want to join data based on the index, we should use the &lt;code&gt;join()&lt;/code&gt; method.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here is the guide for performing the joining, merging, and combining multiple datasets using pandas\ud83d\udc47\ud83d\udc47\ud83d\udc47&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://geekpython.in/multiple-datasets-integration-using-pandas\"&gt;Join, Merge, and Combine Multiple Datasets Using pandas&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?auto=webp&amp;v=enabled&amp;s=a86eb9301b61fa532a6d31f179f928edeac5c80f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d24a3db04a0e4fc4a34d774000d20ee3771c1662", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8028e69481dcd025a846db21a926b6b68b0a0ec6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ab601003583d9a1723acb0c83e7410f66d07c0a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25157b9375bd2ae56788ea4f0c9a96d2e8324291", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=079aa6053c57cbf1981b753528aba55790fc8cf8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/dn32WCU3_ytItEV1EltZmzTDO2wmPCFbtAKXRNKAdrc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7537826672a08f63baec8c917ad34c6f6e1c0b4", "width": 1080, "height": 567}], "variants": {}, "id": "gRfQV35yrH1dVxSBfhVGiluToaN_lKvBv96jgo5GOSQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rfc42", "is_robot_indexable": true, "report_reasons": null, "author": "python4geeks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rfc42/join_merge_and_combine_multiple_datasets_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rfc42/join_merge_and_combine_multiple_datasets_using/", "subreddit_subscribers": 114363, "created_utc": 1688573885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bfcpv85y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Conquer the Digital world with stellar Data transformation by leveraging Techmango\u2019s Bespoke Data Analytics services", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": true, "name": "t3_14safoa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/jaLnRxRZqOFlcDe7xuNxitTL-lq8JkixO8hjtMcj4t0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688652780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techmango.net", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.techmango.net/conquer-the-digital-world-with-stellar-data-transformation-by-leveraging-techmangos-bespoke-data-analytics-services", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jfwyuc9N8lFGx5SafasSExGQcOeooWywVIkIGJH4rx4.jpg?auto=webp&amp;v=enabled&amp;s=a87220ab4c812913f125e48b0354b0e1f156097e", "width": 1034, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jfwyuc9N8lFGx5SafasSExGQcOeooWywVIkIGJH4rx4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67ae8a22f2f7e4af67f6a9fcd33bae48e4833e05", "width": 108, "height": 62}, {"url": "https://external-preview.redd.it/jfwyuc9N8lFGx5SafasSExGQcOeooWywVIkIGJH4rx4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db3cb51de22ebd84c512066ba498c9e0218e6503", "width": 216, "height": 125}, {"url": "https://external-preview.redd.it/jfwyuc9N8lFGx5SafasSExGQcOeooWywVIkIGJH4rx4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f04f453a6854a0deaafcfd1e3803cbce64589a9", "width": 320, "height": 185}, {"url": "https://external-preview.redd.it/jfwyuc9N8lFGx5SafasSExGQcOeooWywVIkIGJH4rx4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d839daf004c2fecf7bf549c21dd9f2a9b56ae8c", "width": 640, "height": 371}, {"url": "https://external-preview.redd.it/jfwyuc9N8lFGx5SafasSExGQcOeooWywVIkIGJH4rx4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89d79e0103a7c6f23089d5ec50ef035fec314e70", "width": 960, "height": 557}], "variants": {}, "id": "C17rmXTtUXIiGPKBaSB94nTJtif5OZ2tgbFqeWGXARI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14safoa", "is_robot_indexable": true, "report_reasons": null, "author": "jack-khan-011", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14safoa/conquer_the_digital_world_with_stellar_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.techmango.net/conquer-the-digital-world-with-stellar-data-transformation-by-leveraging-techmangos-bespoke-data-analytics-services", "subreddit_subscribers": 114363, "created_utc": 1688652780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. We have our data in Bigquery and the data-checks are going to be a core part of our data platform. Moreover, we would need to scale it to hundreds of clients and run daily checks as well as periodic checks. \n\nI investigated for a while and I decided to go with elementary ([https://github.com/elementary-data/elementary/tree/master](https://github.com/elementary-data/elementary/tree/master)), since we use dbt and it has kind of a nice UI. However, we've been running into \"query too complex\" errors in bigquery since a very early stage of our system, so I don't think it will scale very good. We discarded great expectations for the cumbersomeness of it and because we didn't really like it.\n\nNow, we are thinking on implementing our own solution, since we have a more narrow use case than great expectations or elementary could have, so we wouldn't need that much features. However, I am not sure what would be the best tech to use.\n\nSomething like elementary for data in bigquery?  \nPandera using pandas or pyspark dataframes?  \nUse polars and create our own queries?  \nOur own SparkSQL code in a cluster?\n\nI hear you!", "author_fullname": "t2_chl6zxlwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deploy data checks at scale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s8te8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688649077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. We have our data in Bigquery and the data-checks are going to be a core part of our data platform. Moreover, we would need to scale it to hundreds of clients and run daily checks as well as periodic checks. &lt;/p&gt;\n\n&lt;p&gt;I investigated for a while and I decided to go with elementary (&lt;a href=\"https://github.com/elementary-data/elementary/tree/master\"&gt;https://github.com/elementary-data/elementary/tree/master&lt;/a&gt;), since we use dbt and it has kind of a nice UI. However, we&amp;#39;ve been running into &amp;quot;query too complex&amp;quot; errors in bigquery since a very early stage of our system, so I don&amp;#39;t think it will scale very good. We discarded great expectations for the cumbersomeness of it and because we didn&amp;#39;t really like it.&lt;/p&gt;\n\n&lt;p&gt;Now, we are thinking on implementing our own solution, since we have a more narrow use case than great expectations or elementary could have, so we wouldn&amp;#39;t need that much features. However, I am not sure what would be the best tech to use.&lt;/p&gt;\n\n&lt;p&gt;Something like elementary for data in bigquery?&lt;br/&gt;\nPandera using pandas or pyspark dataframes?&lt;br/&gt;\nUse polars and create our own queries?&lt;br/&gt;\nOur own SparkSQL code in a cluster?&lt;/p&gt;\n\n&lt;p&gt;I hear you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?auto=webp&amp;v=enabled&amp;s=634e5ec84f7d8897d421cfdc161efa7805d444b0", "width": 3168, "height": 792}, "resolutions": [{"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=498c2fddb4d2684ba4cc9d399fb431b5dd281658", "width": 108, "height": 27}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e6d15bcfabed1bc27af505ad731f07c0c756c9f", "width": 216, "height": 54}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a8f90762fbf3577e9eb79d3feac89fe33805e29", "width": 320, "height": 80}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c427279e08eedcf270ab4efb0a12718cc9650fbb", "width": 640, "height": 160}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7eef48fd5437b9ba8b7935666c1bf7d5036c4c0d", "width": 960, "height": 240}, {"url": "https://external-preview.redd.it/GJqYvNILW7ONv6KTnDKXwC2d1dQUuWUVKF8Ggg48FKc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bde5bbaa1d8e2fa7da7958ba290616a1d961486d", "width": 1080, "height": 270}], "variants": {}, "id": "rqjJjwLJeYpUH4-kw1hYUZ0GgiauI67rZbnHZR7OTag"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14s8te8", "is_robot_indexable": true, "report_reasons": null, "author": "JLTDE", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s8te8/how_to_deploy_data_checks_at_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s8te8/how_to_deploy_data_checks_at_scale/", "subreddit_subscribers": 114363, "created_utc": 1688649077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "*Disclaimer: I'm now asking for a project on BigQuery, so specific answers for BigQuery will help a lot in the short run. But, I would love to understand it better conceptually, so I'll be able to apply it to other systems as well.*   \n\n\nUsually, when optimizing a \"big data\" table we would partition and/or cluster it.   \nBoth allow one-to-many hierarchically \"indexing\" more than one field.   \nThe classic partition example would be time:  \n```\nyear/month/day/hour  \n``` \nSame for clustering, if we cluster by `col_a` and then by `col_b`, it means a one-to-many between `col_a` to `col_b`, for example:  \n```\n  col_a   col_b  \n ------- ------- \n  a1      b1     \n  a1      b2     \n  a2      b3     \n  a2      b4     \n\n```\n  \nHow about a case where we have?\n\n```\n  col_a   col_b  \n ------- ------- \n  a1      b1     \n  a1      b2     \n  a2      b1     \n  a2      b2     \n```\n\nIn this case, the relationship is many to many, and common query pattern predicates would use `col_a`, `col_b`, or both.  \n\n\nHow would we optimize such a table to reduce data scans?  \n\n\nThank you. :)", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to optimize data modeling to reduce data scan for many-to-many \"partition/clustering\" fields?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s6clc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688643509.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688642869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Disclaimer: I&amp;#39;m now asking for a project on BigQuery, so specific answers for BigQuery will help a lot in the short run. But, I would love to understand it better conceptually, so I&amp;#39;ll be able to apply it to other systems as well.&lt;/em&gt;   &lt;/p&gt;\n\n&lt;p&gt;Usually, when optimizing a &amp;quot;big data&amp;quot; table we would partition and/or cluster it.&lt;br/&gt;\nBoth allow one-to-many hierarchically &amp;quot;indexing&amp;quot; more than one field.&lt;br/&gt;\nThe classic partition example would be time:&lt;br/&gt;\n&lt;code&gt;\nyear/month/day/hour  \n&lt;/code&gt; \nSame for clustering, if we cluster by &lt;code&gt;col_a&lt;/code&gt; and then by &lt;code&gt;col_b&lt;/code&gt;, it means a one-to-many between &lt;code&gt;col_a&lt;/code&gt; to &lt;code&gt;col_b&lt;/code&gt;, for example:&lt;br/&gt;\n```\n  col_a   col_b  &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;a1      b1&lt;br/&gt;\n  a1      b2&lt;br/&gt;\n  a2      b3&lt;br/&gt;\n  a2      b4     &lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;How about a case where we have?&lt;/p&gt;\n\n&lt;p&gt;```\n  col_a   col_b  &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;a1      b1&lt;br/&gt;\n  a1      b2&lt;br/&gt;\n  a2      b1&lt;br/&gt;\n  a2      b2&lt;br/&gt;\n```&lt;/p&gt;\n\n&lt;p&gt;In this case, the relationship is many to many, and common query pattern predicates would use &lt;code&gt;col_a&lt;/code&gt;, &lt;code&gt;col_b&lt;/code&gt;, or both.  &lt;/p&gt;\n\n&lt;p&gt;How would we optimize such a table to reduce data scans?  &lt;/p&gt;\n\n&lt;p&gt;Thank you. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14s6clc", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s6clc/how_to_optimize_data_modeling_to_reduce_data_scan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s6clc/how_to_optimize_data_modeling_to_reduce_data_scan/", "subreddit_subscribers": 114363, "created_utc": 1688642869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am exploring azure Devops for ARM deployment as part of infrastructure provisioning.\nWhat is the need for a CI build. Why can't I directly release the code changes?", "author_fullname": "t2_3vjykfp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the need of CI build?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s3b1w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688634119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am exploring azure Devops for ARM deployment as part of infrastructure provisioning.\nWhat is the need for a CI build. Why can&amp;#39;t I directly release the code changes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14s3b1w", "is_robot_indexable": true, "report_reasons": null, "author": "akhilseban", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14s3b1w/what_is_the_need_of_ci_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14s3b1w/what_is_the_need_of_ci_build/", "subreddit_subscribers": 114363, "created_utc": 1688634119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, need help with this problem. This is already a functioning code, however, it replaces all the active\\_count it has inputted to null whenever there's a new active\\_count to input. \n\nI think the problem is in my case method, is there any way I could ignore active\\_count whenever generated\\_date is not equal to current date?\n\n&amp;#x200B;\n\n    with \n    cte_date_generator as (\n    \n        select -1 + row_number() over(order by 0) index, start_date + index generated_date \n        from (select '2023-07-01'::date start_date, current_date()::date end_date)\n        join table(generator(rowcount =&gt; 20000 )) x\n        qualify index &lt; 1 + end_date - start_date\n        order by generated_date desc\n    \n    )\n    \n    select \n        generated_date,\n        case \n        when generated_date = CAST(current_timestamp as date) \n            then (select count(*) from my_table) \n            end as active_count\n    from cte_date_generator \n\n&amp;#x200B;", "author_fullname": "t2_cokcobrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in DBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ryzco", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688620929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, need help with this problem. This is already a functioning code, however, it replaces all the active_count it has inputted to null whenever there&amp;#39;s a new active_count to input. &lt;/p&gt;\n\n&lt;p&gt;I think the problem is in my case method, is there any way I could ignore active_count whenever generated_date is not equal to current date?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with \ncte_date_generator as (\n\n    select -1 + row_number() over(order by 0) index, start_date + index generated_date \n    from (select &amp;#39;2023-07-01&amp;#39;::date start_date, current_date()::date end_date)\n    join table(generator(rowcount =&amp;gt; 20000 )) x\n    qualify index &amp;lt; 1 + end_date - start_date\n    order by generated_date desc\n\n)\n\nselect \n    generated_date,\n    case \n    when generated_date = CAST(current_timestamp as date) \n        then (select count(*) from my_table) \n        end as active_count\nfrom cte_date_generator \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ryzco", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious_Goose_659", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ryzco/need_help_in_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ryzco/need_help_in_dbt/", "subreddit_subscribers": 114363, "created_utc": 1688620929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a csv file sitting in S3 and what I need to do is migrate this into some actual database and not just a csv file in S3... How do I do this portion? So some feedback I've heard so far is (since the file is small, only around 800 - 900 records of data to start with) use Lambda to write it row by row into a database of my choice in AWS RDS (for example I could use postgres). \n\nHow do I access this data in the database from an app I'd want to build (like how do I perform search with a specific NLP algorithm over the database)? What if my user wants to perform a search using some query and I want to use some NLP algorithm that I develop to match the query with the closest record or top 5 records in the database. I'll be writing the NLP algorithm / possible search code in Python but the front-end may be built with something else, is that an issue? \n\nIs there anyone that's well versed with this type of stuff and doesn't mind if I chatted with them regarding all this? That would help a ton!", "author_fullname": "t2_5692by6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to figure out best way to do this", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rwet1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688613702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a csv file sitting in S3 and what I need to do is migrate this into some actual database and not just a csv file in S3... How do I do this portion? So some feedback I&amp;#39;ve heard so far is (since the file is small, only around 800 - 900 records of data to start with) use Lambda to write it row by row into a database of my choice in AWS RDS (for example I could use postgres). &lt;/p&gt;\n\n&lt;p&gt;How do I access this data in the database from an app I&amp;#39;d want to build (like how do I perform search with a specific NLP algorithm over the database)? What if my user wants to perform a search using some query and I want to use some NLP algorithm that I develop to match the query with the closest record or top 5 records in the database. I&amp;#39;ll be writing the NLP algorithm / possible search code in Python but the front-end may be built with something else, is that an issue? &lt;/p&gt;\n\n&lt;p&gt;Is there anyone that&amp;#39;s well versed with this type of stuff and doesn&amp;#39;t mind if I chatted with them regarding all this? That would help a ton!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14rwet1", "is_robot_indexable": true, "report_reasons": null, "author": "anasp1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14rwet1/struggling_to_figure_out_best_way_to_do_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14rwet1/struggling_to_figure_out_best_way_to_do_this/", "subreddit_subscribers": 114363, "created_utc": 1688613702.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}