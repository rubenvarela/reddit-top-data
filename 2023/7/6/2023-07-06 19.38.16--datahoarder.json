{"kind": "Listing", "data": {"after": "t3_14rpl7z", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crater removed from Disney+ after just 48 days, raises questions on media preservation, piracy, and original content.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_14rpzsu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 347, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_tlrlz", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 347, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vgEkziHiag8CD0fRCdO_nEgl1dIzGqT-6MnCMG3jrZY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "movies", "selftext": "", "author_fullname": "t2_4w06b864", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crater removed from Disney+ after just 48 days, raises questions on media preservation, piracy, and original content.", "link_flair_richtext": [{"e": "text", "t": "Discussion"}], "subreddit_name_prefixed": "r/movies", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_14rcamg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 6088, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6088, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vgEkziHiag8CD0fRCdO_nEgl1dIzGqT-6MnCMG3jrZY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688567403.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "independent.co.uk", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.independent.co.uk/arts-entertainment/films/news/disney-plus-crater-original-movie-removed-b2369537.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?auto=webp&amp;v=enabled&amp;s=34e1c8054c8f95adaed95df2b4e50c3a1724e6f9", "width": 1200, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6e71ffcd9f3576de14a2be95ed5ec70f7e927b8", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bd6c89f268c4f6b5d5cddee435f10c4146993bd", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=635f55a241b4b78d7e304b0566bc8e855310fd02", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e93247776926d68f63bfb28052483da4dfa8cbe", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2759e42cc08b8d6b284a795200da9a0a72d3c22", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fab4634279cadb3a4b2cefefcd89e6536ca1e7a2", "width": 1080, "height": 810}], "variants": {}, "id": "aJ9alo-RA3flJHYV6VBKCyvTtlytlxCuDDZLHQJCUbk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1e034d84-381e-11e2-9f6c-12313d14a568", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2qh3s", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14rcamg", "is_robot_indexable": true, "report_reasons": null, "author": "tapdancingtommy7", "discussion_type": null, "num_comments": 1234, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/movies/comments/14rcamg/crater_removed_from_disney_after_just_48_days/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.independent.co.uk/arts-entertainment/films/news/disney-plus-crater-original-movie-removed-b2369537.html", "subreddit_subscribers": 31210694, "created_utc": 1688567403.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1688597107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "independent.co.uk", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.independent.co.uk/arts-entertainment/films/news/disney-plus-crater-original-movie-removed-b2369537.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?auto=webp&amp;v=enabled&amp;s=34e1c8054c8f95adaed95df2b4e50c3a1724e6f9", "width": 1200, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6e71ffcd9f3576de14a2be95ed5ec70f7e927b8", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bd6c89f268c4f6b5d5cddee435f10c4146993bd", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=635f55a241b4b78d7e304b0566bc8e855310fd02", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e93247776926d68f63bfb28052483da4dfa8cbe", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2759e42cc08b8d6b284a795200da9a0a72d3c22", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/_oBZkmxaBwCng3TUySqbuK5sLcain4oUN78FnULa4cI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fab4634279cadb3a4b2cefefcd89e6536ca1e7a2", "width": 1080, "height": 810}], "variants": {}, "id": "aJ9alo-RA3flJHYV6VBKCyvTtlytlxCuDDZLHQJCUbk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14rpzsu", "is_robot_indexable": true, "report_reasons": null, "author": "Loosel", "discussion_type": null, "num_comments": 133, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14rcamg", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14rpzsu/crater_removed_from_disney_after_just_48_days/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.independent.co.uk/arts-entertainment/films/news/disney-plus-crater-original-movie-removed-b2369537.html", "subreddit_subscribers": 691384, "created_utc": 1688597107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Article found here!", "author_fullname": "t2_dz0l9v69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate launching 32TB drives this year!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_14s8yao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 149, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 149, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oOsV7fAIKarJV9sj2zeQrfSXBf7NOzSCVBMSYjkHU-Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688649390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ghacks.net", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Article found here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.ghacks.net/2023/06/11/seagate-launching-32-tb-hard-drives-later-this-year-and-50-tb-on-the-horizon/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dFsn00mQdT8Z_Ep7aSuot6gikND-fLNJP5W4eoTTfn4.jpg?auto=webp&amp;v=enabled&amp;s=c424091ee8ae331dea0784b65640253c50ed6e96", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/dFsn00mQdT8Z_Ep7aSuot6gikND-fLNJP5W4eoTTfn4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b9fab635b64e68701862bf61b09ab5681ef32b3", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/dFsn00mQdT8Z_Ep7aSuot6gikND-fLNJP5W4eoTTfn4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5743f14db31fda541efc9e35c567d828a9a4a26", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/dFsn00mQdT8Z_Ep7aSuot6gikND-fLNJP5W4eoTTfn4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c7390dcbe62f92fbbf30178ffd66f0d017e78bd", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/dFsn00mQdT8Z_Ep7aSuot6gikND-fLNJP5W4eoTTfn4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98be2ed03ff661598f7bff56210948a0690a9e61", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/dFsn00mQdT8Z_Ep7aSuot6gikND-fLNJP5W4eoTTfn4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=475c92607a0e145542fa4b9fe11975967f7eb7d3", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/dFsn00mQdT8Z_Ep7aSuot6gikND-fLNJP5W4eoTTfn4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ad863cde071f77a692f7254685ea134c868f8c8", "width": 1080, "height": 720}], "variants": {}, "id": "IabfKLadeUPQXSUu6-Q9KojvopYnJLkZqaXbitGfLbI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14s8yao", "is_robot_indexable": true, "report_reasons": null, "author": "stereojorge", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14s8yao/seagate_launching_32tb_drives_this_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.ghacks.net/2023/06/11/seagate-launching-32-tb-hard-drives-later-this-year-and-50-tb-on-the-horizon/", "subreddit_subscribers": 691384, "created_utc": 1688649390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it OK to mount hard drives upside down.\n\nMy concern is that maybe over time gravity will affect internal components. (I suppose its no difference to having it the normal way up, but I wanted to ask the question to put my mind at rest).\n\nReason for asking is my case has space for 10 drives, however the case has 5 double drive trays, so it requires you to mount 5 of the drives upside down.\n\nDrives are WD Red's Pluses and Pro's (if that makes any difference to the question).", "author_fullname": "t2_64bzq7hu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it OK to mount hard drives upside down?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rom4q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688593969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it OK to mount hard drives upside down.&lt;/p&gt;\n\n&lt;p&gt;My concern is that maybe over time gravity will affect internal components. (I suppose its no difference to having it the normal way up, but I wanted to ask the question to put my mind at rest).&lt;/p&gt;\n\n&lt;p&gt;Reason for asking is my case has space for 10 drives, however the case has 5 double drive trays, so it requires you to mount 5 of the drives upside down.&lt;/p&gt;\n\n&lt;p&gt;Drives are WD Red&amp;#39;s Pluses and Pro&amp;#39;s (if that makes any difference to the question).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14rom4q", "is_robot_indexable": true, "report_reasons": null, "author": "Sparky_S127", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14rom4q/is_it_ok_to_mount_hard_drives_upside_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14rom4q/is_it_ok_to_mount_hard_drives_upside_down/", "subreddit_subscribers": 691384, "created_utc": 1688593969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Whenever I edit videos and render them, I output them into a folder called \"Rendered Videos\". This folder is on an NVME SSD and currently has 135 files totaling 22.1 GB, so not even that big. However, opening this folder takes 10-20 seconds. I have no idea why this happens, and I assumed it would be fixed once I replaced my HDD with an NVME drive, but that did nothing. I assume it's something to do with generating thumbnails, but has anyone else experienced this and do you have a fix? The folder optimization is already set to \"Videos\".", "author_fullname": "t2_7xw9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have a videos folder that takes forever to load?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rvx0e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688612429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whenever I edit videos and render them, I output them into a folder called &amp;quot;Rendered Videos&amp;quot;. This folder is on an NVME SSD and currently has 135 files totaling 22.1 GB, so not even that big. However, opening this folder takes 10-20 seconds. I have no idea why this happens, and I assumed it would be fixed once I replaced my HDD with an NVME drive, but that did nothing. I assume it&amp;#39;s something to do with generating thumbnails, but has anyone else experienced this and do you have a fix? The folder optimization is already set to &amp;quot;Videos&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14rvx0e", "is_robot_indexable": true, "report_reasons": null, "author": "Zarrex", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14rvx0e/anyone_have_a_videos_folder_that_takes_forever_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14rvx0e/anyone_have_a_videos_folder_that_takes_forever_to/", "subreddit_subscribers": 691384, "created_utc": 1688612429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I really like the drag-to-reorder feature on Google Photos. Reorder by renaming them on PC Explorer takes a very long time.\n\nEdit: Adobe Lightroom Classic has this feature, but really appreciate it if anyone suggests easier-to-use and free software for people who needs this.", "author_fullname": "t2_7u1262s4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for software that can select photos and drag them to reorder like Google Photos.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rqxau", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688601304.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688599268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really like the drag-to-reorder feature on Google Photos. Reorder by renaming them on PC Explorer takes a very long time.&lt;/p&gt;\n\n&lt;p&gt;Edit: Adobe Lightroom Classic has this feature, but really appreciate it if anyone suggests easier-to-use and free software for people who needs this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14rqxau", "is_robot_indexable": true, "report_reasons": null, "author": "PingPing01", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14rqxau/looking_for_software_that_can_select_photos_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14rqxau/looking_for_software_that_can_select_photos_and/", "subreddit_subscribers": 691384, "created_utc": 1688599268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI'm about to archive a lot of stuff on Blu Ray disks as cold backup and while it's nothing top secret I would like to prevent anyone who grabs the disk to be able to read from them.  \nMy first idea was to use a password protected zip folder which I then burn on the disk but from what I read this makes it more vulnerable to bit rot/read errors so I wanted to ask if there is a better way.\n\nThanks in advance ", "author_fullname": "t2_ab9muaji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Password protected Blu Ray Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s21z5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688630296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m about to archive a lot of stuff on Blu Ray disks as cold backup and while it&amp;#39;s nothing top secret I would like to prevent anyone who grabs the disk to be able to read from them.&lt;br/&gt;\nMy first idea was to use a password protected zip folder which I then burn on the disk but from what I read this makes it more vulnerable to bit rot/read errors so I wanted to ask if there is a better way.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14s21z5", "is_robot_indexable": true, "report_reasons": null, "author": "Atomfried_Fallout", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14s21z5/password_protected_blu_ray_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14s21z5/password_protected_blu_ray_archive/", "subreddit_subscribers": 691384, "created_utc": 1688630296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know they require 12V, but doesn\u2019t usb have features like power delivery and stuff? Is there no way to use a 3.5 inch hard drive as an external drive and connect it with just a usb cable? I do not know a lot about electronics and stuff, so Im confused about this", "author_fullname": "t2_d338cejp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why can\u2019t USB power 3.5\u201d Hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14sicoh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688669880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know they require 12V, but doesn\u2019t usb have features like power delivery and stuff? Is there no way to use a 3.5 inch hard drive as an external drive and connect it with just a usb cable? I do not know a lot about electronics and stuff, so Im confused about this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14sicoh", "is_robot_indexable": true, "report_reasons": null, "author": "Ihsan3498", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14sicoh/why_cant_usb_power_35_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14sicoh/why_cant_usb_power_35_hard_drives/", "subreddit_subscribers": 691384, "created_utc": 1688669880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Setup is a 80tb Truenas, full of emails/attachments, documents, pdf's, machine calibrations, images, videos, basically all the stuff. \n\nright now its a haystack search for anything that is older than maybe year. Im looking for a way to metatag each file, based on content and create a database of file locations. \n\nIve looked into OpenKM, and it has some potential but the open codebase is lets just say, ancient. like Java 1.8 ancient. \n\nbut its striking along the right direction. Additionally, with the documents/emails, we would like to embed them with openai to make contextual searches easier.  this will likely take some coding as I don't know of any off the shelf solution here. \n\n\nSo other than OpenKM anyone know of a decent document manager?", "author_fullname": "t2_ax716", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need a better way to organize documents in massive nas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14sgoan", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688666767.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688666106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Setup is a 80tb Truenas, full of emails/attachments, documents, pdf&amp;#39;s, machine calibrations, images, videos, basically all the stuff. &lt;/p&gt;\n\n&lt;p&gt;right now its a haystack search for anything that is older than maybe year. Im looking for a way to metatag each file, based on content and create a database of file locations. &lt;/p&gt;\n\n&lt;p&gt;Ive looked into OpenKM, and it has some potential but the open codebase is lets just say, ancient. like Java 1.8 ancient. &lt;/p&gt;\n\n&lt;p&gt;but its striking along the right direction. Additionally, with the documents/emails, we would like to embed them with openai to make contextual searches easier.  this will likely take some coding as I don&amp;#39;t know of any off the shelf solution here. &lt;/p&gt;\n\n&lt;p&gt;So other than OpenKM anyone know of a decent document manager?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14sgoan", "is_robot_indexable": true, "report_reasons": null, "author": "bargaindownhill", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14sgoan/need_a_better_way_to_organize_documents_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14sgoan/need_a_better_way_to_organize_documents_in/", "subreddit_subscribers": 691384, "created_utc": 1688666106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am sure others had a thought of a way to use old computers to navigate the old internet; although that assume you need a server and everything else related to it, to simulate the network as it was.\n\nI am looking at something more simpler: a way to surf internet locally, on a old pentium 2 as if I was online in 1994. Not looking to simulate protocols or what not; just a big dump of all the pages as they were in 1994, so I can put everything on a SD card (256 GB or 512 for example), and use data on it.\n\nI thought I could crawl something like wayback machine, but the amount of technical involvement to remove the extra stuff would be impossible for my limited free time pool; so I was hoping someone made something like an archive, that froze in time websites as they were, and make them available offline. Like a downloadable archive/image I can unpack on my old machine, and that let me use that computer as if it was 1994. \n\nIf there is nothing pre-made, what would you suggest to do, to achieve this? I know I can rely on internet archive and wayback machine for most part, but they are not offline and my concern is that they may eventually disappear; and I don't believe that majority of old internet (not really interested in adult websites and similar, which was a big chunk of what made internet big at that time) would not fit in 5-10 TB at most; so a subset including things like yahoo, geocities, delphi and things like that would fit on a 512 GB card or so.\n\nThoughts?", "author_fullname": "t2_18wupfn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Offline archives to replicate how internet was in 1994?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14sgi0i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688665716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am sure others had a thought of a way to use old computers to navigate the old internet; although that assume you need a server and everything else related to it, to simulate the network as it was.&lt;/p&gt;\n\n&lt;p&gt;I am looking at something more simpler: a way to surf internet locally, on a old pentium 2 as if I was online in 1994. Not looking to simulate protocols or what not; just a big dump of all the pages as they were in 1994, so I can put everything on a SD card (256 GB or 512 for example), and use data on it.&lt;/p&gt;\n\n&lt;p&gt;I thought I could crawl something like wayback machine, but the amount of technical involvement to remove the extra stuff would be impossible for my limited free time pool; so I was hoping someone made something like an archive, that froze in time websites as they were, and make them available offline. Like a downloadable archive/image I can unpack on my old machine, and that let me use that computer as if it was 1994. &lt;/p&gt;\n\n&lt;p&gt;If there is nothing pre-made, what would you suggest to do, to achieve this? I know I can rely on internet archive and wayback machine for most part, but they are not offline and my concern is that they may eventually disappear; and I don&amp;#39;t believe that majority of old internet (not really interested in adult websites and similar, which was a big chunk of what made internet big at that time) would not fit in 5-10 TB at most; so a subset including things like yahoo, geocities, delphi and things like that would fit on a 512 GB card or so.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14sgi0i", "is_robot_indexable": true, "report_reasons": null, "author": "fttklr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14sgi0i/offline_archives_to_replicate_how_internet_was_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14sgi0i/offline_archives_to_replicate_how_internet_was_in/", "subreddit_subscribers": 691384, "created_utc": 1688665716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have one 2TB external drive hooked up to a raspberry pi. It\u2019s going to fill up soon, and while I do have more room to expand with better drives I\u2019m wondering if it\u2019s worth it to get sata drives and connect those to the pi through the methods available.", "author_fullname": "t2_wr2c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do I go next?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14sgbb6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688665317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have one 2TB external drive hooked up to a raspberry pi. It\u2019s going to fill up soon, and while I do have more room to expand with better drives I\u2019m wondering if it\u2019s worth it to get sata drives and connect those to the pi through the methods available.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14sgbb6", "is_robot_indexable": true, "report_reasons": null, "author": "blud97", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14sgbb6/where_do_i_go_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14sgbb6/where_do_i_go_next/", "subreddit_subscribers": 691384, "created_utc": 1688665317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I'm think of either two products for the internal HDD:  \n\\- Seagate Barracuda ST6000DM003   \nor  \n\\- Western Digital  WD60EZAZ   \n\n\nPurpose : Basic storage for documents , images, MP3 audio, a few videos maybe  \n\\*The OS, games and other stuff will be sent to the M.2 SSD\\*  \n\n\nWhich of these two should I choose?  \nOr it doesn't matter?", "author_fullname": "t2_9h4xh041", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "6TB internal desktop drive (for home use) : Seagate Barracuda or Western Digital Blue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14scem1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688657006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m think of either two products for the internal HDD:&lt;br/&gt;\n- Seagate Barracuda ST6000DM003&lt;br/&gt;\nor&lt;br/&gt;\n- Western Digital  WD60EZAZ   &lt;/p&gt;\n\n&lt;p&gt;Purpose : Basic storage for documents , images, MP3 audio, a few videos maybe&lt;br/&gt;\n*The OS, games and other stuff will be sent to the M.2 SSD*  &lt;/p&gt;\n\n&lt;p&gt;Which of these two should I choose?&lt;br/&gt;\nOr it doesn&amp;#39;t matter?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14scem1", "is_robot_indexable": true, "report_reasons": null, "author": "blackcyborg009", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14scem1/6tb_internal_desktop_drive_for_home_use_seagate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14scem1/6tb_internal_desktop_drive_for_home_use_seagate/", "subreddit_subscribers": 691384, "created_utc": 1688657006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Help friends --\n\nI've had \"fight club\" unlimited Google Drive at $12/month since 2016. I have about 60 TB of data up on my legacy Google Drive. Now, I can't upload anything -- getting the dreaded \"you're out of storage space\" notifications. \n\nI'm a filmmaker shooting 4k+ for personal and commercial film projects. This data is my whole life. It exists (in theory) on little hard drives all around my office, but who knows when they may fail. So essentially this cloud storage is a repository of my whole career.\n\nDetails: I have access to a gbps ethernet cable and I'm working off of Mac OS. I'm thinking of ordering 20+TB drives and downloading everything as it is off of Google Drive, to then reupload to another cloud solution. However, I'm leaving on Tuesday for 3 weeks on a shoot in Europe. Even if I downloaded Parallels Access and left my computer open for 3 weeks and remotely checked on the status of these transfers, something will still probably go wrong with all the data I have to download and/or transfer.  \n\nI've also been experiencing [this issue](https://support.google.com/drive/thread/125012643/fix-google-drive-for-desktop-mac-big-sur-server-connections-interrupted-message-on-finder?hl=en) from Google Drive where I go to transfer lots of data from Google Drive to a destination, and within a few minutes it says \"server connection interrupted.\" So manually dragging and dropping and letting it cook is causing a ton of problems for me.\n\nWoof.\n\nMy questions, in order:  \n1) Any recommendations on cloud storage with unlimited data? I'm tempted by [Sync.com](https://Sync.com), but hearing that they only offer storage. I honestly dgaf, as long as it's accessible. Should I bite? Any other unlimited options that I should consider? I would like to only do this big migration once. \n\n2) Would it be terribly outside the order of operations to transfer this entirely to another cloud solution, and then download to a NAS? I just don't have the time to get the hardware purchased, installed, and set up before I leave for this shoot in a few days.\n\n3) Any thoughts on when Google might start deleting my data? \n\n4) What are the best cloud storage migration solutions? I used to use CloudHQ for this, but it looks like they don't transfer to sync.com.\n\n5) What questions have I not asked that I should be considering here?\n\n&amp;#x200B;\n\n//\n\n&amp;#x200B;\n\nThanks in advance for your kindness and advice at this ridiculous and potentially painful juncture.", "author_fullname": "t2_kzy98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Filmmaker with 54 TB of data on Google Drive Unlimited now being throttled -- what next?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sbblz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688654756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help friends --&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had &amp;quot;fight club&amp;quot; unlimited Google Drive at $12/month since 2016. I have about 60 TB of data up on my legacy Google Drive. Now, I can&amp;#39;t upload anything -- getting the dreaded &amp;quot;you&amp;#39;re out of storage space&amp;quot; notifications. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a filmmaker shooting 4k+ for personal and commercial film projects. This data is my whole life. It exists (in theory) on little hard drives all around my office, but who knows when they may fail. So essentially this cloud storage is a repository of my whole career.&lt;/p&gt;\n\n&lt;p&gt;Details: I have access to a gbps ethernet cable and I&amp;#39;m working off of Mac OS. I&amp;#39;m thinking of ordering 20+TB drives and downloading everything as it is off of Google Drive, to then reupload to another cloud solution. However, I&amp;#39;m leaving on Tuesday for 3 weeks on a shoot in Europe. Even if I downloaded Parallels Access and left my computer open for 3 weeks and remotely checked on the status of these transfers, something will still probably go wrong with all the data I have to download and/or transfer.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also been experiencing &lt;a href=\"https://support.google.com/drive/thread/125012643/fix-google-drive-for-desktop-mac-big-sur-server-connections-interrupted-message-on-finder?hl=en\"&gt;this issue&lt;/a&gt; from Google Drive where I go to transfer lots of data from Google Drive to a destination, and within a few minutes it says &amp;quot;server connection interrupted.&amp;quot; So manually dragging and dropping and letting it cook is causing a ton of problems for me.&lt;/p&gt;\n\n&lt;p&gt;Woof.&lt;/p&gt;\n\n&lt;p&gt;My questions, in order:&lt;br/&gt;\n1) Any recommendations on cloud storage with unlimited data? I&amp;#39;m tempted by &lt;a href=\"https://Sync.com\"&gt;Sync.com&lt;/a&gt;, but hearing that they only offer storage. I honestly dgaf, as long as it&amp;#39;s accessible. Should I bite? Any other unlimited options that I should consider? I would like to only do this big migration once. &lt;/p&gt;\n\n&lt;p&gt;2) Would it be terribly outside the order of operations to transfer this entirely to another cloud solution, and then download to a NAS? I just don&amp;#39;t have the time to get the hardware purchased, installed, and set up before I leave for this shoot in a few days.&lt;/p&gt;\n\n&lt;p&gt;3) Any thoughts on when Google might start deleting my data? &lt;/p&gt;\n\n&lt;p&gt;4) What are the best cloud storage migration solutions? I used to use CloudHQ for this, but it looks like they don&amp;#39;t transfer to sync.com.&lt;/p&gt;\n\n&lt;p&gt;5) What questions have I not asked that I should be considering here?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;//&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your kindness and advice at this ridiculous and potentially painful juncture.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14sbblz", "is_robot_indexable": true, "report_reasons": null, "author": "staroats", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14sbblz/filmmaker_with_54_tb_of_data_on_google_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14sbblz/filmmaker_with_54_tb_of_data_on_google_drive/", "subreddit_subscribers": 691384, "created_utc": 1688654756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A question for hoarders in general:\n\nIs there a file system similar to Mergerfs (i. e. mounted over existing directories) but aimed at redundancy?\n\nLet's say I have a fraction of my data that needs more than an occasional cold backup (two external HDs, mergerd too) but at the same time doesn't fit into a versioning service (git like).\n\nBasically today I use syncthing for, um, loss prevention, but I'd like something that works on a single, multi-disk PC", "author_fullname": "t2_sg76dvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mergerfs, but with redundancy. Anyone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14sa2v1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688651995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A question for hoarders in general:&lt;/p&gt;\n\n&lt;p&gt;Is there a file system similar to Mergerfs (i. e. mounted over existing directories) but aimed at redundancy?&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I have a fraction of my data that needs more than an occasional cold backup (two external HDs, mergerd too) but at the same time doesn&amp;#39;t fit into a versioning service (git like).&lt;/p&gt;\n\n&lt;p&gt;Basically today I use syncthing for, um, loss prevention, but I&amp;#39;d like something that works on a single, multi-disk PC&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14sa2v1", "is_robot_indexable": true, "report_reasons": null, "author": "AlternativeBasis", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14sa2v1/mergerfs_but_with_redundancy_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14sa2v1/mergerfs_but_with_redundancy_anyone/", "subreddit_subscribers": 691384, "created_utc": 1688651995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nHello, I'm planning a NAS/Light Server build to use to host and store old youtube videos (Plex), random files of my own I need to save, torrented content (interested in getting into \\*arr software), and perhaps to serve as a server for things like BitWarden and Minecraft. I plan to use unRaid as my OS. My planned build is here: [https://pcpartpicker.com/list/Htps6r](https://pcpartpicker.com/list/Htps6r) (I already have the CPU cooler and the PSU lying around).  I don't want to spend too much at first, and I think 8TB in RAID 1 with used parts is a good place to start. Later on I can build a better one and possibly use this one as a backup. Interested in hearing thoughts on what I have picked out. I also have a few other questions:\n\n* Would it be recommended to get an SSD? I've seen people talk about one being useful for caching.\n* If I decided to add another drive, how easy would it be to change from RAID 1 to 5?", "author_fullname": "t2_mqskseq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on my planned NAS build? Also questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rr8gb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688600039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m planning a NAS/Light Server build to use to host and store old youtube videos (Plex), random files of my own I need to save, torrented content (interested in getting into *arr software), and perhaps to serve as a server for things like BitWarden and Minecraft. I plan to use unRaid as my OS. My planned build is here: &lt;a href=\"https://pcpartpicker.com/list/Htps6r\"&gt;https://pcpartpicker.com/list/Htps6r&lt;/a&gt; (I already have the CPU cooler and the PSU lying around).  I don&amp;#39;t want to spend too much at first, and I think 8TB in RAID 1 with used parts is a good place to start. Later on I can build a better one and possibly use this one as a backup. Interested in hearing thoughts on what I have picked out. I also have a few other questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Would it be recommended to get an SSD? I&amp;#39;ve seen people talk about one being useful for caching.&lt;/li&gt;\n&lt;li&gt;If I decided to add another drive, how easy would it be to change from RAID 1 to 5?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14rr8gb", "is_robot_indexable": true, "report_reasons": null, "author": "OneSteelTank", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14rr8gb/thoughts_on_my_planned_nas_build_also_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14rr8gb/thoughts_on_my_planned_nas_build_also_questions/", "subreddit_subscribers": 691384, "created_utc": 1688600039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey folks, new to data storage and analog tape conversions, but I'm picking up a project to convert an archive of old Hi8 tapes to digital; in my research, I've found a ton of great articles and posts both on this subreddit and over at [digitalfaq.com](https://digitalfaq.com). Seems like many posts on that forum are written by site staff LordSmurf, who is well-known even on this platform and [videohelp.com](https://videohelp.com), and his advice is often referred to in Reddit posts on the topic. I think I'm ready to begin the process and start procuring equipment for my project, but it seems like a lot of the recommended equipment is only available secondhand either from eBay (hit or miss) or from forum members such as LordSmurf himself, who in particular refurbs a lot of these old units and sells them.\n\n&amp;#x200B;\n\nFrom what I gather, a lot of his advice is sound, and he has an incredible amount of experience with analog AV equipment and doing conversions, but I am a little hesitant to drop upwards of $2k on equipment I know little about. I'm not new to buying/selling on forums, but most of the gear that he has listed doesn't have any info turn up on Google, so I feel like I can't do my due diligence in researching what I'm buying. No company page, product page, or even other sellers of such units on eBay or other marketplaces. Now, I know that many of these units are so old and had such a niche market that webpages for them can't be expected, and that the advice preached on that forum is to buy, use, and resell and consider any incurred losses a rental fee. Normally I'd feel comfortable enough with that; however, I haven't found any other way to resell the equipment when I'm finished (other than digitalFAQ itself), so I really don't want to be stuck with such expensive, antiquated equipment that can't be easily resold.\n\n&amp;#x200B;\n\nFurther, I saw a [thread here on this very subreddit](https://www.reddit.com/r/DataHoarder/comments/z9rv0z/word_of_caution_for_anyone_looking_at_using/) a few months back that detailed a very poor experience with LordSmurf. It certainly doesn't bode well, but to be fair, it's the only instance of a negative interaction with him that I've found, and it was for a tape conversion service. I'm only looking to buy hardware from him, and it seems most people who have transacted with him are happy with their purchase. I'm also aware that he is somewhat of a polarizing figure, with some users here deriding his rather gatekeep-y, \"my way or the highway\" attitude. And yet, some of the most detailed how-to guides, equipment recs and reviews, and general advice I can find online about this rather esoteric and nearly extinct art of analog tape conversions are written by him.\n\n&amp;#x200B;\n\nSo, anyone have experiences on buying used and refurbished gear from this particular individual on [digitalFAQ.com](https://digitalFAQ.com)? Do they really retain their resale value that well, and were you able to offload your high dollar equipment easily after using it?\n\n&amp;#x200B;\n\nThanks in advance, and please let me know if there's better subreddits to post this in!", "author_fullname": "t2_9cu5q1yg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digitalfaq.com, Refurb Gear from LordSmurf Trustworthy? Resale value hold up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14si54q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688669399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, new to data storage and analog tape conversions, but I&amp;#39;m picking up a project to convert an archive of old Hi8 tapes to digital; in my research, I&amp;#39;ve found a ton of great articles and posts both on this subreddit and over at &lt;a href=\"https://digitalfaq.com\"&gt;digitalfaq.com&lt;/a&gt;. Seems like many posts on that forum are written by site staff LordSmurf, who is well-known even on this platform and &lt;a href=\"https://videohelp.com\"&gt;videohelp.com&lt;/a&gt;, and his advice is often referred to in Reddit posts on the topic. I think I&amp;#39;m ready to begin the process and start procuring equipment for my project, but it seems like a lot of the recommended equipment is only available secondhand either from eBay (hit or miss) or from forum members such as LordSmurf himself, who in particular refurbs a lot of these old units and sells them.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;From what I gather, a lot of his advice is sound, and he has an incredible amount of experience with analog AV equipment and doing conversions, but I am a little hesitant to drop upwards of $2k on equipment I know little about. I&amp;#39;m not new to buying/selling on forums, but most of the gear that he has listed doesn&amp;#39;t have any info turn up on Google, so I feel like I can&amp;#39;t do my due diligence in researching what I&amp;#39;m buying. No company page, product page, or even other sellers of such units on eBay or other marketplaces. Now, I know that many of these units are so old and had such a niche market that webpages for them can&amp;#39;t be expected, and that the advice preached on that forum is to buy, use, and resell and consider any incurred losses a rental fee. Normally I&amp;#39;d feel comfortable enough with that; however, I haven&amp;#39;t found any other way to resell the equipment when I&amp;#39;m finished (other than digitalFAQ itself), so I really don&amp;#39;t want to be stuck with such expensive, antiquated equipment that can&amp;#39;t be easily resold.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Further, I saw a &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/z9rv0z/word_of_caution_for_anyone_looking_at_using/\"&gt;thread here on this very subreddit&lt;/a&gt; a few months back that detailed a very poor experience with LordSmurf. It certainly doesn&amp;#39;t bode well, but to be fair, it&amp;#39;s the only instance of a negative interaction with him that I&amp;#39;ve found, and it was for a tape conversion service. I&amp;#39;m only looking to buy hardware from him, and it seems most people who have transacted with him are happy with their purchase. I&amp;#39;m also aware that he is somewhat of a polarizing figure, with some users here deriding his rather gatekeep-y, &amp;quot;my way or the highway&amp;quot; attitude. And yet, some of the most detailed how-to guides, equipment recs and reviews, and general advice I can find online about this rather esoteric and nearly extinct art of analog tape conversions are written by him.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So, anyone have experiences on buying used and refurbished gear from this particular individual on &lt;a href=\"https://digitalFAQ.com\"&gt;digitalFAQ.com&lt;/a&gt;? Do they really retain their resale value that well, and were you able to offload your high dollar equipment easily after using it?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance, and please let me know if there&amp;#39;s better subreddits to post this in!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bmmH_g4z-FVRqpGv-GJa1tq49F3UBGXFuzmmXykwmrI.jpg?auto=webp&amp;v=enabled&amp;s=527dcb0135a05ee6745b590998ef4629a938d8c3", "width": 73, "height": 73}, "resolutions": [], "variants": {}, "id": "Q40bQkiTOYW4hkF-ZLWpRnee2w3QwOGF9g-IeYJ8RUU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14si54q", "is_robot_indexable": true, "report_reasons": null, "author": "twopeaksmall", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14si54q/digitalfaqcom_refurb_gear_from_lordsmurf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14si54q/digitalfaqcom_refurb_gear_from_lordsmurf/", "subreddit_subscribers": 691384, "created_utc": 1688669399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If a flash drive passes the test can I be sure that its 100% legitimate", "author_fullname": "t2_8oihaf0t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is h2wtestw enough to check legitimacy of flash drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14shwqj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688668856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If a flash drive passes the test can I be sure that its 100% legitimate&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14shwqj", "is_robot_indexable": true, "report_reasons": null, "author": "onionbiscuits", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14shwqj/is_h2wtestw_enough_to_check_legitimacy_of_flash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14shwqj/is_h2wtestw_enough_to_check_legitimacy_of_flash/", "subreddit_subscribers": 691384, "created_utc": 1688668856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to host a bunch of very high resolution images using the [DZI (deep zoom) format](https://en.wikipedia.org/wiki/Deep_Zoom). I am hoping to use object storage because that is generally cheaper. Unfortunately, when I tried doing this with Backblaze B2, I hit my request limit (2,500/day) very quickly. \n\nThat is because DZI format works by breaking an image up into smaller tiles, which are then dynamically loaded as the user zooms and pans around the image. Usually these are separate files, but to make it work with object hosting, some people more clever than myself have created a way to zip the files and then use byte ranges to extract the needed tiles.\n\nThus, my issue on Backblaze B2 wasn't that there was so much data to be transferred, but that there were a ton of requests for each byte range representing a tile (just panning and image can make dozens of requests in a few seconds).\n\nI am still very new to all this cloud stuff, so I am trying to figure out what the most cost effective and performant options are. Amazon S3 looks to be more generous with requests, but I hate to do business with Amazon (they kill workers).\n\nCan anyone recommend object hosting that is well priced for the use-case of needing many requests but only moderate storage needs?", "author_fullname": "t2_r25yo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hosting objects with few or no caps on the number of requests. Cheapest services?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14sh69q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688667185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to host a bunch of very high resolution images using the &lt;a href=\"https://en.wikipedia.org/wiki/Deep_Zoom\"&gt;DZI (deep zoom) format&lt;/a&gt;. I am hoping to use object storage because that is generally cheaper. Unfortunately, when I tried doing this with Backblaze B2, I hit my request limit (2,500/day) very quickly. &lt;/p&gt;\n\n&lt;p&gt;That is because DZI format works by breaking an image up into smaller tiles, which are then dynamically loaded as the user zooms and pans around the image. Usually these are separate files, but to make it work with object hosting, some people more clever than myself have created a way to zip the files and then use byte ranges to extract the needed tiles.&lt;/p&gt;\n\n&lt;p&gt;Thus, my issue on Backblaze B2 wasn&amp;#39;t that there was so much data to be transferred, but that there were a ton of requests for each byte range representing a tile (just panning and image can make dozens of requests in a few seconds).&lt;/p&gt;\n\n&lt;p&gt;I am still very new to all this cloud stuff, so I am trying to figure out what the most cost effective and performant options are. Amazon S3 looks to be more generous with requests, but I hate to do business with Amazon (they kill workers).&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend object hosting that is well priced for the use-case of needing many requests but only moderate storage needs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_tyfLJSNff7UmmpJMgQSkmApl5_cd102Q8tZXktHAug.jpg?auto=webp&amp;v=enabled&amp;s=6fd4021dcae5c4015dea0302df7f58e39b16fd0a", "width": 120, "height": 93}, "resolutions": [{"url": "https://external-preview.redd.it/_tyfLJSNff7UmmpJMgQSkmApl5_cd102Q8tZXktHAug.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0306b06a8d3cc3c3257749d7cf7c84d90a1ceeb0", "width": 108, "height": 83}], "variants": {}, "id": "TQ9dK5CcQ5IczuvNX7J1xi_GzGPlE8nl0QFBM4HWzLg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14sh69q", "is_robot_indexable": true, "report_reasons": null, "author": "nKephalos", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14sh69q/hosting_objects_with_few_or_no_caps_on_the_number/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14sh69q/hosting_objects_with_few_or_no_caps_on_the_number/", "subreddit_subscribers": 691384, "created_utc": 1688667185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Let' s say, I have like 100 files that start with \"abcd\\_00\" at the start. Suppose the files are \"abcd\\_00001\" to \"abcd\\_00100\". And all these files are amongs thousands of files with different names, and those files might also have their similar file name patterns.  \nNow I need a software, where I would instruct it to take the first 7 words of the file name into account, and running it will make the program go through all the existing files in the folder and show me a list like this:  \n\n\n1)  \"abcd\\_00\" ---&gt; 100 Files  \n2) \"1234\\_ab\" --&gt; 5 Files  \n3) \"loremip\" --&gt; 30 Files  \n....  \n...  \n...  \n\n\nI have tried to find something like this but to no avail. Can anyone help me find something similar to this?", "author_fullname": "t2_1bupqeao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any software that goes through all the files in a folder and lists all the file names in a ranking order, with the top name having the most amount of files with the similar name structure? Detailed example below:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s9lfu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688650893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39; s say, I have like 100 files that start with &amp;quot;abcd_00&amp;quot; at the start. Suppose the files are &amp;quot;abcd_00001&amp;quot; to &amp;quot;abcd_00100&amp;quot;. And all these files are amongs thousands of files with different names, and those files might also have their similar file name patterns.&lt;br/&gt;\nNow I need a software, where I would instruct it to take the first 7 words of the file name into account, and running it will make the program go through all the existing files in the folder and show me a list like this:  &lt;/p&gt;\n\n&lt;p&gt;1)  &amp;quot;abcd_00&amp;quot; ---&amp;gt; 100 Files&lt;br/&gt;\n2) &amp;quot;1234_ab&amp;quot; --&amp;gt; 5 Files&lt;br/&gt;\n3) &amp;quot;loremip&amp;quot; --&amp;gt; 30 Files&lt;br/&gt;\n....&lt;br/&gt;\n...&lt;br/&gt;\n...  &lt;/p&gt;\n\n&lt;p&gt;I have tried to find something like this but to no avail. Can anyone help me find something similar to this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14s9lfu", "is_robot_indexable": true, "report_reasons": null, "author": "BeastBoiii2000", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14s9lfu/is_there_any_software_that_goes_through_all_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14s9lfu/is_there_any_software_that_goes_through_all_the/", "subreddit_subscribers": 691384, "created_utc": 1688650893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all. Recently found a few songs by some artists that I love that have exclusively been uploaded to Vimeo. I was curious to see what the highest quality audio that Vimeo provides, so that I can rip the audio in the best quality possible, without re-encoding and/or having any loss of quality. Like with YouTube and their OPUS streams which sometimes allow higher than 128kbps audio, is there a possibility to do this with Vimeo as well? What YT-DLP string would work the best for achieving all of this? Thanks :)", "author_fullname": "t2_14sosd3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ripping / Archiving Audio From Vimeo Videos In Highest Quality?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s9cxh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688650364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. Recently found a few songs by some artists that I love that have exclusively been uploaded to Vimeo. I was curious to see what the highest quality audio that Vimeo provides, so that I can rip the audio in the best quality possible, without re-encoding and/or having any loss of quality. Like with YouTube and their OPUS streams which sometimes allow higher than 128kbps audio, is there a possibility to do this with Vimeo as well? What YT-DLP string would work the best for achieving all of this? Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "256GB sadly", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14s9cxh", "is_robot_indexable": true, "report_reasons": null, "author": "FinleyGomez", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14s9cxh/ripping_archiving_audio_from_vimeo_videos_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14s9cxh/ripping_archiving_audio_from_vimeo_videos_in/", "subreddit_subscribers": 691384, "created_utc": 1688650364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't know what the easiest option for the average person would be though. \n\nhttps://www.rareddit.com/ is an example of such a site. If an easy how-to guide could be created that would allow the average non-techy person to create a free website like that I think it would then be able to spread.", "author_fullname": "t2_d5eznvwb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We should spread a way for people to host their own Reddit data before deleting it. It can be done for free with static site generators and Netlify, Cloudflare pages, and Github pages.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s7cm7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688645501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know what the easiest option for the average person would be though. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.rareddit.com/\"&gt;https://www.rareddit.com/&lt;/a&gt; is an example of such a site. If an easy how-to guide could be created that would allow the average non-techy person to create a free website like that I think it would then be able to spread.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14s7cm7", "is_robot_indexable": true, "report_reasons": null, "author": "iloveheyzeus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14s7cm7/we_should_spread_a_way_for_people_to_host_their/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14s7cm7/we_should_spread_a_way_for_people_to_host_their/", "subreddit_subscribers": 691384, "created_utc": 1688645501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can someone who has a clue what they are doing help me...pretty please?!?!\n\nI will fully admit to being relatively clueless when it comes to code of any kind. After fighting with this for over a week, I need help!\n\nI am trying to automate my daily downloads through Task Scheduler using yt-dlp. I have it working when I did 1 task per YT channel. That meant a ton of windows popping up every hour all day long. So, I tried to switch to a batch file. For some reason (which I am hoping someone can tell me) this will not work. When I run the yt-dlp command directly in Terminal or PS, it runs with no issues. When I run it through TS, the PS window pops up then disappears immediately before I can even see it. The log history says the task ran. Usually when there is an error I can see it. Also, when the task actually runs I can see it.\n\nI downloaded RoboIntern, thinking maybe it was something weird with TS. The same thing happened.\n\nThis is the command (please don't judge, like I said I can barely get by with the basics! lol):\n\nyt-dlp --live-from-start --paths H:/ -o \"%(channel)s/%(upload\\_date)s %(title)s.%(ext)s\" --dateafter yesterday -a \"D:\\\\Files\\\\tasks\\\\batch1.txt\"\n\nThe batch file is just the list of YT channels.\n\nLike I said, everything works perfect when run manually through PS. That task with -a on replaced with a url works when run through Task Scheduler. Can someone tell me what I am missing? THANK YOU!!!", "author_fullname": "t2_fl7ie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "yt-dlp: Automating Download Question - Task Scheduler not working with Batch File", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s67y4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688642516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone who has a clue what they are doing help me...pretty please?!?!&lt;/p&gt;\n\n&lt;p&gt;I will fully admit to being relatively clueless when it comes to code of any kind. After fighting with this for over a week, I need help!&lt;/p&gt;\n\n&lt;p&gt;I am trying to automate my daily downloads through Task Scheduler using yt-dlp. I have it working when I did 1 task per YT channel. That meant a ton of windows popping up every hour all day long. So, I tried to switch to a batch file. For some reason (which I am hoping someone can tell me) this will not work. When I run the yt-dlp command directly in Terminal or PS, it runs with no issues. When I run it through TS, the PS window pops up then disappears immediately before I can even see it. The log history says the task ran. Usually when there is an error I can see it. Also, when the task actually runs I can see it.&lt;/p&gt;\n\n&lt;p&gt;I downloaded RoboIntern, thinking maybe it was something weird with TS. The same thing happened.&lt;/p&gt;\n\n&lt;p&gt;This is the command (please don&amp;#39;t judge, like I said I can barely get by with the basics! lol):&lt;/p&gt;\n\n&lt;p&gt;yt-dlp --live-from-start --paths H:/ -o &amp;quot;%(channel)s/%(upload_date)s %(title)s.%(ext)s&amp;quot; --dateafter yesterday -a &amp;quot;D:\\Files\\tasks\\batch1.txt&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The batch file is just the list of YT channels.&lt;/p&gt;\n\n&lt;p&gt;Like I said, everything works perfect when run manually through PS. That task with -a on replaced with a url works when run through Task Scheduler. Can someone tell me what I am missing? THANK YOU!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14s67y4", "is_robot_indexable": true, "report_reasons": null, "author": "MSK7", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14s67y4/ytdlp_automating_download_question_task_scheduler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14s67y4/ytdlp_automating_download_question_task_scheduler/", "subreddit_subscribers": 691384, "created_utc": 1688642516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "TLDR : Decently powerful ARM SBC running Pimox (an unofficial version ARM version of proxmox), emulating an x86 system to run TrueNAS. Thoughts?\n\nLonger version : I'm going to be installing Pimox on an Orange Pi 5+ (8 cores / 16GB RAM / NVMe) for ARM vs x86 tinkering. Since I'm going to be running x86 anyway and I hate OMV... I might as well use my preferred NAS OS TrueNAS. (Performance is a concern, but see the unrelated section below)\n\nI move between 2 locations somewhat frequently, so this machine will be 'my' offsite backup 50% of the time. The other 50% will be handled by a raspberry pi running OMV. Plus I have a Storj account and oracle cloud account for an extra couple hundred GB of offsite storage, but I don't consider those as mine.\n\nI actually do pay oracle cloud some money so I doubt they'll close my account randomly(?) But still, I refuse to plan around that as a certainty.\n\nBoth the emulated TrueNAS and OMV instances will have 1TB of dedicated storage for the things I consider most valuable. These machines will have read only access to the main server and solely access it through a VPN (or through LAN). The main server doesn't have any credentials for the backup servers.\n\nI haven't decided on the syncing method (cron vs task, rsync vs zfs send etc). But in any case both the offsite backup machines will make periodic snapshots with an undetermined retention policy in order to protect against ransomware.\n\nPotential jankiness of x86 emulated on ARM aside (although one of the devs said they don't see an issue with it provided the same caveats as regular virtualization), I think this is a pretty good set up. 1 of the machines will always be local for fast recoveries, 1 machine will be remote. That handles 3 2 1.\n\nLong snapshot retention policies with ZFS's checksumming hopefully lets me deal with some of the nastier scenarios. The main server has a pretty robust pool to reduce the chances of needing a backup in the first place. Plus throw in about a terabyte of cloud storage here and there for some questionable recovery paths...\n\nI think that checks all the boxes aside from capacity. I don't have the cash for a full backup, and the sentimental value per bit goes WAAAAY down after the first terabyte or so. It's probably fine\n\nUnrelated : x86 emulation does take a lot of resources but it's not as bad as you might think. Debian ran pretty much in realtime on my phone (lags behind by a second or so). TrueNAS takes like 15 minutes to boot but a lot of that seems to be caused by some processes it's expecting but times out, which delays things. Once you get into the OS the terminal works pretty OK.\n\nI haven't been able to run any actual performance benchmarks on it, but WINE + BOX64 let me run prime95 on my phone as well. Cinebench and handbrake doesn't work though.", "author_fullname": "t2_upalof7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pimox + Emulated TrueNAS VM for backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14s3rtu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688635507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR : Decently powerful ARM SBC running Pimox (an unofficial version ARM version of proxmox), emulating an x86 system to run TrueNAS. Thoughts?&lt;/p&gt;\n\n&lt;p&gt;Longer version : I&amp;#39;m going to be installing Pimox on an Orange Pi 5+ (8 cores / 16GB RAM / NVMe) for ARM vs x86 tinkering. Since I&amp;#39;m going to be running x86 anyway and I hate OMV... I might as well use my preferred NAS OS TrueNAS. (Performance is a concern, but see the unrelated section below)&lt;/p&gt;\n\n&lt;p&gt;I move between 2 locations somewhat frequently, so this machine will be &amp;#39;my&amp;#39; offsite backup 50% of the time. The other 50% will be handled by a raspberry pi running OMV. Plus I have a Storj account and oracle cloud account for an extra couple hundred GB of offsite storage, but I don&amp;#39;t consider those as mine.&lt;/p&gt;\n\n&lt;p&gt;I actually do pay oracle cloud some money so I doubt they&amp;#39;ll close my account randomly(?) But still, I refuse to plan around that as a certainty.&lt;/p&gt;\n\n&lt;p&gt;Both the emulated TrueNAS and OMV instances will have 1TB of dedicated storage for the things I consider most valuable. These machines will have read only access to the main server and solely access it through a VPN (or through LAN). The main server doesn&amp;#39;t have any credentials for the backup servers.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t decided on the syncing method (cron vs task, rsync vs zfs send etc). But in any case both the offsite backup machines will make periodic snapshots with an undetermined retention policy in order to protect against ransomware.&lt;/p&gt;\n\n&lt;p&gt;Potential jankiness of x86 emulated on ARM aside (although one of the devs said they don&amp;#39;t see an issue with it provided the same caveats as regular virtualization), I think this is a pretty good set up. 1 of the machines will always be local for fast recoveries, 1 machine will be remote. That handles 3 2 1.&lt;/p&gt;\n\n&lt;p&gt;Long snapshot retention policies with ZFS&amp;#39;s checksumming hopefully lets me deal with some of the nastier scenarios. The main server has a pretty robust pool to reduce the chances of needing a backup in the first place. Plus throw in about a terabyte of cloud storage here and there for some questionable recovery paths...&lt;/p&gt;\n\n&lt;p&gt;I think that checks all the boxes aside from capacity. I don&amp;#39;t have the cash for a full backup, and the sentimental value per bit goes WAAAAY down after the first terabyte or so. It&amp;#39;s probably fine&lt;/p&gt;\n\n&lt;p&gt;Unrelated : x86 emulation does take a lot of resources but it&amp;#39;s not as bad as you might think. Debian ran pretty much in realtime on my phone (lags behind by a second or so). TrueNAS takes like 15 minutes to boot but a lot of that seems to be caused by some processes it&amp;#39;s expecting but times out, which delays things. Once you get into the OS the terminal works pretty OK.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t been able to run any actual performance benchmarks on it, but WINE + BOX64 let me run prime95 on my phone as well. Cinebench and handbrake doesn&amp;#39;t work though.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "vTrueNAS 72TB / Hyper-V", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14s3rtu", "is_robot_indexable": true, "report_reasons": null, "author": "Party_9001", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14s3rtu/pimox_emulated_truenas_vm_for_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14s3rtu/pimox_emulated_truenas_vm_for_backups/", "subreddit_subscribers": 691384, "created_utc": 1688635507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know it's a longshot but I'm wondering if other than clips on YouTube is there a site or somebody that regularly rips and uploads Sirius original \ncontent like Howard Stern, Eddie Trunk etc?\n\nThanks in advance!!", "author_fullname": "t2_26dmrv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SiriusXM original content rips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rtqf3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688606644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s a longshot but I&amp;#39;m wondering if other than clips on YouTube is there a site or somebody that regularly rips and uploads Sirius original \ncontent like Howard Stern, Eddie Trunk etc?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14rtqf3", "is_robot_indexable": true, "report_reasons": null, "author": "Rated-R-Ron", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14rtqf3/siriusxm_original_content_rips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14rtqf3/siriusxm_original_content_rips/", "subreddit_subscribers": 691384, "created_utc": 1688606644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not an issue at all, just curious what might cause this: Got myself a new 18tb hard drive (formatted ext4) and right now in the process of copying the content of an older 4tb disk (ext3) on it. I bet there are smoother ways to do this but I pretty much just used f5 with mc. While watching the progress from time to time I noticed that on a per file basis there are crazy different reading speeds, some files copy at 80mb/s while others drop down to 20mb/s and sometimes even below. \n\nNot knowing too much about all this I checked the syslog and didn't see any reading errors. Also, I remember reading that fragmentation (what would make the speed differences more logical) don't happen with ext3/4 since chunks of the needed size are reserved, but maybe I'm wrong about this.  As I said, not a big issue since it's working fine, just a curious interest why this happens. \n\nTIA for any explanation about potential reasons!", "author_fullname": "t2_mm345ara", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Significant different reading speeds between files while copying complete harddisk (ext3 to ext4)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rt63o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688605155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not an issue at all, just curious what might cause this: Got myself a new 18tb hard drive (formatted ext4) and right now in the process of copying the content of an older 4tb disk (ext3) on it. I bet there are smoother ways to do this but I pretty much just used f5 with mc. While watching the progress from time to time I noticed that on a per file basis there are crazy different reading speeds, some files copy at 80mb/s while others drop down to 20mb/s and sometimes even below. &lt;/p&gt;\n\n&lt;p&gt;Not knowing too much about all this I checked the syslog and didn&amp;#39;t see any reading errors. Also, I remember reading that fragmentation (what would make the speed differences more logical) don&amp;#39;t happen with ext3/4 since chunks of the needed size are reserved, but maybe I&amp;#39;m wrong about this.  As I said, not a big issue since it&amp;#39;s working fine, just a curious interest why this happens. &lt;/p&gt;\n\n&lt;p&gt;TIA for any explanation about potential reasons!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14rt63o", "is_robot_indexable": true, "report_reasons": null, "author": "jrhenk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14rt63o/significant_different_reading_speeds_between/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14rt63o/significant_different_reading_speeds_between/", "subreddit_subscribers": 691384, "created_utc": 1688605155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What\u2019s the best solution? Want to have an offline backup. Keeping everything else in place.", "author_fullname": "t2_xs0wv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "offline Backup for iCloud Photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14rpl7z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688596166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s the best solution? Want to have an offline backup. Keeping everything else in place.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14rpl7z", "is_robot_indexable": true, "report_reasons": null, "author": "lucy3141592", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14rpl7z/offline_backup_for_icloud_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14rpl7z/offline_backup_for_icloud_photos/", "subreddit_subscribers": 691384, "created_utc": 1688596166.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}