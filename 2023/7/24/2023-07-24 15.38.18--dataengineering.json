{"kind": "Listing", "data": {"after": "t3_157ke6v", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a senior engineer, but have never had a proper code review because my managers and colleagues tend to have a data analyst/DBA background. Sometimes they ask questions about high level logic, but nobody has ever spent more than 5 minutes on reading my code or nitpicked small things which means I can't learn and grow.\n\nWhat if I join a REAL DE team in the future as a senior with REAL code reviews and everyone can see how amateurish my code looks? That's going to be quite embarrassing and it will probably take forever to ship something to production.", "author_fullname": "t2_vsf3ige5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have never had my code reviewed thoroughly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ip1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 122, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 122, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690128456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a senior engineer, but have never had a proper code review because my managers and colleagues tend to have a data analyst/DBA background. Sometimes they ask questions about high level logic, but nobody has ever spent more than 5 minutes on reading my code or nitpicked small things which means I can&amp;#39;t learn and grow.&lt;/p&gt;\n\n&lt;p&gt;What if I join a REAL DE team in the future as a senior with REAL code reviews and everyone can see how amateurish my code looks? That&amp;#39;s going to be quite embarrassing and it will probably take forever to ship something to production.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157ip1t", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated_Ad_1108", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157ip1t/i_have_never_had_my_code_reviewed_thoroughly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157ip1t/i_have_never_had_my_code_reviewed_thoroughly/", "subreddit_subscribers": 117698, "created_utc": 1690128456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in the market for a DE position, couldn't sleep last night and was reflecting on interviews I've had so far. In 4+ cases, the hiring manager has specifically asked how I  would use data to increase sales. I completely understand that this role requires being a liaison to every department but how far does/should that go?\n\nThis isn't verbatim, but one conversation went like this:\n\nHiring Manager (HM): \"Say for instance, we had a new director of marketing. How would you build a dashboard to help their department?\"\n\nMe: \"I would meet with the director to understand what metrics are most important for their team.\"\n\nHM: \"What if the director didn't know what metrics they should be looking at.\"\n\nMe: \"Then I would ask what goals the department has and work backwards from there. Additionally,  I would prepare some visualizations for data exploration that we could review together. \n\nHM: \"What if the director didn't have any goals?\"\n\nAt this point, I was thinking I wouldn't want to work at a company without any leadership from someone in a director role. I think I understand what he was getting at, but it was still awkward. Is this equivalent to asking a prospective hire in sales this:\n\nHR: \"How would you design a data pipeline that incorporates salesforce and hubspot data?\"\n\nSales Hire (SH): \"I would work with the analytics engineering team, outlining what I need the data for.\"\n\nHR: \"What if the analytics engineering team didn't know how to design a pipeline?\"\n\nSH: ...\n\nAnother example of a question I got verbatim for a DE position:\n\nHR: \"How should we increase air conditioner sales?\"\n\nMe (Never having sold an air conditioner): \"I would assume that air-conditioner sales are driven by new home construction. I would identify areas that are experiencing growth/new development and focus marketing there.\"\n\nMaybe it's just this market, but I feel like I keep flubbing these questions because I don't have a degree in marketing. ", "author_fullname": "t2_7ix4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scope creep in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157lwnh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690136121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in the market for a DE position, couldn&amp;#39;t sleep last night and was reflecting on interviews I&amp;#39;ve had so far. In 4+ cases, the hiring manager has specifically asked how I  would use data to increase sales. I completely understand that this role requires being a liaison to every department but how far does/should that go?&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t verbatim, but one conversation went like this:&lt;/p&gt;\n\n&lt;p&gt;Hiring Manager (HM): &amp;quot;Say for instance, we had a new director of marketing. How would you build a dashboard to help their department?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;I would meet with the director to understand what metrics are most important for their team.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;HM: &amp;quot;What if the director didn&amp;#39;t know what metrics they should be looking at.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;Then I would ask what goals the department has and work backwards from there. Additionally,  I would prepare some visualizations for data exploration that we could review together. &lt;/p&gt;\n\n&lt;p&gt;HM: &amp;quot;What if the director didn&amp;#39;t have any goals?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;At this point, I was thinking I wouldn&amp;#39;t want to work at a company without any leadership from someone in a director role. I think I understand what he was getting at, but it was still awkward. Is this equivalent to asking a prospective hire in sales this:&lt;/p&gt;\n\n&lt;p&gt;HR: &amp;quot;How would you design a data pipeline that incorporates salesforce and hubspot data?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Sales Hire (SH): &amp;quot;I would work with the analytics engineering team, outlining what I need the data for.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;HR: &amp;quot;What if the analytics engineering team didn&amp;#39;t know how to design a pipeline?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;SH: ...&lt;/p&gt;\n\n&lt;p&gt;Another example of a question I got verbatim for a DE position:&lt;/p&gt;\n\n&lt;p&gt;HR: &amp;quot;How should we increase air conditioner sales?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me (Never having sold an air conditioner): &amp;quot;I would assume that air-conditioner sales are driven by new home construction. I would identify areas that are experiencing growth/new development and focus marketing there.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Maybe it&amp;#39;s just this market, but I feel like I keep flubbing these questions because I don&amp;#39;t have a degree in marketing. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157lwnh", "is_robot_indexable": true, "report_reasons": null, "author": "jonesaphore", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157lwnh/scope_creep_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157lwnh/scope_creep_in_de/", "subreddit_subscribers": 117698, "created_utc": 1690136121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious to see what others use to unit test in the DE space. I work primarily on the transformation side, where we\u2019ve picked up DBT. Our stack is GitHub Actions for CI/CD, AWS/Airflow for orchestration, logging, observability, restartability, and a light runtime to create the initial DBT compilation, that\u2019s then pushed down to SnowFlake and utilizes that run time to populate the objects and run data quality checks in the SnowFlake runtime.\n\nI\u2019ve been addressing unit testing in this stack. My team\u2019s skill set more so pertains to SQL developers rather than DE, and even then their SQL is half baked at best. \n\nUnit testing within DBT is spotty at best, flat out doesn\u2019t exist at worst. I\u2019ve written a Python script that extends DBT to dynamically generate a test to every node, and allows for additional tests to be written and compiled/ran, within the CI/CD pipeline. This enables the team to continue using SQL, and the script will do the rest. If the written or generated test fails, the deployment fails.\n\nData is loaded to and read from the warehouse. I hoped to abstract from the warehouse, but SnowFlake having a closed source engine wasn\u2019t conducive to that approach. My thought was to ingest the node sql files into duckdb and have an in memory database. Not the case given SnowFlake, but oh well.\n\nWhat are your stacks and unit testing solutions?", "author_fullname": "t2_708ooj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your unit testing implementation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157tf13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690153965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious to see what others use to unit test in the DE space. I work primarily on the transformation side, where we\u2019ve picked up DBT. Our stack is GitHub Actions for CI/CD, AWS/Airflow for orchestration, logging, observability, restartability, and a light runtime to create the initial DBT compilation, that\u2019s then pushed down to SnowFlake and utilizes that run time to populate the objects and run data quality checks in the SnowFlake runtime.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been addressing unit testing in this stack. My team\u2019s skill set more so pertains to SQL developers rather than DE, and even then their SQL is half baked at best. &lt;/p&gt;\n\n&lt;p&gt;Unit testing within DBT is spotty at best, flat out doesn\u2019t exist at worst. I\u2019ve written a Python script that extends DBT to dynamically generate a test to every node, and allows for additional tests to be written and compiled/ran, within the CI/CD pipeline. This enables the team to continue using SQL, and the script will do the rest. If the written or generated test fails, the deployment fails.&lt;/p&gt;\n\n&lt;p&gt;Data is loaded to and read from the warehouse. I hoped to abstract from the warehouse, but SnowFlake having a closed source engine wasn\u2019t conducive to that approach. My thought was to ingest the node sql files into duckdb and have an in memory database. Not the case given SnowFlake, but oh well.&lt;/p&gt;\n\n&lt;p&gt;What are your stacks and unit testing solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157tf13", "is_robot_indexable": true, "report_reasons": null, "author": "ExistentialFajitas", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157tf13/what_is_your_unit_testing_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157tf13/what_is_your_unit_testing_implementation/", "subreddit_subscribers": 117698, "created_utc": 1690153965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. \n\nWhat are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?", "author_fullname": "t2_dv159drh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does DE belong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157j46z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690129459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. &lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157j46z", "is_robot_indexable": true, "report_reasons": null, "author": "Sad-Fail-5337", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157j46z/where_does_de_belong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157j46z/where_does_de_belong/", "subreddit_subscribers": 117698, "created_utc": 1690129459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for my first DE job, transitioning from DA. I'm just curious where did you look for a DE job posting. The current sites I'm following are Linked In and Indeed. Is there any other sites that specializes in jobs like SWE or DE? Maybe Stackoverflow? \n\nThank you for your input", "author_fullname": "t2_ceq9dvcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you find your DE job (recently, like within 1-2 years)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157x027", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690163793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for my first DE job, transitioning from DA. I&amp;#39;m just curious where did you look for a DE job posting. The current sites I&amp;#39;m following are Linked In and Indeed. Is there any other sites that specializes in jobs like SWE or DE? Maybe Stackoverflow? &lt;/p&gt;\n\n&lt;p&gt;Thank you for your input&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157x027", "is_robot_indexable": true, "report_reasons": null, "author": "uniznoir", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157x027/where_do_you_find_your_de_job_recently_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157x027/where_do_you_find_your_de_job_recently_like/", "subreddit_subscribers": 117698, "created_utc": 1690163793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIve recently been tasked to lead the development of a new data warehouse at my company. The problem is, while I am experienced in the field, ive never worked on the more backend components (ive been more of an analyst/analytics engineer) and could use some guidance on how to structure and approach this whole process, if youd let me pick your brain a bit, or perhaps theres a better forum for this somewhere?", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have experience building out a data warehouse from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157sk9t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690151763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Ive recently been tasked to lead the development of a new data warehouse at my company. The problem is, while I am experienced in the field, ive never worked on the more backend components (ive been more of an analyst/analytics engineer) and could use some guidance on how to structure and approach this whole process, if youd let me pick your brain a bit, or perhaps theres a better forum for this somewhere?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157sk9t", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157sk9t/does_anyone_have_experience_building_out_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157sk9t/does_anyone_have_experience_building_out_a_data/", "subreddit_subscribers": 117698, "created_utc": 1690151763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a cofounder at a non-tech company in the sense that we don't have any client-facing software, just internal tools in the form of tableau dashboards and excel reports.\n\nI did a web dev bootcamp years ago, but what I'm doing now has been learned from googling and Udemy over the years as problems emerged.\n\nWe're now in year 3 and I feel like this architecture I've hacked out, with 0 production experience in engineering, could use a review, especially as our operations scale.\n\n1. AWS MySQL RDS database (db.t4g.xlarge), with read replica(db.t4g.large) for analytics. Currently at 100GB of data.\n2. On the write side: Data is constantly written to the DB throughout the day, mainly through scheduled AWS Lambda functions that are making API calls (currently 10+ different API systems). \n   1. Other sources: S3 Uploads/SNS/Webhooks -&gt; lambda triggers.\n   2. Proxy endpoint is used to pool connections\n   3. Write data is about 250MB a day\n   4. Write used to be a bottleneck until I figured out proxy endpoints, so I think I'm good for now.\n3. On the read side: I have about 40 tableau dashboards, with data extracts (some reused) that are refreshing daily/hourly from the read replica DB (db.t4g.large). \n   1. Some (full) refreshes can run for up to 5 minutes, which is fine at the moment. \n   2. Also have scheduled reports that run sql and convert to excel reports, to be emailed out.\n   3. This is usually where I run into bottlenecks and cause for upgrading my db instance. I'll upgrade when my extracts take 10+ minutes to refresh, or if I start getting alarm notifications for CPU Utilization (80% and I'm looking to upgrade)\n   4. I've optimized my sql to the best I could using indexing and other tricks, but a combination of joining 4 different tables on 3 keys each, with sorting and group by deduplicating, can push CPU compute to the limit.\n\nWhile I still have room to upgrade my DB, I am a bit concerned as we are heading into growth stage, potentially 4x our current usage. While I know that vertical scaling is going to be fine for me, I do have to consider the cost implications, and I'm wondering if there are new tools and tech that I should be looking into, as I continue to improve on this architecture. ", "author_fullname": "t2_1e2kokl8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self taught \"CTO/Data Engineer\" cofounder. Looking for feedback on architecture.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157yjwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690168215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a cofounder at a non-tech company in the sense that we don&amp;#39;t have any client-facing software, just internal tools in the form of tableau dashboards and excel reports.&lt;/p&gt;\n\n&lt;p&gt;I did a web dev bootcamp years ago, but what I&amp;#39;m doing now has been learned from googling and Udemy over the years as problems emerged.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re now in year 3 and I feel like this architecture I&amp;#39;ve hacked out, with 0 production experience in engineering, could use a review, especially as our operations scale.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;AWS MySQL RDS database (db.t4g.xlarge), with read replica(db.t4g.large) for analytics. Currently at 100GB of data.&lt;/li&gt;\n&lt;li&gt;On the write side: Data is constantly written to the DB throughout the day, mainly through scheduled AWS Lambda functions that are making API calls (currently 10+ different API systems). \n\n&lt;ol&gt;\n&lt;li&gt;Other sources: S3 Uploads/SNS/Webhooks -&amp;gt; lambda triggers.&lt;/li&gt;\n&lt;li&gt;Proxy endpoint is used to pool connections&lt;/li&gt;\n&lt;li&gt;Write data is about 250MB a day&lt;/li&gt;\n&lt;li&gt;Write used to be a bottleneck until I figured out proxy endpoints, so I think I&amp;#39;m good for now.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;On the read side: I have about 40 tableau dashboards, with data extracts (some reused) that are refreshing daily/hourly from the read replica DB (db.t4g.large). \n\n&lt;ol&gt;\n&lt;li&gt;Some (full) refreshes can run for up to 5 minutes, which is fine at the moment. &lt;/li&gt;\n&lt;li&gt;Also have scheduled reports that run sql and convert to excel reports, to be emailed out.&lt;/li&gt;\n&lt;li&gt;This is usually where I run into bottlenecks and cause for upgrading my db instance. I&amp;#39;ll upgrade when my extracts take 10+ minutes to refresh, or if I start getting alarm notifications for CPU Utilization (80% and I&amp;#39;m looking to upgrade)&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve optimized my sql to the best I could using indexing and other tricks, but a combination of joining 4 different tables on 3 keys each, with sorting and group by deduplicating, can push CPU compute to the limit.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;While I still have room to upgrade my DB, I am a bit concerned as we are heading into growth stage, potentially 4x our current usage. While I know that vertical scaling is going to be fine for me, I do have to consider the cost implications, and I&amp;#39;m wondering if there are new tools and tech that I should be looking into, as I continue to improve on this architecture. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157yjwy", "is_robot_indexable": true, "report_reasons": null, "author": "mcdunald", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157yjwy/self_taught_ctodata_engineer_cofounder_looking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157yjwy/self_taught_ctodata_engineer_cofounder_looking/", "subreddit_subscribers": 117698, "created_utc": 1690168215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In LinkedIn I am noticing open positions with the job title as \u201cSnowflake developer\u201d , am I missing something here (in terms of why would they want a snowflake developer over sql developer)", "author_fullname": "t2_8fygnueku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1588jm2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690199711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In LinkedIn I am noticing open positions with the job title as \u201cSnowflake developer\u201d , am I missing something here (in terms of why would they want a snowflake developer over sql developer)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1588jm2", "is_robot_indexable": true, "report_reasons": null, "author": "TestUser__", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1588jm2/snowflake_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1588jm2/snowflake_developer/", "subreddit_subscribers": 117698, "created_utc": 1690199711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I heard the term, \u201cwe rebuild the tables overnight\u201d by a data engineer today. Not really sure on the context, but why is this done and what is it ?", "author_fullname": "t2_a7nec5bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rebuilding Tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1588eeb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690199315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I heard the term, \u201cwe rebuild the tables overnight\u201d by a data engineer today. Not really sure on the context, but why is this done and what is it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1588eeb", "is_robot_indexable": true, "report_reasons": null, "author": "TheCumCopter", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1588eeb/rebuilding_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1588eeb/rebuilding_tables/", "subreddit_subscribers": 117698, "created_utc": 1690199315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a senior data engineer and working in team of 4 people. 2 data scientists and 1 manager. It was new team when I joined, I help them and built automated data pipeline from scratch to extract the data in S3 but they use it less frequently and no recurring jobs or cron jobs setup. I discussed importance of recurring ETL jobs and importance of data warehousing but feels like my manager is not interested in it. He only consider data science work as real work and ready to hire 4 more data scientists. Usually they prefer to develop model with single CSV/parquet file with bare thousand rows data and complete the model with power point presentation. no deployment or nothing because we even don\u2019t have CI/CD/ devpos/ MLops pipelines. I force them to start GitHub for version controlling but it\u2019s only 1 pr in a year so they are not using it anyways. My team only run sagemaker notebook and store any resultant output csv file along with notebook. It\u2019s smaller team so I feel like micromanaging but that\u2019s not issue for me but I am frustrated with they are not considering importance of data engineering at all. My manager is not even handling jira work. He now hired scrum master!!! I am confused since hiring freeze how do I change my team and because I on visa I cannot change my company in upcoming next 2 years. I can stay and chill here but I feel guilty wasting my time in my career and not learning anything new!", "author_fullname": "t2_a0ixumwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feels like data engineering has no future in my team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_158bq43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690207672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a senior data engineer and working in team of 4 people. 2 data scientists and 1 manager. It was new team when I joined, I help them and built automated data pipeline from scratch to extract the data in S3 but they use it less frequently and no recurring jobs or cron jobs setup. I discussed importance of recurring ETL jobs and importance of data warehousing but feels like my manager is not interested in it. He only consider data science work as real work and ready to hire 4 more data scientists. Usually they prefer to develop model with single CSV/parquet file with bare thousand rows data and complete the model with power point presentation. no deployment or nothing because we even don\u2019t have CI/CD/ devpos/ MLops pipelines. I force them to start GitHub for version controlling but it\u2019s only 1 pr in a year so they are not using it anyways. My team only run sagemaker notebook and store any resultant output csv file along with notebook. It\u2019s smaller team so I feel like micromanaging but that\u2019s not issue for me but I am frustrated with they are not considering importance of data engineering at all. My manager is not even handling jira work. He now hired scrum master!!! I am confused since hiring freeze how do I change my team and because I on visa I cannot change my company in upcoming next 2 years. I can stay and chill here but I feel guilty wasting my time in my career and not learning anything new!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "158bq43", "is_robot_indexable": true, "report_reasons": null, "author": "ExcitingAd7292", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/158bq43/feels_like_data_engineering_has_no_future_in_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/158bq43/feels_like_data_engineering_has_no_future_in_my/", "subreddit_subscribers": 117698, "created_utc": 1690207672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Might be a dumb question - \n\nI have 1.5 hour commuting distance, and I would like to keep some of the API or Google Cloud docs on my iPad so that I can read them offline. (There's  a bad signal on the UK trains generally)  \n\n\nI wonder if there's app to let me fiddle around the document offline so that I can use it as if I am accessing the documentations online", "author_fullname": "t2_pd2piq1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool that keep documents offline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_158abs5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690204350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Might be a dumb question - &lt;/p&gt;\n\n&lt;p&gt;I have 1.5 hour commuting distance, and I would like to keep some of the API or Google Cloud docs on my iPad so that I can read them offline. (There&amp;#39;s  a bad signal on the UK trains generally)  &lt;/p&gt;\n\n&lt;p&gt;I wonder if there&amp;#39;s app to let me fiddle around the document offline so that I can use it as if I am accessing the documentations online&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "158abs5", "is_robot_indexable": true, "report_reasons": null, "author": "uk_dataguy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/158abs5/tool_that_keep_documents_offline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/158abs5/tool_that_keep_documents_offline/", "subreddit_subscribers": 117698, "created_utc": 1690204350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What resource do you guys use to ask questions and interact with other people facing similar problems as you while using similar tools? This is the purpose of SO but i feel that for anything cloud DE related (i'm on AWS) i never get any answers. ", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SO but for cloud data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_158a6y5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690204018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What resource do you guys use to ask questions and interact with other people facing similar problems as you while using similar tools? This is the purpose of SO but i feel that for anything cloud DE related (i&amp;#39;m on AWS) i never get any answers. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "158a6y5", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/158a6y5/so_but_for_cloud_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/158a6y5/so_but_for_cloud_data_engineering/", "subreddit_subscribers": 117698, "created_utc": 1690204018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit community!\n\nI'm thrilled to introduce you to Prism, an innovative open-source data orchestration platform. We've been working tirelessly to develop this tool, and now we're excited to invite you all to be a part of our alpha testing phase.\n\n\ud83d\udd17 Website: [https://runprism.com/](https://runprism.com/)\n\n\ud83d\udce2 GitHub Repository: [https://github.com/runprism/prism](https://github.com/runprism/prism)\n\n\ud83d\udcc4 Documentation: [https://docs.runprism.com](https://docs.runprism.com/)\n\n# What is Prism?\n\nPrism is a powerful yet user-friendly orchestration platform designed to streamline your processes, boost productivity, and enhance collaboration across teams. Whether you're a developer, sysadmin, data analyst, or any professional who deals with workflows, Prism has something valuable to offer.\n\n# Key Features\n\n**\ud83d\udd39** **Workflow Automation**\\*\\*:\\*\\* Real-time dependency declaration: With Prism, analysts can declare dependencies using a simple function call. No need to explicitly keep track of the pipeline order \u2014 at runtime, Prism automatically parses the function calls and builds the dependency graph.\n\n**\ud83d\udd39 Intuitive logging:** Prism automatically logs events for parsing the configuration files, compiling the tasks and creating the project, and executing the tasks. No configuration is required.\n\n\ud83d\udd39 **Flexible CLI:** Users can instantiate, compile, and run projects using a simple, but powerful command-line interface.\n\n**\ud83d\udd39 Extensive Plugin Library:** Enjoy a rich collection of integrations with your favorite tools and services.\n\n**\ud83d\udd39 \u201cBatteries included\u201d:** Prism comes with all the essentials needed to get up and running quickly. Users can create and run their first project in less than 2 minutes.\n\n# How to Get Involved\n\nBy joining our Alpha testing phase, you have the unique opportunity to be among the first users to experience Prism in action. Your invaluable feedback will directly impact the development of this platform, helping us make it even better, more stable, and tailored to your needs.\n\nVisit our website [https://runprism.com](https://runprism.com/) to learn more about the platform and its features. In addition, check out our documentation at [https://docs.runprism.com](https://docs.runprism.com/) to get started right away!\n\nAccess the GitHub repository [https://github.com/runprism/prism](https://github.com/runprism/prism) to view the source code, report issues, and contribute to the project.\n\nTry out Prism in your own workflow environment and let us know what you think!\n\nWe highly encourage you to share your thoughts, suggestions, and bug reports with us. Feel free to post your feedback directly in this thread, or if you prefer, you can raise issues on GitHub. Your input is invaluable to us, and together, we can shape Prism into the go-to platform for data workflow orchestration.\n\n# Who We Are\n\nOur team is a group of passionate data engineers, scientists, and developers. We're open-source enthusiasts who believe in the power of community-driven software, and we're committed to making Prism an exceptional orchestration tool and fostering an inclusive environment for all contributors.", "author_fullname": "t2_g2ejflv7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Prism: A Novel, Open-Source Data Orchestration Software. Feedback needed!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157vab7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690158966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit community!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thrilled to introduce you to Prism, an innovative open-source data orchestration platform. We&amp;#39;ve been working tirelessly to develop this tool, and now we&amp;#39;re excited to invite you all to be a part of our alpha testing phase.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd17 Website: &lt;a href=\"https://runprism.com/\"&gt;https://runprism.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udce2 GitHub Repository: &lt;a href=\"https://github.com/runprism/prism\"&gt;https://github.com/runprism/prism&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcc4 Documentation: &lt;a href=\"https://docs.runprism.com/\"&gt;https://docs.runprism.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;What is Prism?&lt;/h1&gt;\n\n&lt;p&gt;Prism is a powerful yet user-friendly orchestration platform designed to streamline your processes, boost productivity, and enhance collaboration across teams. Whether you&amp;#39;re a developer, sysadmin, data analyst, or any professional who deals with workflows, Prism has something valuable to offer.&lt;/p&gt;\n\n&lt;h1&gt;Key Features&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udd39&lt;/strong&gt; &lt;strong&gt;Workflow Automation&lt;/strong&gt;**:** Real-time dependency declaration: With Prism, analysts can declare dependencies using a simple function call. No need to explicitly keep track of the pipeline order \u2014 at runtime, Prism automatically parses the function calls and builds the dependency graph.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udd39 Intuitive logging:&lt;/strong&gt; Prism automatically logs events for parsing the configuration files, compiling the tasks and creating the project, and executing the tasks. No configuration is required.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd39 &lt;strong&gt;Flexible CLI:&lt;/strong&gt; Users can instantiate, compile, and run projects using a simple, but powerful command-line interface.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udd39 Extensive Plugin Library:&lt;/strong&gt; Enjoy a rich collection of integrations with your favorite tools and services.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udd39 \u201cBatteries included\u201d:&lt;/strong&gt; Prism comes with all the essentials needed to get up and running quickly. Users can create and run their first project in less than 2 minutes.&lt;/p&gt;\n\n&lt;h1&gt;How to Get Involved&lt;/h1&gt;\n\n&lt;p&gt;By joining our Alpha testing phase, you have the unique opportunity to be among the first users to experience Prism in action. Your invaluable feedback will directly impact the development of this platform, helping us make it even better, more stable, and tailored to your needs.&lt;/p&gt;\n\n&lt;p&gt;Visit our website &lt;a href=\"https://runprism.com/\"&gt;https://runprism.com&lt;/a&gt; to learn more about the platform and its features. In addition, check out our documentation at &lt;a href=\"https://docs.runprism.com/\"&gt;https://docs.runprism.com&lt;/a&gt; to get started right away!&lt;/p&gt;\n\n&lt;p&gt;Access the GitHub repository &lt;a href=\"https://github.com/runprism/prism\"&gt;https://github.com/runprism/prism&lt;/a&gt; to view the source code, report issues, and contribute to the project.&lt;/p&gt;\n\n&lt;p&gt;Try out Prism in your own workflow environment and let us know what you think!&lt;/p&gt;\n\n&lt;p&gt;We highly encourage you to share your thoughts, suggestions, and bug reports with us. Feel free to post your feedback directly in this thread, or if you prefer, you can raise issues on GitHub. Your input is invaluable to us, and together, we can shape Prism into the go-to platform for data workflow orchestration.&lt;/p&gt;\n\n&lt;h1&gt;Who We Are&lt;/h1&gt;\n\n&lt;p&gt;Our team is a group of passionate data engineers, scientists, and developers. We&amp;#39;re open-source enthusiasts who believe in the power of community-driven software, and we&amp;#39;re committed to making Prism an exceptional orchestration tool and fostering an inclusive environment for all contributors.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "157vab7", "is_robot_indexable": true, "report_reasons": null, "author": "runprism", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157vab7/introducing_prism_a_novel_opensource_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157vab7/introducing_prism_a_novel_opensource_data/", "subreddit_subscribers": 117698, "created_utc": 1690158966.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "found this on substack and reposting here for more reach.", "author_fullname": "t2_vi5mj54d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "name": "t3_157mn03", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.54, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FDDKeJwbGLUab6btVz1qzcE0b4JSqmLUEaFYavlouFc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690137835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;found this on substack and reposting here for more reach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/o908zbyifrdb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?auto=webp&amp;s=5760b5b63c45ff2034b1053d76b21cdda69dbc24", "width": 1179, "height": 718}, "resolutions": [{"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e19db647dba910a9349807b611f66eb7b16cea18", "width": 108, "height": 65}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e69c8470d41e0d0a7f73b9235608653fa071e55b", "width": 216, "height": 131}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9b46d207118d885e3d8ab30d58e1accf87448081", "width": 320, "height": 194}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=980061a81aac3c925fec18c1f93441bd90f4c5a5", "width": 640, "height": 389}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8855e1c1ee649852826ec2f6eebfc8ac8bca21ef", "width": 960, "height": 584}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b0526230ba81f85165e34740b6f2f26fe354d20", "width": 1080, "height": 657}], "variants": {}, "id": "FD8BsKGuc9f_50KXbD-QTDIZrGjNXHpBBM-rg1ah9e0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157mn03", "is_robot_indexable": true, "report_reasons": null, "author": "mrlmld", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157mn03/rust_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/o908zbyifrdb1.jpg", "subreddit_subscribers": 117698, "created_utc": 1690137835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can somebody walk me through the difference in implementing AWS glue as the data transfer layer vs fivetran?\n\nWhat are you rolling on your own when using glue vs what you get out of the box when using fivetran?\n\nWhat do you lose control over with either of them?\n\n pros/cons of each?\n\nSorry for the newb question but I\u2019m having trouble getting a straight answer via my Google research", "author_fullname": "t2_vit6d6oc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newb question: how can I think about fivetran vs AWS glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_158bwpj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690212362.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690208087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can somebody walk me through the difference in implementing AWS glue as the data transfer layer vs fivetran?&lt;/p&gt;\n\n&lt;p&gt;What are you rolling on your own when using glue vs what you get out of the box when using fivetran?&lt;/p&gt;\n\n&lt;p&gt;What do you lose control over with either of them?&lt;/p&gt;\n\n&lt;p&gt;pros/cons of each?&lt;/p&gt;\n\n&lt;p&gt;Sorry for the newb question but I\u2019m having trouble getting a straight answer via my Google research&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "158bwpj", "is_robot_indexable": true, "report_reasons": null, "author": "poopbrainmane", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/158bwpj/newb_question_how_can_i_think_about_fivetran_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/158bwpj/newb_question_how_can_i_think_about_fivetran_vs/", "subreddit_subscribers": 117698, "created_utc": 1690208087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am see many use cases where it is advised not to over-engineer and just use Postgres as your datawarehouse solution. What are some indicators that it is time to move away from Postgres and into a more traditional DW solution such as Snowflake? Or signs that Postgres is not even a good starting point? I am trying to prevent a pitfall where I go with a simple solution that does not scale/age well.", "author_fullname": "t2_8b0w9ipt9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When is time to move away from a Postgres DW Solution to Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_158b3q0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690206222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am see many use cases where it is advised not to over-engineer and just use Postgres as your datawarehouse solution. What are some indicators that it is time to move away from Postgres and into a more traditional DW solution such as Snowflake? Or signs that Postgres is not even a good starting point? I am trying to prevent a pitfall where I go with a simple solution that does not scale/age well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "158b3q0", "is_robot_indexable": true, "report_reasons": null, "author": "JoseyWales10", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/158b3q0/when_is_time_to_move_away_from_a_postgres_dw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/158b3q0/when_is_time_to_move_away_from_a_postgres_dw/", "subreddit_subscribers": 117698, "created_utc": 1690206222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All - Does anyone have experience or a guide of how to run airflow in production? I currently have a Python script that builds the DAG and runs as expected with a sequential executor and Postgres backend.\n\nWhile this works ok, the job will only initialize when my laptop is running. Ideally I\u2019d like to get the job to run in the background each week regardless of whether my laptop is open. \n\nI\u2019ve had a hard time getting this sorted out and was wondering if anyone here could point me in the right direction.", "author_fullname": "t2_5c48q8mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow In Production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_158b3ge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690206203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All - Does anyone have experience or a guide of how to run airflow in production? I currently have a Python script that builds the DAG and runs as expected with a sequential executor and Postgres backend.&lt;/p&gt;\n\n&lt;p&gt;While this works ok, the job will only initialize when my laptop is running. Ideally I\u2019d like to get the job to run in the background each week regardless of whether my laptop is open. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve had a hard time getting this sorted out and was wondering if anyone here could point me in the right direction.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "158b3ge", "is_robot_indexable": true, "report_reasons": null, "author": "cuckflemson1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/158b3ge/airflow_in_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/158b3ge/airflow_in_production/", "subreddit_subscribers": 117698, "created_utc": 1690206203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am curious what % of people here use DBT with Snowflake. I know it's popular, but I'm curious to see the numbers!\n\n[View Poll](https://www.reddit.com/poll/158aza3)", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use Snowflake with DBT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_158aza3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690205934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am curious what % of people here use DBT with Snowflake. I know it&amp;#39;s popular, but I&amp;#39;m curious to see the numbers!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/158aza3\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "158aza3", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1690465134471, "options": [{"text": "Yes, I use Snowflake with DBT", "id": "24035471"}, {"text": "No, I use Snowflake without DBT", "id": "24035472"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 29, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/158aza3/do_you_use_snowflake_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/158aza3/do_you_use_snowflake_with_dbt/", "subreddit_subscribers": 117698, "created_utc": 1690205934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/pe9xjvsy0xdb1.jpg?width=1267&amp;format=pjpg&amp;auto=webp&amp;s=6b6d9af29d508c83c7dc14b7b0af71b57135d0af\n\n  [https://www.dasca.org/world-of-big-data/article/why-every-data-scientist-wants-a-data-engineer](https://www.dasca.org/world-of-big-data/article/why-every-data-scientist-wants-a-data-engineer) ", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineers lay the groundwork on which data scientists build the structure. Know how they are interdependent on each other", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pe9xjvsy0xdb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/pe9xjvsy0xdb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e3c9755058d19f4e40bfbf2203cc80169d1e346"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/pe9xjvsy0xdb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=af9352909e5352675215fb113e2af7c781ab058c"}, {"y": 226, "x": 320, "u": "https://preview.redd.it/pe9xjvsy0xdb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd31fb23f383fcd1de02ebf96f2b180ee902b342"}, {"y": 453, "x": 640, "u": "https://preview.redd.it/pe9xjvsy0xdb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38adcf828d871321f8415795d2463ac739c6f6d9"}, {"y": 679, "x": 960, "u": "https://preview.redd.it/pe9xjvsy0xdb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e63383339279b67b7fedbed50f53bbb1ab20ddf"}, {"y": 764, "x": 1080, "u": "https://preview.redd.it/pe9xjvsy0xdb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7e889f6fbb9ddfdbe8f794354f83a15dbecea705"}], "s": {"y": 897, "x": 1267, "u": "https://preview.redd.it/pe9xjvsy0xdb1.jpg?width=1267&amp;format=pjpg&amp;auto=webp&amp;s=6b6d9af29d508c83c7dc14b7b0af71b57135d0af"}, "id": "pe9xjvsy0xdb1"}}, "name": "t3_158aunm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UaCAmomFIhLBHe-3HPYZRlCn7x4NwYnWrK33Dzj9eYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1690205616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pe9xjvsy0xdb1.jpg?width=1267&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=6b6d9af29d508c83c7dc14b7b0af71b57135d0af\"&gt;https://preview.redd.it/pe9xjvsy0xdb1.jpg?width=1267&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=6b6d9af29d508c83c7dc14b7b0af71b57135d0af&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.dasca.org/world-of-big-data/article/why-every-data-scientist-wants-a-data-engineer\"&gt;https://www.dasca.org/world-of-big-data/article/why-every-data-scientist-wants-a-data-engineer&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5yv6b8nA08LMInbBeDWGXS24bBYmtBuXFtaNpNCkebQ.jpg?auto=webp&amp;s=a42679f782a2b531523c5a971045531a03c13559", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/5yv6b8nA08LMInbBeDWGXS24bBYmtBuXFtaNpNCkebQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d7feed4e372c3fe0bfa1912c2e5b6791f292e0e4", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5yv6b8nA08LMInbBeDWGXS24bBYmtBuXFtaNpNCkebQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d54da90171ff6df005eb51ae5c7ec135fe68cb6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/5yv6b8nA08LMInbBeDWGXS24bBYmtBuXFtaNpNCkebQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d08fcc288ff11e8921005f209fbc2a1a3afad15c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/5yv6b8nA08LMInbBeDWGXS24bBYmtBuXFtaNpNCkebQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=76e8a4d415ef0aae3a15b2b8d2af613ac0969d2d", "width": 640, "height": 336}], "variants": {}, "id": "lvBYtYozQiJ-78JCDr1ZMVc5JzGUvRKG4x1iKGaAqXQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "158aunm", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/158aunm/data_engineers_lay_the_groundwork_on_which_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/158aunm/data_engineers_lay_the_groundwork_on_which_data/", "subreddit_subscribers": 117698, "created_utc": 1690205616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Data Engineering a Complex Career? Challenges Faced by Data Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_158ao7m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VHnn5L4ddxnFTGxwMsT_BTK5ZlJNZtf1-dXepjM3zMg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690205204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "losanews.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://losanews.com/is-data-engineering-a-complex-career-challenges-faced-by-data-engineers/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/X-dmYzZvw4fC6IA_2n-NxpLnRo9eskfrRQ40qaEPOWI.jpg?auto=webp&amp;s=b287bc20382beb92f59b0d74a94443edb47a06ff", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/X-dmYzZvw4fC6IA_2n-NxpLnRo9eskfrRQ40qaEPOWI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f376a7de0833aa497d39ebb15863238c35ca0554", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/X-dmYzZvw4fC6IA_2n-NxpLnRo9eskfrRQ40qaEPOWI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=19036d648550c285ea54a1766cc6749475cbd485", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/X-dmYzZvw4fC6IA_2n-NxpLnRo9eskfrRQ40qaEPOWI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ecdaf99a3ba27cb5c0ef75cf2eb4f6f3a8969a0b", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/X-dmYzZvw4fC6IA_2n-NxpLnRo9eskfrRQ40qaEPOWI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cee7d11c6aeffb8c27e633aee0a0551047d80ebc", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/X-dmYzZvw4fC6IA_2n-NxpLnRo9eskfrRQ40qaEPOWI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d97712dfef898c8d762414bd5d1be98f5fe6a76e", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/X-dmYzZvw4fC6IA_2n-NxpLnRo9eskfrRQ40qaEPOWI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4583df544314054d187d70314a5b521c5a79e56e", "width": 1080, "height": 607}], "variants": {}, "id": "_qysRH5tbxs5AwGIaLyYPwaBSZogyQ-5FgZx1CSax1I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "158ao7m", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/158ao7m/is_data_engineering_a_complex_career_challenges/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://losanews.com/is-data-engineering-a-complex-career-challenges-faced-by-data-engineers/", "subreddit_subscribers": 117698, "created_utc": 1690205204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A while ago I posted about Fluke, an open-source project of mine in Python that could be used as a higher-level API in order to interact with objects in the cloud as if they were files within an ordinary filesystem. With Fluke 0.4.0 just being released, message queues have been added into the mix, making it extremely easy to accomplish various tasks that previously needed a ton of boilerplate code.\n\nFor example, we can constantly poll a message queue for messages, parse these messages in order to extract the path of an object in some S3 bucket, and then transfer these objects to some remote server, all in just a few lines of code!\n\n    from fluke.auth import AWSAuth, RemoteAuth\n    from fluke.queues import AmazonSQSQueue\n    from fluke.storage import AmazonS3Dir, RemoteDir\n    \n    # This object will be used to authenticate\n    # with AWS.\n    aws_auth = AWSAuth(\n        aws_access_key_id=\"aws_access_key\",\n        aws_secret_access_key=\"aws_secret_key\")\n    \n    # This object will be used to authenticate\n    # with the remote machine.\n    rmt_auth = RemoteAuth.from_password(\n        hostname=\"host\",\n        username=\"user\",\n        password=\"password\")\n    \n    with (\n        AmazonSQSQueue(auth=aws_auth, queue='queue') as queue,\n        AmazonS3Dir(auth=aws_auth, bucket='bucket') as bucket,\n        RemoteDir(auth=rmt_auth, path='/home/user/dir') as rmt_dir\n    ):\n        for batch in queue.poll(polling_frequency=60):\n            for msg in batch:\n                path = parser_fun(msg)\n                bucket.get_file(path).transfer_to(dst=rmt_dir)\n\nI'll be happy to respond to any feedback/questions you may have.\n\n\\- PyPI: [https://pypi.org/project/fluke-api/](https://pypi.org/project/fluke-api/)\n\n\\- Github: [https://github.com/manoss96/fluke](https://github.com/manoss96/fluke)\n\n\\- Docs: [https://fluke.readthedocs.io/en/latest/index.html](https://fluke.readthedocs.io/en/latest/index.html)\n\n&amp;#x200B;", "author_fullname": "t2_q7l1xoqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fluke, a simple API to object storage and message queues in the cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1584n2p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690187741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A while ago I posted about Fluke, an open-source project of mine in Python that could be used as a higher-level API in order to interact with objects in the cloud as if they were files within an ordinary filesystem. With Fluke 0.4.0 just being released, message queues have been added into the mix, making it extremely easy to accomplish various tasks that previously needed a ton of boilerplate code.&lt;/p&gt;\n\n&lt;p&gt;For example, we can constantly poll a message queue for messages, parse these messages in order to extract the path of an object in some S3 bucket, and then transfer these objects to some remote server, all in just a few lines of code!&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from fluke.auth import AWSAuth, RemoteAuth\nfrom fluke.queues import AmazonSQSQueue\nfrom fluke.storage import AmazonS3Dir, RemoteDir\n\n# This object will be used to authenticate\n# with AWS.\naws_auth = AWSAuth(\n    aws_access_key_id=&amp;quot;aws_access_key&amp;quot;,\n    aws_secret_access_key=&amp;quot;aws_secret_key&amp;quot;)\n\n# This object will be used to authenticate\n# with the remote machine.\nrmt_auth = RemoteAuth.from_password(\n    hostname=&amp;quot;host&amp;quot;,\n    username=&amp;quot;user&amp;quot;,\n    password=&amp;quot;password&amp;quot;)\n\nwith (\n    AmazonSQSQueue(auth=aws_auth, queue=&amp;#39;queue&amp;#39;) as queue,\n    AmazonS3Dir(auth=aws_auth, bucket=&amp;#39;bucket&amp;#39;) as bucket,\n    RemoteDir(auth=rmt_auth, path=&amp;#39;/home/user/dir&amp;#39;) as rmt_dir\n):\n    for batch in queue.poll(polling_frequency=60):\n        for msg in batch:\n            path = parser_fun(msg)\n            bucket.get_file(path).transfer_to(dst=rmt_dir)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;ll be happy to respond to any feedback/questions you may have.&lt;/p&gt;\n\n&lt;p&gt;- PyPI: &lt;a href=\"https://pypi.org/project/fluke-api/\"&gt;https://pypi.org/project/fluke-api/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;- Github: &lt;a href=\"https://github.com/manoss96/fluke\"&gt;https://github.com/manoss96/fluke&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;- Docs: &lt;a href=\"https://fluke.readthedocs.io/en/latest/index.html\"&gt;https://fluke.readthedocs.io/en/latest/index.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;s=27b6869059bde930b8fa91e163c4a5b593a62755", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=967712caa32aa48e894a0097548ea87ec67be18c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a3c7948dff53aae03712fb7d592fa1bbddccbb4", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1584n2p", "is_robot_indexable": true, "report_reasons": null, "author": "WerdenWissen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1584n2p/fluke_a_simple_api_to_object_storage_and_message/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1584n2p/fluke_a_simple_api_to_object_storage_and_message/", "subreddit_subscribers": 117698, "created_utc": 1690187741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am looking for some advise. I am designing a \"batch data generation pipeline\" that is essentially a batch execution version of a this problem (for now a spark job):\n\n1. User provided id, query parameters, output location.\n\n2. Query a catalog dataset that represents a large list of files and filter the ones that matches exactly the ones needed to produce the output.\n\n3. Execute a set of transformation (groupby, sort, etc) that take output of #2 and produces some output dataframe.\n\n4. Write to output location in some custom format.\n\nSo, I have N instances of the same problem with different (possibly overlapping) inputs. I want to build an efficient way to structure this spark job(s) so that the overhead is low. \n\nOption 1: build a spark job that submits n jobs with different inputs in parallel or in batches with no shared steps (except the spark context)\n\nOption 2: build a spark job that does a sort of dataframe union before submitting it all as a single bigger job.\n\nOption 3: ???\n\nHas anyone done something like this? In terms of scale size - the step 1 (list of files) is about ~5TB and the input used to generate the data is ~10GiB output. The N in the batch is adjustable but I think 100 at a time is probably a minimum point.", "author_fullname": "t2_4eb03", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Packing n querries into 1", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157yia1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690168080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am looking for some advise. I am designing a &amp;quot;batch data generation pipeline&amp;quot; that is essentially a batch execution version of a this problem (for now a spark job):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;User provided id, query parameters, output location.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Query a catalog dataset that represents a large list of files and filter the ones that matches exactly the ones needed to produce the output.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Execute a set of transformation (groupby, sort, etc) that take output of #2 and produces some output dataframe.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Write to output location in some custom format.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So, I have N instances of the same problem with different (possibly overlapping) inputs. I want to build an efficient way to structure this spark job(s) so that the overhead is low. &lt;/p&gt;\n\n&lt;p&gt;Option 1: build a spark job that submits n jobs with different inputs in parallel or in batches with no shared steps (except the spark context)&lt;/p&gt;\n\n&lt;p&gt;Option 2: build a spark job that does a sort of dataframe union before submitting it all as a single bigger job.&lt;/p&gt;\n\n&lt;p&gt;Option 3: ???&lt;/p&gt;\n\n&lt;p&gt;Has anyone done something like this? In terms of scale size - the step 1 (list of files) is about ~5TB and the input used to generate the data is ~10GiB output. The N in the batch is adjustable but I think 100 at a time is probably a minimum point.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157yia1", "is_robot_indexable": true, "report_reasons": null, "author": "ankurcha", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157yia1/packing_n_querries_into_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157yia1/packing_n_querries_into_1/", "subreddit_subscribers": 117698, "created_utc": 1690168080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone here use [Observable Plot](https://observablehq.com/plot/) for visualization? I\u2019m a software dev and data engineer (background in analytics) by day and indie hacker/software bootstrapper by night. I recently found Observable Plot, and I like how it\u2019s a more simplified D3 library without the extreme complexity of D3. As a fan of analytics, I was thinking it would be cool to have an app or platform powered by Observable Plot. Does anyone use it? Do you find it useful? I think it would be fun to build something for it one day.", "author_fullname": "t2_853j9w4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Observable Plot App", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157tbjy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690153722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone here use &lt;a href=\"https://observablehq.com/plot/\"&gt;Observable Plot&lt;/a&gt; for visualization? I\u2019m a software dev and data engineer (background in analytics) by day and indie hacker/software bootstrapper by night. I recently found Observable Plot, and I like how it\u2019s a more simplified D3 library without the extreme complexity of D3. As a fan of analytics, I was thinking it would be cool to have an app or platform powered by Observable Plot. Does anyone use it? Do you find it useful? I think it would be fun to build something for it one day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?auto=webp&amp;s=d61aad96512a29dcaa46ea70b4c8c95d7e5f0c86", "width": 640, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5fbff1bfdc101900113b39ebbacd4d31bba433b2", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9fb242ff425f112d1d0bc1d00a39affc7d4e261b", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=65e3caabb9cf4cb5b2837ff3e18f307223b2cb52", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c18a4fb1fff2a49410ad5f90264959f409db2dcb", "width": 640, "height": 400}], "variants": {}, "id": "ZPQU_vipEkiGX1dZZBsM9Te8h8Cq9X3DaP_mcwE-zKo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157tbjy", "is_robot_indexable": true, "report_reasons": null, "author": "SirLagsABot", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157tbjy/observable_plot_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157tbjy/observable_plot_app/", "subreddit_subscribers": 117698, "created_utc": 1690153722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm fairly new to Pyarrow and parquet files, but have experience with Python.\n\nI'm working on a codebase that processes daily data. We have a Pyarrow Table with 3 columns, one of which is a date. The data goes back to 2007, so ~ 5800 unique dates. The table has 43 million rows, so avg of ~7500 rows per date. The output should be a parquet dataset, partitioned by the date column. So you have an folder with ~5800 folders, named by date. Each folder should contain a single parquet file.\n\nThe repo switches between pandas dataframes and pyarrow tables frequently, mostly pandas for data transformation and pyarrow for parquet reading and writing. The internal processing can be updated, but to work with our other processes, the output needs to remain as daily parquet files.\n\nThis has worked for a long time until we tried updating the Pandas and Pyarrow version, for performance improvements. We went Pandas 1.2 -&gt; 2.0, and Pyarrow 2 -&gt; 12. The original code, that worked:\n\n    pq.write_to_dataset(table, root_path=str(output_filepath),\n                        partition_cols=['action_date'],\n                        allow_truncated_timestamps=True)\n\nNow, with updated pandas and pyarrow on that code, I get the error:\n    pandas_to_parquet Fragment would be written into 4141 partitions. This exceeds the maximum of 1024\n\nI researched and found that pyarrow's behavior changed after version 4.0. It defaults to 1024, and must be set higher. Since I know there's 5800 partitions needed, growing every day, I set it to 7000.\n\n    pq.write_to_dataset(table, root_path=str(output_filepath),\n                        partition_cols=['action_date'],\n                        allow_truncated_timestamps=True,\n                        use_legacy_dataset=False,\n                        max_partitions=7000)\n\nThis took significantly longer to run, many times over. The output folders were correct, but inside each was many parquet files, each only about 2kb. Previously there would be a single parquet, around 20 to 80kb.\n\nI'm trying to figure out how to ensure a single parquet file per daily folder, and have similar or better performance to the previous version with older pandas and pyarrow. The original in memory table I'm trying to write to a parquet dataset is about 280mb. This runs on a larger EC2 instance, AWS Linux.\n\n\n\nTLDR: I updated Pyarrow from 2.0 to 12, and am trying to make the write_to_dataset method function as before, with at least comparable performance. \n\nThank you for any insight or help here, it's very much appreciated!", "author_fullname": "t2_xod94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with Pyarrow behavior - .write_to_dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157mlmc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690137738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m fairly new to Pyarrow and parquet files, but have experience with Python.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a codebase that processes daily data. We have a Pyarrow Table with 3 columns, one of which is a date. The data goes back to 2007, so ~ 5800 unique dates. The table has 43 million rows, so avg of ~7500 rows per date. The output should be a parquet dataset, partitioned by the date column. So you have an folder with ~5800 folders, named by date. Each folder should contain a single parquet file.&lt;/p&gt;\n\n&lt;p&gt;The repo switches between pandas dataframes and pyarrow tables frequently, mostly pandas for data transformation and pyarrow for parquet reading and writing. The internal processing can be updated, but to work with our other processes, the output needs to remain as daily parquet files.&lt;/p&gt;\n\n&lt;p&gt;This has worked for a long time until we tried updating the Pandas and Pyarrow version, for performance improvements. We went Pandas 1.2 -&amp;gt; 2.0, and Pyarrow 2 -&amp;gt; 12. The original code, that worked:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pq.write_to_dataset(table, root_path=str(output_filepath),\n                    partition_cols=[&amp;#39;action_date&amp;#39;],\n                    allow_truncated_timestamps=True)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Now, with updated pandas and pyarrow on that code, I get the error:\n    pandas_to_parquet Fragment would be written into 4141 partitions. This exceeds the maximum of 1024&lt;/p&gt;\n\n&lt;p&gt;I researched and found that pyarrow&amp;#39;s behavior changed after version 4.0. It defaults to 1024, and must be set higher. Since I know there&amp;#39;s 5800 partitions needed, growing every day, I set it to 7000.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pq.write_to_dataset(table, root_path=str(output_filepath),\n                    partition_cols=[&amp;#39;action_date&amp;#39;],\n                    allow_truncated_timestamps=True,\n                    use_legacy_dataset=False,\n                    max_partitions=7000)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This took significantly longer to run, many times over. The output folders were correct, but inside each was many parquet files, each only about 2kb. Previously there would be a single parquet, around 20 to 80kb.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out how to ensure a single parquet file per daily folder, and have similar or better performance to the previous version with older pandas and pyarrow. The original in memory table I&amp;#39;m trying to write to a parquet dataset is about 280mb. This runs on a larger EC2 instance, AWS Linux.&lt;/p&gt;\n\n&lt;p&gt;TLDR: I updated Pyarrow from 2.0 to 12, and am trying to make the write_to_dataset method function as before, with at least comparable performance. &lt;/p&gt;\n\n&lt;p&gt;Thank you for any insight or help here, it&amp;#39;s very much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157mlmc", "is_robot_indexable": true, "report_reasons": null, "author": "bigfishindoggytown", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157mlmc/help_with_pyarrow_behavior_write_to_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157mlmc/help_with_pyarrow_behavior_write_to_dataset/", "subreddit_subscribers": 117698, "created_utc": 1690137738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have airflow on WSL but are otherwise a Windows shop. What sorts of activities would be good practice for improving my command line knowledge? Or what sorts of command line activities are most useful/common for data engineering?\n\nI am very much a learn by doing kind of person. I have to seek out ways to transform whatever I am working on to incorporate what I  am interested in learning, even if it isn't necessary. So identifying what I should be thinking to try in command line will go a long way. Thanks!", "author_fullname": "t2_f1q7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Improving at Command line", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ke6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690132544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have airflow on WSL but are otherwise a Windows shop. What sorts of activities would be good practice for improving my command line knowledge? Or what sorts of command line activities are most useful/common for data engineering?&lt;/p&gt;\n\n&lt;p&gt;I am very much a learn by doing kind of person. I have to seek out ways to transform whatever I am working on to incorporate what I  am interested in learning, even if it isn&amp;#39;t necessary. So identifying what I should be thinking to try in command line will go a long way. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157ke6v", "is_robot_indexable": true, "report_reasons": null, "author": "machinegunke11y", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157ke6v/improving_at_command_line/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157ke6v/improving_at_command_line/", "subreddit_subscribers": 117698, "created_utc": 1690132544.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}