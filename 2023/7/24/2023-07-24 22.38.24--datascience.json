{"kind": "Listing", "data": {"after": "t3_158lssq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, \n\n&amp;#x200B;\n\nNext Monday, I start a new a career in data science. \n\nIm moving from academia in science/engineering (PhD 2020, Postdoct 2020-2023) and have been preparing for a move into data science for the past year and a half (taking online courses/workshops in SQL, machine learning, ETL, etc... ) \n\n&amp;#x200B;\n\nA bit nervous for the change. I have used data science principles throughout my academic career, but moving into a 100% data science job is a big step. Any advice from people who made the move from academia (science/engineering) into data science?", "author_fullname": "t2_bemft", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Start My first Data Science Job Next Week...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_158b0bg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690206005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Next Monday, I start a new a career in data science. &lt;/p&gt;\n\n&lt;p&gt;Im moving from academia in science/engineering (PhD 2020, Postdoct 2020-2023) and have been preparing for a move into data science for the past year and a half (taking online courses/workshops in SQL, machine learning, ETL, etc... ) &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;A bit nervous for the change. I have used data science principles throughout my academic career, but moving into a 100% data science job is a big step. Any advice from people who made the move from academia (science/engineering) into data science?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158b0bg", "is_robot_indexable": true, "report_reasons": null, "author": "lipring69", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158b0bg/start_my_first_data_science_job_next_week/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/158b0bg/start_my_first_data_science_job_next_week/", "subreddit_subscribers": 959997, "created_utc": 1690206005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you do AI/ML stuff often? Deep learning with Neural Networks?\n\nOr do you just make charts with SQL queries? Excel and .csv files?\n\nOr something in between?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What extent is your job \"Advanced Data Science\" vs \"low-level Data Science\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157sidi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690151635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you do AI/ML stuff often? Deep learning with Neural Networks?&lt;/p&gt;\n\n&lt;p&gt;Or do you just make charts with SQL queries? Excel and .csv files?&lt;/p&gt;\n\n&lt;p&gt;Or something in between?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157sidi", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157sidi/what_extent_is_your_job_advanced_data_science_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157sidi/what_extent_is_your_job_advanced_data_science_vs/", "subreddit_subscribers": 959997, "created_utc": 1690151635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I am currently using python and tableau separately. Most of the ETLs, data wrangling are done in python and some aggregations. Though I also use LODs in tableau and, of course, the viz.\n\nI just learned about this tabpy but I can't see why would you use it. Any tabpy users here? Hope you can give me some tabpy use cases or what is it's best use.", "author_fullname": "t2_ftzx68gnj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would you use tabpy? or why not?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1583q4u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690184715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently using python and tableau separately. Most of the ETLs, data wrangling are done in python and some aggregations. Though I also use LODs in tableau and, of course, the viz.&lt;/p&gt;\n\n&lt;p&gt;I just learned about this tabpy but I can&amp;#39;t see why would you use it. Any tabpy users here? Hope you can give me some tabpy use cases or what is it&amp;#39;s best use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1583q4u", "is_robot_indexable": true, "report_reasons": null, "author": "medyosuper", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1583q4u/why_would_you_use_tabpy_or_why_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1583q4u/why_would_you_use_tabpy_or_why_not/", "subreddit_subscribers": 959997, "created_utc": 1690184715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm not a Data Scientist but I'm currently writing my master's thesis on the current state of the Data Science market.\n\nI've noticed that the market seems saturated compared with previous years, and yet it seems to me that the current challenges still require a lot of Data Scientists - GenAI and NLP challenges, for example.\n\n* What do you think are the reasons for this?\n* How is the profession becoming hyper-specialised (arrival of MLOps, vision specialists, etc.)?\n* With the arrival of 'packaged', low-code solutions from big tech, which could be suitable for 80% of projects, do you think 'home-made' DS solutions have a future? Is there a paradox here with the hyperspecialisation mentioned above?\n* What are the current strategic issues surrounding Data Science that your company is facing?\n* As a Data Scientist, how do you see your job evolving over the next few years?\n\nI look forward to reading your answers!\n\nThanks for your time!", "author_fullname": "t2_adwuq6omo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current state of the Data Science market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1584ht7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690189044.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690187272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not a Data Scientist but I&amp;#39;m currently writing my master&amp;#39;s thesis on the current state of the Data Science market.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve noticed that the market seems saturated compared with previous years, and yet it seems to me that the current challenges still require a lot of Data Scientists - GenAI and NLP challenges, for example.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What do you think are the reasons for this?&lt;/li&gt;\n&lt;li&gt;How is the profession becoming hyper-specialised (arrival of MLOps, vision specialists, etc.)?&lt;/li&gt;\n&lt;li&gt;With the arrival of &amp;#39;packaged&amp;#39;, low-code solutions from big tech, which could be suitable for 80% of projects, do you think &amp;#39;home-made&amp;#39; DS solutions have a future? Is there a paradox here with the hyperspecialisation mentioned above?&lt;/li&gt;\n&lt;li&gt;What are the current strategic issues surrounding Data Science that your company is facing?&lt;/li&gt;\n&lt;li&gt;As a Data Scientist, how do you see your job evolving over the next few years?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I look forward to reading your answers!&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1584ht7", "is_robot_indexable": true, "report_reasons": null, "author": "Pole_l", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1584ht7/current_state_of_the_data_science_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1584ht7/current_state_of_the_data_science_market/", "subreddit_subscribers": 959997, "created_utc": 1690187272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When we have such a simple neural network, where we have all neurons of the hidden layer, receiving exactly the same input and the same number of inputs (nth features), from the previous layer. Will it be right to say that the only reason of using multiple neurons in the hidden layer is to initialize random weights and/or biases to all neurons, just so we avoid getting trapped into some local minima? Or are there other reasons of using multiple neurons?  I do understand that there could be several reasons to use multiple neurons, but my question is specifically for the neural network shown in image above. \n\nhttps://preview.redd.it/xr0pn64dpxdb1.png?width=804&amp;format=png&amp;auto=webp&amp;s=6d19a3f6f2c9c82ef92ffcaa66a6ff6c04467202", "author_fullname": "t2_hcgjj0xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do we use multiple neurons in hidden layer for a simple ANN?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 51, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xr0pn64dpxdb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/xr0pn64dpxdb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6d13cc751a1ff208c596a5b318f49ba504211c25"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/xr0pn64dpxdb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=55e4065fe89ee0914b0c077b069a0ef89e46562e"}, {"y": 116, "x": 320, "u": "https://preview.redd.it/xr0pn64dpxdb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1e99f4bdfe1a546bcfd980ccd8ccb60e79fbf78"}, {"y": 233, "x": 640, "u": "https://preview.redd.it/xr0pn64dpxdb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4dc53a7201c4ae74e14671fcb32f1f0286670d55"}], "s": {"y": 293, "x": 804, "u": "https://preview.redd.it/xr0pn64dpxdb1.png?width=804&amp;format=png&amp;auto=webp&amp;s=6d19a3f6f2c9c82ef92ffcaa66a6ff6c04467202"}, "id": "xr0pn64dpxdb1"}}, "name": "t3_158ef4u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZNyUSSr6oghZFHtyhqh-NBhePYSndnXjp-kq6WzUFmA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690213796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When we have such a simple neural network, where we have all neurons of the hidden layer, receiving exactly the same input and the same number of inputs (nth features), from the previous layer. Will it be right to say that the only reason of using multiple neurons in the hidden layer is to initialize random weights and/or biases to all neurons, just so we avoid getting trapped into some local minima? Or are there other reasons of using multiple neurons?  I do understand that there could be several reasons to use multiple neurons, but my question is specifically for the neural network shown in image above. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xr0pn64dpxdb1.png?width=804&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6d19a3f6f2c9c82ef92ffcaa66a6ff6c04467202\"&gt;https://preview.redd.it/xr0pn64dpxdb1.png?width=804&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6d19a3f6f2c9c82ef92ffcaa66a6ff6c04467202&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158ef4u", "is_robot_indexable": true, "report_reasons": null, "author": "Total-Opposite-8396", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158ef4u/why_do_we_use_multiple_neurons_in_hidden_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/158ef4u/why_do_we_use_multiple_neurons_in_hidden_layer/", "subreddit_subscribers": 959997, "created_utc": 1690213796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello r/datascience,\n\nI work at [Meilisearch](https://github.com/meilisearch/meilisearch), an open-source search engine built in Rust. \ud83e\udd80\n\nWe're exploring semantic search &amp; are [launching vector search](https://blog.meilisearch.com/vector-search-announcement/). It works like this:\n\n* Generate embeddings using third-party (like OpenAI or Hugging Face)\n* Store your vector embeddings alongside documents in Meilisearch\n* Query the database to retrieve your results\n\nWe've built a documentation chatbot prototype and seen users implementing vector search to offer \"similar videos\" recommendations.\n\nLet me know what you think!\n\nThanks for reading,", "author_fullname": "t2_hq7t9ih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open-source search engine Meilisearch launches vector search", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1589lpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690202546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I work at &lt;a href=\"https://github.com/meilisearch/meilisearch\"&gt;Meilisearch&lt;/a&gt;, an open-source search engine built in Rust. \ud83e\udd80&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re exploring semantic search &amp;amp; are &lt;a href=\"https://blog.meilisearch.com/vector-search-announcement/\"&gt;launching vector search&lt;/a&gt;. It works like this:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Generate embeddings using third-party (like OpenAI or Hugging Face)&lt;/li&gt;\n&lt;li&gt;Store your vector embeddings alongside documents in Meilisearch&lt;/li&gt;\n&lt;li&gt;Query the database to retrieve your results&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We&amp;#39;ve built a documentation chatbot prototype and seen users implementing vector search to offer &amp;quot;similar videos&amp;quot; recommendations.&lt;/p&gt;\n\n&lt;p&gt;Let me know what you think!&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e2iItn7IS03UYmRAly73xdLq38XHkqm3KvA50uVh8Rc.jpg?auto=webp&amp;s=54f4b4ba145aae5ee6dc3085a1a2689aec545aa6", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/e2iItn7IS03UYmRAly73xdLq38XHkqm3KvA50uVh8Rc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c7521f5ea1a9167e0b8692b2964050822b1cd104", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/e2iItn7IS03UYmRAly73xdLq38XHkqm3KvA50uVh8Rc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f5a35d0d37f2a6bd60744cf1b69f5133e3564945", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/e2iItn7IS03UYmRAly73xdLq38XHkqm3KvA50uVh8Rc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=842ee95bc98654a59c1262789a3753ca4e7a056d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/e2iItn7IS03UYmRAly73xdLq38XHkqm3KvA50uVh8Rc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc368af3d445e6a3f36328d6d77affa8bd1bf6e7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/e2iItn7IS03UYmRAly73xdLq38XHkqm3KvA50uVh8Rc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6750c0c7fad8543dcda52cee9160557b5c9e979a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/e2iItn7IS03UYmRAly73xdLq38XHkqm3KvA50uVh8Rc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0bf15908226187fe44ef050af47922af26c3d3da", "width": 1080, "height": 540}], "variants": {}, "id": "TaZMAKevp1jnSx7H7fyYrBp01M2lK7YyAD8QLf5YNfM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1589lpv", "is_robot_indexable": true, "report_reasons": null, "author": "ggStrift", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1589lpv/opensource_search_engine_meilisearch_launches/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1589lpv/opensource_search_engine_meilisearch_launches/", "subreddit_subscribers": 959997, "created_utc": 1690202546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, just need your ideas on how to approach this. So i have this dataset to the left with numerical and categorical variables. Can I just do a one-hot encoding for the categorical and normally proceed to the usual time-series modeling using the transformed dataset to the right? Thanks!\n\nhttps://preview.redd.it/8zysqjfgktdb1.png?width=1675&amp;format=png&amp;auto=webp&amp;s=f402b245ce8622993c5422b1e0f4c9b037adea8e", "author_fullname": "t2_sh45a0v7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time-series modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 18, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8zysqjfgktdb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 14, "x": 108, "u": "https://preview.redd.it/8zysqjfgktdb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b8ec25c1d8c5260b32044a8d1d2c7965452fe93f"}, {"y": 28, "x": 216, "u": "https://preview.redd.it/8zysqjfgktdb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=76da074f6a345718dce8f97a31f4582c3d199887"}, {"y": 41, "x": 320, "u": "https://preview.redd.it/8zysqjfgktdb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=19758c3989b169e5457115c77d1a35303eccddd5"}, {"y": 83, "x": 640, "u": "https://preview.redd.it/8zysqjfgktdb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=71d4208e9d6ac68817068452826eae25f0e622b5"}, {"y": 124, "x": 960, "u": "https://preview.redd.it/8zysqjfgktdb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc332fcf9f0bcd5c4aa6171426006a331459333b"}, {"y": 140, "x": 1080, "u": "https://preview.redd.it/8zysqjfgktdb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4bbe1bd5d0b90c30f042e4ddb18db52bc22f94ad"}], "s": {"y": 218, "x": 1675, "u": "https://preview.redd.it/8zysqjfgktdb1.png?width=1675&amp;format=png&amp;auto=webp&amp;s=f402b245ce8622993c5422b1e0f4c9b037adea8e"}, "id": "8zysqjfgktdb1"}}, "name": "t3_157wzje", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/wISw3YFzaRxhr815zlGCWlQvuLttFnCJ37dol4wQXV8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690163751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, just need your ideas on how to approach this. So i have this dataset to the left with numerical and categorical variables. Can I just do a one-hot encoding for the categorical and normally proceed to the usual time-series modeling using the transformed dataset to the right? Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8zysqjfgktdb1.png?width=1675&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f402b245ce8622993c5422b1e0f4c9b037adea8e\"&gt;https://preview.redd.it/8zysqjfgktdb1.png?width=1675&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f402b245ce8622993c5422b1e0f4c9b037adea8e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157wzje", "is_robot_indexable": true, "report_reasons": null, "author": "chime_enjoyer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157wzje/timeseries_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157wzje/timeseries_modeling/", "subreddit_subscribers": 959997, "created_utc": 1690163751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a large dataset (3000 features are used here), and I am calculating mutual information scores between each row and every other row. Then, I print out the top X mutual information scores (and which two rows correspond to that mutual information score).\n\nWhen I print these values in Google Collab, however, the top scores seem to give different values vs. Jupyter Notebook, even though I am using the same code.\n\nWhat's also interesting is that these values remain the exact same if they are re-run (in both Collab and Jupyter), so I don't believe it's random.\n\nI will show the first 10 printed lines to demonstrate the difference:\n\nJupyter Notebook\n\n&gt;\\#1: 1397 and 1427: 1.202717856027216  \n&gt;  \n&gt;\\#2: 1400 and 1431: 1.074839333797198  \n&gt;  \n&gt;\\#3: 239 and 423: 1.068564020019758  \n&gt;  \n&gt;\\#4: 1146 and 1400: 1.06539274118781  \n&gt;  \n&gt;\\#5: 1146 and 1177: 1.0448225876789148  \n&gt;  \n&gt;\\#6: 1146 and 1431: 1.0431195289315978  \n&gt;  \n&gt;\\#7: 1411 and 1431: 1.0103705901911808  \n&gt;  \n&gt;\\#8: 1111 and 1525: 1.0037660750701747  \n&gt;  \n&gt;\\#9: 1177 and 1431: 0.9890857137951587  \n&gt;  \n&gt;\\#10: 1146 and 1411: 0.9852993714583413\n\nGoogle Collab\n\n&gt;\\#1: 1146 and 1400: 1.1822506247498457  \n&gt;  \n&gt;\\#2: 239 and 423: 1.0994706698596624  \n&gt;  \n&gt;\\#3: 1397 and 1427: 1.0838558257556066  \n&gt;  \n&gt;\\#4: 1146 and 1177: 1.0766228782259293  \n&gt;  \n&gt;\\#5: 423 and 73: 1.0258894687690598  \n&gt;  \n&gt;\\#6: 1177 and 1411: 1.021696037520684  \n&gt;  \n&gt;\\#7: 1400 and 1431: 1.0134240574963582  \n&gt;  \n&gt;\\#8: 1111 and 1525: 1.0071214141815927  \n&gt;  \n&gt;\\#9: 1146 and 1431: 0.972276347390304  \n&gt;  \n&gt;\\#10: 1146 and 1411: 0.9689222844930194\n\n**Here is the relevant code**\n\nFirst cell:\n\n&amp;#x200B;\n\n    # Note: The following is after inputting the Excel spreadsheet data into dataframe then transposing\n    df = df.T\n    \n    import pandas as pd\n    from sklearn.feature_selection import mutual_info_regression\n\n    # Load the dataset\n    #data = pd.read_excel(\"analysis_file2.xlsx\")\n\n    # Select the first 3,000 feature columns\n    features = df.columns[1:3001]\n\n    # Compute the mutual information between each pair of features\n    mi_matrix = np.zeros((len(features), len(features)))\n    for i in range(len(features)):\n        for j in range(i+1, len(features)):\n            feature_A = df[features[i]].values\n            feature_B = df[features[j]].values\n            mi = mutual_info_regression(feature_A.reshape(-1, 1), feature_B)[0]\n            mi_matrix[i, j] = mi\n            mi_matrix[j, i] = mi\n\n\nSecond cell:\n\n    # Find the top 30 mutual information values\n\n    num = 30 * 2\n\n    top = np.argsort(mi_matrix, axis=None)[-num:]\n\n    sorted_pairs = sorted(zip(top, mi_matrix[np.unravel_index(top, mi_matrix.shape)]), key=lambda x: x[1],     reverse=True)\n\n    # Sorted values and indeces\n    sorted_indices = [pair[0] for pair in sorted_pairs]\n    sorted_values = [pair[1] for pair in sorted_pairs]\n\n    top = np.unique(top)\n    top = np.unravel_index(top, mi_matrix.shape)\n\n    # Print top values Sorted (greatest to least)\n\n    feature1 = [None] * num\n    feature2 = [None] * num\n    mi_value = [None] * num\n    for i in range(num):\n        idx1, idx2 = top[0][i], top[1][i]\n        feature1[i] = features[idx1]\n        feature2[i] = features[idx2]\n        mi_value[i] = mi_matrix[idx1, idx2]\n\n    ind = 0\n    i = 0\n    while (ind != num):\n        if (mi_value[i] == sorted_values[ind]):\n          ind += 2\n          print(f\"#{int(ind/2)}: {feature1[i]} and {feature2[i]}: {mi_value[i]}\")\n          i = 0\n        xi += 1", "author_fullname": "t2_efotpocwb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about getting different results in Google Collab than Jupyter Notebook when calculating mutual information scores.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ubmj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690156320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large dataset (3000 features are used here), and I am calculating mutual information scores between each row and every other row. Then, I print out the top X mutual information scores (and which two rows correspond to that mutual information score).&lt;/p&gt;\n\n&lt;p&gt;When I print these values in Google Collab, however, the top scores seem to give different values vs. Jupyter Notebook, even though I am using the same code.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s also interesting is that these values remain the exact same if they are re-run (in both Collab and Jupyter), so I don&amp;#39;t believe it&amp;#39;s random.&lt;/p&gt;\n\n&lt;p&gt;I will show the first 10 printed lines to demonstrate the difference:&lt;/p&gt;\n\n&lt;p&gt;Jupyter Notebook&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;#1: 1397 and 1427: 1.202717856027216  &lt;/p&gt;\n\n&lt;p&gt;#2: 1400 and 1431: 1.074839333797198  &lt;/p&gt;\n\n&lt;p&gt;#3: 239 and 423: 1.068564020019758  &lt;/p&gt;\n\n&lt;p&gt;#4: 1146 and 1400: 1.06539274118781  &lt;/p&gt;\n\n&lt;p&gt;#5: 1146 and 1177: 1.0448225876789148  &lt;/p&gt;\n\n&lt;p&gt;#6: 1146 and 1431: 1.0431195289315978  &lt;/p&gt;\n\n&lt;p&gt;#7: 1411 and 1431: 1.0103705901911808  &lt;/p&gt;\n\n&lt;p&gt;#8: 1111 and 1525: 1.0037660750701747  &lt;/p&gt;\n\n&lt;p&gt;#9: 1177 and 1431: 0.9890857137951587  &lt;/p&gt;\n\n&lt;p&gt;#10: 1146 and 1411: 0.9852993714583413&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Google Collab&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;#1: 1146 and 1400: 1.1822506247498457  &lt;/p&gt;\n\n&lt;p&gt;#2: 239 and 423: 1.0994706698596624  &lt;/p&gt;\n\n&lt;p&gt;#3: 1397 and 1427: 1.0838558257556066  &lt;/p&gt;\n\n&lt;p&gt;#4: 1146 and 1177: 1.0766228782259293  &lt;/p&gt;\n\n&lt;p&gt;#5: 423 and 73: 1.0258894687690598  &lt;/p&gt;\n\n&lt;p&gt;#6: 1177 and 1411: 1.021696037520684  &lt;/p&gt;\n\n&lt;p&gt;#7: 1400 and 1431: 1.0134240574963582  &lt;/p&gt;\n\n&lt;p&gt;#8: 1111 and 1525: 1.0071214141815927  &lt;/p&gt;\n\n&lt;p&gt;#9: 1146 and 1431: 0.972276347390304  &lt;/p&gt;\n\n&lt;p&gt;#10: 1146 and 1411: 0.9689222844930194&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;Here is the relevant code&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;First cell:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# Note: The following is after inputting the Excel spreadsheet data into dataframe then transposing\ndf = df.T\n\nimport pandas as pd\nfrom sklearn.feature_selection import mutual_info_regression\n\n# Load the dataset\n#data = pd.read_excel(&amp;quot;analysis_file2.xlsx&amp;quot;)\n\n# Select the first 3,000 feature columns\nfeatures = df.columns[1:3001]\n\n# Compute the mutual information between each pair of features\nmi_matrix = np.zeros((len(features), len(features)))\nfor i in range(len(features)):\n    for j in range(i+1, len(features)):\n        feature_A = df[features[i]].values\n        feature_B = df[features[j]].values\n        mi = mutual_info_regression(feature_A.reshape(-1, 1), feature_B)[0]\n        mi_matrix[i, j] = mi\n        mi_matrix[j, i] = mi\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Second cell:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# Find the top 30 mutual information values\n\nnum = 30 * 2\n\ntop = np.argsort(mi_matrix, axis=None)[-num:]\n\nsorted_pairs = sorted(zip(top, mi_matrix[np.unravel_index(top, mi_matrix.shape)]), key=lambda x: x[1],     reverse=True)\n\n# Sorted values and indeces\nsorted_indices = [pair[0] for pair in sorted_pairs]\nsorted_values = [pair[1] for pair in sorted_pairs]\n\ntop = np.unique(top)\ntop = np.unravel_index(top, mi_matrix.shape)\n\n# Print top values Sorted (greatest to least)\n\nfeature1 = [None] * num\nfeature2 = [None] * num\nmi_value = [None] * num\nfor i in range(num):\n    idx1, idx2 = top[0][i], top[1][i]\n    feature1[i] = features[idx1]\n    feature2[i] = features[idx2]\n    mi_value[i] = mi_matrix[idx1, idx2]\n\nind = 0\ni = 0\nwhile (ind != num):\n    if (mi_value[i] == sorted_values[ind]):\n      ind += 2\n      print(f&amp;quot;#{int(ind/2)}: {feature1[i]} and {feature2[i]}: {mi_value[i]}&amp;quot;)\n      i = 0\n    xi += 1\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157ubmj", "is_robot_indexable": true, "report_reasons": null, "author": "MLquestionAccount", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157ubmj/question_about_getting_different_results_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157ubmj/question_about_getting_different_results_in/", "subreddit_subscribers": 959997, "created_utc": 1690156320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is what I am currently stuck with. With more than a hundred sales places and, with so little data on some less successful SKU in less successful spots, like one per a few month. Or newer SKU having less than a month of data.\n\nWhat I am currently doing is \"best guessing\" using excel spreadsheet(i know, i know), and finding analogues in attempt to even remotely forecast fresh SKU, taking sales per spot, per day, per SKU, and filling blanks with the same data of tge same days of another week. Then summarizing it and applying reasonable multipliers.\n\nIs there a better way? It's a lot to do with so many products for so many places, even with careful pivoting.", "author_fullname": "t2_2ndz0you", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecasting on SKU-level bu points of sale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15814hq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690176111.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is what I am currently stuck with. With more than a hundred sales places and, with so little data on some less successful SKU in less successful spots, like one per a few month. Or newer SKU having less than a month of data.&lt;/p&gt;\n\n&lt;p&gt;What I am currently doing is &amp;quot;best guessing&amp;quot; using excel spreadsheet(i know, i know), and finding analogues in attempt to even remotely forecast fresh SKU, taking sales per spot, per day, per SKU, and filling blanks with the same data of tge same days of another week. Then summarizing it and applying reasonable multipliers.&lt;/p&gt;\n\n&lt;p&gt;Is there a better way? It&amp;#39;s a lot to do with so many products for so many places, even with careful pivoting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15814hq", "is_robot_indexable": true, "report_reasons": null, "author": "WlrsWrwgn", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15814hq/forecasting_on_skulevel_bu_points_of_sale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15814hq/forecasting_on_skulevel_bu_points_of_sale/", "subreddit_subscribers": 959997, "created_utc": 1690176111.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been working in DS for almost a decade and am feeling burnt out. I\u2019m contemplating a career change but am feeling lost at what options are available to me. These skills are so specific that I\u2019m not sure if I have any transferable skills.\n\nDo you know anyone who left data, and what career did they move to? I\u2019m just brainstorming at this point. I can absorb a pay cut but don\u2019t want to start completely at zero\u2026", "author_fullname": "t2_3hifbxak", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for Leaving Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_158gxk3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690219304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been working in DS for almost a decade and am feeling burnt out. I\u2019m contemplating a career change but am feeling lost at what options are available to me. These skills are so specific that I\u2019m not sure if I have any transferable skills.&lt;/p&gt;\n\n&lt;p&gt;Do you know anyone who left data, and what career did they move to? I\u2019m just brainstorming at this point. I can absorb a pay cut but don\u2019t want to start completely at zero\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158gxk3", "is_robot_indexable": true, "report_reasons": null, "author": "Bored_at_Work27", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158gxk3/advice_for_leaving_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/158gxk3/advice_for_leaving_data_science/", "subreddit_subscribers": 959997, "created_utc": 1690219304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "According to most career advice it would be good to have some projects in the portfolio to tick the skill boxes when applying.\n\nHowever, Github can get crowded fast. Thus, posting a link to GitHub won\u2018t help much. Ain\u2018t no one got tile to browse all projects just to find the one where you used a lot of SQL or XGBoost.\n\nThe goal would be to give a sentence like \u201eSkills in SQL\u201c and directly link somehow the corresponding repositories. This will maximise the number of checked checkboxes when applying I guess.\n\nDo you have an idea how to achieve this in a decent (beautiful, simple, well structured) way?", "author_fullname": "t2_e9pqzw56", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1583uu6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690185125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;According to most career advice it would be good to have some projects in the portfolio to tick the skill boxes when applying.&lt;/p&gt;\n\n&lt;p&gt;However, Github can get crowded fast. Thus, posting a link to GitHub won\u2018t help much. Ain\u2018t no one got tile to browse all projects just to find the one where you used a lot of SQL or XGBoost.&lt;/p&gt;\n\n&lt;p&gt;The goal would be to give a sentence like \u201eSkills in SQL\u201c and directly link somehow the corresponding repositories. This will maximise the number of checked checkboxes when applying I guess.&lt;/p&gt;\n\n&lt;p&gt;Do you have an idea how to achieve this in a decent (beautiful, simple, well structured) way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1583uu6", "is_robot_indexable": true, "report_reasons": null, "author": "1DimensionIsViolence", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1583uu6/project_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1583uu6/project_portfolio/", "subreddit_subscribers": 959997, "created_utc": 1690185125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Under Data Generalist they have - \n\nData Analysts ([https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Analyst.pdf](https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Analyst.pdf))\n\nData Engineers ([https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Engineer.pdf](https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Engineer.pdf)) \n\nData Managers ([https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Manager.pdf](https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Manager.pdf)) \n\nGeospatial Analysts ([https://www.apsc.gov.au/sites/default/files/2022-12/Geospatial%20Analyst.pdf](https://www.apsc.gov.au/sites/default/files/2022-12/Geospatial%20Analyst.pdf)) \n\n&amp;#x200B;\n\nUnder Data Specialist they have - \n\nData Scientists ([https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Scientist.pdf](https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Scientist.pdf)) \n\nStatistical Methodologists ([https://www.apsc.gov.au/sites/default/files/2022-12/Statistician.pdf](https://www.apsc.gov.au/sites/default/files/2022-12/Statistician.pdf)) \n\n&amp;#x200B;\n\nAll this can be found here [https://www.apsjobs.gov.au/s/graduate-portal/stream/data-stream-MCLCEFMBKO5ZH4TCQQTNQTBMUB4A](https://www.apsjobs.gov.au/s/graduate-portal/stream/data-stream-MCLCEFMBKO5ZH4TCQQTNQTBMUB4A) \n\n&amp;#x200B;\n\nInsightful? Misleading? A bit of both? \n\nInterested in what you people think. ", "author_fullname": "t2_lrr4olcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This is how the Australian Government classifies each data science related job for their graduate program.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1588lx6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690199890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Under Data Generalist they have - &lt;/p&gt;\n\n&lt;p&gt;Data Analysts (&lt;a href=\"https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Analyst.pdf\"&gt;https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Analyst.pdf&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Data Engineers (&lt;a href=\"https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Engineer.pdf\"&gt;https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Engineer.pdf&lt;/a&gt;) &lt;/p&gt;\n\n&lt;p&gt;Data Managers (&lt;a href=\"https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Manager.pdf\"&gt;https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Manager.pdf&lt;/a&gt;) &lt;/p&gt;\n\n&lt;p&gt;Geospatial Analysts (&lt;a href=\"https://www.apsc.gov.au/sites/default/files/2022-12/Geospatial%20Analyst.pdf\"&gt;https://www.apsc.gov.au/sites/default/files/2022-12/Geospatial%20Analyst.pdf&lt;/a&gt;) &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Under Data Specialist they have - &lt;/p&gt;\n\n&lt;p&gt;Data Scientists (&lt;a href=\"https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Scientist.pdf\"&gt;https://www.apsc.gov.au/sites/default/files/2022-12/Data%20Scientist.pdf&lt;/a&gt;) &lt;/p&gt;\n\n&lt;p&gt;Statistical Methodologists (&lt;a href=\"https://www.apsc.gov.au/sites/default/files/2022-12/Statistician.pdf\"&gt;https://www.apsc.gov.au/sites/default/files/2022-12/Statistician.pdf&lt;/a&gt;) &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;All this can be found here &lt;a href=\"https://www.apsjobs.gov.au/s/graduate-portal/stream/data-stream-MCLCEFMBKO5ZH4TCQQTNQTBMUB4A\"&gt;https://www.apsjobs.gov.au/s/graduate-portal/stream/data-stream-MCLCEFMBKO5ZH4TCQQTNQTBMUB4A&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Insightful? Misleading? A bit of both? &lt;/p&gt;\n\n&lt;p&gt;Interested in what you people think. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1588lx6", "is_robot_indexable": true, "report_reasons": null, "author": "Crazy_Cucumber_3888", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1588lx6/this_is_how_the_australian_government_classifies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1588lx6/this_is_how_the_australian_government_classifies/", "subreddit_subscribers": 959997, "created_utc": 1690199890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, \n\nI came up with a certain statistical model that can produce gaussian-like and \"asymmetric-gaussian\" (Maxwell-Boltxmann, chi-squared, etc) type distributions. I want to test it against a large social dataset, in the order of 1e5 and more points per curve. The content (subject, topic) does not matter, it's actually interesting to see how unexpected the use can be. But it must look like a bell-shaped curve, and be freely available. Any tips please?", "author_fullname": "t2_17gpcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help request - need a large social dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1586uhg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690194783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I came up with a certain statistical model that can produce gaussian-like and &amp;quot;asymmetric-gaussian&amp;quot; (Maxwell-Boltxmann, chi-squared, etc) type distributions. I want to test it against a large social dataset, in the order of 1e5 and more points per curve. The content (subject, topic) does not matter, it&amp;#39;s actually interesting to see how unexpected the use can be. But it must look like a bell-shaped curve, and be freely available. Any tips please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1586uhg", "is_robot_indexable": true, "report_reasons": null, "author": "nctrd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1586uhg/help_request_need_a_large_social_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1586uhg/help_request_need_a_large_social_dataset/", "subreddit_subscribers": 959997, "created_utc": 1690194783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I used to be really skilled in doing just about everything in Excel, like, any sort of complex formula, I was easily able to write and solve most issues. For example, doing an average if, countifs, xlookup with multiple conditions... But as I moved more into Python, Tableau, Power BI, advanced SQL stuff like recursive CTEs and crazy complex stuff in other applications, I lost a lot of skill in Excel. Because I wasn't even working in it every single day like I used to be, I used to have '80s spreadsheets a month with tons of crazy formulas. Now, i can pretty much dump anything into a dashboarding program and write a couple of calculated fields that are easily understandable. Quick table calculations in these dashboarding programs is also incredibly easy too....\n\n\nBut earlier this week, I was asked to do some \"old school\" excel work for a client. It was absurdly hard for me. It took me the entire day just to figure out how to use countifs and index match, then to create this very weird and arbitrary lookup table with data validation. It was so strange because this was all stuff that was so easily able to be created in Tableau, yet here I am again, trying to do it in Excel the old-fashioned way with formulas, workarounds, help her columns, it felt like being back in the Stone ages, which is funny, because being so advanced and so skilled in advanced stuff, it was strange that it was so difficult for me.....\n\n\nI mean like seriously, if I could show you my GitHub and the stuff that I've been working on the past month alone, you would think, why would this guy have any trouble in Excel? Just yesterday I was writing an API in Python to connect to redshift and BigQuery, and then pipe a dozen data sets of completely different kinds and complexity into different systems. Little bit of data engineering. Then, doing exploratory data analysis and KNN in R. Like, how did I get to a point where I can do all that, but now, a couple things in Excel are crazy difficult for me? My gosh", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone ever feel like you are losing easier skills as you become more advanced?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_158ltkq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690230010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to be really skilled in doing just about everything in Excel, like, any sort of complex formula, I was easily able to write and solve most issues. For example, doing an average if, countifs, xlookup with multiple conditions... But as I moved more into Python, Tableau, Power BI, advanced SQL stuff like recursive CTEs and crazy complex stuff in other applications, I lost a lot of skill in Excel. Because I wasn&amp;#39;t even working in it every single day like I used to be, I used to have &amp;#39;80s spreadsheets a month with tons of crazy formulas. Now, i can pretty much dump anything into a dashboarding program and write a couple of calculated fields that are easily understandable. Quick table calculations in these dashboarding programs is also incredibly easy too....&lt;/p&gt;\n\n&lt;p&gt;But earlier this week, I was asked to do some &amp;quot;old school&amp;quot; excel work for a client. It was absurdly hard for me. It took me the entire day just to figure out how to use countifs and index match, then to create this very weird and arbitrary lookup table with data validation. It was so strange because this was all stuff that was so easily able to be created in Tableau, yet here I am again, trying to do it in Excel the old-fashioned way with formulas, workarounds, help her columns, it felt like being back in the Stone ages, which is funny, because being so advanced and so skilled in advanced stuff, it was strange that it was so difficult for me.....&lt;/p&gt;\n\n&lt;p&gt;I mean like seriously, if I could show you my GitHub and the stuff that I&amp;#39;ve been working on the past month alone, you would think, why would this guy have any trouble in Excel? Just yesterday I was writing an API in Python to connect to redshift and BigQuery, and then pipe a dozen data sets of completely different kinds and complexity into different systems. Little bit of data engineering. Then, doing exploratory data analysis and KNN in R. Like, how did I get to a point where I can do all that, but now, a couple things in Excel are crazy difficult for me? My gosh&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158ltkq", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158ltkq/anyone_ever_feel_like_you_are_losing_easier/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/158ltkq/anyone_ever_feel_like_you_are_losing_easier/", "subreddit_subscribers": 959997, "created_utc": 1690230010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a problem I'm trying to solve and I'm block so I thought about consulting here, maybe it would help  \nI have a table and one of the features can receive multiple labels , lets say a several numbers. There is no limit to how many labels can be assigned or any limit to the labels value themselves (for clarification, one user can have \\[1,2\\] - 2 labels  and other can have \\[3,22,345,999999999\\] - 4 labels and so on. Also as you can see labels can be from 1 to 999999999 with no limit)\n\nThe trivial solution would be OHE it but even as sparse matrix it can lead to insainely large matrix because there is no limit to have many labels can exist. Target encoding I don't belive to be a solution here and Binary Relevance seems too computationally heavy too. \n\nI'm out of ideas and don't know what could be the possible solution here. Maybe if someone encountered any similar issue or have any insight in general could help?\n\nThanks!", "author_fullname": "t2_3hqmko1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have multi label features I can't OneHotEncode because it will create insainely large dataset, any other solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1585c7p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690190088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a problem I&amp;#39;m trying to solve and I&amp;#39;m block so I thought about consulting here, maybe it would help&lt;br/&gt;\nI have a table and one of the features can receive multiple labels , lets say a several numbers. There is no limit to how many labels can be assigned or any limit to the labels value themselves (for clarification, one user can have [1,2] - 2 labels  and other can have [3,22,345,999999999] - 4 labels and so on. Also as you can see labels can be from 1 to 999999999 with no limit)&lt;/p&gt;\n\n&lt;p&gt;The trivial solution would be OHE it but even as sparse matrix it can lead to insainely large matrix because there is no limit to have many labels can exist. Target encoding I don&amp;#39;t belive to be a solution here and Binary Relevance seems too computationally heavy too. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m out of ideas and don&amp;#39;t know what could be the possible solution here. Maybe if someone encountered any similar issue or have any insight in general could help?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1585c7p", "is_robot_indexable": true, "report_reasons": null, "author": "nuriel8833", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1585c7p/i_have_multi_label_features_i_cant_onehotencode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1585c7p/i_have_multi_label_features_i_cant_onehotencode/", "subreddit_subscribers": 959997, "created_utc": 1690190088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The resources on scheduling optimization for aviation are around 10 years old. I was wondering if anyone had come across any new method to tackle the scheduling problem with new algorithms.", "author_fullname": "t2_bw0f7j43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are genetic algorithms the best we have for scheduling problems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_158o3sg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690234992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The resources on scheduling optimization for aviation are around 10 years old. I was wondering if anyone had come across any new method to tackle the scheduling problem with new algorithms.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158o3sg", "is_robot_indexable": true, "report_reasons": null, "author": "lumpy_rhino", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158o3sg/are_genetic_algorithms_the_best_we_have_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/158o3sg/are_genetic_algorithms_the_best_we_have_for/", "subreddit_subscribers": 959997, "created_utc": 1690234992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have more than 5 year experience for data sciences work. I used to build ETL and abtest for regional leading enterprise. and I am seeking working aboard for better career and need to prepare the interview in English. unfortunately, I do not need to spoke or write English in my past work,   and I worried I could not express my role and experience clearly in English. how to practice and prepare for the interview for a non-native speaker.", "author_fullname": "t2_egz713h9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to prepare a job interview\uff1f", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157z1qi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690169649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have more than 5 year experience for data sciences work. I used to build ETL and abtest for regional leading enterprise. and I am seeking working aboard for better career and need to prepare the interview in English. unfortunately, I do not need to spoke or write English in my past work,   and I worried I could not express my role and experience clearly in English. how to practice and prepare for the interview for a non-native speaker.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "157z1qi", "is_robot_indexable": true, "report_reasons": null, "author": "LunaSolarMilkway", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/157z1qi/how_to_prepare_a_job_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/157z1qi/how_to_prepare_a_job_interview/", "subreddit_subscribers": 959997, "created_utc": 1690169649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Starting tomorrow (Tuesday) and running through Wednesday, it's a totally free, totally virtual, data bonanza! Workshop and mingle with data wizards from Snowflake, Fivetran, Scale, and more. We're smashing down the walls between data and marketing, so we can all achieve more. \ud83d\udcaa\n\n[Register for free](https://www.concensus.live/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=ConCensus&amp;utm_content=nate-c-post), drop-in live, or catch it on your own time. Flexibility is king here. \ud83d\udc51", "author_fullname": "t2_mh2cfxap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got a free slot this week? Check out ConCensus 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_158nrms", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 2, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690234237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Starting tomorrow (Tuesday) and running through Wednesday, it&amp;#39;s a totally free, totally virtual, data bonanza! Workshop and mingle with data wizards from Snowflake, Fivetran, Scale, and more. We&amp;#39;re smashing down the walls between data and marketing, so we can all achieve more. \ud83d\udcaa&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.concensus.live/?utm_source=reddit&amp;amp;utm_medium=social&amp;amp;utm_campaign=ConCensus&amp;amp;utm_content=nate-c-post\"&gt;Register for free&lt;/a&gt;, drop-in live, or catch it on your own time. Flexibility is king here. \ud83d\udc51&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ptctnAItAzZHJMnXJ2I5o5da2u5ILzW6xbAAsPD9BTU.jpg?auto=webp&amp;s=db8dd554dd1c35103e082e3a1293ba5486e088d1", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/ptctnAItAzZHJMnXJ2I5o5da2u5ILzW6xbAAsPD9BTU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3df46ab37a4e87e9016f29460e25c2bb99df0e91", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ptctnAItAzZHJMnXJ2I5o5da2u5ILzW6xbAAsPD9BTU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3ebf6c66886ce3271504c70097b0f1ea98fb8720", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ptctnAItAzZHJMnXJ2I5o5da2u5ILzW6xbAAsPD9BTU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c6bf3328b98aa0f025789d0d32c97a820a8b14d", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ptctnAItAzZHJMnXJ2I5o5da2u5ILzW6xbAAsPD9BTU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=22dd20e998e63b66d3cbc03689f822fb91abaa60", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ptctnAItAzZHJMnXJ2I5o5da2u5ILzW6xbAAsPD9BTU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ba4355d2a97c6dae2433d24c1719729a1e79a3be", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ptctnAItAzZHJMnXJ2I5o5da2u5ILzW6xbAAsPD9BTU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cfdbbc401858780fd5e89b873995f3a7837cafcc", "width": 1080, "height": 567}], "variants": {}, "id": "0NbYplmj0ivS22iWEyjfFF5GO6SfPGXDa50kDzXGvKI"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_77ba55a2-c33c-4351-ac49-807455a80148", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;s=7a2f2b927be72d2b46ebd95bab8c072c3be0fbab", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;s=6e42b7095bcc331e53202438613aa827addf70c3", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;s=c740f7ef642fd2042d62c2bcba98734d08dfae6c", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;s=74e630f1072bb2423034ae48aefa241d834d7186", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;s=0a89cd8011c8210315ee60441eefd77b973a0c82", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Prayers up for the blessed.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 2, "static_icon_height": 2048, "name": "Bless Up", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;s=7a2f2b927be72d2b46ebd95bab8c072c3be0fbab", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;s=6e42b7095bcc331e53202438613aa827addf70c3", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;s=c740f7ef642fd2042d62c2bcba98734d08dfae6c", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;s=74e630f1072bb2423034ae48aefa241d834d7186", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;s=0a89cd8011c8210315ee60441eefd77b973a0c82", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/trfv6ems1md41_BlessUp.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158nrms", "is_robot_indexable": true, "report_reasons": null, "author": "whb2030", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158nrms/got_a_free_slot_this_week_check_out_concensus_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/158nrms/got_a_free_slot_this_week_check_out_concensus_2023/", "subreddit_subscribers": 959997, "created_utc": 1690234237.0, "num_crossposts": 5, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently wondering what my next steps should be in order to have a higher chance of securing a good data analyst / data science job when I graduate next year. I have essentialy 11 months of free time and wonder what the best use of my time will be. I am scared since the job market is tough right now and people a lot more qualified than me are struggling to even find entry level jobs.\r  \n\r  \nBackground:\r  \n\r  \nIn California\r  \n\r  \nGraduated with a Bachelor's in Mathematics from a T30 University\n\nCurrently enrolled in Master's of Informatics program from a well known state school (Will graduate in 11 months)\r  \r  \nCurrently working in a chill job as a Data Coordinator for 2 years: Mainly an inventory management role with small bits of dashboarding via Excel and SAP, so I have a bunch of free time to study.\r  \n\r  \nAny advice would be appreciated whether it be a certifcaiton reccomendation or skillsets to learn/brush up on. I am rusty on Python and SQL since my job doesn't really need to use it that heavily(enough to pull data/ join tables / maniuplate data to build a dashboard)\r  \n\r  \nWhat would my time better be spent doing? I was thinking of taking classes for certification (maybe google analytics or AWS) if they are worth it. Or would my time be better spent trying to learn more Python/SQL. Thanks", "author_fullname": "t2_dd4wg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on things to learn/do before graduating next year", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_158gucg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690219114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently wondering what my next steps should be in order to have a higher chance of securing a good data analyst / data science job when I graduate next year. I have essentialy 11 months of free time and wonder what the best use of my time will be. I am scared since the job market is tough right now and people a lot more qualified than me are struggling to even find entry level jobs.&lt;/p&gt;\n\n&lt;p&gt;Background:&lt;/p&gt;\n\n&lt;p&gt;In California&lt;/p&gt;\n\n&lt;p&gt;Graduated with a Bachelor&amp;#39;s in Mathematics from a T30 University&lt;/p&gt;\n\n&lt;p&gt;Currently enrolled in Master&amp;#39;s of Informatics program from a well known state school (Will graduate in 11 months)&lt;/p&gt;\n\n&lt;p&gt;Currently working in a chill job as a Data Coordinator for 2 years: Mainly an inventory management role with small bits of dashboarding via Excel and SAP, so I have a bunch of free time to study.&lt;/p&gt;\n\n&lt;p&gt;Any advice would be appreciated whether it be a certifcaiton reccomendation or skillsets to learn/brush up on. I am rusty on Python and SQL since my job doesn&amp;#39;t really need to use it that heavily(enough to pull data/ join tables / maniuplate data to build a dashboard)&lt;/p&gt;\n\n&lt;p&gt;What would my time better be spent doing? I was thinking of taking classes for certification (maybe google analytics or AWS) if they are worth it. Or would my time be better spent trying to learn more Python/SQL. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158gucg", "is_robot_indexable": true, "report_reasons": null, "author": "sonnysunsun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158gucg/need_advice_on_things_to_learndo_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/158gucg/need_advice_on_things_to_learndo_before/", "subreddit_subscribers": 959997, "created_utc": 1690219114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am about to graduate from undergraduate this coming semester. I am getting 2 degrees in Businesses Analytics and Management Information Systems and I also have a minor in Software Systems. I\u2019m looking to get into data science/machine learning once I graduate and I\u2019ve been studying and working on projects a decent bit on my own outside of school. I also have an internship this summer doing Software Engineering at an Engineering company. \n\n I\u2019m just kind of lost right now because from what I\u2019ve heard data science is a pretty hard field to get into and most jobs in the field require you to have a decent bit of work experience or a masters degree. I have considered getting a masters degree after I graduate, and my only work experience is from my 3 month internship. So my question is what is some advice you\u2019d have about getting into data science as a new graduate?\n\nI greatly appreciate any advice you have. Thanks", "author_fullname": "t2_g3thnfrka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting into data science as a new graduate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_158bpr1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690207647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am about to graduate from undergraduate this coming semester. I am getting 2 degrees in Businesses Analytics and Management Information Systems and I also have a minor in Software Systems. I\u2019m looking to get into data science/machine learning once I graduate and I\u2019ve been studying and working on projects a decent bit on my own outside of school. I also have an internship this summer doing Software Engineering at an Engineering company. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just kind of lost right now because from what I\u2019ve heard data science is a pretty hard field to get into and most jobs in the field require you to have a decent bit of work experience or a masters degree. I have considered getting a masters degree after I graduate, and my only work experience is from my 3 month internship. So my question is what is some advice you\u2019d have about getting into data science as a new graduate?&lt;/p&gt;\n\n&lt;p&gt;I greatly appreciate any advice you have. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158bpr1", "is_robot_indexable": true, "report_reasons": null, "author": "Wunna19", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158bpr1/getting_into_data_science_as_a_new_graduate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/158bpr1/getting_into_data_science_as_a_new_graduate/", "subreddit_subscribers": 959997, "created_utc": 1690207647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have 3 level categorical response, kind of imbalanced (roughly 60, 25, 15, been a nightmare trying to apply SMOTE to more than 2 levels but that's down the road). Most predictors are 0, but the data are not sparse (in the strict definition of sparse). I tried LDA and decision trees, both models just predict the majority class for every obs. Do I need to rotate or scale the predictors in order to control for them being mostly 0?", "author_fullname": "t2_abhp8o9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying classification on a dataset where most predictors are zero - do I need to scale or rotate, and if so how?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1589ow8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690202777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3 level categorical response, kind of imbalanced (roughly 60, 25, 15, been a nightmare trying to apply SMOTE to more than 2 levels but that&amp;#39;s down the road). Most predictors are 0, but the data are not sparse (in the strict definition of sparse). I tried LDA and decision trees, both models just predict the majority class for every obs. Do I need to rotate or scale the predictors in order to control for them being mostly 0?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1589ow8", "is_robot_indexable": true, "report_reasons": null, "author": "son_of_tv_c", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1589ow8/trying_classification_on_a_dataset_where_most/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1589ow8/trying_classification_on_a_dataset_where_most/", "subreddit_subscribers": 959997, "created_utc": 1690202777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nI am currently envolved in a project to convert calls data from my company to text, so we can derive some value from it or apply NLP techniques... right now we are using already existing Speech-to-text models that cover the Portuguese language (dont need english, only portuguese) but we are struggling with finding a model that allows us to add our own training data to the model. What we want is a pre-trained model that allows us to add extra training data, that we will be creating internally, with the script of the people from the call center, and their voices reading the script.\n\nAnyone knows of the right model or speech-to-text tool that allows for incorporating own training data?  \n\nThanks is advance", "author_fullname": "t2_g4i7s8lsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Speech to Text - Adding My Own Training Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15854m1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690189372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently envolved in a project to convert calls data from my company to text, so we can derive some value from it or apply NLP techniques... right now we are using already existing Speech-to-text models that cover the Portuguese language (dont need english, only portuguese) but we are struggling with finding a model that allows us to add our own training data to the model. What we want is a pre-trained model that allows us to add extra training data, that we will be creating internally, with the script of the people from the call center, and their voices reading the script.&lt;/p&gt;\n\n&lt;p&gt;Anyone knows of the right model or speech-to-text tool that allows for incorporating own training data?  &lt;/p&gt;\n\n&lt;p&gt;Thanks is advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15854m1", "is_robot_indexable": true, "report_reasons": null, "author": "CallMeDataSciDaddy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15854m1/speech_to_text_adding_my_own_training_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15854m1/speech_to_text_adding_my_own_training_data/", "subreddit_subscribers": 959997, "created_utc": 1690189372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm going into my second year in university and I want to break into the data science and data analytics field. Unfortunately, I'm not enrolled in a computer science or a data-related major, I'm a computational psychology major. However, I want to get some real work experience in the data industry. I've been completing a few courses online for data analytics, but I'm not sure what I should do to get a real job or internship in a related field. What are some recommended stepping stones I should take to enter this field?", "author_fullname": "t2_42bxyp3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some ways to get experience for jobs in data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1582l16", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690180948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m going into my second year in university and I want to break into the data science and data analytics field. Unfortunately, I&amp;#39;m not enrolled in a computer science or a data-related major, I&amp;#39;m a computational psychology major. However, I want to get some real work experience in the data industry. I&amp;#39;ve been completing a few courses online for data analytics, but I&amp;#39;m not sure what I should do to get a real job or internship in a related field. What are some recommended stepping stones I should take to enter this field?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1582l16", "is_robot_indexable": true, "report_reasons": null, "author": "posturegeek", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1582l16/what_are_some_ways_to_get_experience_for_jobs_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1582l16/what_are_some_ways_to_get_experience_for_jobs_in/", "subreddit_subscribers": 959997, "created_utc": 1690180948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, had an interview where the 'business insights' manager was talking about some work that they were involved in as a team. He said that they chopped off some data points to make it look like there was a trend for a particular project. Won't hear back for a few days, but doesn't sound like a very scientific or robust approach to data \ud83e\udd14\n\nEdit. Outliers or incomplete months weren't a factor.", "author_fullname": "t2_va4epm9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Interview: Manager Comments.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_158ns7c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690237523.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690234270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, had an interview where the &amp;#39;business insights&amp;#39; manager was talking about some work that they were involved in as a team. He said that they chopped off some data points to make it look like there was a trend for a particular project. Won&amp;#39;t hear back for a few days, but doesn&amp;#39;t sound like a very scientific or robust approach to data \ud83e\udd14&lt;/p&gt;\n\n&lt;p&gt;Edit. Outliers or incomplete months weren&amp;#39;t a factor.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158ns7c", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway_112801", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158ns7c/job_interview_manager_comments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/158ns7c/job_interview_manager_comments/", "subreddit_subscribers": 959997, "created_utc": 1690234270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ck1uxyfk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Code Search Infra for an AI junior developer - that doesn't store code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_158lssq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1690229961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "docs.sweep.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://docs.sweep.dev/blogs/search-infra", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "158lssq", "is_robot_indexable": true, "report_reasons": null, "author": "williamsweep", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/158lssq/code_search_infra_for_an_ai_junior_developer_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://docs.sweep.dev/blogs/search-infra", "subreddit_subscribers": 959997, "created_utc": 1690229961.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}