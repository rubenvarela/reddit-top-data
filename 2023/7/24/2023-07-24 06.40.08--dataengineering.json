{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a senior engineer, but have never had a proper code review because my managers and colleagues tend to have a data analyst/DBA background. Sometimes they ask questions about high level logic, but nobody has ever spent more than 5 minutes on reading my code or nitpicked small things which means I can't learn and grow.\n\nWhat if I join a REAL DE team in the future as a senior with REAL code reviews and everyone can see how amateurish my code looks? That's going to be quite embarrassing and it will probably take forever to ship something to production.", "author_fullname": "t2_vsf3ige5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have never had my code reviewed thoroughly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ip1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 104, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 104, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690128456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a senior engineer, but have never had a proper code review because my managers and colleagues tend to have a data analyst/DBA background. Sometimes they ask questions about high level logic, but nobody has ever spent more than 5 minutes on reading my code or nitpicked small things which means I can&amp;#39;t learn and grow.&lt;/p&gt;\n\n&lt;p&gt;What if I join a REAL DE team in the future as a senior with REAL code reviews and everyone can see how amateurish my code looks? That&amp;#39;s going to be quite embarrassing and it will probably take forever to ship something to production.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157ip1t", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated_Ad_1108", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157ip1t/i_have_never_had_my_code_reviewed_thoroughly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157ip1t/i_have_never_had_my_code_reviewed_thoroughly/", "subreddit_subscribers": 117632, "created_utc": 1690128456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in the market for a DE position, couldn't sleep last night and was reflecting on interviews I've had so far. In 4+ cases, the hiring manager has specifically asked how I  would use data to increase sales. I completely understand that this role requires being a liaison to every department but how far does/should that go?\n\nThis isn't verbatim, but one conversation went like this:\n\nHiring Manager (HM): \"Say for instance, we had a new director of marketing. How would you build a dashboard to help their department?\"\n\nMe: \"I would meet with the director to understand what metrics are most important for their team.\"\n\nHM: \"What if the director didn't know what metrics they should be looking at.\"\n\nMe: \"Then I would ask what goals the department has and work backwards from there. Additionally,  I would prepare some visualizations for data exploration that we could review together. \n\nHM: \"What if the director didn't have any goals?\"\n\nAt this point, I was thinking I wouldn't want to work at a company without any leadership from someone in a director role. I think I understand what he was getting at, but it was still awkward. Is this equivalent to asking a prospective hire in sales this:\n\nHR: \"How would you design a data pipeline that incorporates salesforce and hubspot data?\"\n\nSales Hire (SH): \"I would work with the analytics engineering team, outlining what I need the data for.\"\n\nHR: \"What if the analytics engineering team didn't know how to design a pipeline?\"\n\nSH: ...\n\nAnother example of a question I got verbatim for a DE position:\n\nHR: \"How should we increase air conditioner sales?\"\n\nMe (Never having sold an air conditioner): \"I would assume that air-conditioner sales are driven by new home construction. I would identify areas that are experiencing growth/new development and focus marketing there.\"\n\nMaybe it's just this market, but I feel like I keep flubbing these questions because I don't have a degree in marketing. ", "author_fullname": "t2_7ix4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scope creep in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157lwnh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690136121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in the market for a DE position, couldn&amp;#39;t sleep last night and was reflecting on interviews I&amp;#39;ve had so far. In 4+ cases, the hiring manager has specifically asked how I  would use data to increase sales. I completely understand that this role requires being a liaison to every department but how far does/should that go?&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t verbatim, but one conversation went like this:&lt;/p&gt;\n\n&lt;p&gt;Hiring Manager (HM): &amp;quot;Say for instance, we had a new director of marketing. How would you build a dashboard to help their department?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;I would meet with the director to understand what metrics are most important for their team.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;HM: &amp;quot;What if the director didn&amp;#39;t know what metrics they should be looking at.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;Then I would ask what goals the department has and work backwards from there. Additionally,  I would prepare some visualizations for data exploration that we could review together. &lt;/p&gt;\n\n&lt;p&gt;HM: &amp;quot;What if the director didn&amp;#39;t have any goals?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;At this point, I was thinking I wouldn&amp;#39;t want to work at a company without any leadership from someone in a director role. I think I understand what he was getting at, but it was still awkward. Is this equivalent to asking a prospective hire in sales this:&lt;/p&gt;\n\n&lt;p&gt;HR: &amp;quot;How would you design a data pipeline that incorporates salesforce and hubspot data?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Sales Hire (SH): &amp;quot;I would work with the analytics engineering team, outlining what I need the data for.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;HR: &amp;quot;What if the analytics engineering team didn&amp;#39;t know how to design a pipeline?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;SH: ...&lt;/p&gt;\n\n&lt;p&gt;Another example of a question I got verbatim for a DE position:&lt;/p&gt;\n\n&lt;p&gt;HR: &amp;quot;How should we increase air conditioner sales?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me (Never having sold an air conditioner): &amp;quot;I would assume that air-conditioner sales are driven by new home construction. I would identify areas that are experiencing growth/new development and focus marketing there.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Maybe it&amp;#39;s just this market, but I feel like I keep flubbing these questions because I don&amp;#39;t have a degree in marketing. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157lwnh", "is_robot_indexable": true, "report_reasons": null, "author": "jonesaphore", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157lwnh/scope_creep_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157lwnh/scope_creep_in_de/", "subreddit_subscribers": 117632, "created_utc": 1690136121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title, has anyone made the switch from data engineering to software dev (backend)? How was the transition (outside of internal switch)? What steps did you take to achieve this (new programming language? side projects?  Leetcode?). Any pointers on where to find side projects to collaborate with experienced backend engineers? How has this switch affected progression in your career? What level did you apply for (junior? Mid?) How\u2019s the learning curve on starting the first SWE job?\n\nBackground: I am a mid level data engineer who enjoys solving problems writing code but have found that DE domain offers less opportunities for me to improve my coding skills. I primarily use Python, SQL and spark in my day to day but feel like I could do more with Python, SQL and other languages. In my spare time, I practise by taking on leetcode challenges and reading on backend architecture and design and find it very interesting. I have also created some personal fullstack projects in the past and looking to learn better by collaborating with more experienced backend engineers on projects before applying for SWE roles.\n\nHas anyone had this experience and how did they successfully make the switch? Any recommendations will be highly appreciated.", "author_fullname": "t2_b8q6wfyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How you switched from data engineering to software Backend development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157fm9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690120905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title, has anyone made the switch from data engineering to software dev (backend)? How was the transition (outside of internal switch)? What steps did you take to achieve this (new programming language? side projects?  Leetcode?). Any pointers on where to find side projects to collaborate with experienced backend engineers? How has this switch affected progression in your career? What level did you apply for (junior? Mid?) How\u2019s the learning curve on starting the first SWE job?&lt;/p&gt;\n\n&lt;p&gt;Background: I am a mid level data engineer who enjoys solving problems writing code but have found that DE domain offers less opportunities for me to improve my coding skills. I primarily use Python, SQL and spark in my day to day but feel like I could do more with Python, SQL and other languages. In my spare time, I practise by taking on leetcode challenges and reading on backend architecture and design and find it very interesting. I have also created some personal fullstack projects in the past and looking to learn better by collaborating with more experienced backend engineers on projects before applying for SWE roles.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had this experience and how did they successfully make the switch? Any recommendations will be highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157fm9c", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent_Bad5837", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157fm9c/how_you_switched_from_data_engineering_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157fm9c/how_you_switched_from_data_engineering_to/", "subreddit_subscribers": 117632, "created_utc": 1690120905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. \n\nWhat are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?", "author_fullname": "t2_dv159drh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does DE belong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157j46z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690129459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I run a data team at a 100 person company that includes Data Science and Data engineering. Unexpectedly, I find myself fending off a hostile takeover from a leader on the engineering team, who is declaring that data engineering needs to be moved in with the engineering org. I won\u2019t give any more details because everybody reads Reddit nowadays, but I am curious for people\u2019s opinions here.  I have my own, of course, but would like to hear from you all. &lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of having the data engineering function on the same team as data science, versus having them separate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157j46z", "is_robot_indexable": true, "report_reasons": null, "author": "Sad-Fail-5337", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157j46z/where_does_de_belong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157j46z/where_does_de_belong/", "subreddit_subscribers": 117632, "created_utc": 1690129459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious to see what others use to unit test in the DE space. I work primarily on the transformation side, where we\u2019ve picked up DBT. Our stack is GitHub Actions for CI/CD, AWS/Airflow for orchestration, logging, observability, restartability, and a light runtime to create the initial DBT compilation, that\u2019s then pushed down to SnowFlake and utilizes that run time to populate the objects and run data quality checks in the SnowFlake runtime.\n\nI\u2019ve been addressing unit testing in this stack. My team\u2019s skill set more so pertains to SQL developers rather than DE, and even then their SQL is half baked at best. \n\nUnit testing within DBT is spotty at best, flat out doesn\u2019t exist at worst. I\u2019ve written a Python script that extends DBT to dynamically generate a test to every node, and allows for additional tests to be written and compiled/ran, within the CI/CD pipeline. This enables the team to continue using SQL, and the script will do the rest. If the written or generated test fails, the deployment fails.\n\nData is loaded to and read from the warehouse. I hoped to abstract from the warehouse, but SnowFlake having a closed source engine wasn\u2019t conducive to that approach. My thought was to ingest the node sql files into duckdb and have an in memory database. Not the case given SnowFlake, but oh well.\n\nWhat are your stacks and unit testing solutions?", "author_fullname": "t2_708ooj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your unit testing implementation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157tf13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690153965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious to see what others use to unit test in the DE space. I work primarily on the transformation side, where we\u2019ve picked up DBT. Our stack is GitHub Actions for CI/CD, AWS/Airflow for orchestration, logging, observability, restartability, and a light runtime to create the initial DBT compilation, that\u2019s then pushed down to SnowFlake and utilizes that run time to populate the objects and run data quality checks in the SnowFlake runtime.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been addressing unit testing in this stack. My team\u2019s skill set more so pertains to SQL developers rather than DE, and even then their SQL is half baked at best. &lt;/p&gt;\n\n&lt;p&gt;Unit testing within DBT is spotty at best, flat out doesn\u2019t exist at worst. I\u2019ve written a Python script that extends DBT to dynamically generate a test to every node, and allows for additional tests to be written and compiled/ran, within the CI/CD pipeline. This enables the team to continue using SQL, and the script will do the rest. If the written or generated test fails, the deployment fails.&lt;/p&gt;\n\n&lt;p&gt;Data is loaded to and read from the warehouse. I hoped to abstract from the warehouse, but SnowFlake having a closed source engine wasn\u2019t conducive to that approach. My thought was to ingest the node sql files into duckdb and have an in memory database. Not the case given SnowFlake, but oh well.&lt;/p&gt;\n\n&lt;p&gt;What are your stacks and unit testing solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157tf13", "is_robot_indexable": true, "report_reasons": null, "author": "ExistentialFajitas", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157tf13/what_is_your_unit_testing_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157tf13/what_is_your_unit_testing_implementation/", "subreddit_subscribers": 117632, "created_utc": 1690153965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for my first DE job, transitioning from DA. I'm just curious where did you look for a DE job posting. The current sites I'm following are Linked In and Indeed. Is there any other sites that specializes in jobs like SWE or DE? Maybe Stackoverflow? \n\nThank you for your input", "author_fullname": "t2_ceq9dvcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you find your DE job (recently, like within 1-2 years)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157x027", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690163793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for my first DE job, transitioning from DA. I&amp;#39;m just curious where did you look for a DE job posting. The current sites I&amp;#39;m following are Linked In and Indeed. Is there any other sites that specializes in jobs like SWE or DE? Maybe Stackoverflow? &lt;/p&gt;\n\n&lt;p&gt;Thank you for your input&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157x027", "is_robot_indexable": true, "report_reasons": null, "author": "uniznoir", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157x027/where_do_you_find_your_de_job_recently_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157x027/where_do_you_find_your_de_job_recently_like/", "subreddit_subscribers": 117632, "created_utc": 1690163793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIve recently been tasked to lead the development of a new data warehouse at my company. The problem is, while I am experienced in the field, ive never worked on the more backend components (ive been more of an analyst/analytics engineer) and could use some guidance on how to structure and approach this whole process, if youd let me pick your brain a bit, or perhaps theres a better forum for this somewhere?", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have experience building out a data warehouse from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157sk9t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690151763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Ive recently been tasked to lead the development of a new data warehouse at my company. The problem is, while I am experienced in the field, ive never worked on the more backend components (ive been more of an analyst/analytics engineer) and could use some guidance on how to structure and approach this whole process, if youd let me pick your brain a bit, or perhaps theres a better forum for this somewhere?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157sk9t", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157sk9t/does_anyone_have_experience_building_out_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157sk9t/does_anyone_have_experience_building_out_a_data/", "subreddit_subscribers": 117632, "created_utc": 1690151763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data reporting business is generally needs a lot of humans involvement to ensure the quality of data, any traction for AI in this space &amp; recommendations please", "author_fullname": "t2_va6si3w6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any AI tools / plugins to check data accuracy and data structure ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157b6f7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690107615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data reporting business is generally needs a lot of humans involvement to ensure the quality of data, any traction for AI in this space &amp;amp; recommendations please&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157b6f7", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Pick_8431", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157b6f7/is_there_any_ai_tools_plugins_to_check_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157b6f7/is_there_any_ai_tools_plugins_to_check_data/", "subreddit_subscribers": 117632, "created_utc": 1690107615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a cofounder at a non-tech company in the sense that we don't have any client-facing software, just internal tools in the form of tableau dashboards and excel reports.\n\nI did a web dev bootcamp years ago, but what I'm doing now has been learned from googling and Udemy over the years as problems emerged.\n\nWe're now in year 3 and I feel like this architecture I've hacked out, with 0 production experience in engineering, could use a review, especially as our operations scale.\n\n1. AWS MySQL RDS database (db.t4g.xlarge), with read replica(db.t4g.large) for analytics. Currently at 100GB of data.\n2. On the write side: Data is constantly written to the DB throughout the day, mainly through scheduled AWS Lambda functions that are making API calls (currently 10+ different API systems). \n   1. Other sources: S3 Uploads/SNS/Webhooks -&gt; lambda triggers.\n   2. Proxy endpoint is used to pool connections\n   3. Write data is about 250MB a day\n   4. Write used to be a bottleneck until I figured out proxy endpoints, so I think I'm good for now.\n3. On the read side: I have about 40 tableau dashboards, with data extracts (some reused) that are refreshing daily/hourly from the read replica DB (db.t4g.large). \n   1. Some (full) refreshes can run for up to 5 minutes, which is fine at the moment. \n   2. Also have scheduled reports that run sql and convert to excel reports, to be emailed out.\n   3. This is usually where I run into bottlenecks and cause for upgrading my db instance. I'll upgrade when my extracts take 10+ minutes to refresh, or if I start getting alarm notifications for CPU Utilization (80% and I'm looking to upgrade)\n   4. I've optimized my sql to the best I could using indexing and other tricks, but a combination of joining 4 different tables on 3 keys each, with sorting and group by deduplicating, can push CPU compute to the limit.\n\nWhile I still have room to upgrade my DB, I am a bit concerned as we are heading into growth stage, potentially 4x our current usage. While I know that vertical scaling is going to be fine for me, I do have to consider the cost implications, and I'm wondering if there are new tools and tech that I should be looking into, as I continue to improve on this architecture. ", "author_fullname": "t2_1e2kokl8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self taught \"CTO/Data Engineer\" cofounder. Looking for feedback on architecture.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157yjwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690168215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a cofounder at a non-tech company in the sense that we don&amp;#39;t have any client-facing software, just internal tools in the form of tableau dashboards and excel reports.&lt;/p&gt;\n\n&lt;p&gt;I did a web dev bootcamp years ago, but what I&amp;#39;m doing now has been learned from googling and Udemy over the years as problems emerged.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re now in year 3 and I feel like this architecture I&amp;#39;ve hacked out, with 0 production experience in engineering, could use a review, especially as our operations scale.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;AWS MySQL RDS database (db.t4g.xlarge), with read replica(db.t4g.large) for analytics. Currently at 100GB of data.&lt;/li&gt;\n&lt;li&gt;On the write side: Data is constantly written to the DB throughout the day, mainly through scheduled AWS Lambda functions that are making API calls (currently 10+ different API systems). \n\n&lt;ol&gt;\n&lt;li&gt;Other sources: S3 Uploads/SNS/Webhooks -&amp;gt; lambda triggers.&lt;/li&gt;\n&lt;li&gt;Proxy endpoint is used to pool connections&lt;/li&gt;\n&lt;li&gt;Write data is about 250MB a day&lt;/li&gt;\n&lt;li&gt;Write used to be a bottleneck until I figured out proxy endpoints, so I think I&amp;#39;m good for now.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;On the read side: I have about 40 tableau dashboards, with data extracts (some reused) that are refreshing daily/hourly from the read replica DB (db.t4g.large). \n\n&lt;ol&gt;\n&lt;li&gt;Some (full) refreshes can run for up to 5 minutes, which is fine at the moment. &lt;/li&gt;\n&lt;li&gt;Also have scheduled reports that run sql and convert to excel reports, to be emailed out.&lt;/li&gt;\n&lt;li&gt;This is usually where I run into bottlenecks and cause for upgrading my db instance. I&amp;#39;ll upgrade when my extracts take 10+ minutes to refresh, or if I start getting alarm notifications for CPU Utilization (80% and I&amp;#39;m looking to upgrade)&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve optimized my sql to the best I could using indexing and other tricks, but a combination of joining 4 different tables on 3 keys each, with sorting and group by deduplicating, can push CPU compute to the limit.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;While I still have room to upgrade my DB, I am a bit concerned as we are heading into growth stage, potentially 4x our current usage. While I know that vertical scaling is going to be fine for me, I do have to consider the cost implications, and I&amp;#39;m wondering if there are new tools and tech that I should be looking into, as I continue to improve on this architecture. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157yjwy", "is_robot_indexable": true, "report_reasons": null, "author": "mcdunald", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157yjwy/self_taught_ctodata_engineer_cofounder_looking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157yjwy/self_taught_ctodata_engineer_cofounder_looking/", "subreddit_subscribers": 117632, "created_utc": 1690168215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am looking for some advise. I am designing a \"batch data generation pipeline\" that is essentially a batch execution version of a this problem (for now a spark job):\n\n1. User provided id, query parameters, output location.\n\n2. Query a catalog dataset that represents a large list of files and filter the ones that matches exactly the ones needed to produce the output.\n\n3. Execute a set of transformation (groupby, sort, etc) that take output of #2 and produces some output dataframe.\n\n4. Write to output location in some custom format.\n\nSo, I have N instances of the same problem with different (possibly overlapping) inputs. I want to build an efficient way to structure this spark job(s) so that the overhead is low. \n\nOption 1: build a spark job that submits n jobs with different inputs in parallel or in batches with no shared steps (except the spark context)\n\nOption 2: build a spark job that does a sort of dataframe union before submitting it all as a single bigger job.\n\nOption 3: ???\n\nHas anyone done something like this? In terms of scale size - the step 1 (list of files) is about ~5TB and the input used to generate the data is ~10GiB output. The N in the batch is adjustable but I think 100 at a time is probably a minimum point.", "author_fullname": "t2_4eb03", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Packing n querries into 1", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157yia1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690168080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am looking for some advise. I am designing a &amp;quot;batch data generation pipeline&amp;quot; that is essentially a batch execution version of a this problem (for now a spark job):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;User provided id, query parameters, output location.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Query a catalog dataset that represents a large list of files and filter the ones that matches exactly the ones needed to produce the output.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Execute a set of transformation (groupby, sort, etc) that take output of #2 and produces some output dataframe.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Write to output location in some custom format.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So, I have N instances of the same problem with different (possibly overlapping) inputs. I want to build an efficient way to structure this spark job(s) so that the overhead is low. &lt;/p&gt;\n\n&lt;p&gt;Option 1: build a spark job that submits n jobs with different inputs in parallel or in batches with no shared steps (except the spark context)&lt;/p&gt;\n\n&lt;p&gt;Option 2: build a spark job that does a sort of dataframe union before submitting it all as a single bigger job.&lt;/p&gt;\n\n&lt;p&gt;Option 3: ???&lt;/p&gt;\n\n&lt;p&gt;Has anyone done something like this? In terms of scale size - the step 1 (list of files) is about ~5TB and the input used to generate the data is ~10GiB output. The N in the batch is adjustable but I think 100 at a time is probably a minimum point.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157yia1", "is_robot_indexable": true, "report_reasons": null, "author": "ankurcha", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157yia1/packing_n_querries_into_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157yia1/packing_n_querries_into_1/", "subreddit_subscribers": 117632, "created_utc": 1690168080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit community!\n\nI'm thrilled to introduce you to Prism, an innovative open-source data orchestration platform. We've been working tirelessly to develop this tool, and now we're excited to invite you all to be a part of our alpha testing phase.\n\n\ud83d\udd17 Website: [https://runprism.com/](https://runprism.com/)\n\n\ud83d\udce2 GitHub Repository: [https://github.com/runprism/prism](https://github.com/runprism/prism)\n\n\ud83d\udcc4 Documentation: [https://docs.runprism.com](https://docs.runprism.com/)\n\n# What is Prism?\n\nPrism is a powerful yet user-friendly orchestration platform designed to streamline your processes, boost productivity, and enhance collaboration across teams. Whether you're a developer, sysadmin, data analyst, or any professional who deals with workflows, Prism has something valuable to offer.\n\n# Key Features\n\n**\ud83d\udd39** **Workflow Automation**\\*\\*:\\*\\* Real-time dependency declaration: With Prism, analysts can declare dependencies using a simple function call. No need to explicitly keep track of the pipeline order \u2014 at runtime, Prism automatically parses the function calls and builds the dependency graph.\n\n**\ud83d\udd39 Intuitive logging:** Prism automatically logs events for parsing the configuration files, compiling the tasks and creating the project, and executing the tasks. No configuration is required.\n\n\ud83d\udd39 **Flexible CLI:** Users can instantiate, compile, and run projects using a simple, but powerful command-line interface.\n\n**\ud83d\udd39 Extensive Plugin Library:** Enjoy a rich collection of integrations with your favorite tools and services.\n\n**\ud83d\udd39 \u201cBatteries included\u201d:** Prism comes with all the essentials needed to get up and running quickly. Users can create and run their first project in less than 2 minutes.\n\n# How to Get Involved\n\nBy joining our Alpha testing phase, you have the unique opportunity to be among the first users to experience Prism in action. Your invaluable feedback will directly impact the development of this platform, helping us make it even better, more stable, and tailored to your needs.\n\nVisit our website [https://runprism.com](https://runprism.com/) to learn more about the platform and its features. In addition, check out our documentation at [https://docs.runprism.com](https://docs.runprism.com/) to get started right away!\n\nAccess the GitHub repository [https://github.com/runprism/prism](https://github.com/runprism/prism) to view the source code, report issues, and contribute to the project.\n\nTry out Prism in your own workflow environment and let us know what you think!\n\nWe highly encourage you to share your thoughts, suggestions, and bug reports with us. Feel free to post your feedback directly in this thread, or if you prefer, you can raise issues on GitHub. Your input is invaluable to us, and together, we can shape Prism into the go-to platform for data workflow orchestration.\n\n# Who We Are\n\nOur team is a group of passionate data engineers, scientists, and developers. We're open-source enthusiasts who believe in the power of community-driven software, and we're committed to making Prism an exceptional orchestration tool and fostering an inclusive environment for all contributors.", "author_fullname": "t2_g2ejflv7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Prism: A Novel, Open-Source Data Orchestration Software. Feedback needed!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157vab7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690158966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit community!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thrilled to introduce you to Prism, an innovative open-source data orchestration platform. We&amp;#39;ve been working tirelessly to develop this tool, and now we&amp;#39;re excited to invite you all to be a part of our alpha testing phase.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd17 Website: &lt;a href=\"https://runprism.com/\"&gt;https://runprism.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udce2 GitHub Repository: &lt;a href=\"https://github.com/runprism/prism\"&gt;https://github.com/runprism/prism&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcc4 Documentation: &lt;a href=\"https://docs.runprism.com/\"&gt;https://docs.runprism.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;What is Prism?&lt;/h1&gt;\n\n&lt;p&gt;Prism is a powerful yet user-friendly orchestration platform designed to streamline your processes, boost productivity, and enhance collaboration across teams. Whether you&amp;#39;re a developer, sysadmin, data analyst, or any professional who deals with workflows, Prism has something valuable to offer.&lt;/p&gt;\n\n&lt;h1&gt;Key Features&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udd39&lt;/strong&gt; &lt;strong&gt;Workflow Automation&lt;/strong&gt;**:** Real-time dependency declaration: With Prism, analysts can declare dependencies using a simple function call. No need to explicitly keep track of the pipeline order \u2014 at runtime, Prism automatically parses the function calls and builds the dependency graph.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udd39 Intuitive logging:&lt;/strong&gt; Prism automatically logs events for parsing the configuration files, compiling the tasks and creating the project, and executing the tasks. No configuration is required.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd39 &lt;strong&gt;Flexible CLI:&lt;/strong&gt; Users can instantiate, compile, and run projects using a simple, but powerful command-line interface.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udd39 Extensive Plugin Library:&lt;/strong&gt; Enjoy a rich collection of integrations with your favorite tools and services.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\ud83d\udd39 \u201cBatteries included\u201d:&lt;/strong&gt; Prism comes with all the essentials needed to get up and running quickly. Users can create and run their first project in less than 2 minutes.&lt;/p&gt;\n\n&lt;h1&gt;How to Get Involved&lt;/h1&gt;\n\n&lt;p&gt;By joining our Alpha testing phase, you have the unique opportunity to be among the first users to experience Prism in action. Your invaluable feedback will directly impact the development of this platform, helping us make it even better, more stable, and tailored to your needs.&lt;/p&gt;\n\n&lt;p&gt;Visit our website &lt;a href=\"https://runprism.com/\"&gt;https://runprism.com&lt;/a&gt; to learn more about the platform and its features. In addition, check out our documentation at &lt;a href=\"https://docs.runprism.com/\"&gt;https://docs.runprism.com&lt;/a&gt; to get started right away!&lt;/p&gt;\n\n&lt;p&gt;Access the GitHub repository &lt;a href=\"https://github.com/runprism/prism\"&gt;https://github.com/runprism/prism&lt;/a&gt; to view the source code, report issues, and contribute to the project.&lt;/p&gt;\n\n&lt;p&gt;Try out Prism in your own workflow environment and let us know what you think!&lt;/p&gt;\n\n&lt;p&gt;We highly encourage you to share your thoughts, suggestions, and bug reports with us. Feel free to post your feedback directly in this thread, or if you prefer, you can raise issues on GitHub. Your input is invaluable to us, and together, we can shape Prism into the go-to platform for data workflow orchestration.&lt;/p&gt;\n\n&lt;h1&gt;Who We Are&lt;/h1&gt;\n\n&lt;p&gt;Our team is a group of passionate data engineers, scientists, and developers. We&amp;#39;re open-source enthusiasts who believe in the power of community-driven software, and we&amp;#39;re committed to making Prism an exceptional orchestration tool and fostering an inclusive environment for all contributors.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "157vab7", "is_robot_indexable": true, "report_reasons": null, "author": "runprism", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157vab7/introducing_prism_a_novel_opensource_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157vab7/introducing_prism_a_novel_opensource_data/", "subreddit_subscribers": 117632, "created_utc": 1690158966.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone here use [Observable Plot](https://observablehq.com/plot/) for visualization? I\u2019m a software dev and data engineer (background in analytics) by day and indie hacker/software bootstrapper by night. I recently found Observable Plot, and I like how it\u2019s a more simplified D3 library without the extreme complexity of D3. As a fan of analytics, I was thinking it would be cool to have an app or platform powered by Observable Plot. Does anyone use it? Do you find it useful? I think it would be fun to build something for it one day.", "author_fullname": "t2_853j9w4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Observable Plot App", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157tbjy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690153722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone here use &lt;a href=\"https://observablehq.com/plot/\"&gt;Observable Plot&lt;/a&gt; for visualization? I\u2019m a software dev and data engineer (background in analytics) by day and indie hacker/software bootstrapper by night. I recently found Observable Plot, and I like how it\u2019s a more simplified D3 library without the extreme complexity of D3. As a fan of analytics, I was thinking it would be cool to have an app or platform powered by Observable Plot. Does anyone use it? Do you find it useful? I think it would be fun to build something for it one day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?auto=webp&amp;s=d61aad96512a29dcaa46ea70b4c8c95d7e5f0c86", "width": 640, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5fbff1bfdc101900113b39ebbacd4d31bba433b2", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9fb242ff425f112d1d0bc1d00a39affc7d4e261b", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=65e3caabb9cf4cb5b2837ff3e18f307223b2cb52", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/9vfS41r4Z05A0_9FA_-KGKVpu4Ub5XvMtXltqts0w-w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c18a4fb1fff2a49410ad5f90264959f409db2dcb", "width": 640, "height": 400}], "variants": {}, "id": "ZPQU_vipEkiGX1dZZBsM9Te8h8Cq9X3DaP_mcwE-zKo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157tbjy", "is_robot_indexable": true, "report_reasons": null, "author": "SirLagsABot", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157tbjy/observable_plot_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157tbjy/observable_plot_app/", "subreddit_subscribers": 117632, "created_utc": 1690153722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "found this on substack and reposting here for more reach.", "author_fullname": "t2_vi5mj54d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "name": "t3_157mn03", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FDDKeJwbGLUab6btVz1qzcE0b4JSqmLUEaFYavlouFc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690137835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;found this on substack and reposting here for more reach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/o908zbyifrdb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?auto=webp&amp;s=5760b5b63c45ff2034b1053d76b21cdda69dbc24", "width": 1179, "height": 718}, "resolutions": [{"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e19db647dba910a9349807b611f66eb7b16cea18", "width": 108, "height": 65}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e69c8470d41e0d0a7f73b9235608653fa071e55b", "width": 216, "height": 131}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9b46d207118d885e3d8ab30d58e1accf87448081", "width": 320, "height": 194}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=980061a81aac3c925fec18c1f93441bd90f4c5a5", "width": 640, "height": 389}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8855e1c1ee649852826ec2f6eebfc8ac8bca21ef", "width": 960, "height": 584}, {"url": "https://preview.redd.it/o908zbyifrdb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b0526230ba81f85165e34740b6f2f26fe354d20", "width": 1080, "height": 657}], "variants": {}, "id": "FD8BsKGuc9f_50KXbD-QTDIZrGjNXHpBBM-rg1ah9e0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "157mn03", "is_robot_indexable": true, "report_reasons": null, "author": "mrlmld", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157mn03/rust_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/o908zbyifrdb1.jpg", "subreddit_subscribers": 117632, "created_utc": 1690137835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm fairly new to Pyarrow and parquet files, but have experience with Python.\n\nI'm working on a codebase that processes daily data. We have a Pyarrow Table with 3 columns, one of which is a date. The data goes back to 2007, so ~ 5800 unique dates. The table has 43 million rows, so avg of ~7500 rows per date. The output should be a parquet dataset, partitioned by the date column. So you have an folder with ~5800 folders, named by date. Each folder should contain a single parquet file.\n\nThe repo switches between pandas dataframes and pyarrow tables frequently, mostly pandas for data transformation and pyarrow for parquet reading and writing. The internal processing can be updated, but to work with our other processes, the output needs to remain as daily parquet files.\n\nThis has worked for a long time until we tried updating the Pandas and Pyarrow version, for performance improvements. We went Pandas 1.2 -&gt; 2.0, and Pyarrow 2 -&gt; 12. The original code, that worked:\n\n    pq.write_to_dataset(table, root_path=str(output_filepath),\n                        partition_cols=['action_date'],\n                        allow_truncated_timestamps=True)\n\nNow, with updated pandas and pyarrow on that code, I get the error:\n    pandas_to_parquet Fragment would be written into 4141 partitions. This exceeds the maximum of 1024\n\nI researched and found that pyarrow's behavior changed after version 4.0. It defaults to 1024, and must be set higher. Since I know there's 5800 partitions needed, growing every day, I set it to 7000.\n\n    pq.write_to_dataset(table, root_path=str(output_filepath),\n                        partition_cols=['action_date'],\n                        allow_truncated_timestamps=True,\n                        use_legacy_dataset=False,\n                        max_partitions=7000)\n\nThis took significantly longer to run, many times over. The output folders were correct, but inside each was many parquet files, each only about 2kb. Previously there would be a single parquet, around 20 to 80kb.\n\nI'm trying to figure out how to ensure a single parquet file per daily folder, and have similar or better performance to the previous version with older pandas and pyarrow. The original in memory table I'm trying to write to a parquet dataset is about 280mb. This runs on a larger EC2 instance, AWS Linux.\n\n\n\nTLDR: I updated Pyarrow from 2.0 to 12, and am trying to make the write_to_dataset method function as before, with at least comparable performance. \n\nThank you for any insight or help here, it's very much appreciated!", "author_fullname": "t2_xod94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with Pyarrow behavior - .write_to_dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157mlmc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690137738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m fairly new to Pyarrow and parquet files, but have experience with Python.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a codebase that processes daily data. We have a Pyarrow Table with 3 columns, one of which is a date. The data goes back to 2007, so ~ 5800 unique dates. The table has 43 million rows, so avg of ~7500 rows per date. The output should be a parquet dataset, partitioned by the date column. So you have an folder with ~5800 folders, named by date. Each folder should contain a single parquet file.&lt;/p&gt;\n\n&lt;p&gt;The repo switches between pandas dataframes and pyarrow tables frequently, mostly pandas for data transformation and pyarrow for parquet reading and writing. The internal processing can be updated, but to work with our other processes, the output needs to remain as daily parquet files.&lt;/p&gt;\n\n&lt;p&gt;This has worked for a long time until we tried updating the Pandas and Pyarrow version, for performance improvements. We went Pandas 1.2 -&amp;gt; 2.0, and Pyarrow 2 -&amp;gt; 12. The original code, that worked:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pq.write_to_dataset(table, root_path=str(output_filepath),\n                    partition_cols=[&amp;#39;action_date&amp;#39;],\n                    allow_truncated_timestamps=True)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Now, with updated pandas and pyarrow on that code, I get the error:\n    pandas_to_parquet Fragment would be written into 4141 partitions. This exceeds the maximum of 1024&lt;/p&gt;\n\n&lt;p&gt;I researched and found that pyarrow&amp;#39;s behavior changed after version 4.0. It defaults to 1024, and must be set higher. Since I know there&amp;#39;s 5800 partitions needed, growing every day, I set it to 7000.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pq.write_to_dataset(table, root_path=str(output_filepath),\n                    partition_cols=[&amp;#39;action_date&amp;#39;],\n                    allow_truncated_timestamps=True,\n                    use_legacy_dataset=False,\n                    max_partitions=7000)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This took significantly longer to run, many times over. The output folders were correct, but inside each was many parquet files, each only about 2kb. Previously there would be a single parquet, around 20 to 80kb.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out how to ensure a single parquet file per daily folder, and have similar or better performance to the previous version with older pandas and pyarrow. The original in memory table I&amp;#39;m trying to write to a parquet dataset is about 280mb. This runs on a larger EC2 instance, AWS Linux.&lt;/p&gt;\n\n&lt;p&gt;TLDR: I updated Pyarrow from 2.0 to 12, and am trying to make the write_to_dataset method function as before, with at least comparable performance. &lt;/p&gt;\n\n&lt;p&gt;Thank you for any insight or help here, it&amp;#39;s very much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157mlmc", "is_robot_indexable": true, "report_reasons": null, "author": "bigfishindoggytown", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157mlmc/help_with_pyarrow_behavior_write_to_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157mlmc/help_with_pyarrow_behavior_write_to_dataset/", "subreddit_subscribers": 117632, "created_utc": 1690137738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have airflow on WSL but are otherwise a Windows shop. What sorts of activities would be good practice for improving my command line knowledge? Or what sorts of command line activities are most useful/common for data engineering?\n\nI am very much a learn by doing kind of person. I have to seek out ways to transform whatever I am working on to incorporate what I  am interested in learning, even if it isn't necessary. So identifying what I should be thinking to try in command line will go a long way. Thanks!", "author_fullname": "t2_f1q7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Improving at Command line", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157ke6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690132544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have airflow on WSL but are otherwise a Windows shop. What sorts of activities would be good practice for improving my command line knowledge? Or what sorts of command line activities are most useful/common for data engineering?&lt;/p&gt;\n\n&lt;p&gt;I am very much a learn by doing kind of person. I have to seek out ways to transform whatever I am working on to incorporate what I  am interested in learning, even if it isn&amp;#39;t necessary. So identifying what I should be thinking to try in command line will go a long way. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "157ke6v", "is_robot_indexable": true, "report_reasons": null, "author": "machinegunke11y", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157ke6v/improving_at_command_line/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157ke6v/improving_at_command_line/", "subreddit_subscribers": 117632, "created_utc": 1690132544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHi everyone,\n\nI am planning to switch  from data analytics/BA to data engineering.\n\nMy current skills include SQL (select statements), python pandas, power BI(data modelling and dashboarding), Azure data factory and spark using databricks.\n\nI've just got my DP 900 certificate and contemplating completing either dp203 and/or databricks DE associate.\n\n\nI will also be picking up docker with airflow and Kafka.\n\nWhich of the two certificates mentioned will be better for me ?\n\nThanks in advance for your advice.", "author_fullname": "t2_3o8uixm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DP 203 Vs databricks DE associate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157e9t5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690117215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am planning to switch  from data analytics/BA to data engineering.&lt;/p&gt;\n\n&lt;p&gt;My current skills include SQL (select statements), python pandas, power BI(data modelling and dashboarding), Azure data factory and spark using databricks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just got my DP 900 certificate and contemplating completing either dp203 and/or databricks DE associate.&lt;/p&gt;\n\n&lt;p&gt;I will also be picking up docker with airflow and Kafka.&lt;/p&gt;\n\n&lt;p&gt;Which of the two certificates mentioned will be better for me ?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "157e9t5", "is_robot_indexable": true, "report_reasons": null, "author": "Leonjy92", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157e9t5/dp_203_vs_databricks_de_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157e9t5/dp_203_vs_databricks_de_associate/", "subreddit_subscribers": 117632, "created_utc": 1690117215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With 4 years of experience in the field, I have mostly worked on Spark, Python, Nifi, Airflow, AWS and Azure.\nI moved to Dubai to look for better opportunities however after multiple rounds of 4-5 interviews in the last 2 months, I am unable to convert into a job offer.\nHow to prepare for DE interviews and any resources which can help in the preparation of interviews?", "author_fullname": "t2_ivx2i554", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to covert interviews to job offers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_157plwk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690144697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With 4 years of experience in the field, I have mostly worked on Spark, Python, Nifi, Airflow, AWS and Azure.\nI moved to Dubai to look for better opportunities however after multiple rounds of 4-5 interviews in the last 2 months, I am unable to convert into a job offer.\nHow to prepare for DE interviews and any resources which can help in the preparation of interviews?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "157plwk", "is_robot_indexable": true, "report_reasons": null, "author": "umermd", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/157plwk/how_to_covert_interviews_to_job_offers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/157plwk/how_to_covert_interviews_to_job_offers/", "subreddit_subscribers": 117632, "created_utc": 1690144697.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}