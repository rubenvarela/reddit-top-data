{"kind": "Listing", "data": {"after": "t3_14xgo7v", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got into a data engineering role, it's my first job as a DE. And i am feeling absolutely lost, i don't understand what's happening, everything is everywhere, my team mates are very busy so no one properly explains what's happening and some structural change is happening in the whole section of DE teams. And I feel absolutely overwhelmed.\nHow do you tackle this?", "author_fullname": "t2_vn1meuc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal to feel completely lost during initial months of your data engineering job ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xhi13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689147891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got into a data engineering role, it&amp;#39;s my first job as a DE. And i am feeling absolutely lost, i don&amp;#39;t understand what&amp;#39;s happening, everything is everywhere, my team mates are very busy so no one properly explains what&amp;#39;s happening and some structural change is happening in the whole section of DE teams. And I feel absolutely overwhelmed.\nHow do you tackle this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xhi13", "is_robot_indexable": true, "report_reasons": null, "author": "jojobaoil68", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xhi13/is_it_normal_to_feel_completely_lost_during/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xhi13/is_it_normal_to_feel_completely_lost_during/", "subreddit_subscribers": 115423, "created_utc": 1689147891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone - for context I'm a DE with \\~3 YoE that I spent working in a small startup where I was, *for the most part*, the sole DE.  \nI was responsible for not only implementing an end-to-end data pipeline that handles data from ingestion to analytics dashboards but also built the websockets and APIs needed to interact with different parts of the pipeline - which I really liked.\n\nAround a month ago I got the opportunity to join a big company as a DE, both the job listing and the interview had big emphasis on experience with end-to-end data pipelines and good SWE practices.\n\nI figured this would be a great opportunity to work with more experienced engineers on a project with significantly more data than what I'm used to.\n\nThe data stack is: Airflow - dbt (core) - AWS S3 (data lake) - AWS Redshift (dw) - Quicksight.\n\nMost of the tasks I pick up involve building dbt models, solving merge conflicts, configuring Airflow DAGs or sometimes assisting the analytics team.\n\nThe good thing is that the company has a great data culture and big emphasis on CI/CD and good SWE practices - they also insist on having DEs handle the building of dbt models and query optimization which is a good thing imo.\n\nMy major concern however is that the role doesn't feel as technically challenging as I was hoping for it to be, so do you guys think this is a good position to progress my career long term *from a technical standpoint* or should I keep an eye on other opportunities ?", "author_fullname": "t2_pna4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joined a new company as a DE for a big project and I'm feeling a bit underwhelmed - Would like to hear a second opinion.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xkfjd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689157100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone - for context I&amp;#39;m a DE with ~3 YoE that I spent working in a small startup where I was, &lt;em&gt;for the most part&lt;/em&gt;, the sole DE.&lt;br/&gt;\nI was responsible for not only implementing an end-to-end data pipeline that handles data from ingestion to analytics dashboards but also built the websockets and APIs needed to interact with different parts of the pipeline - which I really liked.&lt;/p&gt;\n\n&lt;p&gt;Around a month ago I got the opportunity to join a big company as a DE, both the job listing and the interview had big emphasis on experience with end-to-end data pipelines and good SWE practices.&lt;/p&gt;\n\n&lt;p&gt;I figured this would be a great opportunity to work with more experienced engineers on a project with significantly more data than what I&amp;#39;m used to.&lt;/p&gt;\n\n&lt;p&gt;The data stack is: Airflow - dbt (core) - AWS S3 (data lake) - AWS Redshift (dw) - Quicksight.&lt;/p&gt;\n\n&lt;p&gt;Most of the tasks I pick up involve building dbt models, solving merge conflicts, configuring Airflow DAGs or sometimes assisting the analytics team.&lt;/p&gt;\n\n&lt;p&gt;The good thing is that the company has a great data culture and big emphasis on CI/CD and good SWE practices - they also insist on having DEs handle the building of dbt models and query optimization which is a good thing imo.&lt;/p&gt;\n\n&lt;p&gt;My major concern however is that the role doesn&amp;#39;t feel as technically challenging as I was hoping for it to be, so do you guys think this is a good position to progress my career long term &lt;em&gt;from a technical standpoint&lt;/em&gt; or should I keep an eye on other opportunities ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xkfjd", "is_robot_indexable": true, "report_reasons": null, "author": "King_TN", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xkfjd/joined_a_new_company_as_a_de_for_a_big_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xkfjd/joined_a_new_company_as_a_de_for_a_big_project/", "subreddit_subscribers": 115423, "created_utc": 1689157100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team is looking at writing a simple framework/platform based on Cloud that'd allow various users to define batch based pipelines. Currently focusing on AWS, there are multiple modules which setup a set of services, dynamic infrastructure, orchestration, roles, notifications for the users as part of the platform. \n\nAs part of orchestration, I started looking at Dagster and one of the thing I immediately realized is that the actual data processing and orchestration is intertwined and deliberately kept together in most of the examples I saw and also a forte of Dagster as I understand compared to the traditional orhestration/workflow frameworks where they are loosely coupled and a DAG is defined.   \n\n\nWhen I look at any orchestrator, the main things I look for is that - orchestration, meaning given a set of tasks, it should be able to execute, report on, track, kill at will, rollback, fanout, do reporting and maintain metadata for it. Combining this with the actual data being processed as part of the actions/tasks is a great thing for small scale pipelines but quickly becomes a scaling/deployment problem if I want to make it available as a service (not looking for Dagster cloud yet) where users can submit many such jobs.   \n\n\nI understand and yet to explore the constructs such as Assets, Operators that allow me integrate with external services (in my case the cloud services which I'd integrate with a good wrapper over common AWS managed services and compute) but before I proceed wanted to check if I am not setting myself on a wrong path just because its supports but is indeed an antipattern.   \n\n\nWhy separate actual compute from orchestration ?   \n\\- I want to fully exploit and use existing AWS services where given a script (say the script/python code utilizing say polars,pandas, duckdb etc), I have a freedom to pack and run it as a docker image on ECS, Fargate, or lamda   \n\\- For a very big workloads, which don't fit into services such as AWS Glue/Redshift for ELT/ETL purpose, be able to spawn an appliance say through spot and get it executed in EC2 and so on..  \n\n\n.. and still use Dagster as a pure orchestrator where it can have a shim layer written that not only launches but tracks these jobs very well, helps with retries, rollbacks etc.", "author_fullname": "t2_qg4yidm6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster - Separating compute and orchestration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xodd2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team is looking at writing a simple framework/platform based on Cloud that&amp;#39;d allow various users to define batch based pipelines. Currently focusing on AWS, there are multiple modules which setup a set of services, dynamic infrastructure, orchestration, roles, notifications for the users as part of the platform. &lt;/p&gt;\n\n&lt;p&gt;As part of orchestration, I started looking at Dagster and one of the thing I immediately realized is that the actual data processing and orchestration is intertwined and deliberately kept together in most of the examples I saw and also a forte of Dagster as I understand compared to the traditional orhestration/workflow frameworks where they are loosely coupled and a DAG is defined.   &lt;/p&gt;\n\n&lt;p&gt;When I look at any orchestrator, the main things I look for is that - orchestration, meaning given a set of tasks, it should be able to execute, report on, track, kill at will, rollback, fanout, do reporting and maintain metadata for it. Combining this with the actual data being processed as part of the actions/tasks is a great thing for small scale pipelines but quickly becomes a scaling/deployment problem if I want to make it available as a service (not looking for Dagster cloud yet) where users can submit many such jobs.   &lt;/p&gt;\n\n&lt;p&gt;I understand and yet to explore the constructs such as Assets, Operators that allow me integrate with external services (in my case the cloud services which I&amp;#39;d integrate with a good wrapper over common AWS managed services and compute) but before I proceed wanted to check if I am not setting myself on a wrong path just because its supports but is indeed an antipattern.   &lt;/p&gt;\n\n&lt;p&gt;Why separate actual compute from orchestration ?&lt;br/&gt;\n- I want to fully exploit and use existing AWS services where given a script (say the script/python code utilizing say polars,pandas, duckdb etc), I have a freedom to pack and run it as a docker image on ECS, Fargate, or lamda&lt;br/&gt;\n- For a very big workloads, which don&amp;#39;t fit into services such as AWS Glue/Redshift for ELT/ETL purpose, be able to spawn an appliance say through spot and get it executed in EC2 and so on..  &lt;/p&gt;\n\n&lt;p&gt;.. and still use Dagster as a pure orchestrator where it can have a shim layer written that not only launches but tracks these jobs very well, helps with retries, rollbacks etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xodd2", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Cartoonist7071", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xodd2/dagster_separating_compute_and_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xodd2/dagster_separating_compute_and_orchestration/", "subreddit_subscribers": 115423, "created_utc": 1689167886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm actually going to make this, so I want to make sure I don't leave out any great jokes. What should the office look like? What struggles should I include? What would make you laugh? ", "author_fullname": "t2_68z0an9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If there was a nature documentary about the \"datus engineerius\" and it's life inside of the corporate habitat, what kinds of things would for sure be pointed out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xoc20", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m actually going to make this, so I want to make sure I don&amp;#39;t leave out any great jokes. What should the office look like? What struggles should I include? What would make you laugh? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xoc20", "is_robot_indexable": true, "report_reasons": null, "author": "3spelledout", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xoc20/if_there_was_a_nature_documentary_about_the_datus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xoc20/if_there_was_a_nature_documentary_about_the_datus/", "subreddit_subscribers": 115423, "created_utc": 1689167792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any easy way to calculate the minimum number of workers, drivers and memory needed in databricks? A website that does the calculation if any?", "author_fullname": "t2_aqp7hdzb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any websites to calculate Databricks drivers and workers required?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xgcwi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689144002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any easy way to calculate the minimum number of workers, drivers and memory needed in databricks? A website that does the calculation if any?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xgcwi", "is_robot_indexable": true, "report_reasons": null, "author": "johnyjohnyespappa", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xgcwi/any_websites_to_calculate_databricks_drivers_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xgcwi/any_websites_to_calculate_databricks_drivers_and/", "subreddit_subscribers": 115423, "created_utc": 1689144002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning Apache Kafka, and I have completed the \"Apache Kafka Series - Learn Apache Kafka for Beginners v3\" course by Stephane Maarek. What do you think should be my next step?", "author_fullname": "t2_feara4tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14x6c6f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689116033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning Apache Kafka, and I have completed the &amp;quot;Apache Kafka Series - Learn Apache Kafka for Beginners v3&amp;quot; course by Stephane Maarek. What do you think should be my next step?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14x6c6f", "is_robot_indexable": true, "report_reasons": null, "author": "Kratos_1412", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14x6c6f/apache_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14x6c6f/apache_kafka/", "subreddit_subscribers": 115423, "created_utc": 1689116033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everybody,  I have been trying to look at systems that process streaming data (downstream from Kafka).  One of the inputs to our decision-making process is to have a good understanding of the throughputs these systems/platforms can handle.  I was hoping that we don't have to set up all these environments and run a side-by-side comparison.  Do you have some suggestions on where I can find this information? ", "author_fullname": "t2_48nrgvyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benchmarks for stream processing systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14x3zux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689110618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody,  I have been trying to look at systems that process streaming data (downstream from Kafka).  One of the inputs to our decision-making process is to have a good understanding of the throughputs these systems/platforms can handle.  I was hoping that we don&amp;#39;t have to set up all these environments and run a side-by-side comparison.  Do you have some suggestions on where I can find this information? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14x3zux", "is_robot_indexable": true, "report_reasons": null, "author": "anupsurendran", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14x3zux/benchmarks_for_stream_processing_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14x3zux/benchmarks_for_stream_processing_systems/", "subreddit_subscribers": 115423, "created_utc": 1689110618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am investigating it  and I see that it has 2 limitations:\n\n1.  All tables created and updated by Delta Live Tables are Delta tables \n2. i can\u2019t customize their target delta table file paths to their desired location for bronze, silver or gold tables.\n\nin my organization we load data in bronze with its original format(could be json, parquet, etc) so we can not use DLT for this  if I am not mistaken and we can't use it either for a workflow with multiple notebooks that write in bronze , silver a gold successively.\n\nhow do you use DLT? which are the remaining use cases?\n\nthanks", "author_fullname": "t2_d6bmxkhw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do you use delta live tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14x2omf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689107698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am investigating it  and I see that it has 2 limitations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; All tables created and updated by Delta Live Tables are Delta tables &lt;/li&gt;\n&lt;li&gt;i can\u2019t customize their target delta table file paths to their desired location for bronze, silver or gold tables.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;in my organization we load data in bronze with its original format(could be json, parquet, etc) so we can not use DLT for this  if I am not mistaken and we can&amp;#39;t use it either for a workflow with multiple notebooks that write in bronze , silver a gold successively.&lt;/p&gt;\n\n&lt;p&gt;how do you use DLT? which are the remaining use cases?&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14x2omf", "is_robot_indexable": true, "report_reasons": null, "author": "PinPrestigious2327", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14x2omf/how_do_you_use_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14x2omf/how_do_you_use_delta_live_tables/", "subreddit_subscribers": 115423, "created_utc": 1689107698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is how it is done:\n\nApache Doris preserves multiple replicas of hot data and the metadata in its backend nodes, and cold data in object storage with only one copy.\n\nhttps://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=116202b543f7ad10392348ddb036a5e125c49081\n\nFull post about [hot-cold data separation](https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High availability of data without consuming too much storage space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"n5t2a43epibb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e93b5fcaf295957400ac50c724629865333f96e"}, {"y": 175, "x": 216, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d3c3d93f39247aba6281cf8abaf9705596906f8"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c900bec99726a420282e06f3c9511c60d807c49"}, {"y": 520, "x": 640, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=46886e8b513861fb5c44f981484edac60289ad1d"}, {"y": 780, "x": 960, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d547c8b465733f08671882765b3a471b95d4ea7"}, {"y": 878, "x": 1080, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2e00bd44ba6a0107a00507b4afb50b27dfd768a6"}], "s": {"y": 1041, "x": 1280, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=116202b543f7ad10392348ddb036a5e125c49081"}, "id": "n5t2a43epibb1"}}, "name": "t3_14xlmy3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cA-TRKk2RQNysgWZvGrT-7xphAfBnKQJyJcIU1Q-Mrg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1689160617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is how it is done:&lt;/p&gt;\n\n&lt;p&gt;Apache Doris preserves multiple replicas of hot data and the metadata in its backend nodes, and cold data in object storage with only one copy.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=116202b543f7ad10392348ddb036a5e125c49081\"&gt;https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=116202b543f7ad10392348ddb036a5e125c49081&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Full post about &lt;a href=\"https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf\"&gt;hot-cold data separation&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?auto=webp&amp;s=9bb433a2d2af7659bbd2aaefc86e6440fb099982", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cebf42d866ba39ad8401ec16025d2e683cb5ec5", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0db6f5ac30249427128f2acbef98d324f22c2d1b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34cbad55217597ab7e3e1f50abad3c5bc069e0d7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5bc2ca5a2ba66071e1827faae996f0dc6f6e329c", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f46f655bcbbc72ddca3942cdffe318e8677b8735", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8874a5ffe10ae71db18d29c8e4b5f59d830878fe", "width": 1080, "height": 720}], "variants": {}, "id": "XHYrsxQam1UsYnZQ-ImG7NyQc780qMXf4eXuq9sAgzc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14xlmy3", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xlmy3/high_availability_of_data_without_consuming_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xlmy3/high_availability_of_data_without_consuming_too/", "subreddit_subscribers": 115423, "created_utc": 1689160617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've all no doubt seen the [\"St. Albnas\"](https://www.reddit.com/r/dataengineering/comments/14442pi/we_have_great_datasets/) meme by now. Data quality is hard \ud83e\udd26\ud83c\udffb\u200d\u2642\ufe0f.\n\nTo have some fun with this, the company I work for (Tinybird) is sponsoring a little \"hackathon\". Clean the data and avoid false positives to get some swag. No winners and losers, just participation prizes! (yay millennials!)\n\nMake sure to read the rules, and have some fun with it!\n\n[https://github.com/tinybirdco/st-albnas-hackathon](https://github.com/tinybirdco/st-albnas-hackathon)", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"St. Albnas\" Hackathon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14xvfx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689183944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve all no doubt seen the &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14442pi/we_have_great_datasets/\"&gt;&amp;quot;St. Albnas&amp;quot;&lt;/a&gt; meme by now. Data quality is hard \ud83e\udd26\ud83c\udffb\u200d\u2642\ufe0f.&lt;/p&gt;\n\n&lt;p&gt;To have some fun with this, the company I work for (Tinybird) is sponsoring a little &amp;quot;hackathon&amp;quot;. Clean the data and avoid false positives to get some swag. No winners and losers, just participation prizes! (yay millennials!)&lt;/p&gt;\n\n&lt;p&gt;Make sure to read the rules, and have some fun with it!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/tinybirdco/st-albnas-hackathon\"&gt;https://github.com/tinybirdco/st-albnas-hackathon&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?auto=webp&amp;s=f0d96abead2cba1a7dcb3cd17af9aeee18d3b110", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=56cd9107ee58fa7c1de7d83a217464eb6edc661c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a032c60f128a58abe914c1be58fc4d197968b554", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cc621d87bd3645dd13b28c63cadc443dd7d9d708", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=880b60a66eaac91ceece4a1cd7fa73876c86604a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ffe2d888799e8c31a0af57a09bd1e70eb66d696", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/A6zUP6AmxZh5fcU9gZcyj8cCcmXM5E3lt4yBKwHl_t8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d3286eb4f4f474031681a6e19b9d2db3c9f2de5c", "width": 1080, "height": 540}], "variants": {}, "id": "GZPGBRybU-NIi8L9efQJzEa2WaNuknEOOl2vPCBbOfw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14xvfx1", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xvfx1/st_albnas_hackathon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xvfx1/st_albnas_hackathon/", "subreddit_subscribers": 115423, "created_utc": 1689183944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI was DS in Google and laid off 4 months ago and I couldn't find any DS position since then (Im living in Switzerland). And I find a great start up but they hiring data engineering position. I would really want to try it since I really like the culture of the company and I did a lot of pipelining in my DS role in Google. But I don't know how Data Eng case study interviews would be. I have no experience on that side and I can't find questions online, maybe i don't know how to search. Is there anyone can help me with mock interview for entry level positions? ", "author_fullname": "t2_78n8udb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to transition from DS to Data Eng, anyone wants to help with mock interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xtaru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689179129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I was DS in Google and laid off 4 months ago and I couldn&amp;#39;t find any DS position since then (Im living in Switzerland). And I find a great start up but they hiring data engineering position. I would really want to try it since I really like the culture of the company and I did a lot of pipelining in my DS role in Google. But I don&amp;#39;t know how Data Eng case study interviews would be. I have no experience on that side and I can&amp;#39;t find questions online, maybe i don&amp;#39;t know how to search. Is there anyone can help me with mock interview for entry level positions? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14xtaru", "is_robot_indexable": true, "report_reasons": null, "author": "hatidzhek", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xtaru/want_to_transition_from_ds_to_data_eng_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xtaru/want_to_transition_from_ds_to_data_eng_anyone/", "subreddit_subscribers": 115423, "created_utc": 1689179129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is recommended? Having your transformation done at S3 or in Redshift via stored.proecedure where S3 acts as a ODS with delta?", "author_fullname": "t2_b7vvf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redshift Vs S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xrl62", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689175412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is recommended? Having your transformation done at S3 or in Redshift via stored.proecedure where S3 acts as a ODS with delta?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xrl62", "is_robot_indexable": true, "report_reasons": null, "author": "planetabhi", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xrl62/redshift_vs_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xrl62/redshift_vs_s3/", "subreddit_subscribers": 115423, "created_utc": 1689175412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi team,\n\nI have ubuntu box where we run our python scripts of off.\n\nOne of my python scripts uses aws cli to extract data from....\n\nwhen i execute python script manually it will run.\n\nwhen i add this python script to run on crontab it starts...but doesnt go past 'aws cli command' executed almost at the very begining of python script.\n\nthe python script with aws CLI:\n\n \n\nsubprocess.run(\\[\"aws\", \"s3\", \"cp\", \"link\\_to\\_aws\\_stage\", \"download\\_to\\_path, \"--recursive\",\"--profile\",\"ABC\"\\])\n\n&amp;#x200B;\n\n**Question:**\n\nhow to workaround that?\n\nhow can i set which ubuntu users can access CLI ?\n\ndo you have any better idea\n\nthanks!\n\n&amp;#x200B;", "author_fullname": "t2_do9wxbfu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help with aws cli", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xqpch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689173421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi team,&lt;/p&gt;\n\n&lt;p&gt;I have ubuntu box where we run our python scripts of off.&lt;/p&gt;\n\n&lt;p&gt;One of my python scripts uses aws cli to extract data from....&lt;/p&gt;\n\n&lt;p&gt;when i execute python script manually it will run.&lt;/p&gt;\n\n&lt;p&gt;when i add this python script to run on crontab it starts...but doesnt go past &amp;#39;aws cli command&amp;#39; executed almost at the very begining of python script.&lt;/p&gt;\n\n&lt;p&gt;the python script with aws CLI:&lt;/p&gt;\n\n&lt;p&gt;subprocess.run([&amp;quot;aws&amp;quot;, &amp;quot;s3&amp;quot;, &amp;quot;cp&amp;quot;, &amp;quot;link_to_aws_stage&amp;quot;, &amp;quot;download_to_path, &amp;quot;--recursive&amp;quot;,&amp;quot;--profile&amp;quot;,&amp;quot;ABC&amp;quot;])&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;how to workaround that?&lt;/p&gt;\n\n&lt;p&gt;how can i set which ubuntu users can access CLI ?&lt;/p&gt;\n\n&lt;p&gt;do you have any better idea&lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xqpch", "is_robot_indexable": true, "report_reasons": null, "author": "87keicam", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xqpch/help_with_aws_cli/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xqpch/help_with_aws_cli/", "subreddit_subscribers": 115423, "created_utc": 1689173421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some background on myself. I recently transitioned into data engineering after 5 years as a data analyst and have been working at a startup since the beginning of the year on a contract basis. I'm practically the sole data engineer so I'm building end-to-end pipelines and I get to work with Python, SQL, DBT, Fivetran, Airflow, Postgres, MongoDB, Elasticsearch. I also do some Devops stuff - DigitalOcean is our main cloud service, but I also work with GCP and Azure (albeit at a surface level). I love the tech stack, but at the same time I'm worried I'm developing bad habits as an engineer since I'm working mostly independently and there's no proper CI/CD, at least for now. There's also no guarantee I'm gonna have a job in around 6 months since there's only a certain amount of money that's been reserved to fund my position, though there are efforts to get more funding.\n\nI recently received a job offer at a FinTech company where the core tech stack is DBT, SQL, Snowflake, and Airflow. Certain things that concern me:\n\n* Python seems to be a small part of the role. In my interview, they mentioned that Python would mostly be used to write up Airflow jobs. The job description also emphasizes more on SQL for deploying analytics code.\n* GCP, AWS or Azure not listed on job description. The team has devops engineers so I imagine they'll be the ones handling cloud infrastructure.\n* I've seen multiple job titles for the role, mainly \"Data Engineer\" and \"Analytics Engineer\". I asked them about this and they said that data and analytics engineers are one and the same to them, and they had put up the role under multiple titles to attract as many applicants as possible.\n\nSome positives I see for the role:\n\n* It's in a bigger proper engineering team, with a scrum master, other DevOps engineers, QA, etc. and CI/CD pipelines in place.\n* I got along well with the hiring manager, who really seems to know his stuff.\n* The team is rapidly expanding, which to me seems like a good sign.\n\nI've been applying to jobs for a couple months now, and I frequently see GCP/AWS/Azure experience as a requirement. Python is easily the most enjoyable part of my job, and I want to be viewed more as programmer or a SWE-focused DE in the long term rather than an analytics engineer or a SQL developer (no hate against these types of roles, they're just not what I'm looking for).\n\nAny advice would be greatly appreciated!\n\nEdit: Revised bullet point on cloud services", "author_fullname": "t2_3bhqq33p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take this job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xqg8d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689177749.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689172853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some background on myself. I recently transitioned into data engineering after 5 years as a data analyst and have been working at a startup since the beginning of the year on a contract basis. I&amp;#39;m practically the sole data engineer so I&amp;#39;m building end-to-end pipelines and I get to work with Python, SQL, DBT, Fivetran, Airflow, Postgres, MongoDB, Elasticsearch. I also do some Devops stuff - DigitalOcean is our main cloud service, but I also work with GCP and Azure (albeit at a surface level). I love the tech stack, but at the same time I&amp;#39;m worried I&amp;#39;m developing bad habits as an engineer since I&amp;#39;m working mostly independently and there&amp;#39;s no proper CI/CD, at least for now. There&amp;#39;s also no guarantee I&amp;#39;m gonna have a job in around 6 months since there&amp;#39;s only a certain amount of money that&amp;#39;s been reserved to fund my position, though there are efforts to get more funding.&lt;/p&gt;\n\n&lt;p&gt;I recently received a job offer at a FinTech company where the core tech stack is DBT, SQL, Snowflake, and Airflow. Certain things that concern me:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python seems to be a small part of the role. In my interview, they mentioned that Python would mostly be used to write up Airflow jobs. The job description also emphasizes more on SQL for deploying analytics code.&lt;/li&gt;\n&lt;li&gt;GCP, AWS or Azure not listed on job description. The team has devops engineers so I imagine they&amp;#39;ll be the ones handling cloud infrastructure.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve seen multiple job titles for the role, mainly &amp;quot;Data Engineer&amp;quot; and &amp;quot;Analytics Engineer&amp;quot;. I asked them about this and they said that data and analytics engineers are one and the same to them, and they had put up the role under multiple titles to attract as many applicants as possible.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Some positives I see for the role:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s in a bigger proper engineering team, with a scrum master, other DevOps engineers, QA, etc. and CI/CD pipelines in place.&lt;/li&gt;\n&lt;li&gt;I got along well with the hiring manager, who really seems to know his stuff.&lt;/li&gt;\n&lt;li&gt;The team is rapidly expanding, which to me seems like a good sign.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve been applying to jobs for a couple months now, and I frequently see GCP/AWS/Azure experience as a requirement. Python is easily the most enjoyable part of my job, and I want to be viewed more as programmer or a SWE-focused DE in the long term rather than an analytics engineer or a SQL developer (no hate against these types of roles, they&amp;#39;re just not what I&amp;#39;m looking for).&lt;/p&gt;\n\n&lt;p&gt;Any advice would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: Revised bullet point on cloud services&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xqg8d", "is_robot_indexable": true, "report_reasons": null, "author": "timbaktubear", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xqg8d/should_i_take_this_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xqg8d/should_i_take_this_job/", "subreddit_subscribers": 115423, "created_utc": 1689172853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Follow up post: [Previous post](https://www.reddit.com/r/dataengineering/comments/14o8h6h/data_engineer_looking_to_study_mechanical/?utm_source=share&amp;utm_medium=web2x&amp;context=3)\n\nHello, So as you know from last time, I was working on a GKE project, where I deployed a docker image that retrieves data from ADH and inserts it into BigQuery, Thank you everyone for your recommendation and your advices, I finally managed to finish the project, I scheduled, everything works perfectly!! My question is: how can I further improve the project by automating the deployment process? I was thinking of terraform and ansible, but I'm here once again to ask about your opinion, and if you have any advice!! \n\nEdit: I used Makefile but I think it's a bit clumsy \n\nTL;DR I want to automate the deployment process of pushing an image to artifact registry on google + apply workload cronjobs using ansible/terraform, Any advices? :D", "author_fullname": "t2_5u3c1gj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automate GKE deployment process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xj1mi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689152860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Follow up post: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14o8h6h/data_engineer_looking_to_study_mechanical/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;Previous post&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hello, So as you know from last time, I was working on a GKE project, where I deployed a docker image that retrieves data from ADH and inserts it into BigQuery, Thank you everyone for your recommendation and your advices, I finally managed to finish the project, I scheduled, everything works perfectly!! My question is: how can I further improve the project by automating the deployment process? I was thinking of terraform and ansible, but I&amp;#39;m here once again to ask about your opinion, and if you have any advice!! &lt;/p&gt;\n\n&lt;p&gt;Edit: I used Makefile but I think it&amp;#39;s a bit clumsy &lt;/p&gt;\n\n&lt;p&gt;TL;DR I want to automate the deployment process of pushing an image to artifact registry on google + apply workload cronjobs using ansible/terraform, Any advices? :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xj1mi", "is_robot_indexable": true, "report_reasons": null, "author": "iGodFather302", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xj1mi/automate_gke_deployment_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xj1mi/automate_gke_deployment_process/", "subreddit_subscribers": 115423, "created_utc": 1689152860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\nI have platform basing on Kafka. A lot of events go through various topics. I am writting streaming app to process events in real time(join on streams are possible). I consider Kafka Streams and Flink as a streaming technologies. My first thought was to use Kafka Streams but I heard that there is some problem with inner Kafka topics during join operations. Could uou gove me some advice what would u use?", "author_fullname": "t2_omva4fi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink or Kafka Streams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xhrhj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689148809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nI have platform basing on Kafka. A lot of events go through various topics. I am writting streaming app to process events in real time(join on streams are possible). I consider Kafka Streams and Flink as a streaming technologies. My first thought was to use Kafka Streams but I heard that there is some problem with inner Kafka topics during join operations. Could uou gove me some advice what would u use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xhrhj", "is_robot_indexable": true, "report_reasons": null, "author": "BigDataMax", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xhrhj/flink_or_kafka_streams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xhrhj/flink_or_kafka_streams/", "subreddit_subscribers": 115423, "created_utc": 1689148809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI'm on a relatively small and new Data Science team and currently trying to figure out the best tech stack/practices for deploying ML models. Right now we use BigQuery for our data base, DBT for the SQL pipeline (am I even referring to it properly?), and VertexAI workbench where the modeling and experimentation is done, and then a BitBucket repo. There is Airflow usage among the data engineers in other teams so there is a precedent there as far as orchestration goes.\n\nGiven that most of my past experience has focused on ad-hoc experimentation and not actual deployment, was hoping to get some general advice on how to set certain pipelines. \n\nUltimately, going forward the current suite of models will have to be retrained on a weekly basis, and the results will have to be uploaded to an environment where analysts can interface with the results.\n\n Currently trying to figure out best practices for building a robust pipeline given the tools we have above and was hoping to get some community feedback from more seasoned engineers.\n\nRight now most of the models are retrained manually.\n\n&amp;#x200B;\n\nGeneral outline of a pipeline that is currently in use that I feel needs to be refactored. \n\n1.)  SQL queries to pull data into python environment, where feature engineering in performed. (Some of the features are generated in the SQL queries where possible). Features are created using functions and the table with the target variable and features are written to a new table in GCP.\n\n2.)  In a separate script, read in the feature table, and then proceed to do some training (train-test splits / Cross Valdiation / Hyperparameter tuning) -&gt; hyper parameters are saved in a pickle file. Final model is trained using the found hyper paramters -&gt; final model saved in pickle file. \n\n3.) In separate script, the feature table is again read into python and the model is loaded from pickle and used to generate the output we need. The predicted values are then read into a final big query table which is referenced by analysts/data engineers for client facing platform.\n\n&amp;#x200B;\n\nWhat would be some better ways of structuring the pipeline above, or are there github ML pipeline examples that exist that I can learn from?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_bf43tms01", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applying Data Engineering best practices to ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14x1r3k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689105657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on a relatively small and new Data Science team and currently trying to figure out the best tech stack/practices for deploying ML models. Right now we use BigQuery for our data base, DBT for the SQL pipeline (am I even referring to it properly?), and VertexAI workbench where the modeling and experimentation is done, and then a BitBucket repo. There is Airflow usage among the data engineers in other teams so there is a precedent there as far as orchestration goes.&lt;/p&gt;\n\n&lt;p&gt;Given that most of my past experience has focused on ad-hoc experimentation and not actual deployment, was hoping to get some general advice on how to set certain pipelines. &lt;/p&gt;\n\n&lt;p&gt;Ultimately, going forward the current suite of models will have to be retrained on a weekly basis, and the results will have to be uploaded to an environment where analysts can interface with the results.&lt;/p&gt;\n\n&lt;p&gt;Currently trying to figure out best practices for building a robust pipeline given the tools we have above and was hoping to get some community feedback from more seasoned engineers.&lt;/p&gt;\n\n&lt;p&gt;Right now most of the models are retrained manually.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;General outline of a pipeline that is currently in use that I feel needs to be refactored. &lt;/p&gt;\n\n&lt;p&gt;1.)  SQL queries to pull data into python environment, where feature engineering in performed. (Some of the features are generated in the SQL queries where possible). Features are created using functions and the table with the target variable and features are written to a new table in GCP.&lt;/p&gt;\n\n&lt;p&gt;2.)  In a separate script, read in the feature table, and then proceed to do some training (train-test splits / Cross Valdiation / Hyperparameter tuning) -&amp;gt; hyper parameters are saved in a pickle file. Final model is trained using the found hyper paramters -&amp;gt; final model saved in pickle file. &lt;/p&gt;\n\n&lt;p&gt;3.) In separate script, the feature table is again read into python and the model is loaded from pickle and used to generate the output we need. The predicted values are then read into a final big query table which is referenced by analysts/data engineers for client facing platform.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What would be some better ways of structuring the pipeline above, or are there github ML pipeline examples that exist that I can learn from?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14x1r3k", "is_robot_indexable": true, "report_reasons": null, "author": "lyrical_empirical", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14x1r3k/applying_data_engineering_best_practices_to_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14x1r3k/applying_data_engineering_best_practices_to_ml/", "subreddit_subscribers": 115423, "created_utc": 1689105657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work in a healthcare company. We use SSIS and SSMS (SQL) for most of our data needs. On the rare occasion, we also use C#, Python, and Powershell. Is this stack good enough to start job hunting or would it be better to pick up some software-specific skills? I thought about learning GCP or AWS but am not sure the likelihood of getting hired with only self-study on those topics. I've been at my current company for 8 years (intern -&gt; data analyst -&gt; database engineer) and it's a good environment / fully remote, but the money just isn't there. I'm currently making $75k/80k a year depending on bonus and yearly raises are 2%. ", "author_fullname": "t2_1b2ivfkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to further career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14xwkrp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689186554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work in a healthcare company. We use SSIS and SSMS (SQL) for most of our data needs. On the rare occasion, we also use C#, Python, and Powershell. Is this stack good enough to start job hunting or would it be better to pick up some software-specific skills? I thought about learning GCP or AWS but am not sure the likelihood of getting hired with only self-study on those topics. I&amp;#39;ve been at my current company for 8 years (intern -&amp;gt; data analyst -&amp;gt; database engineer) and it&amp;#39;s a good environment / fully remote, but the money just isn&amp;#39;t there. I&amp;#39;m currently making $75k/80k a year depending on bonus and yearly raises are 2%. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xwkrp", "is_robot_indexable": true, "report_reasons": null, "author": "WhelminglyMediocre", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xwkrp/how_to_further_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xwkrp/how_to_further_career/", "subreddit_subscribers": 115423, "created_utc": 1689186554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any recommended DSA book ?\n\n&amp;#x200B;", "author_fullname": "t2_ssw3so1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "find DSA books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14xvrmx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689184704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any recommended DSA book ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xvrmx", "is_robot_indexable": true, "report_reasons": null, "author": "datapopcorn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xvrmx/find_dsa_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xvrmx/find_dsa_books/", "subreddit_subscribers": 115423, "created_utc": 1689184704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone ,\n\nI have a lot of HTML files saved in txt on my raw container, and I have to extract only the necessary information from them.Each html file could become a JSON, because they have some levels of nested information.\n\nWhat transformation would be the best in that case to make the data more structured to silver/structured layer?\n\nCreate a JSON?\n\nCreate a parquet file for each html, but duplicate data from the first nests?\n\nCreate a parquet file for each nest with a key to join them in the database?\n\nOr any other path that u guys have in mind?  \n\n\n&amp;#x200B;", "author_fullname": "t2_2t4hdsut", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with HTML files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xqces", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689172615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone ,&lt;/p&gt;\n\n&lt;p&gt;I have a lot of HTML files saved in txt on my raw container, and I have to extract only the necessary information from them.Each html file could become a JSON, because they have some levels of nested information.&lt;/p&gt;\n\n&lt;p&gt;What transformation would be the best in that case to make the data more structured to silver/structured layer?&lt;/p&gt;\n\n&lt;p&gt;Create a JSON?&lt;/p&gt;\n\n&lt;p&gt;Create a parquet file for each html, but duplicate data from the first nests?&lt;/p&gt;\n\n&lt;p&gt;Create a parquet file for each nest with a key to join them in the database?&lt;/p&gt;\n\n&lt;p&gt;Or any other path that u guys have in mind?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xqces", "is_robot_indexable": true, "report_reasons": null, "author": "ltofanelli", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xqces/working_with_html_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xqces/working_with_html_files/", "subreddit_subscribers": 115423, "created_utc": 1689172615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI have been a lurker forever in this sub and today i have decided to know your opinions in some points regarding the implementation of functional programming in Data Engineering (DE).\n\nAfter reading around this paradigm (most articles i have found converge to [Maxime Beauchemin article](https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a)), there are two points that makes my head scratch a bit:\n\n&amp;#x200B;\n\n* **Dimensional snapshots**:  The fact that this can create a lot of redundancy in dimensional tables, this really does not sound like a problem to me. I actually like the fact that with this approach avoids upserts and SCD's by just re-processing the data in a given time period. What i would like to understand is, for those who already implemented dimension snapshots, if the redundancy on the tables took a toll on the visualization tools performance big enough for you to get back to SCDs or something hybrid.\n* **Late arriving facts**: this is the point that really makes me avoid functional programming. Knowing that to we have to center our focus based on the event reception or processing time and not on the event time, it means in my opinion that the dimension partition scheme should be based on the event processing time too. However, the analysts surely do their work based on the event time which it will not benefit from the partition pruning. That could make any query based on the event time be way more costly.\n\nTake in note that i have been working more recently with BigQuery, in which the storage capacity is not a problem and you can partition a table with one column only (aside from clustering). Even in platforms that allows tables with multiple partitions i still think the second point potential costs and performance can be heavily affected.\n\nTake in account these two points, you think functional programming still can be something worth to implement in DE context?\n\nI hope my doubts were clear enough for you to share your take. Best regards!\n\n&amp;#x200B;", "author_fullname": "t2_4errm1ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Funtional Programming in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xq53v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689172144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have been a lurker forever in this sub and today i have decided to know your opinions in some points regarding the implementation of functional programming in Data Engineering (DE).&lt;/p&gt;\n\n&lt;p&gt;After reading around this paradigm (most articles i have found converge to &lt;a href=\"https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a\"&gt;Maxime Beauchemin article&lt;/a&gt;), there are two points that makes my head scratch a bit:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Dimensional snapshots&lt;/strong&gt;:  The fact that this can create a lot of redundancy in dimensional tables, this really does not sound like a problem to me. I actually like the fact that with this approach avoids upserts and SCD&amp;#39;s by just re-processing the data in a given time period. What i would like to understand is, for those who already implemented dimension snapshots, if the redundancy on the tables took a toll on the visualization tools performance big enough for you to get back to SCDs or something hybrid.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Late arriving facts&lt;/strong&gt;: this is the point that really makes me avoid functional programming. Knowing that to we have to center our focus based on the event reception or processing time and not on the event time, it means in my opinion that the dimension partition scheme should be based on the event processing time too. However, the analysts surely do their work based on the event time which it will not benefit from the partition pruning. That could make any query based on the event time be way more costly.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Take in note that i have been working more recently with BigQuery, in which the storage capacity is not a problem and you can partition a table with one column only (aside from clustering). Even in platforms that allows tables with multiple partitions i still think the second point potential costs and performance can be heavily affected.&lt;/p&gt;\n\n&lt;p&gt;Take in account these two points, you think functional programming still can be something worth to implement in DE context?&lt;/p&gt;\n\n&lt;p&gt;I hope my doubts were clear enough for you to share your take. Best regards!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?auto=webp&amp;s=cf073d9e898ab6b6aac9cbd3d617eb1a8d77093f", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e6ca8361de7a95cb6c47013c1938266c06cf1bff", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fae9102fa6d32f067e38cc3b24cc65481bb6ed33", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3efad0c05c8737f8d5c4ac99e42e7579dd97057", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4e73a5bddad916ba74ea62469de010438a9a993", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1fada96526d687a1d1efd7a1d8d1e5d7d033d9c8", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/XW0ef_VBf4RJSfDgg9pqQAOBt7SyX-VVlLvDbPwGbFE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd93c47a0b2c95deabadee9d4fe6e3cc05529c5e", "width": 1080, "height": 720}], "variants": {}, "id": "QnHDt9HlR913WRkisNYJkFlw9Lr3Bt7UcxRxAQAkPdY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xq53v", "is_robot_indexable": true, "report_reasons": null, "author": "lou1uol", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xq53v/funtional_programming_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xq53v/funtional_programming_in_data_engineering/", "subreddit_subscribers": 115423, "created_utc": 1689172144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm running Spark cluster in standalone mode and doing `spark-submit` to submit Spark applications in `client` deploy mode. I would like to get the status (whether success or failure) of the Spark application.\n\nThe reason I have to use `client` deploy mode is that, we are running both Scala and Python Spark applications and `cluster` deploy mode does not support Python Spark applications by now.\n\nThe approach I can think of is to start the Spark history server and then use [its REST endpoint](https://spark.apache.org/docs/latest/monitoring.html#rest-api) to query for status from `&lt;app-id&gt;` and looking for whether there's failed job under the app (Because unfortunately, `spark-master:8080/json` only gives whether the app is running or completed, not fail/succeed). Next, to get the app-id in `client` deploy mode, I have to grep and match the log4j line\n\n```\nStandaloneSchedulerBackend: Connected to Spark cluster with app ID app-xxxxxxx-xxx\n```\n\nI'm wondering is there better approach than this, I've been searching around, but the solution given is all for YARN or `cluster` deploy mode.", "author_fullname": "t2_nerz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retrieve the status(failure/success) of Spark application in Spark Standalone mode with client deploy mode", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xprdy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689171250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running Spark cluster in standalone mode and doing &lt;code&gt;spark-submit&lt;/code&gt; to submit Spark applications in &lt;code&gt;client&lt;/code&gt; deploy mode. I would like to get the status (whether success or failure) of the Spark application.&lt;/p&gt;\n\n&lt;p&gt;The reason I have to use &lt;code&gt;client&lt;/code&gt; deploy mode is that, we are running both Scala and Python Spark applications and &lt;code&gt;cluster&lt;/code&gt; deploy mode does not support Python Spark applications by now.&lt;/p&gt;\n\n&lt;p&gt;The approach I can think of is to start the Spark history server and then use &lt;a href=\"https://spark.apache.org/docs/latest/monitoring.html#rest-api\"&gt;its REST endpoint&lt;/a&gt; to query for status from &lt;code&gt;&amp;lt;app-id&amp;gt;&lt;/code&gt; and looking for whether there&amp;#39;s failed job under the app (Because unfortunately, &lt;code&gt;spark-master:8080/json&lt;/code&gt; only gives whether the app is running or completed, not fail/succeed). Next, to get the app-id in &lt;code&gt;client&lt;/code&gt; deploy mode, I have to grep and match the log4j line&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\nStandaloneSchedulerBackend: Connected to Spark cluster with app ID app-xxxxxxx-xxx\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering is there better approach than this, I&amp;#39;ve been searching around, but the solution given is all for YARN or &lt;code&gt;cluster&lt;/code&gt; deploy mode.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xprdy", "is_robot_indexable": true, "report_reasons": null, "author": "XIAOAGE", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xprdy/retrieve_the_statusfailuresuccess_of_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xprdy/retrieve_the_statusfailuresuccess_of_spark/", "subreddit_subscribers": 115423, "created_utc": 1689171250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m proficient in Tableau, SQL, Alteryx, and Excel. Been stuck in the corporate reporting world for a bit too long and I\u2019d like to advance my skill set. \n\nI\u2019m going to try and stretch for a job that will have me working with SSIS, Automic, Databricks, Fivetran, Medallia architecture, and DBT. I don\u2019t know what any of these things are, not even at a basic level. My friend is the hiring manager so I\u2019ll have a leg up, but I need to be at least conversant in these tools and technologies. \n\nOf course I will be YouTubing and googling these things myself, but figured I\u2019d ask if anyone here knows of a particularly great resource, course, book, etc that provides good coverage of the things I listed, and is catered to someone with my background. Thanks in advance!", "author_fullname": "t2_4mo8008p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips on leveling up from business intelligence to data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xoa4g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m proficient in Tableau, SQL, Alteryx, and Excel. Been stuck in the corporate reporting world for a bit too long and I\u2019d like to advance my skill set. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m going to try and stretch for a job that will have me working with SSIS, Automic, Databricks, Fivetran, Medallia architecture, and DBT. I don\u2019t know what any of these things are, not even at a basic level. My friend is the hiring manager so I\u2019ll have a leg up, but I need to be at least conversant in these tools and technologies. &lt;/p&gt;\n\n&lt;p&gt;Of course I will be YouTubing and googling these things myself, but figured I\u2019d ask if anyone here knows of a particularly great resource, course, book, etc that provides good coverage of the things I listed, and is catered to someone with my background. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xoa4g", "is_robot_indexable": true, "report_reasons": null, "author": "philspyderman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xoa4g/tips_on_leveling_up_from_business_intelligence_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xoa4g/tips_on_leveling_up_from_business_intelligence_to/", "subreddit_subscribers": 115423, "created_utc": 1689167660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Nomenclature is something I don't see brought very often in this subreddit. What naming conventions do you use when it comes to naming tables/jobs/individual pipelines and such, if any?", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What naming conventions do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xncko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689165260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Nomenclature is something I don&amp;#39;t see brought very often in this subreddit. What naming conventions do you use when it comes to naming tables/jobs/individual pipelines and such, if any?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xncko", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xncko/what_naming_conventions_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xncko/what_naming_conventions_do_you_use/", "subreddit_subscribers": 115423, "created_utc": 1689165260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m 2.5 years into my career as a DE.  I\u2019ve got my EL and data modeling skills pretty well developed, but I am rather weak in the analytics aspect.\n\nWhen I say analytics, I mean extracting value from the data I provide.  I can move, organize, and document data very reliably, but I have no idea what BI folks actually *do* with the data.\n\nI\u2019ve tried asking questions to get a better understanding, but they\u2019re busy, and I\u2019m really lacking foundational knowledge on metrics and BI terminology/methodologies to keep up with the conversation.\n\nAnyone know of good books or resources to get up to speed?", "author_fullname": "t2_ez9lptk5m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for learning more about data &amp; analytics products", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xgo7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689145025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m 2.5 years into my career as a DE.  I\u2019ve got my EL and data modeling skills pretty well developed, but I am rather weak in the analytics aspect.&lt;/p&gt;\n\n&lt;p&gt;When I say analytics, I mean extracting value from the data I provide.  I can move, organize, and document data very reliably, but I have no idea what BI folks actually &lt;em&gt;do&lt;/em&gt; with the data.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried asking questions to get a better understanding, but they\u2019re busy, and I\u2019m really lacking foundational knowledge on metrics and BI terminology/methodologies to keep up with the conversation.&lt;/p&gt;\n\n&lt;p&gt;Anyone know of good books or resources to get up to speed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xgo7v", "is_robot_indexable": true, "report_reasons": null, "author": "dr-data-2001", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xgo7v/resources_for_learning_more_about_data_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xgo7v/resources_for_learning_more_about_data_analytics/", "subreddit_subscribers": 115423, "created_utc": 1689145025.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}