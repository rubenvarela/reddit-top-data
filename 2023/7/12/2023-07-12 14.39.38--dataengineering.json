{"kind": "Listing", "data": {"after": "t3_14xlmy3", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So many people think data engineers are only responsible for building data pipelines.\n\nBut in reality, if you are doing a data lake project, you may also need to understand the cloud infra (VPC, IP, DBA infra, Terraform, K8s).\n\nAs a data engineer, I think being a cloud engineer is better than being a data engineer.", "author_fullname": "t2_txqvauef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer isn\u2019t really just data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wv6f6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689090964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So many people think data engineers are only responsible for building data pipelines.&lt;/p&gt;\n\n&lt;p&gt;But in reality, if you are doing a data lake project, you may also need to understand the cloud infra (VPC, IP, DBA infra, Terraform, K8s).&lt;/p&gt;\n\n&lt;p&gt;As a data engineer, I think being a cloud engineer is better than being a data engineer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14wv6f6", "is_robot_indexable": true, "report_reasons": null, "author": "Dice__R", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wv6f6/data_engineer_isnt_really_just_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wv6f6/data_engineer_isnt_really_just_data_engineering/", "subreddit_subscribers": 115384, "created_utc": 1689090964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got into a data engineering role, it's my first job as a DE. And i am feeling absolutely lost, i don't understand what's happening, everything is everywhere, my team mates are very busy so no one properly explains what's happening and some structural change is happening in the whole section of DE teams. And I feel absolutely overwhelmed.\nHow do you tackle this?", "author_fullname": "t2_vn1meuc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal to feel completely lost during initial months of your data engineering job ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xhi13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689147891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got into a data engineering role, it&amp;#39;s my first job as a DE. And i am feeling absolutely lost, i don&amp;#39;t understand what&amp;#39;s happening, everything is everywhere, my team mates are very busy so no one properly explains what&amp;#39;s happening and some structural change is happening in the whole section of DE teams. And I feel absolutely overwhelmed.\nHow do you tackle this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xhi13", "is_robot_indexable": true, "report_reasons": null, "author": "jojobaoil68", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xhi13/is_it_normal_to_feel_completely_lost_during/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xhi13/is_it_normal_to_feel_completely_lost_during/", "subreddit_subscribers": 115384, "created_utc": 1689147891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Preview of Stream Processing Performance Report: Apache Flink and RisingWave Comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14wyfs8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HxoROitqUJU4SYhu2S-EC6aowSdO-lrcU7aINgUyO_U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689098237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.risingwave.com/blog/the-preview-of-stream-processing-performance-report-apache-flink-and-risingwave-comparison/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-7HvcLxR-vh5bcGn9Bmgg0lFlcDGq7SXGm3BpZSLSTs.jpg?auto=webp&amp;s=4deee54975213003aec428e9b2faf715ceeb8a9e", "width": 3533, "height": 4416}, "resolutions": [{"url": "https://external-preview.redd.it/-7HvcLxR-vh5bcGn9Bmgg0lFlcDGq7SXGm3BpZSLSTs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=401403de7e9c1b96af97472763bfd0882fa727e0", "width": 108, "height": 134}, {"url": "https://external-preview.redd.it/-7HvcLxR-vh5bcGn9Bmgg0lFlcDGq7SXGm3BpZSLSTs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ec792cc44c027d23d038ebcfdea53bc3fcc9ff0f", "width": 216, "height": 269}, {"url": "https://external-preview.redd.it/-7HvcLxR-vh5bcGn9Bmgg0lFlcDGq7SXGm3BpZSLSTs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=615a86f8745b609a69ff1c2242acbf844fd1390a", "width": 320, "height": 399}, {"url": "https://external-preview.redd.it/-7HvcLxR-vh5bcGn9Bmgg0lFlcDGq7SXGm3BpZSLSTs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=73f1f340d3347c1f01097bdb4d9fdd0896d68c86", "width": 640, "height": 799}, {"url": "https://external-preview.redd.it/-7HvcLxR-vh5bcGn9Bmgg0lFlcDGq7SXGm3BpZSLSTs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8bdf6a920792de1f278c6a275f94095917980d06", "width": 960, "height": 1199}, {"url": "https://external-preview.redd.it/-7HvcLxR-vh5bcGn9Bmgg0lFlcDGq7SXGm3BpZSLSTs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f03e2ead490eea564f8a4dde10254d893682d1c9", "width": 1080, "height": 1349}], "variants": {}, "id": "x9k2v5bDNTokkZtW3CyOE1b1tJfRb5BBOgn4eEE4Rso"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14wyfs8", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wyfs8/the_preview_of_stream_processing_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.risingwave.com/blog/the-preview-of-stream-processing-performance-report-apache-flink-and-risingwave-comparison/", "subreddit_subscribers": 115384, "created_utc": 1689098237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone - for context I'm a DE with \\~3 YoE that I spent working in a small startup where I was, *for the most part*, the sole DE.  \nI was responsible for not only implementing an end-to-end data pipeline that handles data from ingestion to analytics dashboards but also built the websockets and APIs needed to interact with different parts of the pipeline - which I really liked.\n\nAround a month ago I got the opportunity to join a big company as a DE, both the job listing and the interview had big emphasis on experience with end-to-end data pipelines and good SWE practices.\n\nI figured this would be a great opportunity to work with more experienced engineers on a project with significantly more data than what I'm used to.\n\nThe data stack is: Airflow - dbt (core) - AWS S3 (data lake) - AWS Redshift (dw) - Quicksight.\n\nMost of the tasks I pick up involve building dbt models, solving merge conflicts, configuring Airflow DAGs or sometimes assisting the analytics team.\n\nThe good thing is that the company has a great data culture and big emphasis on CI/CD and good SWE practices - they also insist on having DEs handle the building of dbt models and query optimization which is a good thing imo.\n\nMy major concern however is that the role doesn't feel as technically challenging as I was hoping for it to be, so do you guys think this is a good position to progress my career long term *from a technical standpoint* or should I keep an eye on other opportunities ?", "author_fullname": "t2_pna4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joined a new company as a DE for a big project and I'm feeling a bit underwhelmed - Would like to hear a second opinion.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xkfjd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689157100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone - for context I&amp;#39;m a DE with ~3 YoE that I spent working in a small startup where I was, &lt;em&gt;for the most part&lt;/em&gt;, the sole DE.&lt;br/&gt;\nI was responsible for not only implementing an end-to-end data pipeline that handles data from ingestion to analytics dashboards but also built the websockets and APIs needed to interact with different parts of the pipeline - which I really liked.&lt;/p&gt;\n\n&lt;p&gt;Around a month ago I got the opportunity to join a big company as a DE, both the job listing and the interview had big emphasis on experience with end-to-end data pipelines and good SWE practices.&lt;/p&gt;\n\n&lt;p&gt;I figured this would be a great opportunity to work with more experienced engineers on a project with significantly more data than what I&amp;#39;m used to.&lt;/p&gt;\n\n&lt;p&gt;The data stack is: Airflow - dbt (core) - AWS S3 (data lake) - AWS Redshift (dw) - Quicksight.&lt;/p&gt;\n\n&lt;p&gt;Most of the tasks I pick up involve building dbt models, solving merge conflicts, configuring Airflow DAGs or sometimes assisting the analytics team.&lt;/p&gt;\n\n&lt;p&gt;The good thing is that the company has a great data culture and big emphasis on CI/CD and good SWE practices - they also insist on having DEs handle the building of dbt models and query optimization which is a good thing imo.&lt;/p&gt;\n\n&lt;p&gt;My major concern however is that the role doesn&amp;#39;t feel as technically challenging as I was hoping for it to be, so do you guys think this is a good position to progress my career long term &lt;em&gt;from a technical standpoint&lt;/em&gt; or should I keep an eye on other opportunities ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xkfjd", "is_robot_indexable": true, "report_reasons": null, "author": "King_TN", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xkfjd/joined_a_new_company_as_a_de_for_a_big_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xkfjd/joined_a_new_company_as_a_de_for_a_big_project/", "subreddit_subscribers": 115384, "created_utc": 1689157100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Backdrop:\nI am using pyspark on AWS EMR (22G Mem available, 8 VCores). Trying to process 12 Billion Rows. \n( I am using default settings for memory and executors, new to spark and for lack of better words, dont know how to fix them optimally)\n\nWhat my job does:\nReads two dataframes, crossjoins and writes the output. ( Yes, crossjoin is costly but thats what my requirement is, map every row to everyother row)\n\nProblem:\nSpark creates 200 tasks at Stage 1, 199 get executed instantly and the remaining task doesn't even get executed in another hour. The issue being, 1 task is being run on a single executor so the second executor is being killed by the driver for sitting idle. ( I want both executors, since there are some stages that will come after this particular stage is executed)\n\nWhats already tried:\n1) No, I cant use a broadcast join(both dataset have equal rows)\n2) Data skew seems to be an issue but I repartition the data before and after the join ( among the 400 partition, data varies from habing 28 million to 32 million records, I guess it isnt that skewed afterall)\n\n\nPlease help me get over this menace, been stuck here for the past 2 days. My managers been poking me lol.", "author_fullname": "t2_t9iw9tl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help from Spark Gurus", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wwzs9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689094975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Backdrop:\nI am using pyspark on AWS EMR (22G Mem available, 8 VCores). Trying to process 12 Billion Rows. \n( I am using default settings for memory and executors, new to spark and for lack of better words, dont know how to fix them optimally)&lt;/p&gt;\n\n&lt;p&gt;What my job does:\nReads two dataframes, crossjoins and writes the output. ( Yes, crossjoin is costly but thats what my requirement is, map every row to everyother row)&lt;/p&gt;\n\n&lt;p&gt;Problem:\nSpark creates 200 tasks at Stage 1, 199 get executed instantly and the remaining task doesn&amp;#39;t even get executed in another hour. The issue being, 1 task is being run on a single executor so the second executor is being killed by the driver for sitting idle. ( I want both executors, since there are some stages that will come after this particular stage is executed)&lt;/p&gt;\n\n&lt;p&gt;Whats already tried:\n1) No, I cant use a broadcast join(both dataset have equal rows)\n2) Data skew seems to be an issue but I repartition the data before and after the join ( among the 400 partition, data varies from habing 28 million to 32 million records, I guess it isnt that skewed afterall)&lt;/p&gt;\n\n&lt;p&gt;Please help me get over this menace, been stuck here for the past 2 days. My managers been poking me lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14wwzs9", "is_robot_indexable": true, "report_reasons": null, "author": "Straight-End4310", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wwzs9/need_help_from_spark_gurus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wwzs9/need_help_from_spark_gurus/", "subreddit_subscribers": 115384, "created_utc": 1689094975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ll be doing my last semester this upcoming fall at my university for their masters of science in data engineering. I currently work as a frontend developer. Now, I know that data engineering and frontend are not remotely close, but I needed a place to start working while completing my degree and the market wasn\u2019t doing too hot, so I took this job (and I also hated my previous job). \n\nSome classes that I took include machine learning, big data and data science, a database and a distributed databases, data visualization,  multimedia processing, and information retrieval and web search. There are some others that I can\u2019t remember, but I\u2019ll be taking NPL and computer security in the fall. \n\nMy plan is to stay at my job for about a year from now as I\u2019ve been with them for 8 months and I\u2019ve only stayed at my previous job for 6 months. I\u2019m planning to take that year as interview prep time. I\u2019m not expecting to get a job right into a FAANG, but I would like a data engineering job with a higher salary than what I currently make as a frontend developer ($70k a year in Dallas,TX with no prior experience). \n\nAny advice is greatly appreciated", "author_fullname": "t2_a1k04ei0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Graduating with a masters in data engineering. What advice do you have for job hunting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wsjy0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689084764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll be doing my last semester this upcoming fall at my university for their masters of science in data engineering. I currently work as a frontend developer. Now, I know that data engineering and frontend are not remotely close, but I needed a place to start working while completing my degree and the market wasn\u2019t doing too hot, so I took this job (and I also hated my previous job). &lt;/p&gt;\n\n&lt;p&gt;Some classes that I took include machine learning, big data and data science, a database and a distributed databases, data visualization,  multimedia processing, and information retrieval and web search. There are some others that I can\u2019t remember, but I\u2019ll be taking NPL and computer security in the fall. &lt;/p&gt;\n\n&lt;p&gt;My plan is to stay at my job for about a year from now as I\u2019ve been with them for 8 months and I\u2019ve only stayed at my previous job for 6 months. I\u2019m planning to take that year as interview prep time. I\u2019m not expecting to get a job right into a FAANG, but I would like a data engineering job with a higher salary than what I currently make as a frontend developer ($70k a year in Dallas,TX with no prior experience). &lt;/p&gt;\n\n&lt;p&gt;Any advice is greatly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14wsjy0", "is_robot_indexable": true, "report_reasons": null, "author": "Possible-Health6784", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wsjy0/graduating_with_a_masters_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wsjy0/graduating_with_a_masters_in_data_engineering/", "subreddit_subscribers": 115384, "created_utc": 1689084764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any easy way to calculate the minimum number of workers, drivers and memory needed in databricks? A website that does the calculation if any?", "author_fullname": "t2_aqp7hdzb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any websites to calculate Databricks drivers and workers required?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xgcwi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689144002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any easy way to calculate the minimum number of workers, drivers and memory needed in databricks? A website that does the calculation if any?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xgcwi", "is_robot_indexable": true, "report_reasons": null, "author": "johnyjohnyespappa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xgcwi/any_websites_to_calculate_databricks_drivers_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xgcwi/any_websites_to_calculate_databricks_drivers_and/", "subreddit_subscribers": 115384, "created_utc": 1689144002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning Apache Kafka, and I have completed the \"Apache Kafka Series - Learn Apache Kafka for Beginners v3\" course by Stephane Maarek. What do you think should be my next step?", "author_fullname": "t2_feara4tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14x6c6f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689116033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning Apache Kafka, and I have completed the &amp;quot;Apache Kafka Series - Learn Apache Kafka for Beginners v3&amp;quot; course by Stephane Maarek. What do you think should be my next step?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14x6c6f", "is_robot_indexable": true, "report_reasons": null, "author": "Kratos_1412", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14x6c6f/apache_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14x6c6f/apache_kafka/", "subreddit_subscribers": 115384, "created_utc": 1689116033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am investigating it  and I see that it has 2 limitations:\n\n1.  All tables created and updated by Delta Live Tables are Delta tables \n2. i can\u2019t customize their target delta table file paths to their desired location for bronze, silver or gold tables.\n\nin my organization we load data in bronze with its original format(could be json, parquet, etc) so we can not use DLT for this  if I am not mistaken and we can't use it either for a workflow with multiple notebooks that write in bronze , silver a gold successively.\n\nhow do you use DLT? which are the remaining use cases?\n\nthanks", "author_fullname": "t2_d6bmxkhw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do you use delta live tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14x2omf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689107698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am investigating it  and I see that it has 2 limitations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; All tables created and updated by Delta Live Tables are Delta tables &lt;/li&gt;\n&lt;li&gt;i can\u2019t customize their target delta table file paths to their desired location for bronze, silver or gold tables.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;in my organization we load data in bronze with its original format(could be json, parquet, etc) so we can not use DLT for this  if I am not mistaken and we can&amp;#39;t use it either for a workflow with multiple notebooks that write in bronze , silver a gold successively.&lt;/p&gt;\n\n&lt;p&gt;how do you use DLT? which are the remaining use cases?&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14x2omf", "is_robot_indexable": true, "report_reasons": null, "author": "PinPrestigious2327", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14x2omf/how_do_you_use_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14x2omf/how_do_you_use_delta_live_tables/", "subreddit_subscribers": 115384, "created_utc": 1689107698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So as the title suggests, I'm currently working as a DBA mainly specializing in performance optimization, and I want to make a career shift towards Data Engineering but I'm confused of the roadmap or what to learn.\n\nCurrently I have experience and skills in SQL, Teradata, and a beginner Python (projects made using Pandas, Tkinter, and Data scraping libraries)\nAdditionally I have done some visualization on Power BI and I'm decent at it and DAX.\n\nThe country where I'm looking to apply is mostly dominant in Azure Cloud technologies for data engineering roles,  but most of the job postings also require experience in Python and ETL. \n\nMy initial goal was to do the DP 203 Azure Data Engineer Associate certification but now I'm thinking of learning ETL, Data orchestration and Data modelling before I jump to cloud.\n\nMy plan is to learn spark with databricks, pyspark for ETL. Maybe some Airflow for data orchestration and Kimball for data modelling\n\nShould I go for the DP 203 certification and then focus on the spark, pyspark and Airflow or do this in reverse or is there another better roadmap which could cover ETL, spark and cloud?", "author_fullname": "t2_k9utu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From DBA to Data Engineer, what learning path to take?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ww6ky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689093184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So as the title suggests, I&amp;#39;m currently working as a DBA mainly specializing in performance optimization, and I want to make a career shift towards Data Engineering but I&amp;#39;m confused of the roadmap or what to learn.&lt;/p&gt;\n\n&lt;p&gt;Currently I have experience and skills in SQL, Teradata, and a beginner Python (projects made using Pandas, Tkinter, and Data scraping libraries)\nAdditionally I have done some visualization on Power BI and I&amp;#39;m decent at it and DAX.&lt;/p&gt;\n\n&lt;p&gt;The country where I&amp;#39;m looking to apply is mostly dominant in Azure Cloud technologies for data engineering roles,  but most of the job postings also require experience in Python and ETL. &lt;/p&gt;\n\n&lt;p&gt;My initial goal was to do the DP 203 Azure Data Engineer Associate certification but now I&amp;#39;m thinking of learning ETL, Data orchestration and Data modelling before I jump to cloud.&lt;/p&gt;\n\n&lt;p&gt;My plan is to learn spark with databricks, pyspark for ETL. Maybe some Airflow for data orchestration and Kimball for data modelling&lt;/p&gt;\n\n&lt;p&gt;Should I go for the DP 203 certification and then focus on the spark, pyspark and Airflow or do this in reverse or is there another better roadmap which could cover ETL, spark and cloud?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ww6ky", "is_robot_indexable": true, "report_reasons": null, "author": "irtaza23", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ww6ky/from_dba_to_data_engineer_what_learning_path_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ww6ky/from_dba_to_data_engineer_what_learning_path_to/", "subreddit_subscribers": 115384, "created_utc": 1689093184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team is looking at writing a simple framework/platform based on Cloud that'd allow various users to define batch based pipelines. Currently focusing on AWS, there are multiple modules which setup a set of services, dynamic infrastructure, orchestration, roles, notifications for the users as part of the platform. \n\nAs part of orchestration, I started looking at Dagster and one of the thing I immediately realized is that the actual data processing and orchestration is intertwined and deliberately kept together in most of the examples I saw and also a forte of Dagster as I understand compared to the traditional orhestration/workflow frameworks where they are loosely coupled and a DAG is defined.   \n\n\nWhen I look at any orchestrator, the main things I look for is that - orchestration, meaning given a set of tasks, it should be able to execute, report on, track, kill at will, rollback, fanout, do reporting and maintain metadata for it. Combining this with the actual data being processed as part of the actions/tasks is a great thing for small scale pipelines but quickly becomes a scaling/deployment problem if I want to make it available as a service (not looking for Dagster cloud yet) where users can submit many such jobs.   \n\n\nI understand and yet to explore the constructs such as Assets, Operators that allow me integrate with external services (in my case the cloud services which I'd integrate with a good wrapper over common AWS managed services and compute) but before I proceed wanted to check if I am not setting myself on a wrong path just because its supports but is indeed an antipattern.   \n\n\nWhy separate actual compute from orchestration ?   \n\\- I want to fully exploit and use existing AWS services where given a script (say the script/python code utilizing say polars,pandas, duckdb etc), I have a freedom to pack and run it as a docker image on ECS, Fargate, or lamda   \n\\- For a very big workloads, which don't fit into services such as AWS Glue/Redshift for ELT/ETL purpose, be able to spawn an appliance say through spot and get it executed in EC2 and so on..  \n\n\n.. and still use Dagster as a pure orchestrator where it can have a shim layer written that not only launches but tracks these jobs very well, helps with retries, rollbacks etc.", "author_fullname": "t2_qg4yidm6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster - Separating compute and orchestration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14xodd2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team is looking at writing a simple framework/platform based on Cloud that&amp;#39;d allow various users to define batch based pipelines. Currently focusing on AWS, there are multiple modules which setup a set of services, dynamic infrastructure, orchestration, roles, notifications for the users as part of the platform. &lt;/p&gt;\n\n&lt;p&gt;As part of orchestration, I started looking at Dagster and one of the thing I immediately realized is that the actual data processing and orchestration is intertwined and deliberately kept together in most of the examples I saw and also a forte of Dagster as I understand compared to the traditional orhestration/workflow frameworks where they are loosely coupled and a DAG is defined.   &lt;/p&gt;\n\n&lt;p&gt;When I look at any orchestrator, the main things I look for is that - orchestration, meaning given a set of tasks, it should be able to execute, report on, track, kill at will, rollback, fanout, do reporting and maintain metadata for it. Combining this with the actual data being processed as part of the actions/tasks is a great thing for small scale pipelines but quickly becomes a scaling/deployment problem if I want to make it available as a service (not looking for Dagster cloud yet) where users can submit many such jobs.   &lt;/p&gt;\n\n&lt;p&gt;I understand and yet to explore the constructs such as Assets, Operators that allow me integrate with external services (in my case the cloud services which I&amp;#39;d integrate with a good wrapper over common AWS managed services and compute) but before I proceed wanted to check if I am not setting myself on a wrong path just because its supports but is indeed an antipattern.   &lt;/p&gt;\n\n&lt;p&gt;Why separate actual compute from orchestration ?&lt;br/&gt;\n- I want to fully exploit and use existing AWS services where given a script (say the script/python code utilizing say polars,pandas, duckdb etc), I have a freedom to pack and run it as a docker image on ECS, Fargate, or lamda&lt;br/&gt;\n- For a very big workloads, which don&amp;#39;t fit into services such as AWS Glue/Redshift for ELT/ETL purpose, be able to spawn an appliance say through spot and get it executed in EC2 and so on..  &lt;/p&gt;\n\n&lt;p&gt;.. and still use Dagster as a pure orchestrator where it can have a shim layer written that not only launches but tracks these jobs very well, helps with retries, rollbacks etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xodd2", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Cartoonist7071", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xodd2/dagster_separating_compute_and_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xodd2/dagster_separating_compute_and_orchestration/", "subreddit_subscribers": 115384, "created_utc": 1689167886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everybody,  I have been trying to look at systems that process streaming data (downstream from Kafka).  One of the inputs to our decision-making process is to have a good understanding of the throughputs these systems/platforms can handle.  I was hoping that we don't have to set up all these environments and run a side-by-side comparison.  Do you have some suggestions on where I can find this information? ", "author_fullname": "t2_48nrgvyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benchmarks for stream processing systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14x3zux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689110618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody,  I have been trying to look at systems that process streaming data (downstream from Kafka).  One of the inputs to our decision-making process is to have a good understanding of the throughputs these systems/platforms can handle.  I was hoping that we don&amp;#39;t have to set up all these environments and run a side-by-side comparison.  Do you have some suggestions on where I can find this information? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14x3zux", "is_robot_indexable": true, "report_reasons": null, "author": "anupsurendran", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14x3zux/benchmarks_for_stream_processing_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14x3zux/benchmarks_for_stream_processing_systems/", "subreddit_subscribers": 115384, "created_utc": 1689110618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Am new to working in Azure Databricks, am trying to run a job in the workflow, that creates a job cluster on the run that has one driver and 3 workers each with 56G memory and 8 cores. My question is do we need to set number of executors, memory and cores. \nWhat happens when we set number of executors and what happens when we don't", "author_fullname": "t2_ouayfdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So do we need to set executor memory and core in Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14x02a8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689101877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Am new to working in Azure Databricks, am trying to run a job in the workflow, that creates a job cluster on the run that has one driver and 3 workers each with 56G memory and 8 cores. My question is do we need to set number of executors, memory and cores. \nWhat happens when we set number of executors and what happens when we don&amp;#39;t&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14x02a8", "is_robot_indexable": true, "report_reasons": null, "author": "am_oldmonk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14x02a8/so_do_we_need_to_set_executor_memory_and_core_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14x02a8/so_do_we_need_to_set_executor_memory_and_core_in/", "subreddit_subscribers": 115384, "created_utc": 1689101877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I really like Redshift Spectrum and find it extremely useful when I have a few big files.\n\nThe problem I have is when I have event-based data e.g. output from Firehose and there are lots of smaller files in S3 (millions). I have this scenario where there are a lot of files and the file sizes are not big but it still takes a very long time to read with Redshift Spectrum. The data is partitioned and indexed in Glue based on year, month and day.\n\nAm I doing it wrong? Where is the bottleneck? Is it the S3 Get Requests?\n\nThank you", "author_fullname": "t2_52cc7hzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I Using Redshift Spectrum Wrong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wzd3l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689100292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really like Redshift Spectrum and find it extremely useful when I have a few big files.&lt;/p&gt;\n\n&lt;p&gt;The problem I have is when I have event-based data e.g. output from Firehose and there are lots of smaller files in S3 (millions). I have this scenario where there are a lot of files and the file sizes are not big but it still takes a very long time to read with Redshift Spectrum. The data is partitioned and indexed in Glue based on year, month and day.&lt;/p&gt;\n\n&lt;p&gt;Am I doing it wrong? Where is the bottleneck? Is it the S3 Get Requests?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14wzd3l", "is_robot_indexable": true, "report_reasons": null, "author": "BananaSpears262", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wzd3l/am_i_using_redshift_spectrum_wrong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wzd3l/am_i_using_redshift_spectrum_wrong/", "subreddit_subscribers": 115384, "created_utc": 1689100292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nWe are currently storing images, and text in AWS s3, and small percentage of data comes with annotations. Every week we should remove most of the annotated data and keep only data that are relevant for further training the models which we are currently doing using airflow and sampling techniques.\n\nWe want to migrate fully to the cloud and we are rewriting ML pipelines to Azure stack using Azure ML and storing data in Azure blop storage.\n\nWe want to include sampling pipeline, which basically downloads the data from azure blop storage, do some sampling techniques and moves or copies/deletes data to a new location in azure blop storage and creates new data assets.\n\nWould it make sense to include sampling pipeline in Azure ML pipelines, or rather Azure data factory pipelines? Are there any advantages/disadvantages in using either of those?\n\n ", "author_fullname": "t2_7vjhs5w4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure ML or Azure Data Factory pipelines for this specific case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wwl54", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689094091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently storing images, and text in AWS s3, and small percentage of data comes with annotations. Every week we should remove most of the annotated data and keep only data that are relevant for further training the models which we are currently doing using airflow and sampling techniques.&lt;/p&gt;\n\n&lt;p&gt;We want to migrate fully to the cloud and we are rewriting ML pipelines to Azure stack using Azure ML and storing data in Azure blop storage.&lt;/p&gt;\n\n&lt;p&gt;We want to include sampling pipeline, which basically downloads the data from azure blop storage, do some sampling techniques and moves or copies/deletes data to a new location in azure blop storage and creates new data assets.&lt;/p&gt;\n\n&lt;p&gt;Would it make sense to include sampling pipeline in Azure ML pipelines, or rather Azure data factory pipelines? Are there any advantages/disadvantages in using either of those?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14wwl54", "is_robot_indexable": true, "report_reasons": null, "author": "Desperate-Hat268", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wwl54/azure_ml_or_azure_data_factory_pipelines_for_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wwl54/azure_ml_or_azure_data_factory_pipelines_for_this/", "subreddit_subscribers": 115384, "created_utc": 1689094091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is data infrastructure managed in large chains such as grocery stores? \n\nWhen I visit grocery store job postings website, I don't often come across data-related job postings. Do they typically hire third-party companies to handle their data infrastructure and analytics? \n\nHow to search for these 3ed party companies. Do they have a specific term?", "author_fullname": "t2_upc5lnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who manages data infrastructure in large chains", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wvrn9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689092269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is data infrastructure managed in large chains such as grocery stores? &lt;/p&gt;\n\n&lt;p&gt;When I visit grocery store job postings website, I don&amp;#39;t often come across data-related job postings. Do they typically hire third-party companies to handle their data infrastructure and analytics? &lt;/p&gt;\n\n&lt;p&gt;How to search for these 3ed party companies. Do they have a specific term?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14wvrn9", "is_robot_indexable": true, "report_reasons": null, "author": "eliamartali", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wvrn9/who_manages_data_infrastructure_in_large_chains/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wvrn9/who_manages_data_infrastructure_in_large_chains/", "subreddit_subscribers": 115384, "created_utc": 1689092269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking a lot lately about data modeling, and why despite all the online discussion about \"best practices\", it all still seems so mediocre. That culminated in this blog post about what I call \"[The Data Modeling Divide](https://carlineng.com/?postid=data-modeling-divide#blog)\". Would love your comments/feedback.  \n\n\n(BTW, I'm a PM at Google working on the Looker team, so while this isn't a promotional post, it's definitely related to my day-to-day work!)", "author_fullname": "t2_c9g6hufqj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Modeling Divide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wsq7q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689085190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking a lot lately about data modeling, and why despite all the online discussion about &amp;quot;best practices&amp;quot;, it all still seems so mediocre. That culminated in this blog post about what I call &amp;quot;&lt;a href=\"https://carlineng.com/?postid=data-modeling-divide#blog\"&gt;The Data Modeling Divide&lt;/a&gt;&amp;quot;. Would love your comments/feedback.  &lt;/p&gt;\n\n&lt;p&gt;(BTW, I&amp;#39;m a PM at Google working on the Looker team, so while this isn&amp;#39;t a promotional post, it&amp;#39;s definitely related to my day-to-day work!)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14wsq7q", "is_robot_indexable": true, "report_reasons": null, "author": "carlineng_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14wsq7q/the_data_modeling_divide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wsq7q/the_data_modeling_divide/", "subreddit_subscribers": 115384, "created_utc": 1689085190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm actually going to make this, so I want to make sure I don't leave out any great jokes. What should the office look like? What struggles should I include? What would make you laugh? ", "author_fullname": "t2_68z0an9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If there was a nature documentary about the \"datus engineerius\" and it's life inside of the corporate habitat, what kinds of things would for sure be pointed out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14xoc20", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m actually going to make this, so I want to make sure I don&amp;#39;t leave out any great jokes. What should the office look like? What struggles should I include? What would make you laugh? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xoc20", "is_robot_indexable": true, "report_reasons": null, "author": "3spelledout", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xoc20/if_there_was_a_nature_documentary_about_the_datus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xoc20/if_there_was_a_nature_documentary_about_the_datus/", "subreddit_subscribers": 115384, "created_utc": 1689167792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Follow up post: [Previous post](https://www.reddit.com/r/dataengineering/comments/14o8h6h/data_engineer_looking_to_study_mechanical/?utm_source=share&amp;utm_medium=web2x&amp;context=3)\n\nHello, So as you know from last time, I was working on a GKE project, where I deployed a docker image that retrieves data from ADH and inserts it into BigQuery, Thank you everyone for your recommendation and your advices, I finally managed to finish the project, I scheduled, everything works perfectly!! My question is: how can I further improve the project by automating the deployment process? I was thinking of terraform and ansible, but I'm here once again to ask about your opinion, and if you have any advice!! \n\nEdit: I used Makefile but I think it's a bit clumsy \n\nTL;DR I want to automate the deployment process of pushing an image to artifact registry on google + apply workload cronjobs using ansible/terraform, Any advices? :D", "author_fullname": "t2_5u3c1gj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automate GKE deployment process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xj1mi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689152860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Follow up post: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14o8h6h/data_engineer_looking_to_study_mechanical/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;Previous post&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hello, So as you know from last time, I was working on a GKE project, where I deployed a docker image that retrieves data from ADH and inserts it into BigQuery, Thank you everyone for your recommendation and your advices, I finally managed to finish the project, I scheduled, everything works perfectly!! My question is: how can I further improve the project by automating the deployment process? I was thinking of terraform and ansible, but I&amp;#39;m here once again to ask about your opinion, and if you have any advice!! &lt;/p&gt;\n\n&lt;p&gt;Edit: I used Makefile but I think it&amp;#39;s a bit clumsy &lt;/p&gt;\n\n&lt;p&gt;TL;DR I want to automate the deployment process of pushing an image to artifact registry on google + apply workload cronjobs using ansible/terraform, Any advices? :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xj1mi", "is_robot_indexable": true, "report_reasons": null, "author": "iGodFather302", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xj1mi/automate_gke_deployment_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xj1mi/automate_gke_deployment_process/", "subreddit_subscribers": 115384, "created_utc": 1689152860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\nI have platform basing on Kafka. A lot of events go through various topics. I am writting streaming app to process events in real time(join on streams are possible). I consider Kafka Streams and Flink as a streaming technologies. My first thought was to use Kafka Streams but I heard that there is some problem with inner Kafka topics during join operations. Could uou gove me some advice what would u use?", "author_fullname": "t2_omva4fi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flink or Kafka Streams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xhrhj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689148809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nI have platform basing on Kafka. A lot of events go through various topics. I am writting streaming app to process events in real time(join on streams are possible). I consider Kafka Streams and Flink as a streaming technologies. My first thought was to use Kafka Streams but I heard that there is some problem with inner Kafka topics during join operations. Could uou gove me some advice what would u use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14xhrhj", "is_robot_indexable": true, "report_reasons": null, "author": "BigDataMax", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xhrhj/flink_or_kafka_streams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xhrhj/flink_or_kafka_streams/", "subreddit_subscribers": 115384, "created_utc": 1689148809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI'm on a relatively small and new Data Science team and currently trying to figure out the best tech stack/practices for deploying ML models. Right now we use BigQuery for our data base, DBT for the SQL pipeline (am I even referring to it properly?), and VertexAI workbench where the modeling and experimentation is done, and then a BitBucket repo. There is Airflow usage among the data engineers in other teams so there is a precedent there as far as orchestration goes.\n\nGiven that most of my past experience has focused on ad-hoc experimentation and not actual deployment, was hoping to get some general advice on how to set certain pipelines. \n\nUltimately, going forward the current suite of models will have to be retrained on a weekly basis, and the results will have to be uploaded to an environment where analysts can interface with the results.\n\n Currently trying to figure out best practices for building a robust pipeline given the tools we have above and was hoping to get some community feedback from more seasoned engineers.\n\nRight now most of the models are retrained manually.\n\n&amp;#x200B;\n\nGeneral outline of a pipeline that is currently in use that I feel needs to be refactored. \n\n1.)  SQL queries to pull data into python environment, where feature engineering in performed. (Some of the features are generated in the SQL queries where possible). Features are created using functions and the table with the target variable and features are written to a new table in GCP.\n\n2.)  In a separate script, read in the feature table, and then proceed to do some training (train-test splits / Cross Valdiation / Hyperparameter tuning) -&gt; hyper parameters are saved in a pickle file. Final model is trained using the found hyper paramters -&gt; final model saved in pickle file. \n\n3.) In separate script, the feature table is again read into python and the model is loaded from pickle and used to generate the output we need. The predicted values are then read into a final big query table which is referenced by analysts/data engineers for client facing platform.\n\n&amp;#x200B;\n\nWhat would be some better ways of structuring the pipeline above, or are there github ML pipeline examples that exist that I can learn from?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_bf43tms01", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applying Data Engineering best practices to ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14x1r3k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689105657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on a relatively small and new Data Science team and currently trying to figure out the best tech stack/practices for deploying ML models. Right now we use BigQuery for our data base, DBT for the SQL pipeline (am I even referring to it properly?), and VertexAI workbench where the modeling and experimentation is done, and then a BitBucket repo. There is Airflow usage among the data engineers in other teams so there is a precedent there as far as orchestration goes.&lt;/p&gt;\n\n&lt;p&gt;Given that most of my past experience has focused on ad-hoc experimentation and not actual deployment, was hoping to get some general advice on how to set certain pipelines. &lt;/p&gt;\n\n&lt;p&gt;Ultimately, going forward the current suite of models will have to be retrained on a weekly basis, and the results will have to be uploaded to an environment where analysts can interface with the results.&lt;/p&gt;\n\n&lt;p&gt;Currently trying to figure out best practices for building a robust pipeline given the tools we have above and was hoping to get some community feedback from more seasoned engineers.&lt;/p&gt;\n\n&lt;p&gt;Right now most of the models are retrained manually.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;General outline of a pipeline that is currently in use that I feel needs to be refactored. &lt;/p&gt;\n\n&lt;p&gt;1.)  SQL queries to pull data into python environment, where feature engineering in performed. (Some of the features are generated in the SQL queries where possible). Features are created using functions and the table with the target variable and features are written to a new table in GCP.&lt;/p&gt;\n\n&lt;p&gt;2.)  In a separate script, read in the feature table, and then proceed to do some training (train-test splits / Cross Valdiation / Hyperparameter tuning) -&amp;gt; hyper parameters are saved in a pickle file. Final model is trained using the found hyper paramters -&amp;gt; final model saved in pickle file. &lt;/p&gt;\n\n&lt;p&gt;3.) In separate script, the feature table is again read into python and the model is loaded from pickle and used to generate the output we need. The predicted values are then read into a final big query table which is referenced by analysts/data engineers for client facing platform.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What would be some better ways of structuring the pipeline above, or are there github ML pipeline examples that exist that I can learn from?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14x1r3k", "is_robot_indexable": true, "report_reasons": null, "author": "lyrical_empirical", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14x1r3k/applying_data_engineering_best_practices_to_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14x1r3k/applying_data_engineering_best_practices_to_ml/", "subreddit_subscribers": 115384, "created_utc": 1689105657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I need some advice on how to create a data processing pipeline.  \nI've seen a few tools (airflow, dagster, prefect and others) but I'm not sure if they meet my needs.\n\nIt needs to be deployed inside k8s and can use Azure tools.  \n\n\nHere's the input data:\n\n* A batch of files (different extensions) linked to a client and a project that can arrive at any time.\n* The files are stored in a MinIO storage space. \n\n&amp;#x200B;\n\nI want to process the files one by one, preferably using an API to trigger the job. \n\nEach file will pass through the pipeline, but not through the same jobs. Some extension types will require different processing (or can be excluded). \n\nI also need a dashboard:\n\n* I need to be able to filter by client and project. \n* I need to see pipeline progress (by file) \n* Track the performance of each task. \n* Can be added to client app\n\nRe-run jobs/tasks: \n\nIf a file is made up of the following jobs: \\[A -&gt; B -&gt; \\[C, D\\]\\].  \nI'd like to be able to re-run from step B, which will trigger the re-processing of C and D.\n\n  \nI feel like I have to combine different tools to get the pipeline + the dashboard.\n\n  \n\n\nWe welcome any contributions or tool recommendations!\n\nThank you very much!", "author_fullname": "t2_a1lni9541", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice : Ingestion pipeline tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14wuip0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689089488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I need some advice on how to create a data processing pipeline.&lt;br/&gt;\nI&amp;#39;ve seen a few tools (airflow, dagster, prefect and others) but I&amp;#39;m not sure if they meet my needs.&lt;/p&gt;\n\n&lt;p&gt;It needs to be deployed inside k8s and can use Azure tools.  &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the input data:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A batch of files (different extensions) linked to a client and a project that can arrive at any time.&lt;/li&gt;\n&lt;li&gt;The files are stored in a MinIO storage space. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to process the files one by one, preferably using an API to trigger the job. &lt;/p&gt;\n\n&lt;p&gt;Each file will pass through the pipeline, but not through the same jobs. Some extension types will require different processing (or can be excluded). &lt;/p&gt;\n\n&lt;p&gt;I also need a dashboard:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I need to be able to filter by client and project. &lt;/li&gt;\n&lt;li&gt;I need to see pipeline progress (by file) &lt;/li&gt;\n&lt;li&gt;Track the performance of each task. &lt;/li&gt;\n&lt;li&gt;Can be added to client app&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Re-run jobs/tasks: &lt;/p&gt;\n\n&lt;p&gt;If a file is made up of the following jobs: [A -&amp;gt; B -&amp;gt; [C, D]].&lt;br/&gt;\nI&amp;#39;d like to be able to re-run from step B, which will trigger the re-processing of C and D.&lt;/p&gt;\n\n&lt;p&gt;I feel like I have to combine different tools to get the pipeline + the dashboard.&lt;/p&gt;\n\n&lt;p&gt;We welcome any contributions or tool recommendations!&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14wuip0", "is_robot_indexable": true, "report_reasons": null, "author": "derekoms_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14wuip0/need_advice_ingestion_pipeline_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14wuip0/need_advice_ingestion_pipeline_tool/", "subreddit_subscribers": 115384, "created_utc": 1689089488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m proficient in Tableau, SQL, Alteryx, and Excel. Been stuck in the corporate reporting world for a bit too long and I\u2019d like to advance my skill set. \n\nI\u2019m going to try and stretch for a job that will have me working with SSIS, Automic, Databricks, Fivetran, Medallia architecture, and DBT. I don\u2019t know what any of these things are, not even at a basic level. My friend is the hiring manager so I\u2019ll have a leg up, but I need to be at least conversant in these tools and technologies. \n\nOf course I will be YouTubing and googling these things myself, but figured I\u2019d ask if anyone here knows of a particularly great resource, course, book, etc that provides good coverage of the things I listed, and is catered to someone with my background. Thanks in advance!", "author_fullname": "t2_4mo8008p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips on leveling up from business intelligence to data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14xoa4g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689167660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m proficient in Tableau, SQL, Alteryx, and Excel. Been stuck in the corporate reporting world for a bit too long and I\u2019d like to advance my skill set. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m going to try and stretch for a job that will have me working with SSIS, Automic, Databricks, Fivetran, Medallia architecture, and DBT. I don\u2019t know what any of these things are, not even at a basic level. My friend is the hiring manager so I\u2019ll have a leg up, but I need to be at least conversant in these tools and technologies. &lt;/p&gt;\n\n&lt;p&gt;Of course I will be YouTubing and googling these things myself, but figured I\u2019d ask if anyone here knows of a particularly great resource, course, book, etc that provides good coverage of the things I listed, and is catered to someone with my background. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14xoa4g", "is_robot_indexable": true, "report_reasons": null, "author": "philspyderman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xoa4g/tips_on_leveling_up_from_business_intelligence_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xoa4g/tips_on_leveling_up_from_business_intelligence_to/", "subreddit_subscribers": 115384, "created_utc": 1689167660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Nomenclature is something I don't see brought very often in this subreddit. What naming conventions do you use when it comes to naming tables/jobs/individual pipelines and such, if any?", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What naming conventions do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14xncko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689165260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Nomenclature is something I don&amp;#39;t see brought very often in this subreddit. What naming conventions do you use when it comes to naming tables/jobs/individual pipelines and such, if any?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14xncko", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xncko/what_naming_conventions_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xncko/what_naming_conventions_do_you_use/", "subreddit_subscribers": 115384, "created_utc": 1689165260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is how it is done:\n\nApache Doris preserves multiple replicas of hot data and the metadata in its backend nodes, and cold data in object storage with only one copy.\n\nhttps://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=116202b543f7ad10392348ddb036a5e125c49081\n\nFull post about [hot-cold data separation](https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High availability of data without consuming too much storage space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"n5t2a43epibb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e93b5fcaf295957400ac50c724629865333f96e"}, {"y": 175, "x": 216, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d3c3d93f39247aba6281cf8abaf9705596906f8"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c900bec99726a420282e06f3c9511c60d807c49"}, {"y": 520, "x": 640, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=46886e8b513861fb5c44f981484edac60289ad1d"}, {"y": 780, "x": 960, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d547c8b465733f08671882765b3a471b95d4ea7"}, {"y": 878, "x": 1080, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2e00bd44ba6a0107a00507b4afb50b27dfd768a6"}], "s": {"y": 1041, "x": 1280, "u": "https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=116202b543f7ad10392348ddb036a5e125c49081"}, "id": "n5t2a43epibb1"}}, "name": "t3_14xlmy3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cA-TRKk2RQNysgWZvGrT-7xphAfBnKQJyJcIU1Q-Mrg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1689160617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is how it is done:&lt;/p&gt;\n\n&lt;p&gt;Apache Doris preserves multiple replicas of hot data and the metadata in its backend nodes, and cold data in object storage with only one copy.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=116202b543f7ad10392348ddb036a5e125c49081\"&gt;https://preview.redd.it/n5t2a43epibb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=116202b543f7ad10392348ddb036a5e125c49081&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Full post about &lt;a href=\"https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf\"&gt;hot-cold data separation&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?auto=webp&amp;s=9bb433a2d2af7659bbd2aaefc86e6440fb099982", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cebf42d866ba39ad8401ec16025d2e683cb5ec5", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0db6f5ac30249427128f2acbef98d324f22c2d1b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=34cbad55217597ab7e3e1f50abad3c5bc069e0d7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5bc2ca5a2ba66071e1827faae996f0dc6f6e329c", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f46f655bcbbc72ddca3942cdffe318e8677b8735", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/bW78ToRXbYSgiI_QPzu3yJPUUCxP62TNHz5pzYv1Ej4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8874a5ffe10ae71db18d29c8e4b5f59d830878fe", "width": 1080, "height": 720}], "variants": {}, "id": "XHYrsxQam1UsYnZQ-ImG7NyQc780qMXf4eXuq9sAgzc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14xlmy3", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14xlmy3/high_availability_of_data_without_consuming_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14xlmy3/high_availability_of_data_without_consuming_too/", "subreddit_subscribers": 115384, "created_utc": 1689160617.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}