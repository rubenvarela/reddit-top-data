{"kind": "Listing", "data": {"after": "t3_15bzh0d", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I see there are posts every week about database certifications and such.  I compiled a list late last year which I'm sharing below.  Please let me know of any that I have missed.  Or any dead links and wrong information for that matter.  Certifications are in the eye of the beholder; some employers value them, and others don't.\n\nHere is a link if you want to bookmark my most recent list.\n\n [Database Certification List - Advanced SQL Puzzles](https://advancedsqlpuzzles.com/2022/11/18/database-certification-list/) \n\n**And below is just a copy and paste from the above link.**\n\nEnjoy!!\n\n\\-------------------------------------------------------------------------------------------\n\n[**Microsoft**](https://learn.microsoft.com/en-us/certifications/)\n\nMicrosoft has unfortunately sunsetted its SQL Developer focused certifications ([70-761](https://learn.microsoft.com/en-us/certifications/exams/70-761) and [70-762](https://learn.microsoft.com/en-us/certifications/exams/70-762)) and is focusing on role-based cloud certifications.\u00a0\n\n* [DP-900: Microsoft Azure Data Fundamentals](https://learn.microsoft.com/en-us/certifications/exams/dp-900)\n* [Exam DP-203: Data Engineering on Microsoft Azure](https://learn.microsoft.com/en-us/certifications/exams/dp-203)\n* [Exam DP-300: Administering Microsoft Azure SQL Solutions](https://learn.microsoft.com/en-us/certifications/exams/dp-300)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Amazon**](https://aws.amazon.com/certification/)\n\nAmazon offers the following database certification.\n\n* [AWS Certified Database \u2013 Specialty exam (DBS-C01)](https://aws.amazon.com/certification/certified-database-specialty/)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Google**](https://cloud.google.com/certification)\n\nAnd let\u2019s not forget about Google and their cloud platform.\n\n* [Professional Cloud Database Engineer](https://cloud.google.com/certification/cloud-database-engineer)\n* [Professional Data Engineer](https://cloud.google.com/certification/data-engineer)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Oracle**](https://education.oracle.com/certification)\n\nOracle has numerous certifications ranging from high availability to administration to development. Here are a couple that I recommend. The 1Z0-149 is absurdly difficult, btw.\n\n* [Oracle Database SQL Certified Associate Certification (1Z0-071)](https://education.oracle.com/oracle-database-sql-certified-associate/trackp_457)\n* [Oracle Database PL/SQL Developer Certified Professional (1Z0-149)](https://education.oracle.com/oracle-database-pl-sql-developer-certified-professional/trackp_OCPPLSQL19C)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**MySQL**](https://education.oracle.com/certification)\n\nOracle also offers MySQL certifications as it purchased Sun Microsystems in 2010.\n\nMySQL is free and open-source software under the terms of the GNU General Public License, and is also available under a variety of proprietary licenses. MySQL was owned and sponsored by the Swedish company MySQL AB, which was bought by Sun Microsystems (now Oracle Corporation).\n\n* [MySQL 8.0 Database Developer Oracle Certified Professional (1Z0-909)](https://education.oracle.com/mysql-80-database-developer-oracle-certified-professional/trackp_MYSQLPRG80OCP)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**MariaDB**](https://education.oracle.com/certification)\n\nMariaDB is a popular open-source relational database management system (RDBMS) that was initially developed as a fork of MySQL by the original developers of MySQL. It was created in response to concerns over Oracle\u2019s acquisition of MySQL in 2010 and its potential impact on the open-source nature of the MySQL project.\n\nMariaDB offers a database administrator exam, but not a developer exam.\n\n* [MariaDB Certification Exam](https://mariadb.com/wp-content/uploads/2019/02/mariadb-certification-exam_datasheet_1005.pdf)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**PostgreSQL**](https://www.enterprisedb.com/)\n\nPostgreSQL is a free and open-source relational database management system emphasizing extensibility and SQL compliance. Because it is open-source, there are no vendor certifications, but there is a company called [EDB ](https://www.enterprisedb.com/)that offers solutions, training, and certifications for PostgreSQL. Their [certifications](https://www.enterprisedb.com/training/postgres-certification) appear to be focused on the DBA side.\n\n* [PostgreSQL 12 Associate Certification](https://www.enterprisedb.com/course/postgresql-12-associate-certification)\n* [PostgreSQL 12 Professional Certification](https://www.enterprisedb.com/training/postgres-certification)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**IBM**](https://www.ibm.com/training/credentials/)\n\nDB2 is a set of relational database products offered by IBM that traces its root all the way back to the 1970s. Currently IBM appears to be withdrawing many of its DB2 certifications and issuing new certification exams. The following appears to be the only DB2 exam currently offered, which is more DBA focused.\n\n* [Exam C1000-122: Db2 12 for z/OS DBA Fundamentals](https://www.ibm.com/training/certification/C8003803)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Databricks**](https://www.databricks.com/learn/certification#certifications)\n\nDatabricks offers an associate and professional level data engineering certifications. These are great resources for understanding the product features.\n\n* [Databricks Certified Data Engineer Associate](https://www.databricks.com/learn/certification/data-engineer-associate)\n* [Databricks Certified Data Engineer Professional](https://www.databricks.com/learn/certification/data-engineer-professional)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Snowflake**](https://www.snowflake.com/certifications/)\n\nSnowflake is a fully managed multi-cluster shared data architecture platform that capitalizes on the resources of the cloud. The SnowPro Core certification highlights the product features the best.\n\n* [\\[COF-C02\\] SnowPro Core Certification](https://learn.snowflake.com/courses/course-v1:snowflake+CERT-SPC-GUIDE+B/about?_ga=2.109990149.1818508944.1668788648-1953636227.1655820550)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**Teradata**](https://www.teradata.com/University/Certification)\n\nTeradata (formed in 1979) provides cloud database and analytics-related software, products, and services.\n\n* [Vantage Certified Associate Exam 2.3 (TDVAN1)](https://www.teradata.com/University/Certification/Vantage-Certifications/Associate-Exam-2-3)\n* [Vantage Data Engineering Exam (TDVAN4)](https://www.teradata.com/University/Certification/Vantage-Certifications/Data-Engineering-Exam)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**MongoDB**](https://university.mongodb.com/certification?_ga=2.155916475.143515463.1668790358-1726176162.1668790358)\n\nMongoDB is a source-available cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with optional schemas. MongoDB is developed by MongoDB Inc. and licensed under the Server Side Public License which is deemed non-free by several distributions.\n\nIt appears MongoDB offers certifications tailored to various languages like C#, Java, Python and Node.js.\n\n* [MongoDB Associate Developer Exam](https://learn.mongodb.com/pages/mongodb-associate-developer-exam?_ga=2.155876411.143515463.1668790358-1726176162.1668790358)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**SAP HANA**](https://training.sap.com/certification/)\n\nSAP HANA (High-performance ANalytic Appliance) is a multi-model database that stores data in its memory instead of keeping it on a disk. There are a number of HANA certifications that you can choose from. The following appears to be the most SQL focused.\n\n* [SAP Certified Development Associate \u2013 SAP HANA 2.0 SPS05](https://training.sap.com/certification/c_hanadev_17-sap-certified-development-associate---sap-hana-20-sps05-g/)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n**Below are a few vendor neutral certifications that you may be interest in.**\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**CIW Database Design Specialist**](https://ciwcertified.com/ciw-certifications)\n\nCIW has vendor neutral IT certifications focusing on web professionals, but it does offer a Database Design Specialist certification. This certification focuses on concepts such as the relational model, relational algebra, design, modeling, and the SQL language. The [study guide for the exam](https://www.amazon.com/Study-Guide-1D0-541-Specialist-Certification/dp/1941404073) is a great encapsulation of many database concepts that we should all know.\n\n* [1D0-541: CIW Database Design Specialist](https://ciwcertified.com/ciw-certifications/web-development-series/database-design-specialist)\n\n[**ICCP**](https://iccp.org/index.html)\n\nThe Institute for the Certification of Computing Professionals (ICCP) is a non-profit (501(c)(6)) institution for professional certification in the Computer engineering and Information technology industry. It was founded in 1973 by 8 professional computer societies to promote certification and professionalism in the industry, lower the cost of development and administration of certification for all of the societies and act as the central resource for job standards and performance criteria.\n\nHere are a couple of their certifications that may be of intetest\n\n* [Certified Data Professional (CDP)](https://iccp.org/certified-data-professional-cdp.html)\n* [Certified Big Data Professional (CBDP)](https://iccp.org/certified-big-data-professional.html)\n\n[**DAMA International**](https://cdmp.info/)\n\nCertified Data Management Professional (CDMP) is a globally recognized Data Management Certification program run by DAMA International.\n\nThis exam is centered around [DMBOK ](https://www.dama.org/cpages/body-of-knowledge)and is geared more towards Data Management and Data Governance.\n\n* [About CDMP \u2013 Certified Data Management Professionals](https://cdmp.info/about/)\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n**Below are a few educational websites that advertise certifications, but these (most probably) do not meet the stricter guidelines of the above certifications. Regardless, they may be a good option for students beginning their learning path.**\n\n\\--------------------------------------------------------------------------------------------------------------------\n\n[**W3 Schools**](https://campus.w3schools.com/collections/course-catalog)\n\nW3Schools is a freemium educational website for learning coding online. Initially released in 1998, it derives its name from the World Wide Web but is not affiliated with the W3 Consortium. W3Schools offers courses covering all aspects of web development.\n\n* [Certified SQL Developer](https://campus.w3schools.com/collections/course-catalog/products/sql-course)\n\n[**Datacamp**](https://www.datacamp.com/certification)\n\nDataCamp is\u00a0an online learning platform that helps students build data skills at their own pace.\n\n* [Data Analyst Certification](https://www.datacamp.com/certification/data-analyst)\n* [Data Scientist Certification](https://www.datacamp.com/certification/data-scientist)\n\nYou have reached the end! Happy coding!", "author_fullname": "t2_4d58zyiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A List of Database Certifications Here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bycwi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690552984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see there are posts every week about database certifications and such.  I compiled a list late last year which I&amp;#39;m sharing below.  Please let me know of any that I have missed.  Or any dead links and wrong information for that matter.  Certifications are in the eye of the beholder; some employers value them, and others don&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;Here is a link if you want to bookmark my most recent list.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://advancedsqlpuzzles.com/2022/11/18/database-certification-list/\"&gt;Database Certification List - Advanced SQL Puzzles&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;And below is just a copy and paste from the above link.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Enjoy!!&lt;/p&gt;\n\n&lt;p&gt;-------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learn.microsoft.com/en-us/certifications/\"&gt;&lt;strong&gt;Microsoft&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Microsoft has unfortunately sunsetted its SQL Developer focused certifications (&lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/70-761\"&gt;70-761&lt;/a&gt; and &lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/70-762\"&gt;70-762&lt;/a&gt;) and is focusing on role-based cloud certifications.\u00a0&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/dp-900\"&gt;DP-900: Microsoft Azure Data Fundamentals&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/dp-203\"&gt;Exam DP-203: Data Engineering on Microsoft Azure&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/dp-300\"&gt;Exam DP-300: Administering Microsoft Azure SQL Solutions&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://aws.amazon.com/certification/\"&gt;&lt;strong&gt;Amazon&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Amazon offers the following database certification.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://aws.amazon.com/certification/certified-database-specialty/\"&gt;AWS Certified Database \u2013 Specialty exam (DBS-C01)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cloud.google.com/certification\"&gt;&lt;strong&gt;Google&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And let\u2019s not forget about Google and their cloud platform.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://cloud.google.com/certification/cloud-database-engineer\"&gt;Professional Cloud Database Engineer&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://cloud.google.com/certification/data-engineer\"&gt;Professional Data Engineer&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://education.oracle.com/certification\"&gt;&lt;strong&gt;Oracle&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Oracle has numerous certifications ranging from high availability to administration to development. Here are a couple that I recommend. The 1Z0-149 is absurdly difficult, btw.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://education.oracle.com/oracle-database-sql-certified-associate/trackp_457\"&gt;Oracle Database SQL Certified Associate Certification (1Z0-071)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://education.oracle.com/oracle-database-pl-sql-developer-certified-professional/trackp_OCPPLSQL19C\"&gt;Oracle Database PL/SQL Developer Certified Professional (1Z0-149)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://education.oracle.com/certification\"&gt;&lt;strong&gt;MySQL&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Oracle also offers MySQL certifications as it purchased Sun Microsystems in 2010.&lt;/p&gt;\n\n&lt;p&gt;MySQL is free and open-source software under the terms of the GNU General Public License, and is also available under a variety of proprietary licenses. MySQL was owned and sponsored by the Swedish company MySQL AB, which was bought by Sun Microsystems (now Oracle Corporation).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://education.oracle.com/mysql-80-database-developer-oracle-certified-professional/trackp_MYSQLPRG80OCP\"&gt;MySQL 8.0 Database Developer Oracle Certified Professional (1Z0-909)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://education.oracle.com/certification\"&gt;&lt;strong&gt;MariaDB&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;MariaDB is a popular open-source relational database management system (RDBMS) that was initially developed as a fork of MySQL by the original developers of MySQL. It was created in response to concerns over Oracle\u2019s acquisition of MySQL in 2010 and its potential impact on the open-source nature of the MySQL project.&lt;/p&gt;\n\n&lt;p&gt;MariaDB offers a database administrator exam, but not a developer exam.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://mariadb.com/wp-content/uploads/2019/02/mariadb-certification-exam_datasheet_1005.pdf\"&gt;MariaDB Certification Exam&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.enterprisedb.com/\"&gt;&lt;strong&gt;PostgreSQL&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;PostgreSQL is a free and open-source relational database management system emphasizing extensibility and SQL compliance. Because it is open-source, there are no vendor certifications, but there is a company called &lt;a href=\"https://www.enterprisedb.com/\"&gt;EDB &lt;/a&gt;that offers solutions, training, and certifications for PostgreSQL. Their &lt;a href=\"https://www.enterprisedb.com/training/postgres-certification\"&gt;certifications&lt;/a&gt; appear to be focused on the DBA side.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.enterprisedb.com/course/postgresql-12-associate-certification\"&gt;PostgreSQL 12 Associate Certification&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.enterprisedb.com/training/postgres-certification\"&gt;PostgreSQL 12 Professional Certification&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ibm.com/training/credentials/\"&gt;&lt;strong&gt;IBM&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;DB2 is a set of relational database products offered by IBM that traces its root all the way back to the 1970s. Currently IBM appears to be withdrawing many of its DB2 certifications and issuing new certification exams. The following appears to be the only DB2 exam currently offered, which is more DBA focused.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.ibm.com/training/certification/C8003803\"&gt;Exam C1000-122: Db2 12 for z/OS DBA Fundamentals&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/learn/certification#certifications\"&gt;&lt;strong&gt;Databricks&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Databricks offers an associate and professional level data engineering certifications. These are great resources for understanding the product features.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.databricks.com/learn/certification/data-engineer-associate\"&gt;Databricks Certified Data Engineer Associate&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.databricks.com/learn/certification/data-engineer-professional\"&gt;Databricks Certified Data Engineer Professional&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.snowflake.com/certifications/\"&gt;&lt;strong&gt;Snowflake&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Snowflake is a fully managed multi-cluster shared data architecture platform that capitalizes on the resources of the cloud. The SnowPro Core certification highlights the product features the best.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://learn.snowflake.com/courses/course-v1:snowflake+CERT-SPC-GUIDE+B/about?_ga=2.109990149.1818508944.1668788648-1953636227.1655820550\"&gt;[COF-C02] SnowPro Core Certification&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.teradata.com/University/Certification\"&gt;&lt;strong&gt;Teradata&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Teradata (formed in 1979) provides cloud database and analytics-related software, products, and services.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.teradata.com/University/Certification/Vantage-Certifications/Associate-Exam-2-3\"&gt;Vantage Certified Associate Exam 2.3 (TDVAN1)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.teradata.com/University/Certification/Vantage-Certifications/Data-Engineering-Exam\"&gt;Vantage Data Engineering Exam (TDVAN4)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://university.mongodb.com/certification?_ga=2.155916475.143515463.1668790358-1726176162.1668790358\"&gt;&lt;strong&gt;MongoDB&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;MongoDB is a source-available cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with optional schemas. MongoDB is developed by MongoDB Inc. and licensed under the Server Side Public License which is deemed non-free by several distributions.&lt;/p&gt;\n\n&lt;p&gt;It appears MongoDB offers certifications tailored to various languages like C#, Java, Python and Node.js.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://learn.mongodb.com/pages/mongodb-associate-developer-exam?_ga=2.155876411.143515463.1668790358-1726176162.1668790358\"&gt;MongoDB Associate Developer Exam&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://training.sap.com/certification/\"&gt;&lt;strong&gt;SAP HANA&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;SAP HANA (High-performance ANalytic Appliance) is a multi-model database that stores data in its memory instead of keeping it on a disk. There are a number of HANA certifications that you can choose from. The following appears to be the most SQL focused.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://training.sap.com/certification/c_hanadev_17-sap-certified-development-associate---sap-hana-20-sps05-g/\"&gt;SAP Certified Development Associate \u2013 SAP HANA 2.0 SPS05&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Below are a few vendor neutral certifications that you may be interest in.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ciwcertified.com/ciw-certifications\"&gt;&lt;strong&gt;CIW Database Design Specialist&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;CIW has vendor neutral IT certifications focusing on web professionals, but it does offer a Database Design Specialist certification. This certification focuses on concepts such as the relational model, relational algebra, design, modeling, and the SQL language. The &lt;a href=\"https://www.amazon.com/Study-Guide-1D0-541-Specialist-Certification/dp/1941404073\"&gt;study guide for the exam&lt;/a&gt; is a great encapsulation of many database concepts that we should all know.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://ciwcertified.com/ciw-certifications/web-development-series/database-design-specialist\"&gt;1D0-541: CIW Database Design Specialist&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://iccp.org/index.html\"&gt;&lt;strong&gt;ICCP&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The Institute for the Certification of Computing Professionals (ICCP) is a non-profit (501(c)(6)) institution for professional certification in the Computer engineering and Information technology industry. It was founded in 1973 by 8 professional computer societies to promote certification and professionalism in the industry, lower the cost of development and administration of certification for all of the societies and act as the central resource for job standards and performance criteria.&lt;/p&gt;\n\n&lt;p&gt;Here are a couple of their certifications that may be of intetest&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://iccp.org/certified-data-professional-cdp.html\"&gt;Certified Data Professional (CDP)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://iccp.org/certified-big-data-professional.html\"&gt;Certified Big Data Professional (CBDP)&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://cdmp.info/\"&gt;&lt;strong&gt;DAMA International&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Certified Data Management Professional (CDMP) is a globally recognized Data Management Certification program run by DAMA International.&lt;/p&gt;\n\n&lt;p&gt;This exam is centered around &lt;a href=\"https://www.dama.org/cpages/body-of-knowledge\"&gt;DMBOK &lt;/a&gt;and is geared more towards Data Management and Data Governance.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://cdmp.info/about/\"&gt;About CDMP \u2013 Certified Data Management Professionals&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Below are a few educational websites that advertise certifications, but these (most probably) do not meet the stricter guidelines of the above certifications. Regardless, they may be a good option for students beginning their learning path.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://campus.w3schools.com/collections/course-catalog\"&gt;&lt;strong&gt;W3 Schools&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;W3Schools is a freemium educational website for learning coding online. Initially released in 1998, it derives its name from the World Wide Web but is not affiliated with the W3 Consortium. W3Schools offers courses covering all aspects of web development.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://campus.w3schools.com/collections/course-catalog/products/sql-course\"&gt;Certified SQL Developer&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacamp.com/certification\"&gt;&lt;strong&gt;Datacamp&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;DataCamp is\u00a0an online learning platform that helps students build data skills at their own pace.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.datacamp.com/certification/data-analyst\"&gt;Data Analyst Certification&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.datacamp.com/certification/data-scientist\"&gt;Data Scientist Certification&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You have reached the end! Happy coding!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15bycwi", "is_robot_indexable": true, "report_reasons": null, "author": "sequel-beagle", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bycwi/a_list_of_database_certifications_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bycwi/a_list_of_database_certifications_here/", "subreddit_subscribers": 118850, "created_utc": 1690552984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, here's the situation:\n\n4 years ago I started as an intern in a small company, and then just leveled up there to senior DE.\n\nSince I was an intern obviously there wasn't a technical interview, just a couple \"let's know each other\" talks with HR and the hiring manager.\n\nRecently I interviewed with another company, another small one, which is looking for a senior DE to move forward their data endeavors (they don't have a dedicated data team yet).\n\nThe first interview was with their tech lead, who just today confirmed we're moving forward, and the next interview will be a technical one, with the tech lead + another SWE at their company.\n\nI really have no idea WTF to expect. I am confident in my skills, but I also know I don't really perform well in an \"exam setting\", so I'm afraid my brain will freeze.\n\nAny advice you have is more than welcome", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First technical interview with another company, not sure what to expect. Advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15byxaz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690554274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, here&amp;#39;s the situation:&lt;/p&gt;\n\n&lt;p&gt;4 years ago I started as an intern in a small company, and then just leveled up there to senior DE.&lt;/p&gt;\n\n&lt;p&gt;Since I was an intern obviously there wasn&amp;#39;t a technical interview, just a couple &amp;quot;let&amp;#39;s know each other&amp;quot; talks with HR and the hiring manager.&lt;/p&gt;\n\n&lt;p&gt;Recently I interviewed with another company, another small one, which is looking for a senior DE to move forward their data endeavors (they don&amp;#39;t have a dedicated data team yet).&lt;/p&gt;\n\n&lt;p&gt;The first interview was with their tech lead, who just today confirmed we&amp;#39;re moving forward, and the next interview will be a technical one, with the tech lead + another SWE at their company.&lt;/p&gt;\n\n&lt;p&gt;I really have no idea WTF to expect. I am confident in my skills, but I also know I don&amp;#39;t really perform well in an &amp;quot;exam setting&amp;quot;, so I&amp;#39;m afraid my brain will freeze.&lt;/p&gt;\n\n&lt;p&gt;Any advice you have is more than welcome&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15byxaz", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15byxaz/first_technical_interview_with_another_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15byxaz/first_technical_interview_with_another_company/", "subreddit_subscribers": 118850, "created_utc": 1690554274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started writing the backend service with Fiber (GoLang) in my job. Surely it is a backend development, but I wonder if it is also covered under the scope of data engineering?\n\nHow do backend developers and data engineers communicate generally?\n\nAnd are there any parts that both do?", "author_fullname": "t2_t1xjvr55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The intersection of DE and Backend Dev.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cglfc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690597909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started writing the backend service with Fiber (GoLang) in my job. Surely it is a backend development, but I wonder if it is also covered under the scope of data engineering?&lt;/p&gt;\n\n&lt;p&gt;How do backend developers and data engineers communicate generally?&lt;/p&gt;\n\n&lt;p&gt;And are there any parts that both do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15cglfc", "is_robot_indexable": true, "report_reasons": null, "author": "gxslash", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cglfc/the_intersection_of_de_and_backend_dev/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cglfc/the_intersection_of_de_and_backend_dev/", "subreddit_subscribers": 118850, "created_utc": 1690597909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello I\u2019m working with some students and want to give them some guidance for a project. They\u2019re analytics students. \n\nWe want to analyze 3 billion rows of data that are currently stored as 2500 or so flat files. We want to do some machine learning and present visualizations on a website. \n\nI generally work in sql server and anaconda but never with data sets this large.\n\nWe can use cloud technology, etc., but need to keep costs to a minimum.\n\nQuestion: how would you store the data? Azure? AWS? What tools would you use to query the data? How would you connect the DB to a machine learning tool and how would you display the results on the web?\n\nObv I can google though I just thought I would try here and see if anyone had quick recommendations. Thank you!", "author_fullname": "t2_6f5ggoc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to store and query 3 billion rows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bvyf1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690546921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello I\u2019m working with some students and want to give them some guidance for a project. They\u2019re analytics students. &lt;/p&gt;\n\n&lt;p&gt;We want to analyze 3 billion rows of data that are currently stored as 2500 or so flat files. We want to do some machine learning and present visualizations on a website. &lt;/p&gt;\n\n&lt;p&gt;I generally work in sql server and anaconda but never with data sets this large.&lt;/p&gt;\n\n&lt;p&gt;We can use cloud technology, etc., but need to keep costs to a minimum.&lt;/p&gt;\n\n&lt;p&gt;Question: how would you store the data? Azure? AWS? What tools would you use to query the data? How would you connect the DB to a machine learning tool and how would you display the results on the web?&lt;/p&gt;\n\n&lt;p&gt;Obv I can google though I just thought I would try here and see if anyone had quick recommendations. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15bvyf1", "is_robot_indexable": true, "report_reasons": null, "author": "wackomama", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bvyf1/how_to_store_and_query_3_billion_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bvyf1/how_to_store_and_query_3_billion_rows/", "subreddit_subscribers": 118850, "created_utc": 1690546921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I created a crash course of Polars library of Python and talked about data types in Polars, reading and writing operations, file handling, and powerful data manipulation techniques. I am leaving the link, have a great day!!\n\n[https://www.youtube.com/watch?v=aiHSMYvoqYE](https://www.youtube.com/watch?v=aiHSMYvoqYE)", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recorded a crash course on Polars library of Python (Great library for working with big data) and uploaded it on Youtube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cnwi1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690622900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I created a crash course of Polars library of Python and talked about data types in Polars, reading and writing operations, file handling, and powerful data manipulation techniques. I am leaving the link, have a great day!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=aiHSMYvoqYE\"&gt;https://www.youtube.com/watch?v=aiHSMYvoqYE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rIeX28O2XfIv3Y4U1OTyTkfRQORKzqxxw43Jw5vYzh4.jpg?auto=webp&amp;s=96140c2eb3acba0ac6beadc2b0fde8a7c5df9dc6", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/rIeX28O2XfIv3Y4U1OTyTkfRQORKzqxxw43Jw5vYzh4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f0cced515ca16fd65de90344f4505be38bae9be1", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/rIeX28O2XfIv3Y4U1OTyTkfRQORKzqxxw43Jw5vYzh4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e2ceb1cb25a99dab9a5756f465fc984003531baa", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/rIeX28O2XfIv3Y4U1OTyTkfRQORKzqxxw43Jw5vYzh4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a691db8960c92445122d69e8eea5a7bf8b600430", "width": 320, "height": 240}], "variants": {}, "id": "_rVKQNaxcPqL1qZYn-JkINnf7oHCvdPuQq4k6I3ej4A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15cnwi1", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cnwi1/i_recorded_a_crash_course_on_polars_library_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cnwi1/i_recorded_a_crash_course_on_polars_library_of/", "subreddit_subscribers": 118850, "created_utc": 1690622900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI wanted to share an exciting new open-source project: **\"Accio(**[**https://getaccio.ai/**](https://getaccio.ai/)**)\"**!\n\nWe've noticed the transformative impact of GraphQL on the web development collaboration between frontend and backend developers, particularly in how it empowers frontend developers to decide how to retrieve data. We believe this revolutionary approach should also be available for Data Engineers and Data Analysts.\n\nThat's where Accio comes in. Think of it as a tool that helps Data Engineers to construct a clear and organized layout of the data, mapping out where everything is, and how it all connects. This includes setting up how to calculate specific numbers from the data, like sums or averages. Here is an example:\n\n    Model Customer @sql('select * from customer') {      \n      custkey: INTEGER! @primaryKey      \n      name: VARCHAR      \n      address: VARCHAR      \n      phone: VARCHAR  \n    }    \n    \n    Model Orders @sql('select * from orders') {      \n      orderkey: INTEGER! @primaryKey      \n      custkey: INTEGER!      \n      totalprice: REAL      \n      customer: Customer @relation(OrdersCustomer)  \n    }    \n    \n    Relation OrdersCustomer @condition(Orders.custkey = Customer.custkey) {      \n      models: [Orders, Customer]      \n      type: \"MANY_TO_ONE\"  \n    }  \n\nThis layout acts much like a schema for Data Analysts. Even with a complex database, they can retrieve the exact information they need with simple queries.\n\nLet's take a real-world business example. Suppose users want to calculate the number of orders in each region. Usually, this would require writing several JOIN conditions to link different tables. But with Accio, all the links are predefined.\n\n    SELECT      \n      customer.nation.region.name as region_name, count(*)   \n    FROM Orders   \n    GROUP BY 1;  \n\nAnd in standard SQL, it should be something like\n\n    SELECT       \n      r.r_name as region_name, count(*)   \n    FROM orders o  \n    JOIN customer c ON o.custkey = c.custkey  \n    JOIN nation n ON n.nationkey = c.nationkey  \n    JOIN region r ON r.regionkey = n.regionkey  \n    GROUP BY 1;  \n\nIn conclusion, Accio redefines data interaction, and how it can be retrieved, making it more accessible. It empowers analysts, and simplifies the work of engineers.\n\nExperience the Accio revolution today and take your data management to the next level!\n\nWebsite: [https://www.getaccio.ai/](https://www.getaccio.ai/)\n\nGitHub:\u00a0[https://github.com/Canner/accio](https://github.com/Canner/accio)\n\nhttps://preview.redd.it/t2k5wkod2qeb1.png?width=1349&amp;format=png&amp;auto=webp&amp;s=c331aa5745d2362d275c95308c08568c2a76d7e7", "author_fullname": "t2_133cio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accio: Query Your Data Warehouse Like Exploring One Big View", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": false, "media_metadata": {"t2k5wkod2qeb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/t2k5wkod2qeb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c89049172ad0a6457593f13845ff8373ea7dfe9"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/t2k5wkod2qeb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=22964ee015fd0507f4379e9b785d5df20bf13ffa"}, {"y": 205, "x": 320, "u": "https://preview.redd.it/t2k5wkod2qeb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=783d1c2a0772776fd6a55290c74a989839b499d0"}, {"y": 410, "x": 640, "u": "https://preview.redd.it/t2k5wkod2qeb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab6db5ca934b862d70b2558a76d89834366f2b3a"}, {"y": 616, "x": 960, "u": "https://preview.redd.it/t2k5wkod2qeb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a9a02c58e4e2b877aa22f3d30b0e3cf56f4ee40"}, {"y": 693, "x": 1080, "u": "https://preview.redd.it/t2k5wkod2qeb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1d09bf7ad5ac8fbe311fb843b76d1e88e8c348ea"}], "s": {"y": 866, "x": 1349, "u": "https://preview.redd.it/t2k5wkod2qeb1.png?width=1349&amp;format=png&amp;auto=webp&amp;s=c331aa5745d2362d275c95308c08568c2a76d7e7"}, "id": "t2k5wkod2qeb1"}}, "name": "t3_15c07lg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-ht-wS-a9KH8dFhb-SGNT7_XultwIcf6ftHar032aWk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690557218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I wanted to share an exciting new open-source project: &lt;strong&gt;&amp;quot;Accio(&lt;/strong&gt;&lt;a href=\"https://getaccio.ai/\"&gt;&lt;strong&gt;https://getaccio.ai/&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;)&amp;quot;&lt;/strong&gt;!&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve noticed the transformative impact of GraphQL on the web development collaboration between frontend and backend developers, particularly in how it empowers frontend developers to decide how to retrieve data. We believe this revolutionary approach should also be available for Data Engineers and Data Analysts.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s where Accio comes in. Think of it as a tool that helps Data Engineers to construct a clear and organized layout of the data, mapping out where everything is, and how it all connects. This includes setting up how to calculate specific numbers from the data, like sums or averages. Here is an example:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Model Customer @sql(&amp;#39;select * from customer&amp;#39;) {      \n  custkey: INTEGER! @primaryKey      \n  name: VARCHAR      \n  address: VARCHAR      \n  phone: VARCHAR  \n}    \n\nModel Orders @sql(&amp;#39;select * from orders&amp;#39;) {      \n  orderkey: INTEGER! @primaryKey      \n  custkey: INTEGER!      \n  totalprice: REAL      \n  customer: Customer @relation(OrdersCustomer)  \n}    \n\nRelation OrdersCustomer @condition(Orders.custkey = Customer.custkey) {      \n  models: [Orders, Customer]      \n  type: &amp;quot;MANY_TO_ONE&amp;quot;  \n}  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This layout acts much like a schema for Data Analysts. Even with a complex database, they can retrieve the exact information they need with simple queries.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s take a real-world business example. Suppose users want to calculate the number of orders in each region. Usually, this would require writing several JOIN conditions to link different tables. But with Accio, all the links are predefined.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT      \n  customer.nation.region.name as region_name, count(*)   \nFROM Orders   \nGROUP BY 1;  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And in standard SQL, it should be something like&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT       \n  r.r_name as region_name, count(*)   \nFROM orders o  \nJOIN customer c ON o.custkey = c.custkey  \nJOIN nation n ON n.nationkey = c.nationkey  \nJOIN region r ON r.regionkey = n.regionkey  \nGROUP BY 1;  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;In conclusion, Accio redefines data interaction, and how it can be retrieved, making it more accessible. It empowers analysts, and simplifies the work of engineers.&lt;/p&gt;\n\n&lt;p&gt;Experience the Accio revolution today and take your data management to the next level!&lt;/p&gt;\n\n&lt;p&gt;Website: &lt;a href=\"https://www.getaccio.ai/\"&gt;https://www.getaccio.ai/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;GitHub:\u00a0&lt;a href=\"https://github.com/Canner/accio\"&gt;https://github.com/Canner/accio&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/t2k5wkod2qeb1.png?width=1349&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c331aa5745d2362d275c95308c08568c2a76d7e7\"&gt;https://preview.redd.it/t2k5wkod2qeb1.png?width=1349&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c331aa5745d2362d275c95308c08568c2a76d7e7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15c07lg", "is_robot_indexable": true, "report_reasons": null, "author": "brandboat", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15c07lg/accio_query_your_data_warehouse_like_exploring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15c07lg/accio_query_your_data_warehouse_like_exploring/", "subreddit_subscribers": 118850, "created_utc": 1690557218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apologies if this is a repeated/obvious question. My company uses UI based tools for building data pipelines. I am new to the team and to DE in general.\n\nI'm worried that working with UI based tools will mean that I will be at a disadvantage skillwise. If I have never built a pipeline from scratch using Scala/Spark or performed performance optimizations through code changes, how will I advance in my career? \n\nIs low-code the future? I will do some MOOCs that teach DE fundamentals through code but I'm worried that won't be enough. What can I do to ensure employability?", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UI based tools disadvantage for career growth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15c1g3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690560054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies if this is a repeated/obvious question. My company uses UI based tools for building data pipelines. I am new to the team and to DE in general.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m worried that working with UI based tools will mean that I will be at a disadvantage skillwise. If I have never built a pipeline from scratch using Scala/Spark or performed performance optimizations through code changes, how will I advance in my career? &lt;/p&gt;\n\n&lt;p&gt;Is low-code the future? I will do some MOOCs that teach DE fundamentals through code but I&amp;#39;m worried that won&amp;#39;t be enough. What can I do to ensure employability?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15c1g3u", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15c1g3u/ui_based_tools_disadvantage_for_career_growth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15c1g3u/ui_based_tools_disadvantage_for_career_growth/", "subreddit_subscribers": 118850, "created_utc": 1690560054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the possible no-JVM tooling around stream processing? What I found:\n- bytewax\n- streamz\n- prefect\n- faust\n\n\nCould you recommend what works for you?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stream processing without JVM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15byd2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690552994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the possible no-JVM tooling around stream processing? What I found:\n- bytewax\n- streamz\n- prefect\n- faust&lt;/p&gt;\n\n&lt;p&gt;Could you recommend what works for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15byd2c", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15byd2c/stream_processing_without_jvm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15byd2c/stream_processing_without_jvm/", "subreddit_subscribers": 118850, "created_utc": 1690552994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a junior data engineer and due to budget cuts within my company it looks like I\u2019m getting laid off. I\u2019ve been with this company for 8 months. My only offer right now is for a cybersecurity job with decent pay for a pretty large company. Assuming that while working in this cybersecurity job, I maintain my knowledge of DE while also practicing leetcode, would it be possible to make the switch back to DE in a year or so? Any help would be appreciated!!", "author_fullname": "t2_9ghl0zs1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE to cybersecurity and then back to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cix3x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690605298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a junior data engineer and due to budget cuts within my company it looks like I\u2019m getting laid off. I\u2019ve been with this company for 8 months. My only offer right now is for a cybersecurity job with decent pay for a pretty large company. Assuming that while working in this cybersecurity job, I maintain my knowledge of DE while also practicing leetcode, would it be possible to make the switch back to DE in a year or so? Any help would be appreciated!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15cix3x", "is_robot_indexable": true, "report_reasons": null, "author": "Perfect_Kangaroo6233", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cix3x/de_to_cybersecurity_and_then_back_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cix3x/de_to_cybersecurity_and_then_back_to_de/", "subreddit_subscribers": 118850, "created_utc": 1690605298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have just started my new job as a junior data engineer a month ago. In the beginning, I was re-designing a relational database, which includes more than +100. As I am at the very beginning of my career, it was nice to have experience with relational systems in detail, before deep diving into dimensional modeling, etc. for a data warehouse later on.\n\nUnfortunately, I'm the only one that works with data in the company (It's a small startup). Because of that, I'm having trouble deciding how the whole system should work. I need to mine data from different sources in batches for scheduled periods. I'm thinking to write this operation using Airflow, and putting the raw data in S3 buckets as parquet files. After merging, cleansing, and quality-checking with Pandas, I'm thinking to insert the data into the database using the API I am writing now. For analytics, I'm planning to take snapshots of the database weekly and insert them into a warehouse (probably Snowflake) using DBT for transformations.\n\nI have no idea if this is a good plan. What tools&amp;frameworks do you recommend me to look at? What sources may help me to cover what's under the hood in batch processing and data mining? As a data engineer titled employee, what other things do I need to check for, or what else is considered in the data engineering scope?", "author_fullname": "t2_t1xjvr55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to Roadmap My Data Engineering Processes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cgjd1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690597990.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690597743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have just started my new job as a junior data engineer a month ago. In the beginning, I was re-designing a relational database, which includes more than +100. As I am at the very beginning of my career, it was nice to have experience with relational systems in detail, before deep diving into dimensional modeling, etc. for a data warehouse later on.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, I&amp;#39;m the only one that works with data in the company (It&amp;#39;s a small startup). Because of that, I&amp;#39;m having trouble deciding how the whole system should work. I need to mine data from different sources in batches for scheduled periods. I&amp;#39;m thinking to write this operation using Airflow, and putting the raw data in S3 buckets as parquet files. After merging, cleansing, and quality-checking with Pandas, I&amp;#39;m thinking to insert the data into the database using the API I am writing now. For analytics, I&amp;#39;m planning to take snapshots of the database weekly and insert them into a warehouse (probably Snowflake) using DBT for transformations.&lt;/p&gt;\n\n&lt;p&gt;I have no idea if this is a good plan. What tools&amp;amp;frameworks do you recommend me to look at? What sources may help me to cover what&amp;#39;s under the hood in batch processing and data mining? As a data engineer titled employee, what other things do I need to check for, or what else is considered in the data engineering scope?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15cgjd1", "is_robot_indexable": true, "report_reasons": null, "author": "gxslash", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cgjd1/struggling_to_roadmap_my_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cgjd1/struggling_to_roadmap_my_data_engineering/", "subreddit_subscribers": 118850, "created_utc": 1690597743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3kxbd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Snowflake makes the dbt Python models shine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 95, "top_awarded_type": null, "hide_score": false, "name": "t3_15c3esa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "#46d160", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0lhtXoin9A4KxO7AFFEhytbpNE5rpinDYF1jIfsQnPM.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690564659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hoffa.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://hoffa.medium.com/how-snowflake-makes-the-dbt-python-models-shine-a36d22960edb", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/F7fZ2spzXIKzKuOYQfwsEKlURYOgRhV8ULo3yu9WFLI.jpg?auto=webp&amp;s=c7b1bce1fdd7638f62e8a054545c79f0d1b91b62", "width": 1200, "height": 821}, "resolutions": [{"url": "https://external-preview.redd.it/F7fZ2spzXIKzKuOYQfwsEKlURYOgRhV8ULo3yu9WFLI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=14ef740b89bbba823c69c3f43e470f801ac1b315", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/F7fZ2spzXIKzKuOYQfwsEKlURYOgRhV8ULo3yu9WFLI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1e0c8a59ca902c7a01689118e033f1a41465b957", "width": 216, "height": 147}, {"url": "https://external-preview.redd.it/F7fZ2spzXIKzKuOYQfwsEKlURYOgRhV8ULo3yu9WFLI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f7869842052fc695047af0dee0a4765a7bfd1e18", "width": 320, "height": 218}, {"url": "https://external-preview.redd.it/F7fZ2spzXIKzKuOYQfwsEKlURYOgRhV8ULo3yu9WFLI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f14548cee6a0800a551461c11ff478eacac88f47", "width": 640, "height": 437}, {"url": "https://external-preview.redd.it/F7fZ2spzXIKzKuOYQfwsEKlURYOgRhV8ULo3yu9WFLI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0f46b60237bf8ce640472d8d89d4cb2826cc5668", "width": 960, "height": 656}, {"url": "https://external-preview.redd.it/F7fZ2spzXIKzKuOYQfwsEKlURYOgRhV8ULo3yu9WFLI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6a053dd9a752c48cbc832fb7d4a5a2ff2ee1470e", "width": 1080, "height": 738}], "variants": {}, "id": "2DgWf4Bw-RtaFtcRfm63FImM3CAK2uai5R9VGfL34Jk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "honorary mod | Snowflake", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15c3esa", "is_robot_indexable": true, "report_reasons": null, "author": "fhoffa", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/15c3esa/how_snowflake_makes_the_dbt_python_models_shine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://hoffa.medium.com/how-snowflake-makes-the-dbt-python-models-shine-a36d22960edb", "subreddit_subscribers": 118850, "created_utc": 1690564659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Back again with another unit testing post.\n\nWhen writing tests for transformations, what is your method for having data to suit your test cases?\n\nWe have 74 tables being ingested in one way or another to support transformations for a singular data domain that have a slew of primary keys and foreign keys used for joins. The keys must match when present. EG table_id is always 1 when occurring in X table for X test scenario.\n\nCurrent method is handwriting the data out to CSV files that are loaded through the dbt seed command. Kinda sucks.\n\nI could write an algo to populate data throughout for this particular data domain, but the engineering cost seems high for being domain specific. Recommendations on solutions that are flexible for multiple domains? Preferably a writable solution. We\u2019re not looking to add *another* tool to the stack, preferably.", "author_fullname": "t2_708ooj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Faux data load for unit testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15c2e83", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690562262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Back again with another unit testing post.&lt;/p&gt;\n\n&lt;p&gt;When writing tests for transformations, what is your method for having data to suit your test cases?&lt;/p&gt;\n\n&lt;p&gt;We have 74 tables being ingested in one way or another to support transformations for a singular data domain that have a slew of primary keys and foreign keys used for joins. The keys must match when present. EG table_id is always 1 when occurring in X table for X test scenario.&lt;/p&gt;\n\n&lt;p&gt;Current method is handwriting the data out to CSV files that are loaded through the dbt seed command. Kinda sucks.&lt;/p&gt;\n\n&lt;p&gt;I could write an algo to populate data throughout for this particular data domain, but the engineering cost seems high for being domain specific. Recommendations on solutions that are flexible for multiple domains? Preferably a writable solution. We\u2019re not looking to add &lt;em&gt;another&lt;/em&gt; tool to the stack, preferably.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15c2e83", "is_robot_indexable": true, "report_reasons": null, "author": "ExistentialFajitas", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15c2e83/faux_data_load_for_unit_testing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15c2e83/faux_data_load_for_unit_testing/", "subreddit_subscribers": 118850, "created_utc": 1690562262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We need both ingestion and cataloging\n\nAdditionally, we have pretty common data sources (salesforce, oracle, MongoDB, etc)\n\nSeeing some discussion: https://www.reddit.com/r/dataengineering/comments/14hhvtr/what_is_your_favorite_data_catalog/jpbg954/", "author_fullname": "t2_vit6d6oc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In what cases would you advocate fivetran over AWS glue or vice versa?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15c16yd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690559659.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690559464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We need both ingestion and cataloging&lt;/p&gt;\n\n&lt;p&gt;Additionally, we have pretty common data sources (salesforce, oracle, MongoDB, etc)&lt;/p&gt;\n\n&lt;p&gt;Seeing some discussion: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14hhvtr/what_is_your_favorite_data_catalog/jpbg954/\"&gt;https://www.reddit.com/r/dataengineering/comments/14hhvtr/what_is_your_favorite_data_catalog/jpbg954/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15c16yd", "is_robot_indexable": true, "report_reasons": null, "author": "poopbrainmane", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15c16yd/in_what_cases_would_you_advocate_fivetran_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15c16yd/in_what_cases_would_you_advocate_fivetran_over/", "subreddit_subscribers": 118850, "created_utc": 1690559464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At a recent meetup I saw guys punting AbInitio for all ETL and WH processes. Is this the way to go? I know it's got some nuances to the language, but it's got some simple looking connectors and components. Is it worth it? Connections I deal with are the normal SQL, XLS, Kafka, etc. I'm proficient in Python and SQL. Will it be tough to learn? And is it worth the effort?", "author_fullname": "t2_11t26p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AbInitio a yes or no?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15cod1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690624550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At a recent meetup I saw guys punting AbInitio for all ETL and WH processes. Is this the way to go? I know it&amp;#39;s got some nuances to the language, but it&amp;#39;s got some simple looking connectors and components. Is it worth it? Connections I deal with are the normal SQL, XLS, Kafka, etc. I&amp;#39;m proficient in Python and SQL. Will it be tough to learn? And is it worth the effort?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15cod1t", "is_robot_indexable": true, "report_reasons": null, "author": "byeproduct", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cod1t/abinitio_a_yes_or_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cod1t/abinitio_a_yes_or_no/", "subreddit_subscribers": 118850, "created_utc": 1690624550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi , I need some help and advice on how stores procedures are being used as data engineer in migration project, from mysql to azure cloud. It says incremental loading.  I am new to this field and role and this is the job , I am reading about stored procedures but simply sql commands, but I am missing how exactly it is used and why? Anyone with such experience can please guide me ? So I can explain this in interview well.", "author_fullname": "t2_t526hbv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stored procedures as a data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15c3mxk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690565175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi , I need some help and advice on how stores procedures are being used as data engineer in migration project, from mysql to azure cloud. It says incremental loading.  I am new to this field and role and this is the job , I am reading about stored procedures but simply sql commands, but I am missing how exactly it is used and why? Anyone with such experience can please guide me ? So I can explain this in interview well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15c3mxk", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Ticket6016", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15c3mxk/stored_procedures_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15c3mxk/stored_procedures_as_a_data_engineer/", "subreddit_subscribers": 118850, "created_utc": 1690565175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, sorry in advance for my english first of all. I have a small company and we are using data warehousing program. Up till now, we take the flow of data of different warehouses, and we manually do the match with our database codification, to be able to utilize the data for statistic ecc.\n\nSince this takes a crapload of time and resources, we start wondering if there is a way/a program to do this work. I make an example:\n\nLet's take a single record (usually the montly flow of data from the warehouse is 10.000-20.000 records), the product description is \"Beautiful Water Still VAP 24 500\". In our database the product description is \"Water Beautiful Vap Still pz24 CL.50\" and the code is 000035. Our work is assign the code 000035 to the original description. Keep in mind that we have plenty of very very similar descriptions, that vary just in format or number of pieces (e.g. \"Water Beautiful Vap Still pz.24 CL.75\"), and this make all our custom solution (excel formulas i.e. v.lookup index match ecc.) struggle, since most of times they match the wrong product.\n\nSo my question is: there are programs that can do a perfect match, even if the description is misleading, incomplete and there are many similar result in the core database? \n\nSorry if this not the right place / the question is too stupid.", "author_fullname": "t2_13p257", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best solution to match different data sources into a single database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bxdth", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690550621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, sorry in advance for my english first of all. I have a small company and we are using data warehousing program. Up till now, we take the flow of data of different warehouses, and we manually do the match with our database codification, to be able to utilize the data for statistic ecc.&lt;/p&gt;\n\n&lt;p&gt;Since this takes a crapload of time and resources, we start wondering if there is a way/a program to do this work. I make an example:&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s take a single record (usually the montly flow of data from the warehouse is 10.000-20.000 records), the product description is &amp;quot;Beautiful Water Still VAP 24 500&amp;quot;. In our database the product description is &amp;quot;Water Beautiful Vap Still pz24 CL.50&amp;quot; and the code is 000035. Our work is assign the code 000035 to the original description. Keep in mind that we have plenty of very very similar descriptions, that vary just in format or number of pieces (e.g. &amp;quot;Water Beautiful Vap Still pz.24 CL.75&amp;quot;), and this make all our custom solution (excel formulas i.e. v.lookup index match ecc.) struggle, since most of times they match the wrong product.&lt;/p&gt;\n\n&lt;p&gt;So my question is: there are programs that can do a perfect match, even if the description is misleading, incomplete and there are many similar result in the core database? &lt;/p&gt;\n\n&lt;p&gt;Sorry if this not the right place / the question is too stupid.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15bxdth", "is_robot_indexable": true, "report_reasons": null, "author": "Leru76", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bxdth/whats_the_best_solution_to_match_different_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bxdth/whats_the_best_solution_to_match_different_data/", "subreddit_subscribers": 118850, "created_utc": 1690550621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The company im working in is an AWS shop now and most of our data sits in S3. My boss is seriously considering Microsoft Data Fabric after meeting with sales team. \n\nCan anyone give an opinion on using Shortcuts in Microsoft Data Fabric to connect to S3 in order to realise a data mesh architecture? Will it rack up massive egress costs from s3?", "author_fullname": "t2_mr7f2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft data fabric and working with AWS via shortcuts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15colib", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690625352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The company im working in is an AWS shop now and most of our data sits in S3. My boss is seriously considering Microsoft Data Fabric after meeting with sales team. &lt;/p&gt;\n\n&lt;p&gt;Can anyone give an opinion on using Shortcuts in Microsoft Data Fabric to connect to S3 in order to realise a data mesh architecture? Will it rack up massive egress costs from s3?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15colib", "is_robot_indexable": true, "report_reasons": null, "author": "detaurus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15colib/microsoft_data_fabric_and_working_with_aws_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15colib/microsoft_data_fabric_and_working_with_aws_via/", "subreddit_subscribers": 118850, "created_utc": 1690625352.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Grab Reduces Traffic Cost for Kafka Consumers on AWS to Zero", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15cnrhf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CHzxOlIdFai73jdps92QFmTBe2u_Muatxm35LWGgVVs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690622386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2023/07/grab-apache-kafka-aws-cost/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?auto=webp&amp;s=0215757ae25713ea844ebf251d8017ef21a46dcf", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8c4b47c1e2c2616fc7bbbd7ab15707f9527f3555", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=97432d70baea78d7c5fd7caa036cd57c55ca5fbb", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=212c8330116c5159534c69e1ffc2f844ecb2b1a2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=39eed804b9cfe931843414614801fc3d0abcce68", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa570a8e3701065aee193930e08baf55979373b5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/qxxJXdmMUJ3dsKeLP7nXD14D7XXZqDZU5I74XsvsEdU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=34802f7b3f0c815b784533832b12539e38a522b6", "width": 1080, "height": 567}], "variants": {}, "id": "aTjRY1Q9I9oaBT4jYUFfCvmgvYk6dxx7itnnM5s6qXs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15cnrhf", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cnrhf/grab_reduces_traffic_cost_for_kafka_consumers_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2023/07/grab-apache-kafka-aws-cost/", "subreddit_subscribers": 118850, "created_utc": 1690622386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m working on a side project. It is to just fetch the data from the API. There are 2 columns which changes its status. Like say - instore availability and online availability of the product.\nMy aim to track these two column to see how much time the product was available instore and how much time the product was online available.\n\nFor now, I have designed a pipeline, that fetches the data from the api and store in GCP cloud storage. The data is appended every time.\nNext I\u2019m planning to apply Slowly Changing Dimension - Type 2, to track both history data and new data. Is it the correct way to do that,? I\u2019m using big query for this step.\n\nAlso to get new data, I would be polling the data every say 15 minutes using Airflow.\n\nFor the target, I would be polling big query and create a dashboard may be using streamlit - https://streamlit.io ( need your inputs here too, since I\u2019m new to creating dashboards )\n\nWhat are your thoughts on this?", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need your inputs on the mentioned scenario", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cjvjs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690608772.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690608485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a side project. It is to just fetch the data from the API. There are 2 columns which changes its status. Like say - instore availability and online availability of the product.\nMy aim to track these two column to see how much time the product was available instore and how much time the product was online available.&lt;/p&gt;\n\n&lt;p&gt;For now, I have designed a pipeline, that fetches the data from the api and store in GCP cloud storage. The data is appended every time.\nNext I\u2019m planning to apply Slowly Changing Dimension - Type 2, to track both history data and new data. Is it the correct way to do that,? I\u2019m using big query for this step.&lt;/p&gt;\n\n&lt;p&gt;Also to get new data, I would be polling the data every say 15 minutes using Airflow.&lt;/p&gt;\n\n&lt;p&gt;For the target, I would be polling big query and create a dashboard may be using streamlit - &lt;a href=\"https://streamlit.io\"&gt;https://streamlit.io&lt;/a&gt; ( need your inputs here too, since I\u2019m new to creating dashboards )&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NXBBgLYiyJjXURFzDGoQsVzAI9Fy597r1v9btldZXsw.jpg?auto=webp&amp;s=70e3c02be5b52bbc6d00188b82f6dfa84a731b65", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/NXBBgLYiyJjXURFzDGoQsVzAI9Fy597r1v9btldZXsw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a92b0d1ef64b226674bd70f1bde51615fe66f9a3", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/NXBBgLYiyJjXURFzDGoQsVzAI9Fy597r1v9btldZXsw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4740ba3d52f606bdfee4a35310a66175f43f95f0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/NXBBgLYiyJjXURFzDGoQsVzAI9Fy597r1v9btldZXsw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e9f6c843305aeadb71a22ccaaf9554276bcdb406", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/NXBBgLYiyJjXURFzDGoQsVzAI9Fy597r1v9btldZXsw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5250c7f9d45c0bd0083d0d3256b63afb177a60c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/NXBBgLYiyJjXURFzDGoQsVzAI9Fy597r1v9btldZXsw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f187a0a348b10af41d73e3eac03d2e02fdd744fa", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/NXBBgLYiyJjXURFzDGoQsVzAI9Fy597r1v9btldZXsw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8be103ecad30e16e3c1bf437e18e92c5238d6d2d", "width": 1080, "height": 567}], "variants": {}, "id": "2GkEr-f7WU61lyrRdUq4Vdk8_qLmlzKzmtn7dmNgzUA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15cjvjs", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15cjvjs/need_your_inputs_on_the_mentioned_scenario/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cjvjs/need_your_inputs_on_the_mentioned_scenario/", "subreddit_subscribers": 118850, "created_utc": 1690608485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any  Linkurious  like software but cheaper? cus  Linkurious  is 990$ per year so for learning purpose, it is kinda expensive... is there any software like  Linkurious  but at lower cost?", "author_fullname": "t2_9wizwc3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linkurious like software but cheaper", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cjv36", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690608435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any  Linkurious  like software but cheaper? cus  Linkurious  is 990$ per year so for learning purpose, it is kinda expensive... is there any software like  Linkurious  but at lower cost?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15cjv36", "is_robot_indexable": true, "report_reasons": null, "author": "justwaiyan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cjv36/linkurious_like_software_but_cheaper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cjv36/linkurious_like_software_but_cheaper/", "subreddit_subscribers": 118850, "created_utc": 1690608435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear r/dataenginering,\n\nI'm seeking a solution that supports performing ETL on petabyte-sized data and subsequent ML deployment. \n\nHigh-level production stages are:\n\nPerform ETL -&gt; Feed features to a model -&gt; Calculate predictions -&gt; Save predictions to the database\n\nSo far, I have found 5 possible combinations to make this work:  \n1) pyspark for ETL + Ray for ML deployment. \n\n2) Spark on Ray (Ray DP) for ETL + Ray for ML. This is an integrated solution: [https://github.com/oap-project/raydp](https://github.com/oap-project/raydp).\n\n3) Dask on Ray for ETL + Ray for ML. \n\n4) Standalone Dask.\n\n5) Standalone pyspark.\n\nIn addition to production deployment, I plan to use the stack for data science experiments. Ideally, I'd want to perform data computations on a remote cluster via local Jupyter. A great example is [https://www.youtube.com/watch?v=nH\\_AQo8WdKw](https://www.youtube.com/watch?v=nH_AQo8WdKw).  \n\n\nI want to get the best-performing solution that fits the use cases. Any suggestion are highly appreciated! Thanks.  \n\n\n&amp;#x200B;", "author_fullname": "t2_en4s89gx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please help me choose a stack (Spark, Ray, Dask, Modin)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15cgqni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690598347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear &lt;a href=\"/r/dataenginering\"&gt;r/dataenginering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seeking a solution that supports performing ETL on petabyte-sized data and subsequent ML deployment. &lt;/p&gt;\n\n&lt;p&gt;High-level production stages are:&lt;/p&gt;\n\n&lt;p&gt;Perform ETL -&amp;gt; Feed features to a model -&amp;gt; Calculate predictions -&amp;gt; Save predictions to the database&lt;/p&gt;\n\n&lt;p&gt;So far, I have found 5 possible combinations to make this work:&lt;br/&gt;\n1) pyspark for ETL + Ray for ML deployment. &lt;/p&gt;\n\n&lt;p&gt;2) Spark on Ray (Ray DP) for ETL + Ray for ML. This is an integrated solution: &lt;a href=\"https://github.com/oap-project/raydp\"&gt;https://github.com/oap-project/raydp&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;3) Dask on Ray for ETL + Ray for ML. &lt;/p&gt;\n\n&lt;p&gt;4) Standalone Dask.&lt;/p&gt;\n\n&lt;p&gt;5) Standalone pyspark.&lt;/p&gt;\n\n&lt;p&gt;In addition to production deployment, I plan to use the stack for data science experiments. Ideally, I&amp;#39;d want to perform data computations on a remote cluster via local Jupyter. A great example is &lt;a href=\"https://www.youtube.com/watch?v=nH_AQo8WdKw\"&gt;https://www.youtube.com/watch?v=nH_AQo8WdKw&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;I want to get the best-performing solution that fits the use cases. Any suggestion are highly appreciated! Thanks.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yTbjYpUxUlF0AiC10_MnpoBIcUc597PtyJ65Lzrl9yI.jpg?auto=webp&amp;s=153c7aaa0e3eb794afc025cc78339d5354f787c0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/yTbjYpUxUlF0AiC10_MnpoBIcUc597PtyJ65Lzrl9yI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b08382c1d1a87912293a4d86c38da136d24d5d93", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/yTbjYpUxUlF0AiC10_MnpoBIcUc597PtyJ65Lzrl9yI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2671d57c1e6b74bbc0b590a4bfbe0b9a56568775", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/yTbjYpUxUlF0AiC10_MnpoBIcUc597PtyJ65Lzrl9yI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7b36a315773a7d206164a50e5fe8947a683ffe3", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/yTbjYpUxUlF0AiC10_MnpoBIcUc597PtyJ65Lzrl9yI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0df101d0c2553e5f26bc89d32da610de1c1caf25", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/yTbjYpUxUlF0AiC10_MnpoBIcUc597PtyJ65Lzrl9yI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49508f5345ac22cd9f5f00d2dff74a177eb7cc6f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/yTbjYpUxUlF0AiC10_MnpoBIcUc597PtyJ65Lzrl9yI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=da1a37a27635498cf9f31577ed0d73195cfeee7e", "width": 1080, "height": 540}], "variants": {}, "id": "v8_QSyChaxiwWfo6zTA_Vv6f536PrbAbpbQFhd-i0eY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15cgqni", "is_robot_indexable": true, "report_reasons": null, "author": "nirewi1508", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15cgqni/please_help_me_choose_a_stack_spark_ray_dask_modin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15cgqni/please_help_me_choose_a_stack_spark_ray_dask_modin/", "subreddit_subscribers": 118850, "created_utc": 1690598347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accelerating Database Backup and Restore with MinIO Jumbo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "name": "t3_15ca9wz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/efH0WMj1xDl7BQxsjuer8GUzQ6FlciirfNzBd2cXPHc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690580976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/database-backup-restore-minio-jumbo/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z4n6djwjc7Yo3UJt1z_sCDy9F1LfduqGMa9V8LEyAAY.jpg?auto=webp&amp;s=60fff997116299dfdd2da7fd81149f35fea29748", "width": 2000, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/Z4n6djwjc7Yo3UJt1z_sCDy9F1LfduqGMa9V8LEyAAY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6e2cc1dc246e5bb8ef2adf4da884da1a2bbd946b", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/Z4n6djwjc7Yo3UJt1z_sCDy9F1LfduqGMa9V8LEyAAY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4bb3bfd2aecd720a14b5ebe154b4c017956ccac", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/Z4n6djwjc7Yo3UJt1z_sCDy9F1LfduqGMa9V8LEyAAY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2fb33fb108ff67c43183f71a2250eb31548f7bf0", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/Z4n6djwjc7Yo3UJt1z_sCDy9F1LfduqGMa9V8LEyAAY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e43da3bcc93207f28cb00e232610d16a4694ba85", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/Z4n6djwjc7Yo3UJt1z_sCDy9F1LfduqGMa9V8LEyAAY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d40482d7bdac3d21fca3b216d8ebceda8a6f9db", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/Z4n6djwjc7Yo3UJt1z_sCDy9F1LfduqGMa9V8LEyAAY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bd78cd204a6579cfc4e8b0c7a95d250cbe56083e", "width": 1080, "height": 322}], "variants": {}, "id": "44re98amqjYQ1qHRNCzfflGHesJslWH-vk8FS4pZeaE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ca9wz", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ca9wz/accelerating_database_backup_and_restore_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/database-backup-restore-minio-jumbo/", "subreddit_subscribers": 118850, "created_utc": 1690580976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an aspiring data engineer intern, and I've been presented with an exciting opportunity to work on a mini-side project for my team. My manager has entrusted me with creating a data model scheme, which will be crucial for our data engineering processes. However, I'm feeling a bit overwhelmed and could really use some help and guidance from the experienced members of this community.\n\nProject Background:\nAs part of my internship, I'm trying to transition to the data engineering team, and this project is a fantastic chance for me to showcase my skills and prove my worth. The data model scheme I'm working on will be used to organize and structure our data, ensuring efficiency, reliability, and ease of access for various data engineering tasks.\n\nThe Ask:\nI'm reaching out to all the experienced data engineers, architects, and anyone knowledgeable in data modeling to lend me your expertise and advice. If you have experience in designing data models or have insights into best practices, I'd greatly appreciate any feedback you can provide.\n\nWhat I'm Hoping For:\nTips and best practices for data modeling and schema design. This is my first data model so roast me!!!!\n\nLink to the reference: https://docs.uipath.com/insights/automation-cloud/latest/user-guide/real-time-data-export-data-model", "author_fullname": "t2_814w9dxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking guidance for data modeling scheme creation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 110, "top_awarded_type": null, "hide_score": false, "name": "t3_15c66g0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jy28-XLz3b2STFyIbBfPyUpx7RiNv9WYuKMqYmbX8us.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690571181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an aspiring data engineer intern, and I&amp;#39;ve been presented with an exciting opportunity to work on a mini-side project for my team. My manager has entrusted me with creating a data model scheme, which will be crucial for our data engineering processes. However, I&amp;#39;m feeling a bit overwhelmed and could really use some help and guidance from the experienced members of this community.&lt;/p&gt;\n\n&lt;p&gt;Project Background:\nAs part of my internship, I&amp;#39;m trying to transition to the data engineering team, and this project is a fantastic chance for me to showcase my skills and prove my worth. The data model scheme I&amp;#39;m working on will be used to organize and structure our data, ensuring efficiency, reliability, and ease of access for various data engineering tasks.&lt;/p&gt;\n\n&lt;p&gt;The Ask:\nI&amp;#39;m reaching out to all the experienced data engineers, architects, and anyone knowledgeable in data modeling to lend me your expertise and advice. If you have experience in designing data models or have insights into best practices, I&amp;#39;d greatly appreciate any feedback you can provide.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m Hoping For:\nTips and best practices for data modeling and schema design. This is my first data model so roast me!!!!&lt;/p&gt;\n\n&lt;p&gt;Link to the reference: &lt;a href=\"https://docs.uipath.com/insights/automation-cloud/latest/user-guide/real-time-data-export-data-model\"&gt;https://docs.uipath.com/insights/automation-cloud/latest/user-guide/real-time-data-export-data-model&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yint0x038reb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yint0x038reb1.jpg?auto=webp&amp;s=4b18d8a314e3d146f76fc254b759e5d67628bd6a", "width": 2981, "height": 2358}, "resolutions": [{"url": "https://preview.redd.it/yint0x038reb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d59bf10c7bde2bad765ed66c1a1d9ac7b4d00761", "width": 108, "height": 85}, {"url": "https://preview.redd.it/yint0x038reb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7477a90ebb7fb2a8ba9714095a4af8a0cc322d74", "width": 216, "height": 170}, {"url": "https://preview.redd.it/yint0x038reb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ca30ac3c18ce6792e6bce0a520fbc633b839f328", "width": 320, "height": 253}, {"url": "https://preview.redd.it/yint0x038reb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9c3cb6baf1774b5c6352053d064951ff13f73529", "width": 640, "height": 506}, {"url": "https://preview.redd.it/yint0x038reb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=729a31ed64cf17a4ddba679932f6220f767168e1", "width": 960, "height": 759}, {"url": "https://preview.redd.it/yint0x038reb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fb75acf4bc3da05a0c0519acc5b8a6a50e8e0fc9", "width": 1080, "height": 854}], "variants": {}, "id": "V9hRtrWfwhTA1p02YAgY3KpcJ609UKM9h6KyvQ2PEKw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15c66g0", "is_robot_indexable": true, "report_reasons": null, "author": "Fragrant-Switch-9881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15c66g0/seeking_guidance_for_data_modeling_scheme_creation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yint0x038reb1.jpg", "subreddit_subscribers": 118850, "created_utc": 1690571181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data analyst slowly transitioning into data engineering. I have good knowledge of python modules related to data analysis.\n\nNow, our vendor has provided APIs to request data. For example, let's say there is a sales API. The API format is such that I will have to enter date_1 and date_2 to get sales from date_1 to date_2.\n\nwww.dumnyurl.com/saleslines/date_1/date_2\n\nI want to create a dashboard or interface where I can have the end user enter date_1 and date_2 and then a button to retrieve the data. \n\nMy org. currently have powerbi but there doesn't seem to be this functionality in powerbi. I also read about using dash, but how would I be able to provide access to the dashboard to only people in my organisation and stop outside access. Can something low cost be done on Azure cloud for this?\n\nI was just wondering if anyone has worked on something like this before or if there are any recommended solutions.", "author_fullname": "t2_t05ji4fs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Options for creating an end user interface for an API call", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bx2hn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690549841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst slowly transitioning into data engineering. I have good knowledge of python modules related to data analysis.&lt;/p&gt;\n\n&lt;p&gt;Now, our vendor has provided APIs to request data. For example, let&amp;#39;s say there is a sales API. The API format is such that I will have to enter date_1 and date_2 to get sales from date_1 to date_2.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.dumnyurl.com/saleslines/date_1/date_2\"&gt;www.dumnyurl.com/saleslines/date_1/date_2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I want to create a dashboard or interface where I can have the end user enter date_1 and date_2 and then a button to retrieve the data. &lt;/p&gt;\n\n&lt;p&gt;My org. currently have powerbi but there doesn&amp;#39;t seem to be this functionality in powerbi. I also read about using dash, but how would I be able to provide access to the dashboard to only people in my organisation and stop outside access. Can something low cost be done on Azure cloud for this?&lt;/p&gt;\n\n&lt;p&gt;I was just wondering if anyone has worked on something like this before or if there are any recommended solutions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15bx2hn", "is_robot_indexable": true, "report_reasons": null, "author": "kkchn001", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bx2hn/options_for_creating_an_end_user_interface_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bx2hn/options_for_creating_an_end_user_interface_for_an/", "subreddit_subscribers": 118850, "created_utc": 1690549841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, \n\nIm preparing for azure dp -203 certification and I really want to practice services in azure. Due to some work issue I was not able to make use of $200 credits free trial, now it is over and asking for pay as u go subscription and here in this subscription it is charging amount for some of the resources, I hardly practiced anything. I need to practice different resources required for data engineering and do some projects which would help to get a job. I don't even have student id. May I please please know is there any other way we can access azure resources for free. \n\nI have already wasted most of my time is searching how can I acess free subscription to practice.\nIt would be really helpful if I get some tips here. \n\nThank you.", "author_fullname": "t2_adz0yno6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get free azure subscription(I do t have student id and by 1 month free trial credits are over)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15bzh0d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690555538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, &lt;/p&gt;\n\n&lt;p&gt;Im preparing for azure dp -203 certification and I really want to practice services in azure. Due to some work issue I was not able to make use of $200 credits free trial, now it is over and asking for pay as u go subscription and here in this subscription it is charging amount for some of the resources, I hardly practiced anything. I need to practice different resources required for data engineering and do some projects which would help to get a job. I don&amp;#39;t even have student id. May I please please know is there any other way we can access azure resources for free. &lt;/p&gt;\n\n&lt;p&gt;I have already wasted most of my time is searching how can I acess free subscription to practice.\nIt would be really helpful if I get some tips here. &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15bzh0d", "is_robot_indexable": true, "report_reasons": null, "author": "Brunda_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15bzh0d/how_to_get_free_azure_subscriptioni_do_t_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15bzh0d/how_to_get_free_azure_subscriptioni_do_t_have/", "subreddit_subscribers": 118850, "created_utc": 1690555538.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}