{"kind": "Listing", "data": {"after": "t3_15ah9wf", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Turns out databases are \"relational\" or something", "author_fullname": "t2_qlmkijv8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The data engineer came to me... tears in his eyes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 107, "top_awarded_type": null, "hide_score": false, "name": "t3_15ae6kp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 145, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 145, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w5lBiBLnqC1xzIdkywBWCqB0YGYQeRWrqr08EMByD2s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690397313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Turns out databases are &amp;quot;relational&amp;quot; or something&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1wm37l33vceb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1wm37l33vceb1.png?auto=webp&amp;s=8eb68cc0feab067c94c5d88ca54a7eda2cbfcfd2", "width": 1080, "height": 830}, "resolutions": [{"url": "https://preview.redd.it/1wm37l33vceb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=48652b42e4fe71b9c48eac0b2a2c6a0eaaad045b", "width": 108, "height": 83}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=79d5b3781803dce41f5534196cb74c8f84aa1caa", "width": 216, "height": 166}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=afdafe3ea62eae50680c1797cac89dd8c6010a0f", "width": 320, "height": 245}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=992489262d93f2834aba10c908b504e4f58e328a", "width": 640, "height": 491}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=97be176695471f82f58a8349a936a5d2c170eaf9", "width": 960, "height": 737}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b45cda7bf48386140f347a041f725b62cbbe33b", "width": 1080, "height": 830}], "variants": {}, "id": "UwqiG5dVs8n80MCeWPA1--klG-ySKne2YEq3LyGRi8k"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15ae6kp", "is_robot_indexable": true, "report_reasons": null, "author": "shed_antlers", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ae6kp/the_data_engineer_came_to_me_tears_in_his_eyes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1wm37l33vceb1.png", "subreddit_subscribers": 118210, "created_utc": 1690397313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great Expectations is bloaty. What are the alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a45gt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690373573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15a45gt", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "subreddit_subscribers": 118210, "created_utc": 1690373573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started my career as a data engineer. I have been learning a lot at work, but I think it\u2019s slowing down and not fast enough. I really want to get good at data engineering, I aspire to become a better data engineer. What can I do during my spare time to work on that? I am planning to start work on Leetcode, to practice my Python and build up DSA knowledge. What else can I do to learn faster?\n\nI use mainly SQL and no code GUI for ETL (which is bad I believe)", "author_fullname": "t2_b4x7m5t6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I become a better data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159v9e8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690345164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started my career as a data engineer. I have been learning a lot at work, but I think it\u2019s slowing down and not fast enough. I really want to get good at data engineering, I aspire to become a better data engineer. What can I do during my spare time to work on that? I am planning to start work on Leetcode, to practice my Python and build up DSA knowledge. What else can I do to learn faster?&lt;/p&gt;\n\n&lt;p&gt;I use mainly SQL and no code GUI for ETL (which is bad I believe)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159v9e8", "is_robot_indexable": true, "report_reasons": null, "author": "heyveryfunny", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159v9e8/how_do_i_become_a_better_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159v9e8/how_do_i_become_a_better_data_engineer/", "subreddit_subscribers": 118210, "created_utc": 1690345164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow data enthusiasts!\n\nI've recently been hired to work in a new small DE team, and I've been tasked with building a more \"big data\" environment for our company. Unfortunately, we have a strict policy against using cloud storage, so I'm looking for recommendations and guidance on creating a robust solution with open-source tools only.\n\nCurrently, most of our data (CDRs files) is continuously stored on a server using cron jobs, and we load it into Oracle. Additionally, we have dblinks connections from other databases to our main Oracle database. However, we're facing some challenges with slow PowerBI dashboards due to the large volume of data ( hundreds of billions of rows), complex joins, and aggregation functions.\n\n&amp;#x200B;\n\nHere's what I'm thinking of for our new environment:\n\n1. Data Ingestion: I'm considering using Apache Airflow and Kafka. or is kafka overkill ? any alternative if ?\n2. Data Processing: Spark seems like a great choice for data processing ?\n3. Datalake: I've come across HDFS as a popular choice, but I'm also curious about other alternative as I heard Hadoop is a pain to manage. Any experiences or feedback on Minio?\n4. Analytics Oriented Database: As our PowerBI dashboards are becoming slower with increasing data volume (overload Oracle) , I believe it's essential to have an analytics-oriented database to improve performance. I'd love to hear your recommendations for databases that work well with PowerBI and can handle large-scale analytical workloads.\n\nOur ultimate goal is to not only improve the performance of our current analytical processes but also lay the groundwork for \"potential future\" machine learning projects.\n\nIf you have any experience, suggestions, or advice regarding these components or any other tool that you think could enhance our environment, please share your insights! I greatly appreciate any help you can provide.\n\nFeel free to ask for more details if needed. Thank you for taking the time to read this post!", "author_fullname": "t2_kfjsv6pf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommandation needed for building an Open Source pipeline / datalake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159yg87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690359315.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690355604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow data enthusiasts!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently been hired to work in a new small DE team, and I&amp;#39;ve been tasked with building a more &amp;quot;big data&amp;quot; environment for our company. Unfortunately, we have a strict policy against using cloud storage, so I&amp;#39;m looking for recommendations and guidance on creating a robust solution with open-source tools only.&lt;/p&gt;\n\n&lt;p&gt;Currently, most of our data (CDRs files) is continuously stored on a server using cron jobs, and we load it into Oracle. Additionally, we have dblinks connections from other databases to our main Oracle database. However, we&amp;#39;re facing some challenges with slow PowerBI dashboards due to the large volume of data ( hundreds of billions of rows), complex joins, and aggregation functions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I&amp;#39;m thinking of for our new environment:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Ingestion: I&amp;#39;m considering using Apache Airflow and Kafka. or is kafka overkill ? any alternative if ?&lt;/li&gt;\n&lt;li&gt;Data Processing: Spark seems like a great choice for data processing ?&lt;/li&gt;\n&lt;li&gt;Datalake: I&amp;#39;ve come across HDFS as a popular choice, but I&amp;#39;m also curious about other alternative as I heard Hadoop is a pain to manage. Any experiences or feedback on Minio?&lt;/li&gt;\n&lt;li&gt;Analytics Oriented Database: As our PowerBI dashboards are becoming slower with increasing data volume (overload Oracle) , I believe it&amp;#39;s essential to have an analytics-oriented database to improve performance. I&amp;#39;d love to hear your recommendations for databases that work well with PowerBI and can handle large-scale analytical workloads.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Our ultimate goal is to not only improve the performance of our current analytical processes but also lay the groundwork for &amp;quot;potential future&amp;quot; machine learning projects.&lt;/p&gt;\n\n&lt;p&gt;If you have any experience, suggestions, or advice regarding these components or any other tool that you think could enhance our environment, please share your insights! I greatly appreciate any help you can provide.&lt;/p&gt;\n\n&lt;p&gt;Feel free to ask for more details if needed. Thank you for taking the time to read this post!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159yg87", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_War6424", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159yg87/recommandation_needed_for_building_an_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159yg87/recommandation_needed_for_building_an_open_source/", "subreddit_subscribers": 118210, "created_utc": 1690355604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gxlue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why JSON still rocks as a format for data lakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "name": "t3_159lfpu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QkrFPbGLgQt_fuj6g_1E0SKdylh0jkDw6IBVB6uyHjU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690320045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "opendatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://opendatascience.com/choosing-a-data-lake-format-what-to-actually-look-for/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?auto=webp&amp;s=15ae1e8a8050436aed75049ca4b948c53c5d9915", "width": 640, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=41801bd050610bf9e2348de7a544a0e5edd482ff", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=811cc432778ab2e43e8ec8e9e3e299b59b3fd864", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9a6dd6572b02906f9f4ef731baf72a24bfe3592b", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=afe1e23618374a28450a0abece2ccdc9610cadd2", "width": 640, "height": 300}], "variants": {}, "id": "r9qfcfrYWA9wAXPOHHaOzOE10XGpP8py2K_jMNXGL2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "159lfpu", "is_robot_indexable": true, "report_reasons": null, "author": "artsyfartsiest", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159lfpu/why_json_still_rocks_as_a_format_for_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://opendatascience.com/choosing-a-data-lake-format-what-to-actually-look-for/", "subreddit_subscribers": 118210, "created_utc": 1690320045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer at one of the big techs, and I'm considering a role as a Specialist Solutions Architect at Databricks. It specializes on data engineering but it seems to be a lot of customer facing role, which is different from my current role.\n\nHow is this position in terms of career progression? I do want the option to get back to data or software engineering in the future, and I feel I will get shoed in to a client facing role if I take this.\n\nAlso if anyone knows anything about the pros and cons of this position at Databricks, like wlb/comp, etc. I would love to know!", "author_fullname": "t2_ih0l5i9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solutions Architect role at Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a26zd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690368116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer at one of the big techs, and I&amp;#39;m considering a role as a Specialist Solutions Architect at Databricks. It specializes on data engineering but it seems to be a lot of customer facing role, which is different from my current role.&lt;/p&gt;\n\n&lt;p&gt;How is this position in terms of career progression? I do want the option to get back to data or software engineering in the future, and I feel I will get shoed in to a client facing role if I take this.&lt;/p&gt;\n\n&lt;p&gt;Also if anyone knows anything about the pros and cons of this position at Databricks, like wlb/comp, etc. I would love to know!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15a26zd", "is_robot_indexable": true, "report_reasons": null, "author": "DataApe", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a26zd/solutions_architect_role_at_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a26zd/solutions_architect_role_at_databricks/", "subreddit_subscribers": 118210, "created_utc": 1690368116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a backend developer involved in building an analytics pipeline for our application to display usage statistics to our users. I had no training in data engineering so far.\n\nBefore reading about ELT, I had an idea to utilize an AWS Glue job to extract data from the source (MySQL), transform it within the same Glue job, and load the resulting set into a data warehouse to perform queries. But as I understand, this would be a classic ETL approach.\n\nBut the ELT approach, as I understand it, would look different: utilize an AWS Glue job to load data into a data warehouse as is (basically copy the existing MySQL tables there), and then transform data using queries like:\n\n    INSERT into table3\n    SELECT table1.column_a, table1.column_b, table2.column_c, table2.column_d, FROM table1\n    JOIN table2\n\nEvery source I read mentions that the ELT is a superior and more recent approach than ETL.\n\nBut I don't feel like this. I have a couple of concerns about ELT:\n\n* With ETL, the tool (AWS Glue) would maintain incremental data extraction. With ELT, I must implement a mechanism for incremental data transformation (e.g. only insert changed rows into *table3*)\n* AWS Glue performs transformations in parallel. This is not likely the case for relational databases like MySQL, as it would process the query above on a single node.\n\nSo my questions are:\n\n* Are there flaws in my understanding of ELT?\n* Which databases/tools can act as data warehouses which support incremental load and parallelism?\n* Which of them are available in AWS?\n\nI'd also prefer not to use sophisticated or enterprise tools since we don't have lots of data (less than 10M rows). Thanks.", "author_fullname": "t2_zkr4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which databases are good for ELT (Extract-Load-Transform)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a0sux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690363720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a backend developer involved in building an analytics pipeline for our application to display usage statistics to our users. I had no training in data engineering so far.&lt;/p&gt;\n\n&lt;p&gt;Before reading about ELT, I had an idea to utilize an AWS Glue job to extract data from the source (MySQL), transform it within the same Glue job, and load the resulting set into a data warehouse to perform queries. But as I understand, this would be a classic ETL approach.&lt;/p&gt;\n\n&lt;p&gt;But the ELT approach, as I understand it, would look different: utilize an AWS Glue job to load data into a data warehouse as is (basically copy the existing MySQL tables there), and then transform data using queries like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;INSERT into table3\nSELECT table1.column_a, table1.column_b, table2.column_c, table2.column_d, FROM table1\nJOIN table2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Every source I read mentions that the ELT is a superior and more recent approach than ETL.&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t feel like this. I have a couple of concerns about ELT:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;With ETL, the tool (AWS Glue) would maintain incremental data extraction. With ELT, I must implement a mechanism for incremental data transformation (e.g. only insert changed rows into &lt;em&gt;table3&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;AWS Glue performs transformations in parallel. This is not likely the case for relational databases like MySQL, as it would process the query above on a single node.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So my questions are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are there flaws in my understanding of ELT?&lt;/li&gt;\n&lt;li&gt;Which databases/tools can act as data warehouses which support incremental load and parallelism?&lt;/li&gt;\n&lt;li&gt;Which of them are available in AWS?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d also prefer not to use sophisticated or enterprise tools since we don&amp;#39;t have lots of data (less than 10M rows). Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a0sux", "is_robot_indexable": true, "report_reasons": null, "author": "binary-data", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a0sux/which_databases_are_good_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a0sux/which_databases_are_good_for_elt/", "subreddit_subscribers": 118210, "created_utc": 1690363720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have around 500+ GB of data per day with 800 columns that I need to load into Redshift for 5 years worth of data. However, the data loading process is quite slow using copy command from s3 to redshift. Any suggestions on how to optimize and speed up the data loading in Redshift", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load huge volume of data to redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159wr91", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690349909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 500+ GB of data per day with 800 columns that I need to load into Redshift for 5 years worth of data. However, the data loading process is quite slow using copy command from s3 to redshift. Any suggestions on how to optimize and speed up the data loading in Redshift&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159wr91", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159wr91/load_huge_volume_of_data_to_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159wr91/load_huge_volume_of_data_to_redshift/", "subreddit_subscribers": 118210, "created_utc": 1690349909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I'm working on AWS and have it available for experiments.\n\nIf you have any guide/tutorial/walkthrough to recommend, please do share!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend a good k8s / EKS guide?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a32at", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690370610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I&amp;#39;m working on AWS and have it available for experiments.&lt;/p&gt;\n\n&lt;p&gt;If you have any guide/tutorial/walkthrough to recommend, please do share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a32at", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "subreddit_subscribers": 118210, "created_utc": 1690370610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm consulting with a team of data engineers as a solution architect. Long story short, they're looking to do some work for this customer that will entail hopping into the database and doing the normal thing of writing procs and such to enable some capabilities like automated quality checking/testing, enforcing constraints, yada yada. \n\nI've worked quite a bit with GIS and with most of ESRIs products, but this was the first time really looking at the table-level structure of an ArcGIS warehouse and it doesn't seem like the team I'm on really had either. Some quick googling didn't return any solid leads, but does anybody know of any best practices when developing capabilities within or next to a running enterprise level ESRI warehouse?", "author_fullname": "t2_fp2tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for working within ArcGis Warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159s722", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690336366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m consulting with a team of data engineers as a solution architect. Long story short, they&amp;#39;re looking to do some work for this customer that will entail hopping into the database and doing the normal thing of writing procs and such to enable some capabilities like automated quality checking/testing, enforcing constraints, yada yada. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve worked quite a bit with GIS and with most of ESRIs products, but this was the first time really looking at the table-level structure of an ArcGIS warehouse and it doesn&amp;#39;t seem like the team I&amp;#39;m on really had either. Some quick googling didn&amp;#39;t return any solid leads, but does anybody know of any best practices when developing capabilities within or next to a running enterprise level ESRI warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159s722", "is_robot_indexable": true, "report_reasons": null, "author": "lostinthewalls", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159s722/best_practices_for_working_within_arcgis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159s722/best_practices_for_working_within_arcgis/", "subreddit_subscribers": 118210, "created_utc": 1690336366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019m a Data Scientist of 5 years out of a job and have just got an interview for a Data Engineer role coming up. I\u2019m thinking it\u2019s a good role as I like the engineering stuff, and really need a job!\n\n So my questions are: \n1) What topics are worth focusing my prep/study on? \n2) I need to prepare a set of a few slides about a recent DE end to end project I\u2019ve worked on. Any tips on that, as I have created a feature store for ML before, and have some personal projects too?\n\nThanks for any advice and tips!", "author_fullname": "t2_7kdevi10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist interviewing for a Data Engineering role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a02oy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690361223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m a Data Scientist of 5 years out of a job and have just got an interview for a Data Engineer role coming up. I\u2019m thinking it\u2019s a good role as I like the engineering stuff, and really need a job!&lt;/p&gt;\n\n&lt;p&gt;So my questions are: \n1) What topics are worth focusing my prep/study on? \n2) I need to prepare a set of a few slides about a recent DE end to end project I\u2019ve worked on. Any tips on that, as I have created a feature store for ML before, and have some personal projects too?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice and tips!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15a02oy", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive_Fact_6561", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a02oy/data_scientist_interviewing_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a02oy/data_scientist_interviewing_for_a_data/", "subreddit_subscribers": 118210, "created_utc": 1690361223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "50-60GB database on aurora, everythings fine on writes/updates and transactional operations. We hooked the db to be used as analytics dashboard pulling a fair amount of data but disk i/o is extremely slow from query plan around 5-15mb/s. Bumping up instance ram and loading all working database into shared_buffers cache everything works fine. So I came up to the following conclusions:\n\n- aws aurora is basically unusable for olap workloads as i/o timings are terribly slow (and couldn't find an official figure from aws)\n- aws aurora storage layer uses a storage attached network observed disk i/o is very low and there is no OS level cache so they recommend loading up all databse in memory\n- does aws rds postgres with provisioned ssd suffer from the same problem? iops and throughput are 100x better on paper\n- anyone had similar experiences with aurora and working with relatively large datasets?\n- considering moving to redshift", "author_fullname": "t2_b5vlra5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Aurora not usable for OLAP workloads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15agi5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690402621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;50-60GB database on aurora, everythings fine on writes/updates and transactional operations. We hooked the db to be used as analytics dashboard pulling a fair amount of data but disk i/o is extremely slow from query plan around 5-15mb/s. Bumping up instance ram and loading all working database into shared_buffers cache everything works fine. So I came up to the following conclusions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;aws aurora is basically unusable for olap workloads as i/o timings are terribly slow (and couldn&amp;#39;t find an official figure from aws)&lt;/li&gt;\n&lt;li&gt;aws aurora storage layer uses a storage attached network observed disk i/o is very low and there is no OS level cache so they recommend loading up all databse in memory&lt;/li&gt;\n&lt;li&gt;does aws rds postgres with provisioned ssd suffer from the same problem? iops and throughput are 100x better on paper&lt;/li&gt;\n&lt;li&gt;anyone had similar experiences with aurora and working with relatively large datasets?&lt;/li&gt;\n&lt;li&gt;considering moving to redshift&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15agi5q", "is_robot_indexable": true, "report_reasons": null, "author": "golangcafe", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15agi5q/aws_aurora_not_usable_for_olap_workloads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15agi5q/aws_aurora_not_usable_for_olap_workloads/", "subreddit_subscribers": 118210, "created_utc": 1690402621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a cs software manager at a public company. I\u2019m not currently in a data engineering role, but I want to make a pivot into DE. I\u2019ve had a DE ticket open for several months for them just to scope and there\u2019s no end in sight. It could be several more months before they can even think about looking at our ticket. Suffice it to say our DE team is under resourced. \n\nThis is where I feel that maybe I\u2019m being naive: I feel like the request is simple. We want to create a daily job for some API reports and bring it into our data warehouse. \n\nHow many hoops does one need to jump through in a mid-level organization to write a script then push it to the warehouse? \n\nWhat level of difficulty is this normally? \n\nWould it be rude to write the script and hand it over to the DE team?\n\nLooking for advice to navigate the situation. Thanks!", "author_fullname": "t2_b7jxy4i2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I being naive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ad17i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690394712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a cs software manager at a public company. I\u2019m not currently in a data engineering role, but I want to make a pivot into DE. I\u2019ve had a DE ticket open for several months for them just to scope and there\u2019s no end in sight. It could be several more months before they can even think about looking at our ticket. Suffice it to say our DE team is under resourced. &lt;/p&gt;\n\n&lt;p&gt;This is where I feel that maybe I\u2019m being naive: I feel like the request is simple. We want to create a daily job for some API reports and bring it into our data warehouse. &lt;/p&gt;\n\n&lt;p&gt;How many hoops does one need to jump through in a mid-level organization to write a script then push it to the warehouse? &lt;/p&gt;\n\n&lt;p&gt;What level of difficulty is this normally? &lt;/p&gt;\n\n&lt;p&gt;Would it be rude to write the script and hand it over to the DE team?&lt;/p&gt;\n\n&lt;p&gt;Looking for advice to navigate the situation. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ad17i", "is_robot_indexable": true, "report_reasons": null, "author": "Marble_Kween", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ad17i/am_i_being_naive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ad17i/am_i_being_naive/", "subreddit_subscribers": 118210, "created_utc": 1690394712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If  you were to start over in the Data Engineering or would have to mentor someone, how would you do.   \nTaking into account all these new tools in today's tech stack.  \nI've researched all this, but TBH I don't have idea about 90% of these:  \n  \n\n**\u00b7 ETL and Scheduling or Orchestration or Jobs =**\n\n1. Open source Tools (Airflow(most used), Dagster, Argo, Prefect, Luigi)\n\n2. Traditional UI Tool (SSIS, Informatica, Talend, FiveTran)\n\n3. Cloud Tool (Azure Data Factory, Google Dataflow, AWS Glue)\n\n4. Modern Proprietary Tool (Databricks, Trifacta)\n\n5. Fivetran (just usually mostly used but a little old school) | MWAA (cost effective) | Apache Beam\n\n**\u00b7 Data Warehouse =** Snowflake or BigQuery | For Cloud = Amazon S3\n\n**\u00b7 Data Lakes =** DataBricks, Redshift\n\n**\u00b7 Data Transformation or Data Quality Control testing or Parallel Processing Tools =** dbt, Pandas, Apache Spark, \n\n**\u00b7 BI =** Power BI\n\n**\u00b7 Exploratory Data Analysis =** Snowflake, Jupyter, Alteryx, Snowflake Snowsight\n\n**\u00b7 Scaling Workers =** aws lambdas, kubernetes\n\n**\u00b7 Devops Methods =** Observability, alerting, incident management, ci/cd and good pr hygiene apply as much to DE as regular backend SE\n\n**\u00b7 Stream Processing =** Apache Kafka,\n\n**\u00b7 AWS Services =** RDS (to setup and scale db in cloud)", "author_fullname": "t2_3k9gevl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you learn DE if you had to start over ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15adu9z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690396515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If  you were to start over in the Data Engineering or would have to mentor someone, how would you do.&lt;br/&gt;\nTaking into account all these new tools in today&amp;#39;s tech stack.&lt;br/&gt;\nI&amp;#39;ve researched all this, but TBH I don&amp;#39;t have idea about 90% of these:  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 ETL and Scheduling or Orchestration or Jobs =&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Open source Tools (Airflow(most used), Dagster, Argo, Prefect, Luigi)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Traditional UI Tool (SSIS, Informatica, Talend, FiveTran)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Cloud Tool (Azure Data Factory, Google Dataflow, AWS Glue)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Modern Proprietary Tool (Databricks, Trifacta)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Fivetran (just usually mostly used but a little old school) | MWAA (cost effective) | Apache Beam&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Data Warehouse =&lt;/strong&gt; Snowflake or BigQuery | For Cloud = Amazon S3&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Data Lakes =&lt;/strong&gt; DataBricks, Redshift&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Data Transformation or Data Quality Control testing or Parallel Processing Tools =&lt;/strong&gt; dbt, Pandas, Apache Spark, &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 BI =&lt;/strong&gt; Power BI&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Exploratory Data Analysis =&lt;/strong&gt; Snowflake, Jupyter, Alteryx, Snowflake Snowsight&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Scaling Workers =&lt;/strong&gt; aws lambdas, kubernetes&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Devops Methods =&lt;/strong&gt; Observability, alerting, incident management, ci/cd and good pr hygiene apply as much to DE as regular backend SE&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Stream Processing =&lt;/strong&gt; Apache Kafka,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 AWS Services =&lt;/strong&gt; RDS (to setup and scale db in cloud)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15adu9z", "is_robot_indexable": true, "report_reasons": null, "author": "Pillstyr", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15adu9z/how_would_you_learn_de_if_you_had_to_start_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15adu9z/how_would_you_learn_de_if_you_had_to_start_over/", "subreddit_subscribers": 118210, "created_utc": 1690396515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems like Redshift would be good to learn, but the pricing I see on it scares the c#@p out of me. Does anyone know a good tutorial which also includes how much will be spent by following along and also shows thorough instructions on how to shut down and destroy the resources when finished?", "author_fullname": "t2_io9vf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scared of Redshift - Any Good Resources to Learn with Low Cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15acq1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690394010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems like Redshift would be good to learn, but the pricing I see on it scares the c#@p out of me. Does anyone know a good tutorial which also includes how much will be spent by following along and also shows thorough instructions on how to shut down and destroy the resources when finished?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15acq1h", "is_robot_indexable": true, "report_reasons": null, "author": "Scalar_Mikeman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15acq1h/scared_of_redshift_any_good_resources_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15acq1h/scared_of_redshift_any_good_resources_to_learn/", "subreddit_subscribers": 118210, "created_utc": 1690394010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Appreciate if you can share it...\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a guide to design a star schema from a data vault?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15aayhz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690390064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Appreciate if you can share it...&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15aayhz", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15aayhz/do_you_have_a_guide_to_design_a_star_schema_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15aayhz/do_you_have_a_guide_to_design_a_star_schema_from/", "subreddit_subscribers": 118210, "created_utc": 1690390064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nSQL query tuning and optimization.\n\nSQL indexing.\n\nSQL integration.\n\nSQL reporting.\n\nSQL execution plans.", "author_fullname": "t2_97jhjawv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the right learning order for these SQL subjects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a94v3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690385880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SQL query tuning and optimization.&lt;/p&gt;\n\n&lt;p&gt;SQL indexing.&lt;/p&gt;\n\n&lt;p&gt;SQL integration.&lt;/p&gt;\n\n&lt;p&gt;SQL reporting.&lt;/p&gt;\n\n&lt;p&gt;SQL execution plans.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a94v3", "is_robot_indexable": true, "report_reasons": null, "author": "TreatOk8778", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a94v3/whats_the_right_learning_order_for_these_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a94v3/whats_the_right_learning_order_for_these_sql/", "subreddit_subscribers": 118210, "created_utc": 1690385880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm assisting a non-profit in a food supply chain project and wanting to understand the cheapest, most efficient way to track the lat/longs of their trucks over time, including real-time. Only about \\~10 trucks and we don't need anything fancy. Just truck+datetime+lat+long.\n\nWhat hardware/tools would be cheapest to obtain this type of information? Options I've considered, but each has their downsides:\n\n1. My mind went to Airtags first for simplicity purposes, but accessing history seems possibly achievable, but frustrating.\n2. Verizon Connect Fleet Tracking - Ability to access historical data, but I didn't see lat/long in their video. Also probably too expensive, but they're too vague on pricing on their site.\n3. A quick \"GPS Fleet Tracking\" search yields a ton of different company offerings, but many seem like overkill (and would likely price as such). I'm looking for the simplest offering, not the most robust.\n\nFor what it's worth, I'm relatively new to data engineering and brand new to ingestion of lat/longs, so apologies if this is a stupid question!", "author_fullname": "t2_pmps7fj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to ingest lat/long data via GPS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a8yck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690385459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m assisting a non-profit in a food supply chain project and wanting to understand the cheapest, most efficient way to track the lat/longs of their trucks over time, including real-time. Only about ~10 trucks and we don&amp;#39;t need anything fancy. Just truck+datetime+lat+long.&lt;/p&gt;\n\n&lt;p&gt;What hardware/tools would be cheapest to obtain this type of information? Options I&amp;#39;ve considered, but each has their downsides:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;My mind went to Airtags first for simplicity purposes, but accessing history seems possibly achievable, but frustrating.&lt;/li&gt;\n&lt;li&gt;Verizon Connect Fleet Tracking - Ability to access historical data, but I didn&amp;#39;t see lat/long in their video. Also probably too expensive, but they&amp;#39;re too vague on pricing on their site.&lt;/li&gt;\n&lt;li&gt;A quick &amp;quot;GPS Fleet Tracking&amp;quot; search yields a ton of different company offerings, but many seem like overkill (and would likely price as such). I&amp;#39;m looking for the simplest offering, not the most robust.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For what it&amp;#39;s worth, I&amp;#39;m relatively new to data engineering and brand new to ingestion of lat/longs, so apologies if this is a stupid question!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a8yck", "is_robot_indexable": true, "report_reasons": null, "author": "hornfan87", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a8yck/easiest_way_to_ingest_latlong_data_via_gps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a8yck/easiest_way_to_ingest_latlong_data_via_gps/", "subreddit_subscribers": 118210, "created_utc": 1690385459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently working on replacing one of our online management systems with a new one and one of the requirements for the migration is to sort out how we are going to do this on a DW side.\n\nI know that my role is to figure out what the ETL/ELT process is and make sure that the data pipelines are feeding in but the biggest concern I have is understanding whether my job involves getting the business logic for field transformation directly or whether this is something which the BI team should do ? I've worked as a BI analyst in the business and I've always thought that this should be a BI job to understand how each column is calculated at least on a high end level and then work with the DE to figure out whether there's any extra details to any columns. One of the arguments for it being a DE job for business logic requirements is that there is already backend logic to this which I think is fair but not all the column is mapped 1-1 and the systems totally different.\n\nHaven't asked my manager but was hoping to grab some 2nd opinions before this is raised up as it's definitely making me frustrated. As context I've work in BI for 4 years and DE for 2.", "author_fullname": "t2_2ahdonrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE or BI to figure out business logic requirements ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a7d7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690381714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently working on replacing one of our online management systems with a new one and one of the requirements for the migration is to sort out how we are going to do this on a DW side.&lt;/p&gt;\n\n&lt;p&gt;I know that my role is to figure out what the ETL/ELT process is and make sure that the data pipelines are feeding in but the biggest concern I have is understanding whether my job involves getting the business logic for field transformation directly or whether this is something which the BI team should do ? I&amp;#39;ve worked as a BI analyst in the business and I&amp;#39;ve always thought that this should be a BI job to understand how each column is calculated at least on a high end level and then work with the DE to figure out whether there&amp;#39;s any extra details to any columns. One of the arguments for it being a DE job for business logic requirements is that there is already backend logic to this which I think is fair but not all the column is mapped 1-1 and the systems totally different.&lt;/p&gt;\n\n&lt;p&gt;Haven&amp;#39;t asked my manager but was hoping to grab some 2nd opinions before this is raised up as it&amp;#39;s definitely making me frustrated. As context I&amp;#39;ve work in BI for 4 years and DE for 2.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a7d7y", "is_robot_indexable": true, "report_reasons": null, "author": "taafpxd", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a7d7y/de_or_bi_to_figure_out_business_logic_requirements/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a7d7y/de_or_bi_to_figure_out_business_logic_requirements/", "subreddit_subscribers": 118210, "created_utc": 1690381714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability: The Next Frontier of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a6h78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1690379554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15a6h78", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a6h78/data_observability_the_next_frontier_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "subreddit_subscribers": 118210, "created_utc": 1690379554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests, I'm trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I'm able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying \n\n\"Cannot infer schema when the input path \\`/mnt/mnt\\_s3\\` is empty. Please try to start the stream when there are files in the input path, or specify the schema.\"\n\nHowever [dbutils.fs.ls](https://dbutils.fs.ls)('/mnt/mnt\\_s3') gives me this \\[FileInfo(path='dbfs:/mnt/mnt\\_s3/flightdata2018.json', name='flightdata2018.json', size=3276800, modificationTime=1690369838000)\\]\n\nP.S Complete noob to databricks, any help is greatly appreciated ", "author_fullname": "t2_a2sp7ole", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Live Tables Pipeline unable to read data from S3 mount", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a5734", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690376327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests, I&amp;#39;m trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I&amp;#39;m able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Cannot infer schema when the input path `/mnt/mnt_s3` is empty. Please try to start the stream when there are files in the input path, or specify the schema.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;However &lt;a href=\"https://dbutils.fs.ls\"&gt;dbutils.fs.ls&lt;/a&gt;(&amp;#39;/mnt/mnt_s3&amp;#39;) gives me this [FileInfo(path=&amp;#39;dbfs:/mnt/mnt_s3/flightdata2018.json&amp;#39;, name=&amp;#39;flightdata2018.json&amp;#39;, size=3276800, modificationTime=1690369838000)]&lt;/p&gt;\n\n&lt;p&gt;P.S Complete noob to databricks, any help is greatly appreciated &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a5734", "is_robot_indexable": true, "report_reasons": null, "author": "No_Conversation_2474", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "subreddit_subscribers": 118210, "created_utc": 1690376327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious how common it is for libraries to employ data engineers.\n\nThanks!", "author_fullname": "t2_a7uw8rfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here work for a library?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159y9fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690354955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious how common it is for libraries to employ data engineers.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159y9fq", "is_robot_indexable": true, "report_reasons": null, "author": "ruthlesscattle", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159y9fq/does_anyone_here_work_for_a_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159y9fq/does_anyone_here_work_for_a_library/", "subreddit_subscribers": 118210, "created_utc": 1690354955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How did design your star schema with dbt?\n\nDid you utilize model or snapshot in dbt?\n\nDid you use data vault as source for star schema?\n\nCould you layout some broad-level idea of architecture to design a star-schema/data-mart using dbt?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt - star schema question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159txoe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690375639.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690341248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How did design your star schema with dbt?&lt;/p&gt;\n\n&lt;p&gt;Did you utilize model or snapshot in dbt?&lt;/p&gt;\n\n&lt;p&gt;Did you use data vault as source for star schema?&lt;/p&gt;\n\n&lt;p&gt;Could you layout some broad-level idea of architecture to design a star-schema/data-mart using dbt?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159txoe", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159txoe/dbt_star_schema_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159txoe/dbt_star_schema_question/", "subreddit_subscribers": 118210, "created_utc": 1690341248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With all the fuss around data Quality tools, how important it is for your organization. Please also mention your org size.", "author_fullname": "t2_95elzkur", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is Data Quality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ahiwc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690404975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With all the fuss around data Quality tools, how important it is for your organization. Please also mention your org size.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ahiwc", "is_robot_indexable": true, "report_reasons": null, "author": "ninja790", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ahiwc/how_important_is_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ahiwc/how_important_is_data_quality/", "subreddit_subscribers": 118210, "created_utc": 1690404975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone \ud83d\udc4b\n\nMy name is Ian and I'm working on AI-powered data tools for analytics teams. A common pain point we've heard from data practitioners across the industry is that writing and maintaining quality documentation is harder than it needs to be. Oftentimes documentation is sparse or out of date and manually manipulating doc YAML files can be tedious.\n\nWe've built a new VS Code extension that allows you to read and edit your dbt model docs side-by-side as your developing. We've also integrated our custom LLM infrastructure into the extension to help you come up with a first draft of the docs and start chipping away quickly at empty data catalog views.\n\nCheck out the demo video below and reach out to me either below or via DM if you'd like to try! Our extension is free and the installation only takes 30 seconds.\n\n&amp;#x200B;\n\nhttps://reddit.com/link/15ah9wf/video/q7tzrts1fdeb1/player", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing: \u2728 Docs Composer for dbt core", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "media_metadata": {"q7tzrts1fdeb1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/15ah9wf/asset/q7tzrts1fdeb1/DASHPlaylist.mpd?a=1692999501%2CNGZlMDJhYTRlNzM4NmExZGY1YWIzNjc1ZjEzOTVkY2UwNGEyZTM1Yjk5ZjU0NTc4YmEwNGIwMzI1ZTFiYzY2OQ%3D%3D&amp;v=1&amp;f=sd", "x": 1728, "y": 1080, "hlsUrl": "https://v.redd.it/link/15ah9wf/asset/q7tzrts1fdeb1/HLSPlaylist.m3u8?a=1692999501%2CZDJkMmZmYmYzY2EwNmExNzhjMjI1YzY0OGI5NDNmNDZkYThmNmYzNWQ2OTkwMTg3MzgyNzE3YmMyNTY0ZjU0ZA%3D%3D&amp;v=1&amp;f=sd", "id": "q7tzrts1fdeb1", "isGif": false}}, "name": "t3_15ah9wf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690404402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;My name is Ian and I&amp;#39;m working on AI-powered data tools for analytics teams. A common pain point we&amp;#39;ve heard from data practitioners across the industry is that writing and maintaining quality documentation is harder than it needs to be. Oftentimes documentation is sparse or out of date and manually manipulating doc YAML files can be tedious.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve built a new VS Code extension that allows you to read and edit your dbt model docs side-by-side as your developing. We&amp;#39;ve also integrated our custom LLM infrastructure into the extension to help you come up with a first draft of the docs and start chipping away quickly at empty data catalog views.&lt;/p&gt;\n\n&lt;p&gt;Check out the demo video below and reach out to me either below or via DM if you&amp;#39;d like to try! Our extension is free and the installation only takes 30 seconds.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/15ah9wf/video/q7tzrts1fdeb1/player\"&gt;https://reddit.com/link/15ah9wf/video/q7tzrts1fdeb1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ah9wf", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ah9wf/introducing_docs_composer_for_dbt_core/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ah9wf/introducing_docs_composer_for_dbt_core/", "subreddit_subscribers": 118210, "created_utc": 1690404402.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}