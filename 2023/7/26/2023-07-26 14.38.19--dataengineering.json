{"kind": "Listing", "data": {"after": "t3_15a08ss", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm considering a job in insurance. It has all the tools and skills I want to learn, master, but I wonder what working in insurance will mean for my day-to-day. I come from a public sector background, so I'm used to feeling \"good\" about my work. Insurance isn't \"bad\" but it often has that reputation. ", "author_fullname": "t2_98rrwspa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you all care about the type of data you're working with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159g777", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690308697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m considering a job in insurance. It has all the tools and skills I want to learn, master, but I wonder what working in insurance will mean for my day-to-day. I come from a public sector background, so I&amp;#39;m used to feeling &amp;quot;good&amp;quot; about my work. Insurance isn&amp;#39;t &amp;quot;bad&amp;quot; but it often has that reputation. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159g777", "is_robot_indexable": true, "report_reasons": null, "author": "what_duck", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/159g777/do_you_all_care_about_the_type_of_data_youre/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159g777/do_you_all_care_about_the_type_of_data_youre/", "subreddit_subscribers": 118134, "created_utc": 1690308697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In a recent Data Engineering Podcast episode I heard that there are data engineers and architects working on distributed data pipelines processing large amounts of data and a bunch of tools including distributed messaging systems or pub-sub tools like kafka, kinesis and data processing like spark, flink among others to deliver analytics and predictive algorithms.\n\nThere were a couple of anecdotes that made me curious.\n\nFirst one was that in a well known networking and tooling company they planned for 9 months to setup their analytics stack and ended up taking 3 years to build something that could do the job but not scale.\n\nSecond one was that these systems were so complex that the data orgs were often working 18 hours a day 7 days a week to operate and maintain the data stack.\n\nI can relate to the first claim, and partially to the second one. I want to learn from the community.\n\nThis community is 117k strong, therefore a pretty solid sample size. I want to learn from your experience about the veracity of the anecdotes. Here are a couple of prompts/questions for you to share.\n\n* What is the gap between planned work and the actual time taken to build the data pipelines that you have worked on?  \n9 months plan and 36 months delivery is a 300% additional time required over the planned effort, I can't see that in startups, growth stage companies, even scale ups. What is your experience?\n* On an average what would you average hours per week to support the data pipelines operations?  \n18 hours a day 7 days a week amounts to 126 hour weeks, I can attest to 70 maybe even 80 hour weeks with on-call issues. is 126 hours per week, for real?", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data engineers taking 4X the amount of time to build, or working 18 hours a week maintaining data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159cf8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690300484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In a recent Data Engineering Podcast episode I heard that there are data engineers and architects working on distributed data pipelines processing large amounts of data and a bunch of tools including distributed messaging systems or pub-sub tools like kafka, kinesis and data processing like spark, flink among others to deliver analytics and predictive algorithms.&lt;/p&gt;\n\n&lt;p&gt;There were a couple of anecdotes that made me curious.&lt;/p&gt;\n\n&lt;p&gt;First one was that in a well known networking and tooling company they planned for 9 months to setup their analytics stack and ended up taking 3 years to build something that could do the job but not scale.&lt;/p&gt;\n\n&lt;p&gt;Second one was that these systems were so complex that the data orgs were often working 18 hours a day 7 days a week to operate and maintain the data stack.&lt;/p&gt;\n\n&lt;p&gt;I can relate to the first claim, and partially to the second one. I want to learn from the community.&lt;/p&gt;\n\n&lt;p&gt;This community is 117k strong, therefore a pretty solid sample size. I want to learn from your experience about the veracity of the anecdotes. Here are a couple of prompts/questions for you to share.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What is the gap between planned work and the actual time taken to build the data pipelines that you have worked on?&lt;br/&gt;\n9 months plan and 36 months delivery is a 300% additional time required over the planned effort, I can&amp;#39;t see that in startups, growth stage companies, even scale ups. What is your experience?&lt;/li&gt;\n&lt;li&gt;On an average what would you average hours per week to support the data pipelines operations?&lt;br/&gt;\n18 hours a day 7 days a week amounts to 126 hour weeks, I can attest to 70 maybe even 80 hour weeks with on-call issues. is 126 hours per week, for real?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159cf8h", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159cf8h/are_data_engineers_taking_4x_the_amount_of_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159cf8h/are_data_engineers_taking_4x_the_amount_of_time/", "subreddit_subscribers": 118134, "created_utc": 1690300484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started my career as a data engineer. I have been learning a lot at work, but I think it\u2019s slowing down and not fast enough. I really want to get good at data engineering, I aspire to become a better data engineer. What can I do during my spare time to work on that? I am planning to start work on Leetcode, to practice my Python and build up DSA knowledge. What else can I do to learn faster?\n\nI use mainly SQL and no code GUI for ETL (which is bad I believe)", "author_fullname": "t2_b4x7m5t6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I become a better data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159v9e8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690345164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started my career as a data engineer. I have been learning a lot at work, but I think it\u2019s slowing down and not fast enough. I really want to get good at data engineering, I aspire to become a better data engineer. What can I do during my spare time to work on that? I am planning to start work on Leetcode, to practice my Python and build up DSA knowledge. What else can I do to learn faster?&lt;/p&gt;\n\n&lt;p&gt;I use mainly SQL and no code GUI for ETL (which is bad I believe)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159v9e8", "is_robot_indexable": true, "report_reasons": null, "author": "heyveryfunny", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159v9e8/how_do_i_become_a_better_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159v9e8/how_do_i_become_a_better_data_engineer/", "subreddit_subscribers": 118134, "created_utc": 1690345164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow data enthusiasts!\n\nI've recently been hired to work in a new small DE team, and I've been tasked with building a more \"big data\" environment for our company. Unfortunately, we have a strict policy against using cloud storage, so I'm looking for recommendations and guidance on creating a robust solution with open-source tools only.\n\nCurrently, most of our data (CDRs files) is continuously stored on a server using cron jobs, and we load it into Oracle. Additionally, we have dblinks connections from other databases to our main Oracle database. However, we're facing some challenges with slow PowerBI dashboards due to the large volume of data ( hundreds of billions of rows), complex joins, and aggregation functions.\n\n&amp;#x200B;\n\nHere's what I'm thinking of for our new environment:\n\n1. Data Ingestion: I'm considering using Apache Airflow and Kafka. or is kafka overkill ? any alternative if ?\n2. Data Processing: Spark seems like a great choice for data processing ?\n3. Datalake: I've come across HDFS as a popular choice, but I'm also curious about other alternative as I heard Hadoop is a pain to manage. Any experiences or feedback on Minio?\n4. Analytics Oriented Database: As our PowerBI dashboards are becoming slower with increasing data volume (overload Oracle) , I believe it's essential to have an analytics-oriented database to improve performance. I'd love to hear your recommendations for databases that work well with PowerBI and can handle large-scale analytical workloads.\n\nOur ultimate goal is to not only improve the performance of our current analytical processes but also lay the groundwork for \"potential future\" machine learning projects.\n\nIf you have any experience, suggestions, or advice regarding these components or any other tool that you think could enhance our environment, please share your insights! I greatly appreciate any help you can provide.\n\nFeel free to ask for more details if needed. Thank you for taking the time to read this post!", "author_fullname": "t2_kfjsv6pf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommandation needed for building an Open Source pipeline / datalake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159yg87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690359315.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690355604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow data enthusiasts!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently been hired to work in a new small DE team, and I&amp;#39;ve been tasked with building a more &amp;quot;big data&amp;quot; environment for our company. Unfortunately, we have a strict policy against using cloud storage, so I&amp;#39;m looking for recommendations and guidance on creating a robust solution with open-source tools only.&lt;/p&gt;\n\n&lt;p&gt;Currently, most of our data (CDRs files) is continuously stored on a server using cron jobs, and we load it into Oracle. Additionally, we have dblinks connections from other databases to our main Oracle database. However, we&amp;#39;re facing some challenges with slow PowerBI dashboards due to the large volume of data ( hundreds of billions of rows), complex joins, and aggregation functions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I&amp;#39;m thinking of for our new environment:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Ingestion: I&amp;#39;m considering using Apache Airflow and Kafka. or is kafka overkill ? any alternative if ?&lt;/li&gt;\n&lt;li&gt;Data Processing: Spark seems like a great choice for data processing ?&lt;/li&gt;\n&lt;li&gt;Datalake: I&amp;#39;ve come across HDFS as a popular choice, but I&amp;#39;m also curious about other alternative as I heard Hadoop is a pain to manage. Any experiences or feedback on Minio?&lt;/li&gt;\n&lt;li&gt;Analytics Oriented Database: As our PowerBI dashboards are becoming slower with increasing data volume (overload Oracle) , I believe it&amp;#39;s essential to have an analytics-oriented database to improve performance. I&amp;#39;d love to hear your recommendations for databases that work well with PowerBI and can handle large-scale analytical workloads.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Our ultimate goal is to not only improve the performance of our current analytical processes but also lay the groundwork for &amp;quot;potential future&amp;quot; machine learning projects.&lt;/p&gt;\n\n&lt;p&gt;If you have any experience, suggestions, or advice regarding these components or any other tool that you think could enhance our environment, please share your insights! I greatly appreciate any help you can provide.&lt;/p&gt;\n\n&lt;p&gt;Feel free to ask for more details if needed. Thank you for taking the time to read this post!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159yg87", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_War6424", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159yg87/recommandation_needed_for_building_an_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159yg87/recommandation_needed_for_building_an_open_source/", "subreddit_subscribers": 118134, "created_utc": 1690355604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gxlue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why JSON still rocks as a format for data lakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "name": "t3_159lfpu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QkrFPbGLgQt_fuj6g_1E0SKdylh0jkDw6IBVB6uyHjU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690320045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "opendatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://opendatascience.com/choosing-a-data-lake-format-what-to-actually-look-for/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?auto=webp&amp;s=15ae1e8a8050436aed75049ca4b948c53c5d9915", "width": 640, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=41801bd050610bf9e2348de7a544a0e5edd482ff", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=811cc432778ab2e43e8ec8e9e3e299b59b3fd864", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9a6dd6572b02906f9f4ef731baf72a24bfe3592b", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=afe1e23618374a28450a0abece2ccdc9610cadd2", "width": 640, "height": 300}], "variants": {}, "id": "r9qfcfrYWA9wAXPOHHaOzOE10XGpP8py2K_jMNXGL2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "159lfpu", "is_robot_indexable": true, "report_reasons": null, "author": "artsyfartsiest", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159lfpu/why_json_still_rocks_as_a_format_for_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://opendatascience.com/choosing-a-data-lake-format-what-to-actually-look-for/", "subreddit_subscribers": 118134, "created_utc": 1690320045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What ETL tools are people using to put data in to snowflake form sources such as SQL &amp; SAP", "author_fullname": "t2_viay6ncm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159bzjg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690299541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What ETL tools are people using to put data in to snowflake form sources such as SQL &amp;amp; SAP&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159bzjg", "is_robot_indexable": true, "report_reasons": null, "author": "dontevenaddme", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159bzjg/etl_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159bzjg/etl_tools/", "subreddit_subscribers": 118134, "created_utc": 1690299541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a senior DE at a midsize company. \nI see the following path -\nDE &gt; Senior &gt; Lead &gt; Principal &gt; Manager\n\nWhat would come next?\n\nI always wonder this because I can\u2019t remember the last time I heard a VP or DE. I know VP of Analytics exists but it\u2019s often the Analysts or Data Scientists who take up those roles. \n\nHence the question.", "author_fullname": "t2_bfd45sy5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What position after \u201cManager of DE\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159glvw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690309577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a senior DE at a midsize company. \nI see the following path -\nDE &amp;gt; Senior &amp;gt; Lead &amp;gt; Principal &amp;gt; Manager&lt;/p&gt;\n\n&lt;p&gt;What would come next?&lt;/p&gt;\n\n&lt;p&gt;I always wonder this because I can\u2019t remember the last time I heard a VP or DE. I know VP of Analytics exists but it\u2019s often the Analysts or Data Scientists who take up those roles. &lt;/p&gt;\n\n&lt;p&gt;Hence the question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159glvw", "is_robot_indexable": true, "report_reasons": null, "author": "nrskmn", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159glvw/what_position_after_manager_of_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159glvw/what_position_after_manager_of_de/", "subreddit_subscribers": 118134, "created_utc": 1690309577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great Expectations is bloaty. What are the alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a45gt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690373573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a45gt", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "subreddit_subscribers": 118134, "created_utc": 1690373573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, let me preface this by saying my earliest career experience involved working in SQL Server. I worked in SQL server for the first 8-ish years of my data engineering journey (in addition to using other applications that connected to SQL server - SSIS, SSAS, Tableau, PowerBI, etc.).   \nHowever, the last 3.5 years have all been snowflake development except for one short client experience where I was basically working in ADF, azure and sql server. I really appreciate what snowflake has to offer but I'm curious to know from those of you who have worked with Azure synapse and/or the azure spectrum of products, whether you enjoy it or if (assuming you've had some experience with snowflake) you prefer working with a RDBMS tool like snowflake?   \nYes, I know this isn't exactly an apples to oranges comparison but I'm thinking of dipping my foot back into the azure space and I'd like to hear opinions from anyone who's experienced both?", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working in Snowflake vs Azure synapse (or the Azure suite in general)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159cd98", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690300358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, let me preface this by saying my earliest career experience involved working in SQL Server. I worked in SQL server for the first 8-ish years of my data engineering journey (in addition to using other applications that connected to SQL server - SSIS, SSAS, Tableau, PowerBI, etc.).&lt;br/&gt;\nHowever, the last 3.5 years have all been snowflake development except for one short client experience where I was basically working in ADF, azure and sql server. I really appreciate what snowflake has to offer but I&amp;#39;m curious to know from those of you who have worked with Azure synapse and/or the azure spectrum of products, whether you enjoy it or if (assuming you&amp;#39;ve had some experience with snowflake) you prefer working with a RDBMS tool like snowflake?&lt;br/&gt;\nYes, I know this isn&amp;#39;t exactly an apples to oranges comparison but I&amp;#39;m thinking of dipping my foot back into the azure space and I&amp;#39;d like to hear opinions from anyone who&amp;#39;s experienced both?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159cd98", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159cd98/working_in_snowflake_vs_azure_synapse_or_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159cd98/working_in_snowflake_vs_azure_synapse_or_the/", "subreddit_subscribers": 118134, "created_utc": 1690300358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer at one of the big techs, and I'm considering a role as a Specialist Solutions Architect at Databricks. It specializes on data engineering but it seems to be a lot of customer facing role, which is different from my current role.\n\nHow is this position in terms of career progression? I do want the option to get back to data or software engineering in the future, and I feel I will get shoed in to a client facing role if I take this.\n\nAlso if anyone knows anything about the pros and cons of this position at Databricks, like wlb/comp, etc. I would love to know!", "author_fullname": "t2_ih0l5i9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solutions Architect role at Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a26zd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690368116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer at one of the big techs, and I&amp;#39;m considering a role as a Specialist Solutions Architect at Databricks. It specializes on data engineering but it seems to be a lot of customer facing role, which is different from my current role.&lt;/p&gt;\n\n&lt;p&gt;How is this position in terms of career progression? I do want the option to get back to data or software engineering in the future, and I feel I will get shoed in to a client facing role if I take this.&lt;/p&gt;\n\n&lt;p&gt;Also if anyone knows anything about the pros and cons of this position at Databricks, like wlb/comp, etc. I would love to know!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15a26zd", "is_robot_indexable": true, "report_reasons": null, "author": "DataApe", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a26zd/solutions_architect_role_at_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a26zd/solutions_architect_role_at_databricks/", "subreddit_subscribers": 118134, "created_utc": 1690368116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have around 500+ GB of data per day with 800 columns that I need to load into Redshift for 5 years worth of data. However, the data loading process is quite slow using copy command from s3 to redshift. Any suggestions on how to optimize and speed up the data loading in Redshift", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load huge volume of data to redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159wr91", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690349909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 500+ GB of data per day with 800 columns that I need to load into Redshift for 5 years worth of data. However, the data loading process is quite slow using copy command from s3 to redshift. Any suggestions on how to optimize and speed up the data loading in Redshift&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159wr91", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159wr91/load_huge_volume_of_data_to_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159wr91/load_huge_volume_of_data_to_redshift/", "subreddit_subscribers": 118134, "created_utc": 1690349909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm consulting with a team of data engineers as a solution architect. Long story short, they're looking to do some work for this customer that will entail hopping into the database and doing the normal thing of writing procs and such to enable some capabilities like automated quality checking/testing, enforcing constraints, yada yada. \n\nI've worked quite a bit with GIS and with most of ESRIs products, but this was the first time really looking at the table-level structure of an ArcGIS warehouse and it doesn't seem like the team I'm on really had either. Some quick googling didn't return any solid leads, but does anybody know of any best practices when developing capabilities within or next to a running enterprise level ESRI warehouse?", "author_fullname": "t2_fp2tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for working within ArcGis Warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159s722", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690336366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m consulting with a team of data engineers as a solution architect. Long story short, they&amp;#39;re looking to do some work for this customer that will entail hopping into the database and doing the normal thing of writing procs and such to enable some capabilities like automated quality checking/testing, enforcing constraints, yada yada. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve worked quite a bit with GIS and with most of ESRIs products, but this was the first time really looking at the table-level structure of an ArcGIS warehouse and it doesn&amp;#39;t seem like the team I&amp;#39;m on really had either. Some quick googling didn&amp;#39;t return any solid leads, but does anybody know of any best practices when developing capabilities within or next to a running enterprise level ESRI warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159s722", "is_robot_indexable": true, "report_reasons": null, "author": "lostinthewalls", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159s722/best_practices_for_working_within_arcgis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159s722/best_practices_for_working_within_arcgis/", "subreddit_subscribers": 118134, "created_utc": 1690336366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do we answer question about describing work experience in an interview if someone has more than 8+ years of experience in multiple organization. Sometimes I think I am going too long and sometimes I feel Its too short. Whats the best way to describe it . How long we should spend in describing it?2 mins 5 mins or more?Is there any template for this ?", "author_fullname": "t2_dn5rzvxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Describing previous work experiences in an Interview.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159g9rt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690308861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do we answer question about describing work experience in an interview if someone has more than 8+ years of experience in multiple organization. Sometimes I think I am going too long and sometimes I feel Its too short. Whats the best way to describe it . How long we should spend in describing it?2 mins 5 mins or more?Is there any template for this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "159g9rt", "is_robot_indexable": true, "report_reasons": null, "author": "Fickle-Picture-7674", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159g9rt/describing_previous_work_experiences_in_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159g9rt/describing_previous_work_experiences_in_an/", "subreddit_subscribers": 118134, "created_utc": 1690308861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019m a Data Scientist of 5 years out of a job and have just got an interview for a Data Engineer role coming up. I\u2019m thinking it\u2019s a good role as I like the engineering stuff, and really need a job!\n\n So my questions are: \n1) What topics are worth focusing my prep/study on? \n2) I need to prepare a set of a few slides about a recent DE end to end project I\u2019ve worked on. Any tips on that, as I have created a feature store for ML before, and have some personal projects too?\n\nThanks for any advice and tips!", "author_fullname": "t2_7kdevi10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist interviewing for a Data Engineering role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a02oy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690361223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m a Data Scientist of 5 years out of a job and have just got an interview for a Data Engineer role coming up. I\u2019m thinking it\u2019s a good role as I like the engineering stuff, and really need a job!&lt;/p&gt;\n\n&lt;p&gt;So my questions are: \n1) What topics are worth focusing my prep/study on? \n2) I need to prepare a set of a few slides about a recent DE end to end project I\u2019ve worked on. Any tips on that, as I have created a feature store for ML before, and have some personal projects too?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice and tips!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15a02oy", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive_Fact_6561", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a02oy/data_scientist_interviewing_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a02oy/data_scientist_interviewing_for_a_data/", "subreddit_subscribers": 118134, "created_utc": 1690361223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# The Big Data Problem\n\nImagine you start in a new company as someone in charge of their real-time streaming infrastructure.\n\nYou are tasked with the problem of **computing the percentile distribution** of the company\u2019s terabytes\u2019 stream of data consisting of billions of records in Kafka, each representing a latency metric data point.\n\nCalculating a percentile for a large dataset is very expensive, to do so - you need to:\n\n1. store all the values\n2. sort them\n3. return the value whose rank matches the percentile (e.g 99th item)\n\nSuch big data aggregations are very tricky to solve. There is no way you can do this with terabytes.\n\nThe solution?\n\n# Streaming Stochastic Sublinear Algorithms\n\nAlso called **Sketch algorithms**, these are algorithms that trade off a bit of accuracy for massive efficiency gains. They are:\n\n* **probabilistic** (not 100% correct) - they usually have a strict, known ***error bound***.\n* **one-pass** \\- they go over each item in the stream only once.\n* have **sub-linear space growth** \\- input data grows, but the algorithm\u2019s memory requirement does NOT grow linearly with it.\n* **parallelizable** &amp; **composable** \\- you can split the data into two sets, compute sketches on them and then merge the results while guaranteeing the same accuracy. Parallelization can really scale this to infinity.\n* **data insensitive** \\- Big Data is extremely messy and disorganized. These algorithms handle things like NaN, infinites, nulls and are insensitive to the distribution/order of the data.\n\n# DataDog\u2019s Example\n\nIn the example above, you were actually placed in DataDog.\n\nThey invented their own sketch algorithm named [*DDSketch*](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3ZsZGIub3JnL3B2bGRiL3ZvbDEyL3AyMTk1LW1hc3Nvbi5wZGY_dXRtX3NvdXJjZT0ybWludXRlc3RyZWFtaW5nLmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXN0b2NoYXN0aWMtc3VibGluZWFyLXN0cmVhbWluZy1hbGdvcml0aG1zIiwicG9zdF9pZCI6IjlkNjYyN2FhLWVkMDQtNDExMC04N2JhLWQyZmE0NDZjOTUwZSIsInB1YmxpY2F0aW9uX2lkIjoiMjYyYmJjNTktZDkyNS00MTcxLWFmZDYtYjE0NGEyYzM2MzZlIiwidmlzaXRfdG9rZW4iOiI3N2Q3MzkyMi1lY2QwLTRmN2ItYTNhYS05NDYwOTBlZDMzNDgiLCJpYXQiOjE2OTAzMDk4MDYuNzcsImlzcyI6Im9yY2hpZCJ9.hC6ECvmb-GrfMbqoEglbq_vewfjS6SkKMqh6S54BG8s).\n\nIt offers a 2% relative error bound, which means that if the true p99 is 60s \u2192 the sketch would return **58.8-61.2s**.\n\nThe algorithm is pretty simple:\n\n1. Create buckets covering ranges of the desired error rate (+-2% in this case)\n2. Each bucket keeps a counter of the amount of data points within that range.\n3. When processing an item (latency metric data point), increment the counter of the appropriate bucket\n4. To count the desired percentile, you sum up the bucket\u2019s values until you get to the desired percentile. Whatever bucket that percentile is in - that\u2019s your value.\n\nWith this, you only need:\n\n**- 275** buckets  \n**-** **\\~2KB**  \nto cover the range from 1 millisecond to 1 minute.\n\nAnother key point? This can be endlessly parallelized.\n\nAs we [*learned from S3*](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3R3aXR0ZXIuY29tL0JkS296bG92c2tpL3N0YXR1cy8xNjYzODc5MjU3NDk4NzIyMzA2P3M9MjAmdXRtX3NvdXJjZT0ybWludXRlc3RyZWFtaW5nLmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXN0b2NoYXN0aWMtc3VibGluZWFyLXN0cmVhbWluZy1hbGdvcml0aG1zIiwicG9zdF9pZCI6IjlkNjYyN2FhLWVkMDQtNDExMC04N2JhLWQyZmE0NDZjOTUwZSIsInB1YmxpY2F0aW9uX2lkIjoiMjYyYmJjNTktZDkyNS00MTcxLWFmZDYtYjE0NGEyYzM2MzZlIiwidmlzaXRfdG9rZW4iOiI3N2Q3MzkyMi1lY2QwLTRmN2ItYTNhYS05NDYwOTBlZDMzNDgiLCJpYXQiOjE2OTAzMDk4MDYuNzcsImlzcyI6Im9yY2hpZCJ9.V9XUMqa4mMnJvdtbkT4CM9HUqBEpiVW0eOyfvPYCnCk), parallelization is key to unlocking great performance at tremendous scale.\n\nNotice - merging the sketch results together is as simple as merging two dictionaries/hashmaps of size 275!\n\n# Other Uses\n\nSketch algorithms are used heavily in the industry for other things like:\n\n* uniqueness - distinct elements\n* frequency of items (heavy hitters)\n* set union/intersection/difference\n* AI large vector/matrix decomposition\n* graph analysis - connectivity, weighted matching\n\nFor more examples &amp; visuals, see [the original place this was posted](https://2minutestreaming.beehiiv.com/p/streaming-sketch-algorithms).", "author_fullname": "t2_d2c8s0pb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to Sketch Algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159grgy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690309915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;The Big Data Problem&lt;/h1&gt;\n\n&lt;p&gt;Imagine you start in a new company as someone in charge of their real-time streaming infrastructure.&lt;/p&gt;\n\n&lt;p&gt;You are tasked with the problem of &lt;strong&gt;computing the percentile distribution&lt;/strong&gt; of the company\u2019s terabytes\u2019 stream of data consisting of billions of records in Kafka, each representing a latency metric data point.&lt;/p&gt;\n\n&lt;p&gt;Calculating a percentile for a large dataset is very expensive, to do so - you need to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;store all the values&lt;/li&gt;\n&lt;li&gt;sort them&lt;/li&gt;\n&lt;li&gt;return the value whose rank matches the percentile (e.g 99th item)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Such big data aggregations are very tricky to solve. There is no way you can do this with terabytes.&lt;/p&gt;\n\n&lt;p&gt;The solution?&lt;/p&gt;\n\n&lt;h1&gt;Streaming Stochastic Sublinear Algorithms&lt;/h1&gt;\n\n&lt;p&gt;Also called &lt;strong&gt;Sketch algorithms&lt;/strong&gt;, these are algorithms that trade off a bit of accuracy for massive efficiency gains. They are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;probabilistic&lt;/strong&gt; (not 100% correct) - they usually have a strict, known &lt;strong&gt;&lt;em&gt;error bound&lt;/em&gt;&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;one-pass&lt;/strong&gt; - they go over each item in the stream only once.&lt;/li&gt;\n&lt;li&gt;have &lt;strong&gt;sub-linear space growth&lt;/strong&gt; - input data grows, but the algorithm\u2019s memory requirement does NOT grow linearly with it.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;parallelizable&lt;/strong&gt; &amp;amp; &lt;strong&gt;composable&lt;/strong&gt; - you can split the data into two sets, compute sketches on them and then merge the results while guaranteeing the same accuracy. Parallelization can really scale this to infinity.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;data insensitive&lt;/strong&gt; - Big Data is extremely messy and disorganized. These algorithms handle things like NaN, infinites, nulls and are insensitive to the distribution/order of the data.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;DataDog\u2019s Example&lt;/h1&gt;\n\n&lt;p&gt;In the example above, you were actually placed in DataDog.&lt;/p&gt;\n\n&lt;p&gt;They invented their own sketch algorithm named &lt;a href=\"https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3ZsZGIub3JnL3B2bGRiL3ZvbDEyL3AyMTk1LW1hc3Nvbi5wZGY_dXRtX3NvdXJjZT0ybWludXRlc3RyZWFtaW5nLmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXN0b2NoYXN0aWMtc3VibGluZWFyLXN0cmVhbWluZy1hbGdvcml0aG1zIiwicG9zdF9pZCI6IjlkNjYyN2FhLWVkMDQtNDExMC04N2JhLWQyZmE0NDZjOTUwZSIsInB1YmxpY2F0aW9uX2lkIjoiMjYyYmJjNTktZDkyNS00MTcxLWFmZDYtYjE0NGEyYzM2MzZlIiwidmlzaXRfdG9rZW4iOiI3N2Q3MzkyMi1lY2QwLTRmN2ItYTNhYS05NDYwOTBlZDMzNDgiLCJpYXQiOjE2OTAzMDk4MDYuNzcsImlzcyI6Im9yY2hpZCJ9.hC6ECvmb-GrfMbqoEglbq_vewfjS6SkKMqh6S54BG8s\"&gt;&lt;em&gt;DDSketch&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It offers a 2% relative error bound, which means that if the true p99 is 60s \u2192 the sketch would return &lt;strong&gt;58.8-61.2s&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;The algorithm is pretty simple:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create buckets covering ranges of the desired error rate (+-2% in this case)&lt;/li&gt;\n&lt;li&gt;Each bucket keeps a counter of the amount of data points within that range.&lt;/li&gt;\n&lt;li&gt;When processing an item (latency metric data point), increment the counter of the appropriate bucket&lt;/li&gt;\n&lt;li&gt;To count the desired percentile, you sum up the bucket\u2019s values until you get to the desired percentile. Whatever bucket that percentile is in - that\u2019s your value.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;With this, you only need:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- 275&lt;/strong&gt; buckets&lt;br/&gt;\n&lt;strong&gt;-&lt;/strong&gt; &lt;strong&gt;~2KB&lt;/strong&gt;&lt;br/&gt;\nto cover the range from 1 millisecond to 1 minute.&lt;/p&gt;\n\n&lt;p&gt;Another key point? This can be endlessly parallelized.&lt;/p&gt;\n\n&lt;p&gt;As we &lt;a href=\"https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3R3aXR0ZXIuY29tL0JkS296bG92c2tpL3N0YXR1cy8xNjYzODc5MjU3NDk4NzIyMzA2P3M9MjAmdXRtX3NvdXJjZT0ybWludXRlc3RyZWFtaW5nLmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXN0b2NoYXN0aWMtc3VibGluZWFyLXN0cmVhbWluZy1hbGdvcml0aG1zIiwicG9zdF9pZCI6IjlkNjYyN2FhLWVkMDQtNDExMC04N2JhLWQyZmE0NDZjOTUwZSIsInB1YmxpY2F0aW9uX2lkIjoiMjYyYmJjNTktZDkyNS00MTcxLWFmZDYtYjE0NGEyYzM2MzZlIiwidmlzaXRfdG9rZW4iOiI3N2Q3MzkyMi1lY2QwLTRmN2ItYTNhYS05NDYwOTBlZDMzNDgiLCJpYXQiOjE2OTAzMDk4MDYuNzcsImlzcyI6Im9yY2hpZCJ9.V9XUMqa4mMnJvdtbkT4CM9HUqBEpiVW0eOyfvPYCnCk\"&gt;&lt;em&gt;learned from S3&lt;/em&gt;&lt;/a&gt;, parallelization is key to unlocking great performance at tremendous scale.&lt;/p&gt;\n\n&lt;p&gt;Notice - merging the sketch results together is as simple as merging two dictionaries/hashmaps of size 275!&lt;/p&gt;\n\n&lt;h1&gt;Other Uses&lt;/h1&gt;\n\n&lt;p&gt;Sketch algorithms are used heavily in the industry for other things like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;uniqueness - distinct elements&lt;/li&gt;\n&lt;li&gt;frequency of items (heavy hitters)&lt;/li&gt;\n&lt;li&gt;set union/intersection/difference&lt;/li&gt;\n&lt;li&gt;AI large vector/matrix decomposition&lt;/li&gt;\n&lt;li&gt;graph analysis - connectivity, weighted matching&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For more examples &amp;amp; visuals, see &lt;a href=\"https://2minutestreaming.beehiiv.com/p/streaming-sketch-algorithms\"&gt;the original place this was posted&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "159grgy", "is_robot_indexable": true, "report_reasons": null, "author": "2minutestreaming", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159grgy/introduction_to_sketch_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159grgy/introduction_to_sketch_algorithms/", "subreddit_subscribers": 118134, "created_utc": 1690309915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I'm working on AWS and have it available for experiments.\n\nIf you have any guide/tutorial/walkthrough to recommend, please do share!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend a good k8s / EKS guide?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a32at", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690370610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I&amp;#39;m working on AWS and have it available for experiments.&lt;/p&gt;\n\n&lt;p&gt;If you have any guide/tutorial/walkthrough to recommend, please do share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a32at", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "subreddit_subscribers": 118134, "created_utc": 1690370610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a backend developer involved in building an analytics pipeline for our application to display usage statistics to our users. I had no training in data engineering so far.\n\nBefore reading about ELT, I had an idea to utilize an AWS Glue job to extract data from the source (MySQL), transform it within the same Glue job, and load the resulting set into a data warehouse to perform queries. But as I understand, this would be a classic ETL approach.\n\nBut the ELT approach, as I understand it, would look different: utilize an AWS Glue job to load data into a data warehouse as is (basically copy the existing MySQL tables there), and then transform data using queries like:\n\n    INSERT into table3\n    SELECT table1.column_a, table1.column_b, table2.column_c, table2.column_d, FROM table1\n    JOIN table2\n\nEvery source I read mentions that the ELT is a superior and more recent approach than ETL.\n\nBut I don't feel like this. I have a couple of concerns about ELT:\n\n* With ETL, the tool (AWS Glue) would maintain incremental data extraction. With ELT, I must implement a mechanism for incremental data transformation (e.g. only insert changed rows into *table3*)\n* AWS Glue performs transformations in parallel. This is not likely the case for relational databases like MySQL, as it would process the query above on a single node.\n\nSo my questions are:\n\n* Are there flaws in my understanding of ELT?\n* Which databases/tools can act as data warehouses which support incremental load and parallelism?\n* Which of them are available in AWS?\n\nI'd also prefer not to use sophisticated or enterprise tools since we don't have lots of data (less than 10M rows). Thanks.", "author_fullname": "t2_zkr4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which databases are good for ELT (Extract-Load-Transform)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a0sux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690363720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a backend developer involved in building an analytics pipeline for our application to display usage statistics to our users. I had no training in data engineering so far.&lt;/p&gt;\n\n&lt;p&gt;Before reading about ELT, I had an idea to utilize an AWS Glue job to extract data from the source (MySQL), transform it within the same Glue job, and load the resulting set into a data warehouse to perform queries. But as I understand, this would be a classic ETL approach.&lt;/p&gt;\n\n&lt;p&gt;But the ELT approach, as I understand it, would look different: utilize an AWS Glue job to load data into a data warehouse as is (basically copy the existing MySQL tables there), and then transform data using queries like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;INSERT into table3\nSELECT table1.column_a, table1.column_b, table2.column_c, table2.column_d, FROM table1\nJOIN table2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Every source I read mentions that the ELT is a superior and more recent approach than ETL.&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t feel like this. I have a couple of concerns about ELT:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;With ETL, the tool (AWS Glue) would maintain incremental data extraction. With ELT, I must implement a mechanism for incremental data transformation (e.g. only insert changed rows into &lt;em&gt;table3&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;AWS Glue performs transformations in parallel. This is not likely the case for relational databases like MySQL, as it would process the query above on a single node.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So my questions are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are there flaws in my understanding of ELT?&lt;/li&gt;\n&lt;li&gt;Which databases/tools can act as data warehouses which support incremental load and parallelism?&lt;/li&gt;\n&lt;li&gt;Which of them are available in AWS?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d also prefer not to use sophisticated or enterprise tools since we don&amp;#39;t have lots of data (less than 10M rows). Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a0sux", "is_robot_indexable": true, "report_reasons": null, "author": "binary-data", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a0sux/which_databases_are_good_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a0sux/which_databases_are_good_for_elt/", "subreddit_subscribers": 118134, "created_utc": 1690363720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all.\n\nI'm curious to hear your opinions about DMS tasks parallelization and replication instance size when running DMS for a database migration.\n\nI understand many factors to consider here. I will try to list them:\n\n* Database Size\n* Data distribution on tables (some tables can be really large while other are small, so best to load large tables in parallel per partition or by range)\n* Time window to perform Full Load (downtime)\n* Use of Full Load + CDC (needed if database is too huge and migration time does not fit in the downtime window)\n\n&amp;#x200B;\n\nSo if I choose a replication instance like\n\ndms.r4.4xlarge16 vCPU122 GIB\n\nDoes it make sense to have 16 threads in  MaxFullLoadSubTasks task settings? Like one thread per vCPU? Would it be better to split that in multiple DMS Migration Tasks? Maybe 2 tasks with 8 MaxFullLoadSubTasks?\n\nHow does one estimate how long it is going to take to migrate a 4TB database using this configuration?\n\nJust wondering how you guys make this kind of design decisions and your train of thought on it.\n\n&amp;#x200B;", "author_fullname": "t2_d60i64x6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DMS Task setting and replication instance size", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159depf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690302627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to hear your opinions about DMS tasks parallelization and replication instance size when running DMS for a database migration.&lt;/p&gt;\n\n&lt;p&gt;I understand many factors to consider here. I will try to list them:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Database Size&lt;/li&gt;\n&lt;li&gt;Data distribution on tables (some tables can be really large while other are small, so best to load large tables in parallel per partition or by range)&lt;/li&gt;\n&lt;li&gt;Time window to perform Full Load (downtime)&lt;/li&gt;\n&lt;li&gt;Use of Full Load + CDC (needed if database is too huge and migration time does not fit in the downtime window)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So if I choose a replication instance like&lt;/p&gt;\n\n&lt;p&gt;dms.r4.4xlarge16 vCPU122 GIB&lt;/p&gt;\n\n&lt;p&gt;Does it make sense to have 16 threads in  MaxFullLoadSubTasks task settings? Like one thread per vCPU? Would it be better to split that in multiple DMS Migration Tasks? Maybe 2 tasks with 8 MaxFullLoadSubTasks?&lt;/p&gt;\n\n&lt;p&gt;How does one estimate how long it is going to take to migrate a 4TB database using this configuration?&lt;/p&gt;\n\n&lt;p&gt;Just wondering how you guys make this kind of design decisions and your train of thought on it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159depf", "is_robot_indexable": true, "report_reasons": null, "author": "PidKiller09", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159depf/dms_task_setting_and_replication_instance_size/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159depf/dms_task_setting_and_replication_instance_size/", "subreddit_subscribers": 118134, "created_utc": 1690302627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests, I'm trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I'm able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying \n\n\"Cannot infer schema when the input path \\`/mnt/mnt\\_s3\\` is empty. Please try to start the stream when there are files in the input path, or specify the schema.\"\n\nHowever [dbutils.fs.ls](https://dbutils.fs.ls)('/mnt/mnt\\_s3') gives me this \\[FileInfo(path='dbfs:/mnt/mnt\\_s3/flightdata2018.json', name='flightdata2018.json', size=3276800, modificationTime=1690369838000)\\]\n\nP.S Complete noob to databricks, any help is greatly appreciated ", "author_fullname": "t2_a2sp7ole", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Live Tables Pipeline unable to read data from S3 mount", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15a5734", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690376327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests, I&amp;#39;m trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I&amp;#39;m able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Cannot infer schema when the input path `/mnt/mnt_s3` is empty. Please try to start the stream when there are files in the input path, or specify the schema.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;However &lt;a href=\"https://dbutils.fs.ls\"&gt;dbutils.fs.ls&lt;/a&gt;(&amp;#39;/mnt/mnt_s3&amp;#39;) gives me this [FileInfo(path=&amp;#39;dbfs:/mnt/mnt_s3/flightdata2018.json&amp;#39;, name=&amp;#39;flightdata2018.json&amp;#39;, size=3276800, modificationTime=1690369838000)]&lt;/p&gt;\n\n&lt;p&gt;P.S Complete noob to databricks, any help is greatly appreciated &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a5734", "is_robot_indexable": true, "report_reasons": null, "author": "No_Conversation_2474", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "subreddit_subscribers": 118134, "created_utc": 1690376327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious how common it is for libraries to employ data engineers.\n\nThanks!", "author_fullname": "t2_a7uw8rfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here work for a library?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159y9fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690354955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious how common it is for libraries to employ data engineers.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159y9fq", "is_robot_indexable": true, "report_reasons": null, "author": "ruthlesscattle", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159y9fq/does_anyone_here_work_for_a_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159y9fq/does_anyone_here_work_for_a_library/", "subreddit_subscribers": 118134, "created_utc": 1690354955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How did design your star schema with dbt?\n\nDid you utilize model or snapshot in dbt?\n\nDid you use data vault as source for star schema?\n\nCould you layout some broad-level idea of architecture to design a star-schema/data-mart using dbt?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt - star schema question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159txoe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690375639.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690341248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How did design your star schema with dbt?&lt;/p&gt;\n\n&lt;p&gt;Did you utilize model or snapshot in dbt?&lt;/p&gt;\n\n&lt;p&gt;Did you use data vault as source for star schema?&lt;/p&gt;\n\n&lt;p&gt;Could you layout some broad-level idea of architecture to design a star-schema/data-mart using dbt?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159txoe", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159txoe/dbt_star_schema_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159txoe/dbt_star_schema_question/", "subreddit_subscribers": 118134, "created_utc": 1690341248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**TL;DR incorporate SQL functionality within Jupyter, access to modern data processing DBs (like DuckDB), polars and data exploration through plotting easier with JupySQL.**\n\nhey r/dataengineering! I'd like to share some news about JupySQL, an open source project my team has been working on!\n\nJupySQL allows you to run SQL and perform exploratory data analysis in Jupyter via magics %sqland %%sqlmagics, and visualize your data with %sqlplot.\n\nThis project is open source, and a successor to [iPython-SQL](https://github.com/catherinedevlin/ipython-sql#legacy-project). It is compatible with all major databases (e.g., PostgreSQL, MySQL, SQL Server), data warehouses (e.g., Snowflake, BigQuery, Redshift), and embedded engines (SQLite, and DuckDB).\n\nThis week the team released version 0.8.0 with improved data profiling and DuckDB performance when converting resulting tables to other formats (pandas and polars).\n\nLearn more: [https://jupysql.ploomber.io/en/latest/quick-start.html](https://jupysql.ploomber.io/en/latest/quick-start.html)\n\nif you have any questions, feel free to ask! And show your support with a star on [GitHub](https://github.com/ploomber/jupysql)!", "author_fullname": "t2_fymggxzxm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From iPython-sql to JupySQL: new updates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159fmf5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690307453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR incorporate SQL functionality within Jupyter, access to modern data processing DBs (like DuckDB), polars and data exploration through plotting easier with JupySQL.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;hey &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;! I&amp;#39;d like to share some news about JupySQL, an open source project my team has been working on!&lt;/p&gt;\n\n&lt;p&gt;JupySQL allows you to run SQL and perform exploratory data analysis in Jupyter via magics %sqland %%sqlmagics, and visualize your data with %sqlplot.&lt;/p&gt;\n\n&lt;p&gt;This project is open source, and a successor to &lt;a href=\"https://github.com/catherinedevlin/ipython-sql#legacy-project\"&gt;iPython-SQL&lt;/a&gt;. It is compatible with all major databases (e.g., PostgreSQL, MySQL, SQL Server), data warehouses (e.g., Snowflake, BigQuery, Redshift), and embedded engines (SQLite, and DuckDB).&lt;/p&gt;\n\n&lt;p&gt;This week the team released version 0.8.0 with improved data profiling and DuckDB performance when converting resulting tables to other formats (pandas and polars).&lt;/p&gt;\n\n&lt;p&gt;Learn more: &lt;a href=\"https://jupysql.ploomber.io/en/latest/quick-start.html\"&gt;https://jupysql.ploomber.io/en/latest/quick-start.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;if you have any questions, feel free to ask! And show your support with a star on &lt;a href=\"https://github.com/ploomber/jupysql\"&gt;GitHub&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?auto=webp&amp;s=5eaa766829f09147ae3b2bc614f13187e68a7ed2", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5a28510613b8de7ed1f6ec1538d38e82e08a43b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=590514cfa4354a7729e11d76f6f5c7030ccb4495", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e9fbbb2d65b14a1965551d9c1be14b5bbda33aca", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df82b64967e5b1f92f666deb91ea92f58224b274", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ea4bf05c21fc35ed35fa555aa184407b6aa6b7b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ec1c6c82462e53121c27c95aa55a2bb87a46908", "width": 1080, "height": 540}], "variants": {}, "id": "PnfZqzALk55bbYPxf42ETuUy79_7mLJARaQ2dFLRMAY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "159fmf5", "is_robot_indexable": true, "report_reasons": null, "author": "ploomber-dev", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159fmf5/from_ipythonsql_to_jupysql_new_updates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159fmf5/from_ipythonsql_to_jupysql_new_updates/", "subreddit_subscribers": 118134, "created_utc": 1690307453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I\u2019m talking to the Director of Business Intelligence at a company we work with.\u00a0  \n\n\nI mentioned the concept of \u201cdemocratizing data\u201d.  \n\n\nHe immediately says: \u201cI was told we needed to build out this mission critical dashboard. After finally rolling it out saw its only ever got 5 views\u201d  \n\n\nThere\u2019s no doubt that data teams need to empower business with data.  \n\n\nBut, is the idea of self-service analytics to truly democratize data just a pipedream? At least beyond some basic spoon-fed reports.  \n\n\nI\u2019d love to hear about your experiences (good, bad, or ugly).\n\n&amp;#x200B;\n\nPost: [https://lassoo.io/blog/2023/07/25/democratizing-data-myth/](https://lassoo.io/blog/2023/07/25/democratizing-data-myth/)  \n", "author_fullname": "t2_8s6trahv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Democratizing Data: A Fairy Tale We All Believed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15a6k4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690379756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019m talking to the Director of Business Intelligence at a company we work with.\u00a0  &lt;/p&gt;\n\n&lt;p&gt;I mentioned the concept of \u201cdemocratizing data\u201d.  &lt;/p&gt;\n\n&lt;p&gt;He immediately says: \u201cI was told we needed to build out this mission critical dashboard. After finally rolling it out saw its only ever got 5 views\u201d  &lt;/p&gt;\n\n&lt;p&gt;There\u2019s no doubt that data teams need to empower business with data.  &lt;/p&gt;\n\n&lt;p&gt;But, is the idea of self-service analytics to truly democratize data just a pipedream? At least beyond some basic spoon-fed reports.  &lt;/p&gt;\n\n&lt;p&gt;I\u2019d love to hear about your experiences (good, bad, or ugly).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Post: &lt;a href=\"https://lassoo.io/blog/2023/07/25/democratizing-data-myth/\"&gt;https://lassoo.io/blog/2023/07/25/democratizing-data-myth/&lt;/a&gt;  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/St_yO-67Hevu00HPqBiWe0BUYXIOJmCBQi98Ks3Aguo.jpg?auto=webp&amp;s=3b1a3db95eb889bbedd685556acb098d53a60b65", "width": 2000, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/St_yO-67Hevu00HPqBiWe0BUYXIOJmCBQi98Ks3Aguo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=014cd9870c0bd4e22e7e00b5ce9663b16480bc79", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/St_yO-67Hevu00HPqBiWe0BUYXIOJmCBQi98Ks3Aguo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bd2f256a712de572c5b6f4c5e653b34bf3b09e74", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/St_yO-67Hevu00HPqBiWe0BUYXIOJmCBQi98Ks3Aguo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20b668923dbcb810bdc8632c518680c99ce52c03", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/St_yO-67Hevu00HPqBiWe0BUYXIOJmCBQi98Ks3Aguo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a8696ccdf412ea5913528a4073d3bab4202e99af", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/St_yO-67Hevu00HPqBiWe0BUYXIOJmCBQi98Ks3Aguo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=23da603ea7815b0ef55620fa4a98545a34312c69", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/St_yO-67Hevu00HPqBiWe0BUYXIOJmCBQi98Ks3Aguo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77d8761f2478a4de9ca1b4b1f9ce33133df00c05", "width": 1080, "height": 810}], "variants": {}, "id": "TW7l8wrRSRLx_oFi0jlm-E8_6D8c-tqTiVKWe-Nx-Nc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15a6k4s", "is_robot_indexable": true, "report_reasons": null, "author": "Crafty_Combination54", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a6k4s/democratizing_data_a_fairy_tale_we_all_believed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a6k4s/democratizing_data_a_fairy_tale_we_all_believed/", "subreddit_subscribers": 118134, "created_utc": 1690379756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability: The Next Frontier of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15a6h78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1690379554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15a6h78", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a6h78/data_observability_the_next_frontier_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "subreddit_subscribers": 118134, "created_utc": 1690379554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We currently have a requirement to replicate data from postgres to oracle. We are using AWS DMS service to achieve this. We feel the cost of this is huge. Data engineering team were asked to suggest better methods to optimizer cost and move away from DMS. \n\nI personally feel DMS is the best service to achieve this. In terms of cost optimization, we can only look at replication instance usage and reduce size etc to reduce costs. \n\nAny other options to achieve data replication? Or any other aspects within DMS I should be looking at to lower the costs. \n\nNote - Our entire infrastructure is on Aws. We heavily use spark, airflow.", "author_fullname": "t2_6kmo2ecy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data replication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a08ss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690361808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We currently have a requirement to replicate data from postgres to oracle. We are using AWS DMS service to achieve this. We feel the cost of this is huge. Data engineering team were asked to suggest better methods to optimizer cost and move away from DMS. &lt;/p&gt;\n\n&lt;p&gt;I personally feel DMS is the best service to achieve this. In terms of cost optimization, we can only look at replication instance usage and reduce size etc to reduce costs. &lt;/p&gt;\n\n&lt;p&gt;Any other options to achieve data replication? Or any other aspects within DMS I should be looking at to lower the costs. &lt;/p&gt;\n\n&lt;p&gt;Note - Our entire infrastructure is on Aws. We heavily use spark, airflow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a08ss", "is_robot_indexable": true, "report_reasons": null, "author": "soujoshi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a08ss/data_replication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a08ss/data_replication/", "subreddit_subscribers": 118134, "created_utc": 1690361808.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}