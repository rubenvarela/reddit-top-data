{"kind": "Listing", "data": {"after": "t3_15a8yck", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm considering a job in insurance. It has all the tools and skills I want to learn, master, but I wonder what working in insurance will mean for my day-to-day. I come from a public sector background, so I'm used to feeling \"good\" about my work. Insurance isn't \"bad\" but it often has that reputation. ", "author_fullname": "t2_98rrwspa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you all care about the type of data you're working with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159g777", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690308697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m considering a job in insurance. It has all the tools and skills I want to learn, master, but I wonder what working in insurance will mean for my day-to-day. I come from a public sector background, so I&amp;#39;m used to feeling &amp;quot;good&amp;quot; about my work. Insurance isn&amp;#39;t &amp;quot;bad&amp;quot; but it often has that reputation. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159g777", "is_robot_indexable": true, "report_reasons": null, "author": "what_duck", "discussion_type": null, "num_comments": 76, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/159g777/do_you_all_care_about_the_type_of_data_youre/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159g777/do_you_all_care_about_the_type_of_data_youre/", "subreddit_subscribers": 118163, "created_utc": 1690308697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started my career as a data engineer. I have been learning a lot at work, but I think it\u2019s slowing down and not fast enough. I really want to get good at data engineering, I aspire to become a better data engineer. What can I do during my spare time to work on that? I am planning to start work on Leetcode, to practice my Python and build up DSA knowledge. What else can I do to learn faster?\n\nI use mainly SQL and no code GUI for ETL (which is bad I believe)", "author_fullname": "t2_b4x7m5t6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I become a better data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159v9e8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690345164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started my career as a data engineer. I have been learning a lot at work, but I think it\u2019s slowing down and not fast enough. I really want to get good at data engineering, I aspire to become a better data engineer. What can I do during my spare time to work on that? I am planning to start work on Leetcode, to practice my Python and build up DSA knowledge. What else can I do to learn faster?&lt;/p&gt;\n\n&lt;p&gt;I use mainly SQL and no code GUI for ETL (which is bad I believe)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159v9e8", "is_robot_indexable": true, "report_reasons": null, "author": "heyveryfunny", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159v9e8/how_do_i_become_a_better_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159v9e8/how_do_i_become_a_better_data_engineer/", "subreddit_subscribers": 118163, "created_utc": 1690345164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great Expectations is bloaty. What are the alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a45gt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690373573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15a45gt", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "subreddit_subscribers": 118163, "created_utc": 1690373573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow data enthusiasts!\n\nI've recently been hired to work in a new small DE team, and I've been tasked with building a more \"big data\" environment for our company. Unfortunately, we have a strict policy against using cloud storage, so I'm looking for recommendations and guidance on creating a robust solution with open-source tools only.\n\nCurrently, most of our data (CDRs files) is continuously stored on a server using cron jobs, and we load it into Oracle. Additionally, we have dblinks connections from other databases to our main Oracle database. However, we're facing some challenges with slow PowerBI dashboards due to the large volume of data ( hundreds of billions of rows), complex joins, and aggregation functions.\n\n&amp;#x200B;\n\nHere's what I'm thinking of for our new environment:\n\n1. Data Ingestion: I'm considering using Apache Airflow and Kafka. or is kafka overkill ? any alternative if ?\n2. Data Processing: Spark seems like a great choice for data processing ?\n3. Datalake: I've come across HDFS as a popular choice, but I'm also curious about other alternative as I heard Hadoop is a pain to manage. Any experiences or feedback on Minio?\n4. Analytics Oriented Database: As our PowerBI dashboards are becoming slower with increasing data volume (overload Oracle) , I believe it's essential to have an analytics-oriented database to improve performance. I'd love to hear your recommendations for databases that work well with PowerBI and can handle large-scale analytical workloads.\n\nOur ultimate goal is to not only improve the performance of our current analytical processes but also lay the groundwork for \"potential future\" machine learning projects.\n\nIf you have any experience, suggestions, or advice regarding these components or any other tool that you think could enhance our environment, please share your insights! I greatly appreciate any help you can provide.\n\nFeel free to ask for more details if needed. Thank you for taking the time to read this post!", "author_fullname": "t2_kfjsv6pf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommandation needed for building an Open Source pipeline / datalake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159yg87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690359315.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690355604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow data enthusiasts!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently been hired to work in a new small DE team, and I&amp;#39;ve been tasked with building a more &amp;quot;big data&amp;quot; environment for our company. Unfortunately, we have a strict policy against using cloud storage, so I&amp;#39;m looking for recommendations and guidance on creating a robust solution with open-source tools only.&lt;/p&gt;\n\n&lt;p&gt;Currently, most of our data (CDRs files) is continuously stored on a server using cron jobs, and we load it into Oracle. Additionally, we have dblinks connections from other databases to our main Oracle database. However, we&amp;#39;re facing some challenges with slow PowerBI dashboards due to the large volume of data ( hundreds of billions of rows), complex joins, and aggregation functions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I&amp;#39;m thinking of for our new environment:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Ingestion: I&amp;#39;m considering using Apache Airflow and Kafka. or is kafka overkill ? any alternative if ?&lt;/li&gt;\n&lt;li&gt;Data Processing: Spark seems like a great choice for data processing ?&lt;/li&gt;\n&lt;li&gt;Datalake: I&amp;#39;ve come across HDFS as a popular choice, but I&amp;#39;m also curious about other alternative as I heard Hadoop is a pain to manage. Any experiences or feedback on Minio?&lt;/li&gt;\n&lt;li&gt;Analytics Oriented Database: As our PowerBI dashboards are becoming slower with increasing data volume (overload Oracle) , I believe it&amp;#39;s essential to have an analytics-oriented database to improve performance. I&amp;#39;d love to hear your recommendations for databases that work well with PowerBI and can handle large-scale analytical workloads.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Our ultimate goal is to not only improve the performance of our current analytical processes but also lay the groundwork for &amp;quot;potential future&amp;quot; machine learning projects.&lt;/p&gt;\n\n&lt;p&gt;If you have any experience, suggestions, or advice regarding these components or any other tool that you think could enhance our environment, please share your insights! I greatly appreciate any help you can provide.&lt;/p&gt;\n\n&lt;p&gt;Feel free to ask for more details if needed. Thank you for taking the time to read this post!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159yg87", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_War6424", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159yg87/recommandation_needed_for_building_an_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159yg87/recommandation_needed_for_building_an_open_source/", "subreddit_subscribers": 118163, "created_utc": 1690355604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gxlue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why JSON still rocks as a format for data lakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "name": "t3_159lfpu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QkrFPbGLgQt_fuj6g_1E0SKdylh0jkDw6IBVB6uyHjU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690320045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "opendatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://opendatascience.com/choosing-a-data-lake-format-what-to-actually-look-for/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?auto=webp&amp;s=15ae1e8a8050436aed75049ca4b948c53c5d9915", "width": 640, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=41801bd050610bf9e2348de7a544a0e5edd482ff", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=811cc432778ab2e43e8ec8e9e3e299b59b3fd864", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9a6dd6572b02906f9f4ef731baf72a24bfe3592b", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=afe1e23618374a28450a0abece2ccdc9610cadd2", "width": 640, "height": 300}], "variants": {}, "id": "r9qfcfrYWA9wAXPOHHaOzOE10XGpP8py2K_jMNXGL2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "159lfpu", "is_robot_indexable": true, "report_reasons": null, "author": "artsyfartsiest", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159lfpu/why_json_still_rocks_as_a_format_for_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://opendatascience.com/choosing-a-data-lake-format-what-to-actually-look-for/", "subreddit_subscribers": 118163, "created_utc": 1690320045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a senior DE at a midsize company. \nI see the following path -\nDE &gt; Senior &gt; Lead &gt; Principal &gt; Manager\n\nWhat would come next?\n\nI always wonder this because I can\u2019t remember the last time I heard a VP or DE. I know VP of Analytics exists but it\u2019s often the Analysts or Data Scientists who take up those roles. \n\nHence the question.", "author_fullname": "t2_bfd45sy5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What position after \u201cManager of DE\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159glvw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690309577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a senior DE at a midsize company. \nI see the following path -\nDE &amp;gt; Senior &amp;gt; Lead &amp;gt; Principal &amp;gt; Manager&lt;/p&gt;\n\n&lt;p&gt;What would come next?&lt;/p&gt;\n\n&lt;p&gt;I always wonder this because I can\u2019t remember the last time I heard a VP or DE. I know VP of Analytics exists but it\u2019s often the Analysts or Data Scientists who take up those roles. &lt;/p&gt;\n\n&lt;p&gt;Hence the question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159glvw", "is_robot_indexable": true, "report_reasons": null, "author": "nrskmn", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159glvw/what_position_after_manager_of_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159glvw/what_position_after_manager_of_de/", "subreddit_subscribers": 118163, "created_utc": 1690309577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer at one of the big techs, and I'm considering a role as a Specialist Solutions Architect at Databricks. It specializes on data engineering but it seems to be a lot of customer facing role, which is different from my current role.\n\nHow is this position in terms of career progression? I do want the option to get back to data or software engineering in the future, and I feel I will get shoed in to a client facing role if I take this.\n\nAlso if anyone knows anything about the pros and cons of this position at Databricks, like wlb/comp, etc. I would love to know!", "author_fullname": "t2_ih0l5i9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solutions Architect role at Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a26zd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690368116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer at one of the big techs, and I&amp;#39;m considering a role as a Specialist Solutions Architect at Databricks. It specializes on data engineering but it seems to be a lot of customer facing role, which is different from my current role.&lt;/p&gt;\n\n&lt;p&gt;How is this position in terms of career progression? I do want the option to get back to data or software engineering in the future, and I feel I will get shoed in to a client facing role if I take this.&lt;/p&gt;\n\n&lt;p&gt;Also if anyone knows anything about the pros and cons of this position at Databricks, like wlb/comp, etc. I would love to know!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15a26zd", "is_robot_indexable": true, "report_reasons": null, "author": "DataApe", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a26zd/solutions_architect_role_at_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a26zd/solutions_architect_role_at_databricks/", "subreddit_subscribers": 118163, "created_utc": 1690368116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have around 500+ GB of data per day with 800 columns that I need to load into Redshift for 5 years worth of data. However, the data loading process is quite slow using copy command from s3 to redshift. Any suggestions on how to optimize and speed up the data loading in Redshift", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load huge volume of data to redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159wr91", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690349909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 500+ GB of data per day with 800 columns that I need to load into Redshift for 5 years worth of data. However, the data loading process is quite slow using copy command from s3 to redshift. Any suggestions on how to optimize and speed up the data loading in Redshift&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159wr91", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159wr91/load_huge_volume_of_data_to_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159wr91/load_huge_volume_of_data_to_redshift/", "subreddit_subscribers": 118163, "created_utc": 1690349909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a backend developer involved in building an analytics pipeline for our application to display usage statistics to our users. I had no training in data engineering so far.\n\nBefore reading about ELT, I had an idea to utilize an AWS Glue job to extract data from the source (MySQL), transform it within the same Glue job, and load the resulting set into a data warehouse to perform queries. But as I understand, this would be a classic ETL approach.\n\nBut the ELT approach, as I understand it, would look different: utilize an AWS Glue job to load data into a data warehouse as is (basically copy the existing MySQL tables there), and then transform data using queries like:\n\n    INSERT into table3\n    SELECT table1.column_a, table1.column_b, table2.column_c, table2.column_d, FROM table1\n    JOIN table2\n\nEvery source I read mentions that the ELT is a superior and more recent approach than ETL.\n\nBut I don't feel like this. I have a couple of concerns about ELT:\n\n* With ETL, the tool (AWS Glue) would maintain incremental data extraction. With ELT, I must implement a mechanism for incremental data transformation (e.g. only insert changed rows into *table3*)\n* AWS Glue performs transformations in parallel. This is not likely the case for relational databases like MySQL, as it would process the query above on a single node.\n\nSo my questions are:\n\n* Are there flaws in my understanding of ELT?\n* Which databases/tools can act as data warehouses which support incremental load and parallelism?\n* Which of them are available in AWS?\n\nI'd also prefer not to use sophisticated or enterprise tools since we don't have lots of data (less than 10M rows). Thanks.", "author_fullname": "t2_zkr4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which databases are good for ELT (Extract-Load-Transform)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a0sux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690363720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a backend developer involved in building an analytics pipeline for our application to display usage statistics to our users. I had no training in data engineering so far.&lt;/p&gt;\n\n&lt;p&gt;Before reading about ELT, I had an idea to utilize an AWS Glue job to extract data from the source (MySQL), transform it within the same Glue job, and load the resulting set into a data warehouse to perform queries. But as I understand, this would be a classic ETL approach.&lt;/p&gt;\n\n&lt;p&gt;But the ELT approach, as I understand it, would look different: utilize an AWS Glue job to load data into a data warehouse as is (basically copy the existing MySQL tables there), and then transform data using queries like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;INSERT into table3\nSELECT table1.column_a, table1.column_b, table2.column_c, table2.column_d, FROM table1\nJOIN table2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Every source I read mentions that the ELT is a superior and more recent approach than ETL.&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t feel like this. I have a couple of concerns about ELT:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;With ETL, the tool (AWS Glue) would maintain incremental data extraction. With ELT, I must implement a mechanism for incremental data transformation (e.g. only insert changed rows into &lt;em&gt;table3&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;AWS Glue performs transformations in parallel. This is not likely the case for relational databases like MySQL, as it would process the query above on a single node.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So my questions are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are there flaws in my understanding of ELT?&lt;/li&gt;\n&lt;li&gt;Which databases/tools can act as data warehouses which support incremental load and parallelism?&lt;/li&gt;\n&lt;li&gt;Which of them are available in AWS?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d also prefer not to use sophisticated or enterprise tools since we don&amp;#39;t have lots of data (less than 10M rows). Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a0sux", "is_robot_indexable": true, "report_reasons": null, "author": "binary-data", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a0sux/which_databases_are_good_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a0sux/which_databases_are_good_for_elt/", "subreddit_subscribers": 118163, "created_utc": 1690363720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm consulting with a team of data engineers as a solution architect. Long story short, they're looking to do some work for this customer that will entail hopping into the database and doing the normal thing of writing procs and such to enable some capabilities like automated quality checking/testing, enforcing constraints, yada yada. \n\nI've worked quite a bit with GIS and with most of ESRIs products, but this was the first time really looking at the table-level structure of an ArcGIS warehouse and it doesn't seem like the team I'm on really had either. Some quick googling didn't return any solid leads, but does anybody know of any best practices when developing capabilities within or next to a running enterprise level ESRI warehouse?", "author_fullname": "t2_fp2tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for working within ArcGis Warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159s722", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690336366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m consulting with a team of data engineers as a solution architect. Long story short, they&amp;#39;re looking to do some work for this customer that will entail hopping into the database and doing the normal thing of writing procs and such to enable some capabilities like automated quality checking/testing, enforcing constraints, yada yada. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve worked quite a bit with GIS and with most of ESRIs products, but this was the first time really looking at the table-level structure of an ArcGIS warehouse and it doesn&amp;#39;t seem like the team I&amp;#39;m on really had either. Some quick googling didn&amp;#39;t return any solid leads, but does anybody know of any best practices when developing capabilities within or next to a running enterprise level ESRI warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159s722", "is_robot_indexable": true, "report_reasons": null, "author": "lostinthewalls", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159s722/best_practices_for_working_within_arcgis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159s722/best_practices_for_working_within_arcgis/", "subreddit_subscribers": 118163, "created_utc": 1690336366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do we answer question about describing work experience in an interview if someone has more than 8+ years of experience in multiple organization. Sometimes I think I am going too long and sometimes I feel Its too short. Whats the best way to describe it . How long we should spend in describing it?2 mins 5 mins or more?Is there any template for this ?", "author_fullname": "t2_dn5rzvxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Describing previous work experiences in an Interview.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159g9rt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690308861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do we answer question about describing work experience in an interview if someone has more than 8+ years of experience in multiple organization. Sometimes I think I am going too long and sometimes I feel Its too short. Whats the best way to describe it . How long we should spend in describing it?2 mins 5 mins or more?Is there any template for this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "159g9rt", "is_robot_indexable": true, "report_reasons": null, "author": "Fickle-Picture-7674", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159g9rt/describing_previous_work_experiences_in_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159g9rt/describing_previous_work_experiences_in_an/", "subreddit_subscribers": 118163, "created_utc": 1690308861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I'm working on AWS and have it available for experiments.\n\nIf you have any guide/tutorial/walkthrough to recommend, please do share!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend a good k8s / EKS guide?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a32at", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690370610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I&amp;#39;m working on AWS and have it available for experiments.&lt;/p&gt;\n\n&lt;p&gt;If you have any guide/tutorial/walkthrough to recommend, please do share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a32at", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "subreddit_subscribers": 118163, "created_utc": 1690370610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019m a Data Scientist of 5 years out of a job and have just got an interview for a Data Engineer role coming up. I\u2019m thinking it\u2019s a good role as I like the engineering stuff, and really need a job!\n\n So my questions are: \n1) What topics are worth focusing my prep/study on? \n2) I need to prepare a set of a few slides about a recent DE end to end project I\u2019ve worked on. Any tips on that, as I have created a feature store for ML before, and have some personal projects too?\n\nThanks for any advice and tips!", "author_fullname": "t2_7kdevi10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist interviewing for a Data Engineering role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a02oy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690361223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m a Data Scientist of 5 years out of a job and have just got an interview for a Data Engineer role coming up. I\u2019m thinking it\u2019s a good role as I like the engineering stuff, and really need a job!&lt;/p&gt;\n\n&lt;p&gt;So my questions are: \n1) What topics are worth focusing my prep/study on? \n2) I need to prepare a set of a few slides about a recent DE end to end project I\u2019ve worked on. Any tips on that, as I have created a feature store for ML before, and have some personal projects too?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice and tips!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15a02oy", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive_Fact_6561", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a02oy/data_scientist_interviewing_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a02oy/data_scientist_interviewing_for_a_data/", "subreddit_subscribers": 118163, "created_utc": 1690361223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# The Big Data Problem\n\nImagine you start in a new company as someone in charge of their real-time streaming infrastructure.\n\nYou are tasked with the problem of **computing the percentile distribution** of the company\u2019s terabytes\u2019 stream of data consisting of billions of records in Kafka, each representing a latency metric data point.\n\nCalculating a percentile for a large dataset is very expensive, to do so - you need to:\n\n1. store all the values\n2. sort them\n3. return the value whose rank matches the percentile (e.g 99th item)\n\nSuch big data aggregations are very tricky to solve. There is no way you can do this with terabytes.\n\nThe solution?\n\n# Streaming Stochastic Sublinear Algorithms\n\nAlso called **Sketch algorithms**, these are algorithms that trade off a bit of accuracy for massive efficiency gains. They are:\n\n* **probabilistic** (not 100% correct) - they usually have a strict, known ***error bound***.\n* **one-pass** \\- they go over each item in the stream only once.\n* have **sub-linear space growth** \\- input data grows, but the algorithm\u2019s memory requirement does NOT grow linearly with it.\n* **parallelizable** &amp; **composable** \\- you can split the data into two sets, compute sketches on them and then merge the results while guaranteeing the same accuracy. Parallelization can really scale this to infinity.\n* **data insensitive** \\- Big Data is extremely messy and disorganized. These algorithms handle things like NaN, infinites, nulls and are insensitive to the distribution/order of the data.\n\n# DataDog\u2019s Example\n\nIn the example above, you were actually placed in DataDog.\n\nThey invented their own sketch algorithm named [*DDSketch*](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3ZsZGIub3JnL3B2bGRiL3ZvbDEyL3AyMTk1LW1hc3Nvbi5wZGY_dXRtX3NvdXJjZT0ybWludXRlc3RyZWFtaW5nLmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXN0b2NoYXN0aWMtc3VibGluZWFyLXN0cmVhbWluZy1hbGdvcml0aG1zIiwicG9zdF9pZCI6IjlkNjYyN2FhLWVkMDQtNDExMC04N2JhLWQyZmE0NDZjOTUwZSIsInB1YmxpY2F0aW9uX2lkIjoiMjYyYmJjNTktZDkyNS00MTcxLWFmZDYtYjE0NGEyYzM2MzZlIiwidmlzaXRfdG9rZW4iOiI3N2Q3MzkyMi1lY2QwLTRmN2ItYTNhYS05NDYwOTBlZDMzNDgiLCJpYXQiOjE2OTAzMDk4MDYuNzcsImlzcyI6Im9yY2hpZCJ9.hC6ECvmb-GrfMbqoEglbq_vewfjS6SkKMqh6S54BG8s).\n\nIt offers a 2% relative error bound, which means that if the true p99 is 60s \u2192 the sketch would return **58.8-61.2s**.\n\nThe algorithm is pretty simple:\n\n1. Create buckets covering ranges of the desired error rate (+-2% in this case)\n2. Each bucket keeps a counter of the amount of data points within that range.\n3. When processing an item (latency metric data point), increment the counter of the appropriate bucket\n4. To count the desired percentile, you sum up the bucket\u2019s values until you get to the desired percentile. Whatever bucket that percentile is in - that\u2019s your value.\n\nWith this, you only need:\n\n**- 275** buckets  \n**-** **\\~2KB**  \nto cover the range from 1 millisecond to 1 minute.\n\nAnother key point? This can be endlessly parallelized.\n\nAs we [*learned from S3*](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3R3aXR0ZXIuY29tL0JkS296bG92c2tpL3N0YXR1cy8xNjYzODc5MjU3NDk4NzIyMzA2P3M9MjAmdXRtX3NvdXJjZT0ybWludXRlc3RyZWFtaW5nLmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXN0b2NoYXN0aWMtc3VibGluZWFyLXN0cmVhbWluZy1hbGdvcml0aG1zIiwicG9zdF9pZCI6IjlkNjYyN2FhLWVkMDQtNDExMC04N2JhLWQyZmE0NDZjOTUwZSIsInB1YmxpY2F0aW9uX2lkIjoiMjYyYmJjNTktZDkyNS00MTcxLWFmZDYtYjE0NGEyYzM2MzZlIiwidmlzaXRfdG9rZW4iOiI3N2Q3MzkyMi1lY2QwLTRmN2ItYTNhYS05NDYwOTBlZDMzNDgiLCJpYXQiOjE2OTAzMDk4MDYuNzcsImlzcyI6Im9yY2hpZCJ9.V9XUMqa4mMnJvdtbkT4CM9HUqBEpiVW0eOyfvPYCnCk), parallelization is key to unlocking great performance at tremendous scale.\n\nNotice - merging the sketch results together is as simple as merging two dictionaries/hashmaps of size 275!\n\n# Other Uses\n\nSketch algorithms are used heavily in the industry for other things like:\n\n* uniqueness - distinct elements\n* frequency of items (heavy hitters)\n* set union/intersection/difference\n* AI large vector/matrix decomposition\n* graph analysis - connectivity, weighted matching\n\nFor more examples &amp; visuals, see [the original place this was posted](https://2minutestreaming.beehiiv.com/p/streaming-sketch-algorithms).", "author_fullname": "t2_d2c8s0pb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to Sketch Algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159grgy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690309915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;The Big Data Problem&lt;/h1&gt;\n\n&lt;p&gt;Imagine you start in a new company as someone in charge of their real-time streaming infrastructure.&lt;/p&gt;\n\n&lt;p&gt;You are tasked with the problem of &lt;strong&gt;computing the percentile distribution&lt;/strong&gt; of the company\u2019s terabytes\u2019 stream of data consisting of billions of records in Kafka, each representing a latency metric data point.&lt;/p&gt;\n\n&lt;p&gt;Calculating a percentile for a large dataset is very expensive, to do so - you need to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;store all the values&lt;/li&gt;\n&lt;li&gt;sort them&lt;/li&gt;\n&lt;li&gt;return the value whose rank matches the percentile (e.g 99th item)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Such big data aggregations are very tricky to solve. There is no way you can do this with terabytes.&lt;/p&gt;\n\n&lt;p&gt;The solution?&lt;/p&gt;\n\n&lt;h1&gt;Streaming Stochastic Sublinear Algorithms&lt;/h1&gt;\n\n&lt;p&gt;Also called &lt;strong&gt;Sketch algorithms&lt;/strong&gt;, these are algorithms that trade off a bit of accuracy for massive efficiency gains. They are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;probabilistic&lt;/strong&gt; (not 100% correct) - they usually have a strict, known &lt;strong&gt;&lt;em&gt;error bound&lt;/em&gt;&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;one-pass&lt;/strong&gt; - they go over each item in the stream only once.&lt;/li&gt;\n&lt;li&gt;have &lt;strong&gt;sub-linear space growth&lt;/strong&gt; - input data grows, but the algorithm\u2019s memory requirement does NOT grow linearly with it.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;parallelizable&lt;/strong&gt; &amp;amp; &lt;strong&gt;composable&lt;/strong&gt; - you can split the data into two sets, compute sketches on them and then merge the results while guaranteeing the same accuracy. Parallelization can really scale this to infinity.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;data insensitive&lt;/strong&gt; - Big Data is extremely messy and disorganized. These algorithms handle things like NaN, infinites, nulls and are insensitive to the distribution/order of the data.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;DataDog\u2019s Example&lt;/h1&gt;\n\n&lt;p&gt;In the example above, you were actually placed in DataDog.&lt;/p&gt;\n\n&lt;p&gt;They invented their own sketch algorithm named &lt;a href=\"https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3ZsZGIub3JnL3B2bGRiL3ZvbDEyL3AyMTk1LW1hc3Nvbi5wZGY_dXRtX3NvdXJjZT0ybWludXRlc3RyZWFtaW5nLmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXN0b2NoYXN0aWMtc3VibGluZWFyLXN0cmVhbWluZy1hbGdvcml0aG1zIiwicG9zdF9pZCI6IjlkNjYyN2FhLWVkMDQtNDExMC04N2JhLWQyZmE0NDZjOTUwZSIsInB1YmxpY2F0aW9uX2lkIjoiMjYyYmJjNTktZDkyNS00MTcxLWFmZDYtYjE0NGEyYzM2MzZlIiwidmlzaXRfdG9rZW4iOiI3N2Q3MzkyMi1lY2QwLTRmN2ItYTNhYS05NDYwOTBlZDMzNDgiLCJpYXQiOjE2OTAzMDk4MDYuNzcsImlzcyI6Im9yY2hpZCJ9.hC6ECvmb-GrfMbqoEglbq_vewfjS6SkKMqh6S54BG8s\"&gt;&lt;em&gt;DDSketch&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It offers a 2% relative error bound, which means that if the true p99 is 60s \u2192 the sketch would return &lt;strong&gt;58.8-61.2s&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;The algorithm is pretty simple:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create buckets covering ranges of the desired error rate (+-2% in this case)&lt;/li&gt;\n&lt;li&gt;Each bucket keeps a counter of the amount of data points within that range.&lt;/li&gt;\n&lt;li&gt;When processing an item (latency metric data point), increment the counter of the appropriate bucket&lt;/li&gt;\n&lt;li&gt;To count the desired percentile, you sum up the bucket\u2019s values until you get to the desired percentile. Whatever bucket that percentile is in - that\u2019s your value.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;With this, you only need:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- 275&lt;/strong&gt; buckets&lt;br/&gt;\n&lt;strong&gt;-&lt;/strong&gt; &lt;strong&gt;~2KB&lt;/strong&gt;&lt;br/&gt;\nto cover the range from 1 millisecond to 1 minute.&lt;/p&gt;\n\n&lt;p&gt;Another key point? This can be endlessly parallelized.&lt;/p&gt;\n\n&lt;p&gt;As we &lt;a href=\"https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3R3aXR0ZXIuY29tL0JkS296bG92c2tpL3N0YXR1cy8xNjYzODc5MjU3NDk4NzIyMzA2P3M9MjAmdXRtX3NvdXJjZT0ybWludXRlc3RyZWFtaW5nLmJlZWhpaXYuY29tJnV0bV9tZWRpdW09cmVmZXJyYWwmdXRtX2NhbXBhaWduPXN0b2NoYXN0aWMtc3VibGluZWFyLXN0cmVhbWluZy1hbGdvcml0aG1zIiwicG9zdF9pZCI6IjlkNjYyN2FhLWVkMDQtNDExMC04N2JhLWQyZmE0NDZjOTUwZSIsInB1YmxpY2F0aW9uX2lkIjoiMjYyYmJjNTktZDkyNS00MTcxLWFmZDYtYjE0NGEyYzM2MzZlIiwidmlzaXRfdG9rZW4iOiI3N2Q3MzkyMi1lY2QwLTRmN2ItYTNhYS05NDYwOTBlZDMzNDgiLCJpYXQiOjE2OTAzMDk4MDYuNzcsImlzcyI6Im9yY2hpZCJ9.V9XUMqa4mMnJvdtbkT4CM9HUqBEpiVW0eOyfvPYCnCk\"&gt;&lt;em&gt;learned from S3&lt;/em&gt;&lt;/a&gt;, parallelization is key to unlocking great performance at tremendous scale.&lt;/p&gt;\n\n&lt;p&gt;Notice - merging the sketch results together is as simple as merging two dictionaries/hashmaps of size 275!&lt;/p&gt;\n\n&lt;h1&gt;Other Uses&lt;/h1&gt;\n\n&lt;p&gt;Sketch algorithms are used heavily in the industry for other things like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;uniqueness - distinct elements&lt;/li&gt;\n&lt;li&gt;frequency of items (heavy hitters)&lt;/li&gt;\n&lt;li&gt;set union/intersection/difference&lt;/li&gt;\n&lt;li&gt;AI large vector/matrix decomposition&lt;/li&gt;\n&lt;li&gt;graph analysis - connectivity, weighted matching&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For more examples &amp;amp; visuals, see &lt;a href=\"https://2minutestreaming.beehiiv.com/p/streaming-sketch-algorithms\"&gt;the original place this was posted&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "159grgy", "is_robot_indexable": true, "report_reasons": null, "author": "2minutestreaming", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159grgy/introduction_to_sketch_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159grgy/introduction_to_sketch_algorithms/", "subreddit_subscribers": 118163, "created_utc": 1690309915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently working on replacing one of our online management systems with a new one and one of the requirements for the migration is to sort out how we are going to do this on a DW side.\n\nI know that my role is to figure out what the ETL/ELT process is and make sure that the data pipelines are feeding in but the biggest concern I have is understanding whether my job involves getting the business logic for field transformation directly or whether this is something which the BI team should do ? I've worked as a BI analyst in the business and I've always thought that this should be a BI job to understand how each column is calculated at least on a high end level and then work with the DE to figure out whether there's any extra details to any columns. One of the arguments for it being a DE job for business logic requirements is that there is already backend logic to this which I think is fair but not all the column is mapped 1-1 and the systems totally different.\n\nHaven't asked my manager but was hoping to grab some 2nd opinions before this is raised up as it's definitely making me frustrated. As context I've work in BI for 4 years and DE for 2.", "author_fullname": "t2_2ahdonrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE or BI to figure out business logic requirements ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a7d7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690381714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently working on replacing one of our online management systems with a new one and one of the requirements for the migration is to sort out how we are going to do this on a DW side.&lt;/p&gt;\n\n&lt;p&gt;I know that my role is to figure out what the ETL/ELT process is and make sure that the data pipelines are feeding in but the biggest concern I have is understanding whether my job involves getting the business logic for field transformation directly or whether this is something which the BI team should do ? I&amp;#39;ve worked as a BI analyst in the business and I&amp;#39;ve always thought that this should be a BI job to understand how each column is calculated at least on a high end level and then work with the DE to figure out whether there&amp;#39;s any extra details to any columns. One of the arguments for it being a DE job for business logic requirements is that there is already backend logic to this which I think is fair but not all the column is mapped 1-1 and the systems totally different.&lt;/p&gt;\n\n&lt;p&gt;Haven&amp;#39;t asked my manager but was hoping to grab some 2nd opinions before this is raised up as it&amp;#39;s definitely making me frustrated. As context I&amp;#39;ve work in BI for 4 years and DE for 2.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a7d7y", "is_robot_indexable": true, "report_reasons": null, "author": "taafpxd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a7d7y/de_or_bi_to_figure_out_business_logic_requirements/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a7d7y/de_or_bi_to_figure_out_business_logic_requirements/", "subreddit_subscribers": 118163, "created_utc": 1690381714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability: The Next Frontier of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a6h78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1690379554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15a6h78", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a6h78/data_observability_the_next_frontier_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "subreddit_subscribers": 118163, "created_utc": 1690379554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests, I'm trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I'm able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying \n\n\"Cannot infer schema when the input path \\`/mnt/mnt\\_s3\\` is empty. Please try to start the stream when there are files in the input path, or specify the schema.\"\n\nHowever [dbutils.fs.ls](https://dbutils.fs.ls)('/mnt/mnt\\_s3') gives me this \\[FileInfo(path='dbfs:/mnt/mnt\\_s3/flightdata2018.json', name='flightdata2018.json', size=3276800, modificationTime=1690369838000)\\]\n\nP.S Complete noob to databricks, any help is greatly appreciated ", "author_fullname": "t2_a2sp7ole", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Live Tables Pipeline unable to read data from S3 mount", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a5734", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690376327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests, I&amp;#39;m trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I&amp;#39;m able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Cannot infer schema when the input path `/mnt/mnt_s3` is empty. Please try to start the stream when there are files in the input path, or specify the schema.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;However &lt;a href=\"https://dbutils.fs.ls\"&gt;dbutils.fs.ls&lt;/a&gt;(&amp;#39;/mnt/mnt_s3&amp;#39;) gives me this [FileInfo(path=&amp;#39;dbfs:/mnt/mnt_s3/flightdata2018.json&amp;#39;, name=&amp;#39;flightdata2018.json&amp;#39;, size=3276800, modificationTime=1690369838000)]&lt;/p&gt;\n\n&lt;p&gt;P.S Complete noob to databricks, any help is greatly appreciated &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a5734", "is_robot_indexable": true, "report_reasons": null, "author": "No_Conversation_2474", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "subreddit_subscribers": 118163, "created_utc": 1690376327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious how common it is for libraries to employ data engineers.\n\nThanks!", "author_fullname": "t2_a7uw8rfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here work for a library?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159y9fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690354955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious how common it is for libraries to employ data engineers.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159y9fq", "is_robot_indexable": true, "report_reasons": null, "author": "ruthlesscattle", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159y9fq/does_anyone_here_work_for_a_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159y9fq/does_anyone_here_work_for_a_library/", "subreddit_subscribers": 118163, "created_utc": 1690354955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How did design your star schema with dbt?\n\nDid you utilize model or snapshot in dbt?\n\nDid you use data vault as source for star schema?\n\nCould you layout some broad-level idea of architecture to design a star-schema/data-mart using dbt?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt - star schema question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159txoe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690375639.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690341248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How did design your star schema with dbt?&lt;/p&gt;\n\n&lt;p&gt;Did you utilize model or snapshot in dbt?&lt;/p&gt;\n\n&lt;p&gt;Did you use data vault as source for star schema?&lt;/p&gt;\n\n&lt;p&gt;Could you layout some broad-level idea of architecture to design a star-schema/data-mart using dbt?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159txoe", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159txoe/dbt_star_schema_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159txoe/dbt_star_schema_question/", "subreddit_subscribers": 118163, "created_utc": 1690341248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**TL;DR incorporate SQL functionality within Jupyter, access to modern data processing DBs (like DuckDB), polars and data exploration through plotting easier with JupySQL.**\n\nhey r/dataengineering! I'd like to share some news about JupySQL, an open source project my team has been working on!\n\nJupySQL allows you to run SQL and perform exploratory data analysis in Jupyter via magics %sqland %%sqlmagics, and visualize your data with %sqlplot.\n\nThis project is open source, and a successor to [iPython-SQL](https://github.com/catherinedevlin/ipython-sql#legacy-project). It is compatible with all major databases (e.g., PostgreSQL, MySQL, SQL Server), data warehouses (e.g., Snowflake, BigQuery, Redshift), and embedded engines (SQLite, and DuckDB).\n\nThis week the team released version 0.8.0 with improved data profiling and DuckDB performance when converting resulting tables to other formats (pandas and polars).\n\nLearn more: [https://jupysql.ploomber.io/en/latest/quick-start.html](https://jupysql.ploomber.io/en/latest/quick-start.html)\n\nif you have any questions, feel free to ask! And show your support with a star on [GitHub](https://github.com/ploomber/jupysql)!", "author_fullname": "t2_fymggxzxm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From iPython-sql to JupySQL: new updates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159fmf5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690307453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR incorporate SQL functionality within Jupyter, access to modern data processing DBs (like DuckDB), polars and data exploration through plotting easier with JupySQL.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;hey &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;! I&amp;#39;d like to share some news about JupySQL, an open source project my team has been working on!&lt;/p&gt;\n\n&lt;p&gt;JupySQL allows you to run SQL and perform exploratory data analysis in Jupyter via magics %sqland %%sqlmagics, and visualize your data with %sqlplot.&lt;/p&gt;\n\n&lt;p&gt;This project is open source, and a successor to &lt;a href=\"https://github.com/catherinedevlin/ipython-sql#legacy-project\"&gt;iPython-SQL&lt;/a&gt;. It is compatible with all major databases (e.g., PostgreSQL, MySQL, SQL Server), data warehouses (e.g., Snowflake, BigQuery, Redshift), and embedded engines (SQLite, and DuckDB).&lt;/p&gt;\n\n&lt;p&gt;This week the team released version 0.8.0 with improved data profiling and DuckDB performance when converting resulting tables to other formats (pandas and polars).&lt;/p&gt;\n\n&lt;p&gt;Learn more: &lt;a href=\"https://jupysql.ploomber.io/en/latest/quick-start.html\"&gt;https://jupysql.ploomber.io/en/latest/quick-start.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;if you have any questions, feel free to ask! And show your support with a star on &lt;a href=\"https://github.com/ploomber/jupysql\"&gt;GitHub&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?auto=webp&amp;s=5eaa766829f09147ae3b2bc614f13187e68a7ed2", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5a28510613b8de7ed1f6ec1538d38e82e08a43b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=590514cfa4354a7729e11d76f6f5c7030ccb4495", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e9fbbb2d65b14a1965551d9c1be14b5bbda33aca", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df82b64967e5b1f92f666deb91ea92f58224b274", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ea4bf05c21fc35ed35fa555aa184407b6aa6b7b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/90Cha81WaAMF6NYzqUXI9Ido2h_m2FIgr6oS4pL7b8Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ec1c6c82462e53121c27c95aa55a2bb87a46908", "width": 1080, "height": 540}], "variants": {}, "id": "PnfZqzALk55bbYPxf42ETuUy79_7mLJARaQ2dFLRMAY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "159fmf5", "is_robot_indexable": true, "report_reasons": null, "author": "ploomber-dev", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159fmf5/from_ipythonsql_to_jupysql_new_updates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159fmf5/from_ipythonsql_to_jupysql_new_updates/", "subreddit_subscribers": 118163, "created_utc": 1690307453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Appreciate if you can share it...\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a guide to design a star schema from a data vault?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15aayhz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690390064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Appreciate if you can share it...&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15aayhz", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15aayhz/do_you_have_a_guide_to_design_a_star_schema_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15aayhz/do_you_have_a_guide_to_design_a_star_schema_from/", "subreddit_subscribers": 118163, "created_utc": 1690390064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a financial institution and they want me to create/develop a single source of truth for our data. Basically they want me to house it in one spot that has live updates so that everyone at the institution can access it and not have to worry if it's outdated or not. When this process is complete they also want me to develop a customer 360 dashboard that would also have live time updates. I have somewhat of a background in coding, data science, and analytics. I know this isn't directly up my alley but I would like to build my knowledge about this sort of thing. I have also used a little of Microsoft Azure in school but never fully tapped into it, just did the basic assignments I was given. Anyways I'm just looking for answers as to where I should start the road map or what softwares or applications would be useful for completing the task.", "author_fullname": "t2_aix6z1cs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Single Data Source and 360 Access", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15a9za1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690387807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a financial institution and they want me to create/develop a single source of truth for our data. Basically they want me to house it in one spot that has live updates so that everyone at the institution can access it and not have to worry if it&amp;#39;s outdated or not. When this process is complete they also want me to develop a customer 360 dashboard that would also have live time updates. I have somewhat of a background in coding, data science, and analytics. I know this isn&amp;#39;t directly up my alley but I would like to build my knowledge about this sort of thing. I have also used a little of Microsoft Azure in school but never fully tapped into it, just did the basic assignments I was given. Anyways I&amp;#39;m just looking for answers as to where I should start the road map or what softwares or applications would be useful for completing the task.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a9za1", "is_robot_indexable": true, "report_reasons": null, "author": "OJ_Dyansty35", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a9za1/single_data_source_and_360_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a9za1/single_data_source_and_360_access/", "subreddit_subscribers": 118163, "created_utc": 1690387807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My 4-engineer team is planning to build data pipelines to do the following - curious what everyone's thoughts are on the best architecture here - thanks in advance for your thoughts:\n\n* Politely scrape public sites - then pop the results into a queue for downstream processing\n* Clean / enrich the results (entity extraction, translation, sentiment, etc.)\n* Expect around 2 million records per day through this pipeline\n* Store the results in ElasticSearch - get them here as quickly as possible, as we're building 'current events' dashboards\n* We also have scheduled jobs we are currently responsible for that we'd like to move into this setup\n* Need to run within AWS, will be tough to bring in other vendors (i.e. Astronomer, Confluent, etc.)\n\nWe don't have an infrastructure team so we're responsible for all the infrastructure we stand up. Our devs are mostly experienced in Python. Our local setups are fully containerized, hoping to keep it that way if possible.\n\nWant to prioritize:\n\n* Good local setup for development\n* Minimize infrastructure maintenance\n* Ease of monitoring and retrying / re-running failed jobs\n* Type safety between steps in data pipeline\n* Ease of finding / visualizing data flow &amp; dependencies\n* Autoscaling in Production\n* Speed of start to end of pipeline for individual records\n\nThinking of using AWS's Managed Airflow for workflow orchestration and achieving enough streaming capabilities through Sensors pointing at Redis or SQS queues... \n\nCurious if this sounds like a reasonable approach, if there's a better architecture these days, and/or if i'm off-base with all of these requirements. Thanks again", "author_fullname": "t2_e1poh23pm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideal system architecture for both workflow orchestration and streaming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15a9awd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690386266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My 4-engineer team is planning to build data pipelines to do the following - curious what everyone&amp;#39;s thoughts are on the best architecture here - thanks in advance for your thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Politely scrape public sites - then pop the results into a queue for downstream processing&lt;/li&gt;\n&lt;li&gt;Clean / enrich the results (entity extraction, translation, sentiment, etc.)&lt;/li&gt;\n&lt;li&gt;Expect around 2 million records per day through this pipeline&lt;/li&gt;\n&lt;li&gt;Store the results in ElasticSearch - get them here as quickly as possible, as we&amp;#39;re building &amp;#39;current events&amp;#39; dashboards&lt;/li&gt;\n&lt;li&gt;We also have scheduled jobs we are currently responsible for that we&amp;#39;d like to move into this setup&lt;/li&gt;\n&lt;li&gt;Need to run within AWS, will be tough to bring in other vendors (i.e. Astronomer, Confluent, etc.)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We don&amp;#39;t have an infrastructure team so we&amp;#39;re responsible for all the infrastructure we stand up. Our devs are mostly experienced in Python. Our local setups are fully containerized, hoping to keep it that way if possible.&lt;/p&gt;\n\n&lt;p&gt;Want to prioritize:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Good local setup for development&lt;/li&gt;\n&lt;li&gt;Minimize infrastructure maintenance&lt;/li&gt;\n&lt;li&gt;Ease of monitoring and retrying / re-running failed jobs&lt;/li&gt;\n&lt;li&gt;Type safety between steps in data pipeline&lt;/li&gt;\n&lt;li&gt;Ease of finding / visualizing data flow &amp;amp; dependencies&lt;/li&gt;\n&lt;li&gt;Autoscaling in Production&lt;/li&gt;\n&lt;li&gt;Speed of start to end of pipeline for individual records&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thinking of using AWS&amp;#39;s Managed Airflow for workflow orchestration and achieving enough streaming capabilities through Sensors pointing at Redis or SQS queues... &lt;/p&gt;\n\n&lt;p&gt;Curious if this sounds like a reasonable approach, if there&amp;#39;s a better architecture these days, and/or if i&amp;#39;m off-base with all of these requirements. Thanks again&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a9awd", "is_robot_indexable": true, "report_reasons": null, "author": "Turbulent-Sand4889", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a9awd/ideal_system_architecture_for_both_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a9awd/ideal_system_architecture_for_both_workflow/", "subreddit_subscribers": 118163, "created_utc": 1690386266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@stefentaime\\_10958/automating-data-pipeline-deployment-on-aws-with-terraform-utilizing-lambda-glue-crawler-1621e0736edd](https://medium.com/@stefentaime_10958/automating-data-pipeline-deployment-on-aws-with-terraform-utilizing-lambda-glue-crawler-1621e0736edd)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rscsdc6fwbeb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=c13b622f69f101645a7e291eb69e12a4ec6f1556", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automating Data Pipeline Deployment on AWS with Terraform: Utilizing Lambda, Glue, Crawler, Redshift, and S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"rscsdc6fwbeb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b7390240f63e7fc31925347e463ea82c23d70ddf"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc1b8ae50c292c0a52f6b077cb283e6f1436ad2b"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7fbad17cc6e3d930427ce1f2af8f1566aa82a58"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=45d2d223fe38b1c3879849686e104ab5e4e0ed26"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4842566c3ad4bb7ae29728fc323b1c6d87ac7457"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0493d2fb3db553c807123115eda2b7e533275546"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=c13b622f69f101645a7e291eb69e12a4ec6f1556"}, "id": "rscsdc6fwbeb1"}}, "name": "t3_15a92hh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SUgfyEh8U7PSvcscp48bmCrP8Wq4W_pOV3LyCkXik8w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1690385721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/automating-data-pipeline-deployment-on-aws-with-terraform-utilizing-lambda-glue-crawler-1621e0736edd\"&gt;https://medium.com/@stefentaime_10958/automating-data-pipeline-deployment-on-aws-with-terraform-utilizing-lambda-glue-crawler-1621e0736edd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rscsdc6fwbeb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c13b622f69f101645a7e291eb69e12a4ec6f1556\"&gt;https://preview.redd.it/rscsdc6fwbeb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c13b622f69f101645a7e291eb69e12a4ec6f1556&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?auto=webp&amp;s=612c9df6ef907f76d90b9d4010c4ec16e413bbfb", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=81db565596712608476f1d6389baba47483d75b9", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c91df118f6b3721b01e3597eb2a2560af8de79f3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a129cfb4f4362cac6dc92dcae285c641fbc3a553", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3ac9c200b7227f0f58c41dce7dcc4f0e3722d05", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=52bdb1484c86e9b958f664ffe330308ab25d3425", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d34bd80b3cb7d0a71f833260f048c859430d3afa", "width": 1080, "height": 607}], "variants": {}, "id": "R9spcbH1HlEC9REJjRmw2v8JazSeB8lYL6yfZwSZlzM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15a92hh", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a92hh/automating_data_pipeline_deployment_on_aws_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a92hh/automating_data_pipeline_deployment_on_aws_with/", "subreddit_subscribers": 118163, "created_utc": 1690385721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm assisting a non-profit in a food supply chain project and wanting to understand the cheapest, most efficient way to track the lat/longs of their trucks over time, including real-time. Only about \\~10 trucks and we don't need anything fancy. Just truck+datetime+lat+long.\n\nWhat hardware/tools would be cheapest to obtain this type of information? Options I've considered, but each has their downsides:\n\n1. My mind went to Airtags first for simplicity purposes, but accessing history seems possibly achievable, but frustrating.\n2. Verizon Connect Fleet Tracking - Ability to access historical data, but I didn't see lat/long in their video. Also probably too expensive, but they're too vague on pricing on their site.\n3. A quick \"GPS Fleet Tracking\" search yields a ton of different company offerings, but many seem like overkill (and would likely price as such). I'm looking for the simplest offering, not the most robust.\n\nFor what it's worth, I'm relatively new to data engineering and brand new to ingestion of lat/longs, so apologies if this is a stupid question!", "author_fullname": "t2_pmps7fj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to ingest lat/long data via GPS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a8yck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690385459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m assisting a non-profit in a food supply chain project and wanting to understand the cheapest, most efficient way to track the lat/longs of their trucks over time, including real-time. Only about ~10 trucks and we don&amp;#39;t need anything fancy. Just truck+datetime+lat+long.&lt;/p&gt;\n\n&lt;p&gt;What hardware/tools would be cheapest to obtain this type of information? Options I&amp;#39;ve considered, but each has their downsides:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;My mind went to Airtags first for simplicity purposes, but accessing history seems possibly achievable, but frustrating.&lt;/li&gt;\n&lt;li&gt;Verizon Connect Fleet Tracking - Ability to access historical data, but I didn&amp;#39;t see lat/long in their video. Also probably too expensive, but they&amp;#39;re too vague on pricing on their site.&lt;/li&gt;\n&lt;li&gt;A quick &amp;quot;GPS Fleet Tracking&amp;quot; search yields a ton of different company offerings, but many seem like overkill (and would likely price as such). I&amp;#39;m looking for the simplest offering, not the most robust.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For what it&amp;#39;s worth, I&amp;#39;m relatively new to data engineering and brand new to ingestion of lat/longs, so apologies if this is a stupid question!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a8yck", "is_robot_indexable": true, "report_reasons": null, "author": "hornfan87", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a8yck/easiest_way_to_ingest_latlong_data_via_gps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a8yck/easiest_way_to_ingest_latlong_data_via_gps/", "subreddit_subscribers": 118163, "created_utc": 1690385459.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}