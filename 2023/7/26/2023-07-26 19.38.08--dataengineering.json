{"kind": "Listing", "data": {"after": "t3_15a8yck", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great Expectations is bloaty. What are the alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a45gt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690373573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15a45gt", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "subreddit_subscribers": 118175, "created_utc": 1690373573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started my career as a data engineer. I have been learning a lot at work, but I think it\u2019s slowing down and not fast enough. I really want to get good at data engineering, I aspire to become a better data engineer. What can I do during my spare time to work on that? I am planning to start work on Leetcode, to practice my Python and build up DSA knowledge. What else can I do to learn faster?\n\nI use mainly SQL and no code GUI for ETL (which is bad I believe)", "author_fullname": "t2_b4x7m5t6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I become a better data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159v9e8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690345164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started my career as a data engineer. I have been learning a lot at work, but I think it\u2019s slowing down and not fast enough. I really want to get good at data engineering, I aspire to become a better data engineer. What can I do during my spare time to work on that? I am planning to start work on Leetcode, to practice my Python and build up DSA knowledge. What else can I do to learn faster?&lt;/p&gt;\n\n&lt;p&gt;I use mainly SQL and no code GUI for ETL (which is bad I believe)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159v9e8", "is_robot_indexable": true, "report_reasons": null, "author": "heyveryfunny", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159v9e8/how_do_i_become_a_better_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159v9e8/how_do_i_become_a_better_data_engineer/", "subreddit_subscribers": 118175, "created_utc": 1690345164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow data enthusiasts!\n\nI've recently been hired to work in a new small DE team, and I've been tasked with building a more \"big data\" environment for our company. Unfortunately, we have a strict policy against using cloud storage, so I'm looking for recommendations and guidance on creating a robust solution with open-source tools only.\n\nCurrently, most of our data (CDRs files) is continuously stored on a server using cron jobs, and we load it into Oracle. Additionally, we have dblinks connections from other databases to our main Oracle database. However, we're facing some challenges with slow PowerBI dashboards due to the large volume of data ( hundreds of billions of rows), complex joins, and aggregation functions.\n\n&amp;#x200B;\n\nHere's what I'm thinking of for our new environment:\n\n1. Data Ingestion: I'm considering using Apache Airflow and Kafka. or is kafka overkill ? any alternative if ?\n2. Data Processing: Spark seems like a great choice for data processing ?\n3. Datalake: I've come across HDFS as a popular choice, but I'm also curious about other alternative as I heard Hadoop is a pain to manage. Any experiences or feedback on Minio?\n4. Analytics Oriented Database: As our PowerBI dashboards are becoming slower with increasing data volume (overload Oracle) , I believe it's essential to have an analytics-oriented database to improve performance. I'd love to hear your recommendations for databases that work well with PowerBI and can handle large-scale analytical workloads.\n\nOur ultimate goal is to not only improve the performance of our current analytical processes but also lay the groundwork for \"potential future\" machine learning projects.\n\nIf you have any experience, suggestions, or advice regarding these components or any other tool that you think could enhance our environment, please share your insights! I greatly appreciate any help you can provide.\n\nFeel free to ask for more details if needed. Thank you for taking the time to read this post!", "author_fullname": "t2_kfjsv6pf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommandation needed for building an Open Source pipeline / datalake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159yg87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690359315.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690355604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow data enthusiasts!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently been hired to work in a new small DE team, and I&amp;#39;ve been tasked with building a more &amp;quot;big data&amp;quot; environment for our company. Unfortunately, we have a strict policy against using cloud storage, so I&amp;#39;m looking for recommendations and guidance on creating a robust solution with open-source tools only.&lt;/p&gt;\n\n&lt;p&gt;Currently, most of our data (CDRs files) is continuously stored on a server using cron jobs, and we load it into Oracle. Additionally, we have dblinks connections from other databases to our main Oracle database. However, we&amp;#39;re facing some challenges with slow PowerBI dashboards due to the large volume of data ( hundreds of billions of rows), complex joins, and aggregation functions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I&amp;#39;m thinking of for our new environment:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Ingestion: I&amp;#39;m considering using Apache Airflow and Kafka. or is kafka overkill ? any alternative if ?&lt;/li&gt;\n&lt;li&gt;Data Processing: Spark seems like a great choice for data processing ?&lt;/li&gt;\n&lt;li&gt;Datalake: I&amp;#39;ve come across HDFS as a popular choice, but I&amp;#39;m also curious about other alternative as I heard Hadoop is a pain to manage. Any experiences or feedback on Minio?&lt;/li&gt;\n&lt;li&gt;Analytics Oriented Database: As our PowerBI dashboards are becoming slower with increasing data volume (overload Oracle) , I believe it&amp;#39;s essential to have an analytics-oriented database to improve performance. I&amp;#39;d love to hear your recommendations for databases that work well with PowerBI and can handle large-scale analytical workloads.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Our ultimate goal is to not only improve the performance of our current analytical processes but also lay the groundwork for &amp;quot;potential future&amp;quot; machine learning projects.&lt;/p&gt;\n\n&lt;p&gt;If you have any experience, suggestions, or advice regarding these components or any other tool that you think could enhance our environment, please share your insights! I greatly appreciate any help you can provide.&lt;/p&gt;\n\n&lt;p&gt;Feel free to ask for more details if needed. Thank you for taking the time to read this post!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159yg87", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_War6424", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159yg87/recommandation_needed_for_building_an_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159yg87/recommandation_needed_for_building_an_open_source/", "subreddit_subscribers": 118175, "created_utc": 1690355604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_gxlue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why JSON still rocks as a format for data lakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "name": "t3_159lfpu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QkrFPbGLgQt_fuj6g_1E0SKdylh0jkDw6IBVB6uyHjU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690320045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "opendatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://opendatascience.com/choosing-a-data-lake-format-what-to-actually-look-for/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?auto=webp&amp;s=15ae1e8a8050436aed75049ca4b948c53c5d9915", "width": 640, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=41801bd050610bf9e2348de7a544a0e5edd482ff", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=811cc432778ab2e43e8ec8e9e3e299b59b3fd864", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9a6dd6572b02906f9f4ef731baf72a24bfe3592b", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/7k2LRi_oVXiK9SlLiFc3L4WGhmp1i_ut1CrDf7G-0yA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=afe1e23618374a28450a0abece2ccdc9610cadd2", "width": 640, "height": 300}], "variants": {}, "id": "r9qfcfrYWA9wAXPOHHaOzOE10XGpP8py2K_jMNXGL2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "159lfpu", "is_robot_indexable": true, "report_reasons": null, "author": "artsyfartsiest", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159lfpu/why_json_still_rocks_as_a_format_for_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://opendatascience.com/choosing-a-data-lake-format-what-to-actually-look-for/", "subreddit_subscribers": 118175, "created_utc": 1690320045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer at one of the big techs, and I'm considering a role as a Specialist Solutions Architect at Databricks. It specializes on data engineering but it seems to be a lot of customer facing role, which is different from my current role.\n\nHow is this position in terms of career progression? I do want the option to get back to data or software engineering in the future, and I feel I will get shoed in to a client facing role if I take this.\n\nAlso if anyone knows anything about the pros and cons of this position at Databricks, like wlb/comp, etc. I would love to know!", "author_fullname": "t2_ih0l5i9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solutions Architect role at Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a26zd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690368116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer at one of the big techs, and I&amp;#39;m considering a role as a Specialist Solutions Architect at Databricks. It specializes on data engineering but it seems to be a lot of customer facing role, which is different from my current role.&lt;/p&gt;\n\n&lt;p&gt;How is this position in terms of career progression? I do want the option to get back to data or software engineering in the future, and I feel I will get shoed in to a client facing role if I take this.&lt;/p&gt;\n\n&lt;p&gt;Also if anyone knows anything about the pros and cons of this position at Databricks, like wlb/comp, etc. I would love to know!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15a26zd", "is_robot_indexable": true, "report_reasons": null, "author": "DataApe", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a26zd/solutions_architect_role_at_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a26zd/solutions_architect_role_at_databricks/", "subreddit_subscribers": 118175, "created_utc": 1690368116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a backend developer involved in building an analytics pipeline for our application to display usage statistics to our users. I had no training in data engineering so far.\n\nBefore reading about ELT, I had an idea to utilize an AWS Glue job to extract data from the source (MySQL), transform it within the same Glue job, and load the resulting set into a data warehouse to perform queries. But as I understand, this would be a classic ETL approach.\n\nBut the ELT approach, as I understand it, would look different: utilize an AWS Glue job to load data into a data warehouse as is (basically copy the existing MySQL tables there), and then transform data using queries like:\n\n    INSERT into table3\n    SELECT table1.column_a, table1.column_b, table2.column_c, table2.column_d, FROM table1\n    JOIN table2\n\nEvery source I read mentions that the ELT is a superior and more recent approach than ETL.\n\nBut I don't feel like this. I have a couple of concerns about ELT:\n\n* With ETL, the tool (AWS Glue) would maintain incremental data extraction. With ELT, I must implement a mechanism for incremental data transformation (e.g. only insert changed rows into *table3*)\n* AWS Glue performs transformations in parallel. This is not likely the case for relational databases like MySQL, as it would process the query above on a single node.\n\nSo my questions are:\n\n* Are there flaws in my understanding of ELT?\n* Which databases/tools can act as data warehouses which support incremental load and parallelism?\n* Which of them are available in AWS?\n\nI'd also prefer not to use sophisticated or enterprise tools since we don't have lots of data (less than 10M rows). Thanks.", "author_fullname": "t2_zkr4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which databases are good for ELT (Extract-Load-Transform)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a0sux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690363720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a backend developer involved in building an analytics pipeline for our application to display usage statistics to our users. I had no training in data engineering so far.&lt;/p&gt;\n\n&lt;p&gt;Before reading about ELT, I had an idea to utilize an AWS Glue job to extract data from the source (MySQL), transform it within the same Glue job, and load the resulting set into a data warehouse to perform queries. But as I understand, this would be a classic ETL approach.&lt;/p&gt;\n\n&lt;p&gt;But the ELT approach, as I understand it, would look different: utilize an AWS Glue job to load data into a data warehouse as is (basically copy the existing MySQL tables there), and then transform data using queries like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;INSERT into table3\nSELECT table1.column_a, table1.column_b, table2.column_c, table2.column_d, FROM table1\nJOIN table2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Every source I read mentions that the ELT is a superior and more recent approach than ETL.&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t feel like this. I have a couple of concerns about ELT:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;With ETL, the tool (AWS Glue) would maintain incremental data extraction. With ELT, I must implement a mechanism for incremental data transformation (e.g. only insert changed rows into &lt;em&gt;table3&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;AWS Glue performs transformations in parallel. This is not likely the case for relational databases like MySQL, as it would process the query above on a single node.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So my questions are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Are there flaws in my understanding of ELT?&lt;/li&gt;\n&lt;li&gt;Which databases/tools can act as data warehouses which support incremental load and parallelism?&lt;/li&gt;\n&lt;li&gt;Which of them are available in AWS?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d also prefer not to use sophisticated or enterprise tools since we don&amp;#39;t have lots of data (less than 10M rows). Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a0sux", "is_robot_indexable": true, "report_reasons": null, "author": "binary-data", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a0sux/which_databases_are_good_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a0sux/which_databases_are_good_for_elt/", "subreddit_subscribers": 118175, "created_utc": 1690363720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have around 500+ GB of data per day with 800 columns that I need to load into Redshift for 5 years worth of data. However, the data loading process is quite slow using copy command from s3 to redshift. Any suggestions on how to optimize and speed up the data loading in Redshift", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load huge volume of data to redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159wr91", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690349909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 500+ GB of data per day with 800 columns that I need to load into Redshift for 5 years worth of data. However, the data loading process is quite slow using copy command from s3 to redshift. Any suggestions on how to optimize and speed up the data loading in Redshift&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159wr91", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159wr91/load_huge_volume_of_data_to_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159wr91/load_huge_volume_of_data_to_redshift/", "subreddit_subscribers": 118175, "created_utc": 1690349909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Turns out databases are \"relational\" or something", "author_fullname": "t2_qlmkijv8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The data engineer came to me... tears in his eyes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 107, "top_awarded_type": null, "hide_score": true, "name": "t3_15ae6kp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w5lBiBLnqC1xzIdkywBWCqB0YGYQeRWrqr08EMByD2s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690397313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Turns out databases are &amp;quot;relational&amp;quot; or something&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1wm37l33vceb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1wm37l33vceb1.png?auto=webp&amp;s=8eb68cc0feab067c94c5d88ca54a7eda2cbfcfd2", "width": 1080, "height": 830}, "resolutions": [{"url": "https://preview.redd.it/1wm37l33vceb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=48652b42e4fe71b9c48eac0b2a2c6a0eaaad045b", "width": 108, "height": 83}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=79d5b3781803dce41f5534196cb74c8f84aa1caa", "width": 216, "height": 166}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=afdafe3ea62eae50680c1797cac89dd8c6010a0f", "width": 320, "height": 245}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=992489262d93f2834aba10c908b504e4f58e328a", "width": 640, "height": 491}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=97be176695471f82f58a8349a936a5d2c170eaf9", "width": 960, "height": 737}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b45cda7bf48386140f347a041f725b62cbbe33b", "width": 1080, "height": 830}], "variants": {}, "id": "UwqiG5dVs8n80MCeWPA1--klG-ySKne2YEq3LyGRi8k"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15ae6kp", "is_robot_indexable": true, "report_reasons": null, "author": "shed_antlers", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ae6kp/the_data_engineer_came_to_me_tears_in_his_eyes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1wm37l33vceb1.png", "subreddit_subscribers": 118175, "created_utc": 1690397313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I'm working on AWS and have it available for experiments.\n\nIf you have any guide/tutorial/walkthrough to recommend, please do share!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend a good k8s / EKS guide?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a32at", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690370610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I&amp;#39;m working on AWS and have it available for experiments.&lt;/p&gt;\n\n&lt;p&gt;If you have any guide/tutorial/walkthrough to recommend, please do share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a32at", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "subreddit_subscribers": 118175, "created_utc": 1690370610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm consulting with a team of data engineers as a solution architect. Long story short, they're looking to do some work for this customer that will entail hopping into the database and doing the normal thing of writing procs and such to enable some capabilities like automated quality checking/testing, enforcing constraints, yada yada. \n\nI've worked quite a bit with GIS and with most of ESRIs products, but this was the first time really looking at the table-level structure of an ArcGIS warehouse and it doesn't seem like the team I'm on really had either. Some quick googling didn't return any solid leads, but does anybody know of any best practices when developing capabilities within or next to a running enterprise level ESRI warehouse?", "author_fullname": "t2_fp2tq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for working within ArcGis Warehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159s722", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690336366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m consulting with a team of data engineers as a solution architect. Long story short, they&amp;#39;re looking to do some work for this customer that will entail hopping into the database and doing the normal thing of writing procs and such to enable some capabilities like automated quality checking/testing, enforcing constraints, yada yada. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve worked quite a bit with GIS and with most of ESRIs products, but this was the first time really looking at the table-level structure of an ArcGIS warehouse and it doesn&amp;#39;t seem like the team I&amp;#39;m on really had either. Some quick googling didn&amp;#39;t return any solid leads, but does anybody know of any best practices when developing capabilities within or next to a running enterprise level ESRI warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159s722", "is_robot_indexable": true, "report_reasons": null, "author": "lostinthewalls", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159s722/best_practices_for_working_within_arcgis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159s722/best_practices_for_working_within_arcgis/", "subreddit_subscribers": 118175, "created_utc": 1690336366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019m a Data Scientist of 5 years out of a job and have just got an interview for a Data Engineer role coming up. I\u2019m thinking it\u2019s a good role as I like the engineering stuff, and really need a job!\n\n So my questions are: \n1) What topics are worth focusing my prep/study on? \n2) I need to prepare a set of a few slides about a recent DE end to end project I\u2019ve worked on. Any tips on that, as I have created a feature store for ML before, and have some personal projects too?\n\nThanks for any advice and tips!", "author_fullname": "t2_7kdevi10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist interviewing for a Data Engineering role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a02oy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690361223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m a Data Scientist of 5 years out of a job and have just got an interview for a Data Engineer role coming up. I\u2019m thinking it\u2019s a good role as I like the engineering stuff, and really need a job!&lt;/p&gt;\n\n&lt;p&gt;So my questions are: \n1) What topics are worth focusing my prep/study on? \n2) I need to prepare a set of a few slides about a recent DE end to end project I\u2019ve worked on. Any tips on that, as I have created a feature store for ML before, and have some personal projects too?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice and tips!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15a02oy", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive_Fact_6561", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a02oy/data_scientist_interviewing_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a02oy/data_scientist_interviewing_for_a_data/", "subreddit_subscribers": 118175, "created_utc": 1690361223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a cs software manager at a public company. I\u2019m not currently in a data engineering role, but I want to make a pivot into DE. I\u2019ve had a DE ticket open for several months for them just to scope and there\u2019s no end in sight. It could be several more months before they can even think about looking at our ticket. Suffice it to say our DE team is under resourced. \n\nThis is where I feel that maybe I\u2019m being naive: I feel like the request is simple. We want to create a daily job for some API reports and bring it into our data warehouse. \n\nHow many hoops does one need to jump through in a mid-level organization to write a script then push it to the warehouse? \n\nWhat level of difficulty is this normally? \n\nWould it be rude to write the script and hand it over to the DE team?\n\nLooking for advice to navigate the situation. Thanks!", "author_fullname": "t2_b7jxy4i2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I being naive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ad17i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690394712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a cs software manager at a public company. I\u2019m not currently in a data engineering role, but I want to make a pivot into DE. I\u2019ve had a DE ticket open for several months for them just to scope and there\u2019s no end in sight. It could be several more months before they can even think about looking at our ticket. Suffice it to say our DE team is under resourced. &lt;/p&gt;\n\n&lt;p&gt;This is where I feel that maybe I\u2019m being naive: I feel like the request is simple. We want to create a daily job for some API reports and bring it into our data warehouse. &lt;/p&gt;\n\n&lt;p&gt;How many hoops does one need to jump through in a mid-level organization to write a script then push it to the warehouse? &lt;/p&gt;\n\n&lt;p&gt;What level of difficulty is this normally? &lt;/p&gt;\n\n&lt;p&gt;Would it be rude to write the script and hand it over to the DE team?&lt;/p&gt;\n\n&lt;p&gt;Looking for advice to navigate the situation. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ad17i", "is_robot_indexable": true, "report_reasons": null, "author": "Marble_Kween", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ad17i/am_i_being_naive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ad17i/am_i_being_naive/", "subreddit_subscribers": 118175, "created_utc": 1690394712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems like Redshift would be good to learn, but the pricing I see on it scares the c#@p out of me. Does anyone know a good tutorial which also includes how much will be spent by following along and also shows thorough instructions on how to shut down and destroy the resources when finished?", "author_fullname": "t2_io9vf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scared of Redshift - Any Good Resources to Learn with Low Cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15acq1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690394010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems like Redshift would be good to learn, but the pricing I see on it scares the c#@p out of me. Does anyone know a good tutorial which also includes how much will be spent by following along and also shows thorough instructions on how to shut down and destroy the resources when finished?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15acq1h", "is_robot_indexable": true, "report_reasons": null, "author": "Scalar_Mikeman", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15acq1h/scared_of_redshift_any_good_resources_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15acq1h/scared_of_redshift_any_good_resources_to_learn/", "subreddit_subscribers": 118175, "created_utc": 1690394010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Appreciate if you can share it...\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a guide to design a star schema from a data vault?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15aayhz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690390064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Appreciate if you can share it...&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15aayhz", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15aayhz/do_you_have_a_guide_to_design_a_star_schema_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15aayhz/do_you_have_a_guide_to_design_a_star_schema_from/", "subreddit_subscribers": 118175, "created_utc": 1690390064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nSQL query tuning and optimization.\n\nSQL indexing.\n\nSQL integration.\n\nSQL reporting.\n\nSQL execution plans.", "author_fullname": "t2_97jhjawv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the right learning order for these SQL subjects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a94v3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690385880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SQL query tuning and optimization.&lt;/p&gt;\n\n&lt;p&gt;SQL indexing.&lt;/p&gt;\n\n&lt;p&gt;SQL integration.&lt;/p&gt;\n\n&lt;p&gt;SQL reporting.&lt;/p&gt;\n\n&lt;p&gt;SQL execution plans.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a94v3", "is_robot_indexable": true, "report_reasons": null, "author": "TreatOk8778", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a94v3/whats_the_right_learning_order_for_these_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a94v3/whats_the_right_learning_order_for_these_sql/", "subreddit_subscribers": 118175, "created_utc": 1690385880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently working on replacing one of our online management systems with a new one and one of the requirements for the migration is to sort out how we are going to do this on a DW side.\n\nI know that my role is to figure out what the ETL/ELT process is and make sure that the data pipelines are feeding in but the biggest concern I have is understanding whether my job involves getting the business logic for field transformation directly or whether this is something which the BI team should do ? I've worked as a BI analyst in the business and I've always thought that this should be a BI job to understand how each column is calculated at least on a high end level and then work with the DE to figure out whether there's any extra details to any columns. One of the arguments for it being a DE job for business logic requirements is that there is already backend logic to this which I think is fair but not all the column is mapped 1-1 and the systems totally different.\n\nHaven't asked my manager but was hoping to grab some 2nd opinions before this is raised up as it's definitely making me frustrated. As context I've work in BI for 4 years and DE for 2.", "author_fullname": "t2_2ahdonrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE or BI to figure out business logic requirements ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a7d7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690381714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently working on replacing one of our online management systems with a new one and one of the requirements for the migration is to sort out how we are going to do this on a DW side.&lt;/p&gt;\n\n&lt;p&gt;I know that my role is to figure out what the ETL/ELT process is and make sure that the data pipelines are feeding in but the biggest concern I have is understanding whether my job involves getting the business logic for field transformation directly or whether this is something which the BI team should do ? I&amp;#39;ve worked as a BI analyst in the business and I&amp;#39;ve always thought that this should be a BI job to understand how each column is calculated at least on a high end level and then work with the DE to figure out whether there&amp;#39;s any extra details to any columns. One of the arguments for it being a DE job for business logic requirements is that there is already backend logic to this which I think is fair but not all the column is mapped 1-1 and the systems totally different.&lt;/p&gt;\n\n&lt;p&gt;Haven&amp;#39;t asked my manager but was hoping to grab some 2nd opinions before this is raised up as it&amp;#39;s definitely making me frustrated. As context I&amp;#39;ve work in BI for 4 years and DE for 2.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a7d7y", "is_robot_indexable": true, "report_reasons": null, "author": "taafpxd", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a7d7y/de_or_bi_to_figure_out_business_logic_requirements/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a7d7y/de_or_bi_to_figure_out_business_logic_requirements/", "subreddit_subscribers": 118175, "created_utc": 1690381714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability: The Next Frontier of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a6h78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1690379554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15a6h78", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a6h78/data_observability_the_next_frontier_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "subreddit_subscribers": 118175, "created_utc": 1690379554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests, I'm trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I'm able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying \n\n\"Cannot infer schema when the input path \\`/mnt/mnt\\_s3\\` is empty. Please try to start the stream when there are files in the input path, or specify the schema.\"\n\nHowever [dbutils.fs.ls](https://dbutils.fs.ls)('/mnt/mnt\\_s3') gives me this \\[FileInfo(path='dbfs:/mnt/mnt\\_s3/flightdata2018.json', name='flightdata2018.json', size=3276800, modificationTime=1690369838000)\\]\n\nP.S Complete noob to databricks, any help is greatly appreciated ", "author_fullname": "t2_a2sp7ole", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Live Tables Pipeline unable to read data from S3 mount", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a5734", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690376327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests, I&amp;#39;m trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I&amp;#39;m able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Cannot infer schema when the input path `/mnt/mnt_s3` is empty. Please try to start the stream when there are files in the input path, or specify the schema.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;However &lt;a href=\"https://dbutils.fs.ls\"&gt;dbutils.fs.ls&lt;/a&gt;(&amp;#39;/mnt/mnt_s3&amp;#39;) gives me this [FileInfo(path=&amp;#39;dbfs:/mnt/mnt_s3/flightdata2018.json&amp;#39;, name=&amp;#39;flightdata2018.json&amp;#39;, size=3276800, modificationTime=1690369838000)]&lt;/p&gt;\n\n&lt;p&gt;P.S Complete noob to databricks, any help is greatly appreciated &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a5734", "is_robot_indexable": true, "report_reasons": null, "author": "No_Conversation_2474", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "subreddit_subscribers": 118175, "created_utc": 1690376327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious how common it is for libraries to employ data engineers.\n\nThanks!", "author_fullname": "t2_a7uw8rfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here work for a library?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159y9fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690354955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious how common it is for libraries to employ data engineers.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "159y9fq", "is_robot_indexable": true, "report_reasons": null, "author": "ruthlesscattle", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159y9fq/does_anyone_here_work_for_a_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159y9fq/does_anyone_here_work_for_a_library/", "subreddit_subscribers": 118175, "created_utc": 1690354955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How did design your star schema with dbt?\n\nDid you utilize model or snapshot in dbt?\n\nDid you use data vault as source for star schema?\n\nCould you layout some broad-level idea of architecture to design a star-schema/data-mart using dbt?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt - star schema question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_159txoe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690375639.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690341248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How did design your star schema with dbt?&lt;/p&gt;\n\n&lt;p&gt;Did you utilize model or snapshot in dbt?&lt;/p&gt;\n\n&lt;p&gt;Did you use data vault as source for star schema?&lt;/p&gt;\n\n&lt;p&gt;Could you layout some broad-level idea of architecture to design a star-schema/data-mart using dbt?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "159txoe", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/159txoe/dbt_star_schema_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/159txoe/dbt_star_schema_question/", "subreddit_subscribers": 118175, "created_utc": 1690341248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don't know if anyone else was confused about the multitude of ETL tools out there.  With the help of ChatGPT I came up with this table.  It really helped turn a light bulb on for me.  It would be great if there could be a public list like this that we could keep updated.\n\n&amp;#x200B;\n\n|Product Name|Description|Specialization|\n|:-|:-|:-|\n|dbt|dbt (data build tool) is a popular open-source data transformation tool that enables data analysts and engineers to transform, analyze, and document data.|Transform|\n|Apache Airflow|Apache Airflow is an open-source platform to programmatically author, schedule, and monitor workflows. It is commonly used for orchestrating data pipelines.|Transform, Load|\n|Apache Spark|Apache Spark is an open-source distributed data processing engine that provides fast and general-purpose cluster computing for big data processing.|Transform|\n|Apache Kafka|Apache Kafka is an open-source distributed event streaming platform used for building real-time data pipelines and streaming applications.|Extract, Transform|\n|Talend|Talend is a popular data integration and data quality platform that supports data engineering, data integration, data profiling, and more.|Extract, Transform, Load|\n|Stitch|Stitch is a cloud-based data integration service that replicates data from various sources into data warehouses for analytics purposes.|Extract, Load|\n|Fivetran|Fivetran is a fully managed data integration service that continuously syncs data from source systems to data warehouses, making it easy to centralize data.|Extract, Load|\n|AWS Glue|AWS Glue is a fully managed extract, transform, and load (ETL) service provided by Amazon Web Services, making it easy to prepare and load data for analytics.|Extract, Transform, Load|\n|Google Cloud Dataflow|Google Cloud Dataflow is a fully managed service for executing Apache Beam pipelines. It supports both batch and stream processing on Google Cloud Platform.|Transform|\n|Databricks|Databricks is a unified data analytics platform that provides a collaborative workspace for data engineering and data science tasks, built on Apache Spark.\u00a0\u00a0|Transform|\n|Matillion|Matillion is a cloud-native ETL and data integration platform that simplifies the process of loading, transforming, and joining data on cloud data warehouses.|Extract, Transform, Load|\n\n^(Table) ^(formatting) ^(brought) ^(to) ^(you) ^(by) [^(ExcelToReddit)](https://xl2reddit.github.io/)", "author_fullname": "t2_j15uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List of ETL tools, short description, and their primary purpose", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15aeh6s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690398006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know if anyone else was confused about the multitude of ETL tools out there.  With the help of ChatGPT I came up with this table.  It really helped turn a light bulb on for me.  It would be great if there could be a public list like this that we could keep updated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Product Name&lt;/th&gt;\n&lt;th align=\"left\"&gt;Description&lt;/th&gt;\n&lt;th align=\"left\"&gt;Specialization&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;dbt&lt;/td&gt;\n&lt;td align=\"left\"&gt;dbt (data build tool) is a popular open-source data transformation tool that enables data analysts and engineers to transform, analyze, and document data.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Transform&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Apache Airflow&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache Airflow is an open-source platform to programmatically author, schedule, and monitor workflows. It is commonly used for orchestrating data pipelines.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Transform, Load&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Apache Spark&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache Spark is an open-source distributed data processing engine that provides fast and general-purpose cluster computing for big data processing.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Transform&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Apache Kafka&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache Kafka is an open-source distributed event streaming platform used for building real-time data pipelines and streaming applications.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Extract, Transform&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Talend&lt;/td&gt;\n&lt;td align=\"left\"&gt;Talend is a popular data integration and data quality platform that supports data engineering, data integration, data profiling, and more.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Extract, Transform, Load&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Stitch&lt;/td&gt;\n&lt;td align=\"left\"&gt;Stitch is a cloud-based data integration service that replicates data from various sources into data warehouses for analytics purposes.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Extract, Load&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Fivetran&lt;/td&gt;\n&lt;td align=\"left\"&gt;Fivetran is a fully managed data integration service that continuously syncs data from source systems to data warehouses, making it easy to centralize data.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Extract, Load&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;AWS Glue&lt;/td&gt;\n&lt;td align=\"left\"&gt;AWS Glue is a fully managed extract, transform, and load (ETL) service provided by Amazon Web Services, making it easy to prepare and load data for analytics.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Extract, Transform, Load&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Google Cloud Dataflow&lt;/td&gt;\n&lt;td align=\"left\"&gt;Google Cloud Dataflow is a fully managed service for executing Apache Beam pipelines. It supports both batch and stream processing on Google Cloud Platform.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Transform&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Databricks&lt;/td&gt;\n&lt;td align=\"left\"&gt;Databricks is a unified data analytics platform that provides a collaborative workspace for data engineering and data science tasks, built on Apache Spark.\u00a0\u00a0&lt;/td&gt;\n&lt;td align=\"left\"&gt;Transform&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Matillion&lt;/td&gt;\n&lt;td align=\"left\"&gt;Matillion is a cloud-native ETL and data integration platform that simplifies the process of loading, transforming, and joining data on cloud data warehouses.&lt;/td&gt;\n&lt;td align=\"left\"&gt;Extract, Transform, Load&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&lt;sup&gt;Table&lt;/sup&gt; &lt;sup&gt;formatting&lt;/sup&gt; &lt;sup&gt;brought&lt;/sup&gt; &lt;sup&gt;to&lt;/sup&gt; &lt;sup&gt;you&lt;/sup&gt; &lt;sup&gt;by&lt;/sup&gt; &lt;a href=\"https://xl2reddit.github.io/\"&gt;&lt;sup&gt;ExcelToReddit&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15aeh6s", "is_robot_indexable": true, "report_reasons": null, "author": "jbrune", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15aeh6s/list_of_etl_tools_short_description_and_their/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15aeh6s/list_of_etl_tools_short_description_and_their/", "subreddit_subscribers": 118175, "created_utc": 1690398006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a financial institution and they want me to create/develop a single source of truth for our data. Basically they want me to house it in one spot that has live updates so that everyone at the institution can access it and not have to worry if it's outdated or not. When this process is complete they also want me to develop a customer 360 dashboard that would also have live time updates. I have somewhat of a background in coding, data science, and analytics. I know this isn't directly up my alley but I would like to build my knowledge about this sort of thing. I have also used a little of Microsoft Azure in school but never fully tapped into it, just did the basic assignments I was given. Anyways I'm just looking for answers as to where I should start the road map or what softwares or applications would be useful for completing the task.", "author_fullname": "t2_aix6z1cs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Single Data Source and 360 Access", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a9za1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690387807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a financial institution and they want me to create/develop a single source of truth for our data. Basically they want me to house it in one spot that has live updates so that everyone at the institution can access it and not have to worry if it&amp;#39;s outdated or not. When this process is complete they also want me to develop a customer 360 dashboard that would also have live time updates. I have somewhat of a background in coding, data science, and analytics. I know this isn&amp;#39;t directly up my alley but I would like to build my knowledge about this sort of thing. I have also used a little of Microsoft Azure in school but never fully tapped into it, just did the basic assignments I was given. Anyways I&amp;#39;m just looking for answers as to where I should start the road map or what softwares or applications would be useful for completing the task.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a9za1", "is_robot_indexable": true, "report_reasons": null, "author": "OJ_Dyansty35", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a9za1/single_data_source_and_360_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a9za1/single_data_source_and_360_access/", "subreddit_subscribers": 118175, "created_utc": 1690387807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My 4-engineer team is planning to build data pipelines to do the following - curious what everyone's thoughts are on the best architecture here - thanks in advance for your thoughts:\n\n* Politely scrape public sites - then pop the results into a queue for downstream processing\n* Clean / enrich the results (entity extraction, translation, sentiment, etc.)\n* Expect around 2 million records per day through this pipeline\n* Store the results in ElasticSearch - get them here as quickly as possible, as we're building 'current events' dashboards\n* We also have scheduled jobs we are currently responsible for that we'd like to move into this setup\n* Need to run within AWS, will be tough to bring in other vendors (i.e. Astronomer, Confluent, etc.)\n\nWe don't have an infrastructure team so we're responsible for all the infrastructure we stand up. Our devs are mostly experienced in Python. Our local setups are fully containerized, hoping to keep it that way if possible.\n\nWant to prioritize:\n\n* Good local setup for development\n* Minimize infrastructure maintenance\n* Ease of monitoring and retrying / re-running failed jobs\n* Type safety between steps in data pipeline\n* Ease of finding / visualizing data flow &amp; dependencies\n* Autoscaling in Production\n* Speed of start to end of pipeline for individual records\n\nThinking of using AWS's Managed Airflow for workflow orchestration and achieving enough streaming capabilities through Sensors pointing at Redis or SQS queues... \n\nCurious if this sounds like a reasonable approach, if there's a better architecture these days, and/or if i'm off-base with all of these requirements. Thanks again", "author_fullname": "t2_e1poh23pm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideal system architecture for both workflow orchestration and streaming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a9awd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690386266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My 4-engineer team is planning to build data pipelines to do the following - curious what everyone&amp;#39;s thoughts are on the best architecture here - thanks in advance for your thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Politely scrape public sites - then pop the results into a queue for downstream processing&lt;/li&gt;\n&lt;li&gt;Clean / enrich the results (entity extraction, translation, sentiment, etc.)&lt;/li&gt;\n&lt;li&gt;Expect around 2 million records per day through this pipeline&lt;/li&gt;\n&lt;li&gt;Store the results in ElasticSearch - get them here as quickly as possible, as we&amp;#39;re building &amp;#39;current events&amp;#39; dashboards&lt;/li&gt;\n&lt;li&gt;We also have scheduled jobs we are currently responsible for that we&amp;#39;d like to move into this setup&lt;/li&gt;\n&lt;li&gt;Need to run within AWS, will be tough to bring in other vendors (i.e. Astronomer, Confluent, etc.)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We don&amp;#39;t have an infrastructure team so we&amp;#39;re responsible for all the infrastructure we stand up. Our devs are mostly experienced in Python. Our local setups are fully containerized, hoping to keep it that way if possible.&lt;/p&gt;\n\n&lt;p&gt;Want to prioritize:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Good local setup for development&lt;/li&gt;\n&lt;li&gt;Minimize infrastructure maintenance&lt;/li&gt;\n&lt;li&gt;Ease of monitoring and retrying / re-running failed jobs&lt;/li&gt;\n&lt;li&gt;Type safety between steps in data pipeline&lt;/li&gt;\n&lt;li&gt;Ease of finding / visualizing data flow &amp;amp; dependencies&lt;/li&gt;\n&lt;li&gt;Autoscaling in Production&lt;/li&gt;\n&lt;li&gt;Speed of start to end of pipeline for individual records&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thinking of using AWS&amp;#39;s Managed Airflow for workflow orchestration and achieving enough streaming capabilities through Sensors pointing at Redis or SQS queues... &lt;/p&gt;\n\n&lt;p&gt;Curious if this sounds like a reasonable approach, if there&amp;#39;s a better architecture these days, and/or if i&amp;#39;m off-base with all of these requirements. Thanks again&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a9awd", "is_robot_indexable": true, "report_reasons": null, "author": "Turbulent-Sand4889", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a9awd/ideal_system_architecture_for_both_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a9awd/ideal_system_architecture_for_both_workflow/", "subreddit_subscribers": 118175, "created_utc": 1690386266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@stefentaime\\_10958/automating-data-pipeline-deployment-on-aws-with-terraform-utilizing-lambda-glue-crawler-1621e0736edd](https://medium.com/@stefentaime_10958/automating-data-pipeline-deployment-on-aws-with-terraform-utilizing-lambda-glue-crawler-1621e0736edd)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rscsdc6fwbeb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=c13b622f69f101645a7e291eb69e12a4ec6f1556", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automating Data Pipeline Deployment on AWS with Terraform: Utilizing Lambda, Glue, Crawler, Redshift, and S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"rscsdc6fwbeb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b7390240f63e7fc31925347e463ea82c23d70ddf"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc1b8ae50c292c0a52f6b077cb283e6f1436ad2b"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7fbad17cc6e3d930427ce1f2af8f1566aa82a58"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=45d2d223fe38b1c3879849686e104ab5e4e0ed26"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4842566c3ad4bb7ae29728fc323b1c6d87ac7457"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0493d2fb3db553c807123115eda2b7e533275546"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/rscsdc6fwbeb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=c13b622f69f101645a7e291eb69e12a4ec6f1556"}, "id": "rscsdc6fwbeb1"}}, "name": "t3_15a92hh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SUgfyEh8U7PSvcscp48bmCrP8Wq4W_pOV3LyCkXik8w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1690385721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/automating-data-pipeline-deployment-on-aws-with-terraform-utilizing-lambda-glue-crawler-1621e0736edd\"&gt;https://medium.com/@stefentaime_10958/automating-data-pipeline-deployment-on-aws-with-terraform-utilizing-lambda-glue-crawler-1621e0736edd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rscsdc6fwbeb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c13b622f69f101645a7e291eb69e12a4ec6f1556\"&gt;https://preview.redd.it/rscsdc6fwbeb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c13b622f69f101645a7e291eb69e12a4ec6f1556&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?auto=webp&amp;s=612c9df6ef907f76d90b9d4010c4ec16e413bbfb", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=81db565596712608476f1d6389baba47483d75b9", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c91df118f6b3721b01e3597eb2a2560af8de79f3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a129cfb4f4362cac6dc92dcae285c641fbc3a553", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3ac9c200b7227f0f58c41dce7dcc4f0e3722d05", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=52bdb1484c86e9b958f664ffe330308ab25d3425", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/eJmNTWeV2N6NQsxEApX1mi7erCc3wcN5V5uXNhzn904.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d34bd80b3cb7d0a71f833260f048c859430d3afa", "width": 1080, "height": 607}], "variants": {}, "id": "R9spcbH1HlEC9REJjRmw2v8JazSeB8lYL6yfZwSZlzM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15a92hh", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a92hh/automating_data_pipeline_deployment_on_aws_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a92hh/automating_data_pipeline_deployment_on_aws_with/", "subreddit_subscribers": 118175, "created_utc": 1690385721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm assisting a non-profit in a food supply chain project and wanting to understand the cheapest, most efficient way to track the lat/longs of their trucks over time, including real-time. Only about \\~10 trucks and we don't need anything fancy. Just truck+datetime+lat+long.\n\nWhat hardware/tools would be cheapest to obtain this type of information? Options I've considered, but each has their downsides:\n\n1. My mind went to Airtags first for simplicity purposes, but accessing history seems possibly achievable, but frustrating.\n2. Verizon Connect Fleet Tracking - Ability to access historical data, but I didn't see lat/long in their video. Also probably too expensive, but they're too vague on pricing on their site.\n3. A quick \"GPS Fleet Tracking\" search yields a ton of different company offerings, but many seem like overkill (and would likely price as such). I'm looking for the simplest offering, not the most robust.\n\nFor what it's worth, I'm relatively new to data engineering and brand new to ingestion of lat/longs, so apologies if this is a stupid question!", "author_fullname": "t2_pmps7fj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to ingest lat/long data via GPS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a8yck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690385459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m assisting a non-profit in a food supply chain project and wanting to understand the cheapest, most efficient way to track the lat/longs of their trucks over time, including real-time. Only about ~10 trucks and we don&amp;#39;t need anything fancy. Just truck+datetime+lat+long.&lt;/p&gt;\n\n&lt;p&gt;What hardware/tools would be cheapest to obtain this type of information? Options I&amp;#39;ve considered, but each has their downsides:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;My mind went to Airtags first for simplicity purposes, but accessing history seems possibly achievable, but frustrating.&lt;/li&gt;\n&lt;li&gt;Verizon Connect Fleet Tracking - Ability to access historical data, but I didn&amp;#39;t see lat/long in their video. Also probably too expensive, but they&amp;#39;re too vague on pricing on their site.&lt;/li&gt;\n&lt;li&gt;A quick &amp;quot;GPS Fleet Tracking&amp;quot; search yields a ton of different company offerings, but many seem like overkill (and would likely price as such). I&amp;#39;m looking for the simplest offering, not the most robust.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For what it&amp;#39;s worth, I&amp;#39;m relatively new to data engineering and brand new to ingestion of lat/longs, so apologies if this is a stupid question!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a8yck", "is_robot_indexable": true, "report_reasons": null, "author": "hornfan87", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a8yck/easiest_way_to_ingest_latlong_data_via_gps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a8yck/easiest_way_to_ingest_latlong_data_via_gps/", "subreddit_subscribers": 118175, "created_utc": 1690385459.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}