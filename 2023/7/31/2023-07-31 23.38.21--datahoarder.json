{"kind": "Listing", "data": {"after": "t3_15ern8u", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7me91nis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Disney Discontinues Physical Media Releases for an Entire Continent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15egxgg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 236, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 236, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pPWRH7l2SiwWOt_WtX1q7VBtV5fp_A_BlO3GX-niWrw.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690811788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "collider.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://collider.com/disney-physical-media-release-discontinue-australia/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?auto=webp&amp;s=00396370454858c269d64c9f04a799af6cc12337", "width": 1400, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbf9a460ed4d3e8528199f7839881801330ea37b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a30f76807415eaac93326ef4c5938dd6cba0e84f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ea61c12d4806c312eafdd182031fef399d395e0", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=107342f0b6fca8ff50e95fc236c8556e7d379f0f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a340719fff0f32833486b2278ca36bfd78e6e034", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9cdcf18f7321a0dba51232d7879ceb6b424ea810", "width": 1080, "height": 540}], "variants": {}, "id": "WEeO1MWsnVDW93KokE5tqFv-yRkh-HygbEtnoJBpdcs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "64TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15egxgg", "is_robot_indexable": true, "report_reasons": null, "author": "WindowlessBasement", "discussion_type": null, "num_comments": 64, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15egxgg/disney_discontinues_physical_media_releases_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://collider.com/disney-physical-media-release-discontinue-australia/", "subreddit_subscribers": 695617, "created_utc": 1690811788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My main problem is organization.\n\nI'm constantly re-writing vocabulary (that's already been digitized) in my notebook and notecards because multiple copies of the same thing is great and I keep on finding more efficient ways to create a comprehensible and effective language class, which is exactly what's saving my language, but I feel like I'm drowning in destructible material.\n\nI have enough money for flash drives, and I already have a printer/scanner specifically for this purpose, so making copies of stuff isn't a problem.", "author_fullname": "t2_2p5226u2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have 30ish notecards, 5 half-filled notebooks, and literally hundreds of loose paper with my critically endangered language and cultural practices written down...and on my computer. How should I digitize it efficiently? How should I organize it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e18mf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 168, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 168, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690763249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My main problem is organization.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m constantly re-writing vocabulary (that&amp;#39;s already been digitized) in my notebook and notecards because multiple copies of the same thing is great and I keep on finding more efficient ways to create a comprehensible and effective language class, which is exactly what&amp;#39;s saving my language, but I feel like I&amp;#39;m drowning in destructible material.&lt;/p&gt;\n\n&lt;p&gt;I have enough money for flash drives, and I already have a printer/scanner specifically for this purpose, so making copies of stuff isn&amp;#39;t a problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e18mf", "is_robot_indexable": true, "report_reasons": null, "author": "Starfire-Galaxy", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e18mf/i_have_30ish_notecards_5_halffilled_notebooks_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e18mf/i_have_30ish_notecards_5_halffilled_notebooks_and/", "subreddit_subscribers": 695617, "created_utc": 1690763249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "At work I receive temperature date logger devices.  They are **single use only**, unless you can flash the firmware.\n\n~~But they act as a thumbdrive where it outputs the temperature report once inserted in a PC, and stop running.  However it only has 400kb available space.~~\n\nI have a whole box full of them, and unless I find a use for them, they're going to a recycling centre(CR battery inside, PCB, chip).\n\n\nEdit: https://www.reddit.com/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/ju7exzw?utm_source=share&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_term=1&amp;utm_content=2\n\nThey can't be used as flash drives.", "author_fullname": "t2_kyyvuhkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any use to Flash Drives that can only store 400kb?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e9w98", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690824090.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690791184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At work I receive temperature date logger devices.  They are &lt;strong&gt;single use only&lt;/strong&gt;, unless you can flash the firmware.&lt;/p&gt;\n\n&lt;p&gt;&lt;del&gt;But they act as a thumbdrive where it outputs the temperature report once inserted in a PC, and stop running.  However it only has 400kb available space.&lt;/del&gt;&lt;/p&gt;\n\n&lt;p&gt;I have a whole box full of them, and unless I find a use for them, they&amp;#39;re going to a recycling centre(CR battery inside, PCB, chip).&lt;/p&gt;\n\n&lt;p&gt;Edit: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/ju7exzw?utm_source=share&amp;amp;utm_medium=android_app&amp;amp;utm_name=androidcss&amp;amp;utm_term=1&amp;amp;utm_content=2\"&gt;https://www.reddit.com/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/ju7exzw?utm_source=share&amp;amp;utm_medium=android_app&amp;amp;utm_name=androidcss&amp;amp;utm_term=1&amp;amp;utm_content=2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They can&amp;#39;t be used as flash drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e9w98", "is_robot_indexable": true, "report_reasons": null, "author": "VlaamsBelanger", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/", "subreddit_subscribers": 695617, "created_utc": 1690791184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got the screws from Google Drive today and wanted to switch to dropbox after seeing on here its a good alternative. I signed up and paid after being told by a rep I could request more space. I was happy to start so I contacted support and was told they have a new limit that just started today that they will ONLY be adding 1TB / month for storage upgrade requests. So this is a warning to anyone thinking of using them. This rule is not advertised at all on the site so I wanted to warn you guys.  \n\n[Here is the chat transcript](https://i.imgur.com/syhmDa7.png)  \n\n\nI also called them and they confirmed this new rule. Does anyone else have any other ideas on where we can go?", "author_fullname": "t2_xxtj8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropbox limits \"as much space as you need\" to 1TB a month", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eoyi4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690830420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got the screws from Google Drive today and wanted to switch to dropbox after seeing on here its a good alternative. I signed up and paid after being told by a rep I could request more space. I was happy to start so I contacted support and was told they have a new limit that just started today that they will ONLY be adding 1TB / month for storage upgrade requests. So this is a warning to anyone thinking of using them. This rule is not advertised at all on the site so I wanted to warn you guys.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.imgur.com/syhmDa7.png\"&gt;Here is the chat transcript&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I also called them and they confirmed this new rule. Does anyone else have any other ideas on where we can go?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Qhwd-CqQpGZ7QDkhXJXkLvZSeDsfICIbzB3eIFonvNo.png?auto=webp&amp;s=303d19b2f7be21af7a2e852d260943f839f818a8", "width": 1050, "height": 288}, "resolutions": [{"url": "https://external-preview.redd.it/Qhwd-CqQpGZ7QDkhXJXkLvZSeDsfICIbzB3eIFonvNo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=174c9ee798f643902b98a377719dda31a5de54b0", "width": 108, "height": 29}, {"url": "https://external-preview.redd.it/Qhwd-CqQpGZ7QDkhXJXkLvZSeDsfICIbzB3eIFonvNo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=aaf8545a9204d9a925533e8ea00e50fd1a1a7d0f", "width": 216, "height": 59}, {"url": "https://external-preview.redd.it/Qhwd-CqQpGZ7QDkhXJXkLvZSeDsfICIbzB3eIFonvNo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a441ef6252c15843ab23828b5b20b0f432118776", "width": 320, "height": 87}, {"url": "https://external-preview.redd.it/Qhwd-CqQpGZ7QDkhXJXkLvZSeDsfICIbzB3eIFonvNo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=32ae9c35b4dcc25083068c48e77d11dbbb7cebc3", "width": 640, "height": 175}, {"url": "https://external-preview.redd.it/Qhwd-CqQpGZ7QDkhXJXkLvZSeDsfICIbzB3eIFonvNo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1c4c9703286eb7663d1b21af23044bb6e536304", "width": 960, "height": 263}], "variants": {}, "id": "pfR7-8W2iY2-7h8IAtdcqYMuHoBI5Syi1MBqA5z1dhA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15eoyi4", "is_robot_indexable": true, "report_reasons": null, "author": "MattDeezly", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eoyi4/dropbox_limits_as_much_space_as_you_need_to_1tb_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eoyi4/dropbox_limits_as_much_space_as_you_need_to_1tb_a/", "subreddit_subscribers": 695617, "created_utc": 1690830420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello friends! I\u2019m a cinematographer, and generate a reasonable amount of data. I shoot advertising so most shoots only tend to be 1-4 days, and within that time I normally generate between 500gb - 4tb. I have 3 general needs for my data storage. \n\n1. Fast access to about 4tb of data of a time to edit projects. This is critical. \n2. Bulletproof back-up of working files until project is completed. This is critical. \n3. Long term storage of projects. The clients don\u2019t care about this (after approx. 6 months from delivery), but I like having an archive of my work, both personally (I made that!) and there is also a professional element (for pitching new jobs, showreel, etc).\n\nWhat I have currently been doing is using a QNAP NAS (TVS-1282T3) connected to a Mac Pro via 10gbe to edit off and store files. It\u2019s 84tb raw and about 50tb after raid stuff etc. I simultaneously back footage up to a couple of 3.5\u201d drives too, one of which gets kept in the office, and one comes home with me. I have a rolling system where I bump the oldest job off the nas to make room for the new job. \n\nI\u2019m worried about longevity of storage and general cost if I decide to upgrade my camera, which will generate a lot more data to store. I\u2019ve been spitballing:\n\n- some sort of SSD type of raid array to edit off. Approx 8tb, and I could have 2 or 3 for redundancy. Double points if I could get some sort of online back-up from an ssd at the office to an identical ssd at home.\n- LTO reader in the office, so once a project is completed, it goes on 3x tapes.\n\nThis would allow me to have quick storage to edit off, and cheaper, more stable storage to handle my archive which is rarely accessed by me or my clients. \n\nI\u2019d ideally want something mac-compatible. I\u2019ve got 2 MacBook pros, 2 iPad pros, a Mac Pro in the office, and a Mac mini at home. \n\nSorry for the wall of text. I\u2019m wondering if I\u2019m missing something or if anyone had an elegant solution. Thanks so much in advance!", "author_fullname": "t2_4o1koz5z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A few questions from a lost cinematographer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e4xf9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690774153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends! I\u2019m a cinematographer, and generate a reasonable amount of data. I shoot advertising so most shoots only tend to be 1-4 days, and within that time I normally generate between 500gb - 4tb. I have 3 general needs for my data storage. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Fast access to about 4tb of data of a time to edit projects. This is critical. &lt;/li&gt;\n&lt;li&gt;Bulletproof back-up of working files until project is completed. This is critical. &lt;/li&gt;\n&lt;li&gt;Long term storage of projects. The clients don\u2019t care about this (after approx. 6 months from delivery), but I like having an archive of my work, both personally (I made that!) and there is also a professional element (for pitching new jobs, showreel, etc).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What I have currently been doing is using a QNAP NAS (TVS-1282T3) connected to a Mac Pro via 10gbe to edit off and store files. It\u2019s 84tb raw and about 50tb after raid stuff etc. I simultaneously back footage up to a couple of 3.5\u201d drives too, one of which gets kept in the office, and one comes home with me. I have a rolling system where I bump the oldest job off the nas to make room for the new job. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m worried about longevity of storage and general cost if I decide to upgrade my camera, which will generate a lot more data to store. I\u2019ve been spitballing:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;some sort of SSD type of raid array to edit off. Approx 8tb, and I could have 2 or 3 for redundancy. Double points if I could get some sort of online back-up from an ssd at the office to an identical ssd at home.&lt;/li&gt;\n&lt;li&gt;LTO reader in the office, so once a project is completed, it goes on 3x tapes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This would allow me to have quick storage to edit off, and cheaper, more stable storage to handle my archive which is rarely accessed by me or my clients. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d ideally want something mac-compatible. I\u2019ve got 2 MacBook pros, 2 iPad pros, a Mac Pro in the office, and a Mac mini at home. &lt;/p&gt;\n\n&lt;p&gt;Sorry for the wall of text. I\u2019m wondering if I\u2019m missing something or if anyone had an elegant solution. Thanks so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e4xf9", "is_robot_indexable": true, "report_reasons": null, "author": "LurkingAlter", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e4xf9/a_few_questions_from_a_lost_cinematographer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e4xf9/a_few_questions_from_a_lost_cinematographer/", "subreddit_subscribers": 695617, "created_utc": 1690774153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My mother unfortunately passed away recently and she had acquired (and kept in storage) 4-5 different MacBook pros, right back to the ones with the hinge design.  \nI don't immediately need access to the data in any of them, Still; I thought it would be cool if there were a simple way to archive/mothball their contents onto (preferably) a single drive called 'mom' or something that was super easy to search and that way if I ever want to find an email/reference number/legal doc/photo years into the future its easy to do so. Then I can donate or recycle the Macbooks.  \nThanks for your time. ", "author_fullname": "t2_9yy7pro6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving Macs of mom who's passed away", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eh7d6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690812435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My mother unfortunately passed away recently and she had acquired (and kept in storage) 4-5 different MacBook pros, right back to the ones with the hinge design.&lt;br/&gt;\nI don&amp;#39;t immediately need access to the data in any of them, Still; I thought it would be cool if there were a simple way to archive/mothball their contents onto (preferably) a single drive called &amp;#39;mom&amp;#39; or something that was super easy to search and that way if I ever want to find an email/reference number/legal doc/photo years into the future its easy to do so. Then I can donate or recycle the Macbooks.&lt;br/&gt;\nThanks for your time. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eh7d6", "is_robot_indexable": true, "report_reasons": null, "author": "herbertthe3rd", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eh7d6/archiving_macs_of_mom_whos_passed_away/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eh7d6/archiving_macs_of_mom_whos_passed_away/", "subreddit_subscribers": 695617, "created_utc": 1690812435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for an extremely durable SSD for a special workload (20TB written per day) In short, I'll need a very high TBW rating. So far I've only found the 2TB DC600M at 3504TBW. Does anyone know more solutions like these?", "author_fullname": "t2_gkm00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Highest TBW SSD possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ecfvn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690799602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for an extremely durable SSD for a special workload (20TB written per day) In short, I&amp;#39;ll need a very high TBW rating. So far I&amp;#39;ve only found the 2TB DC600M at 3504TBW. Does anyone know more solutions like these?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ecfvn", "is_robot_indexable": true, "report_reasons": null, "author": "hambopro", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ecfvn/highest_tbw_ssd_possible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ecfvn/highest_tbw_ssd_possible/", "subreddit_subscribers": 695617, "created_utc": 1690799602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_mgptr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Throwing my hat in the ring for another web-scraper-based Reddit downloader. I wanted a more integrated way to use it so I developed a simple chrome extension to grab links to download.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15ep601", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RC0Y0RoeeO_iQx2xInFdxMsfy0_lNlnWT2W1b7c65_Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690830880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/eric-hamilton/reddit_post_downloader", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?auto=webp&amp;s=d5965d25dff3c66da06dfc3864153d6697eb316e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9400dc036d202f0f8c460c437cecf35e7e48b599", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c3c53ab1e958b94dce1178ddff7025a78385ad6", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1a9b1d0711349fd591590053488a14e601fd8e15", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a8eb5e5f2797796de661cfc74b7780cd3da2f4c7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=982ad621638837f6e425e3159a4c9a0c0d297fd2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c41c42cc94a524e8e917cf4de78dff137ef3bd24", "width": 1080, "height": 540}], "variants": {}, "id": "dJicjODPL_r5MeJsg6paH4QSIu18fJDbLEfpB_2iDe0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ep601", "is_robot_indexable": true, "report_reasons": null, "author": "AirHamyes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ep601/throwing_my_hat_in_the_ring_for_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/eric-hamilton/reddit_post_downloader", "subreddit_subscribers": 695617, "created_utc": 1690830880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just got off the phone with my point of contact at Dropbox, and he informed me that all new users with the advanced plan will be limited to 1 TB of initial storage. Afterward, they will receive only 1 TB of additional storage per month. However, all current users with their data already online will be able to keep their existing storage capacity. So, everyone who is already using Dropbox will be locked into the amount they have uploaded.\n\nHe mentioned that they had a meeting about this plan earlier this morning. The reason they are implementing it is that their servers are getting hit hard due to the significant influx of users switching over to Dropbox. At this point, they are unsure how to manage the increased demand and are taking this tentative step to cope with the situation.", "author_fullname": "t2_cw9v5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropbox Overwhelmed by User Influx", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eqq7e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690834452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just got off the phone with my point of contact at Dropbox, and he informed me that all new users with the advanced plan will be limited to 1 TB of initial storage. Afterward, they will receive only 1 TB of additional storage per month. However, all current users with their data already online will be able to keep their existing storage capacity. So, everyone who is already using Dropbox will be locked into the amount they have uploaded.&lt;/p&gt;\n\n&lt;p&gt;He mentioned that they had a meeting about this plan earlier this morning. The reason they are implementing it is that their servers are getting hit hard due to the significant influx of users switching over to Dropbox. At this point, they are unsure how to manage the increased demand and are taking this tentative step to cope with the situation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eqq7e", "is_robot_indexable": true, "report_reasons": null, "author": "vladen32", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eqq7e/dropbox_overwhelmed_by_user_influx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eqq7e/dropbox_overwhelmed_by_user_influx/", "subreddit_subscribers": 695617, "created_utc": 1690834452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm starting now to organize my data and I'm curious how you all organize you huge amounts of data. My biggest problem is how can I find the files without searching for hours? Would a SQL table with the data typ and name and a link to the path in the folder make sense? \nHow do you solve that problem?", "author_fullname": "t2_vg8a4605", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to organize my few TBs of data in a nice way", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15esixj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690838602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m starting now to organize my data and I&amp;#39;m curious how you all organize you huge amounts of data. My biggest problem is how can I find the files without searching for hours? Would a SQL table with the data typ and name and a link to the path in the folder make sense? \nHow do you solve that problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15esixj", "is_robot_indexable": true, "report_reasons": null, "author": "elPr0fess0r96", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15esixj/i_want_to_organize_my_few_tbs_of_data_in_a_nice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15esixj/i_want_to_organize_my_few_tbs_of_data_in_a_nice/", "subreddit_subscribers": 695617, "created_utc": 1690838602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Device: MacBook Pro M1 Pro. Have Parallels for Windows if needed. a 1 TB HDD, a 2 TB HDD, 1 TB SSD, and a 5 TB HDD  \n\n\nI have a few hard drives that I hoard data in, they aren't constantly connected into my laptop, so I don't have immediate access to them whenever and wherever. I want to create an explorable interface (like an html index of directories maybe?) of all the files in the folders and subfolders in the drive. So that i don't need to connect the hard drive each time I just wanna check the contents of the files. Ideally, I'd want the file size to be indexed too, and not just the names of the files. And yes, it is all just TBs of porn, so if I get maybe video duration and maybe even resolution indexed, it'd be so great, but I understand that seems hard maybe.   \nI know how to create a filelist.txt from the terminal window on the mac. but i dont know of ways to take that index and make into an html GUI. I'd also maybe want it to update if and when I rename/delete/add files.   \n\n\nIs there any tool, or script that I could write, that lets me do all this? The update part is more important to me than the video duration and stuff. I'm new to data hoarding so I don't have too much technical know how of various tools and stuff yet.   \n", "author_fullname": "t2_6am88083", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Indexing and updating an index of all files and folders on a harddrive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e7ge1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690782669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Device: MacBook Pro M1 Pro. Have Parallels for Windows if needed. a 1 TB HDD, a 2 TB HDD, 1 TB SSD, and a 5 TB HDD  &lt;/p&gt;\n\n&lt;p&gt;I have a few hard drives that I hoard data in, they aren&amp;#39;t constantly connected into my laptop, so I don&amp;#39;t have immediate access to them whenever and wherever. I want to create an explorable interface (like an html index of directories maybe?) of all the files in the folders and subfolders in the drive. So that i don&amp;#39;t need to connect the hard drive each time I just wanna check the contents of the files. Ideally, I&amp;#39;d want the file size to be indexed too, and not just the names of the files. And yes, it is all just TBs of porn, so if I get maybe video duration and maybe even resolution indexed, it&amp;#39;d be so great, but I understand that seems hard maybe.&lt;br/&gt;\nI know how to create a filelist.txt from the terminal window on the mac. but i dont know of ways to take that index and make into an html GUI. I&amp;#39;d also maybe want it to update if and when I rename/delete/add files.   &lt;/p&gt;\n\n&lt;p&gt;Is there any tool, or script that I could write, that lets me do all this? The update part is more important to me than the video duration and stuff. I&amp;#39;m new to data hoarding so I don&amp;#39;t have too much technical know how of various tools and stuff yet.   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e7ge1", "is_robot_indexable": true, "report_reasons": null, "author": "BABASS222", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e7ge1/indexing_and_updating_an_index_of_all_files_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e7ge1/indexing_and_updating_an_index_of_all_files_and/", "subreddit_subscribers": 695617, "created_utc": 1690782669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm using WinX DVD Copy Pro to copy the contents of a DVD as MPEG files. This process saves each chapter as a separate MPEG file.\n\nWhat I'd like to do is remove and/or reorder certain chapters and then \"stitch\" the chapters back together so to allow for a continuous viewing experience. As it stands right now, each chapter is played as a standalone file and I haven't found a way to play seamlessly play one chapter after another (I'm using the genero Windows media player).", "author_fullname": "t2_1kj5jtmx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help extracting and then merging DVD chapters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eswh4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690839467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using WinX DVD Copy Pro to copy the contents of a DVD as MPEG files. This process saves each chapter as a separate MPEG file.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;d like to do is remove and/or reorder certain chapters and then &amp;quot;stitch&amp;quot; the chapters back together so to allow for a continuous viewing experience. As it stands right now, each chapter is played as a standalone file and I haven&amp;#39;t found a way to play seamlessly play one chapter after another (I&amp;#39;m using the genero Windows media player).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eswh4", "is_robot_indexable": true, "report_reasons": null, "author": "dxh13", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eswh4/help_extracting_and_then_merging_dvd_chapters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eswh4/help_extracting_and_then_merging_dvd_chapters/", "subreddit_subscribers": 695617, "created_utc": 1690839467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I set up a parity storage pool using 4 drives. Later find out I'm probably losing space usage efficiency because it defaults to 3 drives even though it has 4. I recently popped in 4 20tb drives through hdd dock and usb connected. Then find out that I can't fully make the new space expanded on the original space because column size limits (to about 31tb).\n\nA few questions maybe you can help with.\n\n1) is it possibly to fix storage pool to accommodate all 8 of my drives (4 *8tb 4* 20tb)?\n2) should I make 2 pools anyway, one with 5 disks a second with 3?\n3) should I/do I need to redo the entire storage space (I thought expanding it would work as expected, easy as plug and add.\n4) shoukd I use a different solution like actual raid or different software raid, or migrate to something like synology (which id rather not as I literally possess all the hardware means aside from a raid card (I'm using dell poweredge t310 which I think has built in raid functions of some kind)\n\n5 please explain why powershell is better than the gui. \n\nThanks in advance for all you can provide.", "author_fullname": "t2_6g7sd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage spaces drive configuration questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eswgo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690839467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I set up a parity storage pool using 4 drives. Later find out I&amp;#39;m probably losing space usage efficiency because it defaults to 3 drives even though it has 4. I recently popped in 4 20tb drives through hdd dock and usb connected. Then find out that I can&amp;#39;t fully make the new space expanded on the original space because column size limits (to about 31tb).&lt;/p&gt;\n\n&lt;p&gt;A few questions maybe you can help with.&lt;/p&gt;\n\n&lt;p&gt;1) is it possibly to fix storage pool to accommodate all 8 of my drives (4 &lt;em&gt;8tb 4&lt;/em&gt; 20tb)?\n2) should I make 2 pools anyway, one with 5 disks a second with 3?\n3) should I/do I need to redo the entire storage space (I thought expanding it would work as expected, easy as plug and add.\n4) shoukd I use a different solution like actual raid or different software raid, or migrate to something like synology (which id rather not as I literally possess all the hardware means aside from a raid card (I&amp;#39;m using dell poweredge t310 which I think has built in raid functions of some kind)&lt;/p&gt;\n\n&lt;p&gt;5 please explain why powershell is better than the gui. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for all you can provide.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eswgo", "is_robot_indexable": true, "report_reasons": null, "author": "peacemaker2121", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eswgo/storage_spaces_drive_configuration_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eswgo/storage_spaces_drive_configuration_questions/", "subreddit_subscribers": 695617, "created_utc": 1690839467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello to everyone!\n\nI apologize for the dumb question, but I am a complete noob in the field of controllers. I am writing to ask help in choosing a controller that allows to run in IT mode (which, from what I have understood, means NON raid) capable of 8 internal sata connection (2 SAS).  \nI tried looking at the guide in the wiki, and searching in old posts, but I am not finding boards (also considering the ones used on ebay) at a reasonable price.\n\nI want to ask two things:\n\n* considering for example [this one on ebay](https://www.ebay.it/itm/142033556446), has not written \"LSI\" on the board. Is it a problem? [This one](https://amzn.eu/d/2z0ekW5) should be the same one on amazon, which has \"LSI\" brand showind on the board. Should I somehow \"trust\" more the second one for whatever reason?\n* Is that model (LSI SAS 9211-8i) capable of running in a \"non raid\" mode? in case it is, how difficult is to flash it to run in this mode?\n\nAnd, last but not least, if you have any other controller suggestion, it is welcome!!\n\nThanks in advance!", "author_fullname": "t2_3hwuhm84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAS non raid help needed by a noob!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15esvzx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690839435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello to everyone!&lt;/p&gt;\n\n&lt;p&gt;I apologize for the dumb question, but I am a complete noob in the field of controllers. I am writing to ask help in choosing a controller that allows to run in IT mode (which, from what I have understood, means NON raid) capable of 8 internal sata connection (2 SAS).&lt;br/&gt;\nI tried looking at the guide in the wiki, and searching in old posts, but I am not finding boards (also considering the ones used on ebay) at a reasonable price.&lt;/p&gt;\n\n&lt;p&gt;I want to ask two things:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;considering for example &lt;a href=\"https://www.ebay.it/itm/142033556446\"&gt;this one on ebay&lt;/a&gt;, has not written &amp;quot;LSI&amp;quot; on the board. Is it a problem? &lt;a href=\"https://amzn.eu/d/2z0ekW5\"&gt;This one&lt;/a&gt; should be the same one on amazon, which has &amp;quot;LSI&amp;quot; brand showind on the board. Should I somehow &amp;quot;trust&amp;quot; more the second one for whatever reason?&lt;/li&gt;\n&lt;li&gt;Is that model (LSI SAS 9211-8i) capable of running in a &amp;quot;non raid&amp;quot; mode? in case it is, how difficult is to flash it to run in this mode?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And, last but not least, if you have any other controller suggestion, it is welcome!!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/G220cys7jC_I4fPueVN9fYg80rx4zZcGlP9v2JLAXNc.jpg?auto=webp&amp;s=1dcb09edd4b0f63ee7e9dfc4019fea896959a4c6", "width": 500, "height": 446}, "resolutions": [{"url": "https://external-preview.redd.it/G220cys7jC_I4fPueVN9fYg80rx4zZcGlP9v2JLAXNc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c6683d45f93bc0008fc5d1bc99694d728808bb8", "width": 108, "height": 96}, {"url": "https://external-preview.redd.it/G220cys7jC_I4fPueVN9fYg80rx4zZcGlP9v2JLAXNc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df8ca1499e19a6a2bdb748463dcadb66d4b1a86f", "width": 216, "height": 192}, {"url": "https://external-preview.redd.it/G220cys7jC_I4fPueVN9fYg80rx4zZcGlP9v2JLAXNc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b39ec64a724124d69a37c82bbae0cc9875770999", "width": 320, "height": 285}], "variants": {}, "id": "z7atrJOEcpXG5npbIoODYr0ojbewMGpRJwBMYS9yIbQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15esvzx", "is_robot_indexable": true, "report_reasons": null, "author": "Landomix", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15esvzx/sas_non_raid_help_needed_by_a_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15esvzx/sas_non_raid_help_needed_by_a_noob/", "subreddit_subscribers": 695617, "created_utc": 1690839435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I\u2019m doing a Full Restore in Dashboard, but after I started the process, my device seems to stuck at 0%, and when I try to refresh the Dashboard on my webpage, it was not responding. Its been 3 days, nothing is happening, I can\u2019t access my device through Dashboard or any other means, the device seems to freeze indefinitely.\n\nIt seems I have no choice but to power it off, will this action brick the device?", "author_fullname": "t2_2v9ngucp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help, my WD MYCloud Mirror Gen2 freezes (not responding) during the process of Full Restore, will turning it off brick it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15en9cu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690826497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m doing a Full Restore in Dashboard, but after I started the process, my device seems to stuck at 0%, and when I try to refresh the Dashboard on my webpage, it was not responding. Its been 3 days, nothing is happening, I can\u2019t access my device through Dashboard or any other means, the device seems to freeze indefinitely.&lt;/p&gt;\n\n&lt;p&gt;It seems I have no choice but to power it off, will this action brick the device?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15en9cu", "is_robot_indexable": true, "report_reasons": null, "author": "Starforce2005", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15en9cu/i_need_help_my_wd_mycloud_mirror_gen2_freezes_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15en9cu/i_need_help_my_wd_mycloud_mirror_gen2_freezes_not/", "subreddit_subscribers": 695617, "created_utc": 1690826497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, \n\nI'm currently in the progress of digitizing all of my old cd's/dvd's with pictures from back when I was a kid. \n\nBut some of the disks are a video (in PowerPoint you can export to MP4) of a slideshow (PowerPoint slideshow with effects between images) \n\nAre there any tools you guys know that export the images.\n\nEx if an image if the same image is for 1 second, it knows that it is a picture and not a transition", "author_fullname": "t2_yl2zp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tools of extracting images from a slideshow video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15en4xj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690827426.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690826223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently in the progress of digitizing all of my old cd&amp;#39;s/dvd&amp;#39;s with pictures from back when I was a kid. &lt;/p&gt;\n\n&lt;p&gt;But some of the disks are a video (in PowerPoint you can export to MP4) of a slideshow (PowerPoint slideshow with effects between images) &lt;/p&gt;\n\n&lt;p&gt;Are there any tools you guys know that export the images.&lt;/p&gt;\n\n&lt;p&gt;Ex if an image if the same image is for 1 second, it knows that it is a picture and not a transition&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15en4xj", "is_robot_indexable": true, "report_reasons": null, "author": "lodebakker", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15en4xj/any_tools_of_extracting_images_from_a_slideshow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15en4xj/any_tools_of_extracting_images_from_a_slideshow/", "subreddit_subscribers": 695617, "created_utc": 1690826223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I want to start storing my data on an external hard drive using the 3-2-1 method. I don't actually have that much data yet, only around 100-200GB in photos and documents. I've been looking for the cheapest per TB options, but the more reputable brands only have 1TB and up options, and every product I can find online seems to have loads of negative reviews of people saying they don't work. What should I do?\n\n I'm on a budget, so am open to other options e.g. discs if these would be more long-term (although I don't own a disc drive).\nI also don't want to pay for cloud storage as an alternative.", "author_fullname": "t2_4lcrkr37", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low capacity HDD/ SSD options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15em9ch", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690824224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I want to start storing my data on an external hard drive using the 3-2-1 method. I don&amp;#39;t actually have that much data yet, only around 100-200GB in photos and documents. I&amp;#39;ve been looking for the cheapest per TB options, but the more reputable brands only have 1TB and up options, and every product I can find online seems to have loads of negative reviews of people saying they don&amp;#39;t work. What should I do?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on a budget, so am open to other options e.g. discs if these would be more long-term (although I don&amp;#39;t own a disc drive).\nI also don&amp;#39;t want to pay for cloud storage as an alternative.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15em9ch", "is_robot_indexable": true, "report_reasons": null, "author": "komorebi1998", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15em9ch/low_capacity_hdd_ssd_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15em9ch/low_capacity_hdd_ssd_options/", "subreddit_subscribers": 695617, "created_utc": 1690824224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there! Which would be the best professional scanners to digitize A4 documents on folders (like [this](https://shop.prociechi.it/wp-content/uploads/2015/06/A130_watermark.png)),  but also plain single documents, and have features, (optional but would  be of help), such as renaming, OCR, compressing file size, optimize  quality, centering/align the content and you name it? (Occasionally it would be used to scan A3)  \n\n\nBrowsing the internet, I saw something like [this](https://www.amazon.it/CZUR-ET24-Professionale-Generazione-Riconoscimento/dp/B0B8MM3SFF) ", "author_fullname": "t2_2i2lwlb2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A4 Office Folder Document Scanner: which would be a good pick?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15elvvk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690823347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! Which would be the best professional scanners to digitize A4 documents on folders (like &lt;a href=\"https://shop.prociechi.it/wp-content/uploads/2015/06/A130_watermark.png\"&gt;this&lt;/a&gt;),  but also plain single documents, and have features, (optional but would  be of help), such as renaming, OCR, compressing file size, optimize  quality, centering/align the content and you name it? (Occasionally it would be used to scan A3)  &lt;/p&gt;\n\n&lt;p&gt;Browsing the internet, I saw something like &lt;a href=\"https://www.amazon.it/CZUR-ET24-Professionale-Generazione-Riconoscimento/dp/B0B8MM3SFF\"&gt;this&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UxPFIA2wtQ2AjDw6R4LsYulluciB1DpDFAEsab4HvIw.png?auto=webp&amp;s=371b352945b81163657d00d171420adee09e65e2", "width": 640, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/UxPFIA2wtQ2AjDw6R4LsYulluciB1DpDFAEsab4HvIw.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6c1265d8c79158bf4f3ec09571fb7c776d8bb26e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/UxPFIA2wtQ2AjDw6R4LsYulluciB1DpDFAEsab4HvIw.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ceb3285c4e3f785049b9e3c1cffcbad396214942", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/UxPFIA2wtQ2AjDw6R4LsYulluciB1DpDFAEsab4HvIw.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f8d46c0f4b8207574eb1dce5dc0f46dee2e93a1", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/UxPFIA2wtQ2AjDw6R4LsYulluciB1DpDFAEsab4HvIw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b3503740207747d7413b5a332d27ab93cbb99fd2", "width": 640, "height": 480}], "variants": {}, "id": "A6RS-8PrKj4w1ePruc5VaMsGJT-HV2j7DUaBKmlHupk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15elvvk", "is_robot_indexable": true, "report_reasons": null, "author": "crepuscopoli", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15elvvk/a4_office_folder_document_scanner_which_would_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15elvvk/a4_office_folder_document_scanner_which_would_be/", "subreddit_subscribers": 695617, "created_utc": 1690823347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone! I have a PC that I want to convert into a NAS. I bought 3x6TB HDDs to create a RAID 5 system. My question to yall is this, in the future I want to be able to setup another NAS at a friend's house to backup my files for ultimate redundancy/safeguard of files, what would be your recommendation for NAS programs? Would I be able to use Synology as my NAS program or does Synology only work with Synology NAS boxes?", "author_fullname": "t2_a5x4u6bj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DIY NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eljoy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690822563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I have a PC that I want to convert into a NAS. I bought 3x6TB HDDs to create a RAID 5 system. My question to yall is this, in the future I want to be able to setup another NAS at a friend&amp;#39;s house to backup my files for ultimate redundancy/safeguard of files, what would be your recommendation for NAS programs? Would I be able to use Synology as my NAS program or does Synology only work with Synology NAS boxes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eljoy", "is_robot_indexable": true, "report_reasons": null, "author": "21stCenturyRetard", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eljoy/diy_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eljoy/diy_nas/", "subreddit_subscribers": 695617, "created_utc": 1690822563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all.\n\nHas anyone used these cards?\n\nWhat is your impression ?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/5nfuvz103cfb1.png?width=717&amp;format=png&amp;auto=webp&amp;s=044916cdf2ba99ece91e589070f1716e3d8125fe\n\nhttps://preview.redd.it/zb4b31cy2cfb1.png?width=844&amp;format=png&amp;auto=webp&amp;s=9198d02ecc4ad076dedccac984a8903568f2e3ee\n\n&amp;#x200B;", "author_fullname": "t2_e3zlhbcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NVMe to Sata adapters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "media_metadata": {"5nfuvz103cfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5fc371fb6fa7a10f23866366437643397d381488"}, {"y": 160, "x": 216, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=85237aff1bfe7d0138899a80f9d991256d4bca5f"}, {"y": 237, "x": 320, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4152e63ac5eb7ea5b2623348a84d14a3ba0dbf8f"}, {"y": 475, "x": 640, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2a0b867e43672d4e503e5adafc280908856bdf16"}], "s": {"y": 533, "x": 717, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=717&amp;format=png&amp;auto=webp&amp;s=044916cdf2ba99ece91e589070f1716e3d8125fe"}, "id": "5nfuvz103cfb1"}, "zb4b31cy2cfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=44d9e3543bcea9d2d139f7154566a142b4a378fb"}, {"y": 154, "x": 216, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b040d01cdaeefcad1ee30e468063e600d621a8f6"}, {"y": 228, "x": 320, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=562eeb57aea3ae4cdb78cce438d401cfc19b9331"}, {"y": 456, "x": 640, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c470685d84427327c397e18b6fd99df2c0c49cf"}], "s": {"y": 602, "x": 844, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=844&amp;format=png&amp;auto=webp&amp;s=9198d02ecc4ad076dedccac984a8903568f2e3ee"}, "id": "zb4b31cy2cfb1"}}, "name": "t3_15e23nu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/xpPYShOSJx0_ebFYGXRpwsKMxTTpy28X-21k9kpzPl4.jpg", "edited": 1690823716.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690765682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.&lt;/p&gt;\n\n&lt;p&gt;Has anyone used these cards?&lt;/p&gt;\n\n&lt;p&gt;What is your impression ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5nfuvz103cfb1.png?width=717&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=044916cdf2ba99ece91e589070f1716e3d8125fe\"&gt;https://preview.redd.it/5nfuvz103cfb1.png?width=717&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=044916cdf2ba99ece91e589070f1716e3d8125fe&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zb4b31cy2cfb1.png?width=844&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9198d02ecc4ad076dedccac984a8903568f2e3ee\"&gt;https://preview.redd.it/zb4b31cy2cfb1.png?width=844&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9198d02ecc4ad076dedccac984a8903568f2e3ee&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e23nu", "is_robot_indexable": true, "report_reasons": null, "author": "rob4ik92", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e23nu/nvme_to_sata_adapters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e23nu/nvme_to_sata_adapters/", "subreddit_subscribers": 695617, "created_utc": 1690765682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "(Disclaimer: This isn't a complaint about their services, but a warning/note to future users to not make the mistake that I did.)\n\nTelnyx is a company that's been known pretty well in the field of SIP trunking and related VoIP services, but recently it appears they've been branching out a bit by offering an S3 bucket service. Their offerings are pretty promising, such as $0.004/GB per month, no egress fees, etc. and some may consider them over other, more typical options such as Backblaze B2. However, it's important to note that while their SIP related services are pretty friendly to the average homelabber, their storage services are a completely different beast. This is even reflected in their terms and conditions, where their main acceptable use page makes no mention of any S3-specific rules or limits. This was where I made my mistake, as they have a different acceptable use page for their storage services that is not linked anywhere in the main T&amp;C page. According to the Telnyx Storage terms and conditions, \"Storage Content may not be deleted by Customer for at least 180 days after such Storage Content is uploaded\". The threshold for when they start taking action seems really low, as I just tested it out by uploading ~100mb with rclone, then deleting the bucket after I was done. It's especially dangerous as they have no safeguards or warnings when you're actually deleting data that's less than 180 days old, they'll just send you an email stating that your account was terminated for violation of the acceptable use policy, which may catch some users who may have read the normal T&amp;C but not the S3-specific T&amp;C off guard.", "author_fullname": "t2_th84t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Telnyx Storage: a relatively new option for S3 cloud storage, and a warning for those unaware.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15eunfm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690843663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Disclaimer: This isn&amp;#39;t a complaint about their services, but a warning/note to future users to not make the mistake that I did.)&lt;/p&gt;\n\n&lt;p&gt;Telnyx is a company that&amp;#39;s been known pretty well in the field of SIP trunking and related VoIP services, but recently it appears they&amp;#39;ve been branching out a bit by offering an S3 bucket service. Their offerings are pretty promising, such as $0.004/GB per month, no egress fees, etc. and some may consider them over other, more typical options such as Backblaze B2. However, it&amp;#39;s important to note that while their SIP related services are pretty friendly to the average homelabber, their storage services are a completely different beast. This is even reflected in their terms and conditions, where their main acceptable use page makes no mention of any S3-specific rules or limits. This was where I made my mistake, as they have a different acceptable use page for their storage services that is not linked anywhere in the main T&amp;amp;C page. According to the Telnyx Storage terms and conditions, &amp;quot;Storage Content may not be deleted by Customer for at least 180 days after such Storage Content is uploaded&amp;quot;. The threshold for when they start taking action seems really low, as I just tested it out by uploading ~100mb with rclone, then deleting the bucket after I was done. It&amp;#39;s especially dangerous as they have no safeguards or warnings when you&amp;#39;re actually deleting data that&amp;#39;s less than 180 days old, they&amp;#39;ll just send you an email stating that your account was terminated for violation of the acceptable use policy, which may catch some users who may have read the normal T&amp;amp;C but not the S3-specific T&amp;amp;C off guard.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eunfm", "is_robot_indexable": true, "report_reasons": null, "author": "kirbyofdeath_r", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eunfm/telnyx_storage_a_relatively_new_option_for_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eunfm/telnyx_storage_a_relatively_new_option_for_s3/", "subreddit_subscribers": 695617, "created_utc": 1690843663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guide to get YouTube content into Plex (Caution wall of text)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eroxu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_4e312", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "PleX", "selftext": "TL;DR: A wall of text describing something only a few will want to do. Probably show of been posted in data hoarders.\n\nI had some issues setting this up and running for myself so I thought I would do a guide. \n\n# My current setup\n\n* Synology DS1821+ NAS for storage and running the plex server.\n* Windows PC that downloads everything. \n* YT-DLP to download the videos\n* I rename files with ReNamer \n\n# Storage Setup\n\nCreate a directory that your Plex server can reach that only your YouTube content will be placed into. \n\n# Plex Setup\n\nYou need to download and install the [personal media scanner](https://bitbucket.org/mjarends/plex-scanners/src/master/) and the [personal media agent](https://bitbucket.org/mjarends/extendedpersonalmedia-agent.bundle/src/master/).\n\nFollow the instruction on how to install them from the bitbucket pages. They explain how to install them depending on what OS you are running. \n\nIn the Plex app/webpage\n\n* Click the wrench icon. \n* On the left hand panel under settings click Agents\n* In the main window click Shows\n* click Extended Personal Media Shows\n* Put a check beside Local Media Assets (TV)\n\nNow we need to create a new Library. \n\n* Under Manage on the left hand panel click Libraries\n* Click add Library in the main window\n* For type Select TV Shows\n* Name it (I named mine YouTube)\n* Click Add Folder\n* Click Browser For Media Folder\n* Select the folder you created to put the YouTube content. \n* Click Advanced \n* For Scanner select Extended Personal Media Scanner\n* For Agent select Extended Personal Media Shows\n* Click Save Changes\n\n# YT-DLP scripts\n\nWe are now ready to start adding videos. In the director with the YT-DLP from program I also have the ffmpeg. This is what is used to merge the HD video and audio together. \n\nThis is where I ran into problems. Most of the guides seem to be older and some of the options they use did not work properly.  Do not use  --write-thumbnail like most of the guides say. This will download a webp format image that Plex doesn't understand. Use --embed-thumbnail like in my scripts below. I will go into more detail on the scripts later. \n\nI am using 2 different scripts. One to download playlists from a channel and the other to download an entire channel. \n\n# Do you really need 2 scripts? \n\nIt depends on what you what to do. You may just need one. \n\nI have some youtubers what I want to download their entire channel. There are very few of these, but I wanted them to be downloaded from oldest to newest. There are other youtubers what I just want to download certain playlists. This is most of them. \n\nDownloading playlists from a YouTube channel \n\n    yt-dlp^\n     -ci^\n     -o \"../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_index)s - %%(title)s [%%(id)s].%%(ext)s\"^\n     --download-archive archive.txt^\n     --add-metadata^\n     --embed-thumbnail^\n     -f bestvideo[ext=mp4]+bestaudio[ext=m4a]^\n     --merge-output-format mp4^\n     --batch-file=channel_list.txt\n\nDownloading an entire YouTube channel \n\n    yt-dlp^\n     -ci^\n     --playlist-reverse^\n     -o \"../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_autonumber)s - %%(title)s [%%(id)s].%%(ext)s\"^\n     --download-archive archive.txt^\n     --add-metadata^\n     --embed-thumbnail^\n     -f bestvideo[ext=mp4]+bestaudio[ext=m4a]^\n     --merge-output-format mp4^\n     --batch-file=list.txt\n\nAs you can see the scripts are very similar. I am using these in a .bat file on windows that I run from the command line. \n\nScript break down (The \\^ at the end of each line is how you split a long command between lines in windows.)\n\n* yt-dlp: This calls the program\n* \\-ci: The c resumes downloads. The i ignores errors.\n* \\--playlist-reverse: This is our first difference. YouTube displays videos from newest to oldest. I want them from oldest to newest. This reverses the list to the way I want them. Playlists are normally listed from oldest to newest already do it's not needed for them. \n*  \\-o \"../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist\\_autonumber)s - %%(title)s \\[%%(id)s\\].%%(ext)s\": This is where to write the files and now to name them.\n   * They are put into a folder called dl.folder. In that folder they will be put into a folder called the Youtubers name. Next will be a folder named after the playlist. \n   * The files will be named after the playlist with a season and episode number. \n   * Example of a file name: Minecraft - All The Mods - S01EP01 - A new start \\[hfuedi8\\].mp4\n   * For playlists you want to use the playlist\\_index. This is because you want to have them the same number as in the playlist. If you are downloading an entire YouTube channel you want to use playlist\\_autonumber. This is because you reversed the order but it will still make the newest video 1. Using playlist\\_autonumber will make the oldest video number 1. \n   * Title puts the title of the video\n   * ID is the youtube id of the video. This is useful if you ever need to remove it from the archive.txt file so you can redownload it. \n* \\--download-archive archive.txt: This prevents you from downloading a file you have already downloaded.\n*  \\--add-metadata: This embeds the metadata from the youtube video into the file \n*  \\--embed-thumbnail: This embeds the thumbnail from the youtube video into the file \n*  \\-f bestvideo\\[ext=mp4\\]+bestaudio\\[ext=m4a\\]: Downloads the best quality video and audio youtube has of the file. \n*  \\--merge-output-format mp4: makes sure the output file will be mp4\n*  \\--batch-file=list.txt: This is where you put a list of url's to download. \n\n# Plex Oddities you have to deal with\n\nSome people may see I posted a help question about things not showing up in Plex. This is due to how Plex detects shows. This part took me a few hours to figure out. \n\nOnce you have added a few things to Plex and scanned the library files you may notice some oddities. The channels that you download the entire channel from show up with no issues. The channels that you downloaded playlists from only show the first playlist but no others. I spun my wheels on this for some time. The solution is to use a program like ReNamer and change the season of the playlists videos. \n\nConfused? let be break it down for you. \n\nYou have 3 playlist downloaded from JohnDoe. They are in 3 directories named after the playlists called Minecraft 1, Starcraft 1, and WOW 1. Inside each of those directories are the videos from the playlist. \n\nThey will be named like this.\n\n* Minecraft 1 - S01E01 - start \\[4u832h\\].mp4\n* Starcraft 1 - S01E01 - start \\[2bwjsd\\].mp4\n* WOW 1 - S01E01 - start \\[fnbdjk89\\].mp4\n\nYou need to rename the files in the Startcraft 1 and WOW 1 directors as follows.\n\n* Starcraft 1 - S02E01 - start \\[2bwjsd\\].mp4\n* WOW 1 - S03E01 - start \\[fnbdjk89\\].mp4\n\nTo do this quickly I use R3Namer.\n\nDoing this lets Plex know they are different. \n\n# Last part\n\nIf you don't care about the channel picture and things like that you are done. If you want the channel art/profile pic then you need to change the meta data in Plex for each channel. Go into your YouTube Library and select the pencil icon. This is where you will rename your channel if you don't like the name Plex assigned to it. It is also where you will add the youtubers icon if you want. To get this I just go to youtubers channel and rick click on their profile pic and save it to my computer. From there in Plex click Poster and drag the image you just downloaded into it. You will need to do this for each YouTube channel. \n\nIf anyone has questions please ask, I will try to answer them. ", "author_fullname": "t2_4e312", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guide to get YouTube content into Plex (Caution wall of text)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/PleX", "hidden": false, "pwls": 6, "link_flair_css_class": "tips", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ero6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tips", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690836613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.PleX", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: A wall of text describing something only a few will want to do. Probably show of been posted in data hoarders.&lt;/p&gt;\n\n&lt;p&gt;I had some issues setting this up and running for myself so I thought I would do a guide. &lt;/p&gt;\n\n&lt;h1&gt;My current setup&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Synology DS1821+ NAS for storage and running the plex server.&lt;/li&gt;\n&lt;li&gt;Windows PC that downloads everything. &lt;/li&gt;\n&lt;li&gt;YT-DLP to download the videos&lt;/li&gt;\n&lt;li&gt;I rename files with ReNamer &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Storage Setup&lt;/h1&gt;\n\n&lt;p&gt;Create a directory that your Plex server can reach that only your YouTube content will be placed into. &lt;/p&gt;\n\n&lt;h1&gt;Plex Setup&lt;/h1&gt;\n\n&lt;p&gt;You need to download and install the &lt;a href=\"https://bitbucket.org/mjarends/plex-scanners/src/master/\"&gt;personal media scanner&lt;/a&gt; and the &lt;a href=\"https://bitbucket.org/mjarends/extendedpersonalmedia-agent.bundle/src/master/\"&gt;personal media agent&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Follow the instruction on how to install them from the bitbucket pages. They explain how to install them depending on what OS you are running. &lt;/p&gt;\n\n&lt;p&gt;In the Plex app/webpage&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Click the wrench icon. &lt;/li&gt;\n&lt;li&gt;On the left hand panel under settings click Agents&lt;/li&gt;\n&lt;li&gt;In the main window click Shows&lt;/li&gt;\n&lt;li&gt;click Extended Personal Media Shows&lt;/li&gt;\n&lt;li&gt;Put a check beside Local Media Assets (TV)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now we need to create a new Library. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Under Manage on the left hand panel click Libraries&lt;/li&gt;\n&lt;li&gt;Click add Library in the main window&lt;/li&gt;\n&lt;li&gt;For type Select TV Shows&lt;/li&gt;\n&lt;li&gt;Name it (I named mine YouTube)&lt;/li&gt;\n&lt;li&gt;Click Add Folder&lt;/li&gt;\n&lt;li&gt;Click Browser For Media Folder&lt;/li&gt;\n&lt;li&gt;Select the folder you created to put the YouTube content. &lt;/li&gt;\n&lt;li&gt;Click Advanced &lt;/li&gt;\n&lt;li&gt;For Scanner select Extended Personal Media Scanner&lt;/li&gt;\n&lt;li&gt;For Agent select Extended Personal Media Shows&lt;/li&gt;\n&lt;li&gt;Click Save Changes&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;YT-DLP scripts&lt;/h1&gt;\n\n&lt;p&gt;We are now ready to start adding videos. In the director with the YT-DLP from program I also have the ffmpeg. This is what is used to merge the HD video and audio together. &lt;/p&gt;\n\n&lt;p&gt;This is where I ran into problems. Most of the guides seem to be older and some of the options they use did not work properly.  Do not use  --write-thumbnail like most of the guides say. This will download a webp format image that Plex doesn&amp;#39;t understand. Use --embed-thumbnail like in my scripts below. I will go into more detail on the scripts later. &lt;/p&gt;\n\n&lt;p&gt;I am using 2 different scripts. One to download playlists from a channel and the other to download an entire channel. &lt;/p&gt;\n\n&lt;h1&gt;Do you really need 2 scripts?&lt;/h1&gt;\n\n&lt;p&gt;It depends on what you what to do. You may just need one. &lt;/p&gt;\n\n&lt;p&gt;I have some youtubers what I want to download their entire channel. There are very few of these, but I wanted them to be downloaded from oldest to newest. There are other youtubers what I just want to download certain playlists. This is most of them. &lt;/p&gt;\n\n&lt;p&gt;Downloading playlists from a YouTube channel &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;yt-dlp^\n -ci^\n -o &amp;quot;../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_index)s - %%(title)s [%%(id)s].%%(ext)s&amp;quot;^\n --download-archive archive.txt^\n --add-metadata^\n --embed-thumbnail^\n -f bestvideo[ext=mp4]+bestaudio[ext=m4a]^\n --merge-output-format mp4^\n --batch-file=channel_list.txt\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Downloading an entire YouTube channel &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;yt-dlp^\n -ci^\n --playlist-reverse^\n -o &amp;quot;../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_autonumber)s - %%(title)s [%%(id)s].%%(ext)s&amp;quot;^\n --download-archive archive.txt^\n --add-metadata^\n --embed-thumbnail^\n -f bestvideo[ext=mp4]+bestaudio[ext=m4a]^\n --merge-output-format mp4^\n --batch-file=list.txt\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;As you can see the scripts are very similar. I am using these in a .bat file on windows that I run from the command line. &lt;/p&gt;\n\n&lt;p&gt;Script break down (The ^ at the end of each line is how you split a long command between lines in windows.)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;yt-dlp: This calls the program&lt;/li&gt;\n&lt;li&gt;-ci: The c resumes downloads. The i ignores errors.&lt;/li&gt;\n&lt;li&gt;--playlist-reverse: This is our first difference. YouTube displays videos from newest to oldest. I want them from oldest to newest. This reverses the list to the way I want them. Playlists are normally listed from oldest to newest already do it&amp;#39;s not needed for them. &lt;/li&gt;\n&lt;li&gt; -o &amp;quot;../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_autonumber)s - %%(title)s [%%(id)s].%%(ext)s&amp;quot;: This is where to write the files and now to name them.\n\n&lt;ul&gt;\n&lt;li&gt;They are put into a folder called dl.folder. In that folder they will be put into a folder called the Youtubers name. Next will be a folder named after the playlist. &lt;/li&gt;\n&lt;li&gt;The files will be named after the playlist with a season and episode number. &lt;/li&gt;\n&lt;li&gt;Example of a file name: Minecraft - All The Mods - S01EP01 - A new start [hfuedi8].mp4&lt;/li&gt;\n&lt;li&gt;For playlists you want to use the playlist_index. This is because you want to have them the same number as in the playlist. If you are downloading an entire YouTube channel you want to use playlist_autonumber. This is because you reversed the order but it will still make the newest video 1. Using playlist_autonumber will make the oldest video number 1. &lt;/li&gt;\n&lt;li&gt;Title puts the title of the video&lt;/li&gt;\n&lt;li&gt;ID is the youtube id of the video. This is useful if you ever need to remove it from the archive.txt file so you can redownload it. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;--download-archive archive.txt: This prevents you from downloading a file you have already downloaded.&lt;/li&gt;\n&lt;li&gt; --add-metadata: This embeds the metadata from the youtube video into the file &lt;/li&gt;\n&lt;li&gt; --embed-thumbnail: This embeds the thumbnail from the youtube video into the file &lt;/li&gt;\n&lt;li&gt; -f bestvideo[ext=mp4]+bestaudio[ext=m4a]: Downloads the best quality video and audio youtube has of the file. &lt;/li&gt;\n&lt;li&gt; --merge-output-format mp4: makes sure the output file will be mp4&lt;/li&gt;\n&lt;li&gt; --batch-file=list.txt: This is where you put a list of url&amp;#39;s to download. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Plex Oddities you have to deal with&lt;/h1&gt;\n\n&lt;p&gt;Some people may see I posted a help question about things not showing up in Plex. This is due to how Plex detects shows. This part took me a few hours to figure out. &lt;/p&gt;\n\n&lt;p&gt;Once you have added a few things to Plex and scanned the library files you may notice some oddities. The channels that you download the entire channel from show up with no issues. The channels that you downloaded playlists from only show the first playlist but no others. I spun my wheels on this for some time. The solution is to use a program like ReNamer and change the season of the playlists videos. &lt;/p&gt;\n\n&lt;p&gt;Confused? let be break it down for you. &lt;/p&gt;\n\n&lt;p&gt;You have 3 playlist downloaded from JohnDoe. They are in 3 directories named after the playlists called Minecraft 1, Starcraft 1, and WOW 1. Inside each of those directories are the videos from the playlist. &lt;/p&gt;\n\n&lt;p&gt;They will be named like this.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Minecraft 1 - S01E01 - start [4u832h].mp4&lt;/li&gt;\n&lt;li&gt;Starcraft 1 - S01E01 - start [2bwjsd].mp4&lt;/li&gt;\n&lt;li&gt;WOW 1 - S01E01 - start [fnbdjk89].mp4&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You need to rename the files in the Startcraft 1 and WOW 1 directors as follows.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Starcraft 1 - S02E01 - start [2bwjsd].mp4&lt;/li&gt;\n&lt;li&gt;WOW 1 - S03E01 - start [fnbdjk89].mp4&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To do this quickly I use R3Namer.&lt;/p&gt;\n\n&lt;p&gt;Doing this lets Plex know they are different. &lt;/p&gt;\n\n&lt;h1&gt;Last part&lt;/h1&gt;\n\n&lt;p&gt;If you don&amp;#39;t care about the channel picture and things like that you are done. If you want the channel art/profile pic then you need to change the meta data in Plex for each channel. Go into your YouTube Library and select the pencil icon. This is where you will rename your channel if you don&amp;#39;t like the name Plex assigned to it. It is also where you will add the youtubers icon if you want. To get this I just go to youtubers channel and rick click on their profile pic and save it to my computer. From there in Plex click Poster and drag the image you just downloaded into it. You will need to do this for each YouTube channel. &lt;/p&gt;\n\n&lt;p&gt;If anyone has questions please ask, I will try to answer them. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_02d9ab2c-162e-4c01-8438-317a016ed3d9", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;s=10034f3fdf8214c8377134bb60c5b832d4bbf588", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;s=100f785bf261fa9452a5d82ee0ef0793369dbfa5", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;s=b15d030fdfbbe4af4a5b34ab9dc90a174df40a23", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;s=601c75be6ee30dc4b47a5c65d64dea9a185502a1", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;s=540f36e65c0e2f1347fe32020e4a1565e3680437", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm in this with you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Take My Energy", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;s=045db73f47a9513c44823d132b4c393ab9241b6a", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;s=298a02e0edbb5b5e293087eeede63802cbe1d2c7", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d06d606eb23dbcd6dbe39ee0e60588c5eb89065", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;s=ecd9854b14104a36a210028c43420f0dababd96b", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;s=0d5d7b92c1d66aff435f2ad32e6330ca2b971f6d", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "ac1f62e2-409a-11e5-a180-0ec131dbf691", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ql7e", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0a7bff", "id": "15ero6e", "is_robot_indexable": true, "report_reasons": null, "author": "quehegan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/PleX/comments/15ero6e/guide_to_get_youtube_content_into_plex_caution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/PleX/comments/15ero6e/guide_to_get_youtube_content_into_plex_caution/", "subreddit_subscribers": 265628, "created_utc": 1690836613.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1690836663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.PleX", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/PleX/comments/15ero6e/guide_to_get_youtube_content_into_plex_caution/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eroxu", "is_robot_indexable": true, "report_reasons": null, "author": "quehegan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15ero6e", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eroxu/guide_to_get_youtube_content_into_plex_caution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/PleX/comments/15ero6e/guide_to_get_youtube_content_into_plex_caution/", "subreddit_subscribers": 695617, "created_utc": 1690836663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two external hdds where I store infrequently used files. Let's call them Drive 1 and Drive 2. I want to transfer my 'more important' files to Drive 2, which is the newer of the two. The problem is that both drives are almost full which means I can't really transfer files from one drive to another. Is there any way that will transfer files directly from drive 1 to drive 2, as drive 2 transfers files to drive 1?", "author_fullname": "t2_avtzqkxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extremely dumb question about moving files between drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eiy5p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690816500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two external hdds where I store infrequently used files. Let&amp;#39;s call them Drive 1 and Drive 2. I want to transfer my &amp;#39;more important&amp;#39; files to Drive 2, which is the newer of the two. The problem is that both drives are almost full which means I can&amp;#39;t really transfer files from one drive to another. Is there any way that will transfer files directly from drive 1 to drive 2, as drive 2 transfers files to drive 1?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eiy5p", "is_robot_indexable": true, "report_reasons": null, "author": "officialfe", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eiy5p/extremely_dumb_question_about_moving_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eiy5p/extremely_dumb_question_about_moving_files/", "subreddit_subscribers": 695617, "created_utc": 1690816500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I'm looking for a discord chat downloader for windows. A program that can download threads, and entire conversations.", "author_fullname": "t2_7n3bibna", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best discord chat exporter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e8tgl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690787435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m looking for a discord chat downloader for windows. A program that can download threads, and entire conversations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": true, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e8tgl", "is_robot_indexable": true, "report_reasons": null, "author": "Shadowlight888", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e8tgl/best_discord_chat_exporter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e8tgl/best_discord_chat_exporter/", "subreddit_subscribers": 695617, "created_utc": 1690787435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Found one on GitHub but it\u2019s through the command line and I don\u2019t understand it. Is there one with a UI?", "author_fullname": "t2_4v83t7zf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a good youtube downloader that runs locally on your pc?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ern8u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690836553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Found one on GitHub but it\u2019s through the command line and I don\u2019t understand it. Is there one with a UI?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ern8u", "is_robot_indexable": true, "report_reasons": null, "author": "_spider_trans_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ern8u/is_there_a_good_youtube_downloader_that_runs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ern8u/is_there_a_good_youtube_downloader_that_runs/", "subreddit_subscribers": 695617, "created_utc": 1690836553.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}