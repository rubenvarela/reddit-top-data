{"kind": "Listing", "data": {"after": "t3_15e50yl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings everyone,\n\nI am a Data Engineer with approximately three to four years of experience in this domain. Currently, I am exploring job opportunities, particularly within product-based companies in Europe.\n\nI would greatly appreciate it if you could share your recent interview experiences for Data Engineering roles ( any level ). I'm particularly interested in understanding the various stages and types of interviews you encountered during your job application process.\n\nWith few interviews which I gave, it looked something like below\n1. Screening round - call with recruiters, briefing for what role is about\n2. Hiring manager round - interview round with hiring manager, discussing depth about your previous experiences\n3. Technical round or take home assignments - not much aware of this round, since I have just started interviewing and few are lined up in upcoming days\n4. Designing data pipeline\n5. Culture fit / Behavior round \n6. HR and release of offer after negotiations.\n\nThank you for your insights in advance.", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer interview experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dutwi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690747259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a Data Engineer with approximately three to four years of experience in this domain. Currently, I am exploring job opportunities, particularly within product-based companies in Europe.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate it if you could share your recent interview experiences for Data Engineering roles ( any level ). I&amp;#39;m particularly interested in understanding the various stages and types of interviews you encountered during your job application process.&lt;/p&gt;\n\n&lt;p&gt;With few interviews which I gave, it looked something like below\n1. Screening round - call with recruiters, briefing for what role is about\n2. Hiring manager round - interview round with hiring manager, discussing depth about your previous experiences\n3. Technical round or take home assignments - not much aware of this round, since I have just started interviewing and few are lined up in upcoming days\n4. Designing data pipeline\n5. Culture fit / Behavior round \n6. HR and release of offer after negotiations.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your insights in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15dutwi", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15dutwi/data_engineer_interview_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15dutwi/data_engineer_interview_experiences/", "subreddit_subscribers": 119555, "created_utc": 1690747259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently a data analyst with two years experience and have a bachelor's degree in Actuarial sciences. I have some competence in SQL, PowerBI, SSIS and have decades of experience in Excel and have a reasonable enough understanding of Linear Algebra, Calculus (1-4), Statistics, , SARIMAX Time Series analysis that I believe that I could pick up many of the ML basics pretty quick. That's my argument for a Data Science Master's Degree. On the other hand most of the problems I see with the data projects that I'm envlolved in stem from the business leaders not understanding the importance of having solid data quality and data pipelines. I believe as time goes on in the next decade or so that more companies will realize they actually need Data Engineers as a solid basis to build their application upon. This is my argument of getting a Data Engineer Master's. Can anyone help me with some direction, insite or constructive criticism of my arguments that I have to help me get off the fence and get an education. ", "author_fullname": "t2_17ejdi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to get either a Data Engineer Masters or a Data Scientist Master: Tell me why you chose to go with your path!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15duqal", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690747017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a data analyst with two years experience and have a bachelor&amp;#39;s degree in Actuarial sciences. I have some competence in SQL, PowerBI, SSIS and have decades of experience in Excel and have a reasonable enough understanding of Linear Algebra, Calculus (1-4), Statistics, , SARIMAX Time Series analysis that I believe that I could pick up many of the ML basics pretty quick. That&amp;#39;s my argument for a Data Science Master&amp;#39;s Degree. On the other hand most of the problems I see with the data projects that I&amp;#39;m envlolved in stem from the business leaders not understanding the importance of having solid data quality and data pipelines. I believe as time goes on in the next decade or so that more companies will realize they actually need Data Engineers as a solid basis to build their application upon. This is my argument of getting a Data Engineer Master&amp;#39;s. Can anyone help me with some direction, insite or constructive criticism of my arguments that I have to help me get off the fence and get an education. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15duqal", "is_robot_indexable": true, "report_reasons": null, "author": "Apollo_3_14", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15duqal/looking_to_get_either_a_data_engineer_masters_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15duqal/looking_to_get_either_a_data_engineer_masters_or/", "subreddit_subscribers": 119555, "created_utc": 1690747017.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks,\n\nlong time listener first time caller. i wanted to get some advice on how i might advance my career in the DE world. i'm a data warehouse developer at my current job and we use an on-premise oracle data warehouse and build our data pipelines with SSIS - they have hopes of migrating our DW solution to the cloud eventually, but i fear it will be several years from now and that i will be tragically left behind on the skill curve by then. i'm hoping to hop into a job that utilizes a more modern data solution, and of course, pays more. \n\n&amp;#x200B;\n\nso yeah, my experience includes:\n\n\\- building data pipelines in SSIS\n\n\\- advanced knowledge of SQL\n\n\\- adequate knowledge of python (mostly retrieving data via APIs)\n\n\\- a data science master's degree (for what it's worth, but i've since decided i prefer DE)\n\n\\- replicating some of my company's current pipelines in ADF and Spark with ADLS, as a sort of proof of concept for my manager\n\n&amp;#x200B;\n\ni was thinking of maybe getting some certs in databricks or some equally popular DE technologies just to show some initiative, though i'm not sure any hiring managers would care. i'm not sure i could reasonably expect to get hired with the experience i have, though i'm very confident i could perform the duties of the role in a more modern DE environment.\n\nwhat do ya think?", "author_fullname": "t2_75va525m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "job search advice (~3 years of DE)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e5pab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690776645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks,&lt;/p&gt;\n\n&lt;p&gt;long time listener first time caller. i wanted to get some advice on how i might advance my career in the DE world. i&amp;#39;m a data warehouse developer at my current job and we use an on-premise oracle data warehouse and build our data pipelines with SSIS - they have hopes of migrating our DW solution to the cloud eventually, but i fear it will be several years from now and that i will be tragically left behind on the skill curve by then. i&amp;#39;m hoping to hop into a job that utilizes a more modern data solution, and of course, pays more. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;so yeah, my experience includes:&lt;/p&gt;\n\n&lt;p&gt;- building data pipelines in SSIS&lt;/p&gt;\n\n&lt;p&gt;- advanced knowledge of SQL&lt;/p&gt;\n\n&lt;p&gt;- adequate knowledge of python (mostly retrieving data via APIs)&lt;/p&gt;\n\n&lt;p&gt;- a data science master&amp;#39;s degree (for what it&amp;#39;s worth, but i&amp;#39;ve since decided i prefer DE)&lt;/p&gt;\n\n&lt;p&gt;- replicating some of my company&amp;#39;s current pipelines in ADF and Spark with ADLS, as a sort of proof of concept for my manager&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;i was thinking of maybe getting some certs in databricks or some equally popular DE technologies just to show some initiative, though i&amp;#39;m not sure any hiring managers would care. i&amp;#39;m not sure i could reasonably expect to get hired with the experience i have, though i&amp;#39;m very confident i could perform the duties of the role in a more modern DE environment.&lt;/p&gt;\n\n&lt;p&gt;what do ya think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15e5pab", "is_robot_indexable": true, "report_reasons": null, "author": "Comprehensive_Ad8288", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15e5pab/job_search_advice_3_years_of_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15e5pab/job_search_advice_3_years_of_de/", "subreddit_subscribers": 119555, "created_utc": 1690776645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A simple way to estimate the memory consumption of PySpark DataFrames by programmatically accessing the optimised plan information:\n\n[https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2](https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2)\n\n&amp;#x200B;", "author_fullname": "t2_e3mh2l7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A simple way to estimate memory consumption of PySpark DataFrame", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ehmrq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690813460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A simple way to estimate the memory consumption of PySpark DataFrames by programmatically accessing the optimised plan information:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2\"&gt;https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?auto=webp&amp;s=c79e6a26fbaf1b0ae4f9552012bab2a811a8cacd", "width": 1200, "height": 623}, "resolutions": [{"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3aad9f746dd11309eb12c9c68c1d25fe1041ddff", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c27be2fd999524ab701c860eed0cce2a89dbbf7e", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=47413ab088e7632d0eb0daf75176223cb543502f", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=075f4f5fafa170b9a94dd79c93b1ad454654486e", "width": 640, "height": 332}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4a08b2f189c2f979ff3c38d257e395f53bfad447", "width": 960, "height": 498}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5345536f98b02d41771ee1edf12cc9130d772075", "width": 1080, "height": 560}], "variants": {}, "id": "n29cfFHNk2u3vCw_xWvFUwRTEQWw47D3ymtpySy0cDE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ehmrq", "is_robot_indexable": true, "report_reasons": null, "author": "Hefty-Consequence443", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ehmrq/a_simple_way_to_estimate_memory_consumption_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ehmrq/a_simple_way_to_estimate_memory_consumption_of/", "subreddit_subscribers": 119555, "created_utc": 1690813460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI'm looking for a sanity check on an experience I'm having with a team lead/jira sprint lead. He seems brilliant but I'm looking for advice on what to do with a potentially unstable jira team lead.\n\nI've been with this company 6+ months. Agile/jira/sprints. A lot of looker based tickets, and some python. I enjoy the looker, and its interesting catching up on all the docs and looking through codebase.\n\nTeam felt great on joining. I noticed our team lead seems to be very \"passionate\". The other 6 on the team are pretty calm and stable so it feels to even out. Something seemed to shift last month. \n\nI met to go over a python 5 line functional commit, and he asked me on the spot if I wanted to refactor this into something better architecturally. I was worried about finishing the ticket, but he seemed confident so I said \"if you think it's possible\". He said it was easy and we started pair programming this (my in retrospect opinion) monstrosity. \n\nWhat I'm worried about is little things I'm observing:\n* Asked me to remove a variable and implement DRY code in 6 places. Repeating the call/not storing the data. Major wtf question for me.\n* Given two tickets, one using a new field created by the previous. I asked if these were linear tickets (T1 creates a full timestamp from two elements, T2 uses T1.timestamp). I was told no with an air of \"why would you think that\".\n* Left an interdepartmental meeting abruptly during a discussion because another department was trying to explain something didn't want to hear. (I've never heard of just exiting a meeting abruptly)\n* Reprimanded for using specific markdown in ticket communication, that i found referenced in our team written docs after.\n* Every sprint is a nebulous push for higher points. Last sprint we did 50% more points than projected and there wasn't a satisfaction relayed in retro.\n\nI get along great with the other members on the team. I come from a finance/IT background, so I'm wondering for guidance on what are norms in jira style work.", "author_fullname": "t2_pkwxz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE team experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eg3n3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690809757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a sanity check on an experience I&amp;#39;m having with a team lead/jira sprint lead. He seems brilliant but I&amp;#39;m looking for advice on what to do with a potentially unstable jira team lead.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been with this company 6+ months. Agile/jira/sprints. A lot of looker based tickets, and some python. I enjoy the looker, and its interesting catching up on all the docs and looking through codebase.&lt;/p&gt;\n\n&lt;p&gt;Team felt great on joining. I noticed our team lead seems to be very &amp;quot;passionate&amp;quot;. The other 6 on the team are pretty calm and stable so it feels to even out. Something seemed to shift last month. &lt;/p&gt;\n\n&lt;p&gt;I met to go over a python 5 line functional commit, and he asked me on the spot if I wanted to refactor this into something better architecturally. I was worried about finishing the ticket, but he seemed confident so I said &amp;quot;if you think it&amp;#39;s possible&amp;quot;. He said it was easy and we started pair programming this (my in retrospect opinion) monstrosity. &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m worried about is little things I&amp;#39;m observing:\n* Asked me to remove a variable and implement DRY code in 6 places. Repeating the call/not storing the data. Major wtf question for me.\n* Given two tickets, one using a new field created by the previous. I asked if these were linear tickets (T1 creates a full timestamp from two elements, T2 uses T1.timestamp). I was told no with an air of &amp;quot;why would you think that&amp;quot;.\n* Left an interdepartmental meeting abruptly during a discussion because another department was trying to explain something didn&amp;#39;t want to hear. (I&amp;#39;ve never heard of just exiting a meeting abruptly)\n* Reprimanded for using specific markdown in ticket communication, that i found referenced in our team written docs after.\n* Every sprint is a nebulous push for higher points. Last sprint we did 50% more points than projected and there wasn&amp;#39;t a satisfaction relayed in retro.&lt;/p&gt;\n\n&lt;p&gt;I get along great with the other members on the team. I come from a finance/IT background, so I&amp;#39;m wondering for guidance on what are norms in jira style work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15eg3n3", "is_robot_indexable": true, "report_reasons": null, "author": "iupuiclubs", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eg3n3/de_team_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eg3n3/de_team_experience/", "subreddit_subscribers": 119555, "created_utc": 1690809757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! A few months ago my friend and I were working on a sustainability software project and wanted to use semantic search/vector search to help improve search accuracy for materials in our PostgreSQL database.\n\n  \nWe found it difficult to do well with standard vector databases and so we ended up making a [nice open-source package to layer semantic search on top of Postgres](https://github.com/getretake/retake) with just a few lines of code. It supports Python backends right now, always stays in sync with PostgreSQL via Kafka, doubles as a vector store, and can be deployed anywhere.\n\n  \nWe wrote some [documentation](https://docs.getretake.com/quickstart) on it and are curious to see what people do with it! If you encounter any issues or have exciting ideas, feel free to [open an issue](https://github.com/getretake/retake/issues) or contribute alongside us to make it better! Any feedback is warmly appreciated", "author_fullname": "t2_4iwrwdc0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We created an open-source semantic search package on top of PostgreSQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e0zpu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690762555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! A few months ago my friend and I were working on a sustainability software project and wanted to use semantic search/vector search to help improve search accuracy for materials in our PostgreSQL database.&lt;/p&gt;\n\n&lt;p&gt;We found it difficult to do well with standard vector databases and so we ended up making a &lt;a href=\"https://github.com/getretake/retake\"&gt;nice open-source package to layer semantic search on top of Postgres&lt;/a&gt; with just a few lines of code. It supports Python backends right now, always stays in sync with PostgreSQL via Kafka, doubles as a vector store, and can be deployed anywhere.&lt;/p&gt;\n\n&lt;p&gt;We wrote some &lt;a href=\"https://docs.getretake.com/quickstart\"&gt;documentation&lt;/a&gt; on it and are curious to see what people do with it! If you encounter any issues or have exciting ideas, feel free to &lt;a href=\"https://github.com/getretake/retake/issues\"&gt;open an issue&lt;/a&gt; or contribute alongside us to make it better! Any feedback is warmly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VWWX_mtCNMf7o-_k3snkUT5JpG36zQT9FtjUzmc_Toc.jpg?auto=webp&amp;s=b31424476a988d8dc2778e14a9c8886cf036f170", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/VWWX_mtCNMf7o-_k3snkUT5JpG36zQT9FtjUzmc_Toc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a101cb5241c85134cf5dd8ef08c93e85407f4693", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/VWWX_mtCNMf7o-_k3snkUT5JpG36zQT9FtjUzmc_Toc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c21edaeb46971a2d3ff40c619cb9020606d75482", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/VWWX_mtCNMf7o-_k3snkUT5JpG36zQT9FtjUzmc_Toc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab6a2830e3bc19836389d5395601ec1c477673ec", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/VWWX_mtCNMf7o-_k3snkUT5JpG36zQT9FtjUzmc_Toc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1070c00493571c4b056184507fae786c4c9e75b7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/VWWX_mtCNMf7o-_k3snkUT5JpG36zQT9FtjUzmc_Toc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5cf1ff17427b619c8c050954dcf73af00f457158", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/VWWX_mtCNMf7o-_k3snkUT5JpG36zQT9FtjUzmc_Toc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3970ba16aefe4189bee3bad1599ab04a745d0497", "width": 1080, "height": 540}], "variants": {}, "id": "UqdL6Orlg3zFA3jXEXUZlpzYbIo4m5DAXyuS_1GsGp4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15e0zpu", "is_robot_indexable": true, "report_reasons": null, "author": "philippemnoel", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15e0zpu/we_created_an_opensource_semantic_search_package/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15e0zpu/we_created_an_opensource_semantic_search_package/", "subreddit_subscribers": 119555, "created_utc": 1690762555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone,\n\n&amp;#x200B;\n\nI'm currently tasked with building out the first DW at my organization. I have been in conversation with Finance since the beginning and I finally go them to generate a list of their needs for the future. The concern I have is that I'm not sure how to discern some of the requests between finance and accounting. As I understand it, accounting is a whole other beast that generally not worth building out a data platform for and is best left for an accounting team to address, as it can be a very complicated and low ROI endeavor for a data eng team to embark on.\n\n&amp;#x200B;\n\nMy question specifically is where is the line here? Is it when numbers are used to pair against an SOW for audit reports? is it when you need to account for changes in orders (forfeited, transfers, etc)?\n\n&amp;#x200B;\n\nThank you!\n\n&amp;#x200B;", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on how to manage data requests from Finance.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ds6ai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690740623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently tasked with building out the first DW at my organization. I have been in conversation with Finance since the beginning and I finally go them to generate a list of their needs for the future. The concern I have is that I&amp;#39;m not sure how to discern some of the requests between finance and accounting. As I understand it, accounting is a whole other beast that generally not worth building out a data platform for and is best left for an accounting team to address, as it can be a very complicated and low ROI endeavor for a data eng team to embark on.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question specifically is where is the line here? Is it when numbers are used to pair against an SOW for audit reports? is it when you need to account for changes in orders (forfeited, transfers, etc)?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ds6ai", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ds6ai/need_advice_on_how_to_manage_data_requests_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ds6ai/need_advice_on_how_to_manage_data_requests_from/", "subreddit_subscribers": 119555, "created_utc": 1690740623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for an analytical team, and the idea of supporting our BI and analysts with transforming data and making it reusable is really appealing because there's a lot of duplication and hokey practices.\n\nThe idea of being able to manage virtual mappings, queries and transformations as maintainable models like dbt is appealing, but most of our folks are using python and spark so it doesn't seem like they would be able to make much use out of dbt since it's all SQL based (unless I'm misunderstanding DBT and after you create a DBT view / model it can be callable from python or spark somehow?).\n\nHow should I consider managing the 'T' in ELT but having it version controlled, reusable and documented in a primarily notebooks driven spark and python environment?\n\n We have our own local conda repo, could I just materialize and save transforms for them to use as a python module they can just run without going through all the HTTP or container setup?\n\nBasically the use case is when an analyst needs a bit more heavy transformations, deduplication or some other processing and  rather than just writing a notebook and giving it to them, how else can I make it something that can be reused and maintained?", "author_fullname": "t2_51nsnxi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SWE Practices for Analytics without DBT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dw48y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690750277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for an analytical team, and the idea of supporting our BI and analysts with transforming data and making it reusable is really appealing because there&amp;#39;s a lot of duplication and hokey practices.&lt;/p&gt;\n\n&lt;p&gt;The idea of being able to manage virtual mappings, queries and transformations as maintainable models like dbt is appealing, but most of our folks are using python and spark so it doesn&amp;#39;t seem like they would be able to make much use out of dbt since it&amp;#39;s all SQL based (unless I&amp;#39;m misunderstanding DBT and after you create a DBT view / model it can be callable from python or spark somehow?).&lt;/p&gt;\n\n&lt;p&gt;How should I consider managing the &amp;#39;T&amp;#39; in ELT but having it version controlled, reusable and documented in a primarily notebooks driven spark and python environment?&lt;/p&gt;\n\n&lt;p&gt;We have our own local conda repo, could I just materialize and save transforms for them to use as a python module they can just run without going through all the HTTP or container setup?&lt;/p&gt;\n\n&lt;p&gt;Basically the use case is when an analyst needs a bit more heavy transformations, deduplication or some other processing and  rather than just writing a notebook and giving it to them, how else can I make it something that can be reused and maintained?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15dw48y", "is_robot_indexable": true, "report_reasons": null, "author": "VersatileGuru", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15dw48y/swe_practices_for_analytics_without_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15dw48y/swe_practices_for_analytics_without_dbt/", "subreddit_subscribers": 119555, "created_utc": 1690750277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_e35wa210", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How To Create Compound Efficiencies In Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_15dt6fx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dQaEmZ5pYsCRUw7BV6xv1Z0U9YMyjGkPRtkVMYrozhU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690743150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "devinterrupted.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://devinterrupted.substack.com/p/how-to-create-compound-efficiencies", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2ToGPbrO2JUDe5tkGevnEMdU6Re6SXQPGZDyNnfHn8o.jpg?auto=webp&amp;s=447681767f428ecbd2f39a5113a96ded0032805a", "width": 1098, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/2ToGPbrO2JUDe5tkGevnEMdU6Re6SXQPGZDyNnfHn8o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d9c32dc8f921cdf01d65c6caeb32e0e50e0884dc", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/2ToGPbrO2JUDe5tkGevnEMdU6Re6SXQPGZDyNnfHn8o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d1abf224ac4d1f2359bb4feb0535ea4f26e74c2", "width": 216, "height": 118}, {"url": "https://external-preview.redd.it/2ToGPbrO2JUDe5tkGevnEMdU6Re6SXQPGZDyNnfHn8o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b91ad18f90ca03e8c308daaf05dc03390bc1554", "width": 320, "height": 174}, {"url": "https://external-preview.redd.it/2ToGPbrO2JUDe5tkGevnEMdU6Re6SXQPGZDyNnfHn8o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3ba042d607526047c41627e6aea5074234c37602", "width": 640, "height": 349}, {"url": "https://external-preview.redd.it/2ToGPbrO2JUDe5tkGevnEMdU6Re6SXQPGZDyNnfHn8o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c914ac96ab32056dd798732e78185c6ae1e88c7f", "width": 960, "height": 524}, {"url": "https://external-preview.redd.it/2ToGPbrO2JUDe5tkGevnEMdU6Re6SXQPGZDyNnfHn8o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a5697c981c901e10e3417cc7dcb461a8cdc4a944", "width": 1080, "height": 590}], "variants": {}, "id": "fcpa2mQtXYHlP07C-Dv6_GpBwvNw4H1J44Q2_Zt_Cmk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15dt6fx", "is_robot_indexable": true, "report_reasons": null, "author": "pinpepnet", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15dt6fx/how_to_create_compound_efficiencies_in_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://devinterrupted.substack.com/p/how-to-create-compound-efficiencies", "subreddit_subscribers": 119555, "created_utc": 1690743150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9uiwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change Data Capture Is Still an Anti-pattern. And You Still Should Use It.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15eimaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EqcO4tOozS3KMUyYVWDbtIDz-eFVSIYykV-3DgL5b2E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690815715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "streamingdata.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://streamingdata.substack.com/p/change-data-capture-is-still-an-anti", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?auto=webp&amp;s=04d6977076f8d968368d6533d4d93bcc4e03f4d3", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=febf87d18ab938c89253d5e7d0697e337bf0e88e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c37da59f1936c995870386de473bad9a4a0c1260", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a059a8e1f66d01ae2eb0b0a1b4572e8187739f1a", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e139e12aa841bac14920bb64d92f70324e0d70d0", "width": 640, "height": 333}], "variants": {}, "id": "TL5zSeeNMw6fBGF0Ca693DL1GL7baDPqZ8ZyarYmuos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15eimaj", "is_robot_indexable": true, "report_reasons": null, "author": "sap1enz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eimaj/change_data_capture_is_still_an_antipattern_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://streamingdata.substack.com/p/change-data-capture-is-still-an-anti", "subreddit_subscribers": 119555, "created_utc": 1690815715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[ Is there any way to statistically test \\(In R\\) the association between the red dots \\(rock art\\) and the yellow dots \\(funerary monuments\\)? I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots. How do i test for that relationship objectivley? ](https://preview.redd.it/vg882vbglafb1.png?width=1724&amp;format=png&amp;auto=webp&amp;s=d1b1cde262fe505260cf0f1b26d9fc4849f45c03)\n\n *I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots.*\n\nI already have the coordinates of all the points so could easily do this via distance measurements between each point.\n\nI've been reading papers and there seem to be **a couple of options** (none of which are explained very well, and I'd love some more clarification on):\n\n1. Use a Monte-Carlo simulation \\[Vanacker et al. 2001\\] to prove red dots are not randomly situated. Apparently Vanacker converted the distance measurements between points into categories eg. &lt;10km, 10-15km, 15-20km etc. But they didn't include a very good method or any of their code in the paper so I can't tell exactly how that would work and am struggling to find other examples/resources\n2. Point Pattern Analysis since I am dealing with 'environmental coviariates' = second-order properties? \\[Kempf &amp; Gunther 2023 say they: \"used spatstat package in R and function rhohat to calculate site intensity as a function of the pre-processed focal raster data to visualise the effect of attraction or repulsion given by a specific parameter...\"\\] Why do they need to convert point data to raster data for this analysis?\n3. Multivariate Regression since this would allow me to include other variables like elevation, distance from water source, soil type etc\n\nOr are all these ideas bad and should I try another way?\n\nThankyou so much for your help, feel free to point me elsewhere but this is the result of my googling so far :))))", "author_fullname": "t2_socde6rs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to test the relationship between red dots &amp; yellow dots??? [R package, archaeologist needs help lol]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vg882vbglafb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/vg882vbglafb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5312bc37b7b2dbc29a814a285a3e6a0225d99819"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/vg882vbglafb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=20189d6f8566e82971122504bc2d97771d522122"}, {"y": 229, "x": 320, "u": "https://preview.redd.it/vg882vbglafb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dee7fbb917dbca48d150737d700ef9169e30a55f"}, {"y": 459, "x": 640, "u": "https://preview.redd.it/vg882vbglafb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f82136c0a393b7f2386314940132a4662a565726"}, {"y": 689, "x": 960, "u": "https://preview.redd.it/vg882vbglafb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=413aaa943380d65b1da513e425150096ed49b1c5"}, {"y": 775, "x": 1080, "u": "https://preview.redd.it/vg882vbglafb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b90b373ebc9b343cdcc283b51684d5b27cffee5a"}], "s": {"y": 1238, "x": 1724, "u": "https://preview.redd.it/vg882vbglafb1.png?width=1724&amp;format=png&amp;auto=webp&amp;s=d1b1cde262fe505260cf0f1b26d9fc4849f45c03"}, "id": "vg882vbglafb1"}}, "name": "t3_15eek4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/P-1KPd2RoBWVeYgzDInKZqayr_JvkCrePMNqfBR5MY8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690805744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vg882vbglafb1.png?width=1724&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d1b1cde262fe505260cf0f1b26d9fc4849f45c03\"&gt; Is there any way to statistically test (In R) the association between the red dots (rock art) and the yellow dots (funerary monuments)? I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots. How do i test for that relationship objectivley? &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I already have the coordinates of all the points so could easily do this via distance measurements between each point.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been reading papers and there seem to be &lt;strong&gt;a couple of options&lt;/strong&gt; (none of which are explained very well, and I&amp;#39;d love some more clarification on):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use a Monte-Carlo simulation [Vanacker et al. 2001] to prove red dots are not randomly situated. Apparently Vanacker converted the distance measurements between points into categories eg. &amp;lt;10km, 10-15km, 15-20km etc. But they didn&amp;#39;t include a very good method or any of their code in the paper so I can&amp;#39;t tell exactly how that would work and am struggling to find other examples/resources&lt;/li&gt;\n&lt;li&gt;Point Pattern Analysis since I am dealing with &amp;#39;environmental coviariates&amp;#39; = second-order properties? [Kempf &amp;amp; Gunther 2023 say they: &amp;quot;used spatstat package in R and function rhohat to calculate site intensity as a function of the pre-processed focal raster data to visualise the effect of attraction or repulsion given by a specific parameter...&amp;quot;] Why do they need to convert point data to raster data for this analysis?&lt;/li&gt;\n&lt;li&gt;Multivariate Regression since this would allow me to include other variables like elevation, distance from water source, soil type etc&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Or are all these ideas bad and should I try another way?&lt;/p&gt;\n\n&lt;p&gt;Thankyou so much for your help, feel free to point me elsewhere but this is the result of my googling so far :))))&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15eek4s", "is_robot_indexable": true, "report_reasons": null, "author": "enemies2l0vers", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eek4s/how_to_test_the_relationship_between_red_dots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eek4s/how_to_test_the_relationship_between_red_dots/", "subreddit_subscribers": 119555, "created_utc": 1690805744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thank you for any advice you can offer on this. Also - Is it common to have the BI tool query pre loaded / static extracts (eg. in Tableau)? Or is the live connection mode to the data warehouse more common?", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you size clusters for dashboard use cases where where the BI tool generates multiple queries for each refresh. Is your refresh interval getting more frequent?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e4ilk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690772832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for any advice you can offer on this. Also - Is it common to have the BI tool query pre loaded / static extracts (eg. in Tableau)? Or is the live connection mode to the data warehouse more common?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15e4ilk", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15e4ilk/how_do_you_size_clusters_for_dashboard_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15e4ilk/how_do_you_size_clusters_for_dashboard_use_cases/", "subreddit_subscribers": 119555, "created_utc": 1690772832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, \n\nJust starting a new project which involves a full migration of all types of data into a data warehouse (which I have to design). I am currently looking at non-digital data i.e paper data records and I have been recommended Docparser for digitsation and transformation into SQL  and NoSQL setups. Has anybody got any experience with this product, or could you recommend any others?\n\nMany thanks in advance.", "author_fullname": "t2_8p2u7cmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docparser reviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dr3pv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690737968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, &lt;/p&gt;\n\n&lt;p&gt;Just starting a new project which involves a full migration of all types of data into a data warehouse (which I have to design). I am currently looking at non-digital data i.e paper data records and I have been recommended Docparser for digitsation and transformation into SQL  and NoSQL setups. Has anybody got any experience with this product, or could you recommend any others?&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15dr3pv", "is_robot_indexable": true, "report_reasons": null, "author": "Jamese0", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15dr3pv/docparser_reviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15dr3pv/docparser_reviews/", "subreddit_subscribers": 119555, "created_utc": 1690737968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI\u2019m a senior data engineer with almost 7 years of experience, and now I got to the point where I was trying to look for the next step in my career and I just\u2026 couldn\u2019t see anything.\n\nSo my question is, would an architecture role be the next step? Has anyone here moved from data engineering to a data architecture or even a solutions architect role?\n\nThanks!", "author_fullname": "t2_3ng50ktz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to an Architecture role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15elp9j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690822913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a senior data engineer with almost 7 years of experience, and now I got to the point where I was trying to look for the next step in my career and I just\u2026 couldn\u2019t see anything.&lt;/p&gt;\n\n&lt;p&gt;So my question is, would an architecture role be the next step? Has anyone here moved from data engineering to a data architecture or even a solutions architect role?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15elp9j", "is_robot_indexable": true, "report_reasons": null, "author": "BramosR", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15elp9j/moving_to_an_architecture_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15elp9j/moving_to_an_architecture_role/", "subreddit_subscribers": 119555, "created_utc": 1690822913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uwe2fsd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Privacy and Compliance: Ethical Web Scraping with Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": true, "name": "t3_15el2db", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jhOA75Fk1ktoAzFAamgUhBYJMJ76YyPrv4_DjTa9X4A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690821405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "python.plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://python.plainenglish.io/data-privacy-and-compliance-ethical-web-scraping-with-bright-data-and-python-8cc63b1c3db4", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?auto=webp&amp;s=06555f7649fcae44965dac64533ac3e8f8aff8db", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=69ea7d740c393012ddac3f83725683c1a940df28", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d39648ee820a4cfe2b0c2954d84fc01c5b07b219", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8fc4974b7a859d01a6964f4e0a244beb4eb2cffd", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38aee157ee7b9846d27afbe70ffa7d94e2b27c1c", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad3b95d186adba8bbec6c7dd1644dfc4a745fd8d", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3bfe2f2e64fc341d77feb22a401d5cc808dda91f", "width": 1080, "height": 720}], "variants": {}, "id": "tvGC4kMTZH_dAo7ZG8KQVPXGNKxuXAB9zqbQJOwoTME"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15el2db", "is_robot_indexable": true, "report_reasons": null, "author": "TheLostWanderer47", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15el2db/data_privacy_and_compliance_ethical_web_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://python.plainenglish.io/data-privacy-and-compliance-ethical-web-scraping-with-bright-data-and-python-8cc63b1c3db4", "subreddit_subscribers": 119555, "created_utc": 1690821405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm totally new to spark and learning it continuously.  Currently working in a pipeline were I have already extracted needed data from a source file and did all the transformations and the final df looks fine to write and heres were I'm stuck now. When I try to write the output in s3 by using partitionBy based on two columns \"name\" and \"type\" and since there maybe multiple entries for same name and type combination while writing parquet if its present in different partition it writes a new file instead of appending.\n\nTo overcome this previously my teammates have tried doing coalesce(1) and the final df have over 2 million records and it was taking more time and it was never completed even after 2-3 hours.\n\nSo suggested using repartition(100, \"domain\") based on the column domain which will make sure all name and type for a single domain comes under same partition. But still it also took the same time and the sink process is not completing.\n\nTo cross check why its getting stuck.. once the final df is ready I checked the natural partitions and it was around 1060 something so I have again tried repartition with 500 and based on domain column and again takes the same time.\n\nWe are using AWS EMR with 1 master 14 cores to do this and tried increasing it to 20 as well but still stuck at the same point.\n\nSince its in jupyter notebook in EMR.. the last job process which is doing the sink process finishes first 54 steps within 10 seconds ans afterwards its taking more than 45 mins for a single task and total 1000 something tasks were scheduled (55/1012).\n\nCan you someone please help me out how to resolve this issue and write the file ? so that s3 has name/type/single parquet file for it which is used my a restapi to get data.", "author_fullname": "t2_5s0b87mm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sink process taking way too long in Pyspark dataframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ekclt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690819741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m totally new to spark and learning it continuously.  Currently working in a pipeline were I have already extracted needed data from a source file and did all the transformations and the final df looks fine to write and heres were I&amp;#39;m stuck now. When I try to write the output in s3 by using partitionBy based on two columns &amp;quot;name&amp;quot; and &amp;quot;type&amp;quot; and since there maybe multiple entries for same name and type combination while writing parquet if its present in different partition it writes a new file instead of appending.&lt;/p&gt;\n\n&lt;p&gt;To overcome this previously my teammates have tried doing coalesce(1) and the final df have over 2 million records and it was taking more time and it was never completed even after 2-3 hours.&lt;/p&gt;\n\n&lt;p&gt;So suggested using repartition(100, &amp;quot;domain&amp;quot;) based on the column domain which will make sure all name and type for a single domain comes under same partition. But still it also took the same time and the sink process is not completing.&lt;/p&gt;\n\n&lt;p&gt;To cross check why its getting stuck.. once the final df is ready I checked the natural partitions and it was around 1060 something so I have again tried repartition with 500 and based on domain column and again takes the same time.&lt;/p&gt;\n\n&lt;p&gt;We are using AWS EMR with 1 master 14 cores to do this and tried increasing it to 20 as well but still stuck at the same point.&lt;/p&gt;\n\n&lt;p&gt;Since its in jupyter notebook in EMR.. the last job process which is doing the sink process finishes first 54 steps within 10 seconds ans afterwards its taking more than 45 mins for a single task and total 1000 something tasks were scheduled (55/1012).&lt;/p&gt;\n\n&lt;p&gt;Can you someone please help me out how to resolve this issue and write the file ? so that s3 has name/type/single parquet file for it which is used my a restapi to get data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ekclt", "is_robot_indexable": true, "report_reasons": null, "author": "imameeer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ekclt/sink_process_taking_way_too_long_in_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ekclt/sink_process_taking_way_too_long_in_pyspark/", "subreddit_subscribers": 119555, "created_utc": 1690819741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in my last (hopefully) year of grad school and I'm also working full time. I have goals of working in data engineering, but currently I work in a role that isn't in the general field of data analytics, nor data engineering, however, I've done multiple analytics projects at work, as well have made some automation pipelines, but my day to day work doesn't really involve data engineering work. I've been advised by mentors to find work that would allow me to use sql or python on a daily basis so I wouldn't have to worry about doing side projects outside of work and school. I just want to be in a good position come graduation time so I can compete for data engineering roles, and that's only possible if I keep my skills sharp (SQL, Python, etc) Any advice would be greatly appreciated.\n\nEdit: The only program I use at work is a no-code program, but I'm hesitant to dive into using it because I don't want my coding skills to atrophy. ", "author_fullname": "t2_5e8sloz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this feasible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ekc89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690819717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in my last (hopefully) year of grad school and I&amp;#39;m also working full time. I have goals of working in data engineering, but currently I work in a role that isn&amp;#39;t in the general field of data analytics, nor data engineering, however, I&amp;#39;ve done multiple analytics projects at work, as well have made some automation pipelines, but my day to day work doesn&amp;#39;t really involve data engineering work. I&amp;#39;ve been advised by mentors to find work that would allow me to use sql or python on a daily basis so I wouldn&amp;#39;t have to worry about doing side projects outside of work and school. I just want to be in a good position come graduation time so I can compete for data engineering roles, and that&amp;#39;s only possible if I keep my skills sharp (SQL, Python, etc) Any advice would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Edit: The only program I use at work is a no-code program, but I&amp;#39;m hesitant to dive into using it because I don&amp;#39;t want my coding skills to atrophy. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ekc89", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableCharity7222", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ekc89/is_this_feasible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ekc89/is_this_feasible/", "subreddit_subscribers": 119555, "created_utc": 1690819717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c5ysf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got laid off from a pretty small team but not getting any callbacks. Please review my CV.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_15ek7dk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/UD-igs9Sg_7ipiJbHT40orb2XnyYWF84UPz3QuiIfl8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690819421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/9g01w1o5qbfb1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/9g01w1o5qbfb1.png?auto=webp&amp;s=35ef4e7e29761f7c4a275440cbd91976bff01466", "width": 951, "height": 1186}, "resolutions": [{"url": "https://preview.redd.it/9g01w1o5qbfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ea1c1552dbd495c655828d9c1fabfab5f35af8c", "width": 108, "height": 134}, {"url": "https://preview.redd.it/9g01w1o5qbfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6007990e8f93045adf90fa66ea2a32b15a652252", "width": 216, "height": 269}, {"url": "https://preview.redd.it/9g01w1o5qbfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf58ce61499d5b104fcc6bb88ddcb2a943c8944f", "width": 320, "height": 399}, {"url": "https://preview.redd.it/9g01w1o5qbfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=dfb190347722fad161ce3128bb51747f199e3f84", "width": 640, "height": 798}], "variants": {}, "id": "rRgR7mIKYDDphcfvhxGjf5bQCWP85XkeOVYO9tDpS3M"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ek7dk", "is_robot_indexable": true, "report_reasons": null, "author": "cellularcone", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ek7dk/just_got_laid_off_from_a_pretty_small_team_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/9g01w1o5qbfb1.png", "subreddit_subscribers": 119555, "created_utc": 1690819421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, I'm working on a Side project design to Hash Credit card number data with a Secret value from Secret manager. \n\nDBT to read Source BQ table, Get secret value &amp; concatenate with PII Column which needs to be hashed with SHA256. \n\nI'm not able to integrate DBT with Secret Manager. Storing secret as Environment variable option cannot be used as SM option to be tried. \n\nI have options to include Cloud Function, Composer in my design. \n\nSo I have below things in mind:\n\n1. Composer DAG to access secret via Cloud function &amp; pass as XCOM variable to DBT task. \n2. Composer DAG to get secret using Secret backend &amp; pass as XCOM variable to DBT task. \n\nAlso, Secrets should not be in readable format in Composer logs. \n\nWhich one is feasible or please advise other alternatives? \n\n   \n\n   ", "author_fullname": "t2_4cullil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Options to integrate DBT with GCP Secret Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ej945", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690817193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, I&amp;#39;m working on a Side project design to Hash Credit card number data with a Secret value from Secret manager. &lt;/p&gt;\n\n&lt;p&gt;DBT to read Source BQ table, Get secret value &amp;amp; concatenate with PII Column which needs to be hashed with SHA256. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not able to integrate DBT with Secret Manager. Storing secret as Environment variable option cannot be used as SM option to be tried. &lt;/p&gt;\n\n&lt;p&gt;I have options to include Cloud Function, Composer in my design. &lt;/p&gt;\n\n&lt;p&gt;So I have below things in mind:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Composer DAG to access secret via Cloud function &amp;amp; pass as XCOM variable to DBT task. &lt;/li&gt;\n&lt;li&gt;Composer DAG to get secret using Secret backend &amp;amp; pass as XCOM variable to DBT task. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Also, Secrets should not be in readable format in Composer logs. &lt;/p&gt;\n\n&lt;p&gt;Which one is feasible or please advise other alternatives? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ej945", "is_robot_indexable": true, "report_reasons": null, "author": "tmanipra", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ej945/options_to_integrate_dbt_with_gcp_secret_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ej945/options_to_integrate_dbt_with_gcp_secret_manager/", "subreddit_subscribers": 119555, "created_utc": 1690817193.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jcps4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Half A Day To Half An Hour! Performance Tuning Snowpark For Identity Resolution On Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15ej2ut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Mo9w-SCZDoUdLx4yA70JihCnGdcmx4FyARLr_oB-YaQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690816796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "learningfromdata.zingg.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.learningfromdata.zingg.ai/p/performance-tuning-snowpark-for-identity", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?auto=webp&amp;s=5d8def0021de1e2f85598e36470a26e0ec402fba", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c0999c9e40d8dcf09d3448231f2754f11ae5acb", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b48066ea9d017b7c0c5b48e3c39ded75b318300", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=35787ae8b289888943a45689ee895bb083c8629e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b3dad013369b5c2145c1fac01d0b96c5e6c8ee32", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05732a92520a7a957f314e51c8d3a18c5870d748", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a4bcf7705bc971a7ee8da726a2be9448f3f8769", "width": 1080, "height": 540}], "variants": {}, "id": "3buw50ybg4THUy9GX79YY19y00pyPQxd1bi1KbbgoqA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ej2ut", "is_robot_indexable": true, "report_reasons": null, "author": "sonalg", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ej2ut/from_half_a_day_to_half_an_hour_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.learningfromdata.zingg.ai/p/performance-tuning-snowpark-for-identity", "subreddit_subscribers": 119555, "created_utc": 1690816796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys!\n\nI'm looking to enhance my data skills and dive deeper into Microsoft's powerful suite of tools for Business Intelligence and data processing. Specifically, I'm interested in learning more about SSIS, SSAS, SSRS, and Power BI.\n\nI'm reaching out for some course recommendations do you guys perhaps have any? ", "author_fullname": "t2_14erwu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Course Recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eifq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690815295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to enhance my data skills and dive deeper into Microsoft&amp;#39;s powerful suite of tools for Business Intelligence and data processing. Specifically, I&amp;#39;m interested in learning more about SSIS, SSAS, SSRS, and Power BI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out for some course recommendations do you guys perhaps have any? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15eifq6", "is_robot_indexable": true, "report_reasons": null, "author": "Pershanthen", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eifq6/course_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eifq6/course_recommendations/", "subreddit_subscribers": 119555, "created_utc": 1690815295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for service or tool similiar to [Metabase](https://www.metabase.com/) or [Redash](https://redash.io/) that allows me to add data source - for example Postgres connection, and create raw SQL queries that can be shared or exposed through API. So instead of keeping raw SQL code somewhere, my other service would call this tool e.g. `http://microservice/query=1?param1=xx&amp;page=2` and get the results from the DB. \nThese calls are internal only and part of ETL processes, but of course authentication would be required.\n\nThe services that I mentioned are more or less focused only on visualizations, I do not really need that, but for example Metabase is almost perfect as it has API that can work with parametrized queries, but for sake of visualizations it has hard limit on the count of results that are returned.\n\nAny other suggestions are welcome.", "author_fullname": "t2_bq4w6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool or service for querying and exposing database through API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ehxh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690814149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for service or tool similiar to &lt;a href=\"https://www.metabase.com/\"&gt;Metabase&lt;/a&gt; or &lt;a href=\"https://redash.io/\"&gt;Redash&lt;/a&gt; that allows me to add data source - for example Postgres connection, and create raw SQL queries that can be shared or exposed through API. So instead of keeping raw SQL code somewhere, my other service would call this tool e.g. &lt;code&gt;http://microservice/query=1?param1=xx&amp;amp;page=2&lt;/code&gt; and get the results from the DB. \nThese calls are internal only and part of ETL processes, but of course authentication would be required.&lt;/p&gt;\n\n&lt;p&gt;The services that I mentioned are more or less focused only on visualizations, I do not really need that, but for example Metabase is almost perfect as it has API that can work with parametrized queries, but for sake of visualizations it has hard limit on the count of results that are returned.&lt;/p&gt;\n\n&lt;p&gt;Any other suggestions are welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?auto=webp&amp;s=107572bcffe6e16e601fbfa7adc0948b3a2b6a4f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ea6b7aafd33b2a93630e2b42c1775d84785fb06b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dea1182b323f20b6b0a5185baae08721cb8bbe51", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9bc515316f645bf42bf4d975ac01befc3882170", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff6d758cd5061450003cad4ff1bf8722b6f23020", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9b1f1f0306bc5a9d8342065c4ecdaff26236763", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d13f1df515a957d9bda81a3c03e2e7f352d9cb62", "width": 1080, "height": 567}], "variants": {}, "id": "H_7x2FRMyu4Laqv2RVCvsaxLrQmcsL3NrNoLvhi3x7o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ehxh4", "is_robot_indexable": true, "report_reasons": null, "author": "Montty1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ehxh4/tool_or_service_for_querying_and_exposing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ehxh4/tool_or_service_for_querying_and_exposing/", "subreddit_subscribers": 119555, "created_utc": 1690814149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm preparing to interview for an entry-level systems engineering role in the data engineering department. Supposedly, it's directly related to systems engineering, so compute resources in Google cloud, setting up confluence and resolving Jira tickets. My concern even though this is an entry-level position is that they are going to be asking a lot of questions about some technical stuff that I've only had brief, extremely limited exposure to. I've used confluence for a grand sum of about 20 hours total, Jira for like 50 hours total, and Even though I am very well versed in a lot of data engineering functions, my skill and systems engineering is kind of lacking because I never had exposure to that.\n\nHere are some questions I have:\n\n \n\n\n- How do I address questions that I don't know, or don't have experience with? I think I have shot myself in the foot in the past in interviews when faced with these kind of questions. I usually say something like \"well I don't really have experience with this directly, in all honesty, but I am definitely open to learning more about this and finding out more\". I'm not even sure how to answer these questions when I don't know the answer.  \"What's your experience with Bash scripting/confluence/JIRA?\" How do I answer this question with novice level experience and skill and not sound like an idiot? \"I've never done that \" It's definitely not the best way to answer this I bet.... How do I explain it? \n\n\n\n- How do I explain my experience with projects unrelated to work in a way that doesn't sound clowny? I've been studying Google cloud platform and taking training on it extensively through Coursera and on Google's cloud platform website to try and skill up, and go for a certification in infrastructure. To that effect, I have several practice projects where I develop APIs, set up GCP and arrange compute resources, set up IAM roles, etc. I just don't know how to explain it in a way that makes it sound like it's more than just a silly project", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing for an entry level \"systems engineering\" role. Can anyone give me some advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eg1ap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690809600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m preparing to interview for an entry-level systems engineering role in the data engineering department. Supposedly, it&amp;#39;s directly related to systems engineering, so compute resources in Google cloud, setting up confluence and resolving Jira tickets. My concern even though this is an entry-level position is that they are going to be asking a lot of questions about some technical stuff that I&amp;#39;ve only had brief, extremely limited exposure to. I&amp;#39;ve used confluence for a grand sum of about 20 hours total, Jira for like 50 hours total, and Even though I am very well versed in a lot of data engineering functions, my skill and systems engineering is kind of lacking because I never had exposure to that.&lt;/p&gt;\n\n&lt;p&gt;Here are some questions I have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;How do I address questions that I don&amp;#39;t know, or don&amp;#39;t have experience with? I think I have shot myself in the foot in the past in interviews when faced with these kind of questions. I usually say something like &amp;quot;well I don&amp;#39;t really have experience with this directly, in all honesty, but I am definitely open to learning more about this and finding out more&amp;quot;. I&amp;#39;m not even sure how to answer these questions when I don&amp;#39;t know the answer.  &amp;quot;What&amp;#39;s your experience with Bash scripting/confluence/JIRA?&amp;quot; How do I answer this question with novice level experience and skill and not sound like an idiot? &amp;quot;I&amp;#39;ve never done that &amp;quot; It&amp;#39;s definitely not the best way to answer this I bet.... How do I explain it? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do I explain my experience with projects unrelated to work in a way that doesn&amp;#39;t sound clowny? I&amp;#39;ve been studying Google cloud platform and taking training on it extensively through Coursera and on Google&amp;#39;s cloud platform website to try and skill up, and go for a certification in infrastructure. To that effect, I have several practice projects where I develop APIs, set up GCP and arrange compute resources, set up IAM roles, etc. I just don&amp;#39;t know how to explain it in a way that makes it sound like it&amp;#39;s more than just a silly project&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15eg1ap", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eg1ap/preparing_for_an_entry_level_systems_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eg1ap/preparing_for_an_entry_level_systems_engineering/", "subreddit_subscribers": 119555, "created_utc": 1690809600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polyglot Apache Arrow: Java and Python Perspective", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15ecqrj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EVly904NB1iuwtZC_WePHFYp1FabOhz-bHqQ5EvdBaE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690800517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/gooddata-developers/polyglot-apache-arrow-java-and-python-perspective-bf2ce020e27d", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RpEP5Aq5nOsB77UoDNrCIW3-e93tAPDwOXVKImft85I.jpg?auto=webp&amp;s=6f313696f614754cb1fee96e7cf89905da0c2516", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/RpEP5Aq5nOsB77UoDNrCIW3-e93tAPDwOXVKImft85I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1aa322d013b79150eb1fb8c4284240bd4b8381de", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/RpEP5Aq5nOsB77UoDNrCIW3-e93tAPDwOXVKImft85I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d59579518c32335b949f2b83c73f206ee46ce556", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/RpEP5Aq5nOsB77UoDNrCIW3-e93tAPDwOXVKImft85I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=17929ce713e1b3f215085de3d111a2a64c12ca62", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/RpEP5Aq5nOsB77UoDNrCIW3-e93tAPDwOXVKImft85I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=10f3f4e211aebfe987bc172f14a0848b2964a989", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/RpEP5Aq5nOsB77UoDNrCIW3-e93tAPDwOXVKImft85I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ca996fa4cd22b0b5f1f5fcd75ed4bdb30e26cba4", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/RpEP5Aq5nOsB77UoDNrCIW3-e93tAPDwOXVKImft85I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3da28123a6096ca1afade1266c67391f1c79134e", "width": 1080, "height": 565}], "variants": {}, "id": "x23mhmYlBg9uFrU7iwk9Hi2XzihBpowKOxBYfAdYzNQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ecqrj", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ecqrj/polyglot_apache_arrow_java_and_python_perspective/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/gooddata-developers/polyglot-apache-arrow-java-and-python-perspective-bf2ce020e27d", "subreddit_subscribers": 119555, "created_utc": 1690800517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have just started my full time job in the same company after almost a year there as a part time (70%). We use DBT+Snowflake+Argo (transitioning to Flyte, it's pretty nice!) for our ETL. And the team is in charge of creating APIs to access the data. \nAs a part time, my job mainly consisted of data modeling, being in charge of small end to end ETL projects, visualization (kida sick of Tableau already haha) and stepping up my SQL game. \nNow I'm  in a place where I need to know a little more where I want to specialize, and I'm not sure what other companies are doing. I have never used any of the services like Spark or Haddop because we don't have any use in those. \nI guess I'm not sure which field is more needed, and what skills should I learn to become a more worthy data engineer. \n\nWould appreciate any insights on everything I said. Thanks you guys!", "author_fullname": "t2_zbab4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing a field to specialize in", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e50yl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690774471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have just started my full time job in the same company after almost a year there as a part time (70%). We use DBT+Snowflake+Argo (transitioning to Flyte, it&amp;#39;s pretty nice!) for our ETL. And the team is in charge of creating APIs to access the data. \nAs a part time, my job mainly consisted of data modeling, being in charge of small end to end ETL projects, visualization (kida sick of Tableau already haha) and stepping up my SQL game. \nNow I&amp;#39;m  in a place where I need to know a little more where I want to specialize, and I&amp;#39;m not sure what other companies are doing. I have never used any of the services like Spark or Haddop because we don&amp;#39;t have any use in those. \nI guess I&amp;#39;m not sure which field is more needed, and what skills should I learn to become a more worthy data engineer. &lt;/p&gt;\n\n&lt;p&gt;Would appreciate any insights on everything I said. Thanks you guys!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15e50yl", "is_robot_indexable": true, "report_reasons": null, "author": "chenvili", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15e50yl/choosing_a_field_to_specialize_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15e50yl/choosing_a_field_to_specialize_in/", "subreddit_subscribers": 119555, "created_utc": 1690774471.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}