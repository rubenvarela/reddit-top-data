{"kind": "Listing", "data": {"after": "t3_15e9j2r", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My main problem is organization.\n\nI'm constantly re-writing vocabulary (that's already been digitized) in my notebook and notecards because multiple copies of the same thing is great and I keep on finding more efficient ways to create a comprehensible and effective language class, which is exactly what's saving my language, but I feel like I'm drowning in destructible material.\n\nI have enough money for flash drives, and I already have a printer/scanner specifically for this purpose, so making copies of stuff isn't a problem.", "author_fullname": "t2_2p5226u2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have 30ish notecards, 5 half-filled notebooks, and literally hundreds of loose paper with my critically endangered language and cultural practices written down...and on my computer. How should I digitize it efficiently? How should I organize it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e18mf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 159, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 159, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690763249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My main problem is organization.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m constantly re-writing vocabulary (that&amp;#39;s already been digitized) in my notebook and notecards because multiple copies of the same thing is great and I keep on finding more efficient ways to create a comprehensible and effective language class, which is exactly what&amp;#39;s saving my language, but I feel like I&amp;#39;m drowning in destructible material.&lt;/p&gt;\n\n&lt;p&gt;I have enough money for flash drives, and I already have a printer/scanner specifically for this purpose, so making copies of stuff isn&amp;#39;t a problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e18mf", "is_robot_indexable": true, "report_reasons": null, "author": "Starfire-Galaxy", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e18mf/i_have_30ish_notecards_5_halffilled_notebooks_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e18mf/i_have_30ish_notecards_5_halffilled_notebooks_and/", "subreddit_subscribers": 695583, "created_utc": 1690763249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7me91nis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Disney Discontinues Physical Media Releases for an Entire Continent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15egxgg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pPWRH7l2SiwWOt_WtX1q7VBtV5fp_A_BlO3GX-niWrw.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690811788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "collider.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://collider.com/disney-physical-media-release-discontinue-australia/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?auto=webp&amp;s=00396370454858c269d64c9f04a799af6cc12337", "width": 1400, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbf9a460ed4d3e8528199f7839881801330ea37b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a30f76807415eaac93326ef4c5938dd6cba0e84f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ea61c12d4806c312eafdd182031fef399d395e0", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=107342f0b6fca8ff50e95fc236c8556e7d379f0f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a340719fff0f32833486b2278ca36bfd78e6e034", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9cdcf18f7321a0dba51232d7879ceb6b424ea810", "width": 1080, "height": 540}], "variants": {}, "id": "WEeO1MWsnVDW93KokE5tqFv-yRkh-HygbEtnoJBpdcs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "64TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15egxgg", "is_robot_indexable": true, "report_reasons": null, "author": "WindowlessBasement", "discussion_type": null, "num_comments": 20, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15egxgg/disney_discontinues_physical_media_releases_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://collider.com/disney-physical-media-release-discontinue-australia/", "subreddit_subscribers": 695583, "created_utc": 1690811788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "At work I receive temperature date logger devices.  They are **single use only**, unless you can flash the firmware.\n\n~~But they act as a thumbdrive where it outputs the temperature report once inserted in a PC, and stop running.  However it only has 400kb available space.~~\n\nI have a whole box full of them, and unless I find a use for them, they're going to a recycling centre(CR battery inside, PCB, chip).\n\n\nEdit: https://www.reddit.com/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/ju7exzw?utm_source=share&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_term=1&amp;utm_content=2\n\nThey can't be used as flash drives.", "author_fullname": "t2_kyyvuhkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any use to Flash Drives that can only store 400kb?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e9w98", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690824090.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690791184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At work I receive temperature date logger devices.  They are &lt;strong&gt;single use only&lt;/strong&gt;, unless you can flash the firmware.&lt;/p&gt;\n\n&lt;p&gt;&lt;del&gt;But they act as a thumbdrive where it outputs the temperature report once inserted in a PC, and stop running.  However it only has 400kb available space.&lt;/del&gt;&lt;/p&gt;\n\n&lt;p&gt;I have a whole box full of them, and unless I find a use for them, they&amp;#39;re going to a recycling centre(CR battery inside, PCB, chip).&lt;/p&gt;\n\n&lt;p&gt;Edit: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/ju7exzw?utm_source=share&amp;amp;utm_medium=android_app&amp;amp;utm_name=androidcss&amp;amp;utm_term=1&amp;amp;utm_content=2\"&gt;https://www.reddit.com/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/ju7exzw?utm_source=share&amp;amp;utm_medium=android_app&amp;amp;utm_name=androidcss&amp;amp;utm_term=1&amp;amp;utm_content=2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They can&amp;#39;t be used as flash drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e9w98", "is_robot_indexable": true, "report_reasons": null, "author": "VlaamsBelanger", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e9w98/is_there_any_use_to_flash_drives_that_can_only/", "subreddit_subscribers": 695583, "created_utc": 1690791184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello friends! I\u2019m a cinematographer, and generate a reasonable amount of data. I shoot advertising so most shoots only tend to be 1-4 days, and within that time I normally generate between 500gb - 4tb. I have 3 general needs for my data storage. \n\n1. Fast access to about 4tb of data of a time to edit projects. This is critical. \n2. Bulletproof back-up of working files until project is completed. This is critical. \n3. Long term storage of projects. The clients don\u2019t care about this (after approx. 6 months from delivery), but I like having an archive of my work, both personally (I made that!) and there is also a professional element (for pitching new jobs, showreel, etc).\n\nWhat I have currently been doing is using a QNAP NAS (TVS-1282T3) connected to a Mac Pro via 10gbe to edit off and store files. It\u2019s 84tb raw and about 50tb after raid stuff etc. I simultaneously back footage up to a couple of 3.5\u201d drives too, one of which gets kept in the office, and one comes home with me. I have a rolling system where I bump the oldest job off the nas to make room for the new job. \n\nI\u2019m worried about longevity of storage and general cost if I decide to upgrade my camera, which will generate a lot more data to store. I\u2019ve been spitballing:\n\n- some sort of SSD type of raid array to edit off. Approx 8tb, and I could have 2 or 3 for redundancy. Double points if I could get some sort of online back-up from an ssd at the office to an identical ssd at home.\n- LTO reader in the office, so once a project is completed, it goes on 3x tapes.\n\nThis would allow me to have quick storage to edit off, and cheaper, more stable storage to handle my archive which is rarely accessed by me or my clients. \n\nI\u2019d ideally want something mac-compatible. I\u2019ve got 2 MacBook pros, 2 iPad pros, a Mac Pro in the office, and a Mac mini at home. \n\nSorry for the wall of text. I\u2019m wondering if I\u2019m missing something or if anyone had an elegant solution. Thanks so much in advance!", "author_fullname": "t2_4o1koz5z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A few questions from a lost cinematographer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e4xf9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690774153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends! I\u2019m a cinematographer, and generate a reasonable amount of data. I shoot advertising so most shoots only tend to be 1-4 days, and within that time I normally generate between 500gb - 4tb. I have 3 general needs for my data storage. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Fast access to about 4tb of data of a time to edit projects. This is critical. &lt;/li&gt;\n&lt;li&gt;Bulletproof back-up of working files until project is completed. This is critical. &lt;/li&gt;\n&lt;li&gt;Long term storage of projects. The clients don\u2019t care about this (after approx. 6 months from delivery), but I like having an archive of my work, both personally (I made that!) and there is also a professional element (for pitching new jobs, showreel, etc).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What I have currently been doing is using a QNAP NAS (TVS-1282T3) connected to a Mac Pro via 10gbe to edit off and store files. It\u2019s 84tb raw and about 50tb after raid stuff etc. I simultaneously back footage up to a couple of 3.5\u201d drives too, one of which gets kept in the office, and one comes home with me. I have a rolling system where I bump the oldest job off the nas to make room for the new job. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m worried about longevity of storage and general cost if I decide to upgrade my camera, which will generate a lot more data to store. I\u2019ve been spitballing:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;some sort of SSD type of raid array to edit off. Approx 8tb, and I could have 2 or 3 for redundancy. Double points if I could get some sort of online back-up from an ssd at the office to an identical ssd at home.&lt;/li&gt;\n&lt;li&gt;LTO reader in the office, so once a project is completed, it goes on 3x tapes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This would allow me to have quick storage to edit off, and cheaper, more stable storage to handle my archive which is rarely accessed by me or my clients. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d ideally want something mac-compatible. I\u2019ve got 2 MacBook pros, 2 iPad pros, a Mac Pro in the office, and a Mac mini at home. &lt;/p&gt;\n\n&lt;p&gt;Sorry for the wall of text. I\u2019m wondering if I\u2019m missing something or if anyone had an elegant solution. Thanks so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e4xf9", "is_robot_indexable": true, "report_reasons": null, "author": "LurkingAlter", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e4xf9/a_few_questions_from_a_lost_cinematographer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e4xf9/a_few_questions_from_a_lost_cinematographer/", "subreddit_subscribers": 695583, "created_utc": 1690774153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am in the process of scanning a large quantity of printed photos. Currently, I am manually naming the files based on the month and year stamped on the back. Is there a software that can visually scan for the date and automatically name the files by date?", "author_fullname": "t2_gkpijpe8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software that Automatically Names Scanned Photos by the Dates Stamped on the Back", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dyjnf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690756120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in the process of scanning a large quantity of printed photos. Currently, I am manually naming the files based on the month and year stamped on the back. Is there a software that can visually scan for the date and automatically name the files by date?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15dyjnf", "is_robot_indexable": true, "report_reasons": null, "author": "QuietWanderingNerd", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15dyjnf/software_that_automatically_names_scanned_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15dyjnf/software_that_automatically_names_scanned_photos/", "subreddit_subscribers": 695583, "created_utc": 1690756120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I downloaded some pretty large videos via yt-dlp. The video files were downloaded completely, but when yt-dlp tried to post-process them and add the metadata the process was aborted. Now the videos are no longer online and I'm sitting here with my .mp4 file and the .meta file (generated automatically by yt-dlp).\n\nIs there a command to tell yt-dlp to just take the video and metadata file and merge them? Or do I really have to write out all the data manually and add it via [metadata fields](https://github.com/yt-dlp/yt-dlp#modifying-metadata)?\n\nThe .meta file looks like this:\n\n    ;FFMETADATA1\n    [CHAPTER]\n    TIMEBASE=1/1000\n    START=0\n    END=1463000\n    title=Rick Rollin\n    [CHAPTER]\n    TIMEBASE=1/1000\n    START=1463000\n    END=9387000\n    title=OUTERPLANE\n    [CHAPTER]\n    TIMEBASE=1/1000\n    START=9387000\n    END=23529000\n    title=Rick Rollin\n\n&amp;#x200B;", "author_fullname": "t2_lgx1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Add metadata from .meta files to already downloaded videos via yt-dlp", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dyfv1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690755853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I downloaded some pretty large videos via yt-dlp. The video files were downloaded completely, but when yt-dlp tried to post-process them and add the metadata the process was aborted. Now the videos are no longer online and I&amp;#39;m sitting here with my .mp4 file and the .meta file (generated automatically by yt-dlp).&lt;/p&gt;\n\n&lt;p&gt;Is there a command to tell yt-dlp to just take the video and metadata file and merge them? Or do I really have to write out all the data manually and add it via &lt;a href=\"https://github.com/yt-dlp/yt-dlp#modifying-metadata\"&gt;metadata fields&lt;/a&gt;?&lt;/p&gt;\n\n&lt;p&gt;The .meta file looks like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;;FFMETADATA1\n[CHAPTER]\nTIMEBASE=1/1000\nSTART=0\nEND=1463000\ntitle=Rick Rollin\n[CHAPTER]\nTIMEBASE=1/1000\nSTART=1463000\nEND=9387000\ntitle=OUTERPLANE\n[CHAPTER]\nTIMEBASE=1/1000\nSTART=9387000\nEND=23529000\ntitle=Rick Rollin\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZQ_uJX_Lp6oypSrjhuQOsnbGUpqrxS8YOvbhGDdWTOM.jpg?auto=webp&amp;s=4d74f75a5b0580200e8f00a056c89f07503ad6dc", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/ZQ_uJX_Lp6oypSrjhuQOsnbGUpqrxS8YOvbhGDdWTOM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c8bac97db762ff29d0ded6665048b60ff0b9d29c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ZQ_uJX_Lp6oypSrjhuQOsnbGUpqrxS8YOvbhGDdWTOM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4667e7acb778cc1370932439b266f423bfaaa6e", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ZQ_uJX_Lp6oypSrjhuQOsnbGUpqrxS8YOvbhGDdWTOM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b42a03cccbb3eff0dcaea3f42fce74b514bf9fdd", "width": 320, "height": 320}], "variants": {}, "id": "GSgbDGXRy8cTnzQmF08ew6ybIXeA8LP0f9wGVbbY2xc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15dyfv1", "is_robot_indexable": true, "report_reasons": null, "author": "alex_roston", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15dyfv1/add_metadata_from_meta_files_to_already/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15dyfv1/add_metadata_from_meta_files_to_already/", "subreddit_subscribers": 695583, "created_utc": 1690755853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My mother unfortunately passed away recently and she had acquired (and kept in storage) 4-5 different MacBook pros, right back to the ones with the hinge design.  \nI don't immediately need access to the data in any of them, Still; I thought it would be cool if there were a simple way to archive/mothball their contents onto (preferably) a single drive called 'mom' or something that was super easy to search and that way if I ever want to find an email/reference number/legal doc/photo years into the future its easy to do so. Then I can donate or recycle the Macbooks.  \nThanks for your time. ", "author_fullname": "t2_9yy7pro6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving Macs of mom who's passed away", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eh7d6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690812435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My mother unfortunately passed away recently and she had acquired (and kept in storage) 4-5 different MacBook pros, right back to the ones with the hinge design.&lt;br/&gt;\nI don&amp;#39;t immediately need access to the data in any of them, Still; I thought it would be cool if there were a simple way to archive/mothball their contents onto (preferably) a single drive called &amp;#39;mom&amp;#39; or something that was super easy to search and that way if I ever want to find an email/reference number/legal doc/photo years into the future its easy to do so. Then I can donate or recycle the Macbooks.&lt;br/&gt;\nThanks for your time. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eh7d6", "is_robot_indexable": true, "report_reasons": null, "author": "herbertthe3rd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eh7d6/archiving_macs_of_mom_whos_passed_away/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eh7d6/archiving_macs_of_mom_whos_passed_away/", "subreddit_subscribers": 695583, "created_utc": 1690812435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for an extremely durable SSD for a special workload (20TB written per day) In short, I'll need a very high TBW rating. So far I've only found the 2TB DC600M at 3504TBW. Does anyone know more solutions like these?", "author_fullname": "t2_gkm00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Highest TBW SSD possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ecfvn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690799602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for an extremely durable SSD for a special workload (20TB written per day) In short, I&amp;#39;ll need a very high TBW rating. So far I&amp;#39;ve only found the 2TB DC600M at 3504TBW. Does anyone know more solutions like these?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ecfvn", "is_robot_indexable": true, "report_reasons": null, "author": "hambopro", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ecfvn/highest_tbw_ssd_possible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ecfvn/highest_tbw_ssd_possible/", "subreddit_subscribers": 695583, "created_utc": 1690799602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m trying to figure out the easiest way to transfer data from my fathers WD MyCloud on his home network to my synology on my network. I was hoping to be able to plug it into my DS220+ via USB but that doesn\u2019t appear to be an option. It is a fair amount of files", "author_fullname": "t2_biovz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transferring data from a WD MyCloud on another network to my Synology DS220+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dz2y5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690757502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to figure out the easiest way to transfer data from my fathers WD MyCloud on his home network to my synology on my network. I was hoping to be able to plug it into my DS220+ via USB but that doesn\u2019t appear to be an option. It is a fair amount of files&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15dz2y5", "is_robot_indexable": true, "report_reasons": null, "author": "mmurp36", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15dz2y5/transferring_data_from_a_wd_mycloud_on_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15dz2y5/transferring_data_from_a_wd_mycloud_on_another/", "subreddit_subscribers": 695583, "created_utc": 1690757502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long story short I've settled on using with tape on windows for my archiving needs (Not backup).\n\nI'd like to use tape like a spanning volume. I can keep adding files to folders as the number of tapes increase the software just tells me what tape to put in to get that particular file. I won't be accessing the files often, hence the tape among other reasons. It seems like Hedge Canister ([https://hedge.video/canister](https://hedge.video/canister)) does this, but it's macOS only right now. It can keep a browsable DB of the tapes and can do spanning.\n\nIs there any windows software that can do this? I think preroll-post ([https://www.imagineproducts.com/product/preroll-post/windows](https://www.imagineproducts.com/product/preroll-post/windows)) can do the DB part but not the spanning part. Maybe I'm wrong.\n\nAre there any other good (windows) tape software options out there?\n\nThanks for the help!", "author_fullname": "t2_46qoa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Spanning Archive over LTO tape and DB software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15duob5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690746885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short I&amp;#39;ve settled on using with tape on windows for my archiving needs (Not backup).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to use tape like a spanning volume. I can keep adding files to folders as the number of tapes increase the software just tells me what tape to put in to get that particular file. I won&amp;#39;t be accessing the files often, hence the tape among other reasons. It seems like Hedge Canister (&lt;a href=\"https://hedge.video/canister\"&gt;https://hedge.video/canister&lt;/a&gt;) does this, but it&amp;#39;s macOS only right now. It can keep a browsable DB of the tapes and can do spanning.&lt;/p&gt;\n\n&lt;p&gt;Is there any windows software that can do this? I think preroll-post (&lt;a href=\"https://www.imagineproducts.com/product/preroll-post/windows\"&gt;https://www.imagineproducts.com/product/preroll-post/windows&lt;/a&gt;) can do the DB part but not the spanning part. Maybe I&amp;#39;m wrong.&lt;/p&gt;\n\n&lt;p&gt;Are there any other good (windows) tape software options out there?&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15duob5", "is_robot_indexable": true, "report_reasons": null, "author": "leprechaun7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15duob5/looking_for_spanning_archive_over_lto_tape_and_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15duob5/looking_for_spanning_archive_over_lto_tape_and_db/", "subreddit_subscribers": 695583, "created_utc": 1690746885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Device: MacBook Pro M1 Pro. Have Parallels for Windows if needed. a 1 TB HDD, a 2 TB HDD, 1 TB SSD, and a 5 TB HDD  \n\n\nI have a few hard drives that I hoard data in, they aren't constantly connected into my laptop, so I don't have immediate access to them whenever and wherever. I want to create an explorable interface (like an html index of directories maybe?) of all the files in the folders and subfolders in the drive. So that i don't need to connect the hard drive each time I just wanna check the contents of the files. Ideally, I'd want the file size to be indexed too, and not just the names of the files. And yes, it is all just TBs of porn, so if I get maybe video duration and maybe even resolution indexed, it'd be so great, but I understand that seems hard maybe.   \nI know how to create a filelist.txt from the terminal window on the mac. but i dont know of ways to take that index and make into an html GUI. I'd also maybe want it to update if and when I rename/delete/add files.   \n\n\nIs there any tool, or script that I could write, that lets me do all this? The update part is more important to me than the video duration and stuff. I'm new to data hoarding so I don't have too much technical know how of various tools and stuff yet.   \n", "author_fullname": "t2_6am88083", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Indexing and updating an index of all files and folders on a harddrive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e7ge1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690782669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Device: MacBook Pro M1 Pro. Have Parallels for Windows if needed. a 1 TB HDD, a 2 TB HDD, 1 TB SSD, and a 5 TB HDD  &lt;/p&gt;\n\n&lt;p&gt;I have a few hard drives that I hoard data in, they aren&amp;#39;t constantly connected into my laptop, so I don&amp;#39;t have immediate access to them whenever and wherever. I want to create an explorable interface (like an html index of directories maybe?) of all the files in the folders and subfolders in the drive. So that i don&amp;#39;t need to connect the hard drive each time I just wanna check the contents of the files. Ideally, I&amp;#39;d want the file size to be indexed too, and not just the names of the files. And yes, it is all just TBs of porn, so if I get maybe video duration and maybe even resolution indexed, it&amp;#39;d be so great, but I understand that seems hard maybe.&lt;br/&gt;\nI know how to create a filelist.txt from the terminal window on the mac. but i dont know of ways to take that index and make into an html GUI. I&amp;#39;d also maybe want it to update if and when I rename/delete/add files.   &lt;/p&gt;\n\n&lt;p&gt;Is there any tool, or script that I could write, that lets me do all this? The update part is more important to me than the video duration and stuff. I&amp;#39;m new to data hoarding so I don&amp;#39;t have too much technical know how of various tools and stuff yet.   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e7ge1", "is_robot_indexable": true, "report_reasons": null, "author": "BABASS222", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e7ge1/indexing_and_updating_an_index_of_all_files_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e7ge1/indexing_and_updating_an_index_of_all_files_and/", "subreddit_subscribers": 695583, "created_utc": 1690782669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a folder with roughly 1,000 smartphone images. The unfortunate bit is the metadata is different for each phone. One phone set a \"Date Taken\" field, one set a \"Date Modified\" field, and one set has \"Date Created\". Is there a way for me to consolodate the metadata into just one tag for easy windows sorting? Sorting by \"date\" takes forever whereas simply doing date modified takes way shorter.", "author_fullname": "t2_dkxm61mwa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Folder containing photos from 3 different phones. One set is date taken, one sets metadata is date modified, and one set is date created. How can I sort these properly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dyfiu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690755831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a folder with roughly 1,000 smartphone images. The unfortunate bit is the metadata is different for each phone. One phone set a &amp;quot;Date Taken&amp;quot; field, one set a &amp;quot;Date Modified&amp;quot; field, and one set has &amp;quot;Date Created&amp;quot;. Is there a way for me to consolodate the metadata into just one tag for easy windows sorting? Sorting by &amp;quot;date&amp;quot; takes forever whereas simply doing date modified takes way shorter.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15dyfiu", "is_robot_indexable": true, "report_reasons": null, "author": "karmoin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15dyfiu/folder_containing_photos_from_3_different_phones/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15dyfiu/folder_containing_photos_from_3_different_phones/", "subreddit_subscribers": 695583, "created_utc": 1690755831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone! I have a PC that I want to convert into a NAS. I bought 3x6TB HDDs to create a RAID 5 system. My question to yall is this, in the future I want to be able to setup another NAS at a friend's house to backup my files for ultimate redundancy/safeguard of files, what would be your recommendation for NAS programs? Would I be able to use Synology as my NAS program or does Synology only work with Synology NAS boxes?", "author_fullname": "t2_a5x4u6bj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DIY NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15eljoy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690822563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I have a PC that I want to convert into a NAS. I bought 3x6TB HDDs to create a RAID 5 system. My question to yall is this, in the future I want to be able to setup another NAS at a friend&amp;#39;s house to backup my files for ultimate redundancy/safeguard of files, what would be your recommendation for NAS programs? Would I be able to use Synology as my NAS program or does Synology only work with Synology NAS boxes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eljoy", "is_robot_indexable": true, "report_reasons": null, "author": "21stCenturyRetard", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eljoy/diy_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eljoy/diy_nas/", "subreddit_subscribers": 695583, "created_utc": 1690822563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I'm looking for a discord chat downloader for windows. A program that can download threads, and entire conversations.", "author_fullname": "t2_7n3bibna", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best discord chat exporter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e8tgl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690787435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m looking for a discord chat downloader for windows. A program that can download threads, and entire conversations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": true, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e8tgl", "is_robot_indexable": true, "report_reasons": null, "author": "Shadowlight888", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e8tgl/best_discord_chat_exporter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e8tgl/best_discord_chat_exporter/", "subreddit_subscribers": 695583, "created_utc": 1690787435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have this old Dell Studio XPS 9100 with two 2TB ST32000641AS drives which are about 13 years old. I went to look at the smart data on the main drive, but it only shows 6205 power on hours. I think it must've wrapped around because it's been on 24/7 for about 3 years, plus however many hours it had from previous decade. I haven't used the second drive for a few years (and it was used as an image backup drive so it was rarely used before), and it reads 66162 hours.\n\nIs there a way to find out what the real power on hours value is, maybe if someone knows what value it rolls over at?", "author_fullname": "t2_jjyxa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power on hours rollover on old Seagate Barracuda XT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dvj3s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690748891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have this old Dell Studio XPS 9100 with two 2TB ST32000641AS drives which are about 13 years old. I went to look at the smart data on the main drive, but it only shows 6205 power on hours. I think it must&amp;#39;ve wrapped around because it&amp;#39;s been on 24/7 for about 3 years, plus however many hours it had from previous decade. I haven&amp;#39;t used the second drive for a few years (and it was used as an image backup drive so it was rarely used before), and it reads 66162 hours.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to find out what the real power on hours value is, maybe if someone knows what value it rolls over at?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "2TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15dvj3s", "is_robot_indexable": true, "report_reasons": null, "author": "BBaoVanC", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15dvj3s/power_on_hours_rollover_on_old_seagate_barracuda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15dvj3s/power_on_hours_rollover_on_old_seagate_barracuda/", "subreddit_subscribers": 695583, "created_utc": 1690748891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two external hdds where I store infrequently used files. Let's call them Drive 1 and Drive 2. I want to transfer my 'more important' files to Drive 2, which is the newer of the two. The problem is that both drives are almost full which means I can't really transfer files from one drive to another. Is there any way that will transfer files directly from drive 1 to drive 2, as drive 2 transfers files to drive 1?", "author_fullname": "t2_avtzqkxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extremely dumb question about moving files between drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eiy5p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690816500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two external hdds where I store infrequently used files. Let&amp;#39;s call them Drive 1 and Drive 2. I want to transfer my &amp;#39;more important&amp;#39; files to Drive 2, which is the newer of the two. The problem is that both drives are almost full which means I can&amp;#39;t really transfer files from one drive to another. Is there any way that will transfer files directly from drive 1 to drive 2, as drive 2 transfers files to drive 1?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eiy5p", "is_robot_indexable": true, "report_reasons": null, "author": "officialfe", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eiy5p/extremely_dumb_question_about_moving_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eiy5p/extremely_dumb_question_about_moving_files/", "subreddit_subscribers": 695583, "created_utc": 1690816500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am an avid photographer and currently trying to figure out a solution for archival storage of digital photos. I don't have much data (probably around 50GB of photos that I need archival storage for) and I am trying to find a solution. I am currently looking into [forever.com](https://forever.com) which I can get 25GB of storage for $500 one time purchase. Platforms like Google Drive are much cheaper, but I would like to store my photos in a way for the next generation, not on a platform that will delete them if I don't log in for 2 years.\n\nI have been in two house fires, three home break-ins, and a car fire so the idea of an \"archival\" cloud data storage platform is very appealing to me because of the \"off-site\" aspect. My career path will necessitate being on the road a lot so being able to access my files via the internet is also appealing. Currently, my data is stored on external SSD drives onsite, and I am in the process of organizing it. My other idea for storage would be to burn my files to archival disks (M-Disks or Gold CDs) and put one copy in a safety deposit box at the bank. ", "author_fullname": "t2_anq99ucy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curious about possibly using forever.com for archival data storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ehkxp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690813338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am an avid photographer and currently trying to figure out a solution for archival storage of digital photos. I don&amp;#39;t have much data (probably around 50GB of photos that I need archival storage for) and I am trying to find a solution. I am currently looking into &lt;a href=\"https://forever.com\"&gt;forever.com&lt;/a&gt; which I can get 25GB of storage for $500 one time purchase. Platforms like Google Drive are much cheaper, but I would like to store my photos in a way for the next generation, not on a platform that will delete them if I don&amp;#39;t log in for 2 years.&lt;/p&gt;\n\n&lt;p&gt;I have been in two house fires, three home break-ins, and a car fire so the idea of an &amp;quot;archival&amp;quot; cloud data storage platform is very appealing to me because of the &amp;quot;off-site&amp;quot; aspect. My career path will necessitate being on the road a lot so being able to access my files via the internet is also appealing. Currently, my data is stored on external SSD drives onsite, and I am in the process of organizing it. My other idea for storage would be to burn my files to archival disks (M-Disks or Gold CDs) and put one copy in a safety deposit box at the bank. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?auto=webp&amp;s=65dbedcb068da581966f5196951c432c69971c1e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=edc01860d42dff717b5b11d3b962fdbd84116b43", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9159a7ec316c5ecb3c112dda0f9333ff1cab8ed", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1fe852d3a89892330da2a19011c0527f73d7cd5c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ef243569974ba06c9b70257be7dd0439d08791b7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f074ede3445e0abee23f5a1a7ff388c3d8a46100", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ffbfdde4cf737a6123c36c57b523e673c0ab1812", "width": 1080, "height": 540}], "variants": {}, "id": "3SlCuZWYt-8SZVmQaJ7_HkK995EvwU_V0EJxSNJX8dA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ehkxp", "is_robot_indexable": true, "report_reasons": null, "author": "RadioOperator73", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ehkxp/curious_about_possibly_using_forevercom_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ehkxp/curious_about_possibly_using_forevercom_for/", "subreddit_subscribers": 695583, "created_utc": 1690813338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unifi Video Downloads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ea18c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_lxpfqyl", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Ubiquiti", "selftext": "Back when Ubiquiti discontinued Unifi Video in favor of Unifi Protect, I noticed that they have removed the downloads for anything related to Unifi Video.  I have kept some of the files for it, and thought it would be a good idea to share them with others.  I would only suggest you use this if you have a serious reason to use Unifi Video, as Unifi Protect is better in most ways, and is currently supported.  All of the software that I have listed below is obsolete and does not receive updates.\n\nUnifi Video server for Windows 3.10.13 (latest):  [https://drive.google.com/file/d/1sNBgsCluUmQZapw7CGBuxHACRwcuteI-/view?usp=sharing](https://drive.google.com/file/d/1sNBgsCluUmQZapw7CGBuxHACRwcuteI-/view?usp=sharing)\n\nYou will need an older version of Java for this to work,  I have a copy of JDK 8u202 here.  Just install the Java runtime, you won't need anything else bundled with this installer.\n\nJDK 8u202 for Windows:  [https://drive.google.com/file/d/1qtbhUsPgSyfkxZChUjCNGV3OwgNnfYsq/view?usp=sharing](https://drive.google.com/file/d/1qtbhUsPgSyfkxZChUjCNGV3OwgNnfYsq/view?usp=sharing)\n\nI have noticed that they removed the Android app from the Google Play Store, and I have an .APK for the latest version of that too.\n\nUnifi Video for Android 1.3.6 (latest):  [https://drive.google.com/file/d/1jRM\\_Qmpp4W6DNIYf8NmTq4kiXbm0SA-e/view?usp=sharing](https://drive.google.com/file/d/1jRM_Qmpp4W6DNIYf8NmTq4kiXbm0SA-e/view?usp=sharing)\n\nUnifi Video is pretty good about automatically updating the firmware of your cameras once you adopt them, however if it doesn't, this is an older firmware for the UVC-G3 camera.\n\nUVC-G3 4.4.2 firmware: [https://drive.google.com/file/d/1Dv32OLeKBirNGQAmnBtMLtCTV6WLD0m\\_/view?usp=sharing](https://drive.google.com/file/d/1Dv32OLeKBirNGQAmnBtMLtCTV6WLD0m_/view?usp=sharing)\n\n&amp;#x200B;\n\nI have an older version of the Unifi Video server for Windows (v3.9.12), so if you need that just reply to this post and I will upload it.  I don't see any reason why anyone would want that so I left it out of this post.  If anyone has anymore Unifi Video downloads, please post them in the comments as it may help someone else out!", "author_fullname": "t2_2kbmafor", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unifi Video Downloads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Ubiquiti", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dwlps", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "User Guide", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690751427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Ubiquiti", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Back when Ubiquiti discontinued Unifi Video in favor of Unifi Protect, I noticed that they have removed the downloads for anything related to Unifi Video.  I have kept some of the files for it, and thought it would be a good idea to share them with others.  I would only suggest you use this if you have a serious reason to use Unifi Video, as Unifi Protect is better in most ways, and is currently supported.  All of the software that I have listed below is obsolete and does not receive updates.&lt;/p&gt;\n\n&lt;p&gt;Unifi Video server for Windows 3.10.13 (latest):  &lt;a href=\"https://drive.google.com/file/d/1sNBgsCluUmQZapw7CGBuxHACRwcuteI-/view?usp=sharing\"&gt;https://drive.google.com/file/d/1sNBgsCluUmQZapw7CGBuxHACRwcuteI-/view?usp=sharing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You will need an older version of Java for this to work,  I have a copy of JDK 8u202 here.  Just install the Java runtime, you won&amp;#39;t need anything else bundled with this installer.&lt;/p&gt;\n\n&lt;p&gt;JDK 8u202 for Windows:  &lt;a href=\"https://drive.google.com/file/d/1qtbhUsPgSyfkxZChUjCNGV3OwgNnfYsq/view?usp=sharing\"&gt;https://drive.google.com/file/d/1qtbhUsPgSyfkxZChUjCNGV3OwgNnfYsq/view?usp=sharing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have noticed that they removed the Android app from the Google Play Store, and I have an .APK for the latest version of that too.&lt;/p&gt;\n\n&lt;p&gt;Unifi Video for Android 1.3.6 (latest):  &lt;a href=\"https://drive.google.com/file/d/1jRM_Qmpp4W6DNIYf8NmTq4kiXbm0SA-e/view?usp=sharing\"&gt;https://drive.google.com/file/d/1jRM_Qmpp4W6DNIYf8NmTq4kiXbm0SA-e/view?usp=sharing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Unifi Video is pretty good about automatically updating the firmware of your cameras once you adopt them, however if it doesn&amp;#39;t, this is an older firmware for the UVC-G3 camera.&lt;/p&gt;\n\n&lt;p&gt;UVC-G3 4.4.2 firmware: &lt;a href=\"https://drive.google.com/file/d/1Dv32OLeKBirNGQAmnBtMLtCTV6WLD0m_/view?usp=sharing\"&gt;https://drive.google.com/file/d/1Dv32OLeKBirNGQAmnBtMLtCTV6WLD0m_/view?usp=sharing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have an older version of the Unifi Video server for Windows (v3.9.12), so if you need that just reply to this post and I will upload it.  I don&amp;#39;t see any reason why anyone would want that so I left it out of this post.  If anyone has anymore Unifi Video downloads, please post them in the comments as it may help someone else out!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "57e37abc-5e15-11eb-a66a-0eed3683f38f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ub3z", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15dwlps", "is_robot_indexable": true, "report_reasons": null, "author": "Server_Room_Warrier", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Ubiquiti/comments/15dwlps/unifi_video_downloads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/Ubiquiti/comments/15dwlps/unifi_video_downloads/", "subreddit_subscribers": 158279, "created_utc": 1690751427.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1690791646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Ubiquiti", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/Ubiquiti/comments/15dwlps/unifi_video_downloads/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ea18c", "is_robot_indexable": true, "report_reasons": null, "author": "MOHdennisNL", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15dwlps", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ea18c/unifi_video_downloads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/Ubiquiti/comments/15dwlps/unifi_video_downloads/", "subreddit_subscribers": 695583, "created_utc": 1690791646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all.\n\nHas anyone used these cards?\n\nWhat is your impression ?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/5nfuvz103cfb1.png?width=717&amp;format=png&amp;auto=webp&amp;s=044916cdf2ba99ece91e589070f1716e3d8125fe\n\nhttps://preview.redd.it/zb4b31cy2cfb1.png?width=844&amp;format=png&amp;auto=webp&amp;s=9198d02ecc4ad076dedccac984a8903568f2e3ee\n\n&amp;#x200B;", "author_fullname": "t2_e3zlhbcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NVMe to Sata adapters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "media_metadata": {"5nfuvz103cfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5fc371fb6fa7a10f23866366437643397d381488"}, {"y": 160, "x": 216, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=85237aff1bfe7d0138899a80f9d991256d4bca5f"}, {"y": 237, "x": 320, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4152e63ac5eb7ea5b2623348a84d14a3ba0dbf8f"}, {"y": 475, "x": 640, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2a0b867e43672d4e503e5adafc280908856bdf16"}], "s": {"y": 533, "x": 717, "u": "https://preview.redd.it/5nfuvz103cfb1.png?width=717&amp;format=png&amp;auto=webp&amp;s=044916cdf2ba99ece91e589070f1716e3d8125fe"}, "id": "5nfuvz103cfb1"}, "zb4b31cy2cfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=44d9e3543bcea9d2d139f7154566a142b4a378fb"}, {"y": 154, "x": 216, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b040d01cdaeefcad1ee30e468063e600d621a8f6"}, {"y": 228, "x": 320, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=562eeb57aea3ae4cdb78cce438d401cfc19b9331"}, {"y": 456, "x": 640, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c470685d84427327c397e18b6fd99df2c0c49cf"}], "s": {"y": 602, "x": 844, "u": "https://preview.redd.it/zb4b31cy2cfb1.png?width=844&amp;format=png&amp;auto=webp&amp;s=9198d02ecc4ad076dedccac984a8903568f2e3ee"}, "id": "zb4b31cy2cfb1"}}, "name": "t3_15e23nu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/xpPYShOSJx0_ebFYGXRpwsKMxTTpy28X-21k9kpzPl4.jpg", "edited": 1690823716.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690765682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.&lt;/p&gt;\n\n&lt;p&gt;Has anyone used these cards?&lt;/p&gt;\n\n&lt;p&gt;What is your impression ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5nfuvz103cfb1.png?width=717&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=044916cdf2ba99ece91e589070f1716e3d8125fe\"&gt;https://preview.redd.it/5nfuvz103cfb1.png?width=717&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=044916cdf2ba99ece91e589070f1716e3d8125fe&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zb4b31cy2cfb1.png?width=844&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9198d02ecc4ad076dedccac984a8903568f2e3ee\"&gt;https://preview.redd.it/zb4b31cy2cfb1.png?width=844&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9198d02ecc4ad076dedccac984a8903568f2e3ee&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e23nu", "is_robot_indexable": true, "report_reasons": null, "author": "rob4ik92", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e23nu/nvme_to_sata_adapters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e23nu/nvme_to_sata_adapters/", "subreddit_subscribers": 695583, "created_utc": 1690765682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay,\n\nso i genuinly have no idea where to ask for help regarding my topic but i think this sub might comes the closest? (i looked for labeling, qr code, and stuff like that and didnt find a single freaking sub...)\n\n&amp;#x200B;\n\nBasically what i want: a local labeling system that works with JUST text. Basically i have a (several) label machines, but i want to make use of the ones that can just produce \"plain\" text.\n\nso my idea was to find an app or smth like that that would allow me to scan stings of text and then show info based on that text.\n\nexample:\n\n\\- Print \"3DP1-1\" (3DPrinter/Filament1/Color1)\n\n\\- take phone and scan\n\n\\- show Info with textbox (or small website) showing me further info (basically more text than whats practical to use on labels) and maybe a picture or smth\n\n&amp;#x200B;\n\nIs there anything that comes close to what im looking for, or is using \"advanced\" label makers my only option?\n\n&amp;#x200B;\n\nSorry if this is the wrong sub again. maybe if you know a better one, let me know :D", "author_fullname": "t2_15prbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Label System that works with text strings?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dt4kg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690743019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay,&lt;/p&gt;\n\n&lt;p&gt;so i genuinly have no idea where to ask for help regarding my topic but i think this sub might comes the closest? (i looked for labeling, qr code, and stuff like that and didnt find a single freaking sub...)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basically what i want: a local labeling system that works with JUST text. Basically i have a (several) label machines, but i want to make use of the ones that can just produce &amp;quot;plain&amp;quot; text.&lt;/p&gt;\n\n&lt;p&gt;so my idea was to find an app or smth like that that would allow me to scan stings of text and then show info based on that text.&lt;/p&gt;\n\n&lt;p&gt;example:&lt;/p&gt;\n\n&lt;p&gt;- Print &amp;quot;3DP1-1&amp;quot; (3DPrinter/Filament1/Color1)&lt;/p&gt;\n\n&lt;p&gt;- take phone and scan&lt;/p&gt;\n\n&lt;p&gt;- show Info with textbox (or small website) showing me further info (basically more text than whats practical to use on labels) and maybe a picture or smth&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there anything that comes close to what im looking for, or is using &amp;quot;advanced&amp;quot; label makers my only option?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is the wrong sub again. maybe if you know a better one, let me know :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15dt4kg", "is_robot_indexable": true, "report_reasons": null, "author": "maxz-Reddit", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15dt4kg/label_system_that_works_with_text_strings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15dt4kg/label_system_that_works_with_text_strings/", "subreddit_subscribers": 695583, "created_utc": 1690743019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi , I Want a Drive To Store My Pics and Videos and Old memories . I usually backup to the Drive Once everymonth . I been using Hdd for that. and now its really slow and almost 8 yrs Old , I did a lot research and even read many posts on this sub but still Cant bring myself to Conclusion to get a External  SSD or HDD. Hdd is slow but might be reliable . ssd are fast but i read that they are limited to write cycles . I have almost 250gb of files . SanDisk extreme ssd are failing a lot as im seeing reviews of them online . Samsung is good but i dont know weather to choose which one. Which would be better to store and use it like once or twice in a month. but i want that to last minimum 5 yrs . Please help me out . My seagate hardrive lasted long . but now due to many files it has become slow and i think its health is at 20% something and might fail anytime. What should i do?", "author_fullname": "t2_3hvwm2h1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Shall I buy for my Backup storage ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eava1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690794484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi , I Want a Drive To Store My Pics and Videos and Old memories . I usually backup to the Drive Once everymonth . I been using Hdd for that. and now its really slow and almost 8 yrs Old , I did a lot research and even read many posts on this sub but still Cant bring myself to Conclusion to get a External  SSD or HDD. Hdd is slow but might be reliable . ssd are fast but i read that they are limited to write cycles . I have almost 250gb of files . SanDisk extreme ssd are failing a lot as im seeing reviews of them online . Samsung is good but i dont know weather to choose which one. Which would be better to store and use it like once or twice in a month. but i want that to last minimum 5 yrs . Please help me out . My seagate hardrive lasted long . but now due to many files it has become slow and i think its health is at 20% something and might fail anytime. What should i do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eava1", "is_robot_indexable": true, "report_reasons": null, "author": "Manish_mayu", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eava1/what_shall_i_buy_for_my_backup_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eava1/what_shall_i_buy_for_my_backup_storage/", "subreddit_subscribers": 695583, "created_utc": 1690794484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im running two Seagate Exos 20TB drives in my workstation PC for data backup in a windows raid 1 configuration. \n\nWhen i first installed them, they were pretty loud during startup and reads/writes, but i supposed that is something to be expected with a server grade hard drive, even though they are still pretty damm loud compared to the barracudas i used before. Now one of them keeps making a periodic \"tck\" noise about every half second. Is this a sign of a failing/damaged drive? I have them only for about 2 weeks, so I would like to get them replaced before anything bad happens. I can record the sounds and upload them if that helps. TIA.", "author_fullname": "t2_uego8iv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos 20TB Drive making a periodic clicking sound.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e9jz4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690790088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im running two Seagate Exos 20TB drives in my workstation PC for data backup in a windows raid 1 configuration. &lt;/p&gt;\n\n&lt;p&gt;When i first installed them, they were pretty loud during startup and reads/writes, but i supposed that is something to be expected with a server grade hard drive, even though they are still pretty damm loud compared to the barracudas i used before. Now one of them keeps making a periodic &amp;quot;tck&amp;quot; noise about every half second. Is this a sign of a failing/damaged drive? I have them only for about 2 weeks, so I would like to get them replaced before anything bad happens. I can record the sounds and upload them if that helps. TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e9jz4", "is_robot_indexable": true, "report_reasons": null, "author": "DeadlyPants02", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e9jz4/seagate_exos_20tb_drive_making_a_periodic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e9jz4/seagate_exos_20tb_drive_making_a_periodic/", "subreddit_subscribers": 695583, "created_utc": 1690790088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Suddenly after a year of use, it got super laggy after bunch of write, the disk free is still 1.6TB out of 8TB, it feels like my old SMR harddisk that I used in the past that got super laggy after huge write.", "author_fullname": "t2_7bbojdkz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Seagate Backup+ Hub BK (D785) SMR?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15dx4ag", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690752648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Suddenly after a year of use, it got super laggy after bunch of write, the disk free is still 1.6TB out of 8TB, it feels like my old SMR harddisk that I used in the past that got super laggy after huge write.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15dx4ag", "is_robot_indexable": true, "report_reasons": null, "author": "kokizzu2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15dx4ag/is_seagate_backup_hub_bk_d785_smr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15dx4ag/is_seagate_backup_hub_bk_d785_smr/", "subreddit_subscribers": 695583, "created_utc": 1690752648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am 'backing up my multiple reddit user profiles' using a bespoke app, and have noticed recently that .gif images seem to have become a popular format amongst files I have downloaded from reddit using this app.\n\nThese '.gif's are not gifs though - they seem to be mp4/webm encapsulated within a .gif mime type, the issue with this being that attempting to download the video by direct hotlink to the media results in reddit serving me (very slowly) an ENORMOUS .gif file. Quite often files over 80Mb each, and including reposts on the same profile, this has become burdensome.\n\nI am assuming that the underlying media is not actually a .gif, and that every page load (that loads the media instantly) is not serving an 80Mb file.\n\nHas anyone found a way to access alternate streams with better compression/alternate bitrates via URL? Anyone else encountering this issue? I have explored the requests the page is making and have not found any alternate streams in either the requests or the page source, certainly nothing that I have been able to be served.\n\n(nsfw sample media link: https://i.redd.it/sfu0z7ng4afb1.gif)", "author_fullname": "t2_5hf9geng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit .gif's download as alternate media formats", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ekck6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690819738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am &amp;#39;backing up my multiple reddit user profiles&amp;#39; using a bespoke app, and have noticed recently that .gif images seem to have become a popular format amongst files I have downloaded from reddit using this app.&lt;/p&gt;\n\n&lt;p&gt;These &amp;#39;.gif&amp;#39;s are not gifs though - they seem to be mp4/webm encapsulated within a .gif mime type, the issue with this being that attempting to download the video by direct hotlink to the media results in reddit serving me (very slowly) an ENORMOUS .gif file. Quite often files over 80Mb each, and including reposts on the same profile, this has become burdensome.&lt;/p&gt;\n\n&lt;p&gt;I am assuming that the underlying media is not actually a .gif, and that every page load (that loads the media instantly) is not serving an 80Mb file.&lt;/p&gt;\n\n&lt;p&gt;Has anyone found a way to access alternate streams with better compression/alternate bitrates via URL? Anyone else encountering this issue? I have explored the requests the page is making and have not found any alternate streams in either the requests or the page source, certainly nothing that I have been able to be served.&lt;/p&gt;\n\n&lt;p&gt;(nsfw sample media link: &lt;a href=\"https://i.redd.it/sfu0z7ng4afb1.gif\"&gt;https://i.redd.it/sfu0z7ng4afb1.gif&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?format=png8&amp;s=6d80e1cdcc35afee15a5ec532610e71265f63e6e", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=ada1e75bfbcf0f43dfd9da50a4e3cc5c932537e6", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=77941a3932f847b6fb32544e1b1dbc97c962ee21", "width": 216, "height": 383}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?blur=40&amp;format=png8&amp;s=041c356553278ab2358e52e34f9754337688b0ad", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;crop=smart&amp;blur=10&amp;format=png8&amp;s=0e51e5cbc607a192849198a353f8496b344039b7", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;crop=smart&amp;blur=21&amp;format=png8&amp;s=80c5785785bce636e38b9223e5317e5aba59ddd8", "width": 216, "height": 383}]}, "gif": {"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?s=f2e893a1abfda732de70a7d1fcf1d49cd22bef6b", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;crop=smart&amp;s=74b39313035c1acbd158460b4129bde8edbc5d31", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;crop=smart&amp;s=1f2cca793c88f744873bf5858af7679eb304092a", "width": 216, "height": 383}]}, "mp4": {"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?format=mp4&amp;s=95433b7bdbac47e6af7a365304a62941f5a7113b", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;format=mp4&amp;s=e157134d17fe57c14da6656496a213f70e729911", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;format=mp4&amp;s=69feb3b691a446f85b8c840d2477123a4454b283", "width": 216, "height": 383}]}, "nsfw": {"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?blur=40&amp;format=png8&amp;s=041c356553278ab2358e52e34f9754337688b0ad", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;crop=smart&amp;blur=10&amp;format=png8&amp;s=0e51e5cbc607a192849198a353f8496b344039b7", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;crop=smart&amp;blur=21&amp;format=png8&amp;s=80c5785785bce636e38b9223e5317e5aba59ddd8", "width": 216, "height": 383}]}}, "id": "mtv6LEXuc8TTQv-0c4HKyooYkhFKGFp0Qs3-NHuDM6A"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ekck6", "is_robot_indexable": true, "report_reasons": null, "author": "far_kurnell", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ekck6/reddit_gifs_download_as_alternate_media_formats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ekck6/reddit_gifs_download_as_alternate_media_formats/", "subreddit_subscribers": 695583, "created_utc": 1690819738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just set up an Asustor 4 bay NAS with 4 Ironwolf Pro 16TB drives. This thing was loud as hell, scraping and buzzing. When building the RAID I thought it was just loud then, but when it was ready and I was copying files, no change. My old Buffalo with 4x3TB disks is practically silent compated to it. Is it normal for those to be so loud?", "author_fullname": "t2_10fiz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "16TB Ironwolf Pro very loud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e9j2r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690789996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just set up an Asustor 4 bay NAS with 4 Ironwolf Pro 16TB drives. This thing was loud as hell, scraping and buzzing. When building the RAID I thought it was just loud then, but when it was ready and I was copying files, no change. My old Buffalo with 4x3TB disks is practically silent compated to it. Is it normal for those to be so loud?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15e9j2r", "is_robot_indexable": true, "report_reasons": null, "author": "Boogertwilliams", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15e9j2r/16tb_ironwolf_pro_very_loud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15e9j2r/16tb_ironwolf_pro_very_loud/", "subreddit_subscribers": 695583, "created_utc": 1690789996.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}