{"kind": "Listing", "data": {"after": "t3_14yryax", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a Data Engineer what\u2019s your biggest headache, frustration, time suck?", "author_fullname": "t2_3cr575ib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Headaches", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z3dvp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689300344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a Data Engineer what\u2019s your biggest headache, frustration, time suck?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z3dvp", "is_robot_indexable": true, "report_reasons": null, "author": "jayking51", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z3dvp/data_engineering_headaches/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z3dvp/data_engineering_headaches/", "subreddit_subscribers": 115737, "created_utc": 1689300344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few months ago I changed from data scientist to engineer, since in my previous company I did everything myself, but being a CS guy I pref the data engineering part.\n\nIn my current company, a multinational telecommunications, I only do SQL queries and stupid dashboards for marketing and business, I feel frustrated because anyone can do this\u2026  And it has little to do with the Data Engineer role that I was offered.\n\nHow much do you use SQL in your daily work ?", "author_fullname": "t2_4kdegv81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL only - Work frustration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z8hhn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689315999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months ago I changed from data scientist to engineer, since in my previous company I did everything myself, but being a CS guy I pref the data engineering part.&lt;/p&gt;\n\n&lt;p&gt;In my current company, a multinational telecommunications, I only do SQL queries and stupid dashboards for marketing and business, I feel frustrated because anyone can do this\u2026  And it has little to do with the Data Engineer role that I was offered.&lt;/p&gt;\n\n&lt;p&gt;How much do you use SQL in your daily work ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z8hhn", "is_robot_indexable": true, "report_reasons": null, "author": "xchgre", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z8hhn/sql_only_work_frustration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z8hhn/sql_only_work_frustration/", "subreddit_subscribers": 115737, "created_utc": 1689315999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As opposed to other people who asked about no-code/low-code/ GUI-based tools, I want a list of tools which actually require to write code and schedules for data movement.I am very new to all this. I'm currently working as Power BI developer in a company but want to do Data Engineering and ETL stuff in near future.\n\nI read that Informatica and Talend are all GUI-based tools which is not good for long run growth and learning.\n\nEDIT:\n\nThank You everyone for such great input. This just made my day. I think I have alot to learn ahead. After all your comments, I feel like I haven't even scratched the surface.\n\nPlease if anyone of you can share a roadmap. I really need to get in ETL and DE, and soon.\n\nNote: I have 1 year or 1.5 years max to switch and I need it to be ETL or DE job where I could do all this what you guys mentioned in comments.", "author_fullname": "t2_3k9gevl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List of / Suggestion for Code based ETL Tools.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yl2vw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689314853.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689255334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As opposed to other people who asked about no-code/low-code/ GUI-based tools, I want a list of tools which actually require to write code and schedules for data movement.I am very new to all this. I&amp;#39;m currently working as Power BI developer in a company but want to do Data Engineering and ETL stuff in near future.&lt;/p&gt;\n\n&lt;p&gt;I read that Informatica and Talend are all GUI-based tools which is not good for long run growth and learning.&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;Thank You everyone for such great input. This just made my day. I think I have alot to learn ahead. After all your comments, I feel like I haven&amp;#39;t even scratched the surface.&lt;/p&gt;\n\n&lt;p&gt;Please if anyone of you can share a roadmap. I really need to get in ETL and DE, and soon.&lt;/p&gt;\n\n&lt;p&gt;Note: I have 1 year or 1.5 years max to switch and I need it to be ETL or DE job where I could do all this what you guys mentioned in comments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yl2vw", "is_robot_indexable": true, "report_reasons": null, "author": "Pillstyr", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yl2vw/list_of_suggestion_for_code_based_etl_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yl2vw/list_of_suggestion_for_code_based_etl_tools/", "subreddit_subscribers": 115737, "created_utc": 1689255334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The streaming world is dominated by Java based tools like Kafka and Flink but most data scientists live in MATLAB, R, and Python notebooks. I'm curious how y'all collaborate with data scientists in these situations, especially when you want to embed some domain specific data logic / transformation?\n\n\\- Do they write data transformations / build models in their native language and throw it over the wall to you?\n\n\\- Do they learn your toolchain?", "author_fullname": "t2_6khnrfh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you collaborate with notebook savvy data scientists on streaming data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ypog3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689266335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The streaming world is dominated by Java based tools like Kafka and Flink but most data scientists live in MATLAB, R, and Python notebooks. I&amp;#39;m curious how y&amp;#39;all collaborate with data scientists in these situations, especially when you want to embed some domain specific data logic / transformation?&lt;/p&gt;\n\n&lt;p&gt;- Do they write data transformations / build models in their native language and throw it over the wall to you?&lt;/p&gt;\n\n&lt;p&gt;- Do they learn your toolchain?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ypog3", "is_robot_indexable": true, "report_reasons": null, "author": "semicausal", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ypog3/how_do_you_collaborate_with_notebook_savvy_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ypog3/how_do_you_collaborate_with_notebook_savvy_data/", "subreddit_subscribers": 115737, "created_utc": 1689266335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Facing a potential layoff soon, so have started applying to some data engineer, jr data engineer and analytics engineer positions. I thought I'd put a project up on github so any HM could see a bit of my skills. If you saw this and actually looked through it, what would you think?\n\n[https://github.com/jrey999/mlb](https://github.com/jrey999/mlb)", "author_fullname": "t2_v4s5fwgd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you saw this and actually looked through it, what would you think", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z582e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689305728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Facing a potential layoff soon, so have started applying to some data engineer, jr data engineer and analytics engineer positions. I thought I&amp;#39;d put a project up on github so any HM could see a bit of my skills. If you saw this and actually looked through it, what would you think?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/jrey999/mlb\"&gt;https://github.com/jrey999/mlb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?auto=webp&amp;s=f23cd95bd53dfe4d4782e84979e0b6b62d084129", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a3709fc1236118224429386fed0b00f235baf0a2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=45ae7c8e42e8f1b6bd02486b081cc4056b35f870", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ab7afb2fabfb98da681c7ddf4639747d1c14d8d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=adbfb6983d38667cc57a25c401ea92acc4adaf10", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5882b19e3647675aee89370079a541eb94210638", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c01dcaee91410f53051d02152cc9c3ce4b8fdcc", "width": 1080, "height": 540}], "variants": {}, "id": "ZTkos4tP2WpR9wFxhobnnfq39iPZLNNBaB0u--0xAy0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "14z582e", "is_robot_indexable": true, "report_reasons": null, "author": "big_lazerz", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z582e/if_you_saw_this_and_actually_looked_through_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z582e/if_you_saw_this_and_actually_looked_through_it/", "subreddit_subscribers": 115737, "created_utc": 1689305728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have worked as a software engineer and I am now on my second data engineering position. As time marches on it seems that I am fighting a losing battle trying to implement automated logic tests for SQL testing.\n\nAs a software engineer I wrote tests to validate that for input x I would get output y and then make sure all the edge cases were covered. I have worked on data warehouse projects that used a similar \"unit test approach\": load a test data set into the database and verify the result of some sql. When I moved into doing work in a data science department we used Spark to mock out data frames and test the output of an operation.\n\nHowever this does not seem to be how the industry as a whole handles things. It seems that teams test the general shape of some transform logic such as row counts or if a value falls within a range. I am curious what other folks impressions are (not just your team, but data engineering as a whole)?\n\nOn a side note: I read articles like [https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc](https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc) which makes me think people are testing transforms, but then I see polls like this [https://www.jetbrains.com/lp/devecosystem-2021/databases/](https://www.jetbrains.com/lp/devecosystem-2021/databases/) that indicate people don't really test.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_3j0if", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Testing: a loosing battle?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ywjwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689282451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have worked as a software engineer and I am now on my second data engineering position. As time marches on it seems that I am fighting a losing battle trying to implement automated logic tests for SQL testing.&lt;/p&gt;\n\n&lt;p&gt;As a software engineer I wrote tests to validate that for input x I would get output y and then make sure all the edge cases were covered. I have worked on data warehouse projects that used a similar &amp;quot;unit test approach&amp;quot;: load a test data set into the database and verify the result of some sql. When I moved into doing work in a data science department we used Spark to mock out data frames and test the output of an operation.&lt;/p&gt;\n\n&lt;p&gt;However this does not seem to be how the industry as a whole handles things. It seems that teams test the general shape of some transform logic such as row counts or if a value falls within a range. I am curious what other folks impressions are (not just your team, but data engineering as a whole)?&lt;/p&gt;\n\n&lt;p&gt;On a side note: I read articles like &lt;a href=\"https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc\"&gt;https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc&lt;/a&gt; which makes me think people are testing transforms, but then I see polls like this &lt;a href=\"https://www.jetbrains.com/lp/devecosystem-2021/databases/\"&gt;https://www.jetbrains.com/lp/devecosystem-2021/databases/&lt;/a&gt; that indicate people don&amp;#39;t really test.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?auto=webp&amp;s=d89a17b05c97281fdd6453dd599945fcd7336b51", "width": 1005, "height": 444}, "resolutions": [{"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e64df404a8a381f61dba9b394f45d66d2547dcc3", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42e227a370404b011573e86f3dfe060ce05c42c2", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=45c6aabe350b41595aa55f72de51cc2cd7d9642a", "width": 320, "height": 141}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9d006f825a0b89e3e1524059d5ff1f6de8c6f2c", "width": 640, "height": 282}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=21f0334d6bb2c2fcc573a1f64aaa8bd05c5689c5", "width": 960, "height": 424}], "variants": {}, "id": "6c4F5f_MtX1XvNBav9lGrhcENIY60PGLA8mRkZf-GFo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ywjwa", "is_robot_indexable": true, "report_reasons": null, "author": "jaynerd", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ywjwa/sql_testing_a_loosing_battle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ywjwa/sql_testing_a_loosing_battle/", "subreddit_subscribers": 115737, "created_utc": 1689282451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I love cbt. I finally get the fuss now.\n\nBack in the olden days, I'd just dump all of my pandas/polars tasks in one compact jupyter notebook, download it all as a .py file, and call it a day. I genuinely thought that was better and more compact.\n\nBut now after using dbt for the first time, I can sort of see its usefulness. I rewrote the pandas stuff as a chain of CTE statements and breaking them up into different, consecutive SQL files. It really forces you to view things more modular, and while SQL can't do as much stuff as python, I gotta agree that it's overall cleaner to read, even as someone who was taught Python before SQL and thus feels biased for Python.\n\nThe only thing I don't know how to exactly do yet is interrupt the dbt midway to do something only python can do, or rather something SQL can't do (like adding columns that are the output of a machine learning method such as k-means, tf-idf, or PCA), and then resuming the dbt.", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After balking for a long time, tried out dbt for the first time and now am a full convert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z9id2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689319474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I love cbt. I finally get the fuss now.&lt;/p&gt;\n\n&lt;p&gt;Back in the olden days, I&amp;#39;d just dump all of my pandas/polars tasks in one compact jupyter notebook, download it all as a .py file, and call it a day. I genuinely thought that was better and more compact.&lt;/p&gt;\n\n&lt;p&gt;But now after using dbt for the first time, I can sort of see its usefulness. I rewrote the pandas stuff as a chain of CTE statements and breaking them up into different, consecutive SQL files. It really forces you to view things more modular, and while SQL can&amp;#39;t do as much stuff as python, I gotta agree that it&amp;#39;s overall cleaner to read, even as someone who was taught Python before SQL and thus feels biased for Python.&lt;/p&gt;\n\n&lt;p&gt;The only thing I don&amp;#39;t know how to exactly do yet is interrupt the dbt midway to do something only python can do, or rather something SQL can&amp;#39;t do (like adding columns that are the output of a machine learning method such as k-means, tf-idf, or PCA), and then resuming the dbt.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z9id2", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z9id2/after_balking_for_a_long_time_tried_out_dbt_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z9id2/after_balking_for_a_long_time_tried_out_dbt_for/", "subreddit_subscribers": 115737, "created_utc": 1689319474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello Everyone! \n\nWhat are the AWS alerting and notification best practices. While we've covered the basics in the current org where we get a notification on every failure, plain email saying the job is failed. We would like to have a thought process to see what is best in \n\n&amp;#x200B;\n\n How have you expanded your AWS alerts beyond job failures?    \n Have you utilized Amazon SES to deliver timely notifications? how you have optimized the failed emails  \n How have you leveraged AWS Glue and Lambda to automate your alerting process? \n\n For those who have integrated PagerDuty within their AWS infrastructure  \n\n&amp;#x200B;\n\nwhat is the best enterprise-level strategy for alerting and notifications?", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Alerting and Notification Best Practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z2ieu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689297884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone! &lt;/p&gt;\n\n&lt;p&gt;What are the AWS alerting and notification best practices. While we&amp;#39;ve covered the basics in the current org where we get a notification on every failure, plain email saying the job is failed. We would like to have a thought process to see what is best in &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How have you expanded your AWS alerts beyond job failures?&lt;br/&gt;\n Have you utilized Amazon SES to deliver timely notifications? how you have optimized the failed emails&lt;br/&gt;\n How have you leveraged AWS Glue and Lambda to automate your alerting process? &lt;/p&gt;\n\n&lt;p&gt;For those who have integrated PagerDuty within their AWS infrastructure  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;what is the best enterprise-level strategy for alerting and notifications?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z2ieu", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z2ieu/aws_alerting_and_notification_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z2ieu/aws_alerting_and_notification_best_practices/", "subreddit_subscribers": 115737, "created_utc": 1689297884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey yall, so I had a couple questions,\n\nToday I decided to try and work on my courera app. I currently work at Tesla and, honestly, im not happy with it. It's good and all but there's no challenge. I'm working on going back to community college to get a transferable mechanical engineering degree, but I'm exploring my options.\nI came upon the Data engineering certification and I was wondering, if it's JUST a certification, can I do much with that? I've always had a soft spot for programming and computer science, ngl, I've had it rough and never had the ability to completely apply myself in college. Now, I think I actually can and I feel like this would be useful to have in my tool belt, but, I ask again, is there actual application to an IBM data engineer certification?", "author_fullname": "t2_4mjgvza0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ymvb3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689259713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey yall, so I had a couple questions,&lt;/p&gt;\n\n&lt;p&gt;Today I decided to try and work on my courera app. I currently work at Tesla and, honestly, im not happy with it. It&amp;#39;s good and all but there&amp;#39;s no challenge. I&amp;#39;m working on going back to community college to get a transferable mechanical engineering degree, but I&amp;#39;m exploring my options.\nI came upon the Data engineering certification and I was wondering, if it&amp;#39;s JUST a certification, can I do much with that? I&amp;#39;ve always had a soft spot for programming and computer science, ngl, I&amp;#39;ve had it rough and never had the ability to completely apply myself in college. Now, I think I actually can and I feel like this would be useful to have in my tool belt, but, I ask again, is there actual application to an IBM data engineer certification?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ymvb3", "is_robot_indexable": true, "report_reasons": null, "author": "prototypefish72", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ymvb3/data_engineering_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ymvb3/data_engineering_certification/", "subreddit_subscribers": 115737, "created_utc": 1689259713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im looking to get a general idea of the spark ecosystem and fundamentals because at our company we are using a custom made abstraction above \"Apache Spark\". A lot of concepts are mapped 1:1.  Mainly for ETL purposes (data processing etc)\n\nAny idea's suggestions? by reading books, tutorials etc", "author_fullname": "t2_dr0lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn apache spark as a beginner/junior/new grad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ysuu6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689273837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im looking to get a general idea of the spark ecosystem and fundamentals because at our company we are using a custom made abstraction above &amp;quot;Apache Spark&amp;quot;. A lot of concepts are mapped 1:1.  Mainly for ETL purposes (data processing etc)&lt;/p&gt;\n\n&lt;p&gt;Any idea&amp;#39;s suggestions? by reading books, tutorials etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ysuu6", "is_robot_indexable": true, "report_reasons": null, "author": "poepstinktvies", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ysuu6/how_to_learn_apache_spark_as_a_beginnerjuniornew/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ysuu6/how_to_learn_apache_spark_as_a_beginnerjuniornew/", "subreddit_subscribers": 115737, "created_utc": 1689273837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I have an economics degree and currently work as a business analyst. I\u2019m also doing an online MS Applied Statistics. Originally my goal was to become a data scientist, but I\u2019ve realized I prefer working with databases, ETL, data modeling and python more than statistics so now I am leaning more towards data engineering. I\u2019m 3 classes into the degree and have 7 left to graduate in Fall 2025. \nShould I continue with this degree or instead do the BS CS at WGU? All of my gen eds will transfer so I\u2019ll only have to take the core CS classes.", "author_fullname": "t2_5uz2eb6mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MS Applied Statistics or BS Computer Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ymve2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689259719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I have an economics degree and currently work as a business analyst. I\u2019m also doing an online MS Applied Statistics. Originally my goal was to become a data scientist, but I\u2019ve realized I prefer working with databases, ETL, data modeling and python more than statistics so now I am leaning more towards data engineering. I\u2019m 3 classes into the degree and have 7 left to graduate in Fall 2025. \nShould I continue with this degree or instead do the BS CS at WGU? All of my gen eds will transfer so I\u2019ll only have to take the core CS classes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ymve2", "is_robot_indexable": true, "report_reasons": null, "author": "abc__901", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ymve2/ms_applied_statistics_or_bs_computer_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ymve2/ms_applied_statistics_or_bs_computer_science/", "subreddit_subscribers": 115737, "created_utc": 1689259719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use Git Flow in our company. \nThe Develop branch is cloned to creature the Feature branch.\nIn Feature branch we add additional features and all testing (unit, integration, uat) happens in this branch. Once approved, we merge this back to Develop. Then release branch is created from Develop and merged into Prod without any testing.\n\nSo my question is, do we need to perform additional testing in Release branch?", "author_fullname": "t2_gzg678i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Test in Feature or Release branch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z9r5g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689320347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use Git Flow in our company. \nThe Develop branch is cloned to creature the Feature branch.\nIn Feature branch we add additional features and all testing (unit, integration, uat) happens in this branch. Once approved, we merge this back to Develop. Then release branch is created from Develop and merged into Prod without any testing.&lt;/p&gt;\n\n&lt;p&gt;So my question is, do we need to perform additional testing in Release branch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14z9r5g", "is_robot_indexable": true, "report_reasons": null, "author": "ryandane123", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z9r5g/test_in_feature_or_release_branch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z9r5g/test_in_feature_or_release_branch/", "subreddit_subscribers": 115737, "created_utc": 1689320347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all  \nI am seeking advice and suggestions regarding an ELT workflow that my team has been implementing using BigQuery and Spark. I have encountered some challenges and would greatly appreciate the insights of this community.\n\nCurrently, I am using BigQuery for our ELT work, but the cost has been significant due to the rapid increase in data volume. To explore cost reduction options, my team decided to explore Dataproc. Our approach involves exporting BigQuery data to Google Cloud Storage (which is free up to 10TB per day), running a Spark job using the same query as in BigQuery (making it Spark compatible), writing the output DataFrame to GCS, and finally ingesting the data into a table (which is also free).\n\nHowever on doing this, I have observed two peculiar issues that I am struggling to resolve. Firstly, the BigQuery export process generates files of varying sizes, resulting in a large number of small files. This seems to significantly slow down the Spark job. Secondly, during a test job where the total size of input tables was around 300GB, I noticed that the YARN pending memory started at 2TB as shown on dashboard and kept decreasing as the job progressed. I am perplexed as to why the YARN pending memory would be 2TB for a dataset of just a few hundred gigabytes.\n\nGiven these challenges, I am seeking advice from the community. If any of you have attempted a similar workflow or encountered similar issues, I would like to hear about your experiences and the results you achieved. Did you optimize the BigQuery export process to avoid the problem of numerous small files? Do you believe the method of running spark jobs via above mentioned way is appropriate, or would you recommend any changes to improve the Spark job performance? Are there any specific optimizations or best practices you would recommend for Spark jobs?\n\nAny advice or suggestions you can provide would be highly appreciated. Thanks a lot in advance.", "author_fullname": "t2_cu6opso3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small file problem on spark in GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z7y9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689314250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;br/&gt;\nI am seeking advice and suggestions regarding an ELT workflow that my team has been implementing using BigQuery and Spark. I have encountered some challenges and would greatly appreciate the insights of this community.&lt;/p&gt;\n\n&lt;p&gt;Currently, I am using BigQuery for our ELT work, but the cost has been significant due to the rapid increase in data volume. To explore cost reduction options, my team decided to explore Dataproc. Our approach involves exporting BigQuery data to Google Cloud Storage (which is free up to 10TB per day), running a Spark job using the same query as in BigQuery (making it Spark compatible), writing the output DataFrame to GCS, and finally ingesting the data into a table (which is also free).&lt;/p&gt;\n\n&lt;p&gt;However on doing this, I have observed two peculiar issues that I am struggling to resolve. Firstly, the BigQuery export process generates files of varying sizes, resulting in a large number of small files. This seems to significantly slow down the Spark job. Secondly, during a test job where the total size of input tables was around 300GB, I noticed that the YARN pending memory started at 2TB as shown on dashboard and kept decreasing as the job progressed. I am perplexed as to why the YARN pending memory would be 2TB for a dataset of just a few hundred gigabytes.&lt;/p&gt;\n\n&lt;p&gt;Given these challenges, I am seeking advice from the community. If any of you have attempted a similar workflow or encountered similar issues, I would like to hear about your experiences and the results you achieved. Did you optimize the BigQuery export process to avoid the problem of numerous small files? Do you believe the method of running spark jobs via above mentioned way is appropriate, or would you recommend any changes to improve the Spark job performance? Are there any specific optimizations or best practices you would recommend for Spark jobs?&lt;/p&gt;\n\n&lt;p&gt;Any advice or suggestions you can provide would be highly appreciated. Thanks a lot in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z7y9h", "is_robot_indexable": true, "report_reasons": null, "author": "bha159", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z7y9h/small_file_problem_on_spark_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z7y9h/small_file_problem_on_spark_in_gcp/", "subreddit_subscribers": 115737, "created_utc": 1689314250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nThe spark shuffle read on this job is enormous compared to the shuffle write. What does this mean? the partitions are skewed? that I have too much or too little partitions?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/82ehfwhsfqbb1.png?width=1632&amp;format=png&amp;auto=webp&amp;s=d548f2b5cddd5bde5126dbc3bb5cac168bf47d8e", "author_fullname": "t2_5ftfizfi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to make sense of shuffle read vs shuffle writes of a spark stage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 7, "top_awarded_type": null, "hide_score": false, "media_metadata": {"82ehfwhsfqbb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 6, "x": 108, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=274ff734e4e03631c121f6eb664b2265584fb160"}, {"y": 12, "x": 216, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5ee8d2a84ff4463314898b8e9148bafedad42fd"}, {"y": 17, "x": 320, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bd5636efcb0978db3159fb6c06b623f8e68f39ab"}, {"y": 35, "x": 640, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c20f2e85754760bc9b6438ddd78a47b79d4d7a7c"}, {"y": 53, "x": 960, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=daf08b5cb70764997d67baccfb16e96c23870d25"}, {"y": 60, "x": 1080, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fe7d6bab656ebce1f2a1281be59c53b692667fdf"}], "s": {"y": 91, "x": 1632, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=1632&amp;format=png&amp;auto=webp&amp;s=d548f2b5cddd5bde5126dbc3bb5cac168bf47d8e"}, "id": "82ehfwhsfqbb1"}}, "name": "t3_14yklmx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/umooX2ys_WbkmkjAPLBVHHDNaOIwqRScAHRyn9u7hrc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689254131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;The spark shuffle read on this job is enormous compared to the shuffle write. What does this mean? the partitions are skewed? that I have too much or too little partitions?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/82ehfwhsfqbb1.png?width=1632&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d548f2b5cddd5bde5126dbc3bb5cac168bf47d8e\"&gt;https://preview.redd.it/82ehfwhsfqbb1.png?width=1632&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d548f2b5cddd5bde5126dbc3bb5cac168bf47d8e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14yklmx", "is_robot_indexable": true, "report_reasons": null, "author": "ThenBanana", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yklmx/trying_to_make_sense_of_shuffle_read_vs_shuffle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yklmx/trying_to_make_sense_of_shuffle_read_vs_shuffle/", "subreddit_subscribers": 115737, "created_utc": 1689254131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to introduce data science in my organisation. I have access to a lot of logs stored in opensearch. I need to present some solution to get funding. Can you guys give some tips on some solutions you have implemented using logs", "author_fullname": "t2_7g961oi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opensearch logs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14zekds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689336093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to introduce data science in my organisation. I have access to a lot of logs stored in opensearch. I need to present some solution to get funding. Can you guys give some tips on some solutions you have implemented using logs&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zekds", "is_robot_indexable": true, "report_reasons": null, "author": "pessimistic_dilution", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zekds/opensearch_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zekds/opensearch_logs/", "subreddit_subscribers": 115737, "created_utc": 1689336093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems like there are a lot of online courses for data, AI, databases, etc available online through websites like corsaira and you can pay extra for a certificate which I probably wouldn't do. But I wanted to know if you find these helpful?", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you find Coursera or other free online courses helpful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14zej5d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689336009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems like there are a lot of online courses for data, AI, databases, etc available online through websites like corsaira and you can pay extra for a certificate which I probably wouldn&amp;#39;t do. But I wanted to know if you find these helpful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zej5d", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zej5d/do_you_find_coursera_or_other_free_online_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zej5d/do_you_find_coursera_or_other_free_online_courses/", "subreddit_subscribers": 115737, "created_utc": 1689336009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a student who is enrolled in the IBM Data Engineering course of the coursera, and my final assignment is still not peer-reviewed, kindly if anyone of you who is enrolled in this course may review my assignment, then it'll be very helpful. Here is the assignment's link: [https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw](https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw) ", "author_fullname": "t2_bxisw3c1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering's introduction to relational databases assignment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zcesd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689329374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a student who is enrolled in the IBM Data Engineering course of the coursera, and my final assignment is still not peer-reviewed, kindly if anyone of you who is enrolled in this course may review my assignment, then it&amp;#39;ll be very helpful. Here is the assignment&amp;#39;s link: &lt;a href=\"https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw\"&gt;https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?auto=webp&amp;s=1370f7fc33eccde041bb8d913fc5ef24401c04f5", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6cfffb7d905036a18de683f4858275559647f8cb", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c56f4d07956aae6d02302bd31040c6013026d3ac", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66f1d899c02d5073461c22dc9e3587384dbf6136", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=579175bb293e955ce6b51dadc675c17e41f0b0ca", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=95ba17f421b486a5508eaecb231f9ba8eae35bbc", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eda6808809eea88cdc4032df689fc389cbaa90c9", "width": 1080, "height": 565}], "variants": {}, "id": "nnmvZitIdtl3UJSov7ZcIqMwnFG7OvGcVvkNPR4Vsrc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14zcesd", "is_robot_indexable": true, "report_reasons": null, "author": "Simple_Debt5396", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zcesd/data_engineerings_introduction_to_relational/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zcesd/data_engineerings_introduction_to_relational/", "subreddit_subscribers": 115737, "created_utc": 1689329374.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nHow do you usually orchestrate your Airbyte ingestions / connections ?\n\nI\u2019m planning to use data form as well on the transformation layer so I\u2019m curious.\n\nI\u2019m looking for the cheapest easiest to maintain option", "author_fullname": "t2_851if4wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP - Airbyte and orchestration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zb4nb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689325100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;How do you usually orchestrate your Airbyte ingestions / connections ?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m planning to use data form as well on the transformation layer so I\u2019m curious.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for the cheapest easiest to maintain option&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zb4nb", "is_robot_indexable": true, "report_reasons": null, "author": "No-Dress-3160", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zb4nb/gcp_airbyte_and_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zb4nb/gcp_airbyte_and_orchestration/", "subreddit_subscribers": 115737, "created_utc": 1689325100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a couple of spark jobs writing data in hourly partitions using Avro and Parquet formats. The data is stored in AWS S3 in the same bucket, but each partition has a different prefix, e.g. \\`YYYY-MM-DD-HH\\`. How can I ensure that the downstream jobs won't see or be able to access an incomplete partition being written?", "author_fullname": "t2_mafti2dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the techniques to ensure atomic writes to partition?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zan40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689323403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a couple of spark jobs writing data in hourly partitions using Avro and Parquet formats. The data is stored in AWS S3 in the same bucket, but each partition has a different prefix, e.g. `YYYY-MM-DD-HH`. How can I ensure that the downstream jobs won&amp;#39;t see or be able to access an incomplete partition being written?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14zan40", "is_robot_indexable": true, "report_reasons": null, "author": "ad81923", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zan40/what_are_the_techniques_to_ensure_atomic_writes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zan40/what_are_the_techniques_to_ensure_atomic_writes/", "subreddit_subscribers": 115737, "created_utc": 1689323403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it good practice to store event data in object storage one by one? I.e. if I get 1M events/messages a day I store 1M small e.g. JSON files into the S3 and then batch process it at the end of day. Is this reasonable or I should somehow buffer all the messages and then save only one (or little more) batched files into the S3? Also why / why not?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing realtime events in object storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yxlz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689285022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it good practice to store event data in object storage one by one? I.e. if I get 1M events/messages a day I store 1M small e.g. JSON files into the S3 and then batch process it at the end of day. Is this reasonable or I should somehow buffer all the messages and then save only one (or little more) batched files into the S3? Also why / why not?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yxlz3", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yxlz3/storing_realtime_events_in_object_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yxlz3/storing_realtime_events_in_object_storage/", "subreddit_subscribers": 115737, "created_utc": 1689285022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://gretel.ai/blog/bring-your-own-cloud](https://gretel.ai/blog/bring-your-own-cloud)", "author_fullname": "t2_t4pwocav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anonymizing 7 terabytes of data in a hybrid cloud environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yw2dw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689281361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://gretel.ai/blog/bring-your-own-cloud\"&gt;https://gretel.ai/blog/bring-your-own-cloud&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?auto=webp&amp;s=bc3493917d3704a273ac737908af2200db053206", "width": 1440, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=210062dc56f116a92ad54cdf589382f4650558c0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=741b610f3aa7f92a6b0203c040fa6891d241da6f", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5149bccc1297b6b740a39bf74fd35c006475e3bc", "width": 320, "height": 177}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ddf12ec791acf3397800e1010de4283a3b40eca8", "width": 640, "height": 355}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=40087377ec3b0914b0d3606118e69ad54f379863", "width": 960, "height": 533}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd781648c0620c89b350217cc0e058fc94a7142e", "width": 1080, "height": 600}], "variants": {}, "id": "P3FdEpfGKtApmyi9xRhUP9Uq6puzmmJGETUlq8e2RgE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14yw2dw", "is_robot_indexable": true, "report_reasons": null, "author": "Synthesize2023", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yw2dw/anonymizing_7_terabytes_of_data_in_a_hybrid_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yw2dw/anonymizing_7_terabytes_of_data_in_a_hybrid_cloud/", "subreddit_subscribers": 115737, "created_utc": 1689281361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! At my company, Journalize, our users wanted to add arbitrary tags to their data so they could slice and dice against any dimension. To aggregate data over 10M rows, we set up a Clickhouse server with some magic. I'm curious if people can also use what we built. \n\n(note: im expecting the data purists to hate this, and I am ready for that\u2026 :)\n\nWe are calling it ScratchDB: Firestore for analytics. Stream JSON, and we\u2019ll figure out how to get it into an analytical database, and you can run SQL. \n\nWebsite: [https://www.scratchdb.com](https://www.scratchdb.com/)\n\nGithub: [https://github.com/scratchdata/ScratchDB](https://github.com/scratchdata/ScratchDB) \n\nThe problem as I see it: \n\n* At some point, you might find that GROUP BYs are slow in Postgres and want an analytical database\n* Getting started has technical friction: choosing a DB, new underlying storage models, monitoring servers\n* Pricing is opaque: self-hosting vs cloud, credits, vCPUs, it\u2019s hard to answer \u201chow much will this thing cost\u201d, and often the answer is \u201ca lot\u201d\n\nWith ScratchDB:\n\n* No need to issue a CREATE TABLE statement. Send your JSON and we will automatically create tables and columns on the fly.\n* Just pay for what you use via metrics you can easily understand (storage, processing time)\n* ScratchDB is open source (github) and right now it runs on top of DuckDB. (More connectors in the works!) It is written in Go.\n\nI am really curious about what people think. Also, we\u2019d love to know how you\u2019re doing this today, how much it costs, and what your devops looks like. (if you\u2019re willing to shoot me a DM!) \n\nLet us see if we can help you ingest data into your DB more easily. If this is a pain point on non-analytics workloads, I\u2019m interested in talking as this is also on our roadmap.\n\nThanks in advance! ", "author_fullname": "t2_4mv9dvc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Useful or nah: open-source serverless analytics DB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yv3kv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689279112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! At my company, Journalize, our users wanted to add arbitrary tags to their data so they could slice and dice against any dimension. To aggregate data over 10M rows, we set up a Clickhouse server with some magic. I&amp;#39;m curious if people can also use what we built. &lt;/p&gt;\n\n&lt;p&gt;(note: im expecting the data purists to hate this, and I am ready for that\u2026 :)&lt;/p&gt;\n\n&lt;p&gt;We are calling it ScratchDB: Firestore for analytics. Stream JSON, and we\u2019ll figure out how to get it into an analytical database, and you can run SQL. &lt;/p&gt;\n\n&lt;p&gt;Website: &lt;a href=\"https://www.scratchdb.com/\"&gt;https://www.scratchdb.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/scratchdata/ScratchDB\"&gt;https://github.com/scratchdata/ScratchDB&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;The problem as I see it: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;At some point, you might find that GROUP BYs are slow in Postgres and want an analytical database&lt;/li&gt;\n&lt;li&gt;Getting started has technical friction: choosing a DB, new underlying storage models, monitoring servers&lt;/li&gt;\n&lt;li&gt;Pricing is opaque: self-hosting vs cloud, credits, vCPUs, it\u2019s hard to answer \u201chow much will this thing cost\u201d, and often the answer is \u201ca lot\u201d&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With ScratchDB:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;No need to issue a CREATE TABLE statement. Send your JSON and we will automatically create tables and columns on the fly.&lt;/li&gt;\n&lt;li&gt;Just pay for what you use via metrics you can easily understand (storage, processing time)&lt;/li&gt;\n&lt;li&gt;ScratchDB is open source (github) and right now it runs on top of DuckDB. (More connectors in the works!) It is written in Go.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am really curious about what people think. Also, we\u2019d love to know how you\u2019re doing this today, how much it costs, and what your devops looks like. (if you\u2019re willing to shoot me a DM!) &lt;/p&gt;\n\n&lt;p&gt;Let us see if we can help you ingest data into your DB more easily. If this is a pain point on non-analytics workloads, I\u2019m interested in talking as this is also on our roadmap.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14yv3kv", "is_robot_indexable": true, "report_reasons": null, "author": "robertao211", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yv3kv/useful_or_nah_opensource_serverless_analytics_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yv3kv/useful_or_nah_opensource_serverless_analytics_db/", "subreddit_subscribers": 115737, "created_utc": 1689279112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have built a custom Prometheus metrics exporter in Python for a Database system. \nThe exporter's job is to get data from the DB by running SQL queries (E), Convert the tabular data to key value pairs (T) and then send it to Prometheus (L).\nDoes this classify as an ETL job ?", "author_fullname": "t2_2hokn0mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can this be called an ETL ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ysqvg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689273573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have built a custom Prometheus metrics exporter in Python for a Database system. \nThe exporter&amp;#39;s job is to get data from the DB by running SQL queries (E), Convert the tabular data to key value pairs (T) and then send it to Prometheus (L).\nDoes this classify as an ETL job ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ysqvg", "is_robot_indexable": true, "report_reasons": null, "author": "deathlolwut", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ysqvg/can_this_be_called_an_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ysqvg/can_this_be_called_an_etl/", "subreddit_subscribers": 115737, "created_utc": 1689273573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone attended? How does it compare to other Data conferences?\n\nedw2023fall.dataversity.net\n\nI saw this post from earlier this year but didn't catch any mention of this one.", "author_fullname": "t2_4fhdq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enterprise Data World (EDW) Conference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ys7lx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689272290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone attended? How does it compare to other Data conferences?&lt;/p&gt;\n\n&lt;p&gt;edw2023fall.dataversity.net&lt;/p&gt;\n\n&lt;p&gt;I saw this post from earlier this year but didn&amp;#39;t catch any mention of this one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ys7lx", "is_robot_indexable": true, "report_reasons": null, "author": "tolkienwhiteboy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ys7lx/enterprise_data_world_edw_conference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ys7lx/enterprise_data_world_edw_conference/", "subreddit_subscribers": 115737, "created_utc": 1689272290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at an org where our data engineers have bought into dagster. Dagster seems great, except I can\u2019t wrap my head around how to set it up for multiple github repositories.\n\nSo we have one repo that has all the infrastructure code for dagster. Currently our data engineers keep the infra code (terraform) with their job (so its a monorepo). As dagster expands to other teams we have many projects across different repos. So for example some of my models (i am a data scientist) exist in different repos and would continue to exist in different repos. What is the simplest way to allow for me to continue this framework?", "author_fullname": "t2_a071r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster with multiple repos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yryax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689271695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at an org where our data engineers have bought into dagster. Dagster seems great, except I can\u2019t wrap my head around how to set it up for multiple github repositories.&lt;/p&gt;\n\n&lt;p&gt;So we have one repo that has all the infrastructure code for dagster. Currently our data engineers keep the infra code (terraform) with their job (so its a monorepo). As dagster expands to other teams we have many projects across different repos. So for example some of my models (i am a data scientist) exist in different repos and would continue to exist in different repos. What is the simplest way to allow for me to continue this framework?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14yryax", "is_robot_indexable": true, "report_reasons": null, "author": "IAteQuarters", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yryax/dagster_with_multiple_repos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yryax/dagster_with_multiple_repos/", "subreddit_subscribers": 115737, "created_utc": 1689271695.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}