{"kind": "Listing", "data": {"after": "t3_14yvwc6", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks,\n\nFor the past 2 years I've been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, ddl generation, self deployment, schema evolution... basically, as you build better and better pipelines you will want more and more.\n\nThe value proposition is to automate the tedious work you do, so you can focus on better things.\n\nSo dlt is a library where in the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading.\n\nIn its most complex form, you can do almost anything you can want, from memory management, multithreading, extraction DAGs, etc.\n\nThe library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community.\n\nFeedback is very welcome and so are requests for features or destinations.\n\nThe library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.[https://dlthub.com/](https://dlthub.com/)  \n\n\nI know lots of you are jaded and fed up with toy technologies - this is not a toy tech, it's purpose made for productivity and sanity.\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python library for automating data normalisation, schema creation and loading to db", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yfh6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 195, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 195, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689238840.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689238647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks,&lt;/p&gt;\n\n&lt;p&gt;For the past 2 years I&amp;#39;ve been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, ddl generation, self deployment, schema evolution... basically, as you build better and better pipelines you will want more and more.&lt;/p&gt;\n\n&lt;p&gt;The value proposition is to automate the tedious work you do, so you can focus on better things.&lt;/p&gt;\n\n&lt;p&gt;So dlt is a library where in the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading.&lt;/p&gt;\n\n&lt;p&gt;In its most complex form, you can do almost anything you can want, from memory management, multithreading, extraction DAGs, etc.&lt;/p&gt;\n\n&lt;p&gt;The library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community.&lt;/p&gt;\n\n&lt;p&gt;Feedback is very welcome and so are requests for features or destinations.&lt;/p&gt;\n\n&lt;p&gt;The library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.&lt;a href=\"https://dlthub.com/\"&gt;https://dlthub.com/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I know lots of you are jaded and fed up with toy technologies - this is not a toy tech, it&amp;#39;s purpose made for productivity and sanity.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?auto=webp&amp;s=cb39faa311105e22445462cdf83958c4587fedc2", "width": 1200, "height": 898}, "resolutions": [{"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2950fb9a02e9cdd0b136f3013b72924854fdca3f", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f0af0e48140a561a1f7b733a96875956b6389de", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25c5e30c984451ee6ea10cd4e1067e85319086d3", "width": 320, "height": 239}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=784ffdd500b6cb71463c17b9d348b620c417e6b2", "width": 640, "height": 478}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a966fccda316bcff3aef7e4ae872efc79cabbc1", "width": 960, "height": 718}, {"url": "https://external-preview.redd.it/xklrjiOLps--2g06mfk-O6nj8TPQriAlMdAvL1LpduA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec5a6d47433e6864a169a05e9319caa70258c58d", "width": 1080, "height": 808}], "variants": {}, "id": "cUuEsBHL5TMhrkQNJ9leYxFMOF6VgvTJ_EKHwExrn8Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14yfh6p", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 100, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yfh6p/python_library_for_automating_data_normalisation/", "subreddit_subscribers": 115706, "created_utc": 1689238647.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a Data Engineer what\u2019s your biggest headache, frustration, time suck?", "author_fullname": "t2_3cr575ib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Headaches", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z3dvp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689300344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a Data Engineer what\u2019s your biggest headache, frustration, time suck?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z3dvp", "is_robot_indexable": true, "report_reasons": null, "author": "jayking51", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z3dvp/data_engineering_headaches/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z3dvp/data_engineering_headaches/", "subreddit_subscribers": 115706, "created_utc": 1689300344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As opposed to other people who asked about no-code/low-code/ GUI-based tools, I want a list of tools which actually require to write code and schedules for data movement.I am very new to all this. I'm currently working as Power BI developer in a company but want to do Data Engineering and ETL stuff in near future.\n\nI read that Informatica and Talend are all GUI-based tools which is not good for long run growth and learning.\n\nEDIT:\n\nThank You everyone for such great input. This just made my day. I think I have alot to learn ahead. After all your comments, I feel like I haven't even scratched the surface.\n\nPlease if anyone of you can share a roadmap. I really need to get in ETL and DE, and soon.\n\nNote: I have 1 year or 1.5 years max to switch and I need it to be ETL or DE job where I could do all this what you guys mentioned in comments.", "author_fullname": "t2_3k9gevl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List of / Suggestion for Code based ETL Tools.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yl2vw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689314853.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689255334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As opposed to other people who asked about no-code/low-code/ GUI-based tools, I want a list of tools which actually require to write code and schedules for data movement.I am very new to all this. I&amp;#39;m currently working as Power BI developer in a company but want to do Data Engineering and ETL stuff in near future.&lt;/p&gt;\n\n&lt;p&gt;I read that Informatica and Talend are all GUI-based tools which is not good for long run growth and learning.&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;Thank You everyone for such great input. This just made my day. I think I have alot to learn ahead. After all your comments, I feel like I haven&amp;#39;t even scratched the surface.&lt;/p&gt;\n\n&lt;p&gt;Please if anyone of you can share a roadmap. I really need to get in ETL and DE, and soon.&lt;/p&gt;\n\n&lt;p&gt;Note: I have 1 year or 1.5 years max to switch and I need it to be ETL or DE job where I could do all this what you guys mentioned in comments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yl2vw", "is_robot_indexable": true, "report_reasons": null, "author": "Pillstyr", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yl2vw/list_of_suggestion_for_code_based_etl_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yl2vw/list_of_suggestion_for_code_based_etl_tools/", "subreddit_subscribers": 115706, "created_utc": 1689255334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The streaming world is dominated by Java based tools like Kafka and Flink but most data scientists live in MATLAB, R, and Python notebooks. I'm curious how y'all collaborate with data scientists in these situations, especially when you want to embed some domain specific data logic / transformation?\n\n\\- Do they write data transformations / build models in their native language and throw it over the wall to you?\n\n\\- Do they learn your toolchain?", "author_fullname": "t2_6khnrfh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you collaborate with notebook savvy data scientists on streaming data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ypog3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689266335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The streaming world is dominated by Java based tools like Kafka and Flink but most data scientists live in MATLAB, R, and Python notebooks. I&amp;#39;m curious how y&amp;#39;all collaborate with data scientists in these situations, especially when you want to embed some domain specific data logic / transformation?&lt;/p&gt;\n\n&lt;p&gt;- Do they write data transformations / build models in their native language and throw it over the wall to you?&lt;/p&gt;\n\n&lt;p&gt;- Do they learn your toolchain?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ypog3", "is_robot_indexable": true, "report_reasons": null, "author": "semicausal", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ypog3/how_do_you_collaborate_with_notebook_savvy_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ypog3/how_do_you_collaborate_with_notebook_savvy_data/", "subreddit_subscribers": 115706, "created_utc": 1689266335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have worked as a software engineer and I am now on my second data engineering position. As time marches on it seems that I am fighting a losing battle trying to implement automated logic tests for SQL testing.\n\nAs a software engineer I wrote tests to validate that for input x I would get output y and then make sure all the edge cases were covered. I have worked on data warehouse projects that used a similar \"unit test approach\": load a test data set into the database and verify the result of some sql. When I moved into doing work in a data science department we used Spark to mock out data frames and test the output of an operation.\n\nHowever this does not seem to be how the industry as a whole handles things. It seems that teams test the general shape of some transform logic such as row counts or if a value falls within a range. I am curious what other folks impressions are (not just your team, but data engineering as a whole)?\n\nOn a side note: I read articles like [https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc](https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc) which makes me think people are testing transforms, but then I see polls like this [https://www.jetbrains.com/lp/devecosystem-2021/databases/](https://www.jetbrains.com/lp/devecosystem-2021/databases/) that indicate people don't really test.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_3j0if", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Testing: a loosing battle?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ywjwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689282451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have worked as a software engineer and I am now on my second data engineering position. As time marches on it seems that I am fighting a losing battle trying to implement automated logic tests for SQL testing.&lt;/p&gt;\n\n&lt;p&gt;As a software engineer I wrote tests to validate that for input x I would get output y and then make sure all the edge cases were covered. I have worked on data warehouse projects that used a similar &amp;quot;unit test approach&amp;quot;: load a test data set into the database and verify the result of some sql. When I moved into doing work in a data science department we used Spark to mock out data frames and test the output of an operation.&lt;/p&gt;\n\n&lt;p&gt;However this does not seem to be how the industry as a whole handles things. It seems that teams test the general shape of some transform logic such as row counts or if a value falls within a range. I am curious what other folks impressions are (not just your team, but data engineering as a whole)?&lt;/p&gt;\n\n&lt;p&gt;On a side note: I read articles like &lt;a href=\"https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc\"&gt;https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc&lt;/a&gt; which makes me think people are testing transforms, but then I see polls like this &lt;a href=\"https://www.jetbrains.com/lp/devecosystem-2021/databases/\"&gt;https://www.jetbrains.com/lp/devecosystem-2021/databases/&lt;/a&gt; that indicate people don&amp;#39;t really test.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?auto=webp&amp;s=d89a17b05c97281fdd6453dd599945fcd7336b51", "width": 1005, "height": 444}, "resolutions": [{"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e64df404a8a381f61dba9b394f45d66d2547dcc3", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42e227a370404b011573e86f3dfe060ce05c42c2", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=45c6aabe350b41595aa55f72de51cc2cd7d9642a", "width": 320, "height": 141}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9d006f825a0b89e3e1524059d5ff1f6de8c6f2c", "width": 640, "height": 282}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=21f0334d6bb2c2fcc573a1f64aaa8bd05c5689c5", "width": 960, "height": 424}], "variants": {}, "id": "6c4F5f_MtX1XvNBav9lGrhcENIY60PGLA8mRkZf-GFo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ywjwa", "is_robot_indexable": true, "report_reasons": null, "author": "jaynerd", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ywjwa/sql_testing_a_loosing_battle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ywjwa/sql_testing_a_loosing_battle/", "subreddit_subscribers": 115706, "created_utc": 1689282451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few months ago I changed from data scientist to engineer, since in my previous company I did everything myself, but being a CS guy I pref the data engineering part.\n\nIn my current company, a multinational telecommunications, I only do SQL queries and stupid dashboards for marketing and business, I feel frustrated because anyone can do this\u2026  And it has little to do with the Data Engineer role that I was offered.\n\nHow much do you use SQL in your daily work ?", "author_fullname": "t2_4kdegv81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL only - Work frustration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z8hhn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689315999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months ago I changed from data scientist to engineer, since in my previous company I did everything myself, but being a CS guy I pref the data engineering part.&lt;/p&gt;\n\n&lt;p&gt;In my current company, a multinational telecommunications, I only do SQL queries and stupid dashboards for marketing and business, I feel frustrated because anyone can do this\u2026  And it has little to do with the Data Engineer role that I was offered.&lt;/p&gt;\n\n&lt;p&gt;How much do you use SQL in your daily work ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z8hhn", "is_robot_indexable": true, "report_reasons": null, "author": "xchgre", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z8hhn/sql_only_work_frustration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z8hhn/sql_only_work_frustration/", "subreddit_subscribers": 115706, "created_utc": 1689315999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Facing a potential layoff soon, so have started applying to some data engineer, jr data engineer and analytics engineer positions. I thought I'd put a project up on github so any HM could see a bit of my skills. If you saw this and actually looked through it, what would you think?\n\n[https://github.com/jrey999/mlb](https://github.com/jrey999/mlb)", "author_fullname": "t2_v4s5fwgd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you saw this and actually looked through it, what would you think", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z582e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689305728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Facing a potential layoff soon, so have started applying to some data engineer, jr data engineer and analytics engineer positions. I thought I&amp;#39;d put a project up on github so any HM could see a bit of my skills. If you saw this and actually looked through it, what would you think?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/jrey999/mlb\"&gt;https://github.com/jrey999/mlb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?auto=webp&amp;s=f23cd95bd53dfe4d4782e84979e0b6b62d084129", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a3709fc1236118224429386fed0b00f235baf0a2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=45ae7c8e42e8f1b6bd02486b081cc4056b35f870", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ab7afb2fabfb98da681c7ddf4639747d1c14d8d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=adbfb6983d38667cc57a25c401ea92acc4adaf10", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5882b19e3647675aee89370079a541eb94210638", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c01dcaee91410f53051d02152cc9c3ce4b8fdcc", "width": 1080, "height": 540}], "variants": {}, "id": "ZTkos4tP2WpR9wFxhobnnfq39iPZLNNBaB0u--0xAy0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "14z582e", "is_robot_indexable": true, "report_reasons": null, "author": "big_lazerz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z582e/if_you_saw_this_and_actually_looked_through_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z582e/if_you_saw_this_and_actually_looked_through_it/", "subreddit_subscribers": 115706, "created_utc": 1689305728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello Everyone! \n\nWhat are the AWS alerting and notification best practices. While we've covered the basics in the current org where we get a notification on every failure, plain email saying the job is failed. We would like to have a thought process to see what is best in \n\n&amp;#x200B;\n\n How have you expanded your AWS alerts beyond job failures?    \n Have you utilized Amazon SES to deliver timely notifications? how you have optimized the failed emails  \n How have you leveraged AWS Glue and Lambda to automate your alerting process? \n\n For those who have integrated PagerDuty within their AWS infrastructure  \n\n&amp;#x200B;\n\nwhat is the best enterprise-level strategy for alerting and notifications?", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Alerting and Notification Best Practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z2ieu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689297884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone! &lt;/p&gt;\n\n&lt;p&gt;What are the AWS alerting and notification best practices. While we&amp;#39;ve covered the basics in the current org where we get a notification on every failure, plain email saying the job is failed. We would like to have a thought process to see what is best in &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How have you expanded your AWS alerts beyond job failures?&lt;br/&gt;\n Have you utilized Amazon SES to deliver timely notifications? how you have optimized the failed emails&lt;br/&gt;\n How have you leveraged AWS Glue and Lambda to automate your alerting process? &lt;/p&gt;\n\n&lt;p&gt;For those who have integrated PagerDuty within their AWS infrastructure  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;what is the best enterprise-level strategy for alerting and notifications?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z2ieu", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z2ieu/aws_alerting_and_notification_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z2ieu/aws_alerting_and_notification_best_practices/", "subreddit_subscribers": 115706, "created_utc": 1689297884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey yall, so I had a couple questions,\n\nToday I decided to try and work on my courera app. I currently work at Tesla and, honestly, im not happy with it. It's good and all but there's no challenge. I'm working on going back to community college to get a transferable mechanical engineering degree, but I'm exploring my options.\nI came upon the Data engineering certification and I was wondering, if it's JUST a certification, can I do much with that? I've always had a soft spot for programming and computer science, ngl, I've had it rough and never had the ability to completely apply myself in college. Now, I think I actually can and I feel like this would be useful to have in my tool belt, but, I ask again, is there actual application to an IBM data engineer certification?", "author_fullname": "t2_4mjgvza0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ymvb3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689259713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey yall, so I had a couple questions,&lt;/p&gt;\n\n&lt;p&gt;Today I decided to try and work on my courera app. I currently work at Tesla and, honestly, im not happy with it. It&amp;#39;s good and all but there&amp;#39;s no challenge. I&amp;#39;m working on going back to community college to get a transferable mechanical engineering degree, but I&amp;#39;m exploring my options.\nI came upon the Data engineering certification and I was wondering, if it&amp;#39;s JUST a certification, can I do much with that? I&amp;#39;ve always had a soft spot for programming and computer science, ngl, I&amp;#39;ve had it rough and never had the ability to completely apply myself in college. Now, I think I actually can and I feel like this would be useful to have in my tool belt, but, I ask again, is there actual application to an IBM data engineer certification?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ymvb3", "is_robot_indexable": true, "report_reasons": null, "author": "prototypefish72", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ymvb3/data_engineering_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ymvb3/data_engineering_certification/", "subreddit_subscribers": 115706, "created_utc": 1689259713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im looking to get a general idea of the spark ecosystem and fundamentals because at our company we are using a custom made abstraction above \"Apache Spark\". A lot of concepts are mapped 1:1.  Mainly for ETL purposes (data processing etc)\n\nAny idea's suggestions? by reading books, tutorials etc", "author_fullname": "t2_dr0lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn apache spark as a beginner/junior/new grad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ysuu6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689273837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im looking to get a general idea of the spark ecosystem and fundamentals because at our company we are using a custom made abstraction above &amp;quot;Apache Spark&amp;quot;. A lot of concepts are mapped 1:1.  Mainly for ETL purposes (data processing etc)&lt;/p&gt;\n\n&lt;p&gt;Any idea&amp;#39;s suggestions? by reading books, tutorials etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ysuu6", "is_robot_indexable": true, "report_reasons": null, "author": "poepstinktvies", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ysuu6/how_to_learn_apache_spark_as_a_beginnerjuniornew/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ysuu6/how_to_learn_apache_spark_as_a_beginnerjuniornew/", "subreddit_subscribers": 115706, "created_utc": 1689273837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I have an economics degree and currently work as a business analyst. I\u2019m also doing an online MS Applied Statistics. Originally my goal was to become a data scientist, but I\u2019ve realized I prefer working with databases, ETL, data modeling and python more than statistics so now I am leaning more towards data engineering. I\u2019m 3 classes into the degree and have 7 left to graduate in Fall 2025. \nShould I continue with this degree or instead do the BS CS at WGU? All of my gen eds will transfer so I\u2019ll only have to take the core CS classes.", "author_fullname": "t2_5uz2eb6mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MS Applied Statistics or BS Computer Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ymve2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689259719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I have an economics degree and currently work as a business analyst. I\u2019m also doing an online MS Applied Statistics. Originally my goal was to become a data scientist, but I\u2019ve realized I prefer working with databases, ETL, data modeling and python more than statistics so now I am leaning more towards data engineering. I\u2019m 3 classes into the degree and have 7 left to graduate in Fall 2025. \nShould I continue with this degree or instead do the BS CS at WGU? All of my gen eds will transfer so I\u2019ll only have to take the core CS classes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ymve2", "is_robot_indexable": true, "report_reasons": null, "author": "abc__901", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ymve2/ms_applied_statistics_or_bs_computer_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ymve2/ms_applied_statistics_or_bs_computer_science/", "subreddit_subscribers": 115706, "created_utc": 1689259719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use Git Flow in our company. \nThe Develop branch is cloned to creature the Feature branch.\nIn Feature branch we add additional features and all testing (unit, integration, uat) happens in this branch. Once approved, we merge this back to Develop. Then release branch is created from Develop and merged into Prod without any testing.\n\nSo my question is, do we need to perform additional testing in Release branch?", "author_fullname": "t2_gzg678i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Test in Feature or Release branch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14z9r5g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689320347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use Git Flow in our company. \nThe Develop branch is cloned to creature the Feature branch.\nIn Feature branch we add additional features and all testing (unit, integration, uat) happens in this branch. Once approved, we merge this back to Develop. Then release branch is created from Develop and merged into Prod without any testing.&lt;/p&gt;\n\n&lt;p&gt;So my question is, do we need to perform additional testing in Release branch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14z9r5g", "is_robot_indexable": true, "report_reasons": null, "author": "ryandane123", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z9r5g/test_in_feature_or_release_branch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z9r5g/test_in_feature_or_release_branch/", "subreddit_subscribers": 115706, "created_utc": 1689320347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I love cbt. I finally get the fuss now.\n\nBack in the olden days, I'd just dump all of my pandas/polars tasks in one compact jupyter notebook, download it all as a .py file, and call it a day. I genuinely thought that was better and more compact.\n\nBut now after using dbt for the first time, I can sort of see its usefulness. I rewrote the pandas stuff as a chain of CTE statements and breaking them up into different, consecutive SQL files. It really forces you to view things more modular, and while SQL can't do as much stuff as python, I gotta agree that it's overall cleaner to read, even as someone who was taught Python before SQL and thus feels biased for Python.\n\nThe only thing I don't know how to exactly do yet is interrupt the dbt midway to do something only python can do, or rather something SQL can't do (like adding columns that are the output of a machine learning method such as k-means, tf-idf, or PCA), and then resuming the dbt.", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After balking for a long time, tried out dbt for the first time and now am a full convert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14z9id2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689319474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I love cbt. I finally get the fuss now.&lt;/p&gt;\n\n&lt;p&gt;Back in the olden days, I&amp;#39;d just dump all of my pandas/polars tasks in one compact jupyter notebook, download it all as a .py file, and call it a day. I genuinely thought that was better and more compact.&lt;/p&gt;\n\n&lt;p&gt;But now after using dbt for the first time, I can sort of see its usefulness. I rewrote the pandas stuff as a chain of CTE statements and breaking them up into different, consecutive SQL files. It really forces you to view things more modular, and while SQL can&amp;#39;t do as much stuff as python, I gotta agree that it&amp;#39;s overall cleaner to read, even as someone who was taught Python before SQL and thus feels biased for Python.&lt;/p&gt;\n\n&lt;p&gt;The only thing I don&amp;#39;t know how to exactly do yet is interrupt the dbt midway to do something only python can do, or rather something SQL can&amp;#39;t do (like adding columns that are the output of a machine learning method such as k-means, tf-idf, or PCA), and then resuming the dbt.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z9id2", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z9id2/after_balking_for_a_long_time_tried_out_dbt_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z9id2/after_balking_for_a_long_time_tried_out_dbt_for/", "subreddit_subscribers": 115706, "created_utc": 1689319474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all  \nI am seeking advice and suggestions regarding an ELT workflow that my team has been implementing using BigQuery and Spark. I have encountered some challenges and would greatly appreciate the insights of this community.\n\nCurrently, I am using BigQuery for our ELT work, but the cost has been significant due to the rapid increase in data volume. To explore cost reduction options, my team decided to explore Dataproc. Our approach involves exporting BigQuery data to Google Cloud Storage (which is free up to 10TB per day), running a Spark job using the same query as in BigQuery (making it Spark compatible), writing the output DataFrame to GCS, and finally ingesting the data into a table (which is also free).\n\nHowever on doing this, I have observed two peculiar issues that I am struggling to resolve. Firstly, the BigQuery export process generates files of varying sizes, resulting in a large number of small files. This seems to significantly slow down the Spark job. Secondly, during a test job where the total size of input tables was around 300GB, I noticed that the YARN pending memory started at 2TB as shown on dashboard and kept decreasing as the job progressed. I am perplexed as to why the YARN pending memory would be 2TB for a dataset of just a few hundred gigabytes.\n\nGiven these challenges, I am seeking advice from the community. If any of you have attempted a similar workflow or encountered similar issues, I would like to hear about your experiences and the results you achieved. Did you optimize the BigQuery export process to avoid the problem of numerous small files? Do you believe the method of running spark jobs via above mentioned way is appropriate, or would you recommend any changes to improve the Spark job performance? Are there any specific optimizations or best practices you would recommend for Spark jobs?\n\nAny advice or suggestions you can provide would be highly appreciated. Thanks a lot in advance.", "author_fullname": "t2_cu6opso3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small file problem on spark in GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z7y9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689314250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;br/&gt;\nI am seeking advice and suggestions regarding an ELT workflow that my team has been implementing using BigQuery and Spark. I have encountered some challenges and would greatly appreciate the insights of this community.&lt;/p&gt;\n\n&lt;p&gt;Currently, I am using BigQuery for our ELT work, but the cost has been significant due to the rapid increase in data volume. To explore cost reduction options, my team decided to explore Dataproc. Our approach involves exporting BigQuery data to Google Cloud Storage (which is free up to 10TB per day), running a Spark job using the same query as in BigQuery (making it Spark compatible), writing the output DataFrame to GCS, and finally ingesting the data into a table (which is also free).&lt;/p&gt;\n\n&lt;p&gt;However on doing this, I have observed two peculiar issues that I am struggling to resolve. Firstly, the BigQuery export process generates files of varying sizes, resulting in a large number of small files. This seems to significantly slow down the Spark job. Secondly, during a test job where the total size of input tables was around 300GB, I noticed that the YARN pending memory started at 2TB as shown on dashboard and kept decreasing as the job progressed. I am perplexed as to why the YARN pending memory would be 2TB for a dataset of just a few hundred gigabytes.&lt;/p&gt;\n\n&lt;p&gt;Given these challenges, I am seeking advice from the community. If any of you have attempted a similar workflow or encountered similar issues, I would like to hear about your experiences and the results you achieved. Did you optimize the BigQuery export process to avoid the problem of numerous small files? Do you believe the method of running spark jobs via above mentioned way is appropriate, or would you recommend any changes to improve the Spark job performance? Are there any specific optimizations or best practices you would recommend for Spark jobs?&lt;/p&gt;\n\n&lt;p&gt;Any advice or suggestions you can provide would be highly appreciated. Thanks a lot in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z7y9h", "is_robot_indexable": true, "report_reasons": null, "author": "bha159", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z7y9h/small_file_problem_on_spark_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z7y9h/small_file_problem_on_spark_in_gcp/", "subreddit_subscribers": 115706, "created_utc": 1689314250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nThe spark shuffle read on this job is enormous compared to the shuffle write. What does this mean? the partitions are skewed? that I have too much or too little partitions?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/82ehfwhsfqbb1.png?width=1632&amp;format=png&amp;auto=webp&amp;s=d548f2b5cddd5bde5126dbc3bb5cac168bf47d8e", "author_fullname": "t2_5ftfizfi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to make sense of shuffle read vs shuffle writes of a spark stage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 7, "top_awarded_type": null, "hide_score": false, "media_metadata": {"82ehfwhsfqbb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 6, "x": 108, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=274ff734e4e03631c121f6eb664b2265584fb160"}, {"y": 12, "x": 216, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5ee8d2a84ff4463314898b8e9148bafedad42fd"}, {"y": 17, "x": 320, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bd5636efcb0978db3159fb6c06b623f8e68f39ab"}, {"y": 35, "x": 640, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c20f2e85754760bc9b6438ddd78a47b79d4d7a7c"}, {"y": 53, "x": 960, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=daf08b5cb70764997d67baccfb16e96c23870d25"}, {"y": 60, "x": 1080, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fe7d6bab656ebce1f2a1281be59c53b692667fdf"}], "s": {"y": 91, "x": 1632, "u": "https://preview.redd.it/82ehfwhsfqbb1.png?width=1632&amp;format=png&amp;auto=webp&amp;s=d548f2b5cddd5bde5126dbc3bb5cac168bf47d8e"}, "id": "82ehfwhsfqbb1"}}, "name": "t3_14yklmx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/umooX2ys_WbkmkjAPLBVHHDNaOIwqRScAHRyn9u7hrc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689254131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;The spark shuffle read on this job is enormous compared to the shuffle write. What does this mean? the partitions are skewed? that I have too much or too little partitions?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/82ehfwhsfqbb1.png?width=1632&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d548f2b5cddd5bde5126dbc3bb5cac168bf47d8e\"&gt;https://preview.redd.it/82ehfwhsfqbb1.png?width=1632&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d548f2b5cddd5bde5126dbc3bb5cac168bf47d8e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14yklmx", "is_robot_indexable": true, "report_reasons": null, "author": "ThenBanana", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yklmx/trying_to_make_sense_of_shuffle_read_vs_shuffle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yklmx/trying_to_make_sense_of_shuffle_read_vs_shuffle/", "subreddit_subscribers": 115706, "created_utc": 1689254131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am based in France and I'm looking to hear news and presentations from other data practitioners (data engineering mostly). I can't find any meet-ups. Do you guys know some ? Preferably in person events, but since I'm not finding anything, online will do too. Thanks !! ", "author_fullname": "t2_8kenyeuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering meetups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yejyj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689235429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am based in France and I&amp;#39;m looking to hear news and presentations from other data practitioners (data engineering mostly). I can&amp;#39;t find any meet-ups. Do you guys know some ? Preferably in person events, but since I&amp;#39;m not finding anything, online will do too. Thanks !! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yejyj", "is_robot_indexable": true, "report_reasons": null, "author": "btenami", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14yejyj/data_engineering_meetups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yejyj/data_engineering_meetups/", "subreddit_subscribers": 115706, "created_utc": 1689235429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it good practice to store event data in object storage one by one? I.e. if I get 1M events/messages a day I store 1M small e.g. JSON files into the S3 and then batch process it at the end of day. Is this reasonable or I should somehow buffer all the messages and then save only one (or little more) batched files into the S3? Also why / why not?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing realtime events in object storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yxlz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689285022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it good practice to store event data in object storage one by one? I.e. if I get 1M events/messages a day I store 1M small e.g. JSON files into the S3 and then batch process it at the end of day. Is this reasonable or I should somehow buffer all the messages and then save only one (or little more) batched files into the S3? Also why / why not?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yxlz3", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yxlz3/storing_realtime_events_in_object_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yxlz3/storing_realtime_events_in_object_storage/", "subreddit_subscribers": 115706, "created_utc": 1689285022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://gretel.ai/blog/bring-your-own-cloud](https://gretel.ai/blog/bring-your-own-cloud)", "author_fullname": "t2_t4pwocav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anonymizing 7 terabytes of data in a hybrid cloud environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yw2dw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689281361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://gretel.ai/blog/bring-your-own-cloud\"&gt;https://gretel.ai/blog/bring-your-own-cloud&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?auto=webp&amp;s=bc3493917d3704a273ac737908af2200db053206", "width": 1440, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=210062dc56f116a92ad54cdf589382f4650558c0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=741b610f3aa7f92a6b0203c040fa6891d241da6f", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5149bccc1297b6b740a39bf74fd35c006475e3bc", "width": 320, "height": 177}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ddf12ec791acf3397800e1010de4283a3b40eca8", "width": 640, "height": 355}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=40087377ec3b0914b0d3606118e69ad54f379863", "width": 960, "height": 533}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd781648c0620c89b350217cc0e058fc94a7142e", "width": 1080, "height": 600}], "variants": {}, "id": "P3FdEpfGKtApmyi9xRhUP9Uq6puzmmJGETUlq8e2RgE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14yw2dw", "is_robot_indexable": true, "report_reasons": null, "author": "Synthesize2023", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yw2dw/anonymizing_7_terabytes_of_data_in_a_hybrid_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yw2dw/anonymizing_7_terabytes_of_data_in_a_hybrid_cloud/", "subreddit_subscribers": 115706, "created_utc": 1689281361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! At my company, Journalize, our users wanted to add arbitrary tags to their data so they could slice and dice against any dimension. To aggregate data over 10M rows, we set up a Clickhouse server with some magic. I'm curious if people can also use what we built. \n\n(note: im expecting the data purists to hate this, and I am ready for that\u2026 :)\n\nWe are calling it ScratchDB: Firestore for analytics. Stream JSON, and we\u2019ll figure out how to get it into an analytical database, and you can run SQL. \n\nWebsite: [https://www.scratchdb.com](https://www.scratchdb.com/)\n\nGithub: [https://github.com/scratchdata/ScratchDB](https://github.com/scratchdata/ScratchDB) \n\nThe problem as I see it: \n\n* At some point, you might find that GROUP BYs are slow in Postgres and want an analytical database\n* Getting started has technical friction: choosing a DB, new underlying storage models, monitoring servers\n* Pricing is opaque: self-hosting vs cloud, credits, vCPUs, it\u2019s hard to answer \u201chow much will this thing cost\u201d, and often the answer is \u201ca lot\u201d\n\nWith ScratchDB:\n\n* No need to issue a CREATE TABLE statement. Send your JSON and we will automatically create tables and columns on the fly.\n* Just pay for what you use via metrics you can easily understand (storage, processing time)\n* ScratchDB is open source (github) and right now it runs on top of DuckDB. (More connectors in the works!) It is written in Go.\n\nI am really curious about what people think. Also, we\u2019d love to know how you\u2019re doing this today, how much it costs, and what your devops looks like. (if you\u2019re willing to shoot me a DM!) \n\nLet us see if we can help you ingest data into your DB more easily. If this is a pain point on non-analytics workloads, I\u2019m interested in talking as this is also on our roadmap.\n\nThanks in advance! ", "author_fullname": "t2_4mv9dvc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Useful or nah: open-source serverless analytics DB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yv3kv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689279112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! At my company, Journalize, our users wanted to add arbitrary tags to their data so they could slice and dice against any dimension. To aggregate data over 10M rows, we set up a Clickhouse server with some magic. I&amp;#39;m curious if people can also use what we built. &lt;/p&gt;\n\n&lt;p&gt;(note: im expecting the data purists to hate this, and I am ready for that\u2026 :)&lt;/p&gt;\n\n&lt;p&gt;We are calling it ScratchDB: Firestore for analytics. Stream JSON, and we\u2019ll figure out how to get it into an analytical database, and you can run SQL. &lt;/p&gt;\n\n&lt;p&gt;Website: &lt;a href=\"https://www.scratchdb.com/\"&gt;https://www.scratchdb.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/scratchdata/ScratchDB\"&gt;https://github.com/scratchdata/ScratchDB&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;The problem as I see it: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;At some point, you might find that GROUP BYs are slow in Postgres and want an analytical database&lt;/li&gt;\n&lt;li&gt;Getting started has technical friction: choosing a DB, new underlying storage models, monitoring servers&lt;/li&gt;\n&lt;li&gt;Pricing is opaque: self-hosting vs cloud, credits, vCPUs, it\u2019s hard to answer \u201chow much will this thing cost\u201d, and often the answer is \u201ca lot\u201d&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With ScratchDB:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;No need to issue a CREATE TABLE statement. Send your JSON and we will automatically create tables and columns on the fly.&lt;/li&gt;\n&lt;li&gt;Just pay for what you use via metrics you can easily understand (storage, processing time)&lt;/li&gt;\n&lt;li&gt;ScratchDB is open source (github) and right now it runs on top of DuckDB. (More connectors in the works!) It is written in Go.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am really curious about what people think. Also, we\u2019d love to know how you\u2019re doing this today, how much it costs, and what your devops looks like. (if you\u2019re willing to shoot me a DM!) &lt;/p&gt;\n\n&lt;p&gt;Let us see if we can help you ingest data into your DB more easily. If this is a pain point on non-analytics workloads, I\u2019m interested in talking as this is also on our roadmap.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14yv3kv", "is_robot_indexable": true, "report_reasons": null, "author": "robertao211", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yv3kv/useful_or_nah_opensource_serverless_analytics_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yv3kv/useful_or_nah_opensource_serverless_analytics_db/", "subreddit_subscribers": 115706, "created_utc": 1689279112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have built a custom Prometheus metrics exporter in Python for a Database system. \nThe exporter's job is to get data from the DB by running SQL queries (E), Convert the tabular data to key value pairs (T) and then send it to Prometheus (L).\nDoes this classify as an ETL job ?", "author_fullname": "t2_2hokn0mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can this be called an ETL ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ysqvg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689273573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have built a custom Prometheus metrics exporter in Python for a Database system. \nThe exporter&amp;#39;s job is to get data from the DB by running SQL queries (E), Convert the tabular data to key value pairs (T) and then send it to Prometheus (L).\nDoes this classify as an ETL job ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ysqvg", "is_robot_indexable": true, "report_reasons": null, "author": "deathlolwut", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ysqvg/can_this_be_called_an_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ysqvg/can_this_be_called_an_etl/", "subreddit_subscribers": 115706, "created_utc": 1689273573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone attended? How does it compare to other Data conferences?\n\nedw2023fall.dataversity.net\n\nI saw this post from earlier this year but didn't catch any mention of this one.", "author_fullname": "t2_4fhdq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enterprise Data World (EDW) Conference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ys7lx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689272290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone attended? How does it compare to other Data conferences?&lt;/p&gt;\n\n&lt;p&gt;edw2023fall.dataversity.net&lt;/p&gt;\n\n&lt;p&gt;I saw this post from earlier this year but didn&amp;#39;t catch any mention of this one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ys7lx", "is_robot_indexable": true, "report_reasons": null, "author": "tolkienwhiteboy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ys7lx/enterprise_data_world_edw_conference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ys7lx/enterprise_data_world_edw_conference/", "subreddit_subscribers": 115706, "created_utc": 1689272290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at an org where our data engineers have bought into dagster. Dagster seems great, except I can\u2019t wrap my head around how to set it up for multiple github repositories.\n\nSo we have one repo that has all the infrastructure code for dagster. Currently our data engineers keep the infra code (terraform) with their job (so its a monorepo). As dagster expands to other teams we have many projects across different repos. So for example some of my models (i am a data scientist) exist in different repos and would continue to exist in different repos. What is the simplest way to allow for me to continue this framework?", "author_fullname": "t2_a071r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster with multiple repos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yryax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689271695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at an org where our data engineers have bought into dagster. Dagster seems great, except I can\u2019t wrap my head around how to set it up for multiple github repositories.&lt;/p&gt;\n\n&lt;p&gt;So we have one repo that has all the infrastructure code for dagster. Currently our data engineers keep the infra code (terraform) with their job (so its a monorepo). As dagster expands to other teams we have many projects across different repos. So for example some of my models (i am a data scientist) exist in different repos and would continue to exist in different repos. What is the simplest way to allow for me to continue this framework?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14yryax", "is_robot_indexable": true, "report_reasons": null, "author": "IAteQuarters", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yryax/dagster_with_multiple_repos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yryax/dagster_with_multiple_repos/", "subreddit_subscribers": 115706, "created_utc": 1689271695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Rengineers,\n\nLooking for a steer within the world of Microsoft Fabric, which is quite new to me.\n\nWe have about 4 core off the shelf operational systems. 3 have APIs, 1 has csv exports. Not big data.\n\nWe are setting up Data Flows within Microsoft Fabric, where each Data Flow is basically an api endpoint (or csv export) for each system, and thus makes the returned data available for querying and analysis (in Power BI).\n\n**Problem: we have no identity resolution solution, i.e., our unique identifiers in system 1 are different to those in system 2 (and so on), making it difficult to link data across systems.**\n\nThe outcome I'm looking for is a new table that links customers together from all data sources and generates a linkage key (likely using probabilistic matching). This table and linkage key can then be used in any new local data models (in Power BI for example).\n\nHow would you approach this in the world of Fabric? Which experience would you use (likely one of Data Factory, Data Engineering, Data Science, Data Warehouse?). I've narrowed down the likely options here:\n\nPower BI\n\n1. Data Flow\n2. Data Set\n3. Data Mart\n\nData Engineering\n\n1. Lakehouse\n2. Spark Job\n\nData Factory\n\n1. Data pipeline\n\nData science\n\n1. Model\n2. Experiment\n\nData Warehouse\n\n1. Warehouse\n\nAny pointers welcome :-)\n\n&amp;#x200B;", "author_fullname": "t2_e7ybf8uo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identity resolution in Microsoft Fabric", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yr9y1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689272274.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689270130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Rengineers,&lt;/p&gt;\n\n&lt;p&gt;Looking for a steer within the world of Microsoft Fabric, which is quite new to me.&lt;/p&gt;\n\n&lt;p&gt;We have about 4 core off the shelf operational systems. 3 have APIs, 1 has csv exports. Not big data.&lt;/p&gt;\n\n&lt;p&gt;We are setting up Data Flows within Microsoft Fabric, where each Data Flow is basically an api endpoint (or csv export) for each system, and thus makes the returned data available for querying and analysis (in Power BI).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem: we have no identity resolution solution, i.e., our unique identifiers in system 1 are different to those in system 2 (and so on), making it difficult to link data across systems.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The outcome I&amp;#39;m looking for is a new table that links customers together from all data sources and generates a linkage key (likely using probabilistic matching). This table and linkage key can then be used in any new local data models (in Power BI for example).&lt;/p&gt;\n\n&lt;p&gt;How would you approach this in the world of Fabric? Which experience would you use (likely one of Data Factory, Data Engineering, Data Science, Data Warehouse?). I&amp;#39;ve narrowed down the likely options here:&lt;/p&gt;\n\n&lt;p&gt;Power BI&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Flow&lt;/li&gt;\n&lt;li&gt;Data Set&lt;/li&gt;\n&lt;li&gt;Data Mart&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Data Engineering&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Lakehouse&lt;/li&gt;\n&lt;li&gt;Spark Job&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Data Factory&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data pipeline&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Data science&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Model&lt;/li&gt;\n&lt;li&gt;Experiment&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Data Warehouse&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Warehouse&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any pointers welcome :-)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14yr9y1", "is_robot_indexable": true, "report_reasons": null, "author": "data_quantum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yr9y1/identity_resolution_in_microsoft_fabric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yr9y1/identity_resolution_in_microsoft_fabric/", "subreddit_subscribers": 115706, "created_utc": 1689270130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for a partner to study data engineering with, the thing is it is not that I lack motivation, but it is difficult to focus and structure the content when you are learning by yourself, having another person helps to navigate all the ruts in the way. Now disclaimer, I am a complete beginner, no work experience, therefore I look forward to anyone who also wants to learn data engineering from scratch, I know this sub has more experienced people than beginners, so it is alright if you are experienced, I will try my best to keep up with you.\n\nhere are few non negotiables, you must be very disciplined and driven and I promise to be same, preferably enrolled in computer science or similar degree or program and are not completely new to computer science as a subject, this should not be experimental, hobby thing for you and you are willing to put in work to progress.\n\nWe can decide on what resources to learn and make goalpost for projects, applying to internship or job as we progress, weekly discussions or brainstorming session, most importantly constantly sharing what and how we learnt something new or overcame a complex problem, point being having consistent communication, honesty, enthusiasm with learning goal.", "author_fullname": "t2_jhao971m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for study buddy + accountability partner for data engineering as a complete beginner", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yr5ed", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689269834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a partner to study data engineering with, the thing is it is not that I lack motivation, but it is difficult to focus and structure the content when you are learning by yourself, having another person helps to navigate all the ruts in the way. Now disclaimer, I am a complete beginner, no work experience, therefore I look forward to anyone who also wants to learn data engineering from scratch, I know this sub has more experienced people than beginners, so it is alright if you are experienced, I will try my best to keep up with you.&lt;/p&gt;\n\n&lt;p&gt;here are few non negotiables, you must be very disciplined and driven and I promise to be same, preferably enrolled in computer science or similar degree or program and are not completely new to computer science as a subject, this should not be experimental, hobby thing for you and you are willing to put in work to progress.&lt;/p&gt;\n\n&lt;p&gt;We can decide on what resources to learn and make goalpost for projects, applying to internship or job as we progress, weekly discussions or brainstorming session, most importantly constantly sharing what and how we learnt something new or overcame a complex problem, point being having consistent communication, honesty, enthusiasm with learning goal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14yr5ed", "is_robot_indexable": true, "report_reasons": null, "author": "ComputerFine971", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yr5ed/looking_for_study_buddy_accountability_partner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yr5ed/looking_for_study_buddy_accountability_partner/", "subreddit_subscribers": 115706, "created_utc": 1689269834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90z29170", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Grad Software Engineer: Which Data Field Will Stay Relevant in 5 Years? Seeking Insight and Perspectives!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_14yvwc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/hMRZmN4LK5U?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Why I Left Data Science - And Picked Data Engineering Instead\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Why I Left Data Science - And Picked Data Engineering Instead", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/hMRZmN4LK5U?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Why I Left Data Science - And Picked Data Engineering Instead\"&gt;&lt;/iframe&gt;", "author_name": "Seattle Data Guy", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/hMRZmN4LK5U/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SeattleDataGuy"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/hMRZmN4LK5U?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Why I Left Data Science - And Picked Data Engineering Instead\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/14yvwc6", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lp1D98VJca3-0DgGZI03iHo1tedNx2N5VluWGyvovaA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689280962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=hMRZmN4LK5U", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CXjXCaEg86kSp28qW5_-VwbVbMGTyup8JutwtcO6lJk.jpg?auto=webp&amp;s=affb7e74969fa741b50ede173b8ca7dd0aa3242a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/CXjXCaEg86kSp28qW5_-VwbVbMGTyup8JutwtcO6lJk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c043a6c40df45c7cc8cb4e3cb90fb677b720fbaa", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/CXjXCaEg86kSp28qW5_-VwbVbMGTyup8JutwtcO6lJk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=79003f6e5bfdd056cb55a02c13e7233fca2f05e2", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/CXjXCaEg86kSp28qW5_-VwbVbMGTyup8JutwtcO6lJk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2fb1ec5c93f6ffc9e9e4a6ab9122e7cce83b742b", "width": 320, "height": 240}], "variants": {}, "id": "6vB4yvV0KETwghg-rd1WR9_rlBs_VUIKvZAqtq2U1Ms"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yvwc6", "is_robot_indexable": true, "report_reasons": null, "author": "No-Platypus4021", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yvwc6/new_grad_software_engineer_which_data_field_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=hMRZmN4LK5U", "subreddit_subscribers": 115706, "created_utc": 1689280962.0, "num_crossposts": 1, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Why I Left Data Science - And Picked Data Engineering Instead", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/hMRZmN4LK5U?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Why I Left Data Science - And Picked Data Engineering Instead\"&gt;&lt;/iframe&gt;", "author_name": "Seattle Data Guy", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/hMRZmN4LK5U/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SeattleDataGuy"}}, "is_video": false}}], "before": null}}