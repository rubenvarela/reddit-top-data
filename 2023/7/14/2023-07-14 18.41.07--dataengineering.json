{"kind": "Listing", "data": {"after": "t3_14yw2dw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's not a glamorous life, but we all know who really drives the bus", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_14zh0hc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 125, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 125, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/m14lmAG0ui7VEFcfbPvurOvy93OiuuycSgEt0QBVzKg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689342659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/s3fg4dwiqxbb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?auto=webp&amp;s=3b4788debae0b50692b52c64f9b1465f721ec307", "width": 960, "height": 650}, "resolutions": [{"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca4a7e5f025aca555f8d3c025919302b95b3cfdf", "width": 108, "height": 73}, {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c2e25429082ec285073c637ded4f2309193a93d4", "width": 216, "height": 146}, {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=97d836c80ded7134399c0ca4ec91bd1589b084a5", "width": 320, "height": 216}, {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=afff761684fd73ee8df231ea5466221138de4f58", "width": 640, "height": 433}, {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5d72044ab3f3129252dad596c3c4e3e61febeb07", "width": 960, "height": 650}], "variants": {}, "id": "MP16Sf-Yv6ddJsm3DGwjB7o8R2THbfQBktZKU5To4WM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14zh0hc", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zh0hc/its_not_a_glamorous_life_but_we_all_know_who/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/s3fg4dwiqxbb1.png", "subreddit_subscribers": 115785, "created_utc": 1689342659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few months ago I changed from data scientist to engineer, since in my previous company I did everything myself, but being a CS guy I pref the data engineering part.\n\nIn my current company, a multinational telecommunications, I only do SQL queries and stupid dashboards for marketing and business, I feel frustrated because anyone can do this\u2026  And it has little to do with the Data Engineer role that I was offered.\n\nHow much do you use SQL in your daily work ?", "author_fullname": "t2_4kdegv81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL only - Work frustration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z8hhn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689315999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months ago I changed from data scientist to engineer, since in my previous company I did everything myself, but being a CS guy I pref the data engineering part.&lt;/p&gt;\n\n&lt;p&gt;In my current company, a multinational telecommunications, I only do SQL queries and stupid dashboards for marketing and business, I feel frustrated because anyone can do this\u2026  And it has little to do with the Data Engineer role that I was offered.&lt;/p&gt;\n\n&lt;p&gt;How much do you use SQL in your daily work ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z8hhn", "is_robot_indexable": true, "report_reasons": null, "author": "xchgre", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z8hhn/sql_only_work_frustration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z8hhn/sql_only_work_frustration/", "subreddit_subscribers": 115785, "created_utc": 1689315999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a Data Engineer what\u2019s your biggest headache, frustration, time suck?", "author_fullname": "t2_3cr575ib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Headaches", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z3dvp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689300344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a Data Engineer what\u2019s your biggest headache, frustration, time suck?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z3dvp", "is_robot_indexable": true, "report_reasons": null, "author": "jayking51", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z3dvp/data_engineering_headaches/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z3dvp/data_engineering_headaches/", "subreddit_subscribers": 115785, "created_utc": 1689300344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Facing a potential layoff soon, so have started applying to some data engineer, jr data engineer and analytics engineer positions. I thought I'd put a project up on github so any HM could see a bit of my skills. If you saw this and actually looked through it, what would you think?\n\n[https://github.com/jrey999/mlb](https://github.com/jrey999/mlb)", "author_fullname": "t2_v4s5fwgd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you saw this and actually looked through it, what would you think", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z582e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689305728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Facing a potential layoff soon, so have started applying to some data engineer, jr data engineer and analytics engineer positions. I thought I&amp;#39;d put a project up on github so any HM could see a bit of my skills. If you saw this and actually looked through it, what would you think?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/jrey999/mlb\"&gt;https://github.com/jrey999/mlb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?auto=webp&amp;s=f23cd95bd53dfe4d4782e84979e0b6b62d084129", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a3709fc1236118224429386fed0b00f235baf0a2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=45ae7c8e42e8f1b6bd02486b081cc4056b35f870", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ab7afb2fabfb98da681c7ddf4639747d1c14d8d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=adbfb6983d38667cc57a25c401ea92acc4adaf10", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5882b19e3647675aee89370079a541eb94210638", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c01dcaee91410f53051d02152cc9c3ce4b8fdcc", "width": 1080, "height": 540}], "variants": {}, "id": "ZTkos4tP2WpR9wFxhobnnfq39iPZLNNBaB0u--0xAy0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "14z582e", "is_robot_indexable": true, "report_reasons": null, "author": "big_lazerz", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z582e/if_you_saw_this_and_actually_looked_through_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z582e/if_you_saw_this_and_actually_looked_through_it/", "subreddit_subscribers": 115785, "created_utc": 1689305728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I love cbt. I finally get the fuss now.\n\nBack in the olden days, I'd just dump all of my pandas/polars tasks in one compact jupyter notebook, download it all as a .py file, and call it a day. I genuinely thought that was better and more compact.\n\nBut now after using dbt for the first time, I can sort of see its usefulness. I rewrote the pandas stuff as a chain of CTE statements and breaking them up into different, consecutive SQL files. It really forces you to view things more modular, and while SQL can't do as much stuff as python, I gotta agree that it's overall cleaner to read, even as someone who was taught Python before SQL and thus feels biased for Python.\n\nThe only thing I don't know how to exactly do yet is interrupt the dbt midway to do something only python can do, or rather something SQL can't do (like adding columns that are the output of a machine learning method such as k-means, tf-idf, or PCA), and then resuming the dbt.", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After balking for a long time, tried out dbt for the first time and now am a full convert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z9id2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689319474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I love cbt. I finally get the fuss now.&lt;/p&gt;\n\n&lt;p&gt;Back in the olden days, I&amp;#39;d just dump all of my pandas/polars tasks in one compact jupyter notebook, download it all as a .py file, and call it a day. I genuinely thought that was better and more compact.&lt;/p&gt;\n\n&lt;p&gt;But now after using dbt for the first time, I can sort of see its usefulness. I rewrote the pandas stuff as a chain of CTE statements and breaking them up into different, consecutive SQL files. It really forces you to view things more modular, and while SQL can&amp;#39;t do as much stuff as python, I gotta agree that it&amp;#39;s overall cleaner to read, even as someone who was taught Python before SQL and thus feels biased for Python.&lt;/p&gt;\n\n&lt;p&gt;The only thing I don&amp;#39;t know how to exactly do yet is interrupt the dbt midway to do something only python can do, or rather something SQL can&amp;#39;t do (like adding columns that are the output of a machine learning method such as k-means, tf-idf, or PCA), and then resuming the dbt.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z9id2", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 9, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z9id2/after_balking_for_a_long_time_tried_out_dbt_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z9id2/after_balking_for_a_long_time_tried_out_dbt_for/", "subreddit_subscribers": 115785, "created_utc": 1689319474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have worked as a software engineer and I am now on my second data engineering position. As time marches on it seems that I am fighting a losing battle trying to implement automated logic tests for SQL testing.\n\nAs a software engineer I wrote tests to validate that for input x I would get output y and then make sure all the edge cases were covered. I have worked on data warehouse projects that used a similar \"unit test approach\": load a test data set into the database and verify the result of some sql. When I moved into doing work in a data science department we used Spark to mock out data frames and test the output of an operation.\n\nHowever this does not seem to be how the industry as a whole handles things. It seems that teams test the general shape of some transform logic such as row counts or if a value falls within a range. I am curious what other folks impressions are (not just your team, but data engineering as a whole)?\n\nOn a side note: I read articles like [https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc](https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc) which makes me think people are testing transforms, but then I see polls like this [https://www.jetbrains.com/lp/devecosystem-2021/databases/](https://www.jetbrains.com/lp/devecosystem-2021/databases/) that indicate people don't really test.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_3j0if", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Testing: a loosing battle?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ywjwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689282451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have worked as a software engineer and I am now on my second data engineering position. As time marches on it seems that I am fighting a losing battle trying to implement automated logic tests for SQL testing.&lt;/p&gt;\n\n&lt;p&gt;As a software engineer I wrote tests to validate that for input x I would get output y and then make sure all the edge cases were covered. I have worked on data warehouse projects that used a similar &amp;quot;unit test approach&amp;quot;: load a test data set into the database and verify the result of some sql. When I moved into doing work in a data science department we used Spark to mock out data frames and test the output of an operation.&lt;/p&gt;\n\n&lt;p&gt;However this does not seem to be how the industry as a whole handles things. It seems that teams test the general shape of some transform logic such as row counts or if a value falls within a range. I am curious what other folks impressions are (not just your team, but data engineering as a whole)?&lt;/p&gt;\n\n&lt;p&gt;On a side note: I read articles like &lt;a href=\"https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc\"&gt;https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc&lt;/a&gt; which makes me think people are testing transforms, but then I see polls like this &lt;a href=\"https://www.jetbrains.com/lp/devecosystem-2021/databases/\"&gt;https://www.jetbrains.com/lp/devecosystem-2021/databases/&lt;/a&gt; that indicate people don&amp;#39;t really test.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?auto=webp&amp;s=d89a17b05c97281fdd6453dd599945fcd7336b51", "width": 1005, "height": 444}, "resolutions": [{"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e64df404a8a381f61dba9b394f45d66d2547dcc3", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42e227a370404b011573e86f3dfe060ce05c42c2", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=45c6aabe350b41595aa55f72de51cc2cd7d9642a", "width": 320, "height": 141}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9d006f825a0b89e3e1524059d5ff1f6de8c6f2c", "width": 640, "height": 282}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=21f0334d6bb2c2fcc573a1f64aaa8bd05c5689c5", "width": 960, "height": 424}], "variants": {}, "id": "6c4F5f_MtX1XvNBav9lGrhcENIY60PGLA8mRkZf-GFo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ywjwa", "is_robot_indexable": true, "report_reasons": null, "author": "jaynerd", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ywjwa/sql_testing_a_loosing_battle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ywjwa/sql_testing_a_loosing_battle/", "subreddit_subscribers": 115785, "created_utc": 1689282451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was a Business Intelligence Analyst/SQL developer from 2016-2021. I was working mostly with SSIS and Microsoft SQL Server. Cron + Powershell were my best frenemies. I have a fundamental understanding of data structures, patterns, etc; know SQL very well and have a cursory understanding of Python\u2014I\u2019ve done some personal projects but never needed it for work. I\u2019m also pretty familiar with Git and general SDLC best practices. \n\nI worked at two \u201ctech enabled\u201d companies where their primary business was selling a service that was \u201cdata-driven\u201d and backed with \u201ccutting edge tech\u201d but in reality the tech was a giant spaghetti mess behind the scenes and probably 7+ years behind current day at all times. These companies had terrible on-call practices and that plus spaghetti architecture, I was getting constantly pinged after hours for this or that broken thing\u2014a lot of times late at night. In short, I got fully burnt out. \n\nFast forward to today, I ended up landing a TPM role at a company whose tech stack is current day. They have their problems like anywhere else but from what I can tell, the Eng teams have mature on call procedures that actually split up the work. I like this company but despite \u201ctechnical\u201d in the name, the TPM role here is not at all technical. Now I\u2019m working through whether or not it would even be possible to transition over to their DW team and be in more of an Eng role again.\n\nI know I\u2019ve got some skills gaps to fill.  Airflow, Big Query and Python are going to be key for this role and I\u2019ve never worked with them day to day. In reality, if that team even wants me I\u2019d probably need to step down in seniority a level or two and I\u2019d be fine with that. But what I\u2019m trying to work out is, with these more modern tools, is the job really going to be THAT different? Do I need to set the expectation for myself that if I pursue this, I am essentially starting from scratch? I think what really worries me is that I do not have a formal CS background\u2014in my prior life I was totally self taught, so I fear there might be some knowledge gaps I don\u2019t even know I have.", "author_fullname": "t2_oim4bt00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are My Skills Too Far Gone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zgfh5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689341155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was a Business Intelligence Analyst/SQL developer from 2016-2021. I was working mostly with SSIS and Microsoft SQL Server. Cron + Powershell were my best frenemies. I have a fundamental understanding of data structures, patterns, etc; know SQL very well and have a cursory understanding of Python\u2014I\u2019ve done some personal projects but never needed it for work. I\u2019m also pretty familiar with Git and general SDLC best practices. &lt;/p&gt;\n\n&lt;p&gt;I worked at two \u201ctech enabled\u201d companies where their primary business was selling a service that was \u201cdata-driven\u201d and backed with \u201ccutting edge tech\u201d but in reality the tech was a giant spaghetti mess behind the scenes and probably 7+ years behind current day at all times. These companies had terrible on-call practices and that plus spaghetti architecture, I was getting constantly pinged after hours for this or that broken thing\u2014a lot of times late at night. In short, I got fully burnt out. &lt;/p&gt;\n\n&lt;p&gt;Fast forward to today, I ended up landing a TPM role at a company whose tech stack is current day. They have their problems like anywhere else but from what I can tell, the Eng teams have mature on call procedures that actually split up the work. I like this company but despite \u201ctechnical\u201d in the name, the TPM role here is not at all technical. Now I\u2019m working through whether or not it would even be possible to transition over to their DW team and be in more of an Eng role again.&lt;/p&gt;\n\n&lt;p&gt;I know I\u2019ve got some skills gaps to fill.  Airflow, Big Query and Python are going to be key for this role and I\u2019ve never worked with them day to day. In reality, if that team even wants me I\u2019d probably need to step down in seniority a level or two and I\u2019d be fine with that. But what I\u2019m trying to work out is, with these more modern tools, is the job really going to be THAT different? Do I need to set the expectation for myself that if I pursue this, I am essentially starting from scratch? I think what really worries me is that I do not have a formal CS background\u2014in my prior life I was totally self taught, so I fear there might be some knowledge gaps I don\u2019t even know I have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14zgfh5", "is_robot_indexable": true, "report_reasons": null, "author": "Alternative-Engine77", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zgfh5/are_my_skills_too_far_gone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zgfh5/are_my_skills_too_far_gone/", "subreddit_subscribers": 115785, "created_utc": 1689341155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently a data analyst with 2 YOE. I have worked on SQL, python (for retrieving and transformaing the data for analysis),excel and Tableau. I feel that i would be able to do better as a data engineer. So I taught myself spark, hive, azure data factory and databricks (fundamental). Now when I tried to analyse the market requirements for data engineer, I am overwhelmed with the different requirements they have (airflow, Kafka, warehousing , DBT and a lot). I feel like I would have to spend another year to catch up with the requirements. \nHow should I plan? I feel like I am lost. \nPlease help", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overwhelmed with such detailed job descriptions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zhtx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689347877.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689344668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a data analyst with 2 YOE. I have worked on SQL, python (for retrieving and transformaing the data for analysis),excel and Tableau. I feel that i would be able to do better as a data engineer. So I taught myself spark, hive, azure data factory and databricks (fundamental). Now when I tried to analyse the market requirements for data engineer, I am overwhelmed with the different requirements they have (airflow, Kafka, warehousing , DBT and a lot). I feel like I would have to spend another year to catch up with the requirements. \nHow should I plan? I feel like I am lost. \nPlease help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14zhtx1", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zhtx1/overwhelmed_with_such_detailed_job_descriptions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zhtx1/overwhelmed_with_such_detailed_job_descriptions/", "subreddit_subscribers": 115785, "created_utc": 1689344668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello Everyone! \n\nWhat are the AWS alerting and notification best practices. While we've covered the basics in the current org where we get a notification on every failure, plain email saying the job is failed. We would like to have a thought process to see what is best in \n\n&amp;#x200B;\n\n How have you expanded your AWS alerts beyond job failures?    \n Have you utilized Amazon SES to deliver timely notifications? how you have optimized the failed emails  \n How have you leveraged AWS Glue and Lambda to automate your alerting process? \n\n For those who have integrated PagerDuty within their AWS infrastructure  \n\n&amp;#x200B;\n\nwhat is the best enterprise-level strategy for alerting and notifications?", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Alerting and Notification Best Practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z2ieu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689297884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone! &lt;/p&gt;\n\n&lt;p&gt;What are the AWS alerting and notification best practices. While we&amp;#39;ve covered the basics in the current org where we get a notification on every failure, plain email saying the job is failed. We would like to have a thought process to see what is best in &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How have you expanded your AWS alerts beyond job failures?&lt;br/&gt;\n Have you utilized Amazon SES to deliver timely notifications? how you have optimized the failed emails&lt;br/&gt;\n How have you leveraged AWS Glue and Lambda to automate your alerting process? &lt;/p&gt;\n\n&lt;p&gt;For those who have integrated PagerDuty within their AWS infrastructure  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;what is the best enterprise-level strategy for alerting and notifications?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z2ieu", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z2ieu/aws_alerting_and_notification_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z2ieu/aws_alerting_and_notification_best_practices/", "subreddit_subscribers": 115785, "created_utc": 1689297884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im looking to get a general idea of the spark ecosystem and fundamentals because at our company we are using a custom made abstraction above \"Apache Spark\". A lot of concepts are mapped 1:1.  Mainly for ETL purposes (data processing etc)\n\nAny idea's suggestions? by reading books, tutorials etc", "author_fullname": "t2_dr0lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn apache spark as a beginner/junior/new grad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ysuu6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689273837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im looking to get a general idea of the spark ecosystem and fundamentals because at our company we are using a custom made abstraction above &amp;quot;Apache Spark&amp;quot;. A lot of concepts are mapped 1:1.  Mainly for ETL purposes (data processing etc)&lt;/p&gt;\n\n&lt;p&gt;Any idea&amp;#39;s suggestions? by reading books, tutorials etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ysuu6", "is_robot_indexable": true, "report_reasons": null, "author": "poepstinktvies", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ysuu6/how_to_learn_apache_spark_as_a_beginnerjuniornew/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ysuu6/how_to_learn_apache_spark_as_a_beginnerjuniornew/", "subreddit_subscribers": 115785, "created_utc": 1689273837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interesting argument ...\n\nMax Kremer makes the case for Postgres as a protocol. What say you?\n\n[https://lassoo.io/blog/2023/07/12/postgres-as-a-protocol/](https://lassoo.io/blog/2023/07/12/postgres-as-a-protocol/)", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Postgres as a protocol", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zh9r4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689343304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interesting argument ...&lt;/p&gt;\n\n&lt;p&gt;Max Kremer makes the case for Postgres as a protocol. What say you?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lassoo.io/blog/2023/07/12/postgres-as-a-protocol/\"&gt;https://lassoo.io/blog/2023/07/12/postgres-as-a-protocol/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?auto=webp&amp;s=7fedf2eac5f590c277dbed62fe26cfeb652ed405", "width": 2999, "height": 1999}, "resolutions": [{"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=73fb0dc2dacafab2034fea682b33bf91648139d6", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9975375d1e3d91d1d89b51e74eaf0c85cdfd1213", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6027907c03ebe144b4ae266b6755bc3bf81b474f", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=92466a29dc68c9d27011adf08c6d4d699ceb7a1d", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d9ea62c56a85c8a03a9ca01a55043d0f5f155ce8", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6364b6eabb2df7caea959709019fc42f704cbe8a", "width": 1080, "height": 719}], "variants": {}, "id": "aQX_3YZ3wbqFDdbKRgZqTUyXucO8TbZ7I0qDnosF4xw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14zh9r4", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zh9r4/postgres_as_a_protocol/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zh9r4/postgres_as_a_protocol/", "subreddit_subscribers": 115785, "created_utc": 1689343304.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nHow do you usually orchestrate your Airbyte ingestions / connections ?\n\nI\u2019m planning to use data form as well on the transformation layer so I\u2019m curious.\n\nI\u2019m looking for the cheapest easiest to maintain option", "author_fullname": "t2_851if4wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP - Airbyte and orchestration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zb4nb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689325100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;How do you usually orchestrate your Airbyte ingestions / connections ?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m planning to use data form as well on the transformation layer so I\u2019m curious.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for the cheapest easiest to maintain option&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zb4nb", "is_robot_indexable": true, "report_reasons": null, "author": "No-Dress-3160", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zb4nb/gcp_airbyte_and_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zb4nb/gcp_airbyte_and_orchestration/", "subreddit_subscribers": 115785, "created_utc": 1689325100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a couple of spark jobs writing data in hourly partitions using Avro and Parquet formats. The data is stored in AWS S3 in the same bucket, but each partition has a different prefix, e.g. \\`YYYY-MM-DD-HH\\`. How can I ensure that the downstream jobs won't see or be able to access an incomplete partition being written?", "author_fullname": "t2_mafti2dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the techniques to ensure atomic writes to partition?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zan40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689323403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a couple of spark jobs writing data in hourly partitions using Avro and Parquet formats. The data is stored in AWS S3 in the same bucket, but each partition has a different prefix, e.g. `YYYY-MM-DD-HH`. How can I ensure that the downstream jobs won&amp;#39;t see or be able to access an incomplete partition being written?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14zan40", "is_robot_indexable": true, "report_reasons": null, "author": "ad81923", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zan40/what_are_the_techniques_to_ensure_atomic_writes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zan40/what_are_the_techniques_to_ensure_atomic_writes/", "subreddit_subscribers": 115785, "created_utc": 1689323403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all  \nI am seeking advice and suggestions regarding an ELT workflow that my team has been implementing using BigQuery and Spark. I have encountered some challenges and would greatly appreciate the insights of this community.\n\nCurrently, I am using BigQuery for our ELT work, but the cost has been significant due to the rapid increase in data volume. To explore cost reduction options, my team decided to explore Dataproc. Our approach involves exporting BigQuery data to Google Cloud Storage (which is free up to 10TB per day), running a Spark job using the same query as in BigQuery (making it Spark compatible), writing the output DataFrame to GCS, and finally ingesting the data into a table (which is also free).\n\nHowever on doing this, I have observed two peculiar issues that I am struggling to resolve. Firstly, the BigQuery export process generates files of varying sizes, resulting in a large number of small files. This seems to significantly slow down the Spark job. Secondly, during a test job where the total size of input tables was around 300GB, I noticed that the YARN pending memory started at 2TB as shown on dashboard and kept decreasing as the job progressed. I am perplexed as to why the YARN pending memory would be 2TB for a dataset of just a few hundred gigabytes.\n\nGiven these challenges, I am seeking advice from the community. If any of you have attempted a similar workflow or encountered similar issues, I would like to hear about your experiences and the results you achieved. Did you optimize the BigQuery export process to avoid the problem of numerous small files? Do you believe the method of running spark jobs via above mentioned way is appropriate, or would you recommend any changes to improve the Spark job performance? Are there any specific optimizations or best practices you would recommend for Spark jobs?\n\nAny advice or suggestions you can provide would be highly appreciated. Thanks a lot in advance.", "author_fullname": "t2_cu6opso3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small file problem on spark in GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z7y9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689314250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;br/&gt;\nI am seeking advice and suggestions regarding an ELT workflow that my team has been implementing using BigQuery and Spark. I have encountered some challenges and would greatly appreciate the insights of this community.&lt;/p&gt;\n\n&lt;p&gt;Currently, I am using BigQuery for our ELT work, but the cost has been significant due to the rapid increase in data volume. To explore cost reduction options, my team decided to explore Dataproc. Our approach involves exporting BigQuery data to Google Cloud Storage (which is free up to 10TB per day), running a Spark job using the same query as in BigQuery (making it Spark compatible), writing the output DataFrame to GCS, and finally ingesting the data into a table (which is also free).&lt;/p&gt;\n\n&lt;p&gt;However on doing this, I have observed two peculiar issues that I am struggling to resolve. Firstly, the BigQuery export process generates files of varying sizes, resulting in a large number of small files. This seems to significantly slow down the Spark job. Secondly, during a test job where the total size of input tables was around 300GB, I noticed that the YARN pending memory started at 2TB as shown on dashboard and kept decreasing as the job progressed. I am perplexed as to why the YARN pending memory would be 2TB for a dataset of just a few hundred gigabytes.&lt;/p&gt;\n\n&lt;p&gt;Given these challenges, I am seeking advice from the community. If any of you have attempted a similar workflow or encountered similar issues, I would like to hear about your experiences and the results you achieved. Did you optimize the BigQuery export process to avoid the problem of numerous small files? Do you believe the method of running spark jobs via above mentioned way is appropriate, or would you recommend any changes to improve the Spark job performance? Are there any specific optimizations or best practices you would recommend for Spark jobs?&lt;/p&gt;\n\n&lt;p&gt;Any advice or suggestions you can provide would be highly appreciated. Thanks a lot in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z7y9h", "is_robot_indexable": true, "report_reasons": null, "author": "bha159", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z7y9h/small_file_problem_on_spark_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z7y9h/small_file_problem_on_spark_in_gcp/", "subreddit_subscribers": 115785, "created_utc": 1689314250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! At my company, Journalize, our users wanted to add arbitrary tags to their data so they could slice and dice against any dimension. To aggregate data over 10M rows, we set up a Clickhouse server with some magic. I'm curious if people can also use what we built. \n\n(note: im expecting the data purists to hate this, and I am ready for that\u2026 :)\n\nWe are calling it ScratchDB: Firestore for analytics. Stream JSON, and we\u2019ll figure out how to get it into an analytical database, and you can run SQL. \n\nWebsite: [https://www.scratchdb.com](https://www.scratchdb.com/)\n\nGithub: [https://github.com/scratchdata/ScratchDB](https://github.com/scratchdata/ScratchDB) \n\nThe problem as I see it: \n\n* At some point, you might find that GROUP BYs are slow in Postgres and want an analytical database\n* Getting started has technical friction: choosing a DB, new underlying storage models, monitoring servers\n* Pricing is opaque: self-hosting vs cloud, credits, vCPUs, it\u2019s hard to answer \u201chow much will this thing cost\u201d, and often the answer is \u201ca lot\u201d\n\nWith ScratchDB:\n\n* No need to issue a CREATE TABLE statement. Send your JSON and we will automatically create tables and columns on the fly.\n* Just pay for what you use via metrics you can easily understand (storage, processing time)\n* ScratchDB is open source (github) and right now it runs on top of DuckDB. (More connectors in the works!) It is written in Go.\n\nI am really curious about what people think. Also, we\u2019d love to know how you\u2019re doing this today, how much it costs, and what your devops looks like. (if you\u2019re willing to shoot me a DM!) \n\nLet us see if we can help you ingest data into your DB more easily. If this is a pain point on non-analytics workloads, I\u2019m interested in talking as this is also on our roadmap.\n\nThanks in advance! ", "author_fullname": "t2_4mv9dvc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Useful or nah: open-source serverless analytics DB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yv3kv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689279112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! At my company, Journalize, our users wanted to add arbitrary tags to their data so they could slice and dice against any dimension. To aggregate data over 10M rows, we set up a Clickhouse server with some magic. I&amp;#39;m curious if people can also use what we built. &lt;/p&gt;\n\n&lt;p&gt;(note: im expecting the data purists to hate this, and I am ready for that\u2026 :)&lt;/p&gt;\n\n&lt;p&gt;We are calling it ScratchDB: Firestore for analytics. Stream JSON, and we\u2019ll figure out how to get it into an analytical database, and you can run SQL. &lt;/p&gt;\n\n&lt;p&gt;Website: &lt;a href=\"https://www.scratchdb.com/\"&gt;https://www.scratchdb.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/scratchdata/ScratchDB\"&gt;https://github.com/scratchdata/ScratchDB&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;The problem as I see it: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;At some point, you might find that GROUP BYs are slow in Postgres and want an analytical database&lt;/li&gt;\n&lt;li&gt;Getting started has technical friction: choosing a DB, new underlying storage models, monitoring servers&lt;/li&gt;\n&lt;li&gt;Pricing is opaque: self-hosting vs cloud, credits, vCPUs, it\u2019s hard to answer \u201chow much will this thing cost\u201d, and often the answer is \u201ca lot\u201d&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With ScratchDB:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;No need to issue a CREATE TABLE statement. Send your JSON and we will automatically create tables and columns on the fly.&lt;/li&gt;\n&lt;li&gt;Just pay for what you use via metrics you can easily understand (storage, processing time)&lt;/li&gt;\n&lt;li&gt;ScratchDB is open source (github) and right now it runs on top of DuckDB. (More connectors in the works!) It is written in Go.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am really curious about what people think. Also, we\u2019d love to know how you\u2019re doing this today, how much it costs, and what your devops looks like. (if you\u2019re willing to shoot me a DM!) &lt;/p&gt;\n\n&lt;p&gt;Let us see if we can help you ingest data into your DB more easily. If this is a pain point on non-analytics workloads, I\u2019m interested in talking as this is also on our roadmap.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14yv3kv", "is_robot_indexable": true, "report_reasons": null, "author": "robertao211", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yv3kv/useful_or_nah_opensource_serverless_analytics_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yv3kv/useful_or_nah_opensource_serverless_analytics_db/", "subreddit_subscribers": 115785, "created_utc": 1689279112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was hired as a many-hats data analyst.\n\nFor the last few years, I\u2019ve:\n-Worked with SQL/Spark/Python\n-Managed countless ELTs in Databricks\n-Designed architecture and built tables for BI and ML purposes\n-Managed AWS Glue/S3 pipeline that replicates our prod database (eventually into Databricks)\n-Built pipelines that read/write to multiple tools (eg Salesforce, Marketo, Google Sheets) via APIs\n\nBut the areas I\u2019m lacking are:\n-Terabytes of data. At this point Ive only worked with gbs.\n-Best practices. My team was laid off so I no longer get feedback when I could be doing stuff better/more optimally. Not to mention data governance and all that jazz. \n\nBut yeah, I\u2019m wondering how much of my concern is legitimate and how much is imposter syndrome? Current title isn\u2019t an issue\u2014I could change that if I want. But when were you actually \u201cready\u201d and competitive enough to go for data engineer gigs?", "author_fullname": "t2_53o3zuz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m the de facto data engineer at a small startup (50 employees), but I don\u2019t feel like I could be competitive for a \u201creal\u201d data engineering job elsewhere.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14zn3b0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689358156.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689356825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was hired as a many-hats data analyst.&lt;/p&gt;\n\n&lt;p&gt;For the last few years, I\u2019ve:\n-Worked with SQL/Spark/Python\n-Managed countless ELTs in Databricks\n-Designed architecture and built tables for BI and ML purposes\n-Managed AWS Glue/S3 pipeline that replicates our prod database (eventually into Databricks)\n-Built pipelines that read/write to multiple tools (eg Salesforce, Marketo, Google Sheets) via APIs&lt;/p&gt;\n\n&lt;p&gt;But the areas I\u2019m lacking are:\n-Terabytes of data. At this point Ive only worked with gbs.\n-Best practices. My team was laid off so I no longer get feedback when I could be doing stuff better/more optimally. Not to mention data governance and all that jazz. &lt;/p&gt;\n\n&lt;p&gt;But yeah, I\u2019m wondering how much of my concern is legitimate and how much is imposter syndrome? Current title isn\u2019t an issue\u2014I could change that if I want. But when were you actually \u201cready\u201d and competitive enough to go for data engineer gigs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zn3b0", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable_Tooth_501", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zn3b0/im_the_de_facto_data_engineer_at_a_small_startup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zn3b0/im_the_de_facto_data_engineer_at_a_small_startup/", "subreddit_subscribers": 115785, "created_utc": 1689356825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Or both?! I am a software engineer looking to transition to data engineer, prepping for interviews. Been checking out the usual Youtube prep videos and I'm left wondering how prevalent system design is in the D.E. interview process.\n\nIf it makes a difference I'll probably be targeting low to mid level positions.", "author_fullname": "t2_15t1lq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are you more likely to face pipeline design or traditional system design questions in D.E. interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zjwlq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689349569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Or both?! I am a software engineer looking to transition to data engineer, prepping for interviews. Been checking out the usual Youtube prep videos and I&amp;#39;m left wondering how prevalent system design is in the D.E. interview process.&lt;/p&gt;\n\n&lt;p&gt;If it makes a difference I&amp;#39;ll probably be targeting low to mid level positions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14zjwlq", "is_robot_indexable": true, "report_reasons": null, "author": "James76589", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zjwlq/are_you_more_likely_to_face_pipeline_design_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zjwlq/are_you_more_likely_to_face_pipeline_design_or/", "subreddit_subscribers": 115785, "created_utc": 1689349569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Skimming through job descriptions, I see more and more DE roles that require data analysis and dashboarding skills. Usually this is listed under desirable, but I would still avoid those roles as I don't want to be dragged into any kind of analytics work. \n\nLuckily, the majority of jobs still differentiate between data engineering and analytics (be it data analysis or analytics engineering) , but I wonder if more companies are going to hire one person to work on DE and DA tasks simultaneously?", "author_fullname": "t2_vsf3ige5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE jobs with analytics requirements", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zjckj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689348629.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689348263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Skimming through job descriptions, I see more and more DE roles that require data analysis and dashboarding skills. Usually this is listed under desirable, but I would still avoid those roles as I don&amp;#39;t want to be dragged into any kind of analytics work. &lt;/p&gt;\n\n&lt;p&gt;Luckily, the majority of jobs still differentiate between data engineering and analytics (be it data analysis or analytics engineering) , but I wonder if more companies are going to hire one person to work on DE and DA tasks simultaneously?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zjckj", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated_Ad_1108", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zjckj/de_jobs_with_analytics_requirements/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zjckj/de_jobs_with_analytics_requirements/", "subreddit_subscribers": 115785, "created_utc": 1689348263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're working on an ETL pipeline that basically requires piping customer data from an SFTP site to our system on a recurring basis. *Presumably* the data will follow an agreed spec based on an initial sample, but that could change, or out-of-sample data could break some assumptions.\n\nWas looking at FlatFile who seems to lead in this kind of thing, but was curious what others think about the quality or limitations of it?", "author_fullname": "t2_3va4zgr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on FlatFile?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zj7xr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689347972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re working on an ETL pipeline that basically requires piping customer data from an SFTP site to our system on a recurring basis. &lt;em&gt;Presumably&lt;/em&gt; the data will follow an agreed spec based on an initial sample, but that could change, or out-of-sample data could break some assumptions.&lt;/p&gt;\n\n&lt;p&gt;Was looking at FlatFile who seems to lead in this kind of thing, but was curious what others think about the quality or limitations of it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zj7xr", "is_robot_indexable": true, "report_reasons": null, "author": "o_Chamber", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zj7xr/thoughts_on_flatfile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zj7xr/thoughts_on_flatfile/", "subreddit_subscribers": 115785, "created_utc": 1689347972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Join us on July 20th for a free webinar on building change data capture (CDC) pipelines using [Memphis.dev](https://Memphis.dev) and Debezium. Discover how CDC empowers data replication, real-time analytics, and machine learning operations.\n\n[https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/294556053/](https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/294556053/)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to build a CDC Pipeline? Meetup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zhvnq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689344786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Join us on July 20th for a free webinar on building change data capture (CDC) pipelines using &lt;a href=\"https://Memphis.dev\"&gt;Memphis.dev&lt;/a&gt; and Debezium. Discover how CDC empowers data replication, real-time analytics, and machine learning operations.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/294556053/\"&gt;https://www.meetup.com/developers-and-data-powered-by-memphis-dev-platform/events/294556053/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AaXsXZX5F0NG6NKS9jybSvwFTilk4cNhB7171HfhF90.jpg?auto=webp&amp;s=848f0c1c35de3d73077e5047c0355cce291ddb82", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/AaXsXZX5F0NG6NKS9jybSvwFTilk4cNhB7171HfhF90.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5942c8f7e99557ae19afd67157c705fed333a29", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/AaXsXZX5F0NG6NKS9jybSvwFTilk4cNhB7171HfhF90.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2dd05dfd9b20eb0322b74bef6d1eda23e79e8728", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/AaXsXZX5F0NG6NKS9jybSvwFTilk4cNhB7171HfhF90.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=62e5882254512f269b1d794f855b8c30ad118dfe", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/AaXsXZX5F0NG6NKS9jybSvwFTilk4cNhB7171HfhF90.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eb7700b0ee918fdaa51c5a2c68d249dc2f9a86cd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/AaXsXZX5F0NG6NKS9jybSvwFTilk4cNhB7171HfhF90.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c8f87559292d6e8f1a11a48ed75ed697c4cca81", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/AaXsXZX5F0NG6NKS9jybSvwFTilk4cNhB7171HfhF90.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2594cac8b33b17a4363be82fbd2cc21974a51e65", "width": 1080, "height": 607}], "variants": {}, "id": "QdN_mPudeoG4mIbWw6wJ7GepqmAeyDz5ytc4jwNjTiI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14zhvnq", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zhvnq/how_to_build_a_cdc_pipeline_meetup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zhvnq/how_to_build_a_cdc_pipeline_meetup/", "subreddit_subscribers": 115785, "created_utc": 1689344786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to introduce data science in my organisation. I have access to a lot of logs stored in opensearch. I need to present some solution to get funding. Can you guys give some tips on some solutions you have implemented using logs", "author_fullname": "t2_7g961oi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opensearch logs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zekds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689336093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to introduce data science in my organisation. I have access to a lot of logs stored in opensearch. I need to present some solution to get funding. Can you guys give some tips on some solutions you have implemented using logs&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zekds", "is_robot_indexable": true, "report_reasons": null, "author": "pessimistic_dilution", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zekds/opensearch_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zekds/opensearch_logs/", "subreddit_subscribers": 115785, "created_utc": 1689336093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems like there are a lot of online courses for data, AI, databases, etc available online through websites like corsaira and you can pay extra for a certificate which I probably wouldn't do. But I wanted to know if you find these helpful?", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you find Coursera or other free online courses helpful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zej5d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689336009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems like there are a lot of online courses for data, AI, databases, etc available online through websites like corsaira and you can pay extra for a certificate which I probably wouldn&amp;#39;t do. But I wanted to know if you find these helpful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zej5d", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zej5d/do_you_find_coursera_or_other_free_online_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zej5d/do_you_find_coursera_or_other_free_online_courses/", "subreddit_subscribers": 115785, "created_utc": 1689336009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a student who is enrolled in the IBM Data Engineering course of the coursera, and my final assignment is still not peer-reviewed, kindly if anyone of you who is enrolled in this course may review my assignment, then it'll be very helpful. Here is the assignment's link: [https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw](https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw) ", "author_fullname": "t2_bxisw3c1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering's introduction to relational databases assignment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zcesd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689329374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a student who is enrolled in the IBM Data Engineering course of the coursera, and my final assignment is still not peer-reviewed, kindly if anyone of you who is enrolled in this course may review my assignment, then it&amp;#39;ll be very helpful. Here is the assignment&amp;#39;s link: &lt;a href=\"https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw\"&gt;https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?auto=webp&amp;s=1370f7fc33eccde041bb8d913fc5ef24401c04f5", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6cfffb7d905036a18de683f4858275559647f8cb", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c56f4d07956aae6d02302bd31040c6013026d3ac", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66f1d899c02d5073461c22dc9e3587384dbf6136", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=579175bb293e955ce6b51dadc675c17e41f0b0ca", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=95ba17f421b486a5508eaecb231f9ba8eae35bbc", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eda6808809eea88cdc4032df689fc389cbaa90c9", "width": 1080, "height": 565}], "variants": {}, "id": "nnmvZitIdtl3UJSov7ZcIqMwnFG7OvGcVvkNPR4Vsrc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14zcesd", "is_robot_indexable": true, "report_reasons": null, "author": "Simple_Debt5396", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zcesd/data_engineerings_introduction_to_relational/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zcesd/data_engineerings_introduction_to_relational/", "subreddit_subscribers": 115785, "created_utc": 1689329374.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it good practice to store event data in object storage one by one? I.e. if I get 1M events/messages a day I store 1M small e.g. JSON files into the S3 and then batch process it at the end of day. Is this reasonable or I should somehow buffer all the messages and then save only one (or little more) batched files into the S3? Also why / why not?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing realtime events in object storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yxlz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689285022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it good practice to store event data in object storage one by one? I.e. if I get 1M events/messages a day I store 1M small e.g. JSON files into the S3 and then batch process it at the end of day. Is this reasonable or I should somehow buffer all the messages and then save only one (or little more) batched files into the S3? Also why / why not?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yxlz3", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yxlz3/storing_realtime_events_in_object_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yxlz3/storing_realtime_events_in_object_storage/", "subreddit_subscribers": 115785, "created_utc": 1689285022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://gretel.ai/blog/bring-your-own-cloud](https://gretel.ai/blog/bring-your-own-cloud)", "author_fullname": "t2_t4pwocav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anonymizing 7 terabytes of data in a hybrid cloud environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yw2dw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689281361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://gretel.ai/blog/bring-your-own-cloud\"&gt;https://gretel.ai/blog/bring-your-own-cloud&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?auto=webp&amp;s=bc3493917d3704a273ac737908af2200db053206", "width": 1440, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=210062dc56f116a92ad54cdf589382f4650558c0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=741b610f3aa7f92a6b0203c040fa6891d241da6f", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5149bccc1297b6b740a39bf74fd35c006475e3bc", "width": 320, "height": 177}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ddf12ec791acf3397800e1010de4283a3b40eca8", "width": 640, "height": 355}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=40087377ec3b0914b0d3606118e69ad54f379863", "width": 960, "height": 533}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd781648c0620c89b350217cc0e058fc94a7142e", "width": 1080, "height": 600}], "variants": {}, "id": "P3FdEpfGKtApmyi9xRhUP9Uq6puzmmJGETUlq8e2RgE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14yw2dw", "is_robot_indexable": true, "report_reasons": null, "author": "Synthesize2023", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yw2dw/anonymizing_7_terabytes_of_data_in_a_hybrid_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yw2dw/anonymizing_7_terabytes_of_data_in_a_hybrid_cloud/", "subreddit_subscribers": 115785, "created_utc": 1689281361.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}