{"kind": "Listing", "data": {"after": "t3_14ys7lx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few months ago I changed from data scientist to engineer, since in my previous company I did everything myself, but being a CS guy I pref the data engineering part.\n\nIn my current company, a multinational telecommunications, I only do SQL queries and stupid dashboards for marketing and business, I feel frustrated because anyone can do this\u2026  And it has little to do with the Data Engineer role that I was offered.\n\nHow much do you use SQL in your daily work ?", "author_fullname": "t2_4kdegv81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL only - Work frustration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z8hhn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689315999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months ago I changed from data scientist to engineer, since in my previous company I did everything myself, but being a CS guy I pref the data engineering part.&lt;/p&gt;\n\n&lt;p&gt;In my current company, a multinational telecommunications, I only do SQL queries and stupid dashboards for marketing and business, I feel frustrated because anyone can do this\u2026  And it has little to do with the Data Engineer role that I was offered.&lt;/p&gt;\n\n&lt;p&gt;How much do you use SQL in your daily work ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z8hhn", "is_robot_indexable": true, "report_reasons": null, "author": "xchgre", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z8hhn/sql_only_work_frustration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z8hhn/sql_only_work_frustration/", "subreddit_subscribers": 115758, "created_utc": 1689315999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a Data Engineer what\u2019s your biggest headache, frustration, time suck?", "author_fullname": "t2_3cr575ib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Headaches", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z3dvp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689300344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a Data Engineer what\u2019s your biggest headache, frustration, time suck?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z3dvp", "is_robot_indexable": true, "report_reasons": null, "author": "jayking51", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z3dvp/data_engineering_headaches/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z3dvp/data_engineering_headaches/", "subreddit_subscribers": 115758, "created_utc": 1689300344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's not a glamorous life, but we all know who really drives the bus", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": true, "name": "t3_14zh0hc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/m14lmAG0ui7VEFcfbPvurOvy93OiuuycSgEt0QBVzKg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1689342659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/s3fg4dwiqxbb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?auto=webp&amp;s=3b4788debae0b50692b52c64f9b1465f721ec307", "width": 960, "height": 650}, "resolutions": [{"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca4a7e5f025aca555f8d3c025919302b95b3cfdf", "width": 108, "height": 73}, {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c2e25429082ec285073c637ded4f2309193a93d4", "width": 216, "height": 146}, {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=97d836c80ded7134399c0ca4ec91bd1589b084a5", "width": 320, "height": 216}, {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=afff761684fd73ee8df231ea5466221138de4f58", "width": 640, "height": 433}, {"url": "https://preview.redd.it/s3fg4dwiqxbb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5d72044ab3f3129252dad596c3c4e3e61febeb07", "width": 960, "height": 650}], "variants": {}, "id": "MP16Sf-Yv6ddJsm3DGwjB7o8R2THbfQBktZKU5To4WM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14zh0hc", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zh0hc/its_not_a_glamorous_life_but_we_all_know_who/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/s3fg4dwiqxbb1.png", "subreddit_subscribers": 115758, "created_utc": 1689342659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Facing a potential layoff soon, so have started applying to some data engineer, jr data engineer and analytics engineer positions. I thought I'd put a project up on github so any HM could see a bit of my skills. If you saw this and actually looked through it, what would you think?\n\n[https://github.com/jrey999/mlb](https://github.com/jrey999/mlb)", "author_fullname": "t2_v4s5fwgd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you saw this and actually looked through it, what would you think", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z582e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689305728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Facing a potential layoff soon, so have started applying to some data engineer, jr data engineer and analytics engineer positions. I thought I&amp;#39;d put a project up on github so any HM could see a bit of my skills. If you saw this and actually looked through it, what would you think?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/jrey999/mlb\"&gt;https://github.com/jrey999/mlb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?auto=webp&amp;s=f23cd95bd53dfe4d4782e84979e0b6b62d084129", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a3709fc1236118224429386fed0b00f235baf0a2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=45ae7c8e42e8f1b6bd02486b081cc4056b35f870", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ab7afb2fabfb98da681c7ddf4639747d1c14d8d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=adbfb6983d38667cc57a25c401ea92acc4adaf10", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5882b19e3647675aee89370079a541eb94210638", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/rgUqgV8oGIFau_yYTsS7gWs4ZuWDalktRgNu5TubS28.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c01dcaee91410f53051d02152cc9c3ce4b8fdcc", "width": 1080, "height": 540}], "variants": {}, "id": "ZTkos4tP2WpR9wFxhobnnfq39iPZLNNBaB0u--0xAy0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "14z582e", "is_robot_indexable": true, "report_reasons": null, "author": "big_lazerz", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z582e/if_you_saw_this_and_actually_looked_through_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z582e/if_you_saw_this_and_actually_looked_through_it/", "subreddit_subscribers": 115758, "created_utc": 1689305728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The streaming world is dominated by Java based tools like Kafka and Flink but most data scientists live in MATLAB, R, and Python notebooks. I'm curious how y'all collaborate with data scientists in these situations, especially when you want to embed some domain specific data logic / transformation?\n\n\\- Do they write data transformations / build models in their native language and throw it over the wall to you?\n\n\\- Do they learn your toolchain?", "author_fullname": "t2_6khnrfh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you collaborate with notebook savvy data scientists on streaming data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ypog3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689266335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The streaming world is dominated by Java based tools like Kafka and Flink but most data scientists live in MATLAB, R, and Python notebooks. I&amp;#39;m curious how y&amp;#39;all collaborate with data scientists in these situations, especially when you want to embed some domain specific data logic / transformation?&lt;/p&gt;\n\n&lt;p&gt;- Do they write data transformations / build models in their native language and throw it over the wall to you?&lt;/p&gt;\n\n&lt;p&gt;- Do they learn your toolchain?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ypog3", "is_robot_indexable": true, "report_reasons": null, "author": "semicausal", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ypog3/how_do_you_collaborate_with_notebook_savvy_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ypog3/how_do_you_collaborate_with_notebook_savvy_data/", "subreddit_subscribers": 115758, "created_utc": 1689266335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I love cbt. I finally get the fuss now.\n\nBack in the olden days, I'd just dump all of my pandas/polars tasks in one compact jupyter notebook, download it all as a .py file, and call it a day. I genuinely thought that was better and more compact.\n\nBut now after using dbt for the first time, I can sort of see its usefulness. I rewrote the pandas stuff as a chain of CTE statements and breaking them up into different, consecutive SQL files. It really forces you to view things more modular, and while SQL can't do as much stuff as python, I gotta agree that it's overall cleaner to read, even as someone who was taught Python before SQL and thus feels biased for Python.\n\nThe only thing I don't know how to exactly do yet is interrupt the dbt midway to do something only python can do, or rather something SQL can't do (like adding columns that are the output of a machine learning method such as k-means, tf-idf, or PCA), and then resuming the dbt.", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After balking for a long time, tried out dbt for the first time and now am a full convert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z9id2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689319474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I love cbt. I finally get the fuss now.&lt;/p&gt;\n\n&lt;p&gt;Back in the olden days, I&amp;#39;d just dump all of my pandas/polars tasks in one compact jupyter notebook, download it all as a .py file, and call it a day. I genuinely thought that was better and more compact.&lt;/p&gt;\n\n&lt;p&gt;But now after using dbt for the first time, I can sort of see its usefulness. I rewrote the pandas stuff as a chain of CTE statements and breaking them up into different, consecutive SQL files. It really forces you to view things more modular, and while SQL can&amp;#39;t do as much stuff as python, I gotta agree that it&amp;#39;s overall cleaner to read, even as someone who was taught Python before SQL and thus feels biased for Python.&lt;/p&gt;\n\n&lt;p&gt;The only thing I don&amp;#39;t know how to exactly do yet is interrupt the dbt midway to do something only python can do, or rather something SQL can&amp;#39;t do (like adding columns that are the output of a machine learning method such as k-means, tf-idf, or PCA), and then resuming the dbt.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z9id2", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 6, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z9id2/after_balking_for_a_long_time_tried_out_dbt_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z9id2/after_balking_for_a_long_time_tried_out_dbt_for/", "subreddit_subscribers": 115758, "created_utc": 1689319474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have worked as a software engineer and I am now on my second data engineering position. As time marches on it seems that I am fighting a losing battle trying to implement automated logic tests for SQL testing.\n\nAs a software engineer I wrote tests to validate that for input x I would get output y and then make sure all the edge cases were covered. I have worked on data warehouse projects that used a similar \"unit test approach\": load a test data set into the database and verify the result of some sql. When I moved into doing work in a data science department we used Spark to mock out data frames and test the output of an operation.\n\nHowever this does not seem to be how the industry as a whole handles things. It seems that teams test the general shape of some transform logic such as row counts or if a value falls within a range. I am curious what other folks impressions are (not just your team, but data engineering as a whole)?\n\nOn a side note: I read articles like [https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc](https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc) which makes me think people are testing transforms, but then I see polls like this [https://www.jetbrains.com/lp/devecosystem-2021/databases/](https://www.jetbrains.com/lp/devecosystem-2021/databases/) that indicate people don't really test.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_3j0if", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Testing: a loosing battle?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ywjwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689282451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have worked as a software engineer and I am now on my second data engineering position. As time marches on it seems that I am fighting a losing battle trying to implement automated logic tests for SQL testing.&lt;/p&gt;\n\n&lt;p&gt;As a software engineer I wrote tests to validate that for input x I would get output y and then make sure all the edge cases were covered. I have worked on data warehouse projects that used a similar &amp;quot;unit test approach&amp;quot;: load a test data set into the database and verify the result of some sql. When I moved into doing work in a data science department we used Spark to mock out data frames and test the output of an operation.&lt;/p&gt;\n\n&lt;p&gt;However this does not seem to be how the industry as a whole handles things. It seems that teams test the general shape of some transform logic such as row counts or if a value falls within a range. I am curious what other folks impressions are (not just your team, but data engineering as a whole)?&lt;/p&gt;\n\n&lt;p&gt;On a side note: I read articles like &lt;a href=\"https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc\"&gt;https://billcrichmond.medium.com/machine-learning-vs-traditional-software-development-96923dc5ffbc&lt;/a&gt; which makes me think people are testing transforms, but then I see polls like this &lt;a href=\"https://www.jetbrains.com/lp/devecosystem-2021/databases/\"&gt;https://www.jetbrains.com/lp/devecosystem-2021/databases/&lt;/a&gt; that indicate people don&amp;#39;t really test.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?auto=webp&amp;s=d89a17b05c97281fdd6453dd599945fcd7336b51", "width": 1005, "height": 444}, "resolutions": [{"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e64df404a8a381f61dba9b394f45d66d2547dcc3", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42e227a370404b011573e86f3dfe060ce05c42c2", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=45c6aabe350b41595aa55f72de51cc2cd7d9642a", "width": 320, "height": 141}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9d006f825a0b89e3e1524059d5ff1f6de8c6f2c", "width": 640, "height": 282}, {"url": "https://external-preview.redd.it/JZwzxKk230JDv8GrPWxxSQB83G3-kkN2faWjEmdAp18.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=21f0334d6bb2c2fcc573a1f64aaa8bd05c5689c5", "width": 960, "height": 424}], "variants": {}, "id": "6c4F5f_MtX1XvNBav9lGrhcENIY60PGLA8mRkZf-GFo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ywjwa", "is_robot_indexable": true, "report_reasons": null, "author": "jaynerd", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ywjwa/sql_testing_a_loosing_battle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ywjwa/sql_testing_a_loosing_battle/", "subreddit_subscribers": 115758, "created_utc": 1689282451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello Everyone! \n\nWhat are the AWS alerting and notification best practices. While we've covered the basics in the current org where we get a notification on every failure, plain email saying the job is failed. We would like to have a thought process to see what is best in \n\n&amp;#x200B;\n\n How have you expanded your AWS alerts beyond job failures?    \n Have you utilized Amazon SES to deliver timely notifications? how you have optimized the failed emails  \n How have you leveraged AWS Glue and Lambda to automate your alerting process? \n\n For those who have integrated PagerDuty within their AWS infrastructure  \n\n&amp;#x200B;\n\nwhat is the best enterprise-level strategy for alerting and notifications?", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Alerting and Notification Best Practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z2ieu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689297884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone! &lt;/p&gt;\n\n&lt;p&gt;What are the AWS alerting and notification best practices. While we&amp;#39;ve covered the basics in the current org where we get a notification on every failure, plain email saying the job is failed. We would like to have a thought process to see what is best in &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How have you expanded your AWS alerts beyond job failures?&lt;br/&gt;\n Have you utilized Amazon SES to deliver timely notifications? how you have optimized the failed emails&lt;br/&gt;\n How have you leveraged AWS Glue and Lambda to automate your alerting process? &lt;/p&gt;\n\n&lt;p&gt;For those who have integrated PagerDuty within their AWS infrastructure  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;what is the best enterprise-level strategy for alerting and notifications?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z2ieu", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z2ieu/aws_alerting_and_notification_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z2ieu/aws_alerting_and_notification_best_practices/", "subreddit_subscribers": 115758, "created_utc": 1689297884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im looking to get a general idea of the spark ecosystem and fundamentals because at our company we are using a custom made abstraction above \"Apache Spark\". A lot of concepts are mapped 1:1.  Mainly for ETL purposes (data processing etc)\n\nAny idea's suggestions? by reading books, tutorials etc", "author_fullname": "t2_dr0lf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn apache spark as a beginner/junior/new grad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ysuu6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689273837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im looking to get a general idea of the spark ecosystem and fundamentals because at our company we are using a custom made abstraction above &amp;quot;Apache Spark&amp;quot;. A lot of concepts are mapped 1:1.  Mainly for ETL purposes (data processing etc)&lt;/p&gt;\n\n&lt;p&gt;Any idea&amp;#39;s suggestions? by reading books, tutorials etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ysuu6", "is_robot_indexable": true, "report_reasons": null, "author": "poepstinktvies", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ysuu6/how_to_learn_apache_spark_as_a_beginnerjuniornew/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ysuu6/how_to_learn_apache_spark_as_a_beginnerjuniornew/", "subreddit_subscribers": 115758, "created_utc": 1689273837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was a Business Intelligence Analyst/SQL developer from 2016-2021. I was working mostly with SSIS and Microsoft SQL Server. Cron + Powershell were my best frenemies. I have a fundamental understanding of data structures, patterns, etc; know SQL very well and have a cursory understanding of Python\u2014I\u2019ve done some personal projects but never needed it for work. I\u2019m also pretty familiar with Git and general SDLC best practices. \n\nI worked at two \u201ctech enabled\u201d companies where their primary business was selling a service that was \u201cdata-driven\u201d and backed with \u201ccutting edge tech\u201d but in reality the tech was a giant spaghetti mess behind the scenes and probably 7+ years behind current day at all times. These companies had terrible on-call practices and that plus spaghetti architecture, I was getting constantly pinged after hours for this or that broken thing\u2014a lot of times late at night. In short, I got fully burnt out. \n\nFast forward to today, I ended up landing a TPM role at a company whose tech stack is current day. They have their problems like anywhere else but from what I can tell, the Eng teams have mature on call procedures that actually split up the work. I like this company but despite \u201ctechnical\u201d in the name, the TPM role here is not at all technical. Now I\u2019m working through whether or not it would even be possible to transition over to their DW team and be in more of an Eng role again.\n\nI know I\u2019ve got some skills gaps to fill.  Airflow, Big Query and Python are going to be key for this role and I\u2019ve never worked with them day to day. In reality, if that team even wants me I\u2019d probably need to step down in seniority a level or two and I\u2019d be fine with that. But what I\u2019m trying to work out is, with these more modern tools, is the job really going to be THAT different? Do I need to set the expectation for myself that if I pursue this, I am essentially starting from scratch? I think what really worries me is that I do not have a formal CS background\u2014in my prior life I was totally self taught, so I fear there might be some knowledge gaps I don\u2019t even know I have.", "author_fullname": "t2_oim4bt00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are My Skills Too Far Gone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zgfh5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689341155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was a Business Intelligence Analyst/SQL developer from 2016-2021. I was working mostly with SSIS and Microsoft SQL Server. Cron + Powershell were my best frenemies. I have a fundamental understanding of data structures, patterns, etc; know SQL very well and have a cursory understanding of Python\u2014I\u2019ve done some personal projects but never needed it for work. I\u2019m also pretty familiar with Git and general SDLC best practices. &lt;/p&gt;\n\n&lt;p&gt;I worked at two \u201ctech enabled\u201d companies where their primary business was selling a service that was \u201cdata-driven\u201d and backed with \u201ccutting edge tech\u201d but in reality the tech was a giant spaghetti mess behind the scenes and probably 7+ years behind current day at all times. These companies had terrible on-call practices and that plus spaghetti architecture, I was getting constantly pinged after hours for this or that broken thing\u2014a lot of times late at night. In short, I got fully burnt out. &lt;/p&gt;\n\n&lt;p&gt;Fast forward to today, I ended up landing a TPM role at a company whose tech stack is current day. They have their problems like anywhere else but from what I can tell, the Eng teams have mature on call procedures that actually split up the work. I like this company but despite \u201ctechnical\u201d in the name, the TPM role here is not at all technical. Now I\u2019m working through whether or not it would even be possible to transition over to their DW team and be in more of an Eng role again.&lt;/p&gt;\n\n&lt;p&gt;I know I\u2019ve got some skills gaps to fill.  Airflow, Big Query and Python are going to be key for this role and I\u2019ve never worked with them day to day. In reality, if that team even wants me I\u2019d probably need to step down in seniority a level or two and I\u2019d be fine with that. But what I\u2019m trying to work out is, with these more modern tools, is the job really going to be THAT different? Do I need to set the expectation for myself that if I pursue this, I am essentially starting from scratch? I think what really worries me is that I do not have a formal CS background\u2014in my prior life I was totally self taught, so I fear there might be some knowledge gaps I don\u2019t even know I have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14zgfh5", "is_robot_indexable": true, "report_reasons": null, "author": "Alternative-Engine77", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zgfh5/are_my_skills_too_far_gone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zgfh5/are_my_skills_too_far_gone/", "subreddit_subscribers": 115758, "created_utc": 1689341155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody,\n\nHow do you usually orchestrate your Airbyte ingestions / connections ?\n\nI\u2019m planning to use data form as well on the transformation layer so I\u2019m curious.\n\nI\u2019m looking for the cheapest easiest to maintain option", "author_fullname": "t2_851if4wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP - Airbyte and orchestration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zb4nb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689325100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;How do you usually orchestrate your Airbyte ingestions / connections ?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m planning to use data form as well on the transformation layer so I\u2019m curious.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for the cheapest easiest to maintain option&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zb4nb", "is_robot_indexable": true, "report_reasons": null, "author": "No-Dress-3160", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zb4nb/gcp_airbyte_and_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zb4nb/gcp_airbyte_and_orchestration/", "subreddit_subscribers": 115758, "created_utc": 1689325100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a couple of spark jobs writing data in hourly partitions using Avro and Parquet formats. The data is stored in AWS S3 in the same bucket, but each partition has a different prefix, e.g. \\`YYYY-MM-DD-HH\\`. How can I ensure that the downstream jobs won't see or be able to access an incomplete partition being written?", "author_fullname": "t2_mafti2dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the techniques to ensure atomic writes to partition?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zan40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689323403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a couple of spark jobs writing data in hourly partitions using Avro and Parquet formats. The data is stored in AWS S3 in the same bucket, but each partition has a different prefix, e.g. `YYYY-MM-DD-HH`. How can I ensure that the downstream jobs won&amp;#39;t see or be able to access an incomplete partition being written?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14zan40", "is_robot_indexable": true, "report_reasons": null, "author": "ad81923", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zan40/what_are_the_techniques_to_ensure_atomic_writes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zan40/what_are_the_techniques_to_ensure_atomic_writes/", "subreddit_subscribers": 115758, "created_utc": 1689323403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use Git Flow in our company. \nThe Develop branch is cloned to creature the Feature branch.\nIn Feature branch we add additional features and all testing (unit, integration, uat) happens in this branch. Once approved, we merge this back to Develop. Then release branch is created from Develop and merged into Prod without any testing.\n\nSo my question is, do we need to perform additional testing in Release branch?", "author_fullname": "t2_gzg678i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Test in Feature or Release branch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z9r5g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689320347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use Git Flow in our company. \nThe Develop branch is cloned to creature the Feature branch.\nIn Feature branch we add additional features and all testing (unit, integration, uat) happens in this branch. Once approved, we merge this back to Develop. Then release branch is created from Develop and merged into Prod without any testing.&lt;/p&gt;\n\n&lt;p&gt;So my question is, do we need to perform additional testing in Release branch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14z9r5g", "is_robot_indexable": true, "report_reasons": null, "author": "ryandane123", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z9r5g/test_in_feature_or_release_branch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z9r5g/test_in_feature_or_release_branch/", "subreddit_subscribers": 115758, "created_utc": 1689320347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all  \nI am seeking advice and suggestions regarding an ELT workflow that my team has been implementing using BigQuery and Spark. I have encountered some challenges and would greatly appreciate the insights of this community.\n\nCurrently, I am using BigQuery for our ELT work, but the cost has been significant due to the rapid increase in data volume. To explore cost reduction options, my team decided to explore Dataproc. Our approach involves exporting BigQuery data to Google Cloud Storage (which is free up to 10TB per day), running a Spark job using the same query as in BigQuery (making it Spark compatible), writing the output DataFrame to GCS, and finally ingesting the data into a table (which is also free).\n\nHowever on doing this, I have observed two peculiar issues that I am struggling to resolve. Firstly, the BigQuery export process generates files of varying sizes, resulting in a large number of small files. This seems to significantly slow down the Spark job. Secondly, during a test job where the total size of input tables was around 300GB, I noticed that the YARN pending memory started at 2TB as shown on dashboard and kept decreasing as the job progressed. I am perplexed as to why the YARN pending memory would be 2TB for a dataset of just a few hundred gigabytes.\n\nGiven these challenges, I am seeking advice from the community. If any of you have attempted a similar workflow or encountered similar issues, I would like to hear about your experiences and the results you achieved. Did you optimize the BigQuery export process to avoid the problem of numerous small files? Do you believe the method of running spark jobs via above mentioned way is appropriate, or would you recommend any changes to improve the Spark job performance? Are there any specific optimizations or best practices you would recommend for Spark jobs?\n\nAny advice or suggestions you can provide would be highly appreciated. Thanks a lot in advance.", "author_fullname": "t2_cu6opso3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small file problem on spark in GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14z7y9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689314250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;br/&gt;\nI am seeking advice and suggestions regarding an ELT workflow that my team has been implementing using BigQuery and Spark. I have encountered some challenges and would greatly appreciate the insights of this community.&lt;/p&gt;\n\n&lt;p&gt;Currently, I am using BigQuery for our ELT work, but the cost has been significant due to the rapid increase in data volume. To explore cost reduction options, my team decided to explore Dataproc. Our approach involves exporting BigQuery data to Google Cloud Storage (which is free up to 10TB per day), running a Spark job using the same query as in BigQuery (making it Spark compatible), writing the output DataFrame to GCS, and finally ingesting the data into a table (which is also free).&lt;/p&gt;\n\n&lt;p&gt;However on doing this, I have observed two peculiar issues that I am struggling to resolve. Firstly, the BigQuery export process generates files of varying sizes, resulting in a large number of small files. This seems to significantly slow down the Spark job. Secondly, during a test job where the total size of input tables was around 300GB, I noticed that the YARN pending memory started at 2TB as shown on dashboard and kept decreasing as the job progressed. I am perplexed as to why the YARN pending memory would be 2TB for a dataset of just a few hundred gigabytes.&lt;/p&gt;\n\n&lt;p&gt;Given these challenges, I am seeking advice from the community. If any of you have attempted a similar workflow or encountered similar issues, I would like to hear about your experiences and the results you achieved. Did you optimize the BigQuery export process to avoid the problem of numerous small files? Do you believe the method of running spark jobs via above mentioned way is appropriate, or would you recommend any changes to improve the Spark job performance? Are there any specific optimizations or best practices you would recommend for Spark jobs?&lt;/p&gt;\n\n&lt;p&gt;Any advice or suggestions you can provide would be highly appreciated. Thanks a lot in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14z7y9h", "is_robot_indexable": true, "report_reasons": null, "author": "bha159", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14z7y9h/small_file_problem_on_spark_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14z7y9h/small_file_problem_on_spark_in_gcp/", "subreddit_subscribers": 115758, "created_utc": 1689314250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! At my company, Journalize, our users wanted to add arbitrary tags to their data so they could slice and dice against any dimension. To aggregate data over 10M rows, we set up a Clickhouse server with some magic. I'm curious if people can also use what we built. \n\n(note: im expecting the data purists to hate this, and I am ready for that\u2026 :)\n\nWe are calling it ScratchDB: Firestore for analytics. Stream JSON, and we\u2019ll figure out how to get it into an analytical database, and you can run SQL. \n\nWebsite: [https://www.scratchdb.com](https://www.scratchdb.com/)\n\nGithub: [https://github.com/scratchdata/ScratchDB](https://github.com/scratchdata/ScratchDB) \n\nThe problem as I see it: \n\n* At some point, you might find that GROUP BYs are slow in Postgres and want an analytical database\n* Getting started has technical friction: choosing a DB, new underlying storage models, monitoring servers\n* Pricing is opaque: self-hosting vs cloud, credits, vCPUs, it\u2019s hard to answer \u201chow much will this thing cost\u201d, and often the answer is \u201ca lot\u201d\n\nWith ScratchDB:\n\n* No need to issue a CREATE TABLE statement. Send your JSON and we will automatically create tables and columns on the fly.\n* Just pay for what you use via metrics you can easily understand (storage, processing time)\n* ScratchDB is open source (github) and right now it runs on top of DuckDB. (More connectors in the works!) It is written in Go.\n\nI am really curious about what people think. Also, we\u2019d love to know how you\u2019re doing this today, how much it costs, and what your devops looks like. (if you\u2019re willing to shoot me a DM!) \n\nLet us see if we can help you ingest data into your DB more easily. If this is a pain point on non-analytics workloads, I\u2019m interested in talking as this is also on our roadmap.\n\nThanks in advance! ", "author_fullname": "t2_4mv9dvc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Useful or nah: open-source serverless analytics DB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yv3kv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689279112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! At my company, Journalize, our users wanted to add arbitrary tags to their data so they could slice and dice against any dimension. To aggregate data over 10M rows, we set up a Clickhouse server with some magic. I&amp;#39;m curious if people can also use what we built. &lt;/p&gt;\n\n&lt;p&gt;(note: im expecting the data purists to hate this, and I am ready for that\u2026 :)&lt;/p&gt;\n\n&lt;p&gt;We are calling it ScratchDB: Firestore for analytics. Stream JSON, and we\u2019ll figure out how to get it into an analytical database, and you can run SQL. &lt;/p&gt;\n\n&lt;p&gt;Website: &lt;a href=\"https://www.scratchdb.com/\"&gt;https://www.scratchdb.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/scratchdata/ScratchDB\"&gt;https://github.com/scratchdata/ScratchDB&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;The problem as I see it: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;At some point, you might find that GROUP BYs are slow in Postgres and want an analytical database&lt;/li&gt;\n&lt;li&gt;Getting started has technical friction: choosing a DB, new underlying storage models, monitoring servers&lt;/li&gt;\n&lt;li&gt;Pricing is opaque: self-hosting vs cloud, credits, vCPUs, it\u2019s hard to answer \u201chow much will this thing cost\u201d, and often the answer is \u201ca lot\u201d&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With ScratchDB:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;No need to issue a CREATE TABLE statement. Send your JSON and we will automatically create tables and columns on the fly.&lt;/li&gt;\n&lt;li&gt;Just pay for what you use via metrics you can easily understand (storage, processing time)&lt;/li&gt;\n&lt;li&gt;ScratchDB is open source (github) and right now it runs on top of DuckDB. (More connectors in the works!) It is written in Go.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am really curious about what people think. Also, we\u2019d love to know how you\u2019re doing this today, how much it costs, and what your devops looks like. (if you\u2019re willing to shoot me a DM!) &lt;/p&gt;\n\n&lt;p&gt;Let us see if we can help you ingest data into your DB more easily. If this is a pain point on non-analytics workloads, I\u2019m interested in talking as this is also on our roadmap.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14yv3kv", "is_robot_indexable": true, "report_reasons": null, "author": "robertao211", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yv3kv/useful_or_nah_opensource_serverless_analytics_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yv3kv/useful_or_nah_opensource_serverless_analytics_db/", "subreddit_subscribers": 115758, "created_utc": 1689279112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for some advice from experienced engineers for someone beginning their career.\n\nI\u2019m having some difficulty finding a Junior/data engineering role and I feel that my experience is close but not quite what a typical engineer is expected to have. Here are some highlights\n\n1. Apache nifi and spark experience\n2. python, R experience\n3. Data migration, cleaning, validation experience\n\nI also know a little Java but nothing I want to advertise.\n\nAny suggestions on how I can grow my skills? What kind of job should I maybe consider as a stepping stone? What skills should I teach myself in my free time and at what point should I advertise that skill?", "author_fullname": "t2_a1jy0x9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Career Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14ziqho", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689346862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for some advice from experienced engineers for someone beginning their career.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having some difficulty finding a Junior/data engineering role and I feel that my experience is close but not quite what a typical engineer is expected to have. Here are some highlights&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Apache nifi and spark experience&lt;/li&gt;\n&lt;li&gt;python, R experience&lt;/li&gt;\n&lt;li&gt;Data migration, cleaning, validation experience&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I also know a little Java but nothing I want to advertise.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions on how I can grow my skills? What kind of job should I maybe consider as a stepping stone? What skills should I teach myself in my free time and at what point should I advertise that skill?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14ziqho", "is_robot_indexable": true, "report_reasons": null, "author": "ppeen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ziqho/beginner_career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ziqho/beginner_career_advice/", "subreddit_subscribers": 115758, "created_utc": 1689346862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently a data analyst with 2 YOE. I have worked on SQL, python (for retrieving and transformaing the data for analysis),excel and Tableau. I feel that i would be able to do better as a data engineer. So I taught myself spark, hive, azure data factory and databricks (fundamental). Now when I tried to analyse the market requirements for data engineer, I am overwhelmed with the different requirements they have (airflow, Kafka, warehousing , DBT and a lot). I feel like I would have to spend another year to catch up with the requirements. \nHow should I plan? I feel like I am lost. \nPlease help", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overwhelmed with such detailed job descriptions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14zhtx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1689347877.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689344668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a data analyst with 2 YOE. I have worked on SQL, python (for retrieving and transformaing the data for analysis),excel and Tableau. I feel that i would be able to do better as a data engineer. So I taught myself spark, hive, azure data factory and databricks (fundamental). Now when I tried to analyse the market requirements for data engineer, I am overwhelmed with the different requirements they have (airflow, Kafka, warehousing , DBT and a lot). I feel like I would have to spend another year to catch up with the requirements. \nHow should I plan? I feel like I am lost. \nPlease help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14zhtx1", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zhtx1/overwhelmed_with_such_detailed_job_descriptions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zhtx1/overwhelmed_with_such_detailed_job_descriptions/", "subreddit_subscribers": 115758, "created_utc": 1689344668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interesting argument ...\n\nMax Kremer makes the case for Postgres as a protocol. What say you?\n\n[https://lassoo.io/blog/2023/07/12/postgres-as-a-protocol/](https://lassoo.io/blog/2023/07/12/postgres-as-a-protocol/)", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Postgres as a protocol", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14zh9r4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689343304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interesting argument ...&lt;/p&gt;\n\n&lt;p&gt;Max Kremer makes the case for Postgres as a protocol. What say you?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lassoo.io/blog/2023/07/12/postgres-as-a-protocol/\"&gt;https://lassoo.io/blog/2023/07/12/postgres-as-a-protocol/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?auto=webp&amp;s=7fedf2eac5f590c277dbed62fe26cfeb652ed405", "width": 2999, "height": 1999}, "resolutions": [{"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=73fb0dc2dacafab2034fea682b33bf91648139d6", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9975375d1e3d91d1d89b51e74eaf0c85cdfd1213", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6027907c03ebe144b4ae266b6755bc3bf81b474f", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=92466a29dc68c9d27011adf08c6d4d699ceb7a1d", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d9ea62c56a85c8a03a9ca01a55043d0f5f155ce8", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/fh9-PvCt8cx-THJ1VQ860utBGqDjQNEXhwkQsxi_w8E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6364b6eabb2df7caea959709019fc42f704cbe8a", "width": 1080, "height": 719}], "variants": {}, "id": "aQX_3YZ3wbqFDdbKRgZqTUyXucO8TbZ7I0qDnosF4xw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zh9r4", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zh9r4/postgres_as_a_protocol/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zh9r4/postgres_as_a_protocol/", "subreddit_subscribers": 115758, "created_utc": 1689343304.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to introduce data science in my organisation. I have access to a lot of logs stored in opensearch. I need to present some solution to get funding. Can you guys give some tips on some solutions you have implemented using logs", "author_fullname": "t2_7g961oi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opensearch logs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zekds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689336093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to introduce data science in my organisation. I have access to a lot of logs stored in opensearch. I need to present some solution to get funding. Can you guys give some tips on some solutions you have implemented using logs&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zekds", "is_robot_indexable": true, "report_reasons": null, "author": "pessimistic_dilution", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zekds/opensearch_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zekds/opensearch_logs/", "subreddit_subscribers": 115758, "created_utc": 1689336093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems like there are a lot of online courses for data, AI, databases, etc available online through websites like corsaira and you can pay extra for a certificate which I probably wouldn't do. But I wanted to know if you find these helpful?", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you find Coursera or other free online courses helpful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zej5d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689336009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems like there are a lot of online courses for data, AI, databases, etc available online through websites like corsaira and you can pay extra for a certificate which I probably wouldn&amp;#39;t do. But I wanted to know if you find these helpful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14zej5d", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zej5d/do_you_find_coursera_or_other_free_online_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zej5d/do_you_find_coursera_or_other_free_online_courses/", "subreddit_subscribers": 115758, "created_utc": 1689336009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a student who is enrolled in the IBM Data Engineering course of the coursera, and my final assignment is still not peer-reviewed, kindly if anyone of you who is enrolled in this course may review my assignment, then it'll be very helpful. Here is the assignment's link: [https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw](https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw) ", "author_fullname": "t2_bxisw3c1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering's introduction to relational databases assignment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14zcesd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689329374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a student who is enrolled in the IBM Data Engineering course of the coursera, and my final assignment is still not peer-reviewed, kindly if anyone of you who is enrolled in this course may review my assignment, then it&amp;#39;ll be very helpful. Here is the assignment&amp;#39;s link: &lt;a href=\"https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw\"&gt;https://www.coursera.org/learn/introduction-to-relational-databases/peer/ywa1e/project-submission-peer-review/review/GuY1bSIbEe6ZGBI3pbP8tw&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?auto=webp&amp;s=1370f7fc33eccde041bb8d913fc5ef24401c04f5", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6cfffb7d905036a18de683f4858275559647f8cb", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c56f4d07956aae6d02302bd31040c6013026d3ac", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66f1d899c02d5073461c22dc9e3587384dbf6136", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=579175bb293e955ce6b51dadc675c17e41f0b0ca", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=95ba17f421b486a5508eaecb231f9ba8eae35bbc", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eda6808809eea88cdc4032df689fc389cbaa90c9", "width": 1080, "height": 565}], "variants": {}, "id": "nnmvZitIdtl3UJSov7ZcIqMwnFG7OvGcVvkNPR4Vsrc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14zcesd", "is_robot_indexable": true, "report_reasons": null, "author": "Simple_Debt5396", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14zcesd/data_engineerings_introduction_to_relational/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14zcesd/data_engineerings_introduction_to_relational/", "subreddit_subscribers": 115758, "created_utc": 1689329374.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it good practice to store event data in object storage one by one? I.e. if I get 1M events/messages a day I store 1M small e.g. JSON files into the S3 and then batch process it at the end of day. Is this reasonable or I should somehow buffer all the messages and then save only one (or little more) batched files into the S3? Also why / why not?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing realtime events in object storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yxlz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689285022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it good practice to store event data in object storage one by one? I.e. if I get 1M events/messages a day I store 1M small e.g. JSON files into the S3 and then batch process it at the end of day. Is this reasonable or I should somehow buffer all the messages and then save only one (or little more) batched files into the S3? Also why / why not?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14yxlz3", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yxlz3/storing_realtime_events_in_object_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yxlz3/storing_realtime_events_in_object_storage/", "subreddit_subscribers": 115758, "created_utc": 1689285022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://gretel.ai/blog/bring-your-own-cloud](https://gretel.ai/blog/bring-your-own-cloud)", "author_fullname": "t2_t4pwocav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anonymizing 7 terabytes of data in a hybrid cloud environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14yw2dw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1689281361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://gretel.ai/blog/bring-your-own-cloud\"&gt;https://gretel.ai/blog/bring-your-own-cloud&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?auto=webp&amp;s=bc3493917d3704a273ac737908af2200db053206", "width": 1440, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=210062dc56f116a92ad54cdf589382f4650558c0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=741b610f3aa7f92a6b0203c040fa6891d241da6f", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5149bccc1297b6b740a39bf74fd35c006475e3bc", "width": 320, "height": 177}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ddf12ec791acf3397800e1010de4283a3b40eca8", "width": 640, "height": 355}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=40087377ec3b0914b0d3606118e69ad54f379863", "width": 960, "height": 533}, {"url": "https://external-preview.redd.it/zyYu2UmNTIg1nqkl4xN8pnS0jZEVIun-Y1buQPXxlHM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd781648c0620c89b350217cc0e058fc94a7142e", "width": 1080, "height": 600}], "variants": {}, "id": "P3FdEpfGKtApmyi9xRhUP9Uq6puzmmJGETUlq8e2RgE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14yw2dw", "is_robot_indexable": true, "report_reasons": null, "author": "Synthesize2023", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14yw2dw/anonymizing_7_terabytes_of_data_in_a_hybrid_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14yw2dw/anonymizing_7_terabytes_of_data_in_a_hybrid_cloud/", "subreddit_subscribers": 115758, "created_utc": 1689281361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have built a custom Prometheus metrics exporter in Python for a Database system. \nThe exporter's job is to get data from the DB by running SQL queries (E), Convert the tabular data to key value pairs (T) and then send it to Prometheus (L).\nDoes this classify as an ETL job ?", "author_fullname": "t2_2hokn0mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can this be called an ETL ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ysqvg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689273573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have built a custom Prometheus metrics exporter in Python for a Database system. \nThe exporter&amp;#39;s job is to get data from the DB by running SQL queries (E), Convert the tabular data to key value pairs (T) and then send it to Prometheus (L).\nDoes this classify as an ETL job ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ysqvg", "is_robot_indexable": true, "report_reasons": null, "author": "deathlolwut", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ysqvg/can_this_be_called_an_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ysqvg/can_this_be_called_an_etl/", "subreddit_subscribers": 115758, "created_utc": 1689273573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone attended? How does it compare to other Data conferences?\n\nedw2023fall.dataversity.net\n\nI saw this post from earlier this year but didn't catch any mention of this one.", "author_fullname": "t2_4fhdq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enterprise Data World (EDW) Conference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ys7lx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1689272290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone attended? How does it compare to other Data conferences?&lt;/p&gt;\n\n&lt;p&gt;edw2023fall.dataversity.net&lt;/p&gt;\n\n&lt;p&gt;I saw this post from earlier this year but didn&amp;#39;t catch any mention of this one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ys7lx", "is_robot_indexable": true, "report_reasons": null, "author": "tolkienwhiteboy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ys7lx/enterprise_data_world_edw_conference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ys7lx/enterprise_data_world_edw_conference/", "subreddit_subscribers": 115758, "created_utc": 1689272290.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}