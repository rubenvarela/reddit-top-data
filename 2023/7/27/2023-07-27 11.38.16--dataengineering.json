{"kind": "Listing", "data": {"after": "t3_15at8lp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Turns out databases are \"relational\" or something", "author_fullname": "t2_qlmkijv8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The data engineer came to me... tears in his eyes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 107, "top_awarded_type": null, "hide_score": false, "name": "t3_15ae6kp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 527, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 527, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w5lBiBLnqC1xzIdkywBWCqB0YGYQeRWrqr08EMByD2s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690397313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Turns out databases are &amp;quot;relational&amp;quot; or something&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1wm37l33vceb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1wm37l33vceb1.png?auto=webp&amp;s=8eb68cc0feab067c94c5d88ca54a7eda2cbfcfd2", "width": 1080, "height": 830}, "resolutions": [{"url": "https://preview.redd.it/1wm37l33vceb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=48652b42e4fe71b9c48eac0b2a2c6a0eaaad045b", "width": 108, "height": 83}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=79d5b3781803dce41f5534196cb74c8f84aa1caa", "width": 216, "height": 166}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=afdafe3ea62eae50680c1797cac89dd8c6010a0f", "width": 320, "height": 245}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=992489262d93f2834aba10c908b504e4f58e328a", "width": 640, "height": 491}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=97be176695471f82f58a8349a936a5d2c170eaf9", "width": 960, "height": 737}, {"url": "https://preview.redd.it/1wm37l33vceb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b45cda7bf48386140f347a041f725b62cbbe33b", "width": 1080, "height": 830}], "variants": {}, "id": "UwqiG5dVs8n80MCeWPA1--klG-ySKne2YEq3LyGRi8k"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15ae6kp", "is_robot_indexable": true, "report_reasons": null, "author": "shed_antlers", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ae6kp/the_data_engineer_came_to_me_tears_in_his_eyes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1wm37l33vceb1.png", "subreddit_subscribers": 118385, "created_utc": 1690397313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great Expectations is bloaty. What are the alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a45gt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690373573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I set up GE on databricks but I am not happy with it. To the point where I am considering to just keep the very plain selfmade validation modules. Are there other options worth exploring? What I particulary dislike is the creation of custom expectations and all this data context bloat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15a45gt", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a45gt/great_expectations_is_bloaty_what_are_the/", "subreddit_subscribers": 118385, "created_utc": 1690373573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\nWe recently ran an experiment at [Dozer](https://github.com/getdozer/dozer) that I think worth sharing. We processed in real-time 160m records spread across 4 tables and created APIs from the result. The operation consisted of 4 JOINs and 1 aggregation. Here is a link to the experiment:\n\n[https://github.com/getdozer/dozer-samples/tree/main/usecases/scaling-ecommerce](https://github.com/getdozer/dozer-samples/tree/main/usecases/scaling-ecommerce)\n\nWould love to get your feedback.  \n\n\nThanks  \nMatteo", "author_fullname": "t2_5efs1s7d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Processing 160m of records (with 4 JOINs and 1 aggregation) in real-time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15axba2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690450727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;We recently ran an experiment at &lt;a href=\"https://github.com/getdozer/dozer\"&gt;Dozer&lt;/a&gt; that I think worth sharing. We processed in real-time 160m records spread across 4 tables and created APIs from the result. The operation consisted of 4 JOINs and 1 aggregation. Here is a link to the experiment:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/getdozer/dozer-samples/tree/main/usecases/scaling-ecommerce\"&gt;https://github.com/getdozer/dozer-samples/tree/main/usecases/scaling-ecommerce&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Would love to get your feedback.  &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;br/&gt;\nMatteo&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/s612CZA7VZM8OY-3Gnn7qwyEW65qB0LXv68Ev2-JnvQ.jpg?auto=webp&amp;s=205a7ce9ef4cd41ab708aeb4c8b2f411ade2b5c6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/s612CZA7VZM8OY-3Gnn7qwyEW65qB0LXv68Ev2-JnvQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b2137c62de69a82f790eca2cf323b4e9fa49a42", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/s612CZA7VZM8OY-3Gnn7qwyEW65qB0LXv68Ev2-JnvQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3e9e76b368d9bd2737828569495d8f080ea1ca66", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/s612CZA7VZM8OY-3Gnn7qwyEW65qB0LXv68Ev2-JnvQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ecc4927d891da4391fe409958ef35c9d5e83965e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/s612CZA7VZM8OY-3Gnn7qwyEW65qB0LXv68Ev2-JnvQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=19b42c63769cc4774b26d17ac2f1dbbcc10fd21a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/s612CZA7VZM8OY-3Gnn7qwyEW65qB0LXv68Ev2-JnvQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5ba1086ce1186414717e41899ed3393ff00818f4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/s612CZA7VZM8OY-3Gnn7qwyEW65qB0LXv68Ev2-JnvQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1f22dfc70fa64869063b5eedee17d4f7b841f7dc", "width": 1080, "height": 540}], "variants": {}, "id": "bsBU-V26yp9Cn213aetzEQxsmD1y-nrva8jMGPRMp5A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15axba2", "is_robot_indexable": true, "report_reasons": null, "author": "matteopelati76", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15axba2/processing_160m_of_records_with_4_joins_and_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15axba2/processing_160m_of_records_with_4_joins_and_1/", "subreddit_subscribers": 118385, "created_utc": 1690450727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone used Microsoft Fabric yet? If your a Microsoft shop are you planning on adopting it? \n\nNot coming from any angle I just haven\u2019t talked with anyone who has been using it a lot.", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft Fabric - have you used it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15am3g2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690415941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone used Microsoft Fabric yet? If your a Microsoft shop are you planning on adopting it? &lt;/p&gt;\n\n&lt;p&gt;Not coming from any angle I just haven\u2019t talked with anyone who has been using it a lot.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15am3g2", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15am3g2/microsoft_fabric_have_you_used_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15am3g2/microsoft_fabric_have_you_used_it/", "subreddit_subscribers": 118385, "created_utc": 1690415941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a cs software manager at a public company. I\u2019m not currently in a data engineering role, but I want to make a pivot into DE. I\u2019ve had a DE ticket open for several months for them just to scope and there\u2019s no end in sight. It could be several more months before they can even think about looking at our ticket. Suffice it to say our DE team is under resourced. \n\nThis is where I feel that maybe I\u2019m being naive: I feel like the request is simple. We want to create a daily job for some API reports and bring it into our data warehouse. \n\nHow many hoops does one need to jump through in a mid-level organization to write a script then push it to the warehouse? \n\nWhat level of difficulty is this normally? \n\nWould it be rude to write the script and hand it over to the DE team?\n\nLooking for advice to navigate the situation. Thanks!", "author_fullname": "t2_b7jxy4i2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I being naive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ad17i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690394712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a cs software manager at a public company. I\u2019m not currently in a data engineering role, but I want to make a pivot into DE. I\u2019ve had a DE ticket open for several months for them just to scope and there\u2019s no end in sight. It could be several more months before they can even think about looking at our ticket. Suffice it to say our DE team is under resourced. &lt;/p&gt;\n\n&lt;p&gt;This is where I feel that maybe I\u2019m being naive: I feel like the request is simple. We want to create a daily job for some API reports and bring it into our data warehouse. &lt;/p&gt;\n\n&lt;p&gt;How many hoops does one need to jump through in a mid-level organization to write a script then push it to the warehouse? &lt;/p&gt;\n\n&lt;p&gt;What level of difficulty is this normally? &lt;/p&gt;\n\n&lt;p&gt;Would it be rude to write the script and hand it over to the DE team?&lt;/p&gt;\n\n&lt;p&gt;Looking for advice to navigate the situation. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ad17i", "is_robot_indexable": true, "report_reasons": null, "author": "Marble_Kween", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ad17i/am_i_being_naive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ad17i/am_i_being_naive/", "subreddit_subscribers": 118385, "created_utc": 1690394712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If  you were to start over in the Data Engineering or would have to mentor someone, how would you do.   \nTaking into account all these new tools in today's tech stack.  \nI've researched all this, but TBH I don't have idea about 90% of these:  \n  \n\n**\u00b7 ETL and Scheduling or Orchestration or Jobs =**\n\n1. Open source Tools (Airflow(most used), Dagster, Argo, Prefect, Luigi)\n\n2. Traditional UI Tool (SSIS, Informatica, Talend, FiveTran)\n\n3. Cloud Tool (Azure Data Factory, Google Dataflow, AWS Glue)\n\n4. Modern Proprietary Tool (Databricks, Trifacta)\n\n5. Fivetran (just usually mostly used but a little old school) | MWAA (cost effective) | Apache Beam\n\n**\u00b7 Data Warehouse =** Snowflake or BigQuery | For Cloud = Amazon S3\n\n**\u00b7 Data Lakes =** DataBricks, Redshift\n\n**\u00b7 Data Transformation or Data Quality Control testing or Parallel Processing Tools =** dbt, Pandas, Apache Spark, \n\n**\u00b7 BI =** Power BI\n\n**\u00b7 Exploratory Data Analysis =** Snowflake, Jupyter, Alteryx, Snowflake Snowsight\n\n**\u00b7 Scaling Workers =** aws lambdas, kubernetes\n\n**\u00b7 Devops Methods =** Observability, alerting, incident management, ci/cd and good pr hygiene apply as much to DE as regular backend SE\n\n**\u00b7 Stream Processing =** Apache Kafka,\n\n**\u00b7 AWS Services =** RDS (to setup and scale db in cloud)", "author_fullname": "t2_3k9gevl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you learn DE if you had to start over ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15adu9z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690396515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If  you were to start over in the Data Engineering or would have to mentor someone, how would you do.&lt;br/&gt;\nTaking into account all these new tools in today&amp;#39;s tech stack.&lt;br/&gt;\nI&amp;#39;ve researched all this, but TBH I don&amp;#39;t have idea about 90% of these:  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 ETL and Scheduling or Orchestration or Jobs =&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Open source Tools (Airflow(most used), Dagster, Argo, Prefect, Luigi)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Traditional UI Tool (SSIS, Informatica, Talend, FiveTran)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Cloud Tool (Azure Data Factory, Google Dataflow, AWS Glue)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Modern Proprietary Tool (Databricks, Trifacta)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Fivetran (just usually mostly used but a little old school) | MWAA (cost effective) | Apache Beam&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Data Warehouse =&lt;/strong&gt; Snowflake or BigQuery | For Cloud = Amazon S3&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Data Lakes =&lt;/strong&gt; DataBricks, Redshift&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Data Transformation or Data Quality Control testing or Parallel Processing Tools =&lt;/strong&gt; dbt, Pandas, Apache Spark, &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 BI =&lt;/strong&gt; Power BI&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Exploratory Data Analysis =&lt;/strong&gt; Snowflake, Jupyter, Alteryx, Snowflake Snowsight&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Scaling Workers =&lt;/strong&gt; aws lambdas, kubernetes&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Devops Methods =&lt;/strong&gt; Observability, alerting, incident management, ci/cd and good pr hygiene apply as much to DE as regular backend SE&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 Stream Processing =&lt;/strong&gt; Apache Kafka,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;\u00b7 AWS Services =&lt;/strong&gt; RDS (to setup and scale db in cloud)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15adu9z", "is_robot_indexable": true, "report_reasons": null, "author": "Pillstyr", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15adu9z/how_would_you_learn_de_if_you_had_to_start_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15adu9z/how_would_you_learn_de_if_you_had_to_start_over/", "subreddit_subscribers": 118385, "created_utc": 1690396515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I'm working on AWS and have it available for experiments.\n\nIf you have any guide/tutorial/walkthrough to recommend, please do share!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend a good k8s / EKS guide?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a32at", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690370610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familiar with Docker and docker-compose, but I never had to use k8s and I would like to learn, in order to be able to deploy my own stuff with this method. Currently I&amp;#39;m working on AWS and have it available for experiments.&lt;/p&gt;\n\n&lt;p&gt;If you have any guide/tutorial/walkthrough to recommend, please do share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a32at", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a32at/recommend_a_good_k8s_eks_guide/", "subreddit_subscribers": 118385, "created_utc": 1690370610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "50-60GB database on aurora, everythings fine on writes/updates and transactional operations. We hooked the db to be used as analytics dashboard pulling a fair amount of data but disk i/o is extremely slow from query plan around 5-15mb/s. Bumping up instance ram and loading all working database into shared_buffers cache everything works fine. So I came up to the following conclusions:\n\n- aws aurora is basically unusable for olap workloads as i/o timings are terribly slow (and couldn't find an official figure from aws)\n- aws aurora storage layer uses a storage attached network observed disk i/o is very low and there is no OS level cache so they recommend loading up all databse in memory\n- does aws rds postgres with provisioned ssd suffer from the same problem? iops and throughput are 100x better on paper\n- anyone had similar experiences with aurora and working with relatively large datasets?\n- considering moving to redshift", "author_fullname": "t2_b5vlra5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Aurora not usable for OLAP workloads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15agi5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690402621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;50-60GB database on aurora, everythings fine on writes/updates and transactional operations. We hooked the db to be used as analytics dashboard pulling a fair amount of data but disk i/o is extremely slow from query plan around 5-15mb/s. Bumping up instance ram and loading all working database into shared_buffers cache everything works fine. So I came up to the following conclusions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;aws aurora is basically unusable for olap workloads as i/o timings are terribly slow (and couldn&amp;#39;t find an official figure from aws)&lt;/li&gt;\n&lt;li&gt;aws aurora storage layer uses a storage attached network observed disk i/o is very low and there is no OS level cache so they recommend loading up all databse in memory&lt;/li&gt;\n&lt;li&gt;does aws rds postgres with provisioned ssd suffer from the same problem? iops and throughput are 100x better on paper&lt;/li&gt;\n&lt;li&gt;anyone had similar experiences with aurora and working with relatively large datasets?&lt;/li&gt;\n&lt;li&gt;considering moving to redshift&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15agi5q", "is_robot_indexable": true, "report_reasons": null, "author": "golangcafe", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15agi5q/aws_aurora_not_usable_for_olap_workloads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15agi5q/aws_aurora_not_usable_for_olap_workloads/", "subreddit_subscribers": 118385, "created_utc": 1690402621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nSQL query tuning and optimization.\n\nSQL indexing.\n\nSQL integration.\n\nSQL reporting.\n\nSQL execution plans.", "author_fullname": "t2_97jhjawv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the right learning order for these SQL subjects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a94v3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690385880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SQL query tuning and optimization.&lt;/p&gt;\n\n&lt;p&gt;SQL indexing.&lt;/p&gt;\n\n&lt;p&gt;SQL integration.&lt;/p&gt;\n\n&lt;p&gt;SQL reporting.&lt;/p&gt;\n\n&lt;p&gt;SQL execution plans.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a94v3", "is_robot_indexable": true, "report_reasons": null, "author": "TreatOk8778", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a94v3/whats_the_right_learning_order_for_these_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a94v3/whats_the_right_learning_order_for_these_sql/", "subreddit_subscribers": 118385, "created_utc": 1690385880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "dbt on Spark vs dbt on Trino\n\nHi, we're running a on-prem data platform solution with stacks of **Iceberg** (parquet), **Hive**, **Spark**, **MINIO**, etc. and planning to use **dbt** for our **SQL transformation** of tabular data (Dim Fact modeling, Data Mart, etc.), after the data has been processed by Spark (Ingestion, parsing, etc.). The processing data size is usually around 10-100s million records per batch\n\n* Should we use dbt on Spark or dbt on Trino. Our use cases are ETL, so what is the difference between the twos, regarding the performance, scalability, feature, etc.? \n   * I don't have much experience with Trino, so I'm not sure if we need to process heavy jobs, will Trino perform as good as Spark, given the same resources. Has anyone use Trino as the processing tool for ETL yet, rather than just a query engine for adhoc/interactive query? I've seen many blogs from Starburst of using Trino as a processing engine for ETL, but not sure if it's true.\n* For dbt on Spark, what should be the setup? Spark Thrift (default Spark Thrift Server or Apache Kyuubi?), Spark HTTP (using Apache Livy) or any other options? \n   * Spark Thrift: Spark Thrift Server seems to have many issues mentioned here ([https://kyuubi.readthedocs.io/en/v1.5.2-incubating/overview/kyuubi\\_vs\\_thriftserver.html#kyuubi-vs-spark-thrift-server](https://kyuubi.readthedocs.io/en/v1.5.2-incubating/overview/kyuubi_vs_thriftserver.html#kyuubi-vs-spark-thrift-server)), which make us think Apache Kyuubi would be a good choice. However, we couldn't find any document/post related to running dbt on Spark Apache Kyuubi\n   * dbt livy: provided by Cloudera, with very few updates. The Apache Livy project doesn't have much update recently, so I'm afraid we will go into another dead end with this approach\n\n&amp;#x200B;", "author_fullname": "t2_4j9omvnso", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Spark vs dbt Trino", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15av4jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690443143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;dbt on Spark vs dbt on Trino&lt;/p&gt;\n\n&lt;p&gt;Hi, we&amp;#39;re running a on-prem data platform solution with stacks of &lt;strong&gt;Iceberg&lt;/strong&gt; (parquet), &lt;strong&gt;Hive&lt;/strong&gt;, &lt;strong&gt;Spark&lt;/strong&gt;, &lt;strong&gt;MINIO&lt;/strong&gt;, etc. and planning to use &lt;strong&gt;dbt&lt;/strong&gt; for our &lt;strong&gt;SQL transformation&lt;/strong&gt; of tabular data (Dim Fact modeling, Data Mart, etc.), after the data has been processed by Spark (Ingestion, parsing, etc.). The processing data size is usually around 10-100s million records per batch&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Should we use dbt on Spark or dbt on Trino. Our use cases are ETL, so what is the difference between the twos, regarding the performance, scalability, feature, etc.? \n\n&lt;ul&gt;\n&lt;li&gt;I don&amp;#39;t have much experience with Trino, so I&amp;#39;m not sure if we need to process heavy jobs, will Trino perform as good as Spark, given the same resources. Has anyone use Trino as the processing tool for ETL yet, rather than just a query engine for adhoc/interactive query? I&amp;#39;ve seen many blogs from Starburst of using Trino as a processing engine for ETL, but not sure if it&amp;#39;s true.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;For dbt on Spark, what should be the setup? Spark Thrift (default Spark Thrift Server or Apache Kyuubi?), Spark HTTP (using Apache Livy) or any other options? \n\n&lt;ul&gt;\n&lt;li&gt;Spark Thrift: Spark Thrift Server seems to have many issues mentioned here (&lt;a href=\"https://kyuubi.readthedocs.io/en/v1.5.2-incubating/overview/kyuubi_vs_thriftserver.html#kyuubi-vs-spark-thrift-server\"&gt;https://kyuubi.readthedocs.io/en/v1.5.2-incubating/overview/kyuubi_vs_thriftserver.html#kyuubi-vs-spark-thrift-server&lt;/a&gt;), which make us think Apache Kyuubi would be a good choice. However, we couldn&amp;#39;t find any document/post related to running dbt on Spark Apache Kyuubi&lt;/li&gt;\n&lt;li&gt;dbt livy: provided by Cloudera, with very few updates. The Apache Livy project doesn&amp;#39;t have much update recently, so I&amp;#39;m afraid we will go into another dead end with this approach&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15av4jc", "is_robot_indexable": true, "report_reasons": null, "author": "chuqbach", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15av4jc/dbt_spark_vs_dbt_trino/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15av4jc/dbt_spark_vs_dbt_trino/", "subreddit_subscribers": 118385, "created_utc": 1690443143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Disclaimer: I have an okay amount of knowledge in containerization and docker, but certainly still learning.\n\nCurrently, I am developing an ETL job as a Docker application that reads parquet data from a data lake, performs transformations, and then loads the processed data back into the data lake. This process is basically read silver layer -&gt; performing transformations -&gt; load to gold layer. The ETL task handles new data that has been ingested within the last minute, where a message queue tells the ETL task which parquet file needs processed. To facilitate the transformations, some data needs to be persisted in an application database, enabling lookups during the transformation process. For instance, the database is used to join previously stored header data with new process data or to perform recursive lookups through parent-child relationships, seeking the \"origin\" for specific IDs. \n\nI'm treating it like a standard application architecture, with the ETL process acting as the \"front end,\" and the database holding the persisted data serving as the \"back end.\" The ETL front end, which is implemented in Python, reads the new data and executes multiple SQL queries against the back-end database (while also writing to it). These queries are needed to perform the necessary transformations. For the deployment, I intend to utilize Docker Compose and manage it as a multi-container application in production, incorporating a PostgreSQL database volume mount. \n\n Now, my primary concern is how to effectively test and develop the SQL queries that the ETL task \"front end\" container needs to execute on the PostgreSQL database backend, given that the database doesn't exist until after the application is up and running. I can't just randomly write the SQL queries throughout the python application and hope they will all work when I actually build and run the container. Just can't seem to wrap my head around this one. \n\nHope this makes sense, I can clarify and makes edits if needed. Thanks! ", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-Container Docker Application for ETL Task", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15arvak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690432327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Disclaimer: I have an okay amount of knowledge in containerization and docker, but certainly still learning.&lt;/p&gt;\n\n&lt;p&gt;Currently, I am developing an ETL job as a Docker application that reads parquet data from a data lake, performs transformations, and then loads the processed data back into the data lake. This process is basically read silver layer -&amp;gt; performing transformations -&amp;gt; load to gold layer. The ETL task handles new data that has been ingested within the last minute, where a message queue tells the ETL task which parquet file needs processed. To facilitate the transformations, some data needs to be persisted in an application database, enabling lookups during the transformation process. For instance, the database is used to join previously stored header data with new process data or to perform recursive lookups through parent-child relationships, seeking the &amp;quot;origin&amp;quot; for specific IDs. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m treating it like a standard application architecture, with the ETL process acting as the &amp;quot;front end,&amp;quot; and the database holding the persisted data serving as the &amp;quot;back end.&amp;quot; The ETL front end, which is implemented in Python, reads the new data and executes multiple SQL queries against the back-end database (while also writing to it). These queries are needed to perform the necessary transformations. For the deployment, I intend to utilize Docker Compose and manage it as a multi-container application in production, incorporating a PostgreSQL database volume mount. &lt;/p&gt;\n\n&lt;p&gt;Now, my primary concern is how to effectively test and develop the SQL queries that the ETL task &amp;quot;front end&amp;quot; container needs to execute on the PostgreSQL database backend, given that the database doesn&amp;#39;t exist until after the application is up and running. I can&amp;#39;t just randomly write the SQL queries throughout the python application and hope they will all work when I actually build and run the container. Just can&amp;#39;t seem to wrap my head around this one. &lt;/p&gt;\n\n&lt;p&gt;Hope this makes sense, I can clarify and makes edits if needed. Thanks! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15arvak", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15arvak/multicontainer_docker_application_for_etl_task/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15arvak/multicontainer_docker_application_for_etl_task/", "subreddit_subscribers": 118385, "created_utc": 1690432327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EP26 - Versioning Data in the Data Lakehouse (File, Table and Catalog Versioning)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_15ar04s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Q3g8NFhvddk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"EP26 - Versioning Data in the Data Lakehouse (File, Table and Catalog Versioning)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "EP26 - Versioning Data in the Data Lakehouse (File, Table and Catalog Versioning)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Q3g8NFhvddk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"EP26 - Versioning Data in the Data Lakehouse (File, Table and Catalog Versioning)\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/Q3g8NFhvddk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Q3g8NFhvddk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"EP26 - Versioning Data in the Data Lakehouse (File, Table and Catalog Versioning)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/15ar04s", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UTHqpTlFHrrrFREZFZTlXAqR4y13Ig3P1bFS37PHAVQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690429699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/Q3g8NFhvddk", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YEosjDQSPs6x5ZEcqj1prjh4vJ4qmRJDPfsj24Cv3cQ.jpg?auto=webp&amp;s=58f6eb9c6da7e629e8d7d9552a11c526550b142f", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/YEosjDQSPs6x5ZEcqj1prjh4vJ4qmRJDPfsj24Cv3cQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=093b1485febcece41dbb6ab0d6c431d65c795dd9", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/YEosjDQSPs6x5ZEcqj1prjh4vJ4qmRJDPfsj24Cv3cQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5c3d43d042ab2f713542f19a17bdfa229b03d4a0", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/YEosjDQSPs6x5ZEcqj1prjh4vJ4qmRJDPfsj24Cv3cQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=88609eb050a6bf25a93e32b82ce82244d89e5855", "width": 320, "height": 240}], "variants": {}, "id": "8_alXOI9EvUESL8dnHyGGGOsh0IN9L4WwQtx6q-hGZk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ar04s", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ar04s/ep26_versioning_data_in_the_data_lakehouse_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/Q3g8NFhvddk", "subreddit_subscribers": 118385, "created_utc": 1690429699.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "EP26 - Versioning Data in the Data Lakehouse (File, Table and Catalog Versioning)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Q3g8NFhvddk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"EP26 - Versioning Data in the Data Lakehouse (File, Table and Catalog Versioning)\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/Q3g8NFhvddk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2cbhndmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is streaming SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15al69d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Re0FrSKMKH7YzlSDIlhfvarfaaPUaILjQFPTJNoxxhQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690413596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arroyo.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arroyo.dev/blog/streaming-sql-explained", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hlUyH04htRFHDmPXMfa2ShAi-5orpk5NucVNicnuep8.jpg?auto=webp&amp;s=60cfb566bad70b9f2446d482dd485a7ce91f2f6a", "width": 4000, "height": 2250}, "resolutions": [{"url": "https://external-preview.redd.it/hlUyH04htRFHDmPXMfa2ShAi-5orpk5NucVNicnuep8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8eecfb2808009fd734c4760b8b50c68a6d1aaa2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/hlUyH04htRFHDmPXMfa2ShAi-5orpk5NucVNicnuep8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1775b73296b89801e089b6019bae3538a3513fc1", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/hlUyH04htRFHDmPXMfa2ShAi-5orpk5NucVNicnuep8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25901a5d50ac17e2eb59f6d17798ef81011aec78", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/hlUyH04htRFHDmPXMfa2ShAi-5orpk5NucVNicnuep8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f31c8d445f2be0eec7b36cbc3f7c1d8aa6fdc1f5", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/hlUyH04htRFHDmPXMfa2ShAi-5orpk5NucVNicnuep8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d643256c055bda777359846c4365c23c6a18a6c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/hlUyH04htRFHDmPXMfa2ShAi-5orpk5NucVNicnuep8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=feab0d107309110d3ed7f808565aa6c0ce73add5", "width": 1080, "height": 607}], "variants": {}, "id": "6IvzkDLHQGPnq8tOrsS9svvlhoQh6aVrBV8elvIdwPc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15al69d", "is_robot_indexable": true, "report_reasons": null, "author": "mwylde_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15al69d/what_is_streaming_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arroyo.dev/blog/streaming-sql-explained", "subreddit_subscribers": 118385, "created_utc": 1690413596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My org uses kafka to ingest data from source teams into snowflake, but then uses dbt + airflow to do nearly every model that happens downstream of raw data. I had a recent conversation with a coworker about how it's kindof a shame that we have real-time data, but don't actually serve it on our data platform except for once or a few times per day. \n\nIs it generally recommended to push everything to stream processing (if it can be)? \n\nFor example, suppose you're a retail company and a typical use case could be serving data for downstream about the price of products. You might maintain: \n\n* the latest price of the product in a dimensional table - `dim_product_current`\n* the historical prices of the product in a type 2 scd history table - `dim_product_history`\n* a daily snapshot of the prices for all of your products on a given day\n\nOf the three, the current use-case seems most appropriate (and easiest to implement) for real-time. Does it even make sense to enable maintaining scd type 2 for streaming data?\n\nCurious how other teams/orgs approach these problems", "author_fullname": "t2_5e0ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming vs Batch modeling discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ak8si", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690411292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My org uses kafka to ingest data from source teams into snowflake, but then uses dbt + airflow to do nearly every model that happens downstream of raw data. I had a recent conversation with a coworker about how it&amp;#39;s kindof a shame that we have real-time data, but don&amp;#39;t actually serve it on our data platform except for once or a few times per day. &lt;/p&gt;\n\n&lt;p&gt;Is it generally recommended to push everything to stream processing (if it can be)? &lt;/p&gt;\n\n&lt;p&gt;For example, suppose you&amp;#39;re a retail company and a typical use case could be serving data for downstream about the price of products. You might maintain: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;the latest price of the product in a dimensional table - &lt;code&gt;dim_product_current&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;the historical prices of the product in a type 2 scd history table - &lt;code&gt;dim_product_history&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;a daily snapshot of the prices for all of your products on a given day&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Of the three, the current use-case seems most appropriate (and easiest to implement) for real-time. Does it even make sense to enable maintaining scd type 2 for streaming data?&lt;/p&gt;\n\n&lt;p&gt;Curious how other teams/orgs approach these problems&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ak8si", "is_robot_indexable": true, "report_reasons": null, "author": "harrytrumanprimate", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ak8si/streaming_vs_batch_modeling_discussion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ak8si/streaming_vs_batch_modeling_discussion/", "subreddit_subscribers": 118385, "created_utc": 1690411292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems like Redshift would be good to learn, but the pricing I see on it scares the c#@p out of me. Does anyone know a good tutorial which also includes how much will be spent by following along and also shows thorough instructions on how to shut down and destroy the resources when finished?", "author_fullname": "t2_io9vf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scared of Redshift - Any Good Resources to Learn with Low Cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15acq1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690394010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems like Redshift would be good to learn, but the pricing I see on it scares the c#@p out of me. Does anyone know a good tutorial which also includes how much will be spent by following along and also shows thorough instructions on how to shut down and destroy the resources when finished?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15acq1h", "is_robot_indexable": true, "report_reasons": null, "author": "Scalar_Mikeman", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15acq1h/scared_of_redshift_any_good_resources_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15acq1h/scared_of_redshift_any_good_resources_to_learn/", "subreddit_subscribers": 118385, "created_utc": 1690394010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Appreciate if you can share it...\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a guide to design a star schema from a data vault?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15aayhz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690390064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Appreciate if you can share it...&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15aayhz", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15aayhz/do_you_have_a_guide_to_design_a_star_schema_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15aayhz/do_you_have_a_guide_to_design_a_star_schema_from/", "subreddit_subscribers": 118385, "created_utc": 1690390064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm assisting a non-profit in a food supply chain project and wanting to understand the cheapest, most efficient way to track the lat/longs of their trucks over time, including real-time. Only about \\~10 trucks and we don't need anything fancy. Just truck+datetime+lat+long.\n\nWhat hardware/tools would be cheapest to obtain this type of information? Options I've considered, but each has their downsides:\n\n1. My mind went to Airtags first for simplicity purposes, but accessing history seems possibly achievable, but frustrating.\n2. Verizon Connect Fleet Tracking - Ability to access historical data, but I didn't see lat/long in their video. Also probably too expensive, but they're too vague on pricing on their site.\n3. A quick \"GPS Fleet Tracking\" search yields a ton of different company offerings, but many seem like overkill (and would likely price as such). I'm looking for the simplest offering, not the most robust.\n\nFor what it's worth, I'm relatively new to data engineering and brand new to ingestion of lat/longs, so apologies if this is a stupid question!", "author_fullname": "t2_pmps7fj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to ingest lat/long data via GPS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a8yck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690385459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m assisting a non-profit in a food supply chain project and wanting to understand the cheapest, most efficient way to track the lat/longs of their trucks over time, including real-time. Only about ~10 trucks and we don&amp;#39;t need anything fancy. Just truck+datetime+lat+long.&lt;/p&gt;\n\n&lt;p&gt;What hardware/tools would be cheapest to obtain this type of information? Options I&amp;#39;ve considered, but each has their downsides:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;My mind went to Airtags first for simplicity purposes, but accessing history seems possibly achievable, but frustrating.&lt;/li&gt;\n&lt;li&gt;Verizon Connect Fleet Tracking - Ability to access historical data, but I didn&amp;#39;t see lat/long in their video. Also probably too expensive, but they&amp;#39;re too vague on pricing on their site.&lt;/li&gt;\n&lt;li&gt;A quick &amp;quot;GPS Fleet Tracking&amp;quot; search yields a ton of different company offerings, but many seem like overkill (and would likely price as such). I&amp;#39;m looking for the simplest offering, not the most robust.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For what it&amp;#39;s worth, I&amp;#39;m relatively new to data engineering and brand new to ingestion of lat/longs, so apologies if this is a stupid question!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a8yck", "is_robot_indexable": true, "report_reasons": null, "author": "hornfan87", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a8yck/easiest_way_to_ingest_latlong_data_via_gps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a8yck/easiest_way_to_ingest_latlong_data_via_gps/", "subreddit_subscribers": 118385, "created_utc": 1690385459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently working on replacing one of our online management systems with a new one and one of the requirements for the migration is to sort out how we are going to do this on a DW side.\n\nI know that my role is to figure out what the ETL/ELT process is and make sure that the data pipelines are feeding in but the biggest concern I have is understanding whether my job involves getting the business logic for field transformation directly or whether this is something which the BI team should do ? I've worked as a BI analyst in the business and I've always thought that this should be a BI job to understand how each column is calculated at least on a high end level and then work with the DE to figure out whether there's any extra details to any columns. One of the arguments for it being a DE job for business logic requirements is that there is already backend logic to this which I think is fair but not all the column is mapped 1-1 and the systems totally different.\n\nHaven't asked my manager but was hoping to grab some 2nd opinions before this is raised up as it's definitely making me frustrated. As context I've work in BI for 4 years and DE for 2.", "author_fullname": "t2_2ahdonrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE or BI to figure out business logic requirements ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a7d7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690381714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently working on replacing one of our online management systems with a new one and one of the requirements for the migration is to sort out how we are going to do this on a DW side.&lt;/p&gt;\n\n&lt;p&gt;I know that my role is to figure out what the ETL/ELT process is and make sure that the data pipelines are feeding in but the biggest concern I have is understanding whether my job involves getting the business logic for field transformation directly or whether this is something which the BI team should do ? I&amp;#39;ve worked as a BI analyst in the business and I&amp;#39;ve always thought that this should be a BI job to understand how each column is calculated at least on a high end level and then work with the DE to figure out whether there&amp;#39;s any extra details to any columns. One of the arguments for it being a DE job for business logic requirements is that there is already backend logic to this which I think is fair but not all the column is mapped 1-1 and the systems totally different.&lt;/p&gt;\n\n&lt;p&gt;Haven&amp;#39;t asked my manager but was hoping to grab some 2nd opinions before this is raised up as it&amp;#39;s definitely making me frustrated. As context I&amp;#39;ve work in BI for 4 years and DE for 2.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a7d7y", "is_robot_indexable": true, "report_reasons": null, "author": "taafpxd", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a7d7y/de_or_bi_to_figure_out_business_logic_requirements/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a7d7y/de_or_bi_to_figure_out_business_logic_requirements/", "subreddit_subscribers": 118385, "created_utc": 1690381714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability: The Next Frontier of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a6h78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1690379554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15a6h78", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a6h78/data_observability_the_next_frontier_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "subreddit_subscribers": 118385, "created_utc": 1690379554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests, I'm trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I'm able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying \n\n\"Cannot infer schema when the input path \\`/mnt/mnt\\_s3\\` is empty. Please try to start the stream when there are files in the input path, or specify the schema.\"\n\nHowever [dbutils.fs.ls](https://dbutils.fs.ls)('/mnt/mnt\\_s3') gives me this \\[FileInfo(path='dbfs:/mnt/mnt\\_s3/flightdata2018.json', name='flightdata2018.json', size=3276800, modificationTime=1690369838000)\\]\n\nP.S Complete noob to databricks, any help is greatly appreciated ", "author_fullname": "t2_a2sp7ole", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Live Tables Pipeline unable to read data from S3 mount", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15a5734", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690376327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests, I&amp;#39;m trying to read in a fair bit of data from my s3 bucket, I decided to go ahead and mount it to my dbfs. While I&amp;#39;m able to read it using Autoloader standard at the same mount location. When I try running my Workflow using Delta Live Tables I get an error saying &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Cannot infer schema when the input path `/mnt/mnt_s3` is empty. Please try to start the stream when there are files in the input path, or specify the schema.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;However &lt;a href=\"https://dbutils.fs.ls\"&gt;dbutils.fs.ls&lt;/a&gt;(&amp;#39;/mnt/mnt_s3&amp;#39;) gives me this [FileInfo(path=&amp;#39;dbfs:/mnt/mnt_s3/flightdata2018.json&amp;#39;, name=&amp;#39;flightdata2018.json&amp;#39;, size=3276800, modificationTime=1690369838000)]&lt;/p&gt;\n\n&lt;p&gt;P.S Complete noob to databricks, any help is greatly appreciated &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15a5734", "is_robot_indexable": true, "report_reasons": null, "author": "No_Conversation_2474", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15a5734/delta_live_tables_pipeline_unable_to_read_data/", "subreddit_subscribers": 118385, "created_utc": 1690376327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am in the process of learning and improvising designing systems and solutions around data engineering usecases. Would like to know better tools and references for learning well-architected solutions (just like AWS Solution Architect - Learning Path), but generalizer and data engineering specific", "author_fullname": "t2_2fcmcq98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which are good tools and references to learn design and architecting data engineering solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ay13l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690453100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in the process of learning and improvising designing systems and solutions around data engineering usecases. Would like to know better tools and references for learning well-architected solutions (just like AWS Solution Architect - Learning Path), but generalizer and data engineering specific&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ay13l", "is_robot_indexable": true, "report_reasons": null, "author": "rockeyjam", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ay13l/which_are_good_tools_and_references_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ay13l/which_are_good_tools_and_references_to_learn/", "subreddit_subscribers": 118385, "created_utc": 1690453100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I'm new to data so don judge my dumb question, anyway I'm supposed to build a simple dimensional model for a library, I already made the data model, I'm using book loans as the fact table, and members, library staff, reservations and books as the dimensions, any advise  to better this because it didn't impress my boss\n\nguys, please help", "author_fullname": "t2_uxog2zx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dimensional model for a library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15axj5g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690451468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I&amp;#39;m new to data so don judge my dumb question, anyway I&amp;#39;m supposed to build a simple dimensional model for a library, I already made the data model, I&amp;#39;m using book loans as the fact table, and members, library staff, reservations and books as the dimensions, any advise  to better this because it didn&amp;#39;t impress my boss&lt;/p&gt;\n\n&lt;p&gt;guys, please help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15axj5g", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Preparation-4231", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15axj5g/dimensional_model_for_a_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15axj5g/dimensional_model_for_a_library/", "subreddit_subscribers": 118385, "created_utc": 1690451468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to work within the cloud space but it's tough to decide which route to take.\nThis is at one of the big 4, I am ok with either or but I am scared in cloud security consulting role I won't be as techinal as the data engineering role in cloud.\n\nIf any data engineer has worked in cloud,could you tell me about the wlb,salary,and remote opportunities?", "author_fullname": "t2_77qdsbiy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud Security Consultant or Cloud Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15awncy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690448460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to work within the cloud space but it&amp;#39;s tough to decide which route to take.\nThis is at one of the big 4, I am ok with either or but I am scared in cloud security consulting role I won&amp;#39;t be as techinal as the data engineering role in cloud.&lt;/p&gt;\n\n&lt;p&gt;If any data engineer has worked in cloud,could you tell me about the wlb,salary,and remote opportunities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15awncy", "is_robot_indexable": true, "report_reasons": null, "author": "YuriHaThicc", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15awncy/cloud_security_consultant_or_cloud_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15awncy/cloud_security_consultant_or_cloud_data_engineer/", "subreddit_subscribers": 118385, "created_utc": 1690448460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. i want to build a concurrent api that can be used for bulk hitting. I just want to know what are some industry standard practices that I can put in the process. I have previously used flask with asynchronous process but just curious about how the process get performed in the industry.", "author_fullname": "t2_270isr53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Concurrent API with bulk hit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15atkim", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690437849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. i want to build a concurrent api that can be used for bulk hitting. I just want to know what are some industry standard practices that I can put in the process. I have previously used flask with asynchronous process but just curious about how the process get performed in the industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15atkim", "is_robot_indexable": true, "report_reasons": null, "author": "rishabhdev_rd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15atkim/concurrent_api_with_bulk_hit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15atkim/concurrent_api_with_bulk_hit/", "subreddit_subscribers": 118385, "created_utc": 1690437849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm using Hive external table to read parquet files with 100 columns. Some of my files don't have a column (let's say its position no is 3), and this column is there in the Hive table schema. When I read the table from Impala, I see that my data in the parquet files that don't have the column gets shifted to the left instead of just adding null in the not present column.\n\nI'm using case-sensitive column name parquet files, which match the hive table column names. \n\nI've not seen this issue happen on Glue Catalog.", "author_fullname": "t2_t1rd5ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hive external table on Parquet files issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15at8lp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690436762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Hive external table to read parquet files with 100 columns. Some of my files don&amp;#39;t have a column (let&amp;#39;s say its position no is 3), and this column is there in the Hive table schema. When I read the table from Impala, I see that my data in the parquet files that don&amp;#39;t have the column gets shifted to the left instead of just adding null in the not present column.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using case-sensitive column name parquet files, which match the hive table column names. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve not seen this issue happen on Glue Catalog.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15at8lp", "is_robot_indexable": true, "report_reasons": null, "author": "PR0K1NG", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15at8lp/hive_external_table_on_parquet_files_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15at8lp/hive_external_table_on_parquet_files_issue/", "subreddit_subscribers": 118385, "created_utc": 1690436762.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}