{"kind": "Listing", "data": {"after": "t3_18ia5ta", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys!\n\nI am making a small group of people learning data engineering where we get on a call together every other week and talk about tools we're learning and other DE-related things. This will be good for everyone in the group to get better at DE and help each other out when needed. \n\nThanks, and happy learning to everyone!\n\nEdit: If more of you are interested consider making small groups with each other.\n\nEdit, again: If you are still interested please reach out to other people who want to make groups.", "author_fullname": "t2_3arqiq34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small Group of Data Engineering Learners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i9w4x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702601650.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702564301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys!&lt;/p&gt;\n\n&lt;p&gt;I am making a small group of people learning data engineering where we get on a call together every other week and talk about tools we&amp;#39;re learning and other DE-related things. This will be good for everyone in the group to get better at DE and help each other out when needed. &lt;/p&gt;\n\n&lt;p&gt;Thanks, and happy learning to everyone!&lt;/p&gt;\n\n&lt;p&gt;Edit: If more of you are interested consider making small groups with each other.&lt;/p&gt;\n\n&lt;p&gt;Edit, again: If you are still interested please reach out to other people who want to make groups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18i9w4x", "is_robot_indexable": true, "report_reasons": null, "author": "RepresentativePen297", "discussion_type": null, "num_comments": 143, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i9w4x/small_group_of_data_engineering_learners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i9w4x/small_group_of_data_engineering_learners/", "subreddit_subscribers": 146052, "created_utc": 1702564301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "People who\u2019ve been in this game since when the hype was really getting started in the beginning of the last decade, what was it like working in the first companies that tried to build big data pipelines? What was the stack you worked on? I know that Hadoop and NoSQL were very trendy at the time, but can you share some more typical technologies that you ran into a lot? Are some of them supplanted by now or are they mostly still going strong?", "author_fullname": "t2_1xobc52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What was data engineering like circa 2011-2013?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ilbto", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702594923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;People who\u2019ve been in this game since when the hype was really getting started in the beginning of the last decade, what was it like working in the first companies that tried to build big data pipelines? What was the stack you worked on? I know that Hadoop and NoSQL were very trendy at the time, but can you share some more typical technologies that you ran into a lot? Are some of them supplanted by now or are they mostly still going strong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ilbto", "is_robot_indexable": true, "report_reasons": null, "author": "pimmen89", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ilbto/what_was_data_engineering_like_circa_20112013/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ilbto/what_was_data_engineering_like_circa_20112013/", "subreddit_subscribers": 146052, "created_utc": 1702594923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a proprietary Excel .VBA that uses a highly complex mathematical function using 6 values to generate a number.  E.g.,:\n\n=PropietaryFormula(A1,B1,C1,D1,E1)*F1\n\nI don't have access to the VBA source code and a can't reverse engineer the math function.  I want to get away from using Excel and be able to fetch the value with an HTTP call (Azure function) by sending the 6 inputs in the HTTP request.   To generate all possible values using these inputs, the end result is around 600 billion unique combinations.\n\nI'm able to use Power Automate Desktop to open Excel, populate the inputs, and generate the needed value using the function.  I think I can do this for about 100,000 rows for each Excel file to stay within the memory limits on my desktop.  From there is where I'm wondering what would be the easiest way to get this into a data warehouse.  I'm thinking I could upload these 100s of thousands of Excel files to Azure ADL2 storage and use Synapse Analytics or Databricks to push them into a database, but I'm hoping someone out there may have a much better, faster, and cheaper idea.\n\nThanks!", "author_fullname": "t2_9lsmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you populate 600 billion rows in a structured database where the values are generated from Excel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18il8i8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702594692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a proprietary Excel .VBA that uses a highly complex mathematical function using 6 values to generate a number.  E.g.,:&lt;/p&gt;\n\n&lt;p&gt;=PropietaryFormula(A1,B1,C1,D1,E1)*F1&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have access to the VBA source code and a can&amp;#39;t reverse engineer the math function.  I want to get away from using Excel and be able to fetch the value with an HTTP call (Azure function) by sending the 6 inputs in the HTTP request.   To generate all possible values using these inputs, the end result is around 600 billion unique combinations.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m able to use Power Automate Desktop to open Excel, populate the inputs, and generate the needed value using the function.  I think I can do this for about 100,000 rows for each Excel file to stay within the memory limits on my desktop.  From there is where I&amp;#39;m wondering what would be the easiest way to get this into a data warehouse.  I&amp;#39;m thinking I could upload these 100s of thousands of Excel files to Azure ADL2 storage and use Synapse Analytics or Databricks to push them into a database, but I&amp;#39;m hoping someone out there may have a much better, faster, and cheaper idea.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18il8i8", "is_robot_indexable": true, "report_reasons": null, "author": "dantasticdotorg", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18il8i8/how_would_you_populate_600_billion_rows_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18il8i8/how_would_you_populate_600_billion_rows_in_a/", "subreddit_subscribers": 146052, "created_utc": 1702594692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was looking into Azure documentation for clustered columnstore indexes and I noticed the following:  \n\" Clustered columnstore indexes work on segments of 1,048,576 rows. As Azure Synapse Analytics has 60 nodes per distribution, the minimum recommended number of rows for a clustered columnstore index is 60,000,000. \"\n\nwhy is it that the don\u00b4t close it to just 1million? also, why is this the exact same limit of rows on excel?\n\nIs there someting I'm missing about this number?", "author_fullname": "t2_38po62bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why 1,048,576 rows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18id3ea", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702573133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was looking into Azure documentation for clustered columnstore indexes and I noticed the following:&lt;br/&gt;\n&amp;quot; Clustered columnstore indexes work on segments of 1,048,576 rows. As Azure Synapse Analytics has 60 nodes per distribution, the minimum recommended number of rows for a clustered columnstore index is 60,000,000. &amp;quot;&lt;/p&gt;\n\n&lt;p&gt;why is it that the don\u00b4t close it to just 1million? also, why is this the exact same limit of rows on excel?&lt;/p&gt;\n\n&lt;p&gt;Is there someting I&amp;#39;m missing about this number?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18id3ea", "is_robot_indexable": true, "report_reasons": null, "author": "Esteban_Rdz", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18id3ea/why_1048576_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18id3ea/why_1048576_rows/", "subreddit_subscribers": 146052, "created_utc": 1702573133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Heres an architectural journey that I experienced on working with a data product on AWS Serverless architecture then  to migrate it back to servers using celery and Kubernetes and creating an entire orchestration workflow that would give  more control in architecture, feature developments, cost reductions and turn around time reductions. What we ended up was with creating our own AWS lambda and stepfunctions and avoid vendor lockins\n\n[https://medium.com/@rajani.param1/back-to-the-future-the-future-might-not-just-be-serverless-after-all-b8165d6e84c2](https://medium.com/@rajani.param1/back-to-the-future-the-future-might-not-just-be-serverless-after-all-b8165d6e84c2)\n\n  \nFeel free to share down your thoughts and opinions on this .  \n", "author_fullname": "t2_5fi8z4gf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To Serverless or not to Serverless that is the question..?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18icwuf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702577435.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702572640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heres an architectural journey that I experienced on working with a data product on AWS Serverless architecture then  to migrate it back to servers using celery and Kubernetes and creating an entire orchestration workflow that would give  more control in architecture, feature developments, cost reductions and turn around time reductions. What we ended up was with creating our own AWS lambda and stepfunctions and avoid vendor lockins&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@rajani.param1/back-to-the-future-the-future-might-not-just-be-serverless-after-all-b8165d6e84c2\"&gt;https://medium.com/@rajani.param1/back-to-the-future-the-future-might-not-just-be-serverless-after-all-b8165d6e84c2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Feel free to share down your thoughts and opinions on this .  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?auto=webp&amp;s=67d661201a964c66dc3ea00e4111958c4811fe64", "width": 1012, "height": 969}, "resolutions": [{"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=961c02fbc890e97e99c12d9c30e2f3de2d710276", "width": 108, "height": 103}, {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb182e35d0e3cc78a4e456b2f3410fd275f7ade3", "width": 216, "height": 206}, {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7c0cbb4a8db6a2a5468b4d2ef7efe2e5d3a21de4", "width": 320, "height": 306}, {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=83b51bc6a41e93746a01b5f547914ad8d1726684", "width": 640, "height": 612}, {"url": "https://external-preview.redd.it/NgGer2EJ-QrPfxGEhcsFKF5-gy4CdGbR9hNIesltjEc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=58a3a85dd698d423e21144f798dbb70c58014e9e", "width": 960, "height": 919}], "variants": {}, "id": "mVLxJRsuAEGjFpeAi_DoJiW5UQVt-Y4U2Q6WWdTEZwg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18icwuf", "is_robot_indexable": true, "report_reasons": null, "author": "Drphysics5", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18icwuf/to_serverless_or_not_to_serverless_that_is_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18icwuf/to_serverless_or_not_to_serverless_that_is_the/", "subreddit_subscribers": 146052, "created_utc": 1702572640.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our org (~ 7000 employees) is looking to get into DataBricks. Management has expressed their belief that a dedicated application admin position should not be necessary since DataBricks handles all the infrastructure for you.\n\nI\u2019m of the belief a mission critical system should have an owner to handle troubleshooting, permissioning, policy rules, etc, and that making it an analyst\u2019s part time job is asking for trouble.\n\nThoughts? Data is probably in the 10 tb range but with a desire to grow into high volume streaming use cases.", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks admin?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18idt4y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702575002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our org (~ 7000 employees) is looking to get into DataBricks. Management has expressed their belief that a dedicated application admin position should not be necessary since DataBricks handles all the infrastructure for you.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m of the belief a mission critical system should have an owner to handle troubleshooting, permissioning, policy rules, etc, and that making it an analyst\u2019s part time job is asking for trouble.&lt;/p&gt;\n\n&lt;p&gt;Thoughts? Data is probably in the 10 tb range but with a desire to grow into high volume streaming use cases.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18idt4y", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18idt4y/databricks_admin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18idt4y/databricks_admin/", "subreddit_subscribers": 146052, "created_utc": 1702575002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A collection of videos shared by Netflix from their [Data Engineering Summit](https://netflixtechblog.com/our-first-netflix-data-engineering-summit-f326b0589102)\n\n* [The Netflix Data Engineering Stack](https://youtu.be/QxaOlmv79ls)\n* [Data Processing Patterns](https://www.youtube.com/watch?v=vuyjK2TFZNk&amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;index=3)\n* [Streaming SQL on Data Mesh using Apache Flink](https://www.youtube.com/watch?v=TwcWvwU7B64&amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;index=4)\n* [Building Reliable Data Pipelines](https://www.youtube.com/watch?v=uWmJxbhI304&amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;index=5)\n* [Knowledge Management \u2014 Leveraging Institutional Data](https://www.youtube.com/watch?v=F4N8AmScZ-w&amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;index=6)\n* [Psyberg, An Incremental ETL Framework Using Iceberg](https://www.youtube.com/watch?v=jRckeOedtx0&amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;index=8)\n* [Start/Stop/Continue for optimizing complex ETL jobs](https://www.youtube.com/watch?v=Dr8LMn-nJGc&amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;index=9)\n* [Media Data for ML Studio Creative Production](https://youtu.be/1gGi3NBZk7M)", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Netflix does Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18ix6hd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702636326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A collection of videos shared by Netflix from their &lt;a href=\"https://netflixtechblog.com/our-first-netflix-data-engineering-summit-f326b0589102\"&gt;Data Engineering Summit&lt;/a&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://youtu.be/QxaOlmv79ls\"&gt;The Netflix Data Engineering Stack&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=vuyjK2TFZNk&amp;amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;amp;index=3\"&gt;Data Processing Patterns&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=TwcWvwU7B64&amp;amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;amp;index=4\"&gt;Streaming SQL on Data Mesh using Apache Flink&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=uWmJxbhI304&amp;amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;amp;index=5\"&gt;Building Reliable Data Pipelines&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=F4N8AmScZ-w&amp;amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;amp;index=6\"&gt;Knowledge Management \u2014 Leveraging Institutional Data&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=jRckeOedtx0&amp;amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;amp;index=8\"&gt;Psyberg, An Incremental ETL Framework Using Iceberg&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=Dr8LMn-nJGc&amp;amp;list=PLSECvWLlUYeF06QK5FOOELvgKdap3cQf0&amp;amp;index=9\"&gt;Start/Stop/Continue for optimizing complex ETL jobs&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://youtu.be/1gGi3NBZk7M\"&gt;Media Data for ML Studio Creative Production&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?auto=webp&amp;s=5c559c3b17160025d56491777d567987248931ef", "width": 1111, "height": 571}, "resolutions": [{"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da24254e4bb038691cfdd4c156a5d5244c08c4bf", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=052f735a1ffa64a0e1d6d51c639439521a6f2004", "width": 216, "height": 111}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d0fc2cebd67c1385fae0b1324dc39348b3217f8", "width": 320, "height": 164}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc32a3e086f0217c8aa2eab757773f562dea42d3", "width": 640, "height": 328}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=756a90ecc71cbca89abb9212b906435a9bd267bd", "width": 960, "height": 493}, {"url": "https://external-preview.redd.it/W5u6SrlwaxjlbNE6tqal8ItkeMrk5nRA-wIEcfOuEwY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b00bb639fe14e1acfb87b0939a9785a7a7e3c46", "width": 1080, "height": 555}], "variants": {}, "id": "TMo7-NZlAEt-Oth2MSgWHW_-6WCPBJ0hDscjjgNPtxU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ix6hd", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ix6hd/how_netflix_does_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ix6hd/how_netflix_does_data_engineering/", "subreddit_subscribers": 146052, "created_utc": 1702636326.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, looking for some advice on my situation. \n\nI have been at my company for 1.5 yrs, having joined in a rotational program where there were 2 rotations, 6 months long each and this is my 3rd team now, doing data engineering(?) work for the first time. In one of my roles during the rotational program, I did primarily data analyst stuff but it was a bs role because I had only 1 project my entire time on the team and that was to create a basic tableau and power bi dashboard. That\u2019s literally it. \n\nI am not entirely sure if I am even a data engineer proper on this team now, because I am mostly doing analyst work and basic level sql queries. I haven\u2019t touched Python or done any ETL work. \n\nRecently, I was having a check in with my manager and he was expressing discontent about how I\u2019m not able to do my work independently yet and haven\u2019t been staying up to date with all updates coming through via email and teams chats. I completely get where he is coming from and I too am frustrated that I can\u2019t really work independently and he gave me some tips but they weren\u2019t really helpful, just the same old \u201clook at the documentation\u201d but the documentation isn\u2019t that much clearer either.\n\nHowever, on the other side, I feel like there wasn\u2019t really any chance to learn when I joined this team and was kind of thrown into this work without any relevant experience and structured trainings. His excuse for this is \u201ceveryone is learning\u201d and that this is new territory for everyone, but if that is the case, I feel like me not being at the same level as my colleagues in working independently should be okay because I\u2019ve never done this type of work before and it isn\u2019t like I\u2019m not trying, because I really am. \n\nIn addition, it can be hard to keep track of all the messages, emails, etc because there is so much back and forth and I get pulled into long meetings, leaving little time for me to do my work. I am still learning how to task switch especially because my previous teams were never this crazy busy. He also said in my check in that things will only get more busy from here onward into the new year. I am really feeling down on myself because I thought I was doing well despite the circumstances, but this was a ding on my confidence in myself. \n\nI am not sure if I can stay on this team long term if this is how things will be with the project ramping up in 2024. \n\nHas anyone else had this experience? Any advice? Should I just find a new role? I don\u2019t want to quit because things are getting hard but I also feel like this isn\u2019t an environment for learning and the longer I stay on this team doing lower level analyst work, the more I am putting myself behind in the data field and doing actual relevant work.", "author_fullname": "t2_tna1k085", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feel like I still don\u2019t know what I\u2019m doing 6 months into my role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ioz9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702605589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, looking for some advice on my situation. &lt;/p&gt;\n\n&lt;p&gt;I have been at my company for 1.5 yrs, having joined in a rotational program where there were 2 rotations, 6 months long each and this is my 3rd team now, doing data engineering(?) work for the first time. In one of my roles during the rotational program, I did primarily data analyst stuff but it was a bs role because I had only 1 project my entire time on the team and that was to create a basic tableau and power bi dashboard. That\u2019s literally it. &lt;/p&gt;\n\n&lt;p&gt;I am not entirely sure if I am even a data engineer proper on this team now, because I am mostly doing analyst work and basic level sql queries. I haven\u2019t touched Python or done any ETL work. &lt;/p&gt;\n\n&lt;p&gt;Recently, I was having a check in with my manager and he was expressing discontent about how I\u2019m not able to do my work independently yet and haven\u2019t been staying up to date with all updates coming through via email and teams chats. I completely get where he is coming from and I too am frustrated that I can\u2019t really work independently and he gave me some tips but they weren\u2019t really helpful, just the same old \u201clook at the documentation\u201d but the documentation isn\u2019t that much clearer either.&lt;/p&gt;\n\n&lt;p&gt;However, on the other side, I feel like there wasn\u2019t really any chance to learn when I joined this team and was kind of thrown into this work without any relevant experience and structured trainings. His excuse for this is \u201ceveryone is learning\u201d and that this is new territory for everyone, but if that is the case, I feel like me not being at the same level as my colleagues in working independently should be okay because I\u2019ve never done this type of work before and it isn\u2019t like I\u2019m not trying, because I really am. &lt;/p&gt;\n\n&lt;p&gt;In addition, it can be hard to keep track of all the messages, emails, etc because there is so much back and forth and I get pulled into long meetings, leaving little time for me to do my work. I am still learning how to task switch especially because my previous teams were never this crazy busy. He also said in my check in that things will only get more busy from here onward into the new year. I am really feeling down on myself because I thought I was doing well despite the circumstances, but this was a ding on my confidence in myself. &lt;/p&gt;\n\n&lt;p&gt;I am not sure if I can stay on this team long term if this is how things will be with the project ramping up in 2024. &lt;/p&gt;\n\n&lt;p&gt;Has anyone else had this experience? Any advice? Should I just find a new role? I don\u2019t want to quit because things are getting hard but I also feel like this isn\u2019t an environment for learning and the longer I stay on this team doing lower level analyst work, the more I am putting myself behind in the data field and doing actual relevant work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ioz9p", "is_robot_indexable": true, "report_reasons": null, "author": "miserablywinning", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ioz9p/feel_like_i_still_dont_know_what_im_doing_6/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ioz9p/feel_like_i_still_dont_know_what_im_doing_6/", "subreddit_subscribers": 146052, "created_utc": 1702605589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We\u2019ve been trying to solve for this problem for a couple of years now. Trying to make a generic platform/product for data quality that would work for multiple data personas within the company. We knew this was going to be a hard one to solve.. and we\u2019re yet to hit that breakthrough. Curious to know what other data folks are doing and how they are solving for data quality.", "author_fullname": "t2_h5ll08of", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iqbbp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702609777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We\u2019ve been trying to solve for this problem for a couple of years now. Trying to make a generic platform/product for data quality that would work for multiple data personas within the company. We knew this was going to be a hard one to solve.. and we\u2019re yet to hit that breakthrough. Curious to know what other data folks are doing and how they are solving for data quality.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18iqbbp", "is_robot_indexable": true, "report_reasons": null, "author": "Lucky-Front7675", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18iqbbp/data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18iqbbp/data_quality/", "subreddit_subscribers": 146052, "created_utc": 1702609777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am an owner of a small retail business who is teaching myself DE/BI concepts via Coursera, ChatGPT, YouTube, podcasts, etc. Our business sells fairly niche goods online and also has a small consignment-based popup inside another retail business. Both my business and our pop-up host each use our own Shopify accounts for sales/inventory/product tracking. \n\nMy business goal is to have a single source of truth for product sales, by aggregating both Shopify accounts sales and product records into a database of my own. Currently, doing any sort of meaningful analysis involves manually exporting a csv from each store and joining the data in spreadsheets (or SQL if I\u2019m feeling saucy and the data is bigger than sheets can take.)\n\nTrying to solve for this has led me to DE-related online courses, which are really interesting and getting me feeling closer to a solution. I had an initial, fleeting success making a PostgreSQL database through [Render.com](https://Render.com) and setting up pipelines in [Make.com](https://Make.com) to catch incoming sales from both Shopify accounts, and load them into a \u2018master\\_sales\u2019 table, that I could then query to answer questions about our total product sales over varying time periods. This ended up becoming a mess, though, after a couple of failed pipeline executions, and numerous missing records and duplicate records. So, I went back to the drawing board. Currently, I've now got a bash script that can query Shopify REST API. I've also got some good grounding in Pandas for data transformation. Overall, I want to get to the point where I have some checks in place. \n\nI\u2019d love to hear from more experienced people in this field about what sort of approach you might apply to this problem. None of the data is that big (yet, right now accumulating about +100MB/month), nor does it need to be updated more frequently than daily (at best). I\u2019m looking at options such as setting up a dedicated linux server at home running cron jobs, or digging into AWS/Azure (because cloud computing is super interesting). How would you approach this business problem?\n\nSince starting this business, I\u2019ve definitely unlocked a part of myself that is continually excited about solving the computer-technical/data/systems design opportunities that might improve my day-to-day experience operating things. I've always been into computers as a hobby, but never for work. My work experience is in bartending and retail.\n\nAlso, I have another question: My small business is very small, and can't pay me that well. I really love all these things I\u2019m learning and data-oriented jobs pay alot better than I'm currently doing. Given that I don\u2019t have any tech industry experience, how might one approach a career change, from service industry and small retail business ownership, into Data Engineering? I\u2019m really happy that I have potential projects on my plate to help me study, as well as add potential fodder to a portfolio. I feel like if a career change is in the books, I should maybe aim for a Junior IT/Data Analytics position as an entry point and try to advance from there? Does anyone have a similar transition experience? ", "author_fullname": "t2_miufv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Small business owner, new to, and interested in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18itcsw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702620192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an owner of a small retail business who is teaching myself DE/BI concepts via Coursera, ChatGPT, YouTube, podcasts, etc. Our business sells fairly niche goods online and also has a small consignment-based popup inside another retail business. Both my business and our pop-up host each use our own Shopify accounts for sales/inventory/product tracking. &lt;/p&gt;\n\n&lt;p&gt;My business goal is to have a single source of truth for product sales, by aggregating both Shopify accounts sales and product records into a database of my own. Currently, doing any sort of meaningful analysis involves manually exporting a csv from each store and joining the data in spreadsheets (or SQL if I\u2019m feeling saucy and the data is bigger than sheets can take.)&lt;/p&gt;\n\n&lt;p&gt;Trying to solve for this has led me to DE-related online courses, which are really interesting and getting me feeling closer to a solution. I had an initial, fleeting success making a PostgreSQL database through &lt;a href=\"https://Render.com\"&gt;Render.com&lt;/a&gt; and setting up pipelines in &lt;a href=\"https://Make.com\"&gt;Make.com&lt;/a&gt; to catch incoming sales from both Shopify accounts, and load them into a \u2018master_sales\u2019 table, that I could then query to answer questions about our total product sales over varying time periods. This ended up becoming a mess, though, after a couple of failed pipeline executions, and numerous missing records and duplicate records. So, I went back to the drawing board. Currently, I&amp;#39;ve now got a bash script that can query Shopify REST API. I&amp;#39;ve also got some good grounding in Pandas for data transformation. Overall, I want to get to the point where I have some checks in place. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d love to hear from more experienced people in this field about what sort of approach you might apply to this problem. None of the data is that big (yet, right now accumulating about +100MB/month), nor does it need to be updated more frequently than daily (at best). I\u2019m looking at options such as setting up a dedicated linux server at home running cron jobs, or digging into AWS/Azure (because cloud computing is super interesting). How would you approach this business problem?&lt;/p&gt;\n\n&lt;p&gt;Since starting this business, I\u2019ve definitely unlocked a part of myself that is continually excited about solving the computer-technical/data/systems design opportunities that might improve my day-to-day experience operating things. I&amp;#39;ve always been into computers as a hobby, but never for work. My work experience is in bartending and retail.&lt;/p&gt;\n\n&lt;p&gt;Also, I have another question: My small business is very small, and can&amp;#39;t pay me that well. I really love all these things I\u2019m learning and data-oriented jobs pay alot better than I&amp;#39;m currently doing. Given that I don\u2019t have any tech industry experience, how might one approach a career change, from service industry and small retail business ownership, into Data Engineering? I\u2019m really happy that I have potential projects on my plate to help me study, as well as add potential fodder to a portfolio. I feel like if a career change is in the books, I should maybe aim for a Junior IT/Data Analytics position as an entry point and try to advance from there? Does anyone have a similar transition experience? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cDDyYwDVuCLRWiYzJf9UerbDnkKv5uUTV46K5o5NMjM.jpg?auto=webp&amp;s=afa45699d6fb3f760fb20e2d9d6f44228063d633", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/cDDyYwDVuCLRWiYzJf9UerbDnkKv5uUTV46K5o5NMjM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0488541fa0dd55375440acdececcdee031a940d5", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cDDyYwDVuCLRWiYzJf9UerbDnkKv5uUTV46K5o5NMjM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba3bfd8369fa2c98c582333a477292123d7ffdb8", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/cDDyYwDVuCLRWiYzJf9UerbDnkKv5uUTV46K5o5NMjM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad745860ee3dc44a3840afefd8869e8efd01055c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/cDDyYwDVuCLRWiYzJf9UerbDnkKv5uUTV46K5o5NMjM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5fe4ec78918e70f6bbec642e50841b7e4c7f4ad1", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/cDDyYwDVuCLRWiYzJf9UerbDnkKv5uUTV46K5o5NMjM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=16765ff17f5a2f4e8135f14db9cb079337aa67fb", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/cDDyYwDVuCLRWiYzJf9UerbDnkKv5uUTV46K5o5NMjM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0991e51843b0a32b2501554aa0168f72ea7e8116", "width": 1080, "height": 607}], "variants": {}, "id": "w1lzwcy17wjJvdZBaFtVGF670_Y4Sib7sWLEw0rNHKc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18itcsw", "is_robot_indexable": true, "report_reasons": null, "author": "dondelamort", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18itcsw/small_business_owner_new_to_and_interested_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18itcsw/small_business_owner_new_to_and_interested_in/", "subreddit_subscribers": 146052, "created_utc": 1702620192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_pxof4neu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing LaunchFlow: The Developer Platform Built for Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ie2zo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1702575712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "launchflow.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.launchflow.com/blog/introducing-launchflow", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ie2zo", "is_robot_indexable": true, "report_reasons": null, "author": "josh_flow", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ie2zo/introducing_launchflow_the_developer_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.launchflow.com/blog/introducing-launchflow", "subreddit_subscribers": 146052, "created_utc": 1702575712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fj8n8tp3j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Database Engines use Functional Dependency Analysis to Improve Join Performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_18ih5ww", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ROhIT7U9rbH6v9fxxr0BjA8yGwUvHK83afHPMnkHcMQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702583902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dolthub.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dolthub.com/blog/2023-12-13-functional-dependency-analysis/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?auto=webp&amp;s=399f65a130fe7e276dcf2f712ab6c84acaefd398", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ac95291e9bfb7eaa406f2ed4b8db927aa863b6e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3bdab7fa719123ca2fdd9b7bd5358504b0375cb9", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5abf32a74a7c9b106a3f8356c095900cceb64406", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e03f01c2a5f37cac07548ca5fc2c1003396eb99", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a289f58fc92cb2f6ca74962bef71ee39d1a7adb0", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/43U8RAV7umjnXMZG0cLdxdRUI3nPqYqJ1jvZnT6AgG8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=21bc571e2e3faa66af1e41315b3c9ebac4fb0473", "width": 1080, "height": 564}], "variants": {}, "id": "GVDVzKAiIGM2SDFASEWM2e-sTg22Qu_GDhOd_tP5EmU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ih5ww", "is_robot_indexable": true, "report_reasons": null, "author": "nick_at_dolt", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ih5ww/how_database_engines_use_functional_dependency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dolthub.com/blog/2023-12-13-functional-dependency-analysis/", "subreddit_subscribers": 146052, "created_utc": 1702583902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI have always been wondering if luster based frameworks like Spark and Flink would make sense for stateless streaming application that also don't needny multi row aggregation (group by, avgs, sums, etc). I mean cases where all we need is to work record by record without needing to aggregate them nor to hold state.\n\nIf, for example, the deployment is done in a k8s cluster, we can write \"standard\" code and scale horizontally to handle more records (parallelism) also eventually opening threads for get more performance (concurrency).\n\nWould that be more perfomant and easy to deploy for such a case, since we avoid the cost of abstraction where we don't need it?\n\nI think that in other words I'm asking what is the purpose of Spark streaming and Flink when records/rows don't have to be aware of each other...\n\n  \nTwo use cases I'm think about is consuming from a Kafka topic and reading new files from S3 where the logic is row-by-row/file-by-file as stated. \n\nAppreciate opinions.\n\nThanks.", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any reason to use Spark or Flink for stateless non aggregative streaming application?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ihmuo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702585389.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702585146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have always been wondering if luster based frameworks like Spark and Flink would make sense for stateless streaming application that also don&amp;#39;t needny multi row aggregation (group by, avgs, sums, etc). I mean cases where all we need is to work record by record without needing to aggregate them nor to hold state.&lt;/p&gt;\n\n&lt;p&gt;If, for example, the deployment is done in a k8s cluster, we can write &amp;quot;standard&amp;quot; code and scale horizontally to handle more records (parallelism) also eventually opening threads for get more performance (concurrency).&lt;/p&gt;\n\n&lt;p&gt;Would that be more perfomant and easy to deploy for such a case, since we avoid the cost of abstraction where we don&amp;#39;t need it?&lt;/p&gt;\n\n&lt;p&gt;I think that in other words I&amp;#39;m asking what is the purpose of Spark streaming and Flink when records/rows don&amp;#39;t have to be aware of each other...&lt;/p&gt;\n\n&lt;p&gt;Two use cases I&amp;#39;m think about is consuming from a Kafka topic and reading new files from S3 where the logic is row-by-row/file-by-file as stated. &lt;/p&gt;\n\n&lt;p&gt;Appreciate opinions.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18ihmuo", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ihmuo/is_there_any_reason_to_use_spark_or_flink_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ihmuo/is_there_any_reason_to_use_spark_or_flink_for/", "subreddit_subscribers": 146052, "created_utc": 1702585146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I\u2019m in over my head at a startup and have to lead the construction of analytics infrastructure that will support customer-facing embedded dashboards along with downloadable reports. \n\nThe volume of data we\u2019re dealing with is nothing crazy, probably gonna be around 20TB. And we aim to support around 5000+ users (though starting much smaller) who will regularly view a few embedded dashboards and also download reports somewhat regularly. The dashboards will need some basic drill-down and date range picking. The data is standard aggregated data that is well-suited for a DWH.\n\nOne of my main questions though is if there are special considerations when the use case is for customer-facing analytics? Will this many users interacting with Snowflake kill us with costs? We are thinking of powering the dashboards/reports with QuickSight or similar. And from the little I know so far, there is some caching that will help reduce the query load on Snowflake. Will that be sufficient?\n\nIs there a better store for aggregated relational data that\u2019s used for customer-facing analytics? Will we survive with Snowflake?\n\nHow do we handle Snowflake users for this? Do we have to provision a user for each customer? I know nothing about it.\n\nWe\u2019re entirely in AWS. I\u2019m thinking we will use DMS CDC to S3 and then 24 hour batch copy the data to Snowflake. Don\u2019t know the best tool for scheduled batch copy, any recommendations? All I know is maybe I could use Airflow or just a simple cron job. From there I will use DBT to populate a handful of star schemas that I would connect to QuickSight or similar. \n\nI would honestly be very grateful for any wisdom on any part of this setup because I\u2019m largely on my own right now to figure this out and get it built.", "author_fullname": "t2_ijoifzps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake for customer-facing analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18is4a1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702616862.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702615758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I\u2019m in over my head at a startup and have to lead the construction of analytics infrastructure that will support customer-facing embedded dashboards along with downloadable reports. &lt;/p&gt;\n\n&lt;p&gt;The volume of data we\u2019re dealing with is nothing crazy, probably gonna be around 20TB. And we aim to support around 5000+ users (though starting much smaller) who will regularly view a few embedded dashboards and also download reports somewhat regularly. The dashboards will need some basic drill-down and date range picking. The data is standard aggregated data that is well-suited for a DWH.&lt;/p&gt;\n\n&lt;p&gt;One of my main questions though is if there are special considerations when the use case is for customer-facing analytics? Will this many users interacting with Snowflake kill us with costs? We are thinking of powering the dashboards/reports with QuickSight or similar. And from the little I know so far, there is some caching that will help reduce the query load on Snowflake. Will that be sufficient?&lt;/p&gt;\n\n&lt;p&gt;Is there a better store for aggregated relational data that\u2019s used for customer-facing analytics? Will we survive with Snowflake?&lt;/p&gt;\n\n&lt;p&gt;How do we handle Snowflake users for this? Do we have to provision a user for each customer? I know nothing about it.&lt;/p&gt;\n\n&lt;p&gt;We\u2019re entirely in AWS. I\u2019m thinking we will use DMS CDC to S3 and then 24 hour batch copy the data to Snowflake. Don\u2019t know the best tool for scheduled batch copy, any recommendations? All I know is maybe I could use Airflow or just a simple cron job. From there I will use DBT to populate a handful of star schemas that I would connect to QuickSight or similar. &lt;/p&gt;\n\n&lt;p&gt;I would honestly be very grateful for any wisdom on any part of this setup because I\u2019m largely on my own right now to figure this out and get it built.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18is4a1", "is_robot_indexable": true, "report_reasons": null, "author": "DataDude999", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18is4a1/snowflake_for_customerfacing_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18is4a1/snowflake_for_customerfacing_analytics/", "subreddit_subscribers": 146052, "created_utc": 1702615758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI'm responsible for building out a financial reporting system at my company and I could use some advice on my approach.\n\n**A little background:** We offer coaching courses that will be split amongst various systems, but all purchased through deals with customers (companies), which are converted to credits and consumed through an atomic product model. We are in the process of transitioning to a credit system, so we will need to convert our existing deals into credits for the future system (deferred credits).\n\nEssentially I need to tie in various data sources to build a table to track at a deal level the amount of credits that have been assigned, unassigned and consumed. One of the challenges is that credit values can vary by deal and therefore need to be tracked at a deal level. Also, they need to burn down to 0 by oldest deal, first in first out. This might add a bit of annoyance dealing with remainders.\n\nHeres an example of roughly what im envisioning:\n\n|Company ID|deal id|trans dt|scheduled dt|completed dt|credit category|$ per credit|\\# of Credits|product|Product Cost|Credits Remaining|\n|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|\n|13|2|2/23/24|||unassigned|20|1000|A|300|1000|\n|13|2|2/23/24|3/01/24||assigned|20|1000|B|400|1000|\n|13|1|1/15/24|1/23/24|1/23/24|consumed|17.50|1500|B|400|1100|\n|13|1|1/15/24|||unassigned|17.50|1500|A|300|1100|\n|13|999|1/1/24|||deferred|23|3000|||0|\n\n&amp;#x200B;\n\nIts unclear to me what the best approach is for working through the many transformations involved here. I could build out a bunch of additional fields and apply calculations to the table at various stages of my pipeline with SQL, but im wondering if theres a more elegant solution through breaking it out into various tables and processes, using python or recursive functions etc.\n\nOne last caveat is that ideally this system will be able to track rate of spend of customers, which Id imagine would most simply be tracked through snapshot tables.\n\nSorry this was a lot, but any help is greatly appreciated!", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Financial Reporting Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ip1ya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702612993.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702605806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m responsible for building out a financial reporting system at my company and I could use some advice on my approach.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;A little background:&lt;/strong&gt; We offer coaching courses that will be split amongst various systems, but all purchased through deals with customers (companies), which are converted to credits and consumed through an atomic product model. We are in the process of transitioning to a credit system, so we will need to convert our existing deals into credits for the future system (deferred credits).&lt;/p&gt;\n\n&lt;p&gt;Essentially I need to tie in various data sources to build a table to track at a deal level the amount of credits that have been assigned, unassigned and consumed. One of the challenges is that credit values can vary by deal and therefore need to be tracked at a deal level. Also, they need to burn down to 0 by oldest deal, first in first out. This might add a bit of annoyance dealing with remainders.&lt;/p&gt;\n\n&lt;p&gt;Heres an example of roughly what im envisioning:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Company ID&lt;/th&gt;\n&lt;th align=\"left\"&gt;deal id&lt;/th&gt;\n&lt;th align=\"left\"&gt;trans dt&lt;/th&gt;\n&lt;th align=\"left\"&gt;scheduled dt&lt;/th&gt;\n&lt;th align=\"left\"&gt;completed dt&lt;/th&gt;\n&lt;th align=\"left\"&gt;credit category&lt;/th&gt;\n&lt;th align=\"left\"&gt;$ per credit&lt;/th&gt;\n&lt;th align=\"left\"&gt;# of Credits&lt;/th&gt;\n&lt;th align=\"left\"&gt;product&lt;/th&gt;\n&lt;th align=\"left\"&gt;Product Cost&lt;/th&gt;\n&lt;th align=\"left\"&gt;Credits Remaining&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;2/23/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;unassigned&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;td align=\"left\"&gt;A&lt;/td&gt;\n&lt;td align=\"left\"&gt;300&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;2/23/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;3/01/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;assigned&lt;/td&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;td align=\"left\"&gt;B&lt;/td&gt;\n&lt;td align=\"left\"&gt;400&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/15/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/23/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/23/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;consumed&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.50&lt;/td&gt;\n&lt;td align=\"left\"&gt;1500&lt;/td&gt;\n&lt;td align=\"left\"&gt;B&lt;/td&gt;\n&lt;td align=\"left\"&gt;400&lt;/td&gt;\n&lt;td align=\"left\"&gt;1100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/15/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;unassigned&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.50&lt;/td&gt;\n&lt;td align=\"left\"&gt;1500&lt;/td&gt;\n&lt;td align=\"left\"&gt;A&lt;/td&gt;\n&lt;td align=\"left\"&gt;300&lt;/td&gt;\n&lt;td align=\"left\"&gt;1100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;13&lt;/td&gt;\n&lt;td align=\"left\"&gt;999&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/1/24&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;deferred&lt;/td&gt;\n&lt;td align=\"left\"&gt;23&lt;/td&gt;\n&lt;td align=\"left\"&gt;3000&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Its unclear to me what the best approach is for working through the many transformations involved here. I could build out a bunch of additional fields and apply calculations to the table at various stages of my pipeline with SQL, but im wondering if theres a more elegant solution through breaking it out into various tables and processes, using python or recursive functions etc.&lt;/p&gt;\n\n&lt;p&gt;One last caveat is that ideally this system will be able to track rate of spend of customers, which Id imagine would most simply be tracked through snapshot tables.&lt;/p&gt;\n\n&lt;p&gt;Sorry this was a lot, but any help is greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ip1ya", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ip1ya/financial_reporting_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ip1ya/financial_reporting_problem/", "subreddit_subscribers": 146052, "created_utc": 1702605806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm starting a new job soon in which I'll be migrating the current data set up to Databricks. The Databricks instance will be created when I join the company.\n\nWhat should I be thinking about/researching prior to this?\n\nE.g. Data modelling, s3 bucket naming conventions, etc.", "author_fullname": "t2_17e8p1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to plan before migrating to Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i84pw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702558883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m starting a new job soon in which I&amp;#39;ll be migrating the current data set up to Databricks. The Databricks instance will be created when I join the company.&lt;/p&gt;\n\n&lt;p&gt;What should I be thinking about/researching prior to this?&lt;/p&gt;\n\n&lt;p&gt;E.g. Data modelling, s3 bucket naming conventions, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18i84pw", "is_robot_indexable": true, "report_reasons": null, "author": "RatBapple", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i84pw/what_to_plan_before_migrating_to_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i84pw/what_to_plan_before_migrating_to_databricks/", "subreddit_subscribers": 146052, "created_utc": 1702558883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\ndlt founder here. one of the dlt users offers a code template and details about how to do event ingestion on the cheap on AWS. In this case he loads it to snowflake.\n\nThe setup Simon describes (code included) costs under 10 usd/1m events, which is 2 orders of magnitude cheaper than some popular SaaS tools.\n\nThere is a code template included. The advantage of using dlt here is that it can process any types of events and with schemas and data contracts we can also control the quality of the data ingested.\n\n[https://dlthub.com/docs/blog/dlt-aws-taktile-blog](https://dlthub.com/docs/blog/dlt-aws-taktile-blog)\n\nIf you are interested to see similar setups, please let me know what you are interested in. We are working on doing the same setup on GCP for ourselves.\n\nIf you want to try it with [data contracts](https://dlthub.com/devel/general-usage/schema-contracts), they are in early release available on devel branch, we are adding bad event sinks and merging them to prod this year.", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event ingestion with AWS lambda and dlt - a case study and code template", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18ix7xx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702636501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;dlt founder here. one of the dlt users offers a code template and details about how to do event ingestion on the cheap on AWS. In this case he loads it to snowflake.&lt;/p&gt;\n\n&lt;p&gt;The setup Simon describes (code included) costs under 10 usd/1m events, which is 2 orders of magnitude cheaper than some popular SaaS tools.&lt;/p&gt;\n\n&lt;p&gt;There is a code template included. The advantage of using dlt here is that it can process any types of events and with schemas and data contracts we can also control the quality of the data ingested.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dlthub.com/docs/blog/dlt-aws-taktile-blog\"&gt;https://dlthub.com/docs/blog/dlt-aws-taktile-blog&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you are interested to see similar setups, please let me know what you are interested in. We are working on doing the same setup on GCP for ourselves.&lt;/p&gt;\n\n&lt;p&gt;If you want to try it with &lt;a href=\"https://dlthub.com/devel/general-usage/schema-contracts\"&gt;data contracts&lt;/a&gt;, they are in early release available on devel branch, we are adding bad event sinks and merging them to prod this year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/N7zat4bST2M6S3HtnPLNjlP4_cRLAh9RdbLGr96Ek-I.jpg?auto=webp&amp;s=a05aa56b4257c1c7f5d1d1ca57689d52084ffa8b", "width": 4032, "height": 2268}, "resolutions": [{"url": "https://external-preview.redd.it/N7zat4bST2M6S3HtnPLNjlP4_cRLAh9RdbLGr96Ek-I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=914049f9e98130b163c4064aa552d154bb7312cc", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/N7zat4bST2M6S3HtnPLNjlP4_cRLAh9RdbLGr96Ek-I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1a824fa9f8f01c716863222da0b9aa3b15696b6d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/N7zat4bST2M6S3HtnPLNjlP4_cRLAh9RdbLGr96Ek-I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f268828bc2c5d6bf61569794231b6dbd40829e7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/N7zat4bST2M6S3HtnPLNjlP4_cRLAh9RdbLGr96Ek-I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fbfe2e0052a20b7b1a62cba4399deca3b61d2e3f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/N7zat4bST2M6S3HtnPLNjlP4_cRLAh9RdbLGr96Ek-I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cad4e1ebea2d81f5191f46bb9f3bbe122788888", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/N7zat4bST2M6S3HtnPLNjlP4_cRLAh9RdbLGr96Ek-I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=73ae6152911933676ecd83dd3364bc30b23093b8", "width": 1080, "height": 607}], "variants": {}, "id": "EPFgYwOLokSnjFQOr12db2YaP5RfXFTu7-zIA1it1LA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "18ix7xx", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ix7xx/event_ingestion_with_aws_lambda_and_dlt_a_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ix7xx/event_ingestion_with_aws_lambda_and_dlt_a_case/", "subreddit_subscribers": 146052, "created_utc": 1702636501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I was previously working on support role for data engineering project . Did some basic debugging . Also migrated some mapping from informatica to databricks using pyspark ,have basic understanding for Hadoop , hive , adf \nBut I want in depth knowledge so I can solve problems . What all should I have knowledge on , any courses that might help??", "author_fullname": "t2_or716h6bv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In depth knowledge of data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ivobt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702629759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I was previously working on support role for data engineering project . Did some basic debugging . Also migrated some mapping from informatica to databricks using pyspark ,have basic understanding for Hadoop , hive , adf \nBut I want in depth knowledge so I can solve problems . What all should I have knowledge on , any courses that might help??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ivobt", "is_robot_indexable": true, "report_reasons": null, "author": "Fit_Ad_3129", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ivobt/in_depth_knowledge_of_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ivobt/in_depth_knowledge_of_data_engineering/", "subreddit_subscribers": 146052, "created_utc": 1702629759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# Hello Data Engineers!\n\nI have a requirement to stream data from **Aurora Postgres RDS** to **Redshift** using AWS services. Currently, my approach involves creating a **DMS** (Database Migration Service) task to migrate data to Kinesis, and then pulling data from **Kinesis** to Redshift by creating an external schema. I'm wondering if there are alternative methods for achieving this.\n\nAdditionally, I need to perform a full load initially, followed by capturing and migrating only the changed data. Are there other recommended approaches for this scenario?\n\nI appreciate any insights or suggestions.", "author_fullname": "t2_7nvr4m4i4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion on Postgres RDS to Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18it9jp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702619891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Hello Data Engineers!&lt;/h1&gt;\n\n&lt;p&gt;I have a requirement to stream data from &lt;strong&gt;Aurora Postgres RDS&lt;/strong&gt; to &lt;strong&gt;Redshift&lt;/strong&gt; using AWS services. Currently, my approach involves creating a &lt;strong&gt;DMS&lt;/strong&gt; (Database Migration Service) task to migrate data to Kinesis, and then pulling data from &lt;strong&gt;Kinesis&lt;/strong&gt; to Redshift by creating an external schema. I&amp;#39;m wondering if there are alternative methods for achieving this.&lt;/p&gt;\n\n&lt;p&gt;Additionally, I need to perform a full load initially, followed by capturing and migrating only the changed data. Are there other recommended approaches for this scenario?&lt;/p&gt;\n\n&lt;p&gt;I appreciate any insights or suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18it9jp", "is_robot_indexable": true, "report_reasons": null, "author": "Flimsy-Mirror974", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18it9jp/discussion_on_postgres_rds_to_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18it9jp/discussion_on_postgres_rds_to_redshift/", "subreddit_subscribers": 146052, "created_utc": 1702619891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Experts,\n\nI'm currently exploring optimal solutions for our project, aiming to identify the most suitable framework or service for our data processing. We operate real-time dashboards that showcase alarms every two minutes, and our goal is to achieve reporting intervals closer to 10 seconds or less for new alarms.\n\nGiven the cost considerations highlighted by our product manager, we're seeking a solution that is efficient without being overly expensive. Our typical data size is approximately 50k records per job. I'd appreciate your recommendations and insights. If you're involved in a similar project, what framework or service are you utilizing? \n \nBTW- this is timeseries data\n\nThank you!", "author_fullname": "t2_6d76dzgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I use for real time job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ic0pw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702570231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Experts,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently exploring optimal solutions for our project, aiming to identify the most suitable framework or service for our data processing. We operate real-time dashboards that showcase alarms every two minutes, and our goal is to achieve reporting intervals closer to 10 seconds or less for new alarms.&lt;/p&gt;\n\n&lt;p&gt;Given the cost considerations highlighted by our product manager, we&amp;#39;re seeking a solution that is efficient without being overly expensive. Our typical data size is approximately 50k records per job. I&amp;#39;d appreciate your recommendations and insights. If you&amp;#39;re involved in a similar project, what framework or service are you utilizing? &lt;/p&gt;\n\n&lt;p&gt;BTW- this is timeseries data&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18ic0pw", "is_robot_indexable": true, "report_reasons": null, "author": "Friendly-Radio-6312", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ic0pw/what_should_i_use_for_real_time_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ic0pw/what_should_i_use_for_real_time_job/", "subreddit_subscribers": 146052, "created_utc": 1702570231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a1tanc569", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ask HN: Is there an open source database like this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ilc2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1702594940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "atwong.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://atwong.medium.com/ask-hn-is-there-an-open-source-database-like-this-39ba6ceaec1e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18ilc2m", "is_robot_indexable": true, "report_reasons": null, "author": "albertstarrocks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ilc2m/ask_hn_is_there_an_open_source_database_like_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://atwong.medium.com/ask-hn-is-there-an-open-source-database-like-this-39ba6ceaec1e", "subreddit_subscribers": 146052, "created_utc": 1702594940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I was hoping to get some advice on the current methdology used for data warehousing in the public sector company I work for. I mention it's public sector to emphasise that both the people there and processes are quite old school. \n\nSo, currently the data warehouse is an on-premise SQL Server solution. The enterprise application we use, among a few other things, gets warehoused nightly via PowerShell scripts that dynamically generate stored procedures from the databases and tables identified from the various SQL servers from the applications and such. These stored procedures then run on a nightly basis via an SSIS package that loops through these and creates batches of tables to warehouse for each CPU thread.\n\nThe person who developed this workflow 10 years or so ago, which hasn't changed since, has now left. The data warehouse is primarily used for reporting in SSRS &amp; Power BI and archiving of data for auditing purposes. Myself and IT are wanting to potentially update our data warehouse methodology to hopefully improve and simplify it. My questions are: is the current workflow an effective data warehousing solution? Would using a cloud platform such as Azure SQL simplify things for reasons such as not needing to worry about scalability? What solutions can be recommended to transform and improve this workflow to warehouse our systems that mainly use on-premise SQL servers? I should also mention the company is very Microsoft orientated. Many thanks in advance for assistance!", "author_fullname": "t2_ppxsc3cy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data warehousing for public sectory company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18i76gi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702555414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I was hoping to get some advice on the current methdology used for data warehousing in the public sector company I work for. I mention it&amp;#39;s public sector to emphasise that both the people there and processes are quite old school. &lt;/p&gt;\n\n&lt;p&gt;So, currently the data warehouse is an on-premise SQL Server solution. The enterprise application we use, among a few other things, gets warehoused nightly via PowerShell scripts that dynamically generate stored procedures from the databases and tables identified from the various SQL servers from the applications and such. These stored procedures then run on a nightly basis via an SSIS package that loops through these and creates batches of tables to warehouse for each CPU thread.&lt;/p&gt;\n\n&lt;p&gt;The person who developed this workflow 10 years or so ago, which hasn&amp;#39;t changed since, has now left. The data warehouse is primarily used for reporting in SSRS &amp;amp; Power BI and archiving of data for auditing purposes. Myself and IT are wanting to potentially update our data warehouse methodology to hopefully improve and simplify it. My questions are: is the current workflow an effective data warehousing solution? Would using a cloud platform such as Azure SQL simplify things for reasons such as not needing to worry about scalability? What solutions can be recommended to transform and improve this workflow to warehouse our systems that mainly use on-premise SQL servers? I should also mention the company is very Microsoft orientated. Many thanks in advance for assistance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18i76gi", "is_robot_indexable": true, "report_reasons": null, "author": "strictlydatabusiness", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18i76gi/data_warehousing_for_public_sectory_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18i76gi/data_warehousing_for_public_sectory_company/", "subreddit_subscribers": 146052, "created_utc": 1702555414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nCurrently employed in tech support, specializing in T-SQL, I've been contemplating a shift towards data engineering. I have a keen interest in working with data on a daily basis, and my previous experience includes a Java course and Selenium training, though my attempts at transitioning to QA automation were met with limited success.\n\nNow, I'm exploring opportunities in data engineering, as my primary goal is to code regularly in my job. I work extensively with T-SQL, handling various technical aspects, including XML files, and have exposure to JavaScript/jQuery and API endpoints.\n\nI'm curious to know if gaining 1 to 1.5 years of experience in my current role could enhance my prospects for a data engineering position. Any advice or insights on leveraging my skills for a successful transition into data engineering would be highly appreciated.\n\nThank you!", "author_fullname": "t2_hljgw2wbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "T-SQL Tech Support to Aspiring Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ifvuc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702580453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Currently employed in tech support, specializing in T-SQL, I&amp;#39;ve been contemplating a shift towards data engineering. I have a keen interest in working with data on a daily basis, and my previous experience includes a Java course and Selenium training, though my attempts at transitioning to QA automation were met with limited success.&lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;m exploring opportunities in data engineering, as my primary goal is to code regularly in my job. I work extensively with T-SQL, handling various technical aspects, including XML files, and have exposure to JavaScript/jQuery and API endpoints.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to know if gaining 1 to 1.5 years of experience in my current role could enhance my prospects for a data engineering position. Any advice or insights on leveraging my skills for a successful transition into data engineering would be highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18ifvuc", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Luck_763", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ifvuc/tsql_tech_support_to_aspiring_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ifvuc/tsql_tech_support_to_aspiring_data_engineer/", "subreddit_subscribers": 146052, "created_utc": 1702580453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the tradeoffs?", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS EMR vs Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18idzt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702575481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the tradeoffs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "18idzt1", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18idzt1/aws_emr_vs_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18idzt1/aws_emr_vs_databricks/", "subreddit_subscribers": 146052, "created_utc": 1702575481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am a undergrad Senior graduating this upcoming Spring, and in my schedule for next semester it's looking like I'll only have space for Data Structures and Algorithms II, or Advanced Database Management, and I'm wondering which one would be more useful for data engineering. I have some experience in ML and may have an opportunity to do some ML work in my upcoming job, so if you happen to have insight into that too, that'd be great.\n\nThe Adv DB Mgmt will use Oracle, MySQL, SQL Server, and will teach Data Warehousing, NoSQL, permissions, triggers, JSON (the course is meant to teach DBA skills). I took the intermediate DB Mgmt course already (which taught relational DBs, triggers, stored procedures in MySQL and SQL Server). I also learned some DW'ing from a previous internship.\n\nThe DS and Algo II will teach things like stacks, heaps, trees, linked lists, binary search, complexity, etc. In C++. I took DS and Algo I which was more focused on OOP and touched a little on linked list, trees, stacks, etc.", "author_fullname": "t2_6iuiajc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "More important skills to develop: DS + Algo or Adv DB Mgmt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ia5ta", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702565063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am a undergrad Senior graduating this upcoming Spring, and in my schedule for next semester it&amp;#39;s looking like I&amp;#39;ll only have space for Data Structures and Algorithms II, or Advanced Database Management, and I&amp;#39;m wondering which one would be more useful for data engineering. I have some experience in ML and may have an opportunity to do some ML work in my upcoming job, so if you happen to have insight into that too, that&amp;#39;d be great.&lt;/p&gt;\n\n&lt;p&gt;The Adv DB Mgmt will use Oracle, MySQL, SQL Server, and will teach Data Warehousing, NoSQL, permissions, triggers, JSON (the course is meant to teach DBA skills). I took the intermediate DB Mgmt course already (which taught relational DBs, triggers, stored procedures in MySQL and SQL Server). I also learned some DW&amp;#39;ing from a previous internship.&lt;/p&gt;\n\n&lt;p&gt;The DS and Algo II will teach things like stacks, heaps, trees, linked lists, binary search, complexity, etc. In C++. I took DS and Algo I which was more focused on OOP and touched a little on linked list, trees, stacks, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18ia5ta", "is_robot_indexable": true, "report_reasons": null, "author": "PuzzleheadedWillow11", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18ia5ta/more_important_skills_to_develop_ds_algo_or_adv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18ia5ta/more_important_skills_to_develop_ds_algo_or_adv/", "subreddit_subscribers": 146052, "created_utc": 1702565063.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}