{"kind": "Listing", "data": {"after": "t3_18izjka", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_d369e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "17.4 million DNS queries over 24 hours via AdGuard Home", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dnstools", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_18io02l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 374, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "DNS Tools", "can_mod_post": false, "score": 374, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/uTgkjFAz_A7XL0NwdMP0eGyZ2HlyEqxGW1wYipKMh_I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702602571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/63iz10yhzc6c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/63iz10yhzc6c1.png?auto=webp&amp;s=eece3af9e17768547772a166abe90045faa9043b", "width": 1082, "height": 1126}, "resolutions": [{"url": "https://preview.redd.it/63iz10yhzc6c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=761ebe04a601df6756f55f6535e5d9a9fb1ee4eb", "width": 108, "height": 112}, {"url": "https://preview.redd.it/63iz10yhzc6c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=561e4d937be9638671484949c44c46966ff109ee", "width": 216, "height": 224}, {"url": "https://preview.redd.it/63iz10yhzc6c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=55e498f7ad58b8c471cec19b81a18681f4e91965", "width": 320, "height": 333}, {"url": "https://preview.redd.it/63iz10yhzc6c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d41bbe9f0cc8077cce7cbcdb9b95b85397bf3c31", "width": 640, "height": 666}, {"url": "https://preview.redd.it/63iz10yhzc6c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=189dc9c08b1b4e57b082df069ba92198898e159f", "width": 960, "height": 999}, {"url": "https://preview.redd.it/63iz10yhzc6c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=081eefb576ff0f4d7102be0a7090438b09adc679", "width": 1080, "height": 1123}], "variants": {}, "id": "2bYK_iBXWgHAoDvfOLtqiu7hjLYJfle713O06ECoX2o"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f0c1d430-7e6b-11e9-9779-0e688895811a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "18io02l", "is_robot_indexable": true, "report_reasons": null, "author": "ctrlaltpineapple", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18io02l/174_million_dns_queries_over_24_hours_via_adguard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/63iz10yhzc6c1.png", "subreddit_subscribers": 299827, "created_utc": 1702602571.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "As 2023 comes to an end I want to understand how you went about self hosting this year. While this is an open ended question, I came up with 5 categories. Obviously there will be some overlap but you can of course mention as many apps and services as you like how you like.\n\nMost used\n\nMost critical \n\nMost recommended \n\nMost fun\n\nMost looking forward to", "author_fullname": "t2_5o6owomn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What we're you hosting in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iqlve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 115, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 115, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702610994.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702610702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As 2023 comes to an end I want to understand how you went about self hosting this year. While this is an open ended question, I came up with 5 categories. Obviously there will be some overlap but you can of course mention as many apps and services as you like how you like.&lt;/p&gt;\n\n&lt;p&gt;Most used&lt;/p&gt;\n\n&lt;p&gt;Most critical &lt;/p&gt;\n\n&lt;p&gt;Most recommended &lt;/p&gt;\n\n&lt;p&gt;Most fun&lt;/p&gt;\n\n&lt;p&gt;Most looking forward to&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iqlve", "is_robot_indexable": true, "report_reasons": null, "author": "Alt_Lightning", "discussion_type": null, "num_comments": 97, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iqlve/what_were_you_hosting_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iqlve/what_were_you_hosting_in_2023/", "subreddit_subscribers": 299827, "created_utc": 1702610702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I recently made the switch exclusively to Jellyfin, leaving behind Plex (Pass) for a variety of reasons. As I encountered several issues with Plex:\n\n1. It's convoluted process for granting access to others, requiring them to create a Plex account.\n2. The necessity for new users to pay for the app on mobile devices.\n3. Privacy concerns associated with Plex.\n\nJellyfin has proven to be compatible with all my devices, presenting no major issues thus far. \n\n&amp;#x200B;\n\nHowever, when it comes to music, its just not the same experience.\n\nWhat I appreciated about Plexamp and am struggling to find in a Jellyfin-compatible player:\n\n* Highlights the most popular songs within an album.\n* Allows buffer settings, enabling resumption even after closing the app or during a connection loss.\n* Displays only artists with albums (in the artists view)\n* Shows albums that are truly albums (in the albums view)\n* Well-designed layouts for recent plays, recently added content, recent playlists, and viewing history.\n* Offers a dark theme with smooth transitions.\n* Sonic analysis feature\n\nI primarily used Plexamp on Android and Windows, and so far, I've explored alternatives such as:\n\n**Finamp** \\- Probably the best option so far, but it still lacks some features. \ud83c\udfaf\n\n**Fintunes** \\- Works but is basic enough, and I found it way too slow. \ud83d\udc0c\n\n**Llamafin** \\- I haven't tested due to its closed-source nature (couldn't find it on github) and limited downloads on the Play Store. Anyone used it? r/Llamafin \ud83d\udd0e\n\nFor Windows I've mainly been using the Web player but that is not a dedicated music player.\n\nAny suggestions or insights into other Jellyfin-compatible players with Plexamp-like features would be greatly appreciated!\n\nEdit: Thank you to everyone that works on Jellyfin and its related applications. \ud83d\udc4f\nIt's an excellent alternative (and in some ways superior)  to a commercial product!\nJust want to make sure this doesn't appear as a complaint in any way! \n\nEdit2: I see the code behind sonic analysis is open source u/XxNerdAtHearthxX are there any future plans for its integration?", "author_fullname": "t2_r85zyhrd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moved exclusively to Jellyfin, struggling to find a Plexamp alternative\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "mediaserving", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18icvt9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Media Serving", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702595443.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702572567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently made the switch exclusively to Jellyfin, leaving behind Plex (Pass) for a variety of reasons. As I encountered several issues with Plex:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;It&amp;#39;s convoluted process for granting access to others, requiring them to create a Plex account.&lt;/li&gt;\n&lt;li&gt;The necessity for new users to pay for the app on mobile devices.&lt;/li&gt;\n&lt;li&gt;Privacy concerns associated with Plex.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Jellyfin has proven to be compatible with all my devices, presenting no major issues thus far. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, when it comes to music, its just not the same experience.&lt;/p&gt;\n\n&lt;p&gt;What I appreciated about Plexamp and am struggling to find in a Jellyfin-compatible player:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Highlights the most popular songs within an album.&lt;/li&gt;\n&lt;li&gt;Allows buffer settings, enabling resumption even after closing the app or during a connection loss.&lt;/li&gt;\n&lt;li&gt;Displays only artists with albums (in the artists view)&lt;/li&gt;\n&lt;li&gt;Shows albums that are truly albums (in the albums view)&lt;/li&gt;\n&lt;li&gt;Well-designed layouts for recent plays, recently added content, recent playlists, and viewing history.&lt;/li&gt;\n&lt;li&gt;Offers a dark theme with smooth transitions.&lt;/li&gt;\n&lt;li&gt;Sonic analysis feature&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I primarily used Plexamp on Android and Windows, and so far, I&amp;#39;ve explored alternatives such as:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Finamp&lt;/strong&gt; - Probably the best option so far, but it still lacks some features. \ud83c\udfaf&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Fintunes&lt;/strong&gt; - Works but is basic enough, and I found it way too slow. \ud83d\udc0c&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Llamafin&lt;/strong&gt; - I haven&amp;#39;t tested due to its closed-source nature (couldn&amp;#39;t find it on github) and limited downloads on the Play Store. Anyone used it? &lt;a href=\"/r/Llamafin\"&gt;r/Llamafin&lt;/a&gt; \ud83d\udd0e&lt;/p&gt;\n\n&lt;p&gt;For Windows I&amp;#39;ve mainly been using the Web player but that is not a dedicated music player.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or insights into other Jellyfin-compatible players with Plexamp-like features would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: Thank you to everyone that works on Jellyfin and its related applications. \ud83d\udc4f\nIt&amp;#39;s an excellent alternative (and in some ways superior)  to a commercial product!\nJust want to make sure this doesn&amp;#39;t appear as a complaint in any way! &lt;/p&gt;\n\n&lt;p&gt;Edit2: I see the code behind sonic analysis is open source &lt;a href=\"/u/XxNerdAtHearthxX\"&gt;u/XxNerdAtHearthxX&lt;/a&gt; are there any future plans for its integration?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb71ccc0-7e67-11e9-841a-0e67038620c2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18icvt9", "is_robot_indexable": true, "report_reasons": null, "author": "TheWicklowWolf", "discussion_type": null, "num_comments": 81, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18icvt9/moved_exclusively_to_jellyfin_struggling_to_find/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18icvt9/moved_exclusively_to_jellyfin_struggling_to_find/", "subreddit_subscribers": 299827, "created_utc": 1702572567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I need a self-host way to share large files (regularly transferring say 10 gig files) with a third party (read only one way is fine). I'd love to hear what sort of tech you'd pick for this:\n\n* Server side (me) has static Ipv4 &amp; reliable 1 gig up on a proxmox setup so server side can be whatever it needs to be software wise\n* Download side is a fast but potentially shaky connection so need something that can recover from outages\n* Has to be authenticated\n* End user is not technical per se, but competent in the generic sense so could manage say sFTP login with keys if necessary\n* I'll be VM'ing this but still has to be pretty solid security wise since I'm exposing this on a static ip (Will probably region lock ufw it)\n* Password auth preferred, but can do keys if necessary\n* End user is on a windows system and can install custom software as long as it is reasonably credible (deluge, winscp etc)\n\nLeaning towards something sftp-ish but unsure how well that copes with flakey connections.\n\nTorrent would be ideal on fault tolerance but then I'd need to encrypt the files manually which feels like a pain.\n\nSomething file-run-ish would also work I guess but if I can dodge the whole SSL thing I will. I'd rather explain ssh keys for sftp than deal with ssl and domains. Something that can just hit the static ip would be better.\n\nWireguard style point to point tunnel, tailscale etc is not an option. I don't control end user side enough to make that happen and not confident I can get that past end user technical ability remotely.\n\nI don't want a nextcloud type custom software solution - something I can stick on a vanilla debian box please.", "author_fullname": "t2_3q8dd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hosting large files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ii893", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702586720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need a self-host way to share large files (regularly transferring say 10 gig files) with a third party (read only one way is fine). I&amp;#39;d love to hear what sort of tech you&amp;#39;d pick for this:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Server side (me) has static Ipv4 &amp;amp; reliable 1 gig up on a proxmox setup so server side can be whatever it needs to be software wise&lt;/li&gt;\n&lt;li&gt;Download side is a fast but potentially shaky connection so need something that can recover from outages&lt;/li&gt;\n&lt;li&gt;Has to be authenticated&lt;/li&gt;\n&lt;li&gt;End user is not technical per se, but competent in the generic sense so could manage say sFTP login with keys if necessary&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ll be VM&amp;#39;ing this but still has to be pretty solid security wise since I&amp;#39;m exposing this on a static ip (Will probably region lock ufw it)&lt;/li&gt;\n&lt;li&gt;Password auth preferred, but can do keys if necessary&lt;/li&gt;\n&lt;li&gt;End user is on a windows system and can install custom software as long as it is reasonably credible (deluge, winscp etc)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Leaning towards something sftp-ish but unsure how well that copes with flakey connections.&lt;/p&gt;\n\n&lt;p&gt;Torrent would be ideal on fault tolerance but then I&amp;#39;d need to encrypt the files manually which feels like a pain.&lt;/p&gt;\n\n&lt;p&gt;Something file-run-ish would also work I guess but if I can dodge the whole SSL thing I will. I&amp;#39;d rather explain ssh keys for sftp than deal with ssl and domains. Something that can just hit the static ip would be better.&lt;/p&gt;\n\n&lt;p&gt;Wireguard style point to point tunnel, tailscale etc is not an option. I don&amp;#39;t control end user side enough to make that happen and not confident I can get that past end user technical ability remotely.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want a nextcloud type custom software solution - something I can stick on a vanilla debian box please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ii893", "is_robot_indexable": true, "report_reasons": null, "author": "AnomalyNexus", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ii893/hosting_large_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ii893/hosting_large_files/", "subreddit_subscribers": 299827, "created_utc": 1702586720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_owqec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] dockcheck - selective auto-update fleets of docker images, with extras. (now v3)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "release", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_18ihbw0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Release", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sF_4MVKtJrPdehXfGYfqgV5dKqMA8y63KpbqeCKqkjA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1702584331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/frluvx78hb6c1.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/frluvx78hb6c1.gif?format=png8&amp;s=43c3b84c64ff451ff056182cc763b82a2df749d6", "width": 725, "height": 510}, "resolutions": [{"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=eb224cc21f8dd4fecd97042df78c80d5de119ee4", "width": 108, "height": 75}, {"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=e63838e5874cccd66aec76cc7293eb619952d9c1", "width": 216, "height": 151}, {"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=56011c5d55f6855cb1937b615c04a85efc9dad31", "width": 320, "height": 225}, {"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=f2101afb1b29fb0ed4f3a9f2cc99c97ed7981921", "width": 640, "height": 450}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/frluvx78hb6c1.gif?s=a06f32be88f9254cbf795f44cc5fff833949dfa7", "width": 725, "height": 510}, "resolutions": [{"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=108&amp;crop=smart&amp;s=c366781299513657344ee0c1eabb246bba23cff2", "width": 108, "height": 75}, {"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=216&amp;crop=smart&amp;s=0feaf767568b90519e4f3c4c87543c15623c07f1", "width": 216, "height": 151}, {"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=320&amp;crop=smart&amp;s=5beeddf431d2728236ec6f2e52f9d2a22942dc75", "width": 320, "height": 225}, {"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=640&amp;crop=smart&amp;s=5745f68b7a240711e539c75ccc8fdb3ceb7969d0", "width": 640, "height": 450}]}, "mp4": {"source": {"url": "https://preview.redd.it/frluvx78hb6c1.gif?format=mp4&amp;s=7db739de62edfbff5ab14256a105f3c471cbad2b", "width": 725, "height": 510}, "resolutions": [{"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=108&amp;format=mp4&amp;s=cd88e31377eaaf214f628ac16c24add34bcb6069", "width": 108, "height": 75}, {"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=216&amp;format=mp4&amp;s=9b57f5c1028658f0a2daef07c891b5847e0fbe06", "width": 216, "height": 151}, {"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=320&amp;format=mp4&amp;s=9165e167ad4b7b59ca2c2481a795c077491921d6", "width": 320, "height": 225}, {"url": "https://preview.redd.it/frluvx78hb6c1.gif?width=640&amp;format=mp4&amp;s=0b52016f06214011c2c447855cbf2d97f3d31ec2", "width": 640, "height": 450}]}}, "id": "soX0PuxX3EsrrkSr1oQCXsUP8nT4qTRZvd9fUvK0qj8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7a2c90d0-4655-11ec-b067-9e334eed55f0", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ihbw0", "is_robot_indexable": true, "report_reasons": null, "author": "Mag37", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ihbw0/oc_dockcheck_selective_autoupdate_fleets_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/frluvx78hb6c1.gif", "subreddit_subscribers": 299827, "created_utc": 1702584331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello esteemed members of r/selfhosted,\n\n&amp;#x200B;\n\nI'm reaching out to tap into the collective wisdom of this knowledgeable community. I'm in search of a reliable, open-source software solution that can diligently monitor my internet upload and download speeds at regular intervals.\n\nThis tool is not just for my curiosity, but also to ensure that my ISP is keeping up their end of the bargain. Essentially, I'm looking to gather evidence in a sophisticated, yet lighthearted, \"I-told-you-so\" package. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83d\udcca\n\nI would greatly appreciate your recommendations for a free software that combines functionality with ease of use.\n\nIf possible, I have a particular fondness for Docker solutions.\n\n&amp;#x200B;\n\nThank you all :)", "author_fullname": "t2_a0vsc0f4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet speed monitoring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "personaldashboard", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ixbks", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Dashboard", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702636917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello esteemed members of &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out to tap into the collective wisdom of this knowledgeable community. I&amp;#39;m in search of a reliable, open-source software solution that can diligently monitor my internet upload and download speeds at regular intervals.&lt;/p&gt;\n\n&lt;p&gt;This tool is not just for my curiosity, but also to ensure that my ISP is keeping up their end of the bargain. Essentially, I&amp;#39;m looking to gather evidence in a sophisticated, yet lighthearted, &amp;quot;I-told-you-so&amp;quot; package. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83d\udcca&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your recommendations for a free software that combines functionality with ease of use.&lt;/p&gt;\n\n&lt;p&gt;If possible, I have a particular fondness for Docker solutions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you all :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "587d404a-7e68-11e9-bd12-0eb480af1d48", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ixbks", "is_robot_indexable": true, "report_reasons": null, "author": "TPK-trade", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ixbks/internet_speed_monitoring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ixbks/internet_speed_monitoring/", "subreddit_subscribers": 299827, "created_utc": 1702636917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi r/selfhosted,\n\nI\u2019m Matija, and I\u2019m one of the maintainers and creators of [OpenSaaS](https://opensaas.sh/). We\u2019ve had this idea for a while, and I\u2019m happy we can finally share it with you and hopefully get your thoughts and feedback.\n\nOpenSaaS is imagined as an open-source and free alternative to all the feature-rich boilerplate starters you\u2019ve been seeing around lately that often sell for north of $300. We believe there should be a free, community-owned, high-quality starting point for developers to create their apps.\n\n&amp;#x200B;\n\n&gt;OpenSaaS is still in its early days, and this is the first time we have shared it with anyone! Please keep in mind not everything is polished yet, and hiccups may occur. We\u2019re grateful for any bug reports or suggestions - feel free to report them on our GitHub.\n\n&amp;#x200B;\n\nYou can access the repository on GitHub at [https://github.com/wasp-lang/open-saas](https://github.com/wasp-lang/open-saas). If you like it and want to support it, we would appreciate you starring the project! That would motivate us to keep going and bring this to more developers.\n\nOpenSaaS is 100% open-source, and easy to deploy to any platform. We take special care not to depend on any proprietary deployment services or 3rd party integrations whenever possible. This is the stack it is built upon:\n\n* React, Node.js &amp; Prisma - powered by Vite &amp; Wasp framework\n* Plausible Analytics for privacy, or Google Analytics for ease\n* Emailing with your own SMTP, SendGrid or EmailGun\n* Administrator dashboard - powered by Tailwind/Tailadmin\n* Blog - powered by Astro", "author_fullname": "t2_x5xwr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Early preview] OpenSaaS: free, open-source boilerplate starter for React &amp; Node.js (admin dashboard, analytics, ...)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "softwaredev", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18idyzt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Software Development", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702575419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m Matija, and I\u2019m one of the maintainers and creators of &lt;a href=\"https://opensaas.sh/\"&gt;OpenSaaS&lt;/a&gt;. We\u2019ve had this idea for a while, and I\u2019m happy we can finally share it with you and hopefully get your thoughts and feedback.&lt;/p&gt;\n\n&lt;p&gt;OpenSaaS is imagined as an open-source and free alternative to all the feature-rich boilerplate starters you\u2019ve been seeing around lately that often sell for north of $300. We believe there should be a free, community-owned, high-quality starting point for developers to create their apps.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;OpenSaaS is still in its early days, and this is the first time we have shared it with anyone! Please keep in mind not everything is polished yet, and hiccups may occur. We\u2019re grateful for any bug reports or suggestions - feel free to report them on our GitHub.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;You can access the repository on GitHub at &lt;a href=\"https://github.com/wasp-lang/open-saas\"&gt;https://github.com/wasp-lang/open-saas&lt;/a&gt;. If you like it and want to support it, we would appreciate you starring the project! That would motivate us to keep going and bring this to more developers.&lt;/p&gt;\n\n&lt;p&gt;OpenSaaS is 100% open-source, and easy to deploy to any platform. We take special care not to depend on any proprietary deployment services or 3rd party integrations whenever possible. This is the stack it is built upon:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;React, Node.js &amp;amp; Prisma - powered by Vite &amp;amp; Wasp framework&lt;/li&gt;\n&lt;li&gt;Plausible Analytics for privacy, or Google Analytics for ease&lt;/li&gt;\n&lt;li&gt;Emailing with your own SMTP, SendGrid or EmailGun&lt;/li&gt;\n&lt;li&gt;Administrator dashboard - powered by Tailwind/Tailadmin&lt;/li&gt;\n&lt;li&gt;Blog - powered by Astro&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-zvw4ZrjsZfIx9rDFE9ASXcG6t7yhw62LpKI5-Oi4Hk.jpg?auto=webp&amp;s=3e5ff9f87e376150c24a421fc6aade5dab247ffd", "width": 1080, "height": 619}, "resolutions": [{"url": "https://external-preview.redd.it/-zvw4ZrjsZfIx9rDFE9ASXcG6t7yhw62LpKI5-Oi4Hk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d0adfbdfcecdc2f1085778a4fa248abd506041c", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/-zvw4ZrjsZfIx9rDFE9ASXcG6t7yhw62LpKI5-Oi4Hk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86496445207183d1af6eb0de9354a7035156d9e6", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/-zvw4ZrjsZfIx9rDFE9ASXcG6t7yhw62LpKI5-Oi4Hk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=117cb34a83a587c98f9cccc018193792d605225f", "width": 320, "height": 183}, {"url": "https://external-preview.redd.it/-zvw4ZrjsZfIx9rDFE9ASXcG6t7yhw62LpKI5-Oi4Hk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f7d329cec2dcb9f515b19c6d1ef1d5fe0d0da9da", "width": 640, "height": 366}, {"url": "https://external-preview.redd.it/-zvw4ZrjsZfIx9rDFE9ASXcG6t7yhw62LpKI5-Oi4Hk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f06794c7d9f86523d20b303d7389b2008e7390f2", "width": 960, "height": 550}, {"url": "https://external-preview.redd.it/-zvw4ZrjsZfIx9rDFE9ASXcG6t7yhw62LpKI5-Oi4Hk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3def80838abea7b3d43963bf99f8c8747ac8445c", "width": 1080, "height": 619}], "variants": {}, "id": "DyWKRArtgqbbANWVDGqvGTtr9rTJ2aPK_VXgB3ki4XQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "684a1552-7e68-11e9-a4b1-0e84949b6a4e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18idyzt", "is_robot_indexable": true, "report_reasons": null, "author": "matijash", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18idyzt/early_preview_opensaas_free_opensource/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18idyzt/early_preview_opensaas_free_opensource/", "subreddit_subscribers": 299827, "created_utc": 1702575419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Is there a tool that will check for container updates and send a message to a configured notification tool instead of auto updating them? Maybe setting up an ignore list too? Be great if the tool could check multiple docker instances.", "author_fullname": "t2_3pr6cf6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Container updates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ijh7x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702590083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a tool that will check for container updates and send a message to a configured notification tool instead of auto updating them? Maybe setting up an ignore list too? Be great if the tool could check multiple docker instances.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ijh7x", "is_robot_indexable": true, "report_reasons": null, "author": "TechyRyan33", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ijh7x/container_updates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ijh7x/container_updates/", "subreddit_subscribers": 299827, "created_utc": 1702590083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey there,\n\nI have been looking for a tool to help me archive emails like MailStore Home, but self-hosted on my network and accessible for my wife and me, unlike MailStore Home.  I also would prefer not to have to run and manage an email server, since I've understood unless you know what you're doing - which I do not - there is a greater change of security issues.\n\nDoes anyone know a solution for this or something that gets close?\n\nThanks a lot!\n\n&amp;#x200B;", "author_fullname": "t2_awqcvsjk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accessible email archive tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "emailmanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18icilt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Email Management", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702571579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I have been looking for a tool to help me archive emails like MailStore Home, but self-hosted on my network and accessible for my wife and me, unlike MailStore Home.  I also would prefer not to have to run and manage an email server, since I&amp;#39;ve understood unless you know what you&amp;#39;re doing - which I do not - there is a greater change of security issues.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know a solution for this or something that gets close?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0690f484-7e68-11e9-80db-0eb480af1d48", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18icilt", "is_robot_indexable": true, "report_reasons": null, "author": "Trekkie8472", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18icilt/accessible_email_archive_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18icilt/accessible_email_archive_tool/", "subreddit_subscribers": 299827, "created_utc": 1702571579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": " \n\nHey\n\nI'm diving into the exciting world of honeypots and cybersecurity at home, and I'd love some guidance on creating a live attack map using Grafana. Specifically, I'm using Cowrie for my honeypot and feeding its data into Prometheus to visualize attacks in Grafana. Now, here's where I could use some help.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;format=png&amp;auto=webp&amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b\n\nI've been inspired by those awesome live attack maps from TPOTCE, and I'm eager to replicate something similar for my own setup. As a newbie in homelabs, I'm wondering if anyone has experience or advice on achieving this. I'd appreciate insights on how to Configure Grafana to visualize the attacks in real-time.\n\nIf you've tackled a similar project or have tips for a homelab newbie, I'd love to hear about your experiences and any resources you found helpful.", "author_fullname": "t2_7dixsldo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a Live Attack Map with Grafana, Cowrie, and Prometheus", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 126, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3yu1gngy6g6c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 97, "x": 108, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8eec587d6c24a02fac84f9548944912c281d97d2"}, {"y": 195, "x": 216, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ccf1ecd4a718dc91fafbbdecce962f5882ab478d"}, {"y": 289, "x": 320, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=571b35d86b53068d98c3621eecc169a2cccb5a95"}, {"y": 578, "x": 640, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=141473d0b9e21d6cecbc41b47cccbdfa25327e37"}, {"y": 867, "x": 960, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=39c78b816374d4d7939511a4ff110b2abc1b43db"}, {"y": 975, "x": 1080, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fe1964b3a71a6a02f3864b791570b95d6a0f0a2e"}], "s": {"y": 1779, "x": 1969, "u": "https://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;format=png&amp;auto=webp&amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b"}, "id": "3yu1gngy6g6c1"}}, "name": "t3_18iyggv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/h0uIxx4KbylDGGBKiqlSjEh74Qh1inkEkmdCMtq0YaY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702641392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m diving into the exciting world of honeypots and cybersecurity at home, and I&amp;#39;d love some guidance on creating a live attack map using Grafana. Specifically, I&amp;#39;m using Cowrie for my honeypot and feeding its data into Prometheus to visualize attacks in Grafana. Now, here&amp;#39;s where I could use some help.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b\"&gt;https://preview.redd.it/3yu1gngy6g6c1.png?width=1969&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f0567f2315cfbfa296a39c42b102cc9e88544d4b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been inspired by those awesome live attack maps from TPOTCE, and I&amp;#39;m eager to replicate something similar for my own setup. As a newbie in homelabs, I&amp;#39;m wondering if anyone has experience or advice on achieving this. I&amp;#39;d appreciate insights on how to Configure Grafana to visualize the attacks in real-time.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve tackled a similar project or have tips for a homelab newbie, I&amp;#39;d love to hear about your experiences and any resources you found helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iyggv", "is_robot_indexable": true, "report_reasons": null, "author": "TheKing464", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iyggv/creating_a_live_attack_map_with_grafana_cowrie/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iyggv/creating_a_live_attack_map_with_grafana_cowrie/", "subreddit_subscribers": 299827, "created_utc": 1702641392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Happy Friday, r/selfhosted! Below is a link to *This Week in Self-Hosted*, a weekly newsletter recap of the latest activity in self-hosted software.\n\nThis week's features include:\n\n* The latest news in self-hosted software\n* Noteworthy software updates, launches, and events\n* Featured content generated by the self-hosted community\n* A spotlight on [Dockge](https://github.com/louislam/dockge?ref=selfh.st), a web-based docker compose stack manager\n\nAs usual, feel free to reach out with questions or comments about the newsletter. Thanks!\n\n---\n\n[This Week in Self-Hosted (15 December 2023)](https://selfh.st/newsletter/2023-12-15/)", "author_fullname": "t2_vvcklg6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This Week in Self-Hosted (15 December 2023)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18iz5mc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702643917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happy Friday, &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt;! Below is a link to &lt;em&gt;This Week in Self-Hosted&lt;/em&gt;, a weekly newsletter recap of the latest activity in self-hosted software.&lt;/p&gt;\n\n&lt;p&gt;This week&amp;#39;s features include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The latest news in self-hosted software&lt;/li&gt;\n&lt;li&gt;Noteworthy software updates, launches, and events&lt;/li&gt;\n&lt;li&gt;Featured content generated by the self-hosted community&lt;/li&gt;\n&lt;li&gt;A spotlight on &lt;a href=\"https://github.com/louislam/dockge?ref=selfh.st\"&gt;Dockge&lt;/a&gt;, a web-based docker compose stack manager&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As usual, feel free to reach out with questions or comments about the newsletter. Thanks!&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;a href=\"https://selfh.st/newsletter/2023-12-15/\"&gt;This Week in Self-Hosted (15 December 2023)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?auto=webp&amp;s=edfc1e87b204020d848795a64b8ddd109f886270", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c09d9bcd169fce6fdd6ec7fe2b47833eb6296217", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a96911c301ea2dc8736504b014f3a27df1e244e7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a033b33b71d55259659ff2a51b42fcacac339838", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3d2f988460654901b3d6b889110ca2a147372098", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ba692125aee2344994701d6c49e2c97855e8965", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/iba5T9OuyWFT5UEHK6EUHFuvsAdDACo9lj5U8n2XPVc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e4378b1466adcd48a4bf01cd798b53307a12061e", "width": 1080, "height": 540}], "variants": {}, "id": "Gf1_-kT8szx_yWNO2zBdA-iQjknAjjAqkcYTWsAw_zE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iz5mc", "is_robot_indexable": true, "report_reasons": null, "author": "selfh-sted", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iz5mc/this_week_in_selfhosted_15_december_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iz5mc/this_week_in_selfhosted_15_december_2023/", "subreddit_subscribers": 299827, "created_utc": 1702643917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "So i've been trying to get Archivebox running for the past few hours and i'm at a loss\n\nThe logs make it seem everything is working properly but when I go to [192.168.1.32:31200](https://192.168.1.32:31200) it just times out. \n\nI've tried using Portainer and running the docker compose setup guide through the shell with no luck.\n\nHere are the Portainer logs:\n\n    chown: cannot access '/browsers/*': No such file or directory\n    [i] [2023-12-15 10:29:49] ArchiveBox v0.7.1+editable: archivebox server --quick-init 0.0.0.0:31200\n       &gt; /data\n    [+] Initializing a new ArchiveBox v0.7.1+editable collection...\n    ----------------------------------------------------------------------\n    [+] Building archive folder structure...\n       + ./archive, ./sources, ./logs...\n       + ./ArchiveBox.conf...\n    [+] Building main SQL index and running initial migrations...\n       Operations to perform:\n       Apply all migrations: admin, auth, contenttypes, core, sessions\n       Running migrations:\n       Applying contenttypes.0001_initial... OK\n       Applying auth.0001_initial... OK\n       Applying admin.0001_initial... OK\n       Applying admin.0002_logentry_remove_auto_add... OK\n       Applying admin.0003_logentry_add_action_flag_choices... OK\n       Applying contenttypes.0002_remove_content_type_name... OK\n       Applying auth.0002_alter_permission_name_max_length... OK\n       Applying auth.0003_alter_user_email_max_length... OK\n       Applying auth.0004_alter_user_username_opts... OK\n       Applying auth.0005_alter_user_last_login_null... OK\n       Applying auth.0006_require_contenttypes_0002... OK\n       Applying auth.0007_alter_validators_add_error_messages... OK\n       Applying auth.0008_alter_user_username_max_length... OK\n       Applying auth.0009_alter_user_last_name_max_length... OK\n       Applying auth.0010_alter_group_name_max_length... OK\n       Applying auth.0011_update_proxy_permissions... OK\n       Applying auth.0012_alter_user_first_name_max_length... OK\n       Applying core.0001_initial... OK\n       Applying core.0002_auto_20200625_1521... OK\n       Applying core.0003_auto_20200630_1034... OK\n       Applying core.0004_auto_20200713_1552... OK\n       Applying core.0005_auto_20200728_0326... OK\n       Applying core.0006_auto_20201012_1520... OK\n       Applying core.0007_archiveresult... OK\n       Applying core.0008_auto_20210105_1421... OK\n       Applying core.0009_auto_20210216_1038... OK\n       Applying core.0010_auto_20210216_1055... OK\n       Applying core.0011_auto_20210216_1331... OK\n       Applying core.0012_auto_20210216_1425... OK\n       Applying core.0013_auto_20210218_0729... OK\n       Applying core.0014_auto_20210218_0729... OK\n       Applying core.0015_auto_20210218_0730... OK\n       Applying core.0016_auto_20210218_1204... OK\n       Applying core.0017_auto_20210219_0211... OK\n       Applying core.0018_auto_20210327_0952... OK\n       Applying core.0019_auto_20210401_0654... OK\n       Applying core.0020_auto_20210410_1031... OK\n       Applying core.0021_auto_20220914_0934... OK\n       Applying core.0022_auto_20231023_2008... OK\n       Applying sessions.0001_initial... OK\n       \u221a ./index.sqlite3\n    [*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n       &gt; Skipping full snapshot directory check (quick mode)\n    ----------------------------------------------------------------------\n    [\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n       Hint: To view your archive index, run:\n           archivebox server  # then visit http://127.0.0.1:8000\n       To add new links, you can run:\n           archivebox add &lt; ~/some/path/to/list_of_links.txt\n       For more usage and examples, run:\n           archivebox help\n    [+] Starting ArchiveBox webserver...\n       &gt; Logging errors to ./logs/errors.log\n    [!] No admin users exist yet, you will not be able to edit links in the UI.\n       To create an admin user, run:\n           archivebox manage createsuperuser\n    Performing system checks...\n    System check identified no issues (0 silenced).\n    December 15, 2023 - 10:29:59\n    Django version 3.1.14, using settings 'core.settings'\n    Starting development server at http://0.0.0.0:31200/\n    Quit the server with CONTROL-C.\n\nAnd here are the Proxmox shell logs:\n\n    chown: cannot access '/browsers/*': No such file or directory\n    [i] [2023-12-15 09:20:08] ArchiveBox v0.7.1+editable: archivebox init --setup\n        &gt; /data\n    \n    [+] Initializing a new ArchiveBox v0.7.1+editable collection...\n    ----------------------------------------------------------------------\n    \n    [+] Building archive folder structure...\n        + ./archive, ./sources, ./logs...\n        + ./ArchiveBox.conf...\n    \n    [+] Building main SQL index and running initial migrations...\n        Operations to perform:\n          Apply all migrations: admin, auth, contenttypes, core, sessions\n        Running migrations:\n        Applying contenttypes.0001_initial... OK\n        Applying auth.0001_initial... OK\n        Applying admin.0001_initial... OK\n        Applying admin.0002_logentry_remove_auto_add... OK\n        Applying admin.0003_logentry_add_action_flag_choices... OK\n        Applying contenttypes.0002_remove_content_type_name... OK\n        Applying auth.0002_alter_permission_name_max_length... OK\n        Applying auth.0003_alter_user_email_max_length... OK\n        Applying auth.0004_alter_user_username_opts... OK\n        Applying auth.0005_alter_user_last_login_null... OK\n        Applying auth.0006_require_contenttypes_0002... OK\n        Applying auth.0007_alter_validators_add_error_messages... OK\n        Applying auth.0008_alter_user_username_max_length... OK\n        Applying auth.0009_alter_user_last_name_max_length... OK\n        Applying auth.0010_alter_group_name_max_length... OK\n        Applying auth.0011_update_proxy_permissions... OK\n        Applying auth.0012_alter_user_first_name_max_length... OK\n        Applying core.0001_initial... OK\n        Applying core.0002_auto_20200625_1521... OK\n        Applying core.0003_auto_20200630_1034... OK\n        Applying core.0004_auto_20200713_1552... OK\n        Applying core.0005_auto_20200728_0326... OK\n        Applying core.0006_auto_20201012_1520... OK\n        Applying core.0007_archiveresult... OK\n        Applying core.0008_auto_20210105_1421... OK\n        Applying core.0009_auto_20210216_1038... OK\n        Applying core.0010_auto_20210216_1055... OK\n        Applying core.0011_auto_20210216_1331... OK\n        Applying core.0012_auto_20210216_1425... OK\n        Applying core.0013_auto_20210218_0729... OK\n        Applying core.0014_auto_20210218_0729... OK\n        Applying core.0015_auto_20210218_0730... OK\n        Applying core.0016_auto_20210218_1204... OK\n        Applying core.0017_auto_20210219_0211... OK\n        Applying core.0018_auto_20210327_0952... OK\n        Applying core.0019_auto_20210401_0654... OK\n        Applying core.0020_auto_20210410_1031... OK\n        Applying core.0021_auto_20220914_0934... OK\n        Applying core.0022_auto_20231023_2008... OK\n        Applying sessions.0001_initial... OK\n    \n        \u221a ./index.sqlite3\n    \n    [*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n    \n    [*] [2023-12-15 09:20:19] Writing 0 links to main index...\n        \u221a ./index.sqlite3                                                                                                                                                                                                                                                                 \n    \n    ----------------------------------------------------------------------\n    [\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n    \n    [+] Creating new admin user for the Web UI...\n    Username (leave blank to use 'archivebox'): admin\n    Email address: **********\n    Password: \n    Password (again): \n    The password is too similar to the username.\n    This password is too short. It must contain at least 8 characters.\n    This password is too common.\n    Bypass password validation and create user anyway? [y/N]: y\n    Superuser created successfully.\n    \n    [+] Installing enabled ArchiveBox dependencies automatically...\n    \n        Installing YOUTUBEDL_BINARY automatically using pip...\n    2023.10.13 is already installed yt-dlp\n    \n        Installing CHROME_BINARY automatically using playwright...\n    Chromium 119.0.6045.9 is already installed chromium-browser\n    \n        Installing SINGLEFILE_BINARY, READABILITY_BINARY, MERCURY_BINARY automatically using npm...\n    SINGLEFILE_BINARY, READABILITY_BINARY, and MERCURURY_BINARY are already installed\n    \n    [\u221a] Set up ArchiveBox and its dependencies successfully.\n    0.7.1+editable\n    ArchiveBox v0.7.1+editable Cpython Linux Linux-6.5.11-4-pve-x86_64-with-glibc2.36 x86_64\n    DEBUG=False IN_DOCKER=True IN_QEMU=False IS_TTY=True TZ=UTC FS_ATOMIC=True FS_REMOTE=True FS_USER=911:911 FS_PERMS=644 SEARCH_BACKEND=ripgrep\n    \n    [i] Dependency versions:\n     \u221a  PYTHON_BINARY         v3.11.6         valid     /usr/local/bin/python3.11                                                   \n     \u221a  SQLITE_BINARY         v2.6.0          valid     /usr/local/lib/python3.11/sqlite3/dbapi2.py                                 \n     \u221a  DJANGO_BINARY         v3.1.14         valid     /usr/local/lib/python3.11/site-packages/django/__init__.py                  \n     \u221a  ARCHIVEBOX_BINARY     v0.7.1          valid     /usr/local/bin/archivebox                                                   \n    \n     \u221a  CURL_BINARY           v8.4.0          valid     /usr/bin/curl                                                               \n     \u221a  WGET_BINARY           v1.21.3         valid     /usr/bin/wget                                                               \n     \u221a  NODE_BINARY           v21.1.0         valid     /usr/bin/node                                                               \n     \u221a  SINGLEFILE_BINARY     v1.1.18         valid     /app/node_modules/single-file-cli/single-file                               \n     \u221a  READABILITY_BINARY    v0.0.9          valid     /app/node_modules/readability-extractor/readability-extractor               \n     \u221a  MERCURY_BINARY        v1.0.0          valid     /app/node_modules/@postlight/parser/cli.js                                  \n     \u221a  GIT_BINARY            v2.39.2         valid     /usr/bin/git                                                                \n     \u221a  YOUTUBEDL_BINARY      v2023.10.13     valid     /usr/local/bin/yt-dlp                                                       \n     \u221a  CHROME_BINARY         v119.0.6045.9   valid     /usr/bin/chromium-browser                                                   \n     \u221a  RIPGREP_BINARY        v13.0.0         valid     /usr/bin/rg                                                                 \n    \n    [i] Source-code locations:\n     \u221a  PACKAGE_DIR           24 files        valid     /app/archivebox                                                             \n     \u221a  TEMPLATES_DIR         4 files         valid     /app/archivebox/templates                                                   \n     -  CUSTOM_TEMPLATES_DIR  -               disabled  None                                                                        \n    \n    [i] Secrets locations:\n     -  CHROME_USER_DATA_DIR  -               disabled  None                                                                        \n     -  COOKIES_FILE          -               disabled  None                                                                        \n    \n    [i] Data locations:\n     \u221a  OUTPUT_DIR            5 files @       valid     /data                                                                       \n     \u221a  SOURCES_DIR           0 files         valid     ./sources                                                                   \n     \u221a  LOGS_DIR              1 files         valid     ./logs                                                                      \n     \u221a  ARCHIVE_DIR           0 files         valid     ./archive                                                                   \n     \u221a  CONFIG_FILE           81.0 Bytes      valid     ./ArchiveBox.conf                                                           \n     \u221a  SQL_INDEX             204.0 KB        valid     ./index.sqlite3                                                             \n    \n    \n        Hint: To view your archive index, run:\n            archivebox server  # then visit http://127.0.0.1:8000\n    \n        To add new links, you can run:\n            archivebox add &lt; ~/some/path/to/list_of_links.txt\n    \n        For more usage and examples, run:\n            archivebox help", "author_fullname": "t2_py1z2u36", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archivebox timing out", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ixfjh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702637384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;ve been trying to get Archivebox running for the past few hours and i&amp;#39;m at a loss&lt;/p&gt;\n\n&lt;p&gt;The logs make it seem everything is working properly but when I go to &lt;a href=\"https://192.168.1.32:31200\"&gt;192.168.1.32:31200&lt;/a&gt; it just times out. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried using Portainer and running the docker compose setup guide through the shell with no luck.&lt;/p&gt;\n\n&lt;p&gt;Here are the Portainer logs:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;chown: cannot access &amp;#39;/browsers/*&amp;#39;: No such file or directory\n[i] [2023-12-15 10:29:49] ArchiveBox v0.7.1+editable: archivebox server --quick-init 0.0.0.0:31200\n   &amp;gt; /data\n[+] Initializing a new ArchiveBox v0.7.1+editable collection...\n----------------------------------------------------------------------\n[+] Building archive folder structure...\n   + ./archive, ./sources, ./logs...\n   + ./ArchiveBox.conf...\n[+] Building main SQL index and running initial migrations...\n   Operations to perform:\n   Apply all migrations: admin, auth, contenttypes, core, sessions\n   Running migrations:\n   Applying contenttypes.0001_initial... OK\n   Applying auth.0001_initial... OK\n   Applying admin.0001_initial... OK\n   Applying admin.0002_logentry_remove_auto_add... OK\n   Applying admin.0003_logentry_add_action_flag_choices... OK\n   Applying contenttypes.0002_remove_content_type_name... OK\n   Applying auth.0002_alter_permission_name_max_length... OK\n   Applying auth.0003_alter_user_email_max_length... OK\n   Applying auth.0004_alter_user_username_opts... OK\n   Applying auth.0005_alter_user_last_login_null... OK\n   Applying auth.0006_require_contenttypes_0002... OK\n   Applying auth.0007_alter_validators_add_error_messages... OK\n   Applying auth.0008_alter_user_username_max_length... OK\n   Applying auth.0009_alter_user_last_name_max_length... OK\n   Applying auth.0010_alter_group_name_max_length... OK\n   Applying auth.0011_update_proxy_permissions... OK\n   Applying auth.0012_alter_user_first_name_max_length... OK\n   Applying core.0001_initial... OK\n   Applying core.0002_auto_20200625_1521... OK\n   Applying core.0003_auto_20200630_1034... OK\n   Applying core.0004_auto_20200713_1552... OK\n   Applying core.0005_auto_20200728_0326... OK\n   Applying core.0006_auto_20201012_1520... OK\n   Applying core.0007_archiveresult... OK\n   Applying core.0008_auto_20210105_1421... OK\n   Applying core.0009_auto_20210216_1038... OK\n   Applying core.0010_auto_20210216_1055... OK\n   Applying core.0011_auto_20210216_1331... OK\n   Applying core.0012_auto_20210216_1425... OK\n   Applying core.0013_auto_20210218_0729... OK\n   Applying core.0014_auto_20210218_0729... OK\n   Applying core.0015_auto_20210218_0730... OK\n   Applying core.0016_auto_20210218_1204... OK\n   Applying core.0017_auto_20210219_0211... OK\n   Applying core.0018_auto_20210327_0952... OK\n   Applying core.0019_auto_20210401_0654... OK\n   Applying core.0020_auto_20210410_1031... OK\n   Applying core.0021_auto_20220914_0934... OK\n   Applying core.0022_auto_20231023_2008... OK\n   Applying sessions.0001_initial... OK\n   \u221a ./index.sqlite3\n[*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n   &amp;gt; Skipping full snapshot directory check (quick mode)\n----------------------------------------------------------------------\n[\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n   Hint: To view your archive index, run:\n       archivebox server  # then visit http://127.0.0.1:8000\n   To add new links, you can run:\n       archivebox add &amp;lt; ~/some/path/to/list_of_links.txt\n   For more usage and examples, run:\n       archivebox help\n[+] Starting ArchiveBox webserver...\n   &amp;gt; Logging errors to ./logs/errors.log\n[!] No admin users exist yet, you will not be able to edit links in the UI.\n   To create an admin user, run:\n       archivebox manage createsuperuser\nPerforming system checks...\nSystem check identified no issues (0 silenced).\nDecember 15, 2023 - 10:29:59\nDjango version 3.1.14, using settings &amp;#39;core.settings&amp;#39;\nStarting development server at http://0.0.0.0:31200/\nQuit the server with CONTROL-C.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And here are the Proxmox shell logs:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;chown: cannot access &amp;#39;/browsers/*&amp;#39;: No such file or directory\n[i] [2023-12-15 09:20:08] ArchiveBox v0.7.1+editable: archivebox init --setup\n    &amp;gt; /data\n\n[+] Initializing a new ArchiveBox v0.7.1+editable collection...\n----------------------------------------------------------------------\n\n[+] Building archive folder structure...\n    + ./archive, ./sources, ./logs...\n    + ./ArchiveBox.conf...\n\n[+] Building main SQL index and running initial migrations...\n    Operations to perform:\n      Apply all migrations: admin, auth, contenttypes, core, sessions\n    Running migrations:\n    Applying contenttypes.0001_initial... OK\n    Applying auth.0001_initial... OK\n    Applying admin.0001_initial... OK\n    Applying admin.0002_logentry_remove_auto_add... OK\n    Applying admin.0003_logentry_add_action_flag_choices... OK\n    Applying contenttypes.0002_remove_content_type_name... OK\n    Applying auth.0002_alter_permission_name_max_length... OK\n    Applying auth.0003_alter_user_email_max_length... OK\n    Applying auth.0004_alter_user_username_opts... OK\n    Applying auth.0005_alter_user_last_login_null... OK\n    Applying auth.0006_require_contenttypes_0002... OK\n    Applying auth.0007_alter_validators_add_error_messages... OK\n    Applying auth.0008_alter_user_username_max_length... OK\n    Applying auth.0009_alter_user_last_name_max_length... OK\n    Applying auth.0010_alter_group_name_max_length... OK\n    Applying auth.0011_update_proxy_permissions... OK\n    Applying auth.0012_alter_user_first_name_max_length... OK\n    Applying core.0001_initial... OK\n    Applying core.0002_auto_20200625_1521... OK\n    Applying core.0003_auto_20200630_1034... OK\n    Applying core.0004_auto_20200713_1552... OK\n    Applying core.0005_auto_20200728_0326... OK\n    Applying core.0006_auto_20201012_1520... OK\n    Applying core.0007_archiveresult... OK\n    Applying core.0008_auto_20210105_1421... OK\n    Applying core.0009_auto_20210216_1038... OK\n    Applying core.0010_auto_20210216_1055... OK\n    Applying core.0011_auto_20210216_1331... OK\n    Applying core.0012_auto_20210216_1425... OK\n    Applying core.0013_auto_20210218_0729... OK\n    Applying core.0014_auto_20210218_0729... OK\n    Applying core.0015_auto_20210218_0730... OK\n    Applying core.0016_auto_20210218_1204... OK\n    Applying core.0017_auto_20210219_0211... OK\n    Applying core.0018_auto_20210327_0952... OK\n    Applying core.0019_auto_20210401_0654... OK\n    Applying core.0020_auto_20210410_1031... OK\n    Applying core.0021_auto_20220914_0934... OK\n    Applying core.0022_auto_20231023_2008... OK\n    Applying sessions.0001_initial... OK\n\n    \u221a ./index.sqlite3\n\n[*] Checking links from indexes and archive folders (safe to Ctrl+C)...\n\n[*] [2023-12-15 09:20:19] Writing 0 links to main index...\n    \u221a ./index.sqlite3                                                                                                                                                                                                                                                                 \n\n----------------------------------------------------------------------\n[\u221a] Done. A new ArchiveBox collection was initialized (0 links).\n\n[+] Creating new admin user for the Web UI...\nUsername (leave blank to use &amp;#39;archivebox&amp;#39;): admin\nEmail address: **********\nPassword: \nPassword (again): \nThe password is too similar to the username.\nThis password is too short. It must contain at least 8 characters.\nThis password is too common.\nBypass password validation and create user anyway? [y/N]: y\nSuperuser created successfully.\n\n[+] Installing enabled ArchiveBox dependencies automatically...\n\n    Installing YOUTUBEDL_BINARY automatically using pip...\n2023.10.13 is already installed yt-dlp\n\n    Installing CHROME_BINARY automatically using playwright...\nChromium 119.0.6045.9 is already installed chromium-browser\n\n    Installing SINGLEFILE_BINARY, READABILITY_BINARY, MERCURY_BINARY automatically using npm...\nSINGLEFILE_BINARY, READABILITY_BINARY, and MERCURURY_BINARY are already installed\n\n[\u221a] Set up ArchiveBox and its dependencies successfully.\n0.7.1+editable\nArchiveBox v0.7.1+editable Cpython Linux Linux-6.5.11-4-pve-x86_64-with-glibc2.36 x86_64\nDEBUG=False IN_DOCKER=True IN_QEMU=False IS_TTY=True TZ=UTC FS_ATOMIC=True FS_REMOTE=True FS_USER=911:911 FS_PERMS=644 SEARCH_BACKEND=ripgrep\n\n[i] Dependency versions:\n \u221a  PYTHON_BINARY         v3.11.6         valid     /usr/local/bin/python3.11                                                   \n \u221a  SQLITE_BINARY         v2.6.0          valid     /usr/local/lib/python3.11/sqlite3/dbapi2.py                                 \n \u221a  DJANGO_BINARY         v3.1.14         valid     /usr/local/lib/python3.11/site-packages/django/__init__.py                  \n \u221a  ARCHIVEBOX_BINARY     v0.7.1          valid     /usr/local/bin/archivebox                                                   \n\n \u221a  CURL_BINARY           v8.4.0          valid     /usr/bin/curl                                                               \n \u221a  WGET_BINARY           v1.21.3         valid     /usr/bin/wget                                                               \n \u221a  NODE_BINARY           v21.1.0         valid     /usr/bin/node                                                               \n \u221a  SINGLEFILE_BINARY     v1.1.18         valid     /app/node_modules/single-file-cli/single-file                               \n \u221a  READABILITY_BINARY    v0.0.9          valid     /app/node_modules/readability-extractor/readability-extractor               \n \u221a  MERCURY_BINARY        v1.0.0          valid     /app/node_modules/@postlight/parser/cli.js                                  \n \u221a  GIT_BINARY            v2.39.2         valid     /usr/bin/git                                                                \n \u221a  YOUTUBEDL_BINARY      v2023.10.13     valid     /usr/local/bin/yt-dlp                                                       \n \u221a  CHROME_BINARY         v119.0.6045.9   valid     /usr/bin/chromium-browser                                                   \n \u221a  RIPGREP_BINARY        v13.0.0         valid     /usr/bin/rg                                                                 \n\n[i] Source-code locations:\n \u221a  PACKAGE_DIR           24 files        valid     /app/archivebox                                                             \n \u221a  TEMPLATES_DIR         4 files         valid     /app/archivebox/templates                                                   \n -  CUSTOM_TEMPLATES_DIR  -               disabled  None                                                                        \n\n[i] Secrets locations:\n -  CHROME_USER_DATA_DIR  -               disabled  None                                                                        \n -  COOKIES_FILE          -               disabled  None                                                                        \n\n[i] Data locations:\n \u221a  OUTPUT_DIR            5 files @       valid     /data                                                                       \n \u221a  SOURCES_DIR           0 files         valid     ./sources                                                                   \n \u221a  LOGS_DIR              1 files         valid     ./logs                                                                      \n \u221a  ARCHIVE_DIR           0 files         valid     ./archive                                                                   \n \u221a  CONFIG_FILE           81.0 Bytes      valid     ./ArchiveBox.conf                                                           \n \u221a  SQL_INDEX             204.0 KB        valid     ./index.sqlite3                                                             \n\n\n    Hint: To view your archive index, run:\n        archivebox server  # then visit http://127.0.0.1:8000\n\n    To add new links, you can run:\n        archivebox add &amp;lt; ~/some/path/to/list_of_links.txt\n\n    For more usage and examples, run:\n        archivebox help\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ixfjh", "is_robot_indexable": true, "report_reasons": null, "author": "DisasterousLamps", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ixfjh/archivebox_timing_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ixfjh/archivebox_timing_out/", "subreddit_subscribers": 299827, "created_utc": 1702637384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I\u2019m a bit skeptical of things like cloud flare tunnels and want to set up a Linode instance running a reverse proxy in the cloud. The idea is that I could host things on my local servers, and access them publicly without revealing my public IP. \n\nI\u2019d run something like Traefik on the public cloud node and then poke a hole in my home firewall for that IP only. I don\u2019t want to expose and forward a bunch of ports on my local network even if they\u2019re IP restricted, so I\u2019m thinking I could run another reverse proxy locally and forward 443? Is double hopping through proxies going to lead to headaches?\n\nAlso if everything is always TLS encrypted, would just using a cloudflare tunnel be any less secure?", "author_fullname": "t2_ehz9mae5c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reverse proxy in the cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ir0el", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702611993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a bit skeptical of things like cloud flare tunnels and want to set up a Linode instance running a reverse proxy in the cloud. The idea is that I could host things on my local servers, and access them publicly without revealing my public IP. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d run something like Traefik on the public cloud node and then poke a hole in my home firewall for that IP only. I don\u2019t want to expose and forward a bunch of ports on my local network even if they\u2019re IP restricted, so I\u2019m thinking I could run another reverse proxy locally and forward 443? Is double hopping through proxies going to lead to headaches?&lt;/p&gt;\n\n&lt;p&gt;Also if everything is always TLS encrypted, would just using a cloudflare tunnel be any less secure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ir0el", "is_robot_indexable": true, "report_reasons": null, "author": "BinaryPatrickDev", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ir0el/reverse_proxy_in_the_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ir0el/reverse_proxy_in_the_cloud/", "subreddit_subscribers": 299827, "created_utc": 1702611993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "So I run a big NAS and domoticz for automation on my home network.  I would like to be able to smoothly access this from the outside world, primarily from an android phone.\n\nI know VPN would be the standard and I've done that in the past, but frankly I found it to be tremendous a pain in the ass connecting and disconnecting, especially for my girlfriend.\n\nI'm currently exploring something like port forwarding 22 to a linux machine on my network using pre shared key only ssh, but I'm not real clear on how network access would work from that point.  Can that be set up to direct local traffic to my network and all other traffic via the normal network connection on the phone?  Any article recommendations?  All I can find seem to be directed towards tunneling all internet traffic through your home network, which isn't what I'm trying to do.  I just want to be able to hit my domoticz instance and my file server through the tunnel and ideally leave the connection persistent/auto reconnect when network is lost.", "author_fullname": "t2_pvwcxkg8x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to VPN for remote connection to home network", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ihtji", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702585637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I run a big NAS and domoticz for automation on my home network.  I would like to be able to smoothly access this from the outside world, primarily from an android phone.&lt;/p&gt;\n\n&lt;p&gt;I know VPN would be the standard and I&amp;#39;ve done that in the past, but frankly I found it to be tremendous a pain in the ass connecting and disconnecting, especially for my girlfriend.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently exploring something like port forwarding 22 to a linux machine on my network using pre shared key only ssh, but I&amp;#39;m not real clear on how network access would work from that point.  Can that be set up to direct local traffic to my network and all other traffic via the normal network connection on the phone?  Any article recommendations?  All I can find seem to be directed towards tunneling all internet traffic through your home network, which isn&amp;#39;t what I&amp;#39;m trying to do.  I just want to be able to hit my domoticz instance and my file server through the tunnel and ideally leave the connection persistent/auto reconnect when network is lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ihtji", "is_robot_indexable": true, "report_reasons": null, "author": "tamale_tomato", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ihtji/alternative_to_vpn_for_remote_connection_to_home/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ihtji/alternative_to_vpn_for_remote_connection_to_home/", "subreddit_subscribers": 299827, "created_utc": 1702585637.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Sandstorm is still alive?! Weird, I know.\n\nSix years ago I posted on this sub about a [package I made for Kiwix](https://www.reddit.com/r/selfhosted/comments/6v3gpa/host_wikipedia_and_much_more_at_home_on_sandstorm/). I still believe in the Sandstorm platform, and I wanted to show that it still has potential. I've now released something much more ambitious, an OpenStreetMap app I call **Desert Atlas**:\n\n[https://sandstorm.org/news/2023-12-05-osm-on-sandstorm](https://sandstorm.org/news/2023-12-05-osm-on-sandstorm) *(apologies if the demo button is broken, we've had mysterious issues there)*\n\nIt's **fully self-hosted**. This means you point and click to choose regions of the base map that you download. Kind of like Organic Maps, except the regions are saved to the Sandstorm \"grain\" (i.e. on your server). Once you have your regions, you can privately search and bookmark locations with friends. When you're done you can each export those bookmarks to Organic Maps or OsmAnd for navigation.\n\nBy comparison, Facilmap (available for YunoHost) and Nextcloud Maps call out to third party services for base maps and search queries. Headway on the other hand is fully self-hosted (I saw that they announced themselves in this sub). Desert Atlas is much more stripped down than Headway, mainly because of the limitations of Sandstorm (no Postgres). This trades off some quality and features for even more simplicity: Everything from installation of the app (thanks to Sandstorm) to downloading regions is done in the browser UI. (Sandstorm itself requires a little CLI time at the start.)", "author_fullname": "t2_31bdi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fully self-hosted OpenStreetMap on Sandstorm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "release", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18imzgf", "quarantine": false, "link_flair_text_color": null, "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Release", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702599994.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702599550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sandstorm is still alive?! Weird, I know.&lt;/p&gt;\n\n&lt;p&gt;Six years ago I posted on this sub about a &lt;a href=\"https://www.reddit.com/r/selfhosted/comments/6v3gpa/host_wikipedia_and_much_more_at_home_on_sandstorm/\"&gt;package I made for Kiwix&lt;/a&gt;. I still believe in the Sandstorm platform, and I wanted to show that it still has potential. I&amp;#39;ve now released something much more ambitious, an OpenStreetMap app I call &lt;strong&gt;Desert Atlas&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://sandstorm.org/news/2023-12-05-osm-on-sandstorm\"&gt;https://sandstorm.org/news/2023-12-05-osm-on-sandstorm&lt;/a&gt; &lt;em&gt;(apologies if the demo button is broken, we&amp;#39;ve had mysterious issues there)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s &lt;strong&gt;fully self-hosted&lt;/strong&gt;. This means you point and click to choose regions of the base map that you download. Kind of like Organic Maps, except the regions are saved to the Sandstorm &amp;quot;grain&amp;quot; (i.e. on your server). Once you have your regions, you can privately search and bookmark locations with friends. When you&amp;#39;re done you can each export those bookmarks to Organic Maps or OsmAnd for navigation.&lt;/p&gt;\n\n&lt;p&gt;By comparison, Facilmap (available for YunoHost) and Nextcloud Maps call out to third party services for base maps and search queries. Headway on the other hand is fully self-hosted (I saw that they announced themselves in this sub). Desert Atlas is much more stripped down than Headway, mainly because of the limitations of Sandstorm (no Postgres). This trades off some quality and features for even more simplicity: Everything from installation of the app (thanks to Sandstorm) to downloading regions is done in the browser UI. (Sandstorm itself requires a little CLI time at the start.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ffHr7IhgYIRZT70eZSLaBMe4JaTzIFxLRtgwu59sWKE.jpg?auto=webp&amp;s=31d42c4e50c6fe6399118393b641919cf79a5ae1", "width": 400, "height": 489}, "resolutions": [{"url": "https://external-preview.redd.it/ffHr7IhgYIRZT70eZSLaBMe4JaTzIFxLRtgwu59sWKE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1988359b7cd341959660b1fac9ee734d92640113", "width": 108, "height": 132}, {"url": "https://external-preview.redd.it/ffHr7IhgYIRZT70eZSLaBMe4JaTzIFxLRtgwu59sWKE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=886e9a5dec8ad3ec5e7b66481b406ea2b2c0c84e", "width": 216, "height": 264}, {"url": "https://external-preview.redd.it/ffHr7IhgYIRZT70eZSLaBMe4JaTzIFxLRtgwu59sWKE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2aee50df0638889465dd850d4a88645d4e1c4ddb", "width": 320, "height": 391}], "variants": {}, "id": "bHZ1ZJ2KYlUoT285JXkgeVALnd6Jtz7GjgtW_RWXnsE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7a2c90d0-4655-11ec-b067-9e334eed55f0", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "18imzgf", "is_robot_indexable": true, "report_reasons": null, "author": "orblivion", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18imzgf/fully_selfhosted_openstreetmap_on_sandstorm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18imzgf/fully_selfhosted_openstreetmap_on_sandstorm/", "subreddit_subscribers": 299827, "created_utc": 1702599550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Continuing on from my last post: https://www.reddit.com/r/selfhosted/comments/18bj44u/setting_up_a_local_domain/\n\nI've committed myself to installing Caddy and Pihole to manage my local domains. After doing a bit of googling I decided to host them on an rpi I've got as my Synology NAS 'owns' ports 80 and 443,and it sounded like a lot of faff to get Caddy to work.\n\nThis led me on a new merry adventure as I learned how to backup my pi's \ud83d\ude02 (was not merry at all).\n\nNow that that is done and I'm ready for the next step I'm wondering if there are other services I should be running on other devices instead of on my Synology? \nOr does it not really matter (aside from processing power, of which I think jellyfin is the most intensive)? \n\nCurrently the NAS is hosting portainer, homarr, jelly fin and my  arr stack. After I've got my local domains working I was going to further spin up mealie/tandoori, immich, open project, homeassistant, and calibre.\n\nOne Rpi is currently running klipper, and this is the one I'll run Caddy and pihole from - or should pihole be on the NAS?\n\nThe other rpi is running the lumicube software and not much else.\n\nI do have an old PC I could install Linux on - but I don't think I quite need it. Yet.\n(Incidentally is that the easiest way to go about it with an old PC? Install Mint or DietPi and run dockers from it?)\n\nAs always thanks in advance, I seem to have picked up a fulfilling wee hobby, that has me constantly searching for answers \ud83d\ude02 Does this ever end?", "author_fullname": "t2_gmvk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What services should I run on my NAS and which should I run on rpi/pc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ilqwm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702596061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Continuing on from my last post: &lt;a href=\"https://www.reddit.com/r/selfhosted/comments/18bj44u/setting_up_a_local_domain/\"&gt;https://www.reddit.com/r/selfhosted/comments/18bj44u/setting_up_a_local_domain/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve committed myself to installing Caddy and Pihole to manage my local domains. After doing a bit of googling I decided to host them on an rpi I&amp;#39;ve got as my Synology NAS &amp;#39;owns&amp;#39; ports 80 and 443,and it sounded like a lot of faff to get Caddy to work.&lt;/p&gt;\n\n&lt;p&gt;This led me on a new merry adventure as I learned how to backup my pi&amp;#39;s \ud83d\ude02 (was not merry at all).&lt;/p&gt;\n\n&lt;p&gt;Now that that is done and I&amp;#39;m ready for the next step I&amp;#39;m wondering if there are other services I should be running on other devices instead of on my Synology? \nOr does it not really matter (aside from processing power, of which I think jellyfin is the most intensive)? &lt;/p&gt;\n\n&lt;p&gt;Currently the NAS is hosting portainer, homarr, jelly fin and my  arr stack. After I&amp;#39;ve got my local domains working I was going to further spin up mealie/tandoori, immich, open project, homeassistant, and calibre.&lt;/p&gt;\n\n&lt;p&gt;One Rpi is currently running klipper, and this is the one I&amp;#39;ll run Caddy and pihole from - or should pihole be on the NAS?&lt;/p&gt;\n\n&lt;p&gt;The other rpi is running the lumicube software and not much else.&lt;/p&gt;\n\n&lt;p&gt;I do have an old PC I could install Linux on - but I don&amp;#39;t think I quite need it. Yet.\n(Incidentally is that the easiest way to go about it with an old PC? Install Mint or DietPi and run dockers from it?)&lt;/p&gt;\n\n&lt;p&gt;As always thanks in advance, I seem to have picked up a fulfilling wee hobby, that has me constantly searching for answers \ud83d\ude02 Does this ever end?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ilqwm", "is_robot_indexable": true, "report_reasons": null, "author": "Haliphone", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ilqwm/what_services_should_i_run_on_my_nas_and_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ilqwm/what_services_should_i_run_on_my_nas_and_which/", "subreddit_subscribers": 299827, "created_utc": 1702596061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Unexpected behaviour: When searching my local ip, a nextcloud install wizard is displayed.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/d2ems12q1c6c1.png?width=450&amp;format=png&amp;auto=webp&amp;s=740cac857bf0b30f95f912e5d394b9a428d9e726\n\nI installed nextcloud months ago using the following compose file:\n\n\\---\n\nversion: \"2\"\n\nservices:\n\n  nextcloud:\n\nimage: linuxserver/nextcloud:latest\n\ncontainer\\_name: nextcloud\n\nenvironment:\n\n\\- PUID=1000\n\n\\- PGID=1000\n\n\\- TZ=europe/london\n\n&amp;#x200B;\n\nvolumes:\n\n\\- /home/eg/portainer/Config/Nextcloud/Config:/config\n\n\\- /home/eg/portainer/Config/Nextcloud/Data:/data\n\nports:\n\n\\- 8443:443\n\nrestart: unless-stopped\n\ndepends\\_on:\n\n\\- nextcloud\\_db\n\n  nextcloud\\_db:\n\nimage: linuxserver/mariadb:latest\n\ncontainer\\_name: nextcloud\\_db\n\nenvironment:\n\n\\- PUID=1000\n\n\\- PGID=1000\n\n\\- MYSQL\\_ROOT\\_PASSWORD=password\n\n\\- TZ=europe/london\n\n\\- MYSQL\\_DATABASE=nextcloud\\_db\n\n\\- MYSQL\\_USER=nextcloud\n\n\\- MYSQL\\_PASSWORD=password\n\nvolumes:\n\n\\- /home/eg/portainer/Config/Nextcloud/DB:/config\n\nports:\n\n\\- 3306:3306\n\n&amp;#x200B;\n\nI discovered this entirely on accident when I entered my devices local IP into chrome. \n\n&amp;#x200B;\n\nI have tried numerous attempts at debugging:\n\n&amp;#x200B;\n\n1. This page still shows even after shutting down my nextcloud container\n2. using the command  $ sudo dpkg-query -f '${binary:Package}\\\\n' -W &gt; completePackage.txt generates a text document with all 600 packages installed on my ubuntu server, none of which contain a package called nextcloud or anything similar\n3. using the command $  netstat -ano | grep 80 givecs the following output:\n4. &amp;#x200B;\n\nhttps://preview.redd.it/dgqkxwxq1c6c1.jpg?width=920&amp;format=pjpg&amp;auto=webp&amp;s=b747848d51a1ce61d12b08e143d7de47779ab308\n\nI don't fully understand the output but there is nothing even using HTTP or HTTPS\n\n&amp;#x200B;\n\nExpected behaviour: When no containers running, my local IP should be unresolvable, but even after a reboot as well as my nextcloud stack is stopped this install page still shows. I have also tried clearing browser cache, cookies, and searching from another device.", "author_fullname": "t2_mzt0e93je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nextcloud: Unexpected web installer found when searching local ip", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dgqkxwxq1c6c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 22, "x": 108, "u": "https://preview.redd.it/dgqkxwxq1c6c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=50b4dc123a994ec4d4e5367f88733fa8b41176c1"}, {"y": 44, "x": 216, "u": "https://preview.redd.it/dgqkxwxq1c6c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=521d6508f59dac0d500a05f011af3bf028cc5c83"}, {"y": 66, "x": 320, "u": "https://preview.redd.it/dgqkxwxq1c6c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a88de3d57211e12ee8f70becfec0f4b508d199b2"}, {"y": 132, "x": 640, "u": "https://preview.redd.it/dgqkxwxq1c6c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dbc53329ef39e6a4a7ba8c56f294e34e89ca1447"}], "s": {"y": 190, "x": 920, "u": "https://preview.redd.it/dgqkxwxq1c6c1.jpg?width=920&amp;format=pjpg&amp;auto=webp&amp;s=b747848d51a1ce61d12b08e143d7de47779ab308"}, "id": "dgqkxwxq1c6c1"}, "d2ems12q1c6c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 145, "x": 108, "u": "https://preview.redd.it/d2ems12q1c6c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=38181aab863779eb4386002f7c090f6bef4f8cab"}, {"y": 290, "x": 216, "u": "https://preview.redd.it/d2ems12q1c6c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f4e1cae245c108763a0e6623edd6b589ee41c084"}, {"y": 430, "x": 320, "u": "https://preview.redd.it/d2ems12q1c6c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d0fcaecfa958f44248e681f9b73464ef3a2705d"}], "s": {"y": 606, "x": 450, "u": "https://preview.redd.it/d2ems12q1c6c1.png?width=450&amp;format=png&amp;auto=webp&amp;s=740cac857bf0b30f95f912e5d394b9a428d9e726"}, "id": "d2ems12q1c6c1"}}, "name": "t3_18ijw5a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VmebnWG1onLiI6w-HFd5eHKrDOvQUKTqL2Ua-K5vNuk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702591192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Unexpected behaviour: When searching my local ip, a nextcloud install wizard is displayed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/d2ems12q1c6c1.png?width=450&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=740cac857bf0b30f95f912e5d394b9a428d9e726\"&gt;https://preview.redd.it/d2ems12q1c6c1.png?width=450&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=740cac857bf0b30f95f912e5d394b9a428d9e726&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I installed nextcloud months ago using the following compose file:&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;version: &amp;quot;2&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;services:&lt;/p&gt;\n\n&lt;p&gt;nextcloud:&lt;/p&gt;\n\n&lt;p&gt;image: linuxserver/nextcloud:latest&lt;/p&gt;\n\n&lt;p&gt;container_name: nextcloud&lt;/p&gt;\n\n&lt;p&gt;environment:&lt;/p&gt;\n\n&lt;p&gt;- PUID=1000&lt;/p&gt;\n\n&lt;p&gt;- PGID=1000&lt;/p&gt;\n\n&lt;p&gt;- TZ=europe/london&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;volumes:&lt;/p&gt;\n\n&lt;p&gt;- /home/eg/portainer/Config/Nextcloud/Config:/config&lt;/p&gt;\n\n&lt;p&gt;- /home/eg/portainer/Config/Nextcloud/Data:/data&lt;/p&gt;\n\n&lt;p&gt;ports:&lt;/p&gt;\n\n&lt;p&gt;- 8443:443&lt;/p&gt;\n\n&lt;p&gt;restart: unless-stopped&lt;/p&gt;\n\n&lt;p&gt;depends_on:&lt;/p&gt;\n\n&lt;p&gt;- nextcloud_db&lt;/p&gt;\n\n&lt;p&gt;nextcloud_db:&lt;/p&gt;\n\n&lt;p&gt;image: linuxserver/mariadb:latest&lt;/p&gt;\n\n&lt;p&gt;container_name: nextcloud_db&lt;/p&gt;\n\n&lt;p&gt;environment:&lt;/p&gt;\n\n&lt;p&gt;- PUID=1000&lt;/p&gt;\n\n&lt;p&gt;- PGID=1000&lt;/p&gt;\n\n&lt;p&gt;- MYSQL_ROOT_PASSWORD=password&lt;/p&gt;\n\n&lt;p&gt;- TZ=europe/london&lt;/p&gt;\n\n&lt;p&gt;- MYSQL_DATABASE=nextcloud_db&lt;/p&gt;\n\n&lt;p&gt;- MYSQL_USER=nextcloud&lt;/p&gt;\n\n&lt;p&gt;- MYSQL_PASSWORD=password&lt;/p&gt;\n\n&lt;p&gt;volumes:&lt;/p&gt;\n\n&lt;p&gt;- /home/eg/portainer/Config/Nextcloud/DB:/config&lt;/p&gt;\n\n&lt;p&gt;ports:&lt;/p&gt;\n\n&lt;p&gt;- 3306:3306&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I discovered this entirely on accident when I entered my devices local IP into chrome. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have tried numerous attempts at debugging:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;This page still shows even after shutting down my nextcloud container&lt;/li&gt;\n&lt;li&gt;using the command  $ sudo dpkg-query -f &amp;#39;${binary:Package}\\n&amp;#39; -W &amp;gt; completePackage.txt generates a text document with all 600 packages installed on my ubuntu server, none of which contain a package called nextcloud or anything similar&lt;/li&gt;\n&lt;li&gt;using the command $  netstat -ano | grep 80 givecs the following output:&lt;/li&gt;\n&lt;li&gt;&amp;#x200B;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dgqkxwxq1c6c1.jpg?width=920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b747848d51a1ce61d12b08e143d7de47779ab308\"&gt;https://preview.redd.it/dgqkxwxq1c6c1.jpg?width=920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b747848d51a1ce61d12b08e143d7de47779ab308&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t fully understand the output but there is nothing even using HTTP or HTTPS&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Expected behaviour: When no containers running, my local IP should be unresolvable, but even after a reboot as well as my nextcloud stack is stopped this install page still shows. I have also tried clearing browser cache, cookies, and searching from another device.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ijw5a", "is_robot_indexable": true, "report_reasons": null, "author": "supernova-4420", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ijw5a/nextcloud_unexpected_web_installer_found_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ijw5a/nextcloud_unexpected_web_installer_found_when/", "subreddit_subscribers": 299827, "created_utc": 1702591192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello Selfhosters,\n\nI have been running pihole  and pivpn (wireguard) on a pi zero w for 3 years aproximately. Recenlty I have moved and decidede to build my own server. Im running Proxmox and I have 2 vm's running. One for automated media management and one for Home assistant. I would like to move Pihole and pivpn to my new server. I've tried hosting it on the VM for the automated media management but it is somehow interfering with my indexers so it doesn't work for me. I also like the idea of isolation/serperating certain tasks. So i've tried insalling Pihole in a LXC container wich worked but when I want to install pivpn I run into errors because of privileged or unprivileged container iirc. \n\nAny advise on what would be the best fit for this situation. Im looking for the most lightweigt way to host Pihole + vpn withing proxmox. Can eighter be VM or LXC. Any advise would be much appreciated!", "author_fullname": "t2_7g226", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pihole + VPN on proxmox", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ivsgl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702630263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Selfhosters,&lt;/p&gt;\n\n&lt;p&gt;I have been running pihole  and pivpn (wireguard) on a pi zero w for 3 years aproximately. Recenlty I have moved and decidede to build my own server. Im running Proxmox and I have 2 vm&amp;#39;s running. One for automated media management and one for Home assistant. I would like to move Pihole and pivpn to my new server. I&amp;#39;ve tried hosting it on the VM for the automated media management but it is somehow interfering with my indexers so it doesn&amp;#39;t work for me. I also like the idea of isolation/serperating certain tasks. So i&amp;#39;ve tried insalling Pihole in a LXC container wich worked but when I want to install pivpn I run into errors because of privileged or unprivileged container iirc. &lt;/p&gt;\n\n&lt;p&gt;Any advise on what would be the best fit for this situation. Im looking for the most lightweigt way to host Pihole + vpn withing proxmox. Can eighter be VM or LXC. Any advise would be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ivsgl", "is_robot_indexable": true, "report_reasons": null, "author": "vivachris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ivsgl/pihole_vpn_on_proxmox/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ivsgl/pihole_vpn_on_proxmox/", "subreddit_subscribers": 299827, "created_utc": 1702630263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Been looking for something that can achieve the need but never found anything. So time to ask.\n\n&amp;#x200B;\n\nAs indie dev I always need to get users logs from my apps for support and I'm doing most of the support publicly on a discourse server.\n\nUsers uploading the files to discourse can trigger some small privacy issues and makes it hard to manage for deletion after no more needed.\n\nSo I'm looking for a solution where anonymous people could easily upload files that no one but me and them could access. (With some basic security like file size limits and number of uploads by a given IP per X time)\n\nIdeally it would generate an ID that they give to me and a password so they can still access the file it they want to delete themselves, but can give me the ID publicly as password would be required to access. (And me getting access without the password to avoid the issue of them giving it to me).\n\nBonus would be automated deletion of the files after a configurable delay.\n\nAnything that requires users to create an account does not really work.\n\nIf they no more have access to the file after upload and closing the page this can be OK.", "author_fullname": "t2_9oh0z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hosting securely temporary logs between anonymous persons and me.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iuysh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702626674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been looking for something that can achieve the need but never found anything. So time to ask.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As indie dev I always need to get users logs from my apps for support and I&amp;#39;m doing most of the support publicly on a discourse server.&lt;/p&gt;\n\n&lt;p&gt;Users uploading the files to discourse can trigger some small privacy issues and makes it hard to manage for deletion after no more needed.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for a solution where anonymous people could easily upload files that no one but me and them could access. (With some basic security like file size limits and number of uploads by a given IP per X time)&lt;/p&gt;\n\n&lt;p&gt;Ideally it would generate an ID that they give to me and a password so they can still access the file it they want to delete themselves, but can give me the ID publicly as password would be required to access. (And me getting access without the password to avoid the issue of them giving it to me).&lt;/p&gt;\n\n&lt;p&gt;Bonus would be automated deletion of the files after a configurable delay.&lt;/p&gt;\n\n&lt;p&gt;Anything that requires users to create an account does not really work.&lt;/p&gt;\n\n&lt;p&gt;If they no more have access to the file after upload and closing the page this can be OK.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iuysh", "is_robot_indexable": true, "report_reasons": null, "author": "Tolriq", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iuysh/hosting_securely_temporary_logs_between_anonymous/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iuysh/hosting_securely_temporary_logs_between_anonymous/", "subreddit_subscribers": 299827, "created_utc": 1702626674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm looking for some project / task management software that allows me to view tasks across multiple \"project\" (or whatever term the app uses). Basically the idea is that we have a household \"project\" (currently in Trello) that my wife and I both work on but I also have many side projects that I work on I need to keep separate. However, I want one unified view across all projects where I can see what should be worked on next, what's overdue, what she's working on, etc.\n\n**Requirements:**\n\n* **Cross-project views** (must have)\n* **Mobile support**  (my wife work mostly on mobile for her tasks)\n* **Kanban support** (might be flexible on this but would really like it)\n\nSo far I've tried the following and either they are overloaded with features I don't need, ugly, or in most cases don't have the cross-project view I need.\n\n* **Openproject** (overkill and ugly / unintuitive interface)\n* **Focalboard** (simple, decent, mobile is in beta and janky, no cross-project views)\n* **leantime** (no cross-project view)  \nEdit: Actually there basically is with the Home view which lists your tasks from all projects and you can group them by due date, project, etc. Not bad. I might give this more of a try.\n* **taiga** (no cross-project view)\n* **WeKan** (no cross-project view)\n* **Planka** (no cross-project view)\n* **ZenTao** (cross-project view but clunky mobile experience and a lot of features I don't need)\n* **TaskCafe** (cross-project list view but mobile pretty broken and project semi-abandoned)\n* **NextCloud Deck** (no cross-project view? can't tell)\n* **Plane** (closest so far but only has \"spreadsheet view\" for cross-project view). The [Docker install](https://github.com/makeplane/plane/blob/preview/docker-compose.yml) also requires like 9? images / containers which seems pretty heavy", "author_fullname": "t2_atxoa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project management software that has cross-project dashboard / views?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iqw6d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702621293.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702611615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for some project / task management software that allows me to view tasks across multiple &amp;quot;project&amp;quot; (or whatever term the app uses). Basically the idea is that we have a household &amp;quot;project&amp;quot; (currently in Trello) that my wife and I both work on but I also have many side projects that I work on I need to keep separate. However, I want one unified view across all projects where I can see what should be worked on next, what&amp;#39;s overdue, what she&amp;#39;s working on, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Cross-project views&lt;/strong&gt; (must have)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Mobile support&lt;/strong&gt;  (my wife work mostly on mobile for her tasks)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Kanban support&lt;/strong&gt; (might be flexible on this but would really like it)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So far I&amp;#39;ve tried the following and either they are overloaded with features I don&amp;#39;t need, ugly, or in most cases don&amp;#39;t have the cross-project view I need.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Openproject&lt;/strong&gt; (overkill and ugly / unintuitive interface)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Focalboard&lt;/strong&gt; (simple, decent, mobile is in beta and janky, no cross-project views)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;leantime&lt;/strong&gt; (no cross-project view)&lt;br/&gt;\nEdit: Actually there basically is with the Home view which lists your tasks from all projects and you can group them by due date, project, etc. Not bad. I might give this more of a try.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;taiga&lt;/strong&gt; (no cross-project view)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;WeKan&lt;/strong&gt; (no cross-project view)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Planka&lt;/strong&gt; (no cross-project view)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;ZenTao&lt;/strong&gt; (cross-project view but clunky mobile experience and a lot of features I don&amp;#39;t need)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;TaskCafe&lt;/strong&gt; (cross-project list view but mobile pretty broken and project semi-abandoned)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;NextCloud Deck&lt;/strong&gt; (no cross-project view? can&amp;#39;t tell)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Plane&lt;/strong&gt; (closest so far but only has &amp;quot;spreadsheet view&amp;quot; for cross-project view). The &lt;a href=\"https://github.com/makeplane/plane/blob/preview/docker-compose.yml\"&gt;Docker install&lt;/a&gt; also requires like 9? images / containers which seems pretty heavy&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?auto=webp&amp;s=22698fb6aedf8db0dd8b1096be2170230f52d329", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba7d8cf685e70b5d69626b4cf6136f9e2991fb14", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=19c5ab8605ccee5dab644b663a6cf31d64156530", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=11ede2b49a6d6af8f1f7ac8a2fdc708382287a96", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=28bd12319e14374ebe3c2b42bf09d82377a9f86e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0b1aca5578f2df9dcf49df70d147f11b327c3c02", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/u9NltSktLlemMrpIl0isL5pREEjllMavS2-vgCXs6IY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1ea58a04873f4087fc73eae47035995fdefb8c4", "width": 1080, "height": 540}], "variants": {}, "id": "KscnINYRQTsVomj6pESVRD9AbGWpMuqgnjOqrecfQ1A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iqw6d", "is_robot_indexable": true, "report_reasons": null, "author": "guesswhochickenpoo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iqw6d/project_management_software_that_has_crossproject/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iqw6d/project_management_software_that_has_crossproject/", "subreddit_subscribers": 299827, "created_utc": 1702611615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I came accross a smtp service called Blogmail, where the cost is free by having ads on it. Potentionally getting paid for the ads.\n\n&amp;#x200B;\n\nI want to try it, but the website kinda looks sus. Also their social media links don't really work. Has anybody used Blogmail and provide any review on it? Thanks", "author_fullname": "t2_2ield3wu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody used Blogmail for smtp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18iloqv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702595892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came accross a smtp service called Blogmail, where the cost is free by having ads on it. Potentionally getting paid for the ads.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to try it, but the website kinda looks sus. Also their social media links don&amp;#39;t really work. Has anybody used Blogmail and provide any review on it? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18iloqv", "is_robot_indexable": true, "report_reasons": null, "author": "blue2020xx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18iloqv/anybody_used_blogmail_for_smtp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18iloqv/anybody_used_blogmail_for_smtp/", "subreddit_subscribers": 299827, "created_utc": 1702595892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi. I'm really new to Jellyfin, but does anyone know how I could align my tabs with the top bar (i.e. Home and Favorites in line with the Jellyfin logo)?\n\nThis is how it is now:\n\n[https://imgur.com/Rl9Oc6S](https://imgur.com/Rl9Oc6S)\n\nAnd this is what I'm trying to achieve:\n\n[https://imgur.com/dOM7F9l](https://imgur.com/dOM7F9l)\n\nAny help would be greatly appreciated.", "author_fullname": "t2_a8wzyig5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jellyfin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ij75o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702589345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I&amp;#39;m really new to Jellyfin, but does anyone know how I could align my tabs with the top bar (i.e. Home and Favorites in line with the Jellyfin logo)?&lt;/p&gt;\n\n&lt;p&gt;This is how it is now:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/Rl9Oc6S\"&gt;https://imgur.com/Rl9Oc6S&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And this is what I&amp;#39;m trying to achieve:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/dOM7F9l\"&gt;https://imgur.com/dOM7F9l&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any help would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OpTZvmR9gObxPbAIlm9aWDEb2_zYDehSGUZGfS9A-9s.jpg?auto=webp&amp;s=cf9411ff143e75df1e1084862dcafdabdc7c47d7", "width": 1256, "height": 204}, "resolutions": [{"url": "https://external-preview.redd.it/OpTZvmR9gObxPbAIlm9aWDEb2_zYDehSGUZGfS9A-9s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ed08c0d9e9c886bec7a4a15402b78d879cf1a9e", "width": 108, "height": 17}, {"url": "https://external-preview.redd.it/OpTZvmR9gObxPbAIlm9aWDEb2_zYDehSGUZGfS9A-9s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1edd3c147bc4645225b2a64c7918dd44dfb44361", "width": 216, "height": 35}, {"url": "https://external-preview.redd.it/OpTZvmR9gObxPbAIlm9aWDEb2_zYDehSGUZGfS9A-9s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d9fc797a4c7113bf5ac6293470bb6b026cdb69ce", "width": 320, "height": 51}, {"url": "https://external-preview.redd.it/OpTZvmR9gObxPbAIlm9aWDEb2_zYDehSGUZGfS9A-9s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7237089198b48614b560e1c944c68cf87f6ae40c", "width": 640, "height": 103}, {"url": "https://external-preview.redd.it/OpTZvmR9gObxPbAIlm9aWDEb2_zYDehSGUZGfS9A-9s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=32702a324c9c6faa93f1f7b93a2df136487b51d7", "width": 960, "height": 155}, {"url": "https://external-preview.redd.it/OpTZvmR9gObxPbAIlm9aWDEb2_zYDehSGUZGfS9A-9s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e66938b5b0b13ead0a8137917e840c85753baf95", "width": 1080, "height": 175}], "variants": {}, "id": "MXoM2WmukgNkyCIC09Cc7gn0Lm-Fok-D6j5x2gnJvq8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ij75o", "is_robot_indexable": true, "report_reasons": null, "author": "JoziCowboy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ij75o/jellyfin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ij75o/jellyfin/", "subreddit_subscribers": 299827, "created_utc": 1702589345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "hey\n\nI've purchased several books in pdf and epub format and would like to self host a ebook library/media server to be used without an app and device independently\n\nit's important for me to be able to set bookmarks \n\nI've looked at calibre, komga and kavita\n\nKavita and komga seem to be focused on manga and comics, but my books are either belletristic or rule books for miniature games with a mixture of writing and a lot of pictures\n\ncalibre (web) could fit but I don't like that I have to use them in tandem to get the full feature set \n\ncan you recommend one?", "author_fullname": "t2_50as93h1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ebook reader for pdf and epub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "mediaserving", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18idzjf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Media Serving", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702575461.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve purchased several books in pdf and epub format and would like to self host a ebook library/media server to be used without an app and device independently&lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;s important for me to be able to set bookmarks &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at calibre, komga and kavita&lt;/p&gt;\n\n&lt;p&gt;Kavita and komga seem to be focused on manga and comics, but my books are either belletristic or rule books for miniature games with a mixture of writing and a lot of pictures&lt;/p&gt;\n\n&lt;p&gt;calibre (web) could fit but I don&amp;#39;t like that I have to use them in tandem to get the full feature set &lt;/p&gt;\n\n&lt;p&gt;can you recommend one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb71ccc0-7e67-11e9-841a-0e67038620c2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18idzjf", "is_robot_indexable": true, "report_reasons": null, "author": "IacovHall", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18idzjf/ebook_reader_for_pdf_and_epub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18idzjf/ebook_reader_for_pdf_and_epub/", "subreddit_subscribers": 299827, "created_utc": 1702575461.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm not a total noob at selfhosting but this network stuff really is messing with my brain..\n\nI have a proxmox server and all my services are **local only**.\n\nI have Adguard setup as my DNS server.  \nI have Nginx Proxy Manager setup.\n\nI setup **DNS rewrites** on Adguard:  \nuptimekuma.myserver -&gt; [192.168.1.10](https://192.168.1.10) (works when i go to uptimekuma.myserver:3001)  \njellyfin.myserver -&gt; [192.168.1.15](https://192.168.1.15) (works when i go to uptimekuma.myserver:8096)  \n\\*.myserver -&gt; [192.168.1.2](https://192.168.1.2) (NPM IP adress)\n\nI would like to go to uptimekuma.myserver **without specifiying a port**.  \nSo I set up NPM **Proxy Host**:  \njellyfin.myserver -&gt; IP: [192.168.1.15](https://192.168.1.15) PORT: 8096  \nOn my Browser this is working great by going to [http://jellyfin.myserver](http://jellyfin.myserver)   \nBut when I try it with other services like uptimekuma, proxmox, homeassistant, turnkey file server it does not resolve the adress.\n\nWhat is happening?  \nFrom what i understant when I type uptimekuma.myserver -&gt; Agduard sees \\*.myserver and sends the traffic to -&gt; [192.168.1.2](https://192.168.1.2) nginxproxymanager and this sees uptimekuma.myserver sends it to IP: 192.168.1.15 PORT: 8096... but its not working. If i manualy type [192.168.1.15:8096](https://192.168.1.15:8096) ofc its working as usual.\n\nMy goal is to be able to do everything locally and be able to reach a service by typing grafana.myserver.   \nIf I could add https wihtout messing with online services for ssl certs that would be great as well.  \nI nee that last part in order to get vaultwarden running.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_zvkb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help my understand Reverse Proxy and DNS Rewrites. What is happeing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18ibglj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1702568696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not a total noob at selfhosting but this network stuff really is messing with my brain..&lt;/p&gt;\n\n&lt;p&gt;I have a proxmox server and all my services are &lt;strong&gt;local only&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;I have Adguard setup as my DNS server.&lt;br/&gt;\nI have Nginx Proxy Manager setup.&lt;/p&gt;\n\n&lt;p&gt;I setup &lt;strong&gt;DNS rewrites&lt;/strong&gt; on Adguard:&lt;br/&gt;\nuptimekuma.myserver -&amp;gt; &lt;a href=\"https://192.168.1.10\"&gt;192.168.1.10&lt;/a&gt; (works when i go to uptimekuma.myserver:3001)&lt;br/&gt;\njellyfin.myserver -&amp;gt; &lt;a href=\"https://192.168.1.15\"&gt;192.168.1.15&lt;/a&gt; (works when i go to uptimekuma.myserver:8096)&lt;br/&gt;\n*.myserver -&amp;gt; &lt;a href=\"https://192.168.1.2\"&gt;192.168.1.2&lt;/a&gt; (NPM IP adress)&lt;/p&gt;\n\n&lt;p&gt;I would like to go to uptimekuma.myserver &lt;strong&gt;without specifiying a port&lt;/strong&gt;.&lt;br/&gt;\nSo I set up NPM &lt;strong&gt;Proxy Host&lt;/strong&gt;:&lt;br/&gt;\njellyfin.myserver -&amp;gt; IP: &lt;a href=\"https://192.168.1.15\"&gt;192.168.1.15&lt;/a&gt; PORT: 8096&lt;br/&gt;\nOn my Browser this is working great by going to &lt;a href=\"http://jellyfin.myserver\"&gt;http://jellyfin.myserver&lt;/a&gt;&lt;br/&gt;\nBut when I try it with other services like uptimekuma, proxmox, homeassistant, turnkey file server it does not resolve the adress.&lt;/p&gt;\n\n&lt;p&gt;What is happening?&lt;br/&gt;\nFrom what i understant when I type uptimekuma.myserver -&amp;gt; Agduard sees *.myserver and sends the traffic to -&amp;gt; &lt;a href=\"https://192.168.1.2\"&gt;192.168.1.2&lt;/a&gt; nginxproxymanager and this sees uptimekuma.myserver sends it to IP: 192.168.1.15 PORT: 8096... but its not working. If i manualy type &lt;a href=\"https://192.168.1.15:8096\"&gt;192.168.1.15:8096&lt;/a&gt; ofc its working as usual.&lt;/p&gt;\n\n&lt;p&gt;My goal is to be able to do everything locally and be able to reach a service by typing grafana.myserver.&lt;br/&gt;\nIf I could add https wihtout messing with online services for ssl certs that would be great as well.&lt;br/&gt;\nI nee that last part in order to get vaultwarden running.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18ibglj", "is_robot_indexable": true, "report_reasons": null, "author": "geroulas", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18ibglj/help_my_understand_reverse_proxy_and_dns_rewrites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18ibglj/help_my_understand_reverse_proxy_and_dns_rewrites/", "subreddit_subscribers": 299827, "created_utc": 1702568696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have two sections: **Structured** and **Carnage**\n\nIn **Structured**, I use:\n\nLidarr - For artists and albums (mix of Flac and MP3) with the Spotify Followed Artists List\n\nLidaTube - Homemade app to pick up the albums that Lidarr cannot find\n\n&amp;#x200B;\n\nIn **Carnage**, I use:\n\nSpotTube -  Homemade app to import a spotify playlist via youtube\n\nmetube - To import from youtube\n\nSyncify - Homemade app to stay updated with a Spotify playlist through a schedule\n\nPlaylistDir - Homemade app generating playlists from a folder of MP3s on a set schedule (useful for downloaded playlists)\n\n&amp;#x200B;\n\nWhat do you use?\n\nEdit: Homemade apps here -&gt; [https://github.com/TheWicklowWolf](https://github.com/TheWicklowWolf)", "author_fullname": "t2_r85zyhrd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How I Manage My Music: Structured vs. Carnage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18izjka", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1702645796.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1702645214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two sections: &lt;strong&gt;Structured&lt;/strong&gt; and &lt;strong&gt;Carnage&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In &lt;strong&gt;Structured&lt;/strong&gt;, I use:&lt;/p&gt;\n\n&lt;p&gt;Lidarr - For artists and albums (mix of Flac and MP3) with the Spotify Followed Artists List&lt;/p&gt;\n\n&lt;p&gt;LidaTube - Homemade app to pick up the albums that Lidarr cannot find&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In &lt;strong&gt;Carnage&lt;/strong&gt;, I use:&lt;/p&gt;\n\n&lt;p&gt;SpotTube -  Homemade app to import a spotify playlist via youtube&lt;/p&gt;\n\n&lt;p&gt;metube - To import from youtube&lt;/p&gt;\n\n&lt;p&gt;Syncify - Homemade app to stay updated with a Spotify playlist through a schedule&lt;/p&gt;\n\n&lt;p&gt;PlaylistDir - Homemade app generating playlists from a folder of MP3s on a set schedule (useful for downloaded playlists)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What do you use?&lt;/p&gt;\n\n&lt;p&gt;Edit: Homemade apps here -&amp;gt; &lt;a href=\"https://github.com/TheWicklowWolf\"&gt;https://github.com/TheWicklowWolf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p_FYipKJ0V18zd7aWCLPJfL4duMOtQtRyiE6XxGNtJs.jpg?auto=webp&amp;s=49bac094ac463fdd8fedaeaca347df2e479c3a77", "width": 420, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/p_FYipKJ0V18zd7aWCLPJfL4duMOtQtRyiE6XxGNtJs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=50b3b20c80763cc307a35c23a645568798f9ff9c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/p_FYipKJ0V18zd7aWCLPJfL4duMOtQtRyiE6XxGNtJs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a45ad6decb6c7b66879984c310c0768109b7c1a", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/p_FYipKJ0V18zd7aWCLPJfL4duMOtQtRyiE6XxGNtJs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d3655a539d336a36b3c436c5e6f61b29e668bf3", "width": 320, "height": 320}], "variants": {}, "id": "PdCPoGJ5Tjxkmfb22Vm2n1AVx9Bb6uumSj326zuC8wM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "18izjka", "is_robot_indexable": true, "report_reasons": null, "author": "TheWicklowWolf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/18izjka/how_i_manage_my_music_structured_vs_carnage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/18izjka/how_i_manage_my_music_structured_vs_carnage/", "subreddit_subscribers": 299827, "created_utc": 1702645214.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}